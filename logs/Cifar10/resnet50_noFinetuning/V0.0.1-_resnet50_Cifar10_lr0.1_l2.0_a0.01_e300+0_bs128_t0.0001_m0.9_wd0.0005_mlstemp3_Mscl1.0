V0.0.1-_resnet50_Cifar10_lr0.1_l2.0_a0.01_e300+0_bs128_t0.0001_m0.9_wd0.0005_mlstemp3_Mscl1.0
Files already downloaded and verified
M values:
 {Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.5254763960838318, Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.24196940660476685, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.15759095549583435, Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.13501641154289246, Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.3461485505104065, Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.17473100125789642, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.21617008745670319, Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.14946585893630981, Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.09060623496770859, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.08498729020357132, Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.11497705429792404, Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.11804789304733276, Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False): 0.08379501849412918, Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.1424030363559723, Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False): 0.19753389060497284, Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.16684924066066742, Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.22829987108707428, Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.12801074981689453, Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.09603530913591385, Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.06901206821203232, Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.12272872775793076, Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.0835055485367775, Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.07954221963882446, Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.12703275680541992, Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.19747452437877655, Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False): 0.15407174825668335, Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.1602816879749298, Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False): 0.10645194351673126, Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.10600411146879196, Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.13483507931232452, Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.21709460020065308, Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.11353497207164764, Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.0660422295331955, Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.10686782747507095, Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.06808818876743317, Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.05323619768023491, Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.08759226649999619, Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.07965513318777084, Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.06643471866846085, Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.12164679169654846, Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.09185265004634857, Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.06330689787864685, Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.1110600158572197, Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.12582343816757202, Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False): 0.09035182744264603, Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.07410024106502533, Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False): 0.07018566876649857, Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.0687103122472763, Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.04065759852528572, Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.03755198046565056, Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.04725675657391548, Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.045549724251031876, Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.06192586570978165, Linear(in_features=2048, out_features=100, bias=True): 0.44340774416923523}
current lr 1.00000e-01
Grad=  tensor(6435.8149, device='cuda:0')
Epoch: [0][0/391]	Time 0.267 (0.267)	Data 0.142 (0.142)	Loss 7.4160 (7.4160) ([5.020]+[2.396])	Prec@1 0.781 (0.781)
Epoch: [0][100/391]	Time 0.111 (0.112)	Data 0.000 (0.002)	Loss 5.7461 (8.6571) ([2.359]+[3.387])	Prec@1 13.281 (10.187)
Epoch: [0][200/391]	Time 0.113 (0.111)	Data 0.000 (0.001)	Loss 5.1844 (7.0729) ([2.185]+[2.999])	Prec@1 13.281 (11.831)
Epoch: [0][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 4.7156 (6.3582) ([2.062]+[2.653])	Prec@1 19.531 (14.428)
Test: [0/79]	Time 0.172 (0.172)	Loss 4.4136 (4.4136) ([2.051]+[2.363])	Prec@1 26.562 (26.562)
 * Prec@1 21.690
current lr 1.00000e-01
Grad=  tensor(0.4011, device='cuda:0')
Epoch: [1][0/391]	Time 0.258 (0.258)	Data 0.137 (0.137)	Loss 4.3571 (4.3571) ([1.994]+[2.363])	Prec@1 20.312 (20.312)
Epoch: [1][100/391]	Time 0.109 (0.112)	Data 0.000 (0.001)	Loss 4.0576 (4.2322) ([1.986]+[2.072])	Prec@1 21.875 (21.264)
Epoch: [1][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 3.7712 (4.0790) ([1.957]+[1.814])	Prec@1 24.219 (21.747)
Epoch: [1][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 3.6182 (3.9348) ([2.033]+[1.585])	Prec@1 21.875 (22.506)
Test: [0/79]	Time 0.169 (0.169)	Loss 3.3735 (3.3735) ([1.850]+[1.523])	Prec@1 23.438 (23.438)
 * Prec@1 28.370
current lr 1.00000e-01
Grad=  tensor(1.0549, device='cuda:0')
Epoch: [2][0/391]	Time 0.267 (0.267)	Data 0.148 (0.148)	Loss 3.3599 (3.3599) ([1.837]+[1.523])	Prec@1 24.219 (24.219)
Epoch: [2][100/391]	Time 0.108 (0.110)	Data 0.000 (0.002)	Loss 4.6201 (4.5953) ([1.951]+[2.669])	Prec@1 24.219 (27.266)
Epoch: [2][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 4.1009 (4.4654) ([1.842]+[2.259])	Prec@1 26.562 (28.001)
Epoch: [2][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 3.8006 (4.2778) ([1.931]+[1.870])	Prec@1 24.219 (28.543)
Test: [0/79]	Time 0.169 (0.169)	Loss 3.5298 (3.5298) ([1.931]+[1.599])	Prec@1 32.812 (32.812)
 * Prec@1 27.920
current lr 1.00000e-01
Grad=  tensor(1.0321, device='cuda:0')
Epoch: [3][0/391]	Time 0.259 (0.259)	Data 0.140 (0.140)	Loss 3.5494 (3.5494) ([1.951]+[1.599])	Prec@1 21.875 (21.875)
Epoch: [3][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 3.0901 (3.2610) ([1.729]+[1.361])	Prec@1 28.125 (32.704)
Epoch: [3][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 2.9844 (3.1199) ([1.823]+[1.161])	Prec@1 32.812 (34.220)
Epoch: [3][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 2.8082 (3.0022) ([1.813]+[0.995])	Prec@1 35.938 (35.029)
Test: [0/79]	Time 0.172 (0.172)	Loss 2.4829 (2.4829) ([1.519]+[0.964])	Prec@1 49.219 (49.219)
 * Prec@1 39.240
current lr 1.00000e-01
Grad=  tensor(0.8602, device='cuda:0')
Epoch: [4][0/391]	Time 0.261 (0.261)	Data 0.142 (0.142)	Loss 2.5654 (2.5654) ([1.602]+[0.964])	Prec@1 37.500 (37.500)
Epoch: [4][100/391]	Time 0.109 (0.110)	Data 0.000 (0.002)	Loss 2.5700 (2.5305) ([1.747]+[0.823])	Prec@1 41.406 (38.683)
Epoch: [4][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 2.3134 (2.4552) ([1.590]+[0.723])	Prec@1 42.188 (39.564)
Epoch: [4][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 2.0783 (2.3953) ([1.441]+[0.637])	Prec@1 47.656 (40.140)
Test: [0/79]	Time 0.170 (0.170)	Loss 2.0355 (2.0355) ([1.460]+[0.575])	Prec@1 46.875 (46.875)
 * Prec@1 44.590
current lr 1.00000e-01
Grad=  tensor(1.4301, device='cuda:0')
Epoch: [5][0/391]	Time 0.268 (0.268)	Data 0.149 (0.149)	Loss 2.0020 (2.0020) ([1.427]+[0.575])	Prec@1 49.219 (49.219)
Epoch: [5][100/391]	Time 0.109 (0.110)	Data 0.000 (0.002)	Loss 2.0200 (2.0607) ([1.487]+[0.533])	Prec@1 53.125 (44.423)
Epoch: [5][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 1.9854 (2.0282) ([1.498]+[0.487])	Prec@1 45.312 (44.873)
Epoch: [5][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 2.0400 (1.9873) ([1.565]+[0.475])	Prec@1 47.656 (45.915)
Test: [0/79]	Time 0.171 (0.171)	Loss 1.8347 (1.8347) ([1.402]+[0.433])	Prec@1 46.094 (46.094)
 * Prec@1 46.610
current lr 1.00000e-01
Grad=  tensor(2.4654, device='cuda:0')
Epoch: [6][0/391]	Time 0.265 (0.265)	Data 0.146 (0.146)	Loss 2.0672 (2.0672) ([1.635]+[0.433])	Prec@1 40.625 (40.625)
Epoch: [6][100/391]	Time 0.109 (0.110)	Data 0.000 (0.002)	Loss 1.7905 (1.7516) ([1.375]+[0.416])	Prec@1 51.562 (51.276)
Epoch: [6][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 1.8291 (1.7117) ([1.430]+[0.400])	Prec@1 41.406 (52.631)
Epoch: [6][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 1.6318 (1.6929) ([1.252]+[0.379])	Prec@1 53.125 (53.094)
Test: [0/79]	Time 0.174 (0.174)	Loss 1.6998 (1.6998) ([1.340]+[0.360])	Prec@1 50.000 (50.000)
 * Prec@1 53.420
current lr 1.00000e-01
Grad=  tensor(1.8809, device='cuda:0')
Epoch: [7][0/391]	Time 0.270 (0.270)	Data 0.150 (0.150)	Loss 1.5467 (1.5467) ([1.187]+[0.360])	Prec@1 56.250 (56.250)
Epoch: [7][100/391]	Time 0.110 (0.112)	Data 0.000 (0.002)	Loss 1.5201 (1.5315) ([1.172]+[0.348])	Prec@1 54.688 (57.604)
Epoch: [7][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 1.2855 (1.5051) ([0.946]+[0.339])	Prec@1 67.188 (58.127)
Epoch: [7][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 1.5854 (1.4895) ([1.243]+[0.342])	Prec@1 53.125 (58.677)
Test: [0/79]	Time 0.166 (0.166)	Loss 1.6171 (1.6171) ([1.285]+[0.332])	Prec@1 54.688 (54.688)
 * Prec@1 53.940
current lr 1.00000e-01
Grad=  tensor(1.6325, device='cuda:0')
Epoch: [8][0/391]	Time 0.258 (0.258)	Data 0.138 (0.138)	Loss 1.3839 (1.3839) ([1.052]+[0.332])	Prec@1 61.719 (61.719)
Epoch: [8][100/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 1.4250 (1.4291) ([1.094]+[0.331])	Prec@1 64.844 (60.752)
Epoch: [8][200/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 1.3489 (1.4082) ([1.028]+[0.321])	Prec@1 63.281 (61.384)
Epoch: [8][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 1.2327 (1.3963) ([0.919]+[0.313])	Prec@1 67.188 (61.776)
Test: [0/79]	Time 0.167 (0.167)	Loss 1.2610 (1.2610) ([0.943]+[0.318])	Prec@1 67.188 (67.188)
 * Prec@1 65.160
current lr 1.00000e-01
Grad=  tensor(1.1747, device='cuda:0')
Epoch: [9][0/391]	Time 0.265 (0.265)	Data 0.144 (0.144)	Loss 1.2395 (1.2395) ([0.922]+[0.318])	Prec@1 67.969 (67.969)
Epoch: [9][100/391]	Time 0.111 (0.112)	Data 0.000 (0.002)	Loss 1.3328 (1.3197) ([1.025]+[0.308])	Prec@1 60.156 (64.434)
Epoch: [9][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 1.2761 (1.3126) ([0.972]+[0.305])	Prec@1 67.188 (64.537)
Epoch: [9][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 1.0751 (1.3021) ([0.775]+[0.300])	Prec@1 74.219 (64.823)
Test: [0/79]	Time 0.167 (0.167)	Loss 1.4489 (1.4489) ([1.154]+[0.295])	Prec@1 60.938 (60.938)
 * Prec@1 59.500
current lr 1.00000e-01
Grad=  tensor(1.8329, device='cuda:0')
Epoch: [10][0/391]	Time 0.257 (0.257)	Data 0.136 (0.136)	Loss 1.0867 (1.0867) ([0.791]+[0.295])	Prec@1 74.219 (74.219)
Epoch: [10][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 1.2783 (1.2312) ([0.983]+[0.295])	Prec@1 69.531 (67.141)
Epoch: [10][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 1.1345 (1.2414) ([0.845]+[0.290])	Prec@1 70.312 (66.768)
Epoch: [10][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 1.1621 (1.2307) ([0.879]+[0.283])	Prec@1 65.625 (66.923)
Test: [0/79]	Time 0.172 (0.172)	Loss 1.5761 (1.5761) ([1.288]+[0.288])	Prec@1 58.594 (58.594)
 * Prec@1 57.200
current lr 1.00000e-01
Grad=  tensor(1.1281, device='cuda:0')
Epoch: [11][0/391]	Time 0.264 (0.264)	Data 0.143 (0.143)	Loss 1.0862 (1.0862) ([0.798]+[0.288])	Prec@1 73.438 (73.438)
Epoch: [11][100/391]	Time 0.111 (0.112)	Data 0.000 (0.002)	Loss 1.2969 (1.1903) ([1.014]+[0.283])	Prec@1 64.062 (68.386)
Epoch: [11][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 1.0276 (1.1804) ([0.733]+[0.295])	Prec@1 73.438 (68.478)
Epoch: [11][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 1.1815 (1.1890) ([0.888]+[0.294])	Prec@1 66.406 (68.156)
Test: [0/79]	Time 0.170 (0.170)	Loss 1.2419 (1.2419) ([0.961]+[0.281])	Prec@1 66.406 (66.406)
 * Prec@1 64.990
current lr 1.00000e-01
Grad=  tensor(1.1850, device='cuda:0')
Epoch: [12][0/391]	Time 0.265 (0.265)	Data 0.142 (0.142)	Loss 0.9569 (0.9569) ([0.676]+[0.281])	Prec@1 78.125 (78.125)
Epoch: [12][100/391]	Time 0.109 (0.112)	Data 0.000 (0.002)	Loss 1.1983 (1.1545) ([0.913]+[0.285])	Prec@1 66.406 (69.183)
Epoch: [12][200/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.9744 (1.1529) ([0.692]+[0.283])	Prec@1 73.438 (69.380)
Epoch: [12][300/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 1.1119 (1.1414) ([0.830]+[0.282])	Prec@1 73.438 (69.879)
Test: [0/79]	Time 0.177 (0.177)	Loss 1.2377 (1.2377) ([0.962]+[0.276])	Prec@1 66.406 (66.406)
 * Prec@1 60.960
current lr 1.00000e-01
Grad=  tensor(2.1236, device='cuda:0')
Epoch: [13][0/391]	Time 0.265 (0.265)	Data 0.144 (0.144)	Loss 1.2685 (1.2685) ([0.993]+[0.276])	Prec@1 65.625 (65.625)
Epoch: [13][100/391]	Time 0.111 (0.112)	Data 0.000 (0.002)	Loss 1.0381 (1.1278) ([0.759]+[0.279])	Prec@1 71.094 (70.019)
Epoch: [13][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 1.0586 (1.1149) ([0.787]+[0.272])	Prec@1 75.781 (70.491)
Epoch: [13][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.8571 (1.1040) ([0.587]+[0.270])	Prec@1 82.031 (70.808)
Test: [0/79]	Time 0.173 (0.173)	Loss 1.3566 (1.3566) ([1.087]+[0.269])	Prec@1 63.281 (63.281)
 * Prec@1 64.890
current lr 1.00000e-01
Grad=  tensor(1.7664, device='cuda:0')
Epoch: [14][0/391]	Time 0.260 (0.260)	Data 0.139 (0.139)	Loss 1.0274 (1.0274) ([0.758]+[0.269])	Prec@1 72.656 (72.656)
Epoch: [14][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 1.0259 (1.0789) ([0.761]+[0.265])	Prec@1 69.531 (71.736)
Epoch: [14][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.9636 (1.0734) ([0.701]+[0.263])	Prec@1 73.438 (71.961)
Epoch: [14][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 1.1066 (1.0656) ([0.847]+[0.260])	Prec@1 68.750 (72.181)
Test: [0/79]	Time 0.171 (0.171)	Loss 1.0620 (1.0620) ([0.802]+[0.260])	Prec@1 72.656 (72.656)
 * Prec@1 66.840
current lr 1.00000e-01
Grad=  tensor(1.5740, device='cuda:0')
Epoch: [15][0/391]	Time 0.263 (0.263)	Data 0.142 (0.142)	Loss 0.9236 (0.9236) ([0.664]+[0.260])	Prec@1 72.656 (72.656)
Epoch: [15][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 1.1180 (1.0512) ([0.858]+[0.260])	Prec@1 66.406 (72.532)
Epoch: [15][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 1.2796 (1.0474) ([1.023]+[0.257])	Prec@1 64.062 (72.652)
Epoch: [15][300/391]	Time 0.114 (0.111)	Data 0.000 (0.001)	Loss 0.7617 (1.0380) ([0.507]+[0.255])	Prec@1 81.250 (73.020)
Test: [0/79]	Time 0.170 (0.170)	Loss 1.3826 (1.3826) ([1.127]+[0.256])	Prec@1 61.719 (61.719)
 * Prec@1 59.010
current lr 1.00000e-01
Grad=  tensor(2.0229, device='cuda:0')
Epoch: [16][0/391]	Time 0.257 (0.257)	Data 0.137 (0.137)	Loss 0.9999 (0.9999) ([0.744]+[0.256])	Prec@1 74.219 (74.219)
Epoch: [16][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 1.0033 (1.0057) ([0.747]+[0.256])	Prec@1 72.656 (73.832)
Epoch: [16][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.9732 (1.0050) ([0.716]+[0.258])	Prec@1 75.000 (73.939)
Epoch: [16][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 1.1663 (1.0065) ([0.910]+[0.256])	Prec@1 68.750 (73.811)
Test: [0/79]	Time 0.169 (0.169)	Loss 1.1556 (1.1556) ([0.899]+[0.257])	Prec@1 70.312 (70.312)
 * Prec@1 66.500
current lr 1.00000e-01
Grad=  tensor(1.8801, device='cuda:0')
Epoch: [17][0/391]	Time 0.267 (0.267)	Data 0.142 (0.142)	Loss 1.0342 (1.0342) ([0.777]+[0.257])	Prec@1 72.656 (72.656)
Epoch: [17][100/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 1.0201 (0.9899) ([0.762]+[0.259])	Prec@1 71.094 (74.505)
Epoch: [17][200/391]	Time 0.114 (0.114)	Data 0.000 (0.001)	Loss 0.8474 (0.9787) ([0.590]+[0.257])	Prec@1 82.812 (74.848)
Epoch: [17][300/391]	Time 0.113 (0.114)	Data 0.000 (0.001)	Loss 1.0144 (0.9759) ([0.757]+[0.257])	Prec@1 71.875 (74.881)
Test: [0/79]	Time 0.176 (0.176)	Loss 1.4630 (1.4630) ([1.205]+[0.258])	Prec@1 61.719 (61.719)
 * Prec@1 63.830
current lr 1.00000e-01
Grad=  tensor(1.8420, device='cuda:0')
Epoch: [18][0/391]	Time 0.267 (0.267)	Data 0.144 (0.144)	Loss 0.9743 (0.9743) ([0.717]+[0.258])	Prec@1 76.562 (76.562)
Epoch: [18][100/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.9767 (0.9379) ([0.718]+[0.259])	Prec@1 78.125 (76.671)
Epoch: [18][200/391]	Time 0.114 (0.114)	Data 0.000 (0.001)	Loss 0.9086 (0.9398) ([0.650]+[0.259])	Prec@1 75.781 (76.625)
Epoch: [18][300/391]	Time 0.113 (0.114)	Data 0.000 (0.001)	Loss 0.9466 (0.9414) ([0.688]+[0.258])	Prec@1 77.344 (76.503)
Test: [0/79]	Time 0.178 (0.178)	Loss 0.9984 (0.9984) ([0.740]+[0.258])	Prec@1 71.875 (71.875)
 * Prec@1 74.480
current lr 1.00000e-01
Grad=  tensor(1.8431, device='cuda:0')
Epoch: [19][0/391]	Time 0.269 (0.269)	Data 0.146 (0.146)	Loss 0.8648 (0.8648) ([0.606]+[0.258])	Prec@1 79.688 (79.688)
Epoch: [19][100/391]	Time 0.110 (0.113)	Data 0.000 (0.002)	Loss 0.9147 (0.9237) ([0.657]+[0.257])	Prec@1 78.125 (76.856)
Epoch: [19][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.8006 (0.9197) ([0.543]+[0.257])	Prec@1 80.469 (77.122)
Epoch: [19][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 1.0303 (0.9215) ([0.772]+[0.258])	Prec@1 76.562 (77.025)
Test: [0/79]	Time 0.170 (0.170)	Loss 1.6790 (1.6790) ([1.422]+[0.257])	Prec@1 54.688 (54.688)
 * Prec@1 60.720
current lr 1.00000e-01
Grad=  tensor(1.8763, device='cuda:0')
Epoch: [20][0/391]	Time 0.262 (0.262)	Data 0.141 (0.141)	Loss 0.8557 (0.8557) ([0.599]+[0.257])	Prec@1 77.344 (77.344)
Epoch: [20][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.9411 (0.9035) ([0.684]+[0.258])	Prec@1 82.031 (77.885)
Epoch: [20][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.9968 (0.8912) ([0.740]+[0.256])	Prec@1 72.656 (78.179)
Epoch: [20][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.9348 (0.9014) ([0.678]+[0.257])	Prec@1 75.000 (77.816)
Test: [0/79]	Time 0.174 (0.174)	Loss 1.2184 (1.2184) ([0.962]+[0.256])	Prec@1 64.844 (64.844)
 * Prec@1 64.980
current lr 1.00000e-01
Grad=  tensor(2.4190, device='cuda:0')
Epoch: [21][0/391]	Time 0.268 (0.268)	Data 0.145 (0.145)	Loss 0.9938 (0.9938) ([0.738]+[0.256])	Prec@1 70.312 (70.312)
Epoch: [21][100/391]	Time 0.111 (0.113)	Data 0.000 (0.002)	Loss 0.7954 (0.8912) ([0.539]+[0.256])	Prec@1 79.688 (78.040)
Epoch: [21][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.9189 (0.8949) ([0.663]+[0.256])	Prec@1 77.344 (77.919)
Epoch: [21][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.9185 (0.8932) ([0.662]+[0.256])	Prec@1 78.906 (77.949)
Test: [0/79]	Time 0.174 (0.174)	Loss 0.9501 (0.9501) ([0.695]+[0.255])	Prec@1 76.562 (76.562)
 * Prec@1 76.670
current lr 1.00000e-01
Grad=  tensor(1.4991, device='cuda:0')
Epoch: [22][0/391]	Time 0.267 (0.267)	Data 0.146 (0.146)	Loss 0.7793 (0.7793) ([0.524]+[0.255])	Prec@1 84.375 (84.375)
Epoch: [22][100/391]	Time 0.110 (0.112)	Data 0.000 (0.002)	Loss 0.8561 (0.8658) ([0.601]+[0.255])	Prec@1 78.125 (79.216)
Epoch: [22][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.9259 (0.8790) ([0.672]+[0.254])	Prec@1 76.562 (78.724)
Epoch: [22][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 1.0339 (0.8791) ([0.781]+[0.253])	Prec@1 75.000 (78.558)
Test: [0/79]	Time 0.169 (0.169)	Loss 1.0605 (1.0605) ([0.808]+[0.253])	Prec@1 76.562 (76.562)
 * Prec@1 72.770
current lr 1.00000e-01
Grad=  tensor(1.9831, device='cuda:0')
Epoch: [23][0/391]	Time 0.261 (0.261)	Data 0.142 (0.142)	Loss 0.8662 (0.8662) ([0.614]+[0.253])	Prec@1 80.469 (80.469)
Epoch: [23][100/391]	Time 0.109 (0.110)	Data 0.000 (0.002)	Loss 0.8990 (0.8733) ([0.646]+[0.253])	Prec@1 80.469 (78.349)
Epoch: [23][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.9740 (0.8794) ([0.720]+[0.254])	Prec@1 78.125 (78.273)
Epoch: [23][300/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.9586 (0.8702) ([0.705]+[0.253])	Prec@1 76.562 (78.662)
Test: [0/79]	Time 0.172 (0.172)	Loss 1.4558 (1.4558) ([1.205]+[0.251])	Prec@1 62.500 (62.500)
 * Prec@1 67.220
current lr 1.00000e-01
Grad=  tensor(1.4190, device='cuda:0')
Epoch: [24][0/391]	Time 0.261 (0.261)	Data 0.141 (0.141)	Loss 0.7787 (0.7787) ([0.527]+[0.251])	Prec@1 81.250 (81.250)
Epoch: [24][100/391]	Time 0.109 (0.110)	Data 0.000 (0.002)	Loss 0.8015 (0.8471) ([0.549]+[0.252])	Prec@1 79.688 (79.935)
Epoch: [24][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.9056 (0.8529) ([0.653]+[0.252])	Prec@1 77.344 (79.489)
Epoch: [24][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 1.0438 (0.8530) ([0.792]+[0.251])	Prec@1 75.781 (79.553)
Test: [0/79]	Time 0.174 (0.174)	Loss 1.1164 (1.1164) ([0.865]+[0.251])	Prec@1 67.969 (67.969)
 * Prec@1 68.890
current lr 1.00000e-01
Grad=  tensor(1.9843, device='cuda:0')
Epoch: [25][0/391]	Time 0.260 (0.260)	Data 0.141 (0.141)	Loss 0.8779 (0.8779) ([0.627]+[0.251])	Prec@1 74.219 (74.219)
Epoch: [25][100/391]	Time 0.109 (0.110)	Data 0.000 (0.002)	Loss 0.7798 (0.8629) ([0.528]+[0.252])	Prec@1 81.250 (79.154)
Epoch: [25][200/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.9072 (0.8576) ([0.654]+[0.253])	Prec@1 78.906 (79.256)
Epoch: [25][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.8747 (0.8593) ([0.622]+[0.253])	Prec@1 78.906 (79.065)
Test: [0/79]	Time 0.169 (0.169)	Loss 1.4894 (1.4894) ([1.237]+[0.252])	Prec@1 63.281 (63.281)
 * Prec@1 67.160
current lr 1.00000e-01
Grad=  tensor(2.0819, device='cuda:0')
Epoch: [26][0/391]	Time 0.262 (0.262)	Data 0.141 (0.141)	Loss 0.8046 (0.8046) ([0.553]+[0.252])	Prec@1 81.250 (81.250)
Epoch: [26][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.8485 (0.8342) ([0.598]+[0.251])	Prec@1 78.125 (80.206)
Epoch: [26][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.8442 (0.8330) ([0.593]+[0.251])	Prec@1 77.344 (80.080)
Epoch: [26][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.7974 (0.8391) ([0.546]+[0.251])	Prec@1 81.250 (79.893)
Test: [0/79]	Time 0.168 (0.168)	Loss 1.0294 (1.0294) ([0.778]+[0.251])	Prec@1 75.781 (75.781)
 * Prec@1 72.970
current lr 1.00000e-01
Grad=  tensor(2.0174, device='cuda:0')
Epoch: [27][0/391]	Time 0.263 (0.263)	Data 0.142 (0.142)	Loss 0.8510 (0.8510) ([0.600]+[0.251])	Prec@1 80.469 (80.469)
Epoch: [27][100/391]	Time 0.108 (0.111)	Data 0.000 (0.002)	Loss 0.8175 (0.8419) ([0.568]+[0.250])	Prec@1 78.906 (79.711)
Epoch: [27][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8924 (0.8429) ([0.643]+[0.249])	Prec@1 78.906 (79.458)
Epoch: [27][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 1.0747 (0.8420) ([0.826]+[0.249])	Prec@1 74.219 (79.659)
Test: [0/79]	Time 0.167 (0.167)	Loss 1.1214 (1.1214) ([0.873]+[0.249])	Prec@1 72.656 (72.656)
 * Prec@1 74.740
current lr 1.00000e-01
Grad=  tensor(1.2773, device='cuda:0')
Epoch: [28][0/391]	Time 0.257 (0.257)	Data 0.138 (0.138)	Loss 0.6794 (0.6794) ([0.431]+[0.249])	Prec@1 84.375 (84.375)
Epoch: [28][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.9289 (0.8335) ([0.679]+[0.250])	Prec@1 79.688 (80.446)
Epoch: [28][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.7452 (0.8171) ([0.497]+[0.248])	Prec@1 82.812 (80.776)
Epoch: [28][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.9611 (0.8285) ([0.713]+[0.248])	Prec@1 76.562 (80.279)
Test: [0/79]	Time 0.174 (0.174)	Loss 1.0300 (1.0300) ([0.781]+[0.249])	Prec@1 75.781 (75.781)
 * Prec@1 74.600
current lr 1.00000e-01
Grad=  tensor(2.4790, device='cuda:0')
Epoch: [29][0/391]	Time 0.264 (0.264)	Data 0.143 (0.143)	Loss 0.8603 (0.8603) ([0.612]+[0.249])	Prec@1 74.219 (74.219)
Epoch: [29][100/391]	Time 0.111 (0.112)	Data 0.000 (0.002)	Loss 0.8884 (0.8271) ([0.640]+[0.248])	Prec@1 77.344 (80.121)
Epoch: [29][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.7882 (0.8316) ([0.540]+[0.248])	Prec@1 78.906 (79.998)
Epoch: [29][300/391]	Time 0.108 (0.111)	Data 0.000 (0.001)	Loss 0.7772 (0.8329) ([0.529]+[0.249])	Prec@1 83.594 (79.942)
Test: [0/79]	Time 0.173 (0.173)	Loss 0.9585 (0.9585) ([0.710]+[0.248])	Prec@1 71.094 (71.094)
 * Prec@1 76.140
current lr 1.00000e-01
Grad=  tensor(1.9282, device='cuda:0')
Epoch: [30][0/391]	Time 0.258 (0.258)	Data 0.139 (0.139)	Loss 0.8015 (0.8015) ([0.554]+[0.248])	Prec@1 84.375 (84.375)
Epoch: [30][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8034 (0.8070) ([0.556]+[0.248])	Prec@1 80.469 (80.917)
Epoch: [30][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8031 (0.8179) ([0.555]+[0.248])	Prec@1 80.469 (80.601)
Epoch: [30][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8447 (0.8214) ([0.598]+[0.247])	Prec@1 81.250 (80.388)
Test: [0/79]	Time 0.171 (0.171)	Loss 1.0279 (1.0279) ([0.781]+[0.247])	Prec@1 74.219 (74.219)
 * Prec@1 72.310
current lr 1.00000e-01
Grad=  tensor(2.6241, device='cuda:0')
Epoch: [31][0/391]	Time 0.261 (0.261)	Data 0.140 (0.140)	Loss 0.8459 (0.8459) ([0.599]+[0.247])	Prec@1 78.906 (78.906)
Epoch: [31][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7702 (0.8194) ([0.523]+[0.247])	Prec@1 82.031 (80.593)
Epoch: [31][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8346 (0.8192) ([0.587]+[0.248])	Prec@1 79.688 (80.407)
Epoch: [31][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7997 (0.8227) ([0.552]+[0.248])	Prec@1 78.125 (80.168)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.9399 (0.9399) ([0.693]+[0.247])	Prec@1 78.125 (78.125)
 * Prec@1 76.690
current lr 1.00000e-01
Grad=  tensor(1.7078, device='cuda:0')
Epoch: [32][0/391]	Time 0.265 (0.265)	Data 0.143 (0.143)	Loss 0.7005 (0.7005) ([0.454]+[0.247])	Prec@1 84.375 (84.375)
Epoch: [32][100/391]	Time 0.111 (0.113)	Data 0.000 (0.002)	Loss 0.6838 (0.8225) ([0.436]+[0.248])	Prec@1 85.156 (79.958)
Epoch: [32][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6935 (0.8123) ([0.448]+[0.246])	Prec@1 86.719 (80.667)
Epoch: [32][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.9291 (0.8187) ([0.682]+[0.247])	Prec@1 76.562 (80.497)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.9550 (0.9550) ([0.709]+[0.246])	Prec@1 80.469 (80.469)
 * Prec@1 73.400
current lr 1.00000e-01
Grad=  tensor(1.7842, device='cuda:0')
Epoch: [33][0/391]	Time 0.259 (0.259)	Data 0.138 (0.138)	Loss 0.7395 (0.7395) ([0.494]+[0.246])	Prec@1 83.594 (83.594)
Epoch: [33][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8928 (0.7915) ([0.647]+[0.246])	Prec@1 78.906 (81.436)
Epoch: [33][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6564 (0.7949) ([0.411]+[0.246])	Prec@1 86.719 (81.293)
Epoch: [33][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.9503 (0.8009) ([0.705]+[0.245])	Prec@1 76.562 (81.061)
Test: [0/79]	Time 0.172 (0.172)	Loss 1.0930 (1.0930) ([0.847]+[0.246])	Prec@1 71.094 (71.094)
 * Prec@1 72.930
current lr 1.00000e-01
Grad=  tensor(1.5556, device='cuda:0')
Epoch: [34][0/391]	Time 0.261 (0.261)	Data 0.140 (0.140)	Loss 0.6937 (0.6937) ([0.447]+[0.246])	Prec@1 84.375 (84.375)
Epoch: [34][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8281 (0.8031) ([0.583]+[0.245])	Prec@1 78.125 (80.972)
Epoch: [34][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.6750 (0.8013) ([0.430]+[0.245])	Prec@1 87.500 (80.931)
Epoch: [34][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8209 (0.8027) ([0.576]+[0.245])	Prec@1 75.781 (80.811)
Test: [0/79]	Time 0.172 (0.172)	Loss 0.9408 (0.9408) ([0.695]+[0.246])	Prec@1 75.781 (75.781)
 * Prec@1 76.650
current lr 1.00000e-01
Grad=  tensor(1.8164, device='cuda:0')
Epoch: [35][0/391]	Time 0.259 (0.259)	Data 0.138 (0.138)	Loss 0.7857 (0.7857) ([0.540]+[0.246])	Prec@1 80.469 (80.469)
Epoch: [35][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8155 (0.8020) ([0.570]+[0.245])	Prec@1 78.906 (81.095)
Epoch: [35][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.9696 (0.8000) ([0.725]+[0.244])	Prec@1 79.688 (81.106)
Epoch: [35][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.8746 (0.8042) ([0.630]+[0.245])	Prec@1 81.250 (80.832)
Test: [0/79]	Time 0.171 (0.171)	Loss 0.9024 (0.9024) ([0.658]+[0.245])	Prec@1 74.219 (74.219)
 * Prec@1 74.340
current lr 1.00000e-01
Grad=  tensor(1.3905, device='cuda:0')
Epoch: [36][0/391]	Time 0.261 (0.261)	Data 0.140 (0.140)	Loss 0.6991 (0.6991) ([0.455]+[0.245])	Prec@1 85.156 (85.156)
Epoch: [36][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.9029 (0.7932) ([0.658]+[0.245])	Prec@1 76.562 (81.134)
Epoch: [36][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8474 (0.7906) ([0.603]+[0.244])	Prec@1 81.250 (81.246)
Epoch: [36][300/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.7242 (0.7927) ([0.481]+[0.243])	Prec@1 82.031 (81.159)
Test: [0/79]	Time 0.170 (0.170)	Loss 1.0302 (1.0302) ([0.787]+[0.243])	Prec@1 75.781 (75.781)
 * Prec@1 74.040
current lr 1.00000e-01
Grad=  tensor(2.2296, device='cuda:0')
Epoch: [37][0/391]	Time 0.258 (0.258)	Data 0.139 (0.139)	Loss 0.7558 (0.7558) ([0.513]+[0.243])	Prec@1 77.344 (77.344)
Epoch: [37][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8083 (0.7884) ([0.565]+[0.243])	Prec@1 81.250 (81.149)
Epoch: [37][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.6736 (0.7913) ([0.431]+[0.243])	Prec@1 84.375 (81.110)
Epoch: [37][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.8460 (0.7915) ([0.604]+[0.242])	Prec@1 80.469 (81.048)
Test: [0/79]	Time 0.168 (0.168)	Loss 1.2018 (1.2018) ([0.959]+[0.243])	Prec@1 71.875 (71.875)
 * Prec@1 72.970
current lr 1.00000e-01
Grad=  tensor(1.7274, device='cuda:0')
Epoch: [38][0/391]	Time 0.255 (0.255)	Data 0.135 (0.135)	Loss 0.7713 (0.7713) ([0.529]+[0.243])	Prec@1 83.594 (83.594)
Epoch: [38][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.7799 (0.8015) ([0.537]+[0.243])	Prec@1 82.812 (81.188)
Epoch: [38][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.7513 (0.7943) ([0.508]+[0.243])	Prec@1 80.469 (81.172)
Epoch: [38][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.7090 (0.7941) ([0.466]+[0.243])	Prec@1 83.594 (81.208)
Test: [0/79]	Time 0.170 (0.170)	Loss 1.0480 (1.0480) ([0.806]+[0.242])	Prec@1 75.781 (75.781)
 * Prec@1 73.900
current lr 1.00000e-01
Grad=  tensor(2.0199, device='cuda:0')
Epoch: [39][0/391]	Time 0.255 (0.255)	Data 0.136 (0.136)	Loss 0.8467 (0.8467) ([0.605]+[0.242])	Prec@1 82.031 (82.031)
Epoch: [39][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7862 (0.8031) ([0.544]+[0.242])	Prec@1 85.156 (80.577)
Epoch: [39][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.8864 (0.7878) ([0.644]+[0.242])	Prec@1 78.906 (81.223)
Epoch: [39][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.9167 (0.7917) ([0.675]+[0.242])	Prec@1 77.344 (81.167)
Test: [0/79]	Time 0.173 (0.173)	Loss 0.8800 (0.8800) ([0.638]+[0.242])	Prec@1 76.562 (76.562)
 * Prec@1 75.780
current lr 1.00000e-01
Grad=  tensor(1.5882, device='cuda:0')
Epoch: [40][0/391]	Time 0.256 (0.256)	Data 0.137 (0.137)	Loss 0.6878 (0.6878) ([0.446]+[0.242])	Prec@1 85.156 (85.156)
Epoch: [40][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.6680 (0.7855) ([0.426]+[0.242])	Prec@1 89.062 (81.552)
Epoch: [40][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.9668 (0.7892) ([0.725]+[0.242])	Prec@1 79.688 (81.301)
Epoch: [40][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.7442 (0.7901) ([0.502]+[0.243])	Prec@1 85.938 (81.159)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.9553 (0.9553) ([0.714]+[0.242])	Prec@1 75.000 (75.000)
 * Prec@1 71.240
current lr 1.00000e-01
Grad=  tensor(2.9468, device='cuda:0')
Epoch: [41][0/391]	Time 0.261 (0.261)	Data 0.142 (0.142)	Loss 0.9987 (0.9987) ([0.757]+[0.242])	Prec@1 76.562 (76.562)
Epoch: [41][100/391]	Time 0.108 (0.110)	Data 0.000 (0.002)	Loss 0.7889 (0.7694) ([0.548]+[0.241])	Prec@1 78.906 (81.869)
Epoch: [41][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.7040 (0.7794) ([0.463]+[0.241])	Prec@1 82.812 (81.514)
Epoch: [41][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.9277 (0.7826) ([0.686]+[0.241])	Prec@1 75.000 (81.569)
Test: [0/79]	Time 0.172 (0.172)	Loss 0.9668 (0.9668) ([0.727]+[0.240])	Prec@1 73.438 (73.438)
 * Prec@1 74.950
current lr 1.00000e-01
Grad=  tensor(1.3981, device='cuda:0')
Epoch: [42][0/391]	Time 0.260 (0.260)	Data 0.140 (0.140)	Loss 0.7097 (0.7097) ([0.470]+[0.240])	Prec@1 85.938 (85.938)
Epoch: [42][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8216 (0.7709) ([0.582]+[0.240])	Prec@1 77.344 (81.869)
Epoch: [42][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.8504 (0.7725) ([0.611]+[0.240])	Prec@1 79.688 (81.662)
Epoch: [42][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.7796 (0.7715) ([0.540]+[0.239])	Prec@1 80.469 (81.761)
Test: [0/79]	Time 0.169 (0.169)	Loss 1.0880 (1.0880) ([0.848]+[0.240])	Prec@1 71.875 (71.875)
 * Prec@1 70.910
current lr 1.00000e-01
Grad=  tensor(1.6467, device='cuda:0')
Epoch: [43][0/391]	Time 0.257 (0.257)	Data 0.139 (0.139)	Loss 0.7728 (0.7728) ([0.533]+[0.240])	Prec@1 82.812 (82.812)
Epoch: [43][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.5636 (0.7737) ([0.323]+[0.241])	Prec@1 91.406 (82.054)
Epoch: [43][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.7962 (0.7763) ([0.556]+[0.240])	Prec@1 82.031 (81.775)
Epoch: [43][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.6675 (0.7832) ([0.427]+[0.240])	Prec@1 86.719 (81.455)
Test: [0/79]	Time 0.171 (0.171)	Loss 1.3584 (1.3584) ([1.117]+[0.241])	Prec@1 71.094 (71.094)
 * Prec@1 68.000
current lr 1.00000e-01
Grad=  tensor(2.7996, device='cuda:0')
Epoch: [44][0/391]	Time 0.260 (0.260)	Data 0.140 (0.140)	Loss 0.9213 (0.9213) ([0.680]+[0.241])	Prec@1 79.688 (79.688)
Epoch: [44][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.6959 (0.7733) ([0.455]+[0.241])	Prec@1 83.594 (81.807)
Epoch: [44][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.6606 (0.7787) ([0.420]+[0.241])	Prec@1 88.281 (81.658)
Epoch: [44][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.8323 (0.7758) ([0.592]+[0.240])	Prec@1 78.906 (81.741)
Test: [0/79]	Time 0.169 (0.169)	Loss 1.0986 (1.0986) ([0.859]+[0.240])	Prec@1 75.000 (75.000)
 * Prec@1 74.360
current lr 1.00000e-01
Grad=  tensor(1.8691, device='cuda:0')
Epoch: [45][0/391]	Time 0.258 (0.258)	Data 0.139 (0.139)	Loss 0.7912 (0.7912) ([0.551]+[0.240])	Prec@1 79.688 (79.688)
Epoch: [45][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7250 (0.7713) ([0.485]+[0.240])	Prec@1 84.375 (82.124)
Epoch: [45][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.6557 (0.7700) ([0.416]+[0.239])	Prec@1 84.375 (81.934)
Epoch: [45][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.7229 (0.7749) ([0.483]+[0.239])	Prec@1 84.375 (81.873)
Test: [0/79]	Time 0.169 (0.169)	Loss 1.4546 (1.4546) ([1.216]+[0.239])	Prec@1 63.281 (63.281)
 * Prec@1 63.630
current lr 1.00000e-01
Grad=  tensor(2.3414, device='cuda:0')
Epoch: [46][0/391]	Time 0.254 (0.254)	Data 0.135 (0.135)	Loss 0.6750 (0.6750) ([0.436]+[0.239])	Prec@1 87.500 (87.500)
Epoch: [46][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.8919 (0.7606) ([0.653]+[0.239])	Prec@1 81.250 (82.209)
Epoch: [46][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.7630 (0.7692) ([0.524]+[0.239])	Prec@1 79.688 (81.880)
Epoch: [46][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.8356 (0.7695) ([0.597]+[0.239])	Prec@1 82.031 (81.824)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.8095 (0.8095) ([0.571]+[0.238])	Prec@1 83.594 (83.594)
 * Prec@1 76.920
current lr 1.00000e-01
Grad=  tensor(2.3874, device='cuda:0')
Epoch: [47][0/391]	Time 0.264 (0.264)	Data 0.143 (0.143)	Loss 0.7571 (0.7571) ([0.519]+[0.238])	Prec@1 82.031 (82.031)
Epoch: [47][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.9447 (0.7716) ([0.706]+[0.239])	Prec@1 79.688 (81.993)
Epoch: [47][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.6270 (0.7654) ([0.389]+[0.238])	Prec@1 86.719 (82.292)
Epoch: [47][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7081 (0.7692) ([0.470]+[0.238])	Prec@1 89.062 (82.055)
Test: [0/79]	Time 0.172 (0.172)	Loss 0.8912 (0.8912) ([0.653]+[0.238])	Prec@1 78.906 (78.906)
 * Prec@1 78.060
current lr 1.00000e-01
Grad=  tensor(1.4870, device='cuda:0')
Epoch: [48][0/391]	Time 0.262 (0.262)	Data 0.141 (0.141)	Loss 0.6440 (0.6440) ([0.406]+[0.238])	Prec@1 85.156 (85.156)
Epoch: [48][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8580 (0.7580) ([0.620]+[0.238])	Prec@1 77.344 (82.178)
Epoch: [48][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6465 (0.7605) ([0.409]+[0.238])	Prec@1 86.719 (82.000)
Epoch: [48][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7201 (0.7654) ([0.483]+[0.238])	Prec@1 84.375 (81.972)
Test: [0/79]	Time 0.172 (0.172)	Loss 1.0035 (1.0035) ([0.766]+[0.238])	Prec@1 71.094 (71.094)
 * Prec@1 76.050
current lr 1.00000e-01
Grad=  tensor(1.9717, device='cuda:0')
Epoch: [49][0/391]	Time 0.265 (0.265)	Data 0.143 (0.143)	Loss 0.7975 (0.7975) ([0.560]+[0.238])	Prec@1 82.812 (82.812)
Epoch: [49][100/391]	Time 0.109 (0.111)	Data 0.000 (0.002)	Loss 0.7820 (0.7631) ([0.544]+[0.238])	Prec@1 84.375 (81.753)
Epoch: [49][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8938 (0.7669) ([0.656]+[0.238])	Prec@1 80.469 (81.806)
Epoch: [49][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7365 (0.7676) ([0.499]+[0.237])	Prec@1 79.688 (81.715)
Test: [0/79]	Time 0.169 (0.169)	Loss 1.3396 (1.3396) ([1.102]+[0.238])	Prec@1 66.406 (66.406)
 * Prec@1 70.620
current lr 1.00000e-01
Grad=  tensor(2.8895, device='cuda:0')
Epoch: [50][0/391]	Time 0.258 (0.258)	Data 0.137 (0.137)	Loss 0.8885 (0.8885) ([0.651]+[0.238])	Prec@1 77.344 (77.344)
Epoch: [50][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8355 (0.7663) ([0.597]+[0.238])	Prec@1 77.344 (81.784)
Epoch: [50][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.8422 (0.7630) ([0.605]+[0.238])	Prec@1 77.344 (82.012)
Epoch: [50][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7683 (0.7687) ([0.531]+[0.237])	Prec@1 82.812 (81.813)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.7939 (0.7939) ([0.557]+[0.236])	Prec@1 78.125 (78.125)
 * Prec@1 76.680
current lr 1.00000e-01
Grad=  tensor(2.5105, device='cuda:0')
Epoch: [51][0/391]	Time 0.255 (0.255)	Data 0.135 (0.135)	Loss 0.8612 (0.8612) ([0.625]+[0.236])	Prec@1 82.812 (82.812)
Epoch: [51][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8451 (0.7652) ([0.608]+[0.237])	Prec@1 75.781 (81.915)
Epoch: [51][200/391]	Time 0.108 (0.111)	Data 0.000 (0.001)	Loss 0.5630 (0.7676) ([0.327]+[0.236])	Prec@1 89.062 (81.821)
Epoch: [51][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.6057 (0.7691) ([0.369]+[0.236])	Prec@1 87.500 (81.808)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.9443 (0.9443) ([0.708]+[0.236])	Prec@1 74.219 (74.219)
 * Prec@1 75.900
current lr 1.00000e-01
Grad=  tensor(2.4722, device='cuda:0')
Epoch: [52][0/391]	Time 0.255 (0.255)	Data 0.135 (0.135)	Loss 0.8125 (0.8125) ([0.576]+[0.236])	Prec@1 79.688 (79.688)
Epoch: [52][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.7141 (0.7543) ([0.478]+[0.236])	Prec@1 85.938 (82.565)
Epoch: [52][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.6902 (0.7524) ([0.455]+[0.235])	Prec@1 82.812 (82.525)
Epoch: [52][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.6837 (0.7618) ([0.448]+[0.236])	Prec@1 88.281 (82.226)
Test: [0/79]	Time 0.167 (0.167)	Loss 1.0397 (1.0397) ([0.804]+[0.235])	Prec@1 72.656 (72.656)
 * Prec@1 75.190
current lr 1.00000e-01
Grad=  tensor(1.9802, device='cuda:0')
Epoch: [53][0/391]	Time 0.256 (0.256)	Data 0.136 (0.136)	Loss 0.7596 (0.7596) ([0.524]+[0.235])	Prec@1 83.594 (83.594)
Epoch: [53][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.8334 (0.7369) ([0.598]+[0.235])	Prec@1 77.344 (82.604)
Epoch: [53][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.6999 (0.7590) ([0.464]+[0.236])	Prec@1 81.250 (81.864)
Epoch: [53][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.6379 (0.7585) ([0.402]+[0.236])	Prec@1 86.719 (81.982)
Test: [0/79]	Time 0.172 (0.172)	Loss 0.9140 (0.9140) ([0.678]+[0.236])	Prec@1 77.344 (77.344)
 * Prec@1 76.810
current lr 1.00000e-01
Grad=  tensor(3.1725, device='cuda:0')
Epoch: [54][0/391]	Time 0.255 (0.255)	Data 0.136 (0.136)	Loss 0.9888 (0.9888) ([0.753]+[0.236])	Prec@1 72.656 (72.656)
Epoch: [54][100/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7000 (0.7758) ([0.464]+[0.236])	Prec@1 83.594 (81.304)
Epoch: [54][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.8239 (0.7744) ([0.588]+[0.236])	Prec@1 75.000 (81.472)
Epoch: [54][300/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.7268 (0.7660) ([0.492]+[0.235])	Prec@1 83.594 (81.707)
Test: [0/79]	Time 0.170 (0.170)	Loss 0.8185 (0.8185) ([0.584]+[0.235])	Prec@1 80.469 (80.469)
 * Prec@1 77.950
current lr 1.00000e-01
Grad=  tensor(1.7668, device='cuda:0')
Epoch: [55][0/391]	Time 0.254 (0.254)	Data 0.135 (0.135)	Loss 0.7744 (0.7744) ([0.540]+[0.235])	Prec@1 80.469 (80.469)
Epoch: [55][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.7513 (0.7511) ([0.516]+[0.235])	Prec@1 85.938 (82.101)
Epoch: [55][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.6005 (0.7556) ([0.365]+[0.235])	Prec@1 86.719 (81.996)
Epoch: [55][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.8765 (0.7546) ([0.641]+[0.235])	Prec@1 75.000 (81.979)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.9863 (0.9863) ([0.751]+[0.235])	Prec@1 75.000 (75.000)
 * Prec@1 75.650
current lr 1.00000e-01
Grad=  tensor(2.5883, device='cuda:0')
Epoch: [56][0/391]	Time 0.255 (0.255)	Data 0.136 (0.136)	Loss 0.8139 (0.8139) ([0.579]+[0.235])	Prec@1 79.688 (79.688)
Epoch: [56][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.6839 (0.7584) ([0.448]+[0.235])	Prec@1 84.375 (82.124)
Epoch: [56][200/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.8963 (0.7588) ([0.661]+[0.236])	Prec@1 73.438 (82.078)
Epoch: [56][300/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.8409 (0.7578) ([0.606]+[0.235])	Prec@1 80.469 (82.156)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.9419 (0.9419) ([0.707]+[0.234])	Prec@1 75.000 (75.000)
 * Prec@1 76.180
current lr 1.00000e-01
Grad=  tensor(1.4583, device='cuda:0')
Epoch: [57][0/391]	Time 0.260 (0.260)	Data 0.137 (0.137)	Loss 0.6716 (0.6716) ([0.437]+[0.234])	Prec@1 84.375 (84.375)
Epoch: [57][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7809 (0.7600) ([0.547]+[0.234])	Prec@1 80.469 (81.815)
Epoch: [57][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.7411 (0.7591) ([0.507]+[0.234])	Prec@1 82.812 (82.031)
Epoch: [57][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.9570 (0.7554) ([0.723]+[0.234])	Prec@1 77.344 (82.122)
Test: [0/79]	Time 0.169 (0.169)	Loss 0.9470 (0.9470) ([0.713]+[0.234])	Prec@1 71.875 (71.875)
 * Prec@1 76.820
current lr 1.00000e-01
Grad=  tensor(2.0572, device='cuda:0')
Epoch: [58][0/391]	Time 0.260 (0.260)	Data 0.138 (0.138)	Loss 0.7197 (0.7197) ([0.486]+[0.234])	Prec@1 87.500 (87.500)
Epoch: [58][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.7227 (0.7446) ([0.489]+[0.234])	Prec@1 85.156 (82.689)
Epoch: [58][200/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.7058 (0.7551) ([0.472]+[0.233])	Prec@1 82.812 (82.183)
Epoch: [58][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.7528 (0.7617) ([0.518]+[0.234])	Prec@1 83.594 (82.031)
Test: [0/79]	Time 0.175 (0.175)	Loss 1.0659 (1.0659) ([0.833]+[0.233])	Prec@1 69.531 (69.531)
 * Prec@1 75.060
current lr 1.00000e-01
Grad=  tensor(2.1169, device='cuda:0')
Epoch: [59][0/391]	Time 0.260 (0.260)	Data 0.139 (0.139)	Loss 0.7514 (0.7514) ([0.518]+[0.233])	Prec@1 84.375 (84.375)
Epoch: [59][100/391]	Time 0.109 (0.112)	Data 0.000 (0.001)	Loss 0.7153 (0.7513) ([0.482]+[0.233])	Prec@1 83.594 (82.619)
Epoch: [59][200/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.7783 (0.7402) ([0.546]+[0.232])	Prec@1 82.031 (82.762)
Epoch: [59][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8079 (0.7448) ([0.575]+[0.233])	Prec@1 82.812 (82.545)
Test: [0/79]	Time 0.169 (0.169)	Loss 1.0396 (1.0396) ([0.807]+[0.232])	Prec@1 75.000 (75.000)
 * Prec@1 72.230
current lr 1.00000e-01
Grad=  tensor(1.5650, device='cuda:0')
Epoch: [60][0/391]	Time 0.256 (0.256)	Data 0.138 (0.138)	Loss 0.6810 (0.6810) ([0.449]+[0.232])	Prec@1 85.156 (85.156)
Epoch: [60][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.7983 (0.7449) ([0.566]+[0.232])	Prec@1 83.594 (82.418)
Epoch: [60][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7214 (0.7440) ([0.489]+[0.233])	Prec@1 81.250 (82.505)
Epoch: [60][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7418 (0.7476) ([0.510]+[0.232])	Prec@1 81.250 (82.392)
Test: [0/79]	Time 0.171 (0.171)	Loss 0.9295 (0.9295) ([0.698]+[0.232])	Prec@1 78.125 (78.125)
 * Prec@1 69.660
current lr 1.00000e-01
Grad=  tensor(1.3077, device='cuda:0')
Epoch: [61][0/391]	Time 0.259 (0.259)	Data 0.137 (0.137)	Loss 0.5791 (0.5791) ([0.347]+[0.232])	Prec@1 89.062 (89.062)
Epoch: [61][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7025 (0.7256) ([0.471]+[0.232])	Prec@1 86.719 (83.161)
Epoch: [61][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6911 (0.7413) ([0.459]+[0.232])	Prec@1 84.375 (82.719)
Epoch: [61][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.8796 (0.7444) ([0.648]+[0.232])	Prec@1 77.344 (82.594)
Test: [0/79]	Time 0.171 (0.171)	Loss 0.8868 (0.8868) ([0.655]+[0.232])	Prec@1 77.344 (77.344)
 * Prec@1 75.200
current lr 1.00000e-01
Grad=  tensor(1.8480, device='cuda:0')
Epoch: [62][0/391]	Time 0.257 (0.257)	Data 0.135 (0.135)	Loss 0.6868 (0.6868) ([0.455]+[0.232])	Prec@1 82.812 (82.812)
Epoch: [62][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.8389 (0.7508) ([0.608]+[0.231])	Prec@1 79.688 (82.333)
Epoch: [62][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.6967 (0.7511) ([0.465]+[0.231])	Prec@1 85.156 (82.218)
Epoch: [62][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.8365 (0.7497) ([0.605]+[0.231])	Prec@1 80.469 (82.273)
Test: [0/79]	Time 0.169 (0.169)	Loss 1.2802 (1.2802) ([1.048]+[0.232])	Prec@1 60.938 (60.938)
 * Prec@1 69.940
current lr 1.00000e-01
Grad=  tensor(2.1770, device='cuda:0')
Epoch: [63][0/391]	Time 0.257 (0.257)	Data 0.136 (0.136)	Loss 0.7738 (0.7738) ([0.541]+[0.232])	Prec@1 80.469 (80.469)
Epoch: [63][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7434 (0.7551) ([0.510]+[0.233])	Prec@1 79.688 (82.178)
Epoch: [63][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8408 (0.7422) ([0.609]+[0.232])	Prec@1 78.906 (82.696)
Epoch: [63][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8683 (0.7441) ([0.636]+[0.232])	Prec@1 79.688 (82.602)
Test: [0/79]	Time 0.168 (0.168)	Loss 1.0542 (1.0542) ([0.822]+[0.233])	Prec@1 77.344 (77.344)
 * Prec@1 75.120
current lr 1.00000e-01
Grad=  tensor(2.0893, device='cuda:0')
Epoch: [64][0/391]	Time 0.260 (0.260)	Data 0.138 (0.138)	Loss 0.7871 (0.7871) ([0.555]+[0.233])	Prec@1 81.250 (81.250)
Epoch: [64][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.6665 (0.7408) ([0.434]+[0.232])	Prec@1 85.938 (82.774)
Epoch: [64][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.8831 (0.7410) ([0.651]+[0.232])	Prec@1 75.000 (82.711)
Epoch: [64][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6963 (0.7395) ([0.465]+[0.232])	Prec@1 82.031 (82.659)
Test: [0/79]	Time 0.170 (0.170)	Loss 1.0366 (1.0366) ([0.805]+[0.231])	Prec@1 75.781 (75.781)
 * Prec@1 74.990
current lr 1.00000e-01
Grad=  tensor(2.2203, device='cuda:0')
Epoch: [65][0/391]	Time 0.257 (0.257)	Data 0.137 (0.137)	Loss 0.8795 (0.8795) ([0.648]+[0.231])	Prec@1 77.344 (77.344)
Epoch: [65][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.6640 (0.7402) ([0.432]+[0.232])	Prec@1 86.719 (82.511)
Epoch: [65][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7905 (0.7388) ([0.560]+[0.231])	Prec@1 79.688 (82.505)
Epoch: [65][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.6827 (0.7493) ([0.451]+[0.231])	Prec@1 81.250 (82.117)
Test: [0/79]	Time 0.170 (0.170)	Loss 0.8145 (0.8145) ([0.584]+[0.231])	Prec@1 79.688 (79.688)
 * Prec@1 76.800
current lr 1.00000e-01
Grad=  tensor(1.3820, device='cuda:0')
Epoch: [66][0/391]	Time 0.258 (0.258)	Data 0.137 (0.137)	Loss 0.5989 (0.5989) ([0.368]+[0.231])	Prec@1 88.281 (88.281)
Epoch: [66][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7030 (0.7410) ([0.472]+[0.231])	Prec@1 84.375 (82.658)
Epoch: [66][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.9002 (0.7302) ([0.670]+[0.230])	Prec@1 80.469 (83.135)
Epoch: [66][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.5510 (0.7344) ([0.321]+[0.230])	Prec@1 88.281 (82.820)
Test: [0/79]	Time 0.172 (0.172)	Loss 0.8400 (0.8400) ([0.610]+[0.230])	Prec@1 80.469 (80.469)
 * Prec@1 76.410
current lr 1.00000e-01
Grad=  tensor(1.8755, device='cuda:0')
Epoch: [67][0/391]	Time 0.261 (0.261)	Data 0.140 (0.140)	Loss 0.6444 (0.6444) ([0.415]+[0.230])	Prec@1 84.375 (84.375)
Epoch: [67][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.7537 (0.7492) ([0.523]+[0.230])	Prec@1 83.594 (81.869)
Epoch: [67][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6974 (0.7360) ([0.467]+[0.230])	Prec@1 83.594 (82.525)
Epoch: [67][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7531 (0.7377) ([0.524]+[0.230])	Prec@1 85.938 (82.509)
Test: [0/79]	Time 0.173 (0.173)	Loss 1.1177 (1.1177) ([0.887]+[0.230])	Prec@1 73.438 (73.438)
 * Prec@1 70.950
current lr 1.00000e-01
Grad=  tensor(1.9122, device='cuda:0')
Epoch: [68][0/391]	Time 0.263 (0.263)	Data 0.142 (0.142)	Loss 0.7245 (0.7245) ([0.494]+[0.230])	Prec@1 81.250 (81.250)
Epoch: [68][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7071 (0.7439) ([0.476]+[0.231])	Prec@1 81.250 (82.333)
Epoch: [68][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8313 (0.7351) ([0.601]+[0.230])	Prec@1 78.906 (82.583)
Epoch: [68][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.6823 (0.7430) ([0.452]+[0.230])	Prec@1 86.719 (82.306)
Test: [0/79]	Time 0.170 (0.170)	Loss 0.8683 (0.8683) ([0.639]+[0.229])	Prec@1 78.906 (78.906)
 * Prec@1 73.940
current lr 1.00000e-01
Grad=  tensor(1.6398, device='cuda:0')
Epoch: [69][0/391]	Time 0.266 (0.266)	Data 0.140 (0.140)	Loss 0.6503 (0.6503) ([0.421]+[0.229])	Prec@1 85.156 (85.156)
Epoch: [69][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.7899 (0.7157) ([0.561]+[0.229])	Prec@1 78.906 (83.516)
Epoch: [69][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.6582 (0.7243) ([0.429]+[0.229])	Prec@1 85.156 (83.329)
Epoch: [69][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7701 (0.7330) ([0.542]+[0.228])	Prec@1 80.469 (82.994)
Test: [0/79]	Time 0.170 (0.170)	Loss 1.0891 (1.0891) ([0.861]+[0.228])	Prec@1 71.875 (71.875)
 * Prec@1 71.010
current lr 1.00000e-01
Grad=  tensor(1.6799, device='cuda:0')
Epoch: [70][0/391]	Time 0.257 (0.257)	Data 0.136 (0.136)	Loss 0.7468 (0.7468) ([0.518]+[0.228])	Prec@1 81.250 (81.250)
Epoch: [70][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6330 (0.7408) ([0.404]+[0.229])	Prec@1 85.938 (82.410)
Epoch: [70][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.6812 (0.7400) ([0.453]+[0.229])	Prec@1 84.375 (82.521)
Epoch: [70][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.6714 (0.7407) ([0.444]+[0.228])	Prec@1 83.594 (82.452)
Test: [0/79]	Time 0.170 (0.170)	Loss 0.9111 (0.9111) ([0.684]+[0.228])	Prec@1 75.781 (75.781)
 * Prec@1 78.510
current lr 1.00000e-01
Grad=  tensor(1.6939, device='cuda:0')
Epoch: [71][0/391]	Time 0.257 (0.257)	Data 0.136 (0.136)	Loss 0.7655 (0.7655) ([0.538]+[0.228])	Prec@1 82.812 (82.812)
Epoch: [71][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7242 (0.7287) ([0.497]+[0.227])	Prec@1 82.812 (82.805)
Epoch: [71][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7936 (0.7314) ([0.566]+[0.227])	Prec@1 81.250 (82.867)
Epoch: [71][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7759 (0.7383) ([0.548]+[0.228])	Prec@1 81.250 (82.607)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.7875 (0.7875) ([0.561]+[0.227])	Prec@1 80.469 (80.469)
 * Prec@1 76.320
current lr 1.00000e-01
Grad=  tensor(2.4863, device='cuda:0')
Epoch: [72][0/391]	Time 0.262 (0.262)	Data 0.140 (0.140)	Loss 0.8550 (0.8550) ([0.628]+[0.227])	Prec@1 82.031 (82.031)
Epoch: [72][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6008 (0.7316) ([0.374]+[0.227])	Prec@1 87.500 (82.820)
Epoch: [72][200/391]	Time 0.114 (0.113)	Data 0.000 (0.001)	Loss 0.7887 (0.7428) ([0.560]+[0.228])	Prec@1 80.469 (82.416)
Epoch: [72][300/391]	Time 0.114 (0.113)	Data 0.000 (0.001)	Loss 0.7129 (0.7463) ([0.485]+[0.228])	Prec@1 82.812 (82.327)
Test: [0/79]	Time 0.169 (0.169)	Loss 0.9705 (0.9705) ([0.743]+[0.228])	Prec@1 76.562 (76.562)
 * Prec@1 75.720
current lr 1.00000e-01
Grad=  tensor(1.8297, device='cuda:0')
Epoch: [73][0/391]	Time 0.253 (0.253)	Data 0.130 (0.130)	Loss 0.7523 (0.7523) ([0.524]+[0.228])	Prec@1 82.812 (82.812)
Epoch: [73][100/391]	Time 0.112 (0.115)	Data 0.000 (0.001)	Loss 0.5772 (0.7322) ([0.350]+[0.228])	Prec@1 86.719 (82.758)
Epoch: [73][200/391]	Time 0.114 (0.114)	Data 0.000 (0.001)	Loss 0.7775 (0.7372) ([0.550]+[0.227])	Prec@1 83.594 (82.641)
Epoch: [73][300/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.8053 (0.7386) ([0.579]+[0.227])	Prec@1 80.469 (82.610)
Test: [0/79]	Time 0.177 (0.177)	Loss 1.1059 (1.1059) ([0.879]+[0.226])	Prec@1 68.750 (68.750)
 * Prec@1 74.600
current lr 1.00000e-01
Grad=  tensor(1.9971, device='cuda:0')
Epoch: [74][0/391]	Time 0.261 (0.261)	Data 0.140 (0.140)	Loss 0.7096 (0.7096) ([0.483]+[0.226])	Prec@1 85.156 (85.156)
Epoch: [74][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8193 (0.7102) ([0.593]+[0.226])	Prec@1 78.906 (83.408)
Epoch: [74][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.8222 (0.7262) ([0.595]+[0.227])	Prec@1 79.688 (82.956)
Epoch: [74][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8367 (0.7265) ([0.610]+[0.226])	Prec@1 77.344 (82.984)
Test: [0/79]	Time 0.173 (0.173)	Loss 0.9838 (0.9838) ([0.757]+[0.226])	Prec@1 71.875 (71.875)
 * Prec@1 75.880
current lr 1.00000e-01
Grad=  tensor(1.5946, device='cuda:0')
Epoch: [75][0/391]	Time 0.258 (0.258)	Data 0.138 (0.138)	Loss 0.6348 (0.6348) ([0.408]+[0.226])	Prec@1 82.812 (82.812)
Epoch: [75][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7573 (0.7457) ([0.530]+[0.227])	Prec@1 78.125 (82.356)
Epoch: [75][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7997 (0.7423) ([0.573]+[0.227])	Prec@1 82.812 (82.331)
Epoch: [75][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6081 (0.7391) ([0.382]+[0.226])	Prec@1 85.156 (82.439)
Test: [0/79]	Time 0.171 (0.171)	Loss 1.1820 (1.1820) ([0.956]+[0.226])	Prec@1 67.969 (67.969)
 * Prec@1 71.690
current lr 1.00000e-01
Grad=  tensor(2.7339, device='cuda:0')
Epoch: [76][0/391]	Time 0.259 (0.259)	Data 0.138 (0.138)	Loss 0.7825 (0.7825) ([0.556]+[0.226])	Prec@1 81.250 (81.250)
Epoch: [76][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7590 (0.7270) ([0.533]+[0.226])	Prec@1 83.594 (82.751)
Epoch: [76][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.6056 (0.7274) ([0.379]+[0.227])	Prec@1 85.938 (82.851)
Epoch: [76][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7055 (0.7312) ([0.479]+[0.226])	Prec@1 83.594 (82.794)
Test: [0/79]	Time 0.170 (0.170)	Loss 0.9320 (0.9320) ([0.706]+[0.226])	Prec@1 75.000 (75.000)
 * Prec@1 73.430
current lr 1.00000e-01
Grad=  tensor(2.2647, device='cuda:0')
Epoch: [77][0/391]	Time 0.261 (0.261)	Data 0.140 (0.140)	Loss 0.7282 (0.7282) ([0.502]+[0.226])	Prec@1 83.594 (83.594)
Epoch: [77][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7658 (0.7406) ([0.539]+[0.227])	Prec@1 81.250 (82.271)
Epoch: [77][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.9168 (0.7428) ([0.690]+[0.227])	Prec@1 74.219 (82.272)
Epoch: [77][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.7280 (0.7371) ([0.502]+[0.226])	Prec@1 84.375 (82.532)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.8811 (0.8811) ([0.655]+[0.227])	Prec@1 78.906 (78.906)
 * Prec@1 76.320
current lr 1.00000e-01
Grad=  tensor(2.4644, device='cuda:0')
Epoch: [78][0/391]	Time 0.256 (0.256)	Data 0.136 (0.136)	Loss 0.7887 (0.7887) ([0.562]+[0.227])	Prec@1 84.375 (84.375)
Epoch: [78][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.6378 (0.7266) ([0.411]+[0.226])	Prec@1 84.375 (82.720)
Epoch: [78][200/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.8891 (0.7367) ([0.663]+[0.226])	Prec@1 78.125 (82.552)
Epoch: [78][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.6207 (0.7326) ([0.396]+[0.225])	Prec@1 85.938 (82.787)
Test: [0/79]	Time 0.169 (0.169)	Loss 0.8481 (0.8481) ([0.623]+[0.225])	Prec@1 80.469 (80.469)
 * Prec@1 78.040
current lr 1.00000e-01
Grad=  tensor(2.1722, device='cuda:0')
Epoch: [79][0/391]	Time 0.259 (0.259)	Data 0.140 (0.140)	Loss 0.7577 (0.7577) ([0.533]+[0.225])	Prec@1 82.812 (82.812)
Epoch: [79][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.7803 (0.7176) ([0.555]+[0.225])	Prec@1 82.812 (82.983)
Epoch: [79][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.6043 (0.7208) ([0.380]+[0.225])	Prec@1 89.844 (82.980)
Epoch: [79][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.6752 (0.7262) ([0.451]+[0.225])	Prec@1 85.938 (82.831)
Test: [0/79]	Time 0.168 (0.168)	Loss 1.0669 (1.0669) ([0.842]+[0.225])	Prec@1 67.969 (67.969)
 * Prec@1 72.350
current lr 1.00000e-01
Grad=  tensor(2.1823, device='cuda:0')
Epoch: [80][0/391]	Time 0.255 (0.255)	Data 0.136 (0.136)	Loss 0.7674 (0.7674) ([0.543]+[0.225])	Prec@1 82.031 (82.031)
Epoch: [80][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.8052 (0.7362) ([0.580]+[0.225])	Prec@1 82.031 (82.271)
Epoch: [80][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.8279 (0.7339) ([0.604]+[0.224])	Prec@1 78.906 (82.486)
Epoch: [80][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.8708 (0.7314) ([0.647]+[0.223])	Prec@1 75.781 (82.652)
Test: [0/79]	Time 0.169 (0.169)	Loss 0.7799 (0.7799) ([0.556]+[0.223])	Prec@1 82.812 (82.812)
 * Prec@1 77.930
current lr 1.00000e-01
Grad=  tensor(1.6424, device='cuda:0')
Epoch: [81][0/391]	Time 0.256 (0.256)	Data 0.136 (0.136)	Loss 0.6651 (0.6651) ([0.442]+[0.223])	Prec@1 85.938 (85.938)
Epoch: [81][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.7319 (0.7122) ([0.509]+[0.223])	Prec@1 80.469 (82.990)
Epoch: [81][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.7364 (0.7276) ([0.513]+[0.224])	Prec@1 80.469 (82.606)
Epoch: [81][300/391]	Time 0.110 (0.109)	Data 0.000 (0.001)	Loss 0.7052 (0.7282) ([0.482]+[0.223])	Prec@1 80.469 (82.631)
Test: [0/79]	Time 0.166 (0.166)	Loss 1.0373 (1.0373) ([0.813]+[0.224])	Prec@1 73.438 (73.438)
 * Prec@1 73.830
current lr 1.00000e-01
Grad=  tensor(1.9921, device='cuda:0')
Epoch: [82][0/391]	Time 0.259 (0.259)	Data 0.140 (0.140)	Loss 0.7495 (0.7495) ([0.526]+[0.224])	Prec@1 82.031 (82.031)
Epoch: [82][100/391]	Time 0.109 (0.110)	Data 0.000 (0.002)	Loss 0.6803 (0.7294) ([0.457]+[0.224])	Prec@1 83.594 (82.944)
Epoch: [82][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.6613 (0.7162) ([0.438]+[0.223])	Prec@1 86.719 (83.349)
Epoch: [82][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.7355 (0.7177) ([0.512]+[0.223])	Prec@1 85.938 (83.339)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.9652 (0.9652) ([0.741]+[0.224])	Prec@1 74.219 (74.219)
 * Prec@1 75.540
current lr 1.00000e-01
Grad=  tensor(1.4558, device='cuda:0')
Epoch: [83][0/391]	Time 0.258 (0.258)	Data 0.138 (0.138)	Loss 0.6429 (0.6429) ([0.419]+[0.224])	Prec@1 84.375 (84.375)
Epoch: [83][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.7036 (0.7164) ([0.479]+[0.224])	Prec@1 82.031 (82.735)
Epoch: [83][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.6227 (0.7304) ([0.399]+[0.224])	Prec@1 84.375 (82.389)
Epoch: [83][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.7732 (0.7363) ([0.549]+[0.225])	Prec@1 78.906 (82.216)
Test: [0/79]	Time 0.169 (0.169)	Loss 0.9513 (0.9513) ([0.727]+[0.225])	Prec@1 78.906 (78.906)
 * Prec@1 75.550
current lr 1.00000e-01
Grad=  tensor(2.4281, device='cuda:0')
Epoch: [84][0/391]	Time 0.258 (0.258)	Data 0.138 (0.138)	Loss 0.9043 (0.9043) ([0.680]+[0.225])	Prec@1 75.781 (75.781)
Epoch: [84][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.8342 (0.7190) ([0.611]+[0.223])	Prec@1 78.125 (83.037)
Epoch: [84][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.7964 (0.7200) ([0.572]+[0.224])	Prec@1 82.031 (82.917)
Epoch: [84][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.8609 (0.7205) ([0.637]+[0.223])	Prec@1 79.688 (83.005)
Test: [0/79]	Time 0.170 (0.170)	Loss 1.2561 (1.2561) ([1.033]+[0.223])	Prec@1 67.188 (67.188)
 * Prec@1 68.630
current lr 1.00000e-01
Grad=  tensor(2.4928, device='cuda:0')
Epoch: [85][0/391]	Time 0.256 (0.256)	Data 0.136 (0.136)	Loss 0.8078 (0.8078) ([0.584]+[0.223])	Prec@1 81.250 (81.250)
Epoch: [85][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.6569 (0.7190) ([0.434]+[0.223])	Prec@1 83.594 (83.222)
Epoch: [85][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.6654 (0.7251) ([0.442]+[0.223])	Prec@1 85.156 (82.914)
Epoch: [85][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.7606 (0.7287) ([0.538]+[0.222])	Prec@1 80.469 (82.670)
Test: [0/79]	Time 0.170 (0.170)	Loss 0.9853 (0.9853) ([0.763]+[0.222])	Prec@1 76.562 (76.562)
 * Prec@1 76.070
current lr 1.00000e-01
Grad=  tensor(1.8996, device='cuda:0')
Epoch: [86][0/391]	Time 0.255 (0.255)	Data 0.135 (0.135)	Loss 0.6607 (0.6607) ([0.439]+[0.222])	Prec@1 84.375 (84.375)
Epoch: [86][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.7226 (0.7076) ([0.501]+[0.221])	Prec@1 82.031 (83.192)
Epoch: [86][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.7072 (0.7222) ([0.485]+[0.222])	Prec@1 85.156 (82.937)
Epoch: [86][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.8216 (0.7225) ([0.600]+[0.222])	Prec@1 77.344 (82.844)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.8344 (0.8344) ([0.613]+[0.222])	Prec@1 81.250 (81.250)
 * Prec@1 79.190
current lr 1.00000e-01
Grad=  tensor(1.4061, device='cuda:0')
Epoch: [87][0/391]	Time 0.259 (0.259)	Data 0.140 (0.140)	Loss 0.6397 (0.6397) ([0.418]+[0.222])	Prec@1 84.375 (84.375)
Epoch: [87][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.7992 (0.7100) ([0.578]+[0.221])	Prec@1 82.031 (83.083)
Epoch: [87][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.7330 (0.7094) ([0.512]+[0.221])	Prec@1 84.375 (83.104)
Epoch: [87][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.8896 (0.7189) ([0.668]+[0.221])	Prec@1 76.562 (82.854)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.9172 (0.9172) ([0.695]+[0.222])	Prec@1 74.219 (74.219)
 * Prec@1 72.920
current lr 1.00000e-01
Grad=  tensor(1.7817, device='cuda:0')
Epoch: [88][0/391]	Time 0.257 (0.257)	Data 0.137 (0.137)	Loss 0.6440 (0.6440) ([0.422]+[0.222])	Prec@1 83.594 (83.594)
Epoch: [88][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.6444 (0.7342) ([0.422]+[0.222])	Prec@1 84.375 (82.387)
Epoch: [88][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.7223 (0.7297) ([0.500]+[0.222])	Prec@1 82.031 (82.708)
Epoch: [88][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.6702 (0.7229) ([0.449]+[0.221])	Prec@1 82.812 (82.776)
Test: [0/79]	Time 0.169 (0.169)	Loss 0.8635 (0.8635) ([0.642]+[0.222])	Prec@1 78.906 (78.906)
 * Prec@1 74.400
current lr 1.00000e-01
Grad=  tensor(1.5683, device='cuda:0')
Epoch: [89][0/391]	Time 0.261 (0.261)	Data 0.142 (0.142)	Loss 0.7359 (0.7359) ([0.514]+[0.222])	Prec@1 86.719 (86.719)
Epoch: [89][100/391]	Time 0.108 (0.110)	Data 0.000 (0.002)	Loss 0.6553 (0.7085) ([0.434]+[0.221])	Prec@1 85.938 (83.377)
Epoch: [89][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.7445 (0.7203) ([0.524]+[0.221])	Prec@1 81.250 (82.879)
Epoch: [89][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.7552 (0.7196) ([0.534]+[0.221])	Prec@1 84.375 (82.815)
Test: [0/79]	Time 0.170 (0.170)	Loss 0.7318 (0.7318) ([0.511]+[0.221])	Prec@1 81.250 (81.250)
 * Prec@1 79.100
current lr 1.00000e-01
Grad=  tensor(1.2222, device='cuda:0')
Epoch: [90][0/391]	Time 0.257 (0.257)	Data 0.138 (0.138)	Loss 0.5485 (0.5485) ([0.328]+[0.221])	Prec@1 88.281 (88.281)
Epoch: [90][100/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.6997 (0.7135) ([0.479]+[0.221])	Prec@1 82.812 (83.230)
Epoch: [90][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.6813 (0.7187) ([0.460]+[0.221])	Prec@1 82.812 (82.976)
Epoch: [90][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.7105 (0.7283) ([0.489]+[0.222])	Prec@1 82.031 (82.592)
Test: [0/79]	Time 0.167 (0.167)	Loss 1.2400 (1.2400) ([1.019]+[0.221])	Prec@1 69.531 (69.531)
 * Prec@1 69.390
current lr 1.00000e-01
Grad=  tensor(1.9808, device='cuda:0')
Epoch: [91][0/391]	Time 0.254 (0.254)	Data 0.135 (0.135)	Loss 0.6779 (0.6779) ([0.457]+[0.221])	Prec@1 82.812 (82.812)
Epoch: [91][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.6980 (0.7088) ([0.477]+[0.221])	Prec@1 80.469 (83.284)
Epoch: [91][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.7717 (0.7136) ([0.552]+[0.220])	Prec@1 82.812 (83.217)
Epoch: [91][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.7425 (0.7187) ([0.522]+[0.220])	Prec@1 80.469 (82.989)
Test: [0/79]	Time 0.167 (0.167)	Loss 1.0113 (1.0113) ([0.792]+[0.219])	Prec@1 77.344 (77.344)
 * Prec@1 76.400
current lr 1.00000e-01
Grad=  tensor(1.8574, device='cuda:0')
Epoch: [92][0/391]	Time 0.255 (0.255)	Data 0.137 (0.137)	Loss 0.6479 (0.6479) ([0.429]+[0.219])	Prec@1 85.156 (85.156)
Epoch: [92][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.7940 (0.7154) ([0.575]+[0.219])	Prec@1 81.250 (82.990)
Epoch: [92][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.6833 (0.7106) ([0.464]+[0.219])	Prec@1 85.938 (83.267)
Epoch: [92][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.6758 (0.7137) ([0.456]+[0.219])	Prec@1 81.250 (82.973)
Test: [0/79]	Time 0.170 (0.170)	Loss 1.1585 (1.1585) ([0.939]+[0.220])	Prec@1 71.875 (71.875)
 * Prec@1 72.660
current lr 1.00000e-01
Grad=  tensor(1.9234, device='cuda:0')
Epoch: [93][0/391]	Time 0.257 (0.257)	Data 0.138 (0.138)	Loss 0.6324 (0.6324) ([0.413]+[0.220])	Prec@1 83.594 (83.594)
Epoch: [93][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.6633 (0.7086) ([0.444]+[0.219])	Prec@1 84.375 (83.246)
Epoch: [93][200/391]	Time 0.110 (0.109)	Data 0.000 (0.001)	Loss 0.5973 (0.7085) ([0.379]+[0.218])	Prec@1 89.062 (83.306)
Epoch: [93][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.8036 (0.7146) ([0.584]+[0.219])	Prec@1 72.656 (82.893)
Test: [0/79]	Time 0.167 (0.167)	Loss 1.1478 (1.1478) ([0.929]+[0.219])	Prec@1 71.875 (71.875)
 * Prec@1 71.480
current lr 1.00000e-01
Grad=  tensor(1.5353, device='cuda:0')
Epoch: [94][0/391]	Time 0.258 (0.258)	Data 0.137 (0.137)	Loss 0.5616 (0.5616) ([0.343]+[0.219])	Prec@1 89.062 (89.062)
Epoch: [94][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6137 (0.6951) ([0.395]+[0.219])	Prec@1 88.281 (83.563)
Epoch: [94][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7321 (0.7127) ([0.513]+[0.219])	Prec@1 82.812 (82.902)
Epoch: [94][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7314 (0.7247) ([0.512]+[0.219])	Prec@1 85.156 (82.556)
Test: [0/79]	Time 0.171 (0.171)	Loss 1.2034 (1.2034) ([0.985]+[0.218])	Prec@1 74.219 (74.219)
 * Prec@1 73.650
current lr 1.00000e-01
Grad=  tensor(1.3910, device='cuda:0')
Epoch: [95][0/391]	Time 0.258 (0.258)	Data 0.137 (0.137)	Loss 0.5995 (0.5995) ([0.381]+[0.218])	Prec@1 85.156 (85.156)
Epoch: [95][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6555 (0.7181) ([0.437]+[0.219])	Prec@1 86.719 (83.099)
Epoch: [95][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7098 (0.7085) ([0.491]+[0.219])	Prec@1 78.125 (83.077)
Epoch: [95][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8555 (0.7199) ([0.636]+[0.219])	Prec@1 78.125 (82.812)
Test: [0/79]	Time 0.170 (0.170)	Loss 0.9022 (0.9022) ([0.683]+[0.219])	Prec@1 76.562 (76.562)
 * Prec@1 72.580
current lr 1.00000e-01
Grad=  tensor(1.7473, device='cuda:0')
Epoch: [96][0/391]	Time 0.260 (0.260)	Data 0.138 (0.138)	Loss 0.6179 (0.6179) ([0.399]+[0.219])	Prec@1 88.281 (88.281)
Epoch: [96][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6864 (0.6900) ([0.468]+[0.219])	Prec@1 83.594 (84.127)
Epoch: [96][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.8862 (0.7065) ([0.667]+[0.219])	Prec@1 77.344 (83.656)
Epoch: [96][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8938 (0.7140) ([0.674]+[0.220])	Prec@1 78.125 (83.365)
Test: [0/79]	Time 0.172 (0.172)	Loss 0.9765 (0.9765) ([0.758]+[0.219])	Prec@1 73.438 (73.438)
 * Prec@1 76.450
current lr 1.00000e-01
Grad=  tensor(1.8761, device='cuda:0')
Epoch: [97][0/391]	Time 0.261 (0.261)	Data 0.140 (0.140)	Loss 0.6545 (0.6545) ([0.436]+[0.219])	Prec@1 82.031 (82.031)
Epoch: [97][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.7230 (0.7173) ([0.504]+[0.219])	Prec@1 80.469 (82.929)
Epoch: [97][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.6181 (0.7190) ([0.399]+[0.220])	Prec@1 87.500 (82.972)
Epoch: [97][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.8159 (0.7151) ([0.597]+[0.219])	Prec@1 78.125 (83.181)
Test: [0/79]	Time 0.170 (0.170)	Loss 0.9200 (0.9200) ([0.701]+[0.219])	Prec@1 78.125 (78.125)
 * Prec@1 74.500
current lr 1.00000e-01
Grad=  tensor(1.0364, device='cuda:0')
Epoch: [98][0/391]	Time 0.260 (0.260)	Data 0.140 (0.140)	Loss 0.5870 (0.5870) ([0.368]+[0.219])	Prec@1 88.281 (88.281)
Epoch: [98][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.7122 (0.7107) ([0.493]+[0.219])	Prec@1 81.250 (83.037)
Epoch: [98][200/391]	Time 0.108 (0.111)	Data 0.000 (0.001)	Loss 0.7176 (0.7259) ([0.498]+[0.219])	Prec@1 84.375 (82.451)
Epoch: [98][300/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.7736 (0.7270) ([0.554]+[0.219])	Prec@1 82.812 (82.491)
Test: [0/79]	Time 0.165 (0.165)	Loss 1.0049 (1.0049) ([0.786]+[0.219])	Prec@1 78.906 (78.906)
 * Prec@1 76.570
current lr 1.00000e-01
Grad=  tensor(1.6219, device='cuda:0')
Epoch: [99][0/391]	Time 0.258 (0.258)	Data 0.139 (0.139)	Loss 0.6235 (0.6235) ([0.405]+[0.219])	Prec@1 86.719 (86.719)
Epoch: [99][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.6246 (0.6969) ([0.407]+[0.218])	Prec@1 83.594 (83.516)
Epoch: [99][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.7715 (0.7068) ([0.553]+[0.218])	Prec@1 78.906 (83.182)
Epoch: [99][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.7891 (0.7068) ([0.571]+[0.218])	Prec@1 80.469 (83.212)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.9025 (0.9025) ([0.684]+[0.218])	Prec@1 75.781 (75.781)
 * Prec@1 72.380
current lr 1.00000e-02
Grad=  tensor(1.8024, device='cuda:0')
Epoch: [100][0/391]	Time 0.255 (0.255)	Data 0.136 (0.136)	Loss 0.6296 (0.6296) ([0.411]+[0.218])	Prec@1 85.156 (85.156)
Epoch: [100][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.5927 (0.5675) ([0.391]+[0.201])	Prec@1 89.844 (87.678)
Epoch: [100][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.6010 (0.5403) ([0.401]+[0.200])	Prec@1 85.156 (88.472)
Epoch: [100][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.4352 (0.5217) ([0.237]+[0.198])	Prec@1 92.969 (89.114)
Test: [0/79]	Time 0.172 (0.172)	Loss 0.4031 (0.4031) ([0.206]+[0.197])	Prec@1 91.406 (91.406)
 * Prec@1 89.690
current lr 1.00000e-02
Grad=  tensor(1.2753, device='cuda:0')
Epoch: [101][0/391]	Time 0.259 (0.259)	Data 0.139 (0.139)	Loss 0.4405 (0.4405) ([0.244]+[0.197])	Prec@1 92.969 (92.969)
Epoch: [101][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.4535 (0.4619) ([0.258]+[0.195])	Prec@1 92.969 (91.012)
Epoch: [101][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.4765 (0.4553) ([0.283]+[0.194])	Prec@1 89.844 (91.192)
Epoch: [101][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.4503 (0.4530) ([0.258]+[0.192])	Prec@1 93.750 (91.300)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.4298 (0.4298) ([0.239]+[0.191])	Prec@1 90.625 (90.625)
 * Prec@1 90.130
current lr 1.00000e-02
Grad=  tensor(1.7074, device='cuda:0')
Epoch: [102][0/391]	Time 0.261 (0.261)	Data 0.142 (0.142)	Loss 0.4909 (0.4909) ([0.300]+[0.191])	Prec@1 91.406 (91.406)
Epoch: [102][100/391]	Time 0.108 (0.110)	Data 0.000 (0.002)	Loss 0.4708 (0.4230) ([0.281]+[0.190])	Prec@1 89.062 (92.218)
Epoch: [102][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3942 (0.4217) ([0.206]+[0.189])	Prec@1 92.969 (92.090)
Epoch: [102][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3685 (0.4196) ([0.181]+[0.187])	Prec@1 93.750 (92.107)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.4479 (0.4479) ([0.262]+[0.186])	Prec@1 89.844 (89.844)
 * Prec@1 90.240
current lr 1.00000e-02
Grad=  tensor(1.6815, device='cuda:0')
Epoch: [103][0/391]	Time 0.263 (0.263)	Data 0.145 (0.145)	Loss 0.4356 (0.4356) ([0.249]+[0.186])	Prec@1 93.750 (93.750)
Epoch: [103][100/391]	Time 0.108 (0.110)	Data 0.000 (0.002)	Loss 0.5222 (0.4032) ([0.337]+[0.185])	Prec@1 88.281 (92.760)
Epoch: [103][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3760 (0.4056) ([0.192]+[0.184])	Prec@1 91.406 (92.580)
Epoch: [103][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.4777 (0.4015) ([0.295]+[0.183])	Prec@1 90.625 (92.624)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.3716 (0.3716) ([0.190]+[0.182])	Prec@1 93.750 (93.750)
 * Prec@1 90.910
current lr 1.00000e-02
Grad=  tensor(2.7371, device='cuda:0')
Epoch: [104][0/391]	Time 0.258 (0.258)	Data 0.139 (0.139)	Loss 0.3935 (0.3935) ([0.212]+[0.182])	Prec@1 90.625 (90.625)
Epoch: [104][100/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3077 (0.3867) ([0.127]+[0.181])	Prec@1 96.094 (92.884)
Epoch: [104][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.4130 (0.3878) ([0.233]+[0.180])	Prec@1 92.188 (92.833)
Epoch: [104][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3661 (0.3877) ([0.187]+[0.179])	Prec@1 94.531 (92.855)
Test: [0/79]	Time 0.170 (0.170)	Loss 0.4291 (0.4291) ([0.251]+[0.178])	Prec@1 89.844 (89.844)
 * Prec@1 90.510
current lr 1.00000e-02
Grad=  tensor(2.3750, device='cuda:0')
Epoch: [105][0/391]	Time 0.251 (0.251)	Data 0.134 (0.134)	Loss 0.4146 (0.4146) ([0.237]+[0.178])	Prec@1 90.625 (90.625)
Epoch: [105][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.3947 (0.3701) ([0.218]+[0.177])	Prec@1 91.406 (93.487)
Epoch: [105][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3811 (0.3678) ([0.205]+[0.176])	Prec@1 92.188 (93.424)
Epoch: [105][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2773 (0.3695) ([0.103]+[0.175])	Prec@1 97.656 (93.343)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.4169 (0.4169) ([0.243]+[0.174])	Prec@1 92.188 (92.188)
 * Prec@1 90.760
current lr 1.00000e-02
Grad=  tensor(1.9099, device='cuda:0')
Epoch: [106][0/391]	Time 0.256 (0.256)	Data 0.135 (0.135)	Loss 0.3201 (0.3201) ([0.146]+[0.174])	Prec@1 95.312 (95.312)
Epoch: [106][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3515 (0.3557) ([0.179]+[0.173])	Prec@1 93.750 (93.920)
Epoch: [106][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3197 (0.3547) ([0.148]+[0.172])	Prec@1 94.531 (93.859)
Epoch: [106][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.3984 (0.3581) ([0.227]+[0.171])	Prec@1 92.188 (93.667)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.4145 (0.4145) ([0.244]+[0.170])	Prec@1 93.750 (93.750)
 * Prec@1 90.970
current lr 1.00000e-02
Grad=  tensor(2.2525, device='cuda:0')
Epoch: [107][0/391]	Time 0.260 (0.260)	Data 0.139 (0.139)	Loss 0.3691 (0.3691) ([0.199]+[0.170])	Prec@1 92.969 (92.969)
Epoch: [107][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2856 (0.3441) ([0.116]+[0.169])	Prec@1 96.875 (93.920)
Epoch: [107][200/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2997 (0.3476) ([0.131]+[0.169])	Prec@1 95.312 (93.847)
Epoch: [107][300/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.3161 (0.3491) ([0.148]+[0.168])	Prec@1 95.312 (93.771)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.4347 (0.4347) ([0.268]+[0.167])	Prec@1 92.969 (92.969)
 * Prec@1 90.640
current lr 1.00000e-02
Grad=  tensor(2.4034, device='cuda:0')
Epoch: [108][0/391]	Time 0.255 (0.255)	Data 0.136 (0.136)	Loss 0.3274 (0.3274) ([0.160]+[0.167])	Prec@1 96.094 (96.094)
Epoch: [108][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2621 (0.3388) ([0.096]+[0.166])	Prec@1 97.656 (94.152)
Epoch: [108][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2841 (0.3358) ([0.119]+[0.165])	Prec@1 96.094 (94.232)
Epoch: [108][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3917 (0.3395) ([0.227]+[0.165])	Prec@1 92.969 (94.111)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.4078 (0.4078) ([0.244]+[0.164])	Prec@1 92.188 (92.188)
 * Prec@1 90.570
current lr 1.00000e-02
Grad=  tensor(1.1807, device='cuda:0')
Epoch: [109][0/391]	Time 0.255 (0.255)	Data 0.134 (0.134)	Loss 0.2405 (0.2405) ([0.076]+[0.164])	Prec@1 97.656 (97.656)
Epoch: [109][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.3313 (0.3328) ([0.168]+[0.163])	Prec@1 93.750 (94.222)
Epoch: [109][200/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.2900 (0.3344) ([0.127]+[0.163])	Prec@1 95.312 (94.088)
Epoch: [109][300/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.3550 (0.3338) ([0.193]+[0.162])	Prec@1 92.188 (94.176)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.4165 (0.4165) ([0.255]+[0.161])	Prec@1 91.406 (91.406)
 * Prec@1 90.630
current lr 1.00000e-02
Grad=  tensor(1.7698, device='cuda:0')
Epoch: [110][0/391]	Time 0.257 (0.257)	Data 0.137 (0.137)	Loss 0.2932 (0.2932) ([0.132]+[0.161])	Prec@1 96.875 (96.875)
Epoch: [110][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.3462 (0.3301) ([0.186]+[0.161])	Prec@1 92.969 (94.144)
Epoch: [110][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2949 (0.3252) ([0.135]+[0.160])	Prec@1 96.875 (94.356)
Epoch: [110][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3113 (0.3268) ([0.152]+[0.159])	Prec@1 93.750 (94.324)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.4736 (0.4736) ([0.315]+[0.159])	Prec@1 89.062 (89.062)
 * Prec@1 90.490
current lr 1.00000e-02
Grad=  tensor(3.6540, device='cuda:0')
Epoch: [111][0/391]	Time 0.256 (0.256)	Data 0.137 (0.137)	Loss 0.3245 (0.3245) ([0.166]+[0.159])	Prec@1 94.531 (94.531)
Epoch: [111][100/391]	Time 0.108 (0.111)	Data 0.000 (0.001)	Loss 0.2931 (0.3188) ([0.135]+[0.158])	Prec@1 94.531 (94.578)
Epoch: [111][200/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2879 (0.3204) ([0.130]+[0.158])	Prec@1 93.750 (94.446)
Epoch: [111][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3544 (0.3222) ([0.197]+[0.157])	Prec@1 94.531 (94.363)
Test: [0/79]	Time 0.170 (0.170)	Loss 0.4448 (0.4448) ([0.288]+[0.156])	Prec@1 90.625 (90.625)
 * Prec@1 91.230
current lr 1.00000e-02
Grad=  tensor(4.3511, device='cuda:0')
Epoch: [112][0/391]	Time 0.261 (0.261)	Data 0.141 (0.141)	Loss 0.3628 (0.3628) ([0.206]+[0.156])	Prec@1 93.750 (93.750)
Epoch: [112][100/391]	Time 0.108 (0.110)	Data 0.000 (0.002)	Loss 0.3936 (0.3104) ([0.238]+[0.156])	Prec@1 92.188 (94.763)
Epoch: [112][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3090 (0.3106) ([0.154]+[0.155])	Prec@1 94.531 (94.652)
Epoch: [112][300/391]	Time 0.110 (0.109)	Data 0.000 (0.001)	Loss 0.2887 (0.3135) ([0.134]+[0.155])	Prec@1 95.312 (94.521)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.5093 (0.5093) ([0.355]+[0.154])	Prec@1 88.281 (88.281)
 * Prec@1 89.790
current lr 1.00000e-02
Grad=  tensor(4.7112, device='cuda:0')
Epoch: [113][0/391]	Time 0.260 (0.260)	Data 0.139 (0.139)	Loss 0.3737 (0.3737) ([0.219]+[0.154])	Prec@1 93.750 (93.750)
Epoch: [113][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3108 (0.3150) ([0.157]+[0.154])	Prec@1 96.094 (94.407)
Epoch: [113][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3878 (0.3132) ([0.235]+[0.153])	Prec@1 91.406 (94.492)
Epoch: [113][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3547 (0.3151) ([0.202]+[0.153])	Prec@1 92.969 (94.376)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.4869 (0.4869) ([0.335]+[0.152])	Prec@1 89.062 (89.062)
 * Prec@1 90.570
current lr 1.00000e-02
Grad=  tensor(5.0737, device='cuda:0')
Epoch: [114][0/391]	Time 0.257 (0.257)	Data 0.136 (0.136)	Loss 0.3286 (0.3286) ([0.176]+[0.152])	Prec@1 92.188 (92.188)
Epoch: [114][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2098 (0.2997) ([0.058]+[0.152])	Prec@1 98.438 (94.964)
Epoch: [114][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3008 (0.3049) ([0.149]+[0.151])	Prec@1 93.750 (94.663)
Epoch: [114][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2706 (0.3079) ([0.120]+[0.151])	Prec@1 94.531 (94.552)
Test: [0/79]	Time 0.171 (0.171)	Loss 0.5162 (0.5162) ([0.365]+[0.151])	Prec@1 89.844 (89.844)
 * Prec@1 90.310
current lr 1.00000e-02
Grad=  tensor(6.5016, device='cuda:0')
Epoch: [115][0/391]	Time 0.261 (0.261)	Data 0.139 (0.139)	Loss 0.3244 (0.3244) ([0.174]+[0.151])	Prec@1 94.531 (94.531)
Epoch: [115][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.4299 (0.3003) ([0.280]+[0.150])	Prec@1 90.625 (94.887)
Epoch: [115][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3061 (0.3021) ([0.156]+[0.150])	Prec@1 94.531 (94.757)
Epoch: [115][300/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.3390 (0.3055) ([0.190]+[0.149])	Prec@1 90.625 (94.612)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.4454 (0.4454) ([0.296]+[0.149])	Prec@1 89.062 (89.062)
 * Prec@1 89.550
current lr 1.00000e-02
Grad=  tensor(4.6669, device='cuda:0')
Epoch: [116][0/391]	Time 0.257 (0.257)	Data 0.136 (0.136)	Loss 0.3334 (0.3334) ([0.184]+[0.149])	Prec@1 93.750 (93.750)
Epoch: [116][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2682 (0.2985) ([0.120]+[0.149])	Prec@1 96.875 (94.578)
Epoch: [116][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2805 (0.3048) ([0.132]+[0.148])	Prec@1 94.531 (94.500)
Epoch: [116][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3123 (0.3048) ([0.164]+[0.148])	Prec@1 95.312 (94.521)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.4718 (0.4718) ([0.324]+[0.148])	Prec@1 89.844 (89.844)
 * Prec@1 90.100
current lr 1.00000e-02
Grad=  tensor(4.2005, device='cuda:0')
Epoch: [117][0/391]	Time 0.260 (0.260)	Data 0.137 (0.137)	Loss 0.2968 (0.2968) ([0.149]+[0.148])	Prec@1 94.531 (94.531)
Epoch: [117][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2496 (0.2954) ([0.102]+[0.147])	Prec@1 96.875 (95.003)
Epoch: [117][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2408 (0.2992) ([0.094]+[0.147])	Prec@1 96.094 (94.733)
Epoch: [117][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3083 (0.3042) ([0.162]+[0.147])	Prec@1 94.531 (94.594)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.4708 (0.4708) ([0.324]+[0.146])	Prec@1 89.062 (89.062)
 * Prec@1 90.750
current lr 1.00000e-02
Grad=  tensor(5.5214, device='cuda:0')
Epoch: [118][0/391]	Time 0.257 (0.257)	Data 0.137 (0.137)	Loss 0.2570 (0.2570) ([0.110]+[0.146])	Prec@1 95.312 (95.312)
Epoch: [118][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3023 (0.2956) ([0.156]+[0.146])	Prec@1 96.094 (94.763)
Epoch: [118][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2788 (0.3026) ([0.133]+[0.146])	Prec@1 93.750 (94.469)
Epoch: [118][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3337 (0.3037) ([0.188]+[0.146])	Prec@1 92.969 (94.427)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.4040 (0.4040) ([0.259]+[0.145])	Prec@1 91.406 (91.406)
 * Prec@1 90.110
current lr 1.00000e-02
Grad=  tensor(9.8945, device='cuda:0')
Epoch: [119][0/391]	Time 0.261 (0.261)	Data 0.140 (0.140)	Loss 0.4238 (0.4238) ([0.278]+[0.145])	Prec@1 89.062 (89.062)
Epoch: [119][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2489 (0.2876) ([0.104]+[0.145])	Prec@1 96.875 (94.903)
Epoch: [119][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2660 (0.2954) ([0.121]+[0.145])	Prec@1 96.875 (94.718)
Epoch: [119][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2587 (0.2974) ([0.114]+[0.145])	Prec@1 96.875 (94.664)
Test: [0/79]	Time 0.173 (0.173)	Loss 0.4446 (0.4446) ([0.300]+[0.144])	Prec@1 92.969 (92.969)
 * Prec@1 89.810
current lr 1.00000e-02
Grad=  tensor(5.1589, device='cuda:0')
Epoch: [120][0/391]	Time 0.264 (0.264)	Data 0.142 (0.142)	Loss 0.2864 (0.2864) ([0.142]+[0.144])	Prec@1 95.312 (95.312)
Epoch: [120][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.3035 (0.2873) ([0.159]+[0.144])	Prec@1 94.531 (95.111)
Epoch: [120][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3432 (0.2935) ([0.199]+[0.144])	Prec@1 91.406 (94.768)
Epoch: [120][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3356 (0.2996) ([0.192]+[0.144])	Prec@1 93.750 (94.565)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.4601 (0.4601) ([0.316]+[0.144])	Prec@1 89.844 (89.844)
 * Prec@1 89.080
current lr 1.00000e-02
Grad=  tensor(8.9370, device='cuda:0')
Epoch: [121][0/391]	Time 0.260 (0.260)	Data 0.139 (0.139)	Loss 0.3614 (0.3614) ([0.218]+[0.144])	Prec@1 92.188 (92.188)
Epoch: [121][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3403 (0.2974) ([0.197]+[0.143])	Prec@1 89.844 (94.500)
Epoch: [121][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3809 (0.2957) ([0.238]+[0.143])	Prec@1 91.406 (94.562)
Epoch: [121][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3597 (0.2957) ([0.217]+[0.143])	Prec@1 94.531 (94.619)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.4572 (0.4572) ([0.314]+[0.143])	Prec@1 91.406 (91.406)
 * Prec@1 90.060
current lr 1.00000e-02
Grad=  tensor(6.1404, device='cuda:0')
Epoch: [122][0/391]	Time 0.261 (0.261)	Data 0.136 (0.136)	Loss 0.3266 (0.3266) ([0.184]+[0.143])	Prec@1 95.312 (95.312)
Epoch: [122][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2769 (0.2898) ([0.134]+[0.143])	Prec@1 96.875 (95.026)
Epoch: [122][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.4016 (0.2940) ([0.259]+[0.142])	Prec@1 91.406 (94.761)
Epoch: [122][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3215 (0.2991) ([0.179]+[0.142])	Prec@1 95.312 (94.552)
Test: [0/79]	Time 0.173 (0.173)	Loss 0.5100 (0.5100) ([0.368]+[0.142])	Prec@1 89.844 (89.844)
 * Prec@1 89.290
current lr 1.00000e-02
Grad=  tensor(3.2233, device='cuda:0')
Epoch: [123][0/391]	Time 0.262 (0.262)	Data 0.140 (0.140)	Loss 0.2577 (0.2577) ([0.115]+[0.142])	Prec@1 97.656 (97.656)
Epoch: [123][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2823 (0.2971) ([0.140]+[0.142])	Prec@1 95.312 (94.407)
Epoch: [123][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2430 (0.2945) ([0.101]+[0.142])	Prec@1 96.875 (94.702)
Epoch: [123][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3432 (0.2991) ([0.202]+[0.142])	Prec@1 93.750 (94.466)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.5260 (0.5260) ([0.384]+[0.142])	Prec@1 87.500 (87.500)
 * Prec@1 89.960
current lr 1.00000e-02
Grad=  tensor(7.0819, device='cuda:0')
Epoch: [124][0/391]	Time 0.257 (0.257)	Data 0.137 (0.137)	Loss 0.3154 (0.3154) ([0.174]+[0.142])	Prec@1 96.094 (96.094)
Epoch: [124][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.2383 (0.2925) ([0.097]+[0.141])	Prec@1 96.094 (94.647)
Epoch: [124][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3194 (0.2916) ([0.178]+[0.141])	Prec@1 93.750 (94.706)
Epoch: [124][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2679 (0.2924) ([0.127]+[0.141])	Prec@1 95.312 (94.765)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.4338 (0.4338) ([0.293]+[0.141])	Prec@1 92.188 (92.188)
 * Prec@1 89.420
current lr 1.00000e-02
Grad=  tensor(2.6322, device='cuda:0')
Epoch: [125][0/391]	Time 0.255 (0.255)	Data 0.136 (0.136)	Loss 0.2185 (0.2185) ([0.077]+[0.141])	Prec@1 99.219 (99.219)
Epoch: [125][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.3341 (0.2889) ([0.193]+[0.141])	Prec@1 92.969 (94.872)
Epoch: [125][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2472 (0.2948) ([0.106]+[0.141])	Prec@1 95.312 (94.652)
Epoch: [125][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3306 (0.2966) ([0.190]+[0.141])	Prec@1 94.531 (94.549)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.4834 (0.4834) ([0.343]+[0.141])	Prec@1 90.625 (90.625)
 * Prec@1 90.310
current lr 1.00000e-02
Grad=  tensor(8.9649, device='cuda:0')
Epoch: [126][0/391]	Time 0.257 (0.257)	Data 0.138 (0.138)	Loss 0.3417 (0.3417) ([0.201]+[0.141])	Prec@1 92.969 (92.969)
Epoch: [126][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2799 (0.2864) ([0.140]+[0.140])	Prec@1 95.312 (94.872)
Epoch: [126][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2975 (0.2896) ([0.157]+[0.140])	Prec@1 95.312 (94.733)
Epoch: [126][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2658 (0.2910) ([0.126]+[0.140])	Prec@1 96.094 (94.762)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.3804 (0.3804) ([0.240]+[0.140])	Prec@1 93.750 (93.750)
 * Prec@1 89.490
current lr 1.00000e-02
Grad=  tensor(4.4923, device='cuda:0')
Epoch: [127][0/391]	Time 0.257 (0.257)	Data 0.138 (0.138)	Loss 0.2769 (0.2769) ([0.137]+[0.140])	Prec@1 93.750 (93.750)
Epoch: [127][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2094 (0.2992) ([0.069]+[0.140])	Prec@1 98.438 (94.454)
Epoch: [127][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2844 (0.2941) ([0.144]+[0.140])	Prec@1 94.531 (94.722)
Epoch: [127][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2750 (0.2950) ([0.135]+[0.140])	Prec@1 95.312 (94.645)
Test: [0/79]	Time 0.171 (0.171)	Loss 0.4832 (0.4832) ([0.344]+[0.140])	Prec@1 90.625 (90.625)
 * Prec@1 89.860
current lr 1.00000e-02
Grad=  tensor(7.6102, device='cuda:0')
Epoch: [128][0/391]	Time 0.256 (0.256)	Data 0.136 (0.136)	Loss 0.3711 (0.3711) ([0.231]+[0.140])	Prec@1 95.312 (95.312)
Epoch: [128][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2927 (0.2860) ([0.153]+[0.140])	Prec@1 93.750 (95.019)
Epoch: [128][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3629 (0.2902) ([0.223]+[0.139])	Prec@1 92.969 (94.694)
Epoch: [128][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2663 (0.2954) ([0.127]+[0.139])	Prec@1 96.875 (94.534)
Test: [0/79]	Time 0.169 (0.169)	Loss 0.5154 (0.5154) ([0.376]+[0.139])	Prec@1 90.625 (90.625)
 * Prec@1 90.840
current lr 1.00000e-02
Grad=  tensor(10.9434, device='cuda:0')
Epoch: [129][0/391]	Time 0.258 (0.258)	Data 0.139 (0.139)	Loss 0.3989 (0.3989) ([0.259]+[0.139])	Prec@1 88.281 (88.281)
Epoch: [129][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2799 (0.2796) ([0.141]+[0.139])	Prec@1 94.531 (95.196)
Epoch: [129][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3225 (0.2879) ([0.183]+[0.139])	Prec@1 93.750 (94.869)
Epoch: [129][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3093 (0.2908) ([0.170]+[0.139])	Prec@1 92.969 (94.749)
Test: [0/79]	Time 0.169 (0.169)	Loss 0.4195 (0.4195) ([0.281]+[0.139])	Prec@1 90.625 (90.625)
 * Prec@1 89.660
current lr 1.00000e-02
Grad=  tensor(3.7111, device='cuda:0')
Epoch: [130][0/391]	Time 0.256 (0.256)	Data 0.137 (0.137)	Loss 0.2348 (0.2348) ([0.096]+[0.139])	Prec@1 96.094 (96.094)
Epoch: [130][100/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.2970 (0.2798) ([0.158]+[0.139])	Prec@1 95.312 (95.220)
Epoch: [130][200/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.2562 (0.2886) ([0.117]+[0.139])	Prec@1 96.094 (94.799)
Epoch: [130][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2624 (0.2902) ([0.124]+[0.139])	Prec@1 96.094 (94.796)
Test: [0/79]	Time 0.171 (0.171)	Loss 0.4356 (0.4356) ([0.297]+[0.139])	Prec@1 89.844 (89.844)
 * Prec@1 89.170
current lr 1.00000e-02
Grad=  tensor(3.8932, device='cuda:0')
Epoch: [131][0/391]	Time 0.258 (0.258)	Data 0.137 (0.137)	Loss 0.2391 (0.2391) ([0.100]+[0.139])	Prec@1 95.312 (95.312)
Epoch: [131][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.3853 (0.2895) ([0.247]+[0.139])	Prec@1 91.406 (94.802)
Epoch: [131][200/391]	Time 0.108 (0.111)	Data 0.000 (0.001)	Loss 0.2465 (0.2893) ([0.108]+[0.139])	Prec@1 97.656 (94.827)
Epoch: [131][300/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.3588 (0.2917) ([0.220]+[0.139])	Prec@1 90.625 (94.695)
Test: [0/79]	Time 0.173 (0.173)	Loss 0.4595 (0.4595) ([0.321]+[0.138])	Prec@1 92.969 (92.969)
 * Prec@1 89.960
current lr 1.00000e-02
Grad=  tensor(6.4604, device='cuda:0')
Epoch: [132][0/391]	Time 0.262 (0.262)	Data 0.143 (0.143)	Loss 0.2981 (0.2981) ([0.160]+[0.138])	Prec@1 93.750 (93.750)
Epoch: [132][100/391]	Time 0.108 (0.110)	Data 0.000 (0.002)	Loss 0.2347 (0.2970) ([0.096]+[0.138])	Prec@1 97.656 (94.493)
Epoch: [132][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3519 (0.2953) ([0.213]+[0.138])	Prec@1 91.406 (94.617)
Epoch: [132][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3206 (0.2963) ([0.182]+[0.138])	Prec@1 94.531 (94.549)
Test: [0/79]	Time 0.169 (0.169)	Loss 0.4739 (0.4739) ([0.336]+[0.138])	Prec@1 91.406 (91.406)
 * Prec@1 89.550
current lr 1.00000e-02
Grad=  tensor(8.1123, device='cuda:0')
Epoch: [133][0/391]	Time 0.258 (0.258)	Data 0.140 (0.140)	Loss 0.2764 (0.2764) ([0.138]+[0.138])	Prec@1 94.531 (94.531)
Epoch: [133][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.3081 (0.2790) ([0.170]+[0.138])	Prec@1 93.750 (95.251)
Epoch: [133][200/391]	Time 0.110 (0.109)	Data 0.000 (0.001)	Loss 0.2390 (0.2867) ([0.101]+[0.138])	Prec@1 96.875 (94.858)
Epoch: [133][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.2643 (0.2875) ([0.126]+[0.138])	Prec@1 95.312 (94.887)
Test: [0/79]	Time 0.169 (0.169)	Loss 0.4342 (0.4342) ([0.296]+[0.138])	Prec@1 89.844 (89.844)
 * Prec@1 89.380
current lr 1.00000e-02
Grad=  tensor(6.2246, device='cuda:0')
Epoch: [134][0/391]	Time 0.261 (0.261)	Data 0.140 (0.140)	Loss 0.2806 (0.2806) ([0.142]+[0.138])	Prec@1 95.312 (95.312)
Epoch: [134][100/391]	Time 0.114 (0.115)	Data 0.000 (0.001)	Loss 0.3232 (0.2785) ([0.185]+[0.138])	Prec@1 93.750 (95.374)
Epoch: [134][200/391]	Time 0.113 (0.114)	Data 0.000 (0.001)	Loss 0.2654 (0.2823) ([0.127]+[0.138])	Prec@1 96.875 (95.138)
Epoch: [134][300/391]	Time 0.114 (0.114)	Data 0.000 (0.001)	Loss 0.3615 (0.2879) ([0.223]+[0.138])	Prec@1 92.969 (94.866)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.5165 (0.5165) ([0.378]+[0.138])	Prec@1 86.719 (86.719)
 * Prec@1 89.080
current lr 1.00000e-02
Grad=  tensor(4.2711, device='cuda:0')
Epoch: [135][0/391]	Time 0.258 (0.258)	Data 0.134 (0.134)	Loss 0.2493 (0.2493) ([0.111]+[0.138])	Prec@1 95.312 (95.312)
Epoch: [135][100/391]	Time 0.111 (0.114)	Data 0.000 (0.001)	Loss 0.3002 (0.2732) ([0.162]+[0.138])	Prec@1 95.312 (95.374)
Epoch: [135][200/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.3034 (0.2809) ([0.165]+[0.138])	Prec@1 94.531 (95.056)
Epoch: [135][300/391]	Time 0.109 (0.113)	Data 0.000 (0.001)	Loss 0.3060 (0.2844) ([0.168]+[0.138])	Prec@1 93.750 (94.874)
Test: [0/79]	Time 0.154 (0.154)	Loss 0.6011 (0.6011) ([0.463]+[0.138])	Prec@1 89.844 (89.844)
 * Prec@1 88.360
current lr 1.00000e-02
Grad=  tensor(5.2315, device='cuda:0')
Epoch: [136][0/391]	Time 0.246 (0.246)	Data 0.123 (0.123)	Loss 0.2668 (0.2668) ([0.129]+[0.138])	Prec@1 96.094 (96.094)
Epoch: [136][100/391]	Time 0.112 (0.113)	Data 0.000 (0.001)	Loss 0.3273 (0.2902) ([0.189]+[0.138])	Prec@1 94.531 (94.632)
Epoch: [136][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2851 (0.2916) ([0.147]+[0.138])	Prec@1 94.531 (94.582)
Epoch: [136][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2902 (0.2935) ([0.152]+[0.138])	Prec@1 92.188 (94.539)
Test: [0/79]	Time 0.155 (0.155)	Loss 0.6496 (0.6496) ([0.511]+[0.138])	Prec@1 87.500 (87.500)
 * Prec@1 88.990
current lr 1.00000e-02
Grad=  tensor(5.7759, device='cuda:0')
Epoch: [137][0/391]	Time 0.243 (0.243)	Data 0.121 (0.121)	Loss 0.2766 (0.2766) ([0.138]+[0.138])	Prec@1 94.531 (94.531)
Epoch: [137][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2869 (0.2797) ([0.149]+[0.138])	Prec@1 92.188 (95.135)
Epoch: [137][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2787 (0.2796) ([0.141]+[0.138])	Prec@1 93.750 (95.064)
Epoch: [137][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2507 (0.2866) ([0.113]+[0.138])	Prec@1 96.094 (94.775)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.4209 (0.4209) ([0.282]+[0.138])	Prec@1 92.188 (92.188)
 * Prec@1 89.140
current lr 1.00000e-02
Grad=  tensor(6.2115, device='cuda:0')
Epoch: [138][0/391]	Time 0.246 (0.246)	Data 0.124 (0.124)	Loss 0.2969 (0.2969) ([0.158]+[0.138])	Prec@1 95.312 (95.312)
Epoch: [138][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.2073 (0.2871) ([0.069]+[0.138])	Prec@1 98.438 (95.057)
Epoch: [138][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2024 (0.2912) ([0.064]+[0.138])	Prec@1 99.219 (94.710)
Epoch: [138][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.3135 (0.2930) ([0.175]+[0.138])	Prec@1 92.188 (94.609)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.4998 (0.4998) ([0.361]+[0.138])	Prec@1 86.719 (86.719)
 * Prec@1 89.530
current lr 1.00000e-02
Grad=  tensor(5.3516, device='cuda:0')
Epoch: [139][0/391]	Time 0.237 (0.237)	Data 0.117 (0.117)	Loss 0.2466 (0.2466) ([0.108]+[0.138])	Prec@1 95.312 (95.312)
Epoch: [139][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3107 (0.2862) ([0.172]+[0.138])	Prec@1 93.750 (94.810)
Epoch: [139][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3179 (0.2860) ([0.180]+[0.138])	Prec@1 93.750 (94.846)
Epoch: [139][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.2612 (0.2944) ([0.123]+[0.138])	Prec@1 96.094 (94.518)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.4939 (0.4939) ([0.355]+[0.138])	Prec@1 89.844 (89.844)
 * Prec@1 89.220
current lr 1.00000e-02
Grad=  tensor(6.0752, device='cuda:0')
Epoch: [140][0/391]	Time 0.248 (0.248)	Data 0.128 (0.128)	Loss 0.2766 (0.2766) ([0.138]+[0.138])	Prec@1 94.531 (94.531)
Epoch: [140][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2691 (0.2785) ([0.131]+[0.138])	Prec@1 95.312 (95.235)
Epoch: [140][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2746 (0.2814) ([0.136]+[0.138])	Prec@1 95.312 (95.021)
Epoch: [140][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.4093 (0.2879) ([0.271]+[0.138])	Prec@1 92.188 (94.853)
Test: [0/79]	Time 0.154 (0.154)	Loss 0.3992 (0.3992) ([0.261]+[0.138])	Prec@1 92.188 (92.188)
 * Prec@1 89.970
current lr 1.00000e-02
Grad=  tensor(6.1178, device='cuda:0')
Epoch: [141][0/391]	Time 0.241 (0.241)	Data 0.120 (0.120)	Loss 0.2550 (0.2550) ([0.117]+[0.138])	Prec@1 95.312 (95.312)
Epoch: [141][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3129 (0.2786) ([0.175]+[0.138])	Prec@1 93.750 (95.220)
Epoch: [141][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3059 (0.2902) ([0.168]+[0.138])	Prec@1 92.969 (94.718)
Epoch: [141][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2536 (0.2936) ([0.115]+[0.138])	Prec@1 96.875 (94.539)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.5622 (0.5622) ([0.424]+[0.138])	Prec@1 87.500 (87.500)
 * Prec@1 89.630
current lr 1.00000e-02
Grad=  tensor(7.9827, device='cuda:0')
Epoch: [142][0/391]	Time 0.239 (0.239)	Data 0.119 (0.119)	Loss 0.2896 (0.2896) ([0.151]+[0.138])	Prec@1 95.312 (95.312)
Epoch: [142][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2893 (0.2711) ([0.151]+[0.138])	Prec@1 95.312 (95.483)
Epoch: [142][200/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.3011 (0.2830) ([0.163]+[0.138])	Prec@1 96.094 (95.013)
Epoch: [142][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2901 (0.2878) ([0.152]+[0.138])	Prec@1 95.312 (94.856)
Test: [0/79]	Time 0.153 (0.153)	Loss 0.4692 (0.4692) ([0.331]+[0.138])	Prec@1 92.188 (92.188)
 * Prec@1 89.580
current lr 1.00000e-02
Grad=  tensor(8.1632, device='cuda:0')
Epoch: [143][0/391]	Time 0.242 (0.242)	Data 0.121 (0.121)	Loss 0.2831 (0.2831) ([0.145]+[0.138])	Prec@1 93.750 (93.750)
Epoch: [143][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2914 (0.2711) ([0.153]+[0.138])	Prec@1 92.969 (95.204)
Epoch: [143][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3445 (0.2756) ([0.206]+[0.138])	Prec@1 93.750 (95.095)
Epoch: [143][300/391]	Time 0.112 (0.112)	Data 0.000 (0.000)	Loss 0.3208 (0.2801) ([0.183]+[0.138])	Prec@1 91.406 (95.024)
Test: [0/79]	Time 0.153 (0.153)	Loss 0.4702 (0.4702) ([0.332]+[0.138])	Prec@1 92.969 (92.969)
 * Prec@1 90.110
current lr 1.00000e-02
Grad=  tensor(5.1900, device='cuda:0')
Epoch: [144][0/391]	Time 0.243 (0.243)	Data 0.121 (0.121)	Loss 0.2628 (0.2628) ([0.125]+[0.138])	Prec@1 96.875 (96.875)
Epoch: [144][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3659 (0.2845) ([0.228]+[0.138])	Prec@1 90.625 (94.779)
Epoch: [144][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2664 (0.2847) ([0.128]+[0.138])	Prec@1 98.438 (94.834)
Epoch: [144][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.3811 (0.2900) ([0.243]+[0.139])	Prec@1 92.188 (94.703)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.4524 (0.4524) ([0.314]+[0.139])	Prec@1 92.188 (92.188)
 * Prec@1 90.650
current lr 1.00000e-02
Grad=  tensor(6.1546, device='cuda:0')
Epoch: [145][0/391]	Time 0.244 (0.244)	Data 0.123 (0.123)	Loss 0.3005 (0.3005) ([0.162]+[0.139])	Prec@1 96.875 (96.875)
Epoch: [145][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3153 (0.2774) ([0.177]+[0.138])	Prec@1 95.312 (95.189)
Epoch: [145][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2628 (0.2829) ([0.124]+[0.138])	Prec@1 94.531 (94.959)
Epoch: [145][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2618 (0.2890) ([0.123]+[0.139])	Prec@1 94.531 (94.734)
Test: [0/79]	Time 0.155 (0.155)	Loss 0.4661 (0.4661) ([0.327]+[0.139])	Prec@1 91.406 (91.406)
 * Prec@1 90.480
current lr 1.00000e-02
Grad=  tensor(5.4493, device='cuda:0')
Epoch: [146][0/391]	Time 0.244 (0.244)	Data 0.123 (0.123)	Loss 0.2869 (0.2869) ([0.148]+[0.139])	Prec@1 96.094 (96.094)
Epoch: [146][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2752 (0.2794) ([0.137]+[0.139])	Prec@1 95.312 (95.011)
Epoch: [146][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3664 (0.2823) ([0.228]+[0.139])	Prec@1 92.188 (94.951)
Epoch: [146][300/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.3156 (0.2860) ([0.177]+[0.139])	Prec@1 91.406 (94.843)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.5090 (0.5090) ([0.370]+[0.139])	Prec@1 91.406 (91.406)
 * Prec@1 89.960
current lr 1.00000e-02
Grad=  tensor(3.8835, device='cuda:0')
Epoch: [147][0/391]	Time 0.241 (0.241)	Data 0.121 (0.121)	Loss 0.2446 (0.2446) ([0.106]+[0.139])	Prec@1 97.656 (97.656)
Epoch: [147][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2861 (0.2760) ([0.148]+[0.139])	Prec@1 92.969 (95.166)
Epoch: [147][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2648 (0.2768) ([0.126]+[0.139])	Prec@1 96.875 (95.149)
Epoch: [147][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2124 (0.2849) ([0.074]+[0.139])	Prec@1 97.656 (94.840)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.3724 (0.3724) ([0.234]+[0.139])	Prec@1 93.750 (93.750)
 * Prec@1 89.480
current lr 1.00000e-02
Grad=  tensor(11.4545, device='cuda:0')
Epoch: [148][0/391]	Time 0.245 (0.245)	Data 0.127 (0.127)	Loss 0.2945 (0.2945) ([0.156]+[0.139])	Prec@1 92.188 (92.188)
Epoch: [148][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2522 (0.2725) ([0.114]+[0.139])	Prec@1 96.094 (95.305)
Epoch: [148][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2743 (0.2800) ([0.136]+[0.139])	Prec@1 96.094 (95.048)
Epoch: [148][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3347 (0.2833) ([0.196]+[0.139])	Prec@1 94.531 (94.923)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.5227 (0.5227) ([0.384]+[0.139])	Prec@1 88.281 (88.281)
 * Prec@1 88.640
current lr 1.00000e-02
Grad=  tensor(16.1165, device='cuda:0')
Epoch: [149][0/391]	Time 0.243 (0.243)	Data 0.124 (0.124)	Loss 0.3702 (0.3702) ([0.231]+[0.139])	Prec@1 92.969 (92.969)
Epoch: [149][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2733 (0.2817) ([0.135]+[0.139])	Prec@1 93.750 (94.895)
Epoch: [149][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2563 (0.2795) ([0.118]+[0.139])	Prec@1 96.094 (95.153)
Epoch: [149][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2731 (0.2816) ([0.134]+[0.139])	Prec@1 94.531 (95.009)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.4744 (0.4744) ([0.336]+[0.139])	Prec@1 89.062 (89.062)
 * Prec@1 90.410
current lr 1.00000e-02
Grad=  tensor(5.8369, device='cuda:0')
Epoch: [150][0/391]	Time 0.249 (0.249)	Data 0.128 (0.128)	Loss 0.2430 (0.2430) ([0.104]+[0.139])	Prec@1 96.094 (96.094)
Epoch: [150][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2601 (0.2778) ([0.121]+[0.139])	Prec@1 96.094 (95.142)
Epoch: [150][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2938 (0.2795) ([0.155]+[0.139])	Prec@1 93.750 (95.060)
Epoch: [150][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2727 (0.2809) ([0.134]+[0.139])	Prec@1 96.875 (95.009)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.4853 (0.4853) ([0.346]+[0.139])	Prec@1 88.281 (88.281)
 * Prec@1 89.220
current lr 1.00000e-02
Grad=  tensor(8.5885, device='cuda:0')
Epoch: [151][0/391]	Time 0.239 (0.239)	Data 0.119 (0.119)	Loss 0.2895 (0.2895) ([0.151]+[0.139])	Prec@1 95.312 (95.312)
Epoch: [151][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2523 (0.2823) ([0.113]+[0.139])	Prec@1 95.312 (94.949)
Epoch: [151][200/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.2660 (0.2905) ([0.127]+[0.139])	Prec@1 96.875 (94.772)
Epoch: [151][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3010 (0.2902) ([0.162]+[0.139])	Prec@1 95.312 (94.778)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.4967 (0.4967) ([0.358]+[0.139])	Prec@1 90.625 (90.625)
 * Prec@1 90.010
current lr 1.00000e-02
Grad=  tensor(8.9815, device='cuda:0')
Epoch: [152][0/391]	Time 0.246 (0.246)	Data 0.125 (0.125)	Loss 0.3275 (0.3275) ([0.188]+[0.139])	Prec@1 95.312 (95.312)
Epoch: [152][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2315 (0.2719) ([0.092]+[0.139])	Prec@1 96.094 (95.552)
Epoch: [152][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2912 (0.2868) ([0.152]+[0.139])	Prec@1 92.969 (94.967)
Epoch: [152][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3108 (0.2882) ([0.172]+[0.139])	Prec@1 93.750 (94.934)
Test: [0/79]	Time 0.159 (0.159)	Loss 0.3281 (0.3281) ([0.189]+[0.139])	Prec@1 92.969 (92.969)
 * Prec@1 89.660
current lr 1.00000e-02
Grad=  tensor(6.4491, device='cuda:0')
Epoch: [153][0/391]	Time 0.249 (0.249)	Data 0.129 (0.129)	Loss 0.2906 (0.2906) ([0.151]+[0.139])	Prec@1 94.531 (94.531)
Epoch: [153][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2282 (0.2783) ([0.089]+[0.139])	Prec@1 97.656 (95.297)
Epoch: [153][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3468 (0.2811) ([0.208]+[0.139])	Prec@1 91.406 (95.122)
Epoch: [153][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.3412 (0.2843) ([0.202]+[0.139])	Prec@1 91.406 (95.001)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.4572 (0.4572) ([0.318]+[0.139])	Prec@1 90.625 (90.625)
 * Prec@1 89.920
current lr 1.00000e-02
Grad=  tensor(4.5816, device='cuda:0')
Epoch: [154][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 0.2393 (0.2393) ([0.100]+[0.139])	Prec@1 98.438 (98.438)
Epoch: [154][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2704 (0.2778) ([0.131]+[0.139])	Prec@1 96.094 (95.243)
Epoch: [154][200/391]	Time 0.109 (0.112)	Data 0.000 (0.001)	Loss 0.2877 (0.2803) ([0.149]+[0.139])	Prec@1 93.750 (95.145)
Epoch: [154][300/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.3772 (0.2833) ([0.238]+[0.139])	Prec@1 91.406 (95.035)
Test: [0/79]	Time 0.156 (0.156)	Loss 0.4365 (0.4365) ([0.297]+[0.139])	Prec@1 89.062 (89.062)
 * Prec@1 90.360
current lr 1.00000e-02
Grad=  tensor(6.9063, device='cuda:0')
Epoch: [155][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.2952 (0.2952) ([0.156]+[0.139])	Prec@1 94.531 (94.531)
Epoch: [155][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2058 (0.2679) ([0.066]+[0.139])	Prec@1 98.438 (95.568)
Epoch: [155][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2651 (0.2732) ([0.126]+[0.139])	Prec@1 95.312 (95.297)
Epoch: [155][300/391]	Time 0.110 (0.110)	Data 0.000 (0.000)	Loss 0.4126 (0.2793) ([0.273]+[0.139])	Prec@1 88.281 (95.167)
Test: [0/79]	Time 0.153 (0.153)	Loss 0.3957 (0.3957) ([0.256]+[0.139])	Prec@1 90.625 (90.625)
 * Prec@1 90.180
current lr 1.00000e-02
Grad=  tensor(11.1494, device='cuda:0')
Epoch: [156][0/391]	Time 0.243 (0.243)	Data 0.121 (0.121)	Loss 0.3242 (0.3242) ([0.185]+[0.139])	Prec@1 91.406 (91.406)
Epoch: [156][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.4011 (0.2793) ([0.262]+[0.139])	Prec@1 92.188 (95.127)
Epoch: [156][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3106 (0.2751) ([0.171]+[0.139])	Prec@1 93.750 (95.351)
Epoch: [156][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2769 (0.2786) ([0.137]+[0.139])	Prec@1 95.312 (95.198)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.3885 (0.3885) ([0.249]+[0.139])	Prec@1 89.844 (89.844)
 * Prec@1 89.120
current lr 1.00000e-02
Grad=  tensor(6.3118, device='cuda:0')
Epoch: [157][0/391]	Time 0.247 (0.247)	Data 0.126 (0.126)	Loss 0.2608 (0.2608) ([0.121]+[0.139])	Prec@1 95.312 (95.312)
Epoch: [157][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.3149 (0.2746) ([0.176]+[0.139])	Prec@1 94.531 (95.274)
Epoch: [157][200/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2657 (0.2749) ([0.126]+[0.139])	Prec@1 94.531 (95.246)
Epoch: [157][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2297 (0.2789) ([0.090]+[0.139])	Prec@1 96.875 (95.123)
Test: [0/79]	Time 0.155 (0.155)	Loss 0.4441 (0.4441) ([0.304]+[0.140])	Prec@1 94.531 (94.531)
 * Prec@1 88.000
current lr 1.00000e-02
Grad=  tensor(5.4707, device='cuda:0')
Epoch: [158][0/391]	Time 0.244 (0.244)	Data 0.118 (0.118)	Loss 0.2785 (0.2785) ([0.139]+[0.140])	Prec@1 96.875 (96.875)
Epoch: [158][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2571 (0.2734) ([0.118]+[0.140])	Prec@1 97.656 (95.166)
Epoch: [158][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2811 (0.2774) ([0.141]+[0.140])	Prec@1 95.312 (95.083)
Epoch: [158][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2847 (0.2814) ([0.145]+[0.140])	Prec@1 95.312 (95.032)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.4669 (0.4669) ([0.327]+[0.140])	Prec@1 93.750 (93.750)
 * Prec@1 88.750
current lr 1.00000e-02
Grad=  tensor(7.8978, device='cuda:0')
Epoch: [159][0/391]	Time 0.243 (0.243)	Data 0.123 (0.123)	Loss 0.2919 (0.2919) ([0.152]+[0.140])	Prec@1 95.312 (95.312)
Epoch: [159][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2342 (0.2714) ([0.095]+[0.140])	Prec@1 96.094 (95.653)
Epoch: [159][200/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.1998 (0.2755) ([0.060]+[0.140])	Prec@1 99.219 (95.355)
Epoch: [159][300/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.2729 (0.2799) ([0.133]+[0.140])	Prec@1 92.969 (95.170)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.4989 (0.4989) ([0.359]+[0.140])	Prec@1 89.062 (89.062)
 * Prec@1 88.720
current lr 1.00000e-02
Grad=  tensor(6.3947, device='cuda:0')
Epoch: [160][0/391]	Time 0.242 (0.242)	Data 0.121 (0.121)	Loss 0.2563 (0.2563) ([0.117]+[0.140])	Prec@1 95.312 (95.312)
Epoch: [160][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1887 (0.2603) ([0.049]+[0.140])	Prec@1 99.219 (95.862)
Epoch: [160][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2836 (0.2685) ([0.144]+[0.140])	Prec@1 96.094 (95.452)
Epoch: [160][300/391]	Time 0.110 (0.110)	Data 0.000 (0.000)	Loss 0.2812 (0.2750) ([0.142]+[0.140])	Prec@1 93.750 (95.235)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.5474 (0.5474) ([0.408]+[0.140])	Prec@1 91.406 (91.406)
 * Prec@1 89.930
current lr 1.00000e-02
Grad=  tensor(8.7008, device='cuda:0')
Epoch: [161][0/391]	Time 0.249 (0.249)	Data 0.128 (0.128)	Loss 0.2792 (0.2792) ([0.140]+[0.140])	Prec@1 95.312 (95.312)
Epoch: [161][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2299 (0.2707) ([0.090]+[0.140])	Prec@1 97.656 (95.498)
Epoch: [161][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3016 (0.2733) ([0.162]+[0.140])	Prec@1 92.969 (95.367)
Epoch: [161][300/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.2834 (0.2760) ([0.144]+[0.140])	Prec@1 95.312 (95.284)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.3224 (0.3224) ([0.182]+[0.140])	Prec@1 92.188 (92.188)
 * Prec@1 90.000
current lr 1.00000e-02
Grad=  tensor(6.7850, device='cuda:0')
Epoch: [162][0/391]	Time 0.243 (0.243)	Data 0.122 (0.122)	Loss 0.2753 (0.2753) ([0.135]+[0.140])	Prec@1 95.312 (95.312)
Epoch: [162][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2983 (0.2704) ([0.158]+[0.140])	Prec@1 92.969 (95.498)
Epoch: [162][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2824 (0.2731) ([0.143]+[0.140])	Prec@1 94.531 (95.305)
Epoch: [162][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2245 (0.2774) ([0.085]+[0.140])	Prec@1 97.656 (95.203)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.5626 (0.5626) ([0.423]+[0.140])	Prec@1 90.625 (90.625)
 * Prec@1 89.670
current lr 1.00000e-02
Grad=  tensor(9.9058, device='cuda:0')
Epoch: [163][0/391]	Time 0.249 (0.249)	Data 0.127 (0.127)	Loss 0.2965 (0.2965) ([0.156]+[0.140])	Prec@1 94.531 (94.531)
Epoch: [163][100/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2308 (0.2708) ([0.091]+[0.140])	Prec@1 97.656 (95.490)
Epoch: [163][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.3282 (0.2721) ([0.188]+[0.140])	Prec@1 93.750 (95.414)
Epoch: [163][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3451 (0.2760) ([0.205]+[0.140])	Prec@1 93.750 (95.333)
Test: [0/79]	Time 0.153 (0.153)	Loss 0.4479 (0.4479) ([0.308]+[0.140])	Prec@1 92.188 (92.188)
 * Prec@1 88.600
current lr 1.00000e-02
Grad=  tensor(6.2945, device='cuda:0')
Epoch: [164][0/391]	Time 0.242 (0.242)	Data 0.121 (0.121)	Loss 0.2617 (0.2617) ([0.122]+[0.140])	Prec@1 94.531 (94.531)
Epoch: [164][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2552 (0.2703) ([0.115]+[0.140])	Prec@1 94.531 (95.382)
Epoch: [164][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2487 (0.2742) ([0.109]+[0.140])	Prec@1 96.094 (95.258)
Epoch: [164][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2820 (0.2766) ([0.142]+[0.140])	Prec@1 94.531 (95.162)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.3999 (0.3999) ([0.260]+[0.140])	Prec@1 91.406 (91.406)
 * Prec@1 90.030
current lr 1.00000e-02
Grad=  tensor(13.4881, device='cuda:0')
Epoch: [165][0/391]	Time 0.248 (0.248)	Data 0.128 (0.128)	Loss 0.2936 (0.2936) ([0.154]+[0.140])	Prec@1 96.094 (96.094)
Epoch: [165][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2400 (0.2655) ([0.100]+[0.140])	Prec@1 96.094 (95.769)
Epoch: [165][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3361 (0.2688) ([0.196]+[0.140])	Prec@1 93.750 (95.561)
Epoch: [165][300/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.3398 (0.2735) ([0.200]+[0.140])	Prec@1 92.969 (95.310)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4629 (0.4629) ([0.323]+[0.140])	Prec@1 92.188 (92.188)
 * Prec@1 89.920
current lr 1.00000e-02
Grad=  tensor(4.9090, device='cuda:0')
Epoch: [166][0/391]	Time 0.249 (0.249)	Data 0.127 (0.127)	Loss 0.2271 (0.2271) ([0.087]+[0.140])	Prec@1 97.656 (97.656)
Epoch: [166][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2807 (0.2658) ([0.141]+[0.140])	Prec@1 94.531 (95.722)
Epoch: [166][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3022 (0.2772) ([0.162]+[0.140])	Prec@1 93.750 (95.204)
Epoch: [166][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3662 (0.2799) ([0.226]+[0.140])	Prec@1 91.406 (95.126)
Test: [0/79]	Time 0.158 (0.158)	Loss 0.4292 (0.4292) ([0.289]+[0.140])	Prec@1 91.406 (91.406)
 * Prec@1 89.490
current lr 1.00000e-02
Grad=  tensor(7.4519, device='cuda:0')
Epoch: [167][0/391]	Time 0.245 (0.245)	Data 0.123 (0.123)	Loss 0.2659 (0.2659) ([0.126]+[0.140])	Prec@1 96.094 (96.094)
Epoch: [167][100/391]	Time 0.112 (0.113)	Data 0.000 (0.001)	Loss 0.2777 (0.2757) ([0.138]+[0.140])	Prec@1 96.094 (95.382)
Epoch: [167][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2623 (0.2806) ([0.122]+[0.140])	Prec@1 94.531 (95.083)
Epoch: [167][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 0.2481 (0.2802) ([0.108]+[0.140])	Prec@1 96.094 (95.048)
Test: [0/79]	Time 0.155 (0.155)	Loss 0.5306 (0.5306) ([0.390]+[0.140])	Prec@1 89.844 (89.844)
 * Prec@1 88.540
current lr 1.00000e-02
Grad=  tensor(6.3509, device='cuda:0')
Epoch: [168][0/391]	Time 0.242 (0.242)	Data 0.121 (0.121)	Loss 0.2545 (0.2545) ([0.114]+[0.140])	Prec@1 96.094 (96.094)
Epoch: [168][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.2279 (0.2695) ([0.087]+[0.140])	Prec@1 98.438 (95.575)
Epoch: [168][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2714 (0.2682) ([0.131]+[0.140])	Prec@1 92.969 (95.557)
Epoch: [168][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3218 (0.2735) ([0.181]+[0.140])	Prec@1 93.750 (95.424)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.5005 (0.5005) ([0.360]+[0.140])	Prec@1 86.719 (86.719)
 * Prec@1 90.070
current lr 1.00000e-02
Grad=  tensor(8.1513, device='cuda:0')
Epoch: [169][0/391]	Time 0.240 (0.240)	Data 0.120 (0.120)	Loss 0.2699 (0.2699) ([0.129]+[0.140])	Prec@1 95.312 (95.312)
Epoch: [169][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2605 (0.2736) ([0.120]+[0.140])	Prec@1 96.094 (95.459)
Epoch: [169][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3390 (0.2722) ([0.199]+[0.140])	Prec@1 95.312 (95.507)
Epoch: [169][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2054 (0.2765) ([0.065]+[0.140])	Prec@1 97.656 (95.292)
Test: [0/79]	Time 0.155 (0.155)	Loss 0.4237 (0.4237) ([0.283]+[0.140])	Prec@1 90.625 (90.625)
 * Prec@1 88.730
current lr 1.00000e-02
Grad=  tensor(9.8462, device='cuda:0')
Epoch: [170][0/391]	Time 0.239 (0.239)	Data 0.117 (0.117)	Loss 0.2841 (0.2841) ([0.144]+[0.140])	Prec@1 93.750 (93.750)
Epoch: [170][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3053 (0.2606) ([0.165]+[0.140])	Prec@1 94.531 (95.784)
Epoch: [170][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3062 (0.2688) ([0.166]+[0.140])	Prec@1 94.531 (95.581)
Epoch: [170][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.3028 (0.2728) ([0.162]+[0.140])	Prec@1 92.969 (95.406)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.3797 (0.3797) ([0.239]+[0.141])	Prec@1 92.969 (92.969)
 * Prec@1 89.920
current lr 1.00000e-02
Grad=  tensor(6.2547, device='cuda:0')
Epoch: [171][0/391]	Time 0.248 (0.248)	Data 0.126 (0.126)	Loss 0.2620 (0.2620) ([0.121]+[0.141])	Prec@1 96.094 (96.094)
Epoch: [171][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2349 (0.2674) ([0.094]+[0.141])	Prec@1 97.656 (95.475)
Epoch: [171][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2455 (0.2754) ([0.105]+[0.141])	Prec@1 96.094 (95.278)
Epoch: [171][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2500 (0.2831) ([0.109]+[0.141])	Prec@1 95.312 (94.993)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.4680 (0.4680) ([0.327]+[0.141])	Prec@1 89.062 (89.062)
 * Prec@1 88.430
current lr 1.00000e-02
Grad=  tensor(10.9839, device='cuda:0')
Epoch: [172][0/391]	Time 0.251 (0.251)	Data 0.129 (0.129)	Loss 0.3079 (0.3079) ([0.167]+[0.141])	Prec@1 93.750 (93.750)
Epoch: [172][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2544 (0.2702) ([0.113]+[0.141])	Prec@1 95.312 (95.405)
Epoch: [172][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2084 (0.2740) ([0.068]+[0.141])	Prec@1 98.438 (95.328)
Epoch: [172][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3923 (0.2799) ([0.251]+[0.141])	Prec@1 92.969 (95.069)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.5334 (0.5334) ([0.392]+[0.141])	Prec@1 90.625 (90.625)
 * Prec@1 89.790
current lr 1.00000e-02
Grad=  tensor(6.0202, device='cuda:0')
Epoch: [173][0/391]	Time 0.240 (0.240)	Data 0.121 (0.121)	Loss 0.2378 (0.2378) ([0.097]+[0.141])	Prec@1 97.656 (97.656)
Epoch: [173][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.3112 (0.2524) ([0.171]+[0.141])	Prec@1 92.188 (96.357)
Epoch: [173][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2952 (0.2681) ([0.154]+[0.141])	Prec@1 93.750 (95.740)
Epoch: [173][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3293 (0.2763) ([0.188]+[0.141])	Prec@1 93.750 (95.416)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3966 (0.3966) ([0.255]+[0.141])	Prec@1 92.188 (92.188)
 * Prec@1 87.990
current lr 1.00000e-02
Grad=  tensor(13.2868, device='cuda:0')
Epoch: [174][0/391]	Time 0.239 (0.239)	Data 0.120 (0.120)	Loss 0.3556 (0.3556) ([0.214]+[0.141])	Prec@1 92.188 (92.188)
Epoch: [174][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2852 (0.2757) ([0.144]+[0.141])	Prec@1 95.312 (95.212)
Epoch: [174][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2339 (0.2719) ([0.093]+[0.141])	Prec@1 98.438 (95.460)
Epoch: [174][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2466 (0.2733) ([0.106]+[0.141])	Prec@1 96.875 (95.364)
Test: [0/79]	Time 0.153 (0.153)	Loss 0.5383 (0.5383) ([0.397]+[0.141])	Prec@1 88.281 (88.281)
 * Prec@1 90.660
current lr 1.00000e-02
Grad=  tensor(10.7992, device='cuda:0')
Epoch: [175][0/391]	Time 0.238 (0.238)	Data 0.118 (0.118)	Loss 0.3041 (0.3041) ([0.163]+[0.141])	Prec@1 93.750 (93.750)
Epoch: [175][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2224 (0.2665) ([0.081]+[0.141])	Prec@1 96.875 (95.537)
Epoch: [175][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3020 (0.2720) ([0.161]+[0.141])	Prec@1 95.312 (95.367)
Epoch: [175][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.2742 (0.2780) ([0.133]+[0.141])	Prec@1 96.094 (95.139)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.3549 (0.3549) ([0.214]+[0.141])	Prec@1 91.406 (91.406)
 * Prec@1 90.320
current lr 1.00000e-02
Grad=  tensor(8.2857, device='cuda:0')
Epoch: [176][0/391]	Time 0.256 (0.256)	Data 0.134 (0.134)	Loss 0.2800 (0.2800) ([0.139]+[0.141])	Prec@1 94.531 (94.531)
Epoch: [176][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3146 (0.2720) ([0.173]+[0.141])	Prec@1 95.312 (95.459)
Epoch: [176][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1974 (0.2733) ([0.056]+[0.141])	Prec@1 97.656 (95.367)
Epoch: [176][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3041 (0.2784) ([0.163]+[0.141])	Prec@1 92.969 (95.211)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.4751 (0.4751) ([0.334]+[0.141])	Prec@1 92.188 (92.188)
 * Prec@1 89.480
current lr 1.00000e-02
Grad=  tensor(4.4363, device='cuda:0')
Epoch: [177][0/391]	Time 0.250 (0.250)	Data 0.128 (0.128)	Loss 0.2547 (0.2547) ([0.113]+[0.141])	Prec@1 96.094 (96.094)
Epoch: [177][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.2714 (0.2643) ([0.130]+[0.141])	Prec@1 94.531 (95.692)
Epoch: [177][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2843 (0.2670) ([0.143]+[0.141])	Prec@1 94.531 (95.620)
Epoch: [177][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2933 (0.2738) ([0.152]+[0.141])	Prec@1 96.094 (95.375)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.4021 (0.4021) ([0.261]+[0.141])	Prec@1 92.188 (92.188)
 * Prec@1 90.490
current lr 1.00000e-02
Grad=  tensor(7.0734, device='cuda:0')
Epoch: [178][0/391]	Time 0.249 (0.249)	Data 0.127 (0.127)	Loss 0.2903 (0.2903) ([0.149]+[0.141])	Prec@1 96.875 (96.875)
Epoch: [178][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2182 (0.2576) ([0.077]+[0.141])	Prec@1 97.656 (96.210)
Epoch: [178][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2837 (0.2586) ([0.143]+[0.141])	Prec@1 96.094 (96.055)
Epoch: [178][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.4287 (0.2665) ([0.287]+[0.141])	Prec@1 89.062 (95.808)
Test: [0/79]	Time 0.153 (0.153)	Loss 0.4720 (0.4720) ([0.331]+[0.141])	Prec@1 89.844 (89.844)
 * Prec@1 88.270
current lr 1.00000e-02
Grad=  tensor(11.9246, device='cuda:0')
Epoch: [179][0/391]	Time 0.243 (0.243)	Data 0.122 (0.122)	Loss 0.3077 (0.3077) ([0.166]+[0.141])	Prec@1 92.188 (92.188)
Epoch: [179][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2672 (0.2669) ([0.126]+[0.141])	Prec@1 95.312 (95.560)
Epoch: [179][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2753 (0.2739) ([0.134]+[0.141])	Prec@1 94.531 (95.328)
Epoch: [179][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2370 (0.2728) ([0.096]+[0.141])	Prec@1 98.438 (95.385)
Test: [0/79]	Time 0.155 (0.155)	Loss 0.4394 (0.4394) ([0.298]+[0.141])	Prec@1 92.969 (92.969)
 * Prec@1 89.780
current lr 1.00000e-02
Grad=  tensor(7.8500, device='cuda:0')
Epoch: [180][0/391]	Time 0.244 (0.244)	Data 0.122 (0.122)	Loss 0.2643 (0.2643) ([0.123]+[0.141])	Prec@1 95.312 (95.312)
Epoch: [180][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3890 (0.2669) ([0.248]+[0.141])	Prec@1 91.406 (95.869)
Epoch: [180][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2637 (0.2717) ([0.122]+[0.141])	Prec@1 96.094 (95.573)
Epoch: [180][300/391]	Time 0.113 (0.111)	Data 0.000 (0.001)	Loss 0.2926 (0.2765) ([0.151]+[0.141])	Prec@1 95.312 (95.349)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.5035 (0.5035) ([0.362]+[0.142])	Prec@1 89.844 (89.844)
 * Prec@1 89.250
current lr 1.00000e-02
Grad=  tensor(6.6107, device='cuda:0')
Epoch: [181][0/391]	Time 0.243 (0.243)	Data 0.122 (0.122)	Loss 0.3121 (0.3121) ([0.171]+[0.142])	Prec@1 96.094 (96.094)
Epoch: [181][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3371 (0.2665) ([0.196]+[0.141])	Prec@1 92.188 (95.730)
Epoch: [181][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2369 (0.2646) ([0.096]+[0.141])	Prec@1 97.656 (95.728)
Epoch: [181][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3455 (0.2666) ([0.204]+[0.141])	Prec@1 93.750 (95.694)
Test: [0/79]	Time 0.156 (0.156)	Loss 0.4779 (0.4779) ([0.336]+[0.141])	Prec@1 89.062 (89.062)
 * Prec@1 88.340
current lr 1.00000e-02
Grad=  tensor(5.8593, device='cuda:0')
Epoch: [182][0/391]	Time 0.243 (0.243)	Data 0.121 (0.121)	Loss 0.2631 (0.2631) ([0.122]+[0.141])	Prec@1 95.312 (95.312)
Epoch: [182][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2852 (0.2703) ([0.144]+[0.141])	Prec@1 95.312 (95.738)
Epoch: [182][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2010 (0.2655) ([0.060]+[0.141])	Prec@1 98.438 (95.818)
Epoch: [182][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.2993 (0.2698) ([0.158]+[0.142])	Prec@1 93.750 (95.611)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.4765 (0.4765) ([0.335]+[0.142])	Prec@1 92.969 (92.969)
 * Prec@1 90.310
current lr 1.00000e-02
Grad=  tensor(6.8030, device='cuda:0')
Epoch: [183][0/391]	Time 0.243 (0.243)	Data 0.122 (0.122)	Loss 0.2361 (0.2361) ([0.094]+[0.142])	Prec@1 97.656 (97.656)
Epoch: [183][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1914 (0.2699) ([0.050]+[0.142])	Prec@1 99.219 (95.568)
Epoch: [183][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3503 (0.2710) ([0.209]+[0.142])	Prec@1 91.406 (95.414)
Epoch: [183][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2461 (0.2720) ([0.104]+[0.142])	Prec@1 96.094 (95.393)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.5396 (0.5396) ([0.398]+[0.142])	Prec@1 88.281 (88.281)
 * Prec@1 89.060
current lr 1.00000e-02
Grad=  tensor(7.4902, device='cuda:0')
Epoch: [184][0/391]	Time 0.249 (0.249)	Data 0.128 (0.128)	Loss 0.2689 (0.2689) ([0.127]+[0.142])	Prec@1 95.312 (95.312)
Epoch: [184][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2761 (0.2695) ([0.134]+[0.142])	Prec@1 95.312 (95.637)
Epoch: [184][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2663 (0.2691) ([0.125]+[0.142])	Prec@1 93.750 (95.651)
Epoch: [184][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3267 (0.2726) ([0.185]+[0.142])	Prec@1 94.531 (95.536)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.5951 (0.5951) ([0.453]+[0.142])	Prec@1 86.719 (86.719)
 * Prec@1 88.750
current lr 1.00000e-02
Grad=  tensor(10.1420, device='cuda:0')
Epoch: [185][0/391]	Time 0.249 (0.249)	Data 0.128 (0.128)	Loss 0.2939 (0.2939) ([0.152]+[0.142])	Prec@1 93.750 (93.750)
Epoch: [185][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2599 (0.2682) ([0.118]+[0.142])	Prec@1 94.531 (95.599)
Epoch: [185][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2718 (0.2719) ([0.130]+[0.142])	Prec@1 95.312 (95.452)
Epoch: [185][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2721 (0.2767) ([0.130]+[0.142])	Prec@1 94.531 (95.302)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.6172 (0.6172) ([0.475]+[0.142])	Prec@1 88.281 (88.281)
 * Prec@1 88.960
current lr 1.00000e-02
Grad=  tensor(6.4162, device='cuda:0')
Epoch: [186][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.2665 (0.2665) ([0.124]+[0.142])	Prec@1 94.531 (94.531)
Epoch: [186][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2972 (0.2647) ([0.155]+[0.142])	Prec@1 96.094 (95.599)
Epoch: [186][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2757 (0.2661) ([0.134]+[0.142])	Prec@1 94.531 (95.569)
Epoch: [186][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.3235 (0.2678) ([0.182]+[0.142])	Prec@1 96.875 (95.551)
Test: [0/79]	Time 0.146 (0.146)	Loss 0.4789 (0.4789) ([0.337]+[0.142])	Prec@1 88.281 (88.281)
 * Prec@1 89.100
current lr 1.00000e-02
Grad=  tensor(11.8003, device='cuda:0')
Epoch: [187][0/391]	Time 0.241 (0.241)	Data 0.122 (0.122)	Loss 0.2809 (0.2809) ([0.139]+[0.142])	Prec@1 95.312 (95.312)
Epoch: [187][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2567 (0.2628) ([0.115]+[0.142])	Prec@1 96.094 (95.885)
Epoch: [187][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.3365 (0.2708) ([0.195]+[0.142])	Prec@1 92.188 (95.588)
Epoch: [187][300/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.3256 (0.2720) ([0.184]+[0.142])	Prec@1 95.312 (95.544)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.5001 (0.5001) ([0.358]+[0.142])	Prec@1 89.062 (89.062)
 * Prec@1 89.470
current lr 1.00000e-02
Grad=  tensor(3.3350, device='cuda:0')
Epoch: [188][0/391]	Time 0.246 (0.246)	Data 0.125 (0.125)	Loss 0.2033 (0.2033) ([0.062]+[0.142])	Prec@1 98.438 (98.438)
Epoch: [188][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2385 (0.2582) ([0.097]+[0.142])	Prec@1 97.656 (96.148)
Epoch: [188][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2302 (0.2615) ([0.089]+[0.141])	Prec@1 98.438 (96.020)
Epoch: [188][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1944 (0.2644) ([0.053]+[0.142])	Prec@1 99.219 (95.785)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.4053 (0.4053) ([0.264]+[0.142])	Prec@1 89.844 (89.844)
 * Prec@1 89.130
current lr 1.00000e-02
Grad=  tensor(4.0517, device='cuda:0')
Epoch: [189][0/391]	Time 0.241 (0.241)	Data 0.120 (0.120)	Loss 0.2441 (0.2441) ([0.103]+[0.142])	Prec@1 98.438 (98.438)
Epoch: [189][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2750 (0.2675) ([0.133]+[0.142])	Prec@1 94.531 (95.738)
Epoch: [189][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2223 (0.2795) ([0.081]+[0.142])	Prec@1 96.875 (95.266)
Epoch: [189][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2653 (0.2790) ([0.124]+[0.142])	Prec@1 96.094 (95.229)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.4421 (0.4421) ([0.300]+[0.142])	Prec@1 92.188 (92.188)
 * Prec@1 89.350
current lr 1.00000e-02
Grad=  tensor(11.8171, device='cuda:0')
Epoch: [190][0/391]	Time 0.235 (0.235)	Data 0.114 (0.114)	Loss 0.3311 (0.3311) ([0.189]+[0.142])	Prec@1 95.312 (95.312)
Epoch: [190][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.3132 (0.2640) ([0.172]+[0.142])	Prec@1 92.969 (95.753)
Epoch: [190][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2211 (0.2638) ([0.080]+[0.142])	Prec@1 96.875 (95.763)
Epoch: [190][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2511 (0.2673) ([0.110]+[0.142])	Prec@1 98.438 (95.663)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.3948 (0.3948) ([0.253]+[0.142])	Prec@1 92.188 (92.188)
 * Prec@1 89.290
current lr 1.00000e-02
Grad=  tensor(6.9546, device='cuda:0')
Epoch: [191][0/391]	Time 0.241 (0.241)	Data 0.119 (0.119)	Loss 0.2676 (0.2676) ([0.126]+[0.142])	Prec@1 93.750 (93.750)
Epoch: [191][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2759 (0.2591) ([0.134]+[0.142])	Prec@1 96.094 (96.016)
Epoch: [191][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3007 (0.2631) ([0.159]+[0.142])	Prec@1 94.531 (95.814)
Epoch: [191][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2473 (0.2673) ([0.106]+[0.142])	Prec@1 97.656 (95.684)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.4713 (0.4713) ([0.330]+[0.142])	Prec@1 89.062 (89.062)
 * Prec@1 88.220
current lr 1.00000e-02
Grad=  tensor(3.5295, device='cuda:0')
Epoch: [192][0/391]	Time 0.249 (0.249)	Data 0.127 (0.127)	Loss 0.1960 (0.1960) ([0.054]+[0.142])	Prec@1 98.438 (98.438)
Epoch: [192][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2591 (0.2612) ([0.118]+[0.142])	Prec@1 93.750 (95.893)
Epoch: [192][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3287 (0.2624) ([0.187]+[0.141])	Prec@1 92.188 (95.841)
Epoch: [192][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2405 (0.2660) ([0.099]+[0.142])	Prec@1 96.094 (95.665)
Test: [0/79]	Time 0.155 (0.155)	Loss 0.3343 (0.3343) ([0.193]+[0.142])	Prec@1 93.750 (93.750)
 * Prec@1 89.360
current lr 1.00000e-02
Grad=  tensor(3.7234, device='cuda:0')
Epoch: [193][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.2031 (0.2031) ([0.061]+[0.142])	Prec@1 98.438 (98.438)
Epoch: [193][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2417 (0.2715) ([0.100]+[0.142])	Prec@1 96.875 (95.568)
Epoch: [193][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3187 (0.2712) ([0.177]+[0.142])	Prec@1 93.750 (95.643)
Epoch: [193][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2470 (0.2718) ([0.105]+[0.142])	Prec@1 96.875 (95.619)
Test: [0/79]	Time 0.155 (0.155)	Loss 0.4672 (0.4672) ([0.326]+[0.142])	Prec@1 92.188 (92.188)
 * Prec@1 88.270
current lr 1.00000e-02
Grad=  tensor(9.0839, device='cuda:0')
Epoch: [194][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.2606 (0.2606) ([0.119]+[0.142])	Prec@1 95.312 (95.312)
Epoch: [194][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2469 (0.2595) ([0.105]+[0.142])	Prec@1 96.094 (95.831)
Epoch: [194][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2499 (0.2615) ([0.108]+[0.142])	Prec@1 96.094 (95.806)
Epoch: [194][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2569 (0.2672) ([0.115]+[0.142])	Prec@1 96.094 (95.629)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4099 (0.4099) ([0.268]+[0.142])	Prec@1 93.750 (93.750)
 * Prec@1 90.790
current lr 1.00000e-02
Grad=  tensor(4.8187, device='cuda:0')
Epoch: [195][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.2082 (0.2082) ([0.066]+[0.142])	Prec@1 98.438 (98.438)
Epoch: [195][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2331 (0.2529) ([0.091]+[0.142])	Prec@1 97.656 (96.163)
Epoch: [195][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2101 (0.2587) ([0.068]+[0.142])	Prec@1 97.656 (95.958)
Epoch: [195][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2794 (0.2654) ([0.138]+[0.142])	Prec@1 96.094 (95.723)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.5168 (0.5168) ([0.375]+[0.142])	Prec@1 90.625 (90.625)
 * Prec@1 89.380
current lr 1.00000e-02
Grad=  tensor(9.0726, device='cuda:0')
Epoch: [196][0/391]	Time 0.235 (0.235)	Data 0.114 (0.114)	Loss 0.2791 (0.2791) ([0.137]+[0.142])	Prec@1 94.531 (94.531)
Epoch: [196][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3098 (0.2615) ([0.168]+[0.142])	Prec@1 94.531 (96.001)
Epoch: [196][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3082 (0.2613) ([0.167]+[0.142])	Prec@1 93.750 (96.000)
Epoch: [196][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.3184 (0.2643) ([0.177]+[0.142])	Prec@1 94.531 (95.798)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.5507 (0.5507) ([0.409]+[0.142])	Prec@1 89.062 (89.062)
 * Prec@1 88.970
current lr 1.00000e-02
Grad=  tensor(3.7529, device='cuda:0')
Epoch: [197][0/391]	Time 0.242 (0.242)	Data 0.121 (0.121)	Loss 0.2232 (0.2232) ([0.082]+[0.142])	Prec@1 96.875 (96.875)
Epoch: [197][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2341 (0.2590) ([0.092]+[0.142])	Prec@1 96.875 (95.885)
Epoch: [197][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2219 (0.2627) ([0.080]+[0.142])	Prec@1 97.656 (95.833)
Epoch: [197][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2815 (0.2662) ([0.140]+[0.142])	Prec@1 95.312 (95.741)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.4804 (0.4804) ([0.339]+[0.142])	Prec@1 86.719 (86.719)
 * Prec@1 88.530
current lr 1.00000e-02
Grad=  tensor(6.4260, device='cuda:0')
Epoch: [198][0/391]	Time 0.247 (0.247)	Data 0.126 (0.126)	Loss 0.2430 (0.2430) ([0.101]+[0.142])	Prec@1 96.094 (96.094)
Epoch: [198][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2502 (0.2716) ([0.108]+[0.142])	Prec@1 96.875 (95.444)
Epoch: [198][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3136 (0.2766) ([0.172]+[0.142])	Prec@1 95.312 (95.316)
Epoch: [198][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2542 (0.2741) ([0.112]+[0.142])	Prec@1 96.875 (95.393)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.4835 (0.4835) ([0.342]+[0.142])	Prec@1 89.062 (89.062)
 * Prec@1 87.650
current lr 1.00000e-02
Grad=  tensor(12.4550, device='cuda:0')
Epoch: [199][0/391]	Time 0.242 (0.242)	Data 0.121 (0.121)	Loss 0.3052 (0.3052) ([0.163]+[0.142])	Prec@1 93.750 (93.750)
Epoch: [199][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1942 (0.2511) ([0.052]+[0.142])	Prec@1 98.438 (96.380)
Epoch: [199][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.2401 (0.2594) ([0.098]+[0.142])	Prec@1 96.094 (96.035)
Epoch: [199][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2432 (0.2650) ([0.101]+[0.142])	Prec@1 96.875 (95.775)
Test: [0/79]	Time 0.145 (0.145)	Loss 0.4047 (0.4047) ([0.263]+[0.142])	Prec@1 91.406 (91.406)
 * Prec@1 90.190
current lr 1.00000e-02
Grad=  tensor(3.5778, device='cuda:0')
Epoch: [200][0/391]	Time 0.241 (0.241)	Data 0.121 (0.121)	Loss 0.1972 (0.1972) ([0.055]+[0.142])	Prec@1 97.656 (97.656)
Epoch: [200][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.3095 (0.2573) ([0.168]+[0.142])	Prec@1 93.750 (95.931)
Epoch: [200][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3406 (0.2614) ([0.199]+[0.142])	Prec@1 96.094 (95.794)
Epoch: [200][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2601 (0.2699) ([0.118]+[0.142])	Prec@1 95.312 (95.515)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4166 (0.4166) ([0.274]+[0.142])	Prec@1 89.062 (89.062)
 * Prec@1 89.970
current lr 1.00000e-02
Grad=  tensor(6.3808, device='cuda:0')
Epoch: [201][0/391]	Time 0.239 (0.239)	Data 0.119 (0.119)	Loss 0.2534 (0.2534) ([0.111]+[0.142])	Prec@1 97.656 (97.656)
Epoch: [201][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2295 (0.2654) ([0.087]+[0.142])	Prec@1 97.656 (95.815)
Epoch: [201][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2384 (0.2635) ([0.096]+[0.142])	Prec@1 96.875 (95.861)
Epoch: [201][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.2684 (0.2640) ([0.126]+[0.142])	Prec@1 95.312 (95.829)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3767 (0.3767) ([0.235]+[0.142])	Prec@1 91.406 (91.406)
 * Prec@1 90.300
current lr 1.00000e-02
Grad=  tensor(13.7758, device='cuda:0')
Epoch: [202][0/391]	Time 0.242 (0.242)	Data 0.121 (0.121)	Loss 0.2820 (0.2820) ([0.140]+[0.142])	Prec@1 93.750 (93.750)
Epoch: [202][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3843 (0.2679) ([0.242]+[0.142])	Prec@1 91.406 (95.606)
Epoch: [202][200/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.3226 (0.2640) ([0.181]+[0.142])	Prec@1 93.750 (95.728)
Epoch: [202][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2692 (0.2667) ([0.127]+[0.142])	Prec@1 95.312 (95.629)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.5301 (0.5301) ([0.388]+[0.142])	Prec@1 91.406 (91.406)
 * Prec@1 90.150
current lr 1.00000e-02
Grad=  tensor(8.1908, device='cuda:0')
Epoch: [203][0/391]	Time 0.250 (0.250)	Data 0.130 (0.130)	Loss 0.2490 (0.2490) ([0.107]+[0.142])	Prec@1 95.312 (95.312)
Epoch: [203][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2004 (0.2477) ([0.058]+[0.142])	Prec@1 98.438 (96.349)
Epoch: [203][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2801 (0.2542) ([0.138]+[0.142])	Prec@1 94.531 (96.121)
Epoch: [203][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2839 (0.2599) ([0.142]+[0.142])	Prec@1 96.875 (95.871)
Test: [0/79]	Time 0.154 (0.154)	Loss 0.4109 (0.4109) ([0.269]+[0.142])	Prec@1 91.406 (91.406)
 * Prec@1 89.990
current lr 1.00000e-02
Grad=  tensor(7.0769, device='cuda:0')
Epoch: [204][0/391]	Time 0.239 (0.239)	Data 0.119 (0.119)	Loss 0.2601 (0.2601) ([0.118]+[0.142])	Prec@1 96.094 (96.094)
Epoch: [204][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2641 (0.2543) ([0.122]+[0.142])	Prec@1 96.094 (96.310)
Epoch: [204][200/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2861 (0.2618) ([0.144]+[0.142])	Prec@1 95.312 (95.985)
Epoch: [204][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2730 (0.2649) ([0.131]+[0.142])	Prec@1 95.312 (95.943)
Test: [0/79]	Time 0.146 (0.146)	Loss 0.4494 (0.4494) ([0.307]+[0.142])	Prec@1 92.969 (92.969)
 * Prec@1 88.430
current lr 1.00000e-02
Grad=  tensor(7.1549, device='cuda:0')
Epoch: [205][0/391]	Time 0.239 (0.239)	Data 0.119 (0.119)	Loss 0.2571 (0.2571) ([0.115]+[0.142])	Prec@1 94.531 (94.531)
Epoch: [205][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2538 (0.2577) ([0.112]+[0.142])	Prec@1 93.750 (95.955)
Epoch: [205][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2423 (0.2551) ([0.100]+[0.142])	Prec@1 96.875 (96.105)
Epoch: [205][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.3104 (0.2627) ([0.168]+[0.142])	Prec@1 92.969 (95.793)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.6102 (0.6102) ([0.468]+[0.142])	Prec@1 85.156 (85.156)
 * Prec@1 86.450
current lr 1.00000e-02
Grad=  tensor(7.4654, device='cuda:0')
Epoch: [206][0/391]	Time 0.241 (0.241)	Data 0.121 (0.121)	Loss 0.2775 (0.2775) ([0.135]+[0.142])	Prec@1 96.094 (96.094)
Epoch: [206][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2369 (0.2630) ([0.095]+[0.142])	Prec@1 96.875 (96.071)
Epoch: [206][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2379 (0.2602) ([0.096]+[0.142])	Prec@1 96.875 (96.070)
Epoch: [206][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3074 (0.2630) ([0.165]+[0.142])	Prec@1 92.188 (95.938)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4342 (0.4342) ([0.292]+[0.142])	Prec@1 89.062 (89.062)
 * Prec@1 88.330
current lr 1.00000e-02
Grad=  tensor(5.2023, device='cuda:0')
Epoch: [207][0/391]	Time 0.241 (0.241)	Data 0.121 (0.121)	Loss 0.2037 (0.2037) ([0.061]+[0.142])	Prec@1 99.219 (99.219)
Epoch: [207][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2632 (0.2533) ([0.121]+[0.142])	Prec@1 94.531 (96.063)
Epoch: [207][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3322 (0.2623) ([0.190]+[0.142])	Prec@1 92.969 (95.868)
Epoch: [207][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2929 (0.2672) ([0.150]+[0.142])	Prec@1 94.531 (95.723)
Test: [0/79]	Time 0.157 (0.157)	Loss 0.4884 (0.4884) ([0.346]+[0.143])	Prec@1 89.844 (89.844)
 * Prec@1 89.000
current lr 1.00000e-02
Grad=  tensor(17.7072, device='cuda:0')
Epoch: [208][0/391]	Time 0.242 (0.242)	Data 0.120 (0.120)	Loss 0.4041 (0.4041) ([0.262]+[0.143])	Prec@1 92.188 (92.188)
Epoch: [208][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2801 (0.2594) ([0.138]+[0.142])	Prec@1 93.750 (95.869)
Epoch: [208][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2547 (0.2649) ([0.112]+[0.142])	Prec@1 94.531 (95.697)
Epoch: [208][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3005 (0.2638) ([0.158]+[0.142])	Prec@1 94.531 (95.746)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4225 (0.4225) ([0.280]+[0.143])	Prec@1 91.406 (91.406)
 * Prec@1 89.150
current lr 1.00000e-02
Grad=  tensor(9.0655, device='cuda:0')
Epoch: [209][0/391]	Time 0.242 (0.242)	Data 0.120 (0.120)	Loss 0.2424 (0.2424) ([0.100]+[0.143])	Prec@1 96.875 (96.875)
Epoch: [209][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3412 (0.2617) ([0.199]+[0.142])	Prec@1 92.969 (96.055)
Epoch: [209][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2599 (0.2665) ([0.117]+[0.143])	Prec@1 96.094 (95.728)
Epoch: [209][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1872 (0.2676) ([0.045]+[0.143])	Prec@1 100.000 (95.676)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.6324 (0.6324) ([0.490]+[0.143])	Prec@1 86.719 (86.719)
 * Prec@1 87.200
current lr 1.00000e-02
Grad=  tensor(9.9817, device='cuda:0')
Epoch: [210][0/391]	Time 0.244 (0.244)	Data 0.122 (0.122)	Loss 0.2841 (0.2841) ([0.141]+[0.143])	Prec@1 94.531 (94.531)
Epoch: [210][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2887 (0.2624) ([0.146]+[0.143])	Prec@1 94.531 (95.862)
Epoch: [210][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2552 (0.2602) ([0.113]+[0.143])	Prec@1 97.656 (96.035)
Epoch: [210][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3119 (0.2644) ([0.169]+[0.143])	Prec@1 95.312 (95.829)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.5260 (0.5260) ([0.383]+[0.143])	Prec@1 91.406 (91.406)
 * Prec@1 89.460
current lr 1.00000e-02
Grad=  tensor(6.6162, device='cuda:0')
Epoch: [211][0/391]	Time 0.242 (0.242)	Data 0.120 (0.120)	Loss 0.2405 (0.2405) ([0.098]+[0.143])	Prec@1 96.094 (96.094)
Epoch: [211][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2565 (0.2565) ([0.114]+[0.143])	Prec@1 96.875 (96.225)
Epoch: [211][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2453 (0.2605) ([0.103]+[0.143])	Prec@1 97.656 (96.082)
Epoch: [211][300/391]	Time 0.112 (0.111)	Data 0.000 (0.000)	Loss 0.2325 (0.2661) ([0.090]+[0.143])	Prec@1 96.094 (95.762)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.5363 (0.5363) ([0.394]+[0.143])	Prec@1 89.844 (89.844)
 * Prec@1 89.400
current lr 1.00000e-02
Grad=  tensor(7.7692, device='cuda:0')
Epoch: [212][0/391]	Time 0.241 (0.241)	Data 0.119 (0.119)	Loss 0.2428 (0.2428) ([0.100]+[0.143])	Prec@1 97.656 (97.656)
Epoch: [212][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2687 (0.2675) ([0.126]+[0.143])	Prec@1 96.094 (95.630)
Epoch: [212][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2662 (0.2596) ([0.123]+[0.143])	Prec@1 96.875 (95.923)
Epoch: [212][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3225 (0.2632) ([0.180]+[0.143])	Prec@1 93.750 (95.858)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.5116 (0.5116) ([0.369]+[0.143])	Prec@1 92.188 (92.188)
 * Prec@1 89.720
current lr 1.00000e-02
Grad=  tensor(7.8830, device='cuda:0')
Epoch: [213][0/391]	Time 0.247 (0.247)	Data 0.127 (0.127)	Loss 0.2331 (0.2331) ([0.090]+[0.143])	Prec@1 97.656 (97.656)
Epoch: [213][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2433 (0.2574) ([0.101]+[0.143])	Prec@1 96.875 (95.831)
Epoch: [213][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2432 (0.2625) ([0.100]+[0.143])	Prec@1 98.438 (95.763)
Epoch: [213][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2387 (0.2680) ([0.096]+[0.143])	Prec@1 96.094 (95.567)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.4715 (0.4715) ([0.329]+[0.143])	Prec@1 89.062 (89.062)
 * Prec@1 89.990
current lr 1.00000e-02
Grad=  tensor(3.3553, device='cuda:0')
Epoch: [214][0/391]	Time 0.240 (0.240)	Data 0.120 (0.120)	Loss 0.1962 (0.1962) ([0.053]+[0.143])	Prec@1 99.219 (99.219)
Epoch: [214][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2941 (0.2496) ([0.151]+[0.143])	Prec@1 94.531 (96.465)
Epoch: [214][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2907 (0.2568) ([0.148]+[0.143])	Prec@1 94.531 (96.098)
Epoch: [214][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2342 (0.2650) ([0.091]+[0.143])	Prec@1 96.875 (95.800)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.4206 (0.4206) ([0.278]+[0.143])	Prec@1 89.844 (89.844)
 * Prec@1 90.070
current lr 1.00000e-02
Grad=  tensor(10.8996, device='cuda:0')
Epoch: [215][0/391]	Time 0.240 (0.240)	Data 0.120 (0.120)	Loss 0.2697 (0.2697) ([0.127]+[0.143])	Prec@1 95.312 (95.312)
Epoch: [215][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3403 (0.2615) ([0.197]+[0.143])	Prec@1 92.188 (95.823)
Epoch: [215][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1960 (0.2682) ([0.053]+[0.143])	Prec@1 99.219 (95.725)
Epoch: [215][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2947 (0.2693) ([0.152]+[0.143])	Prec@1 96.094 (95.640)
Test: [0/79]	Time 0.153 (0.153)	Loss 0.4293 (0.4293) ([0.286]+[0.143])	Prec@1 90.625 (90.625)
 * Prec@1 90.180
current lr 1.00000e-02
Grad=  tensor(5.7329, device='cuda:0')
Epoch: [216][0/391]	Time 0.241 (0.241)	Data 0.121 (0.121)	Loss 0.2524 (0.2524) ([0.110]+[0.143])	Prec@1 96.875 (96.875)
Epoch: [216][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2769 (0.2533) ([0.134]+[0.143])	Prec@1 95.312 (96.295)
Epoch: [216][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2692 (0.2602) ([0.126]+[0.143])	Prec@1 96.094 (95.985)
Epoch: [216][300/391]	Time 0.109 (0.111)	Data 0.000 (0.000)	Loss 0.2848 (0.2603) ([0.142]+[0.143])	Prec@1 95.312 (95.889)
Test: [0/79]	Time 0.153 (0.153)	Loss 0.4205 (0.4205) ([0.278]+[0.143])	Prec@1 90.625 (90.625)
 * Prec@1 89.290
current lr 1.00000e-02
Grad=  tensor(10.7538, device='cuda:0')
Epoch: [217][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.2953 (0.2953) ([0.152]+[0.143])	Prec@1 94.531 (94.531)
Epoch: [217][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2854 (0.2561) ([0.143]+[0.143])	Prec@1 94.531 (96.078)
Epoch: [217][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3006 (0.2605) ([0.158]+[0.143])	Prec@1 94.531 (95.934)
Epoch: [217][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3950 (0.2673) ([0.252]+[0.143])	Prec@1 92.188 (95.730)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.5002 (0.5002) ([0.357]+[0.143])	Prec@1 92.188 (92.188)
 * Prec@1 90.290
current lr 1.00000e-02
Grad=  tensor(4.6786, device='cuda:0')
Epoch: [218][0/391]	Time 0.240 (0.240)	Data 0.120 (0.120)	Loss 0.2234 (0.2234) ([0.080]+[0.143])	Prec@1 97.656 (97.656)
Epoch: [218][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2562 (0.2498) ([0.113]+[0.143])	Prec@1 96.094 (96.279)
Epoch: [218][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3049 (0.2551) ([0.162]+[0.143])	Prec@1 94.531 (96.090)
Epoch: [218][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2624 (0.2614) ([0.119]+[0.143])	Prec@1 95.312 (95.762)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.3125 (0.3125) ([0.169]+[0.143])	Prec@1 93.750 (93.750)
 * Prec@1 90.570
current lr 1.00000e-02
Grad=  tensor(3.3542, device='cuda:0')
Epoch: [219][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.2071 (0.2071) ([0.064]+[0.143])	Prec@1 97.656 (97.656)
Epoch: [219][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2561 (0.2500) ([0.113]+[0.143])	Prec@1 97.656 (96.326)
Epoch: [219][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2551 (0.2574) ([0.112]+[0.143])	Prec@1 95.312 (96.035)
Epoch: [219][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2432 (0.2614) ([0.100]+[0.143])	Prec@1 94.531 (95.884)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.4890 (0.4890) ([0.346]+[0.143])	Prec@1 89.844 (89.844)
 * Prec@1 88.490
current lr 1.00000e-02
Grad=  tensor(3.8686, device='cuda:0')
Epoch: [220][0/391]	Time 0.240 (0.240)	Data 0.120 (0.120)	Loss 0.2146 (0.2146) ([0.071]+[0.143])	Prec@1 98.438 (98.438)
Epoch: [220][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2117 (0.2549) ([0.069]+[0.143])	Prec@1 97.656 (96.303)
Epoch: [220][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2855 (0.2561) ([0.142]+[0.143])	Prec@1 95.312 (96.269)
Epoch: [220][300/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.2136 (0.2607) ([0.071]+[0.143])	Prec@1 99.219 (96.063)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3126 (0.3126) ([0.170]+[0.143])	Prec@1 94.531 (94.531)
 * Prec@1 88.320
current lr 1.00000e-02
Grad=  tensor(7.1156, device='cuda:0')
Epoch: [221][0/391]	Time 0.238 (0.238)	Data 0.118 (0.118)	Loss 0.2963 (0.2963) ([0.153]+[0.143])	Prec@1 96.094 (96.094)
Epoch: [221][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2242 (0.2609) ([0.081]+[0.143])	Prec@1 97.656 (95.955)
Epoch: [221][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2725 (0.2583) ([0.130]+[0.143])	Prec@1 94.531 (96.055)
Epoch: [221][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.2319 (0.2620) ([0.089]+[0.143])	Prec@1 95.312 (95.956)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.5164 (0.5164) ([0.373]+[0.143])	Prec@1 90.625 (90.625)
 * Prec@1 88.600
current lr 1.00000e-02
Grad=  tensor(4.4110, device='cuda:0')
Epoch: [222][0/391]	Time 0.243 (0.243)	Data 0.123 (0.123)	Loss 0.2253 (0.2253) ([0.082]+[0.143])	Prec@1 97.656 (97.656)
Epoch: [222][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2980 (0.2569) ([0.155]+[0.143])	Prec@1 94.531 (96.016)
Epoch: [222][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2535 (0.2595) ([0.111]+[0.143])	Prec@1 94.531 (95.923)
Epoch: [222][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2831 (0.2598) ([0.140]+[0.143])	Prec@1 95.312 (95.967)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.3671 (0.3671) ([0.224]+[0.143])	Prec@1 93.750 (93.750)
 * Prec@1 90.290
current lr 1.00000e-02
Grad=  tensor(5.6415, device='cuda:0')
Epoch: [223][0/391]	Time 0.249 (0.249)	Data 0.127 (0.127)	Loss 0.2505 (0.2505) ([0.107]+[0.143])	Prec@1 95.312 (95.312)
Epoch: [223][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2002 (0.2616) ([0.057]+[0.143])	Prec@1 98.438 (95.761)
Epoch: [223][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2917 (0.2623) ([0.149]+[0.143])	Prec@1 95.312 (95.810)
Epoch: [223][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3459 (0.2667) ([0.203]+[0.143])	Prec@1 92.969 (95.676)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.4259 (0.4259) ([0.283]+[0.143])	Prec@1 92.188 (92.188)
 * Prec@1 90.650
current lr 1.00000e-02
Grad=  tensor(4.9454, device='cuda:0')
Epoch: [224][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.2354 (0.2354) ([0.092]+[0.143])	Prec@1 96.875 (96.875)
Epoch: [224][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2584 (0.2508) ([0.115]+[0.143])	Prec@1 94.531 (96.303)
Epoch: [224][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2691 (0.2549) ([0.126]+[0.143])	Prec@1 96.875 (96.152)
Epoch: [224][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1833 (0.2574) ([0.040]+[0.143])	Prec@1 99.219 (96.076)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.5178 (0.5178) ([0.375]+[0.143])	Prec@1 92.969 (92.969)
 * Prec@1 89.280
current lr 1.00000e-02
Grad=  tensor(9.0614, device='cuda:0')
Epoch: [225][0/391]	Time 0.249 (0.249)	Data 0.127 (0.127)	Loss 0.3223 (0.3223) ([0.179]+[0.143])	Prec@1 94.531 (94.531)
Epoch: [225][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2229 (0.2510) ([0.080]+[0.143])	Prec@1 97.656 (96.125)
Epoch: [225][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2140 (0.2486) ([0.071]+[0.143])	Prec@1 97.656 (96.300)
Epoch: [225][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3145 (0.2545) ([0.172]+[0.143])	Prec@1 94.531 (96.109)
Test: [0/79]	Time 0.153 (0.153)	Loss 0.4385 (0.4385) ([0.295]+[0.143])	Prec@1 92.188 (92.188)
 * Prec@1 89.320
current lr 1.00000e-02
Grad=  tensor(9.1579, device='cuda:0')
Epoch: [226][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.2579 (0.2579) ([0.115]+[0.143])	Prec@1 96.875 (96.875)
Epoch: [226][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2731 (0.2619) ([0.130]+[0.143])	Prec@1 92.969 (95.699)
Epoch: [226][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2581 (0.2602) ([0.115]+[0.143])	Prec@1 95.312 (95.826)
Epoch: [226][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2812 (0.2613) ([0.138]+[0.143])	Prec@1 95.312 (95.808)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.6176 (0.6176) ([0.475]+[0.143])	Prec@1 89.844 (89.844)
 * Prec@1 88.310
current lr 1.00000e-02
Grad=  tensor(6.4056, device='cuda:0')
Epoch: [227][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 0.2725 (0.2725) ([0.130]+[0.143])	Prec@1 96.875 (96.875)
Epoch: [227][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2172 (0.2553) ([0.074]+[0.143])	Prec@1 96.875 (95.978)
Epoch: [227][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2566 (0.2613) ([0.114]+[0.143])	Prec@1 95.312 (95.767)
Epoch: [227][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2230 (0.2653) ([0.080]+[0.143])	Prec@1 96.875 (95.668)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.5366 (0.5366) ([0.394]+[0.143])	Prec@1 89.844 (89.844)
 * Prec@1 89.810
current lr 1.00000e-02
Grad=  tensor(4.1248, device='cuda:0')
Epoch: [228][0/391]	Time 0.246 (0.246)	Data 0.125 (0.125)	Loss 0.2313 (0.2313) ([0.088]+[0.143])	Prec@1 97.656 (97.656)
Epoch: [228][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2727 (0.2596) ([0.130]+[0.143])	Prec@1 96.875 (96.125)
Epoch: [228][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2541 (0.2599) ([0.111]+[0.143])	Prec@1 96.094 (96.004)
Epoch: [228][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3240 (0.2635) ([0.181]+[0.143])	Prec@1 93.750 (95.946)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.4485 (0.4485) ([0.305]+[0.143])	Prec@1 90.625 (90.625)
 * Prec@1 89.710
current lr 1.00000e-02
Grad=  tensor(8.4561, device='cuda:0')
Epoch: [229][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.2663 (0.2663) ([0.123]+[0.143])	Prec@1 96.875 (96.875)
Epoch: [229][100/391]	Time 0.109 (0.112)	Data 0.000 (0.001)	Loss 0.2141 (0.2499) ([0.071]+[0.143])	Prec@1 98.438 (96.388)
Epoch: [229][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2825 (0.2532) ([0.140]+[0.143])	Prec@1 94.531 (96.265)
Epoch: [229][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2201 (0.2582) ([0.077]+[0.143])	Prec@1 96.094 (96.065)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4256 (0.4256) ([0.283]+[0.143])	Prec@1 90.625 (90.625)
 * Prec@1 90.820
current lr 1.00000e-02
Grad=  tensor(2.8958, device='cuda:0')
Epoch: [230][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.2002 (0.2002) ([0.057]+[0.143])	Prec@1 98.438 (98.438)
Epoch: [230][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2169 (0.2475) ([0.074]+[0.143])	Prec@1 96.875 (96.395)
Epoch: [230][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2605 (0.2503) ([0.118]+[0.143])	Prec@1 95.312 (96.350)
Epoch: [230][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2661 (0.2568) ([0.123]+[0.143])	Prec@1 95.312 (96.104)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.4739 (0.4739) ([0.331]+[0.143])	Prec@1 92.969 (92.969)
 * Prec@1 89.720
current lr 1.00000e-02
Grad=  tensor(4.5331, device='cuda:0')
Epoch: [231][0/391]	Time 0.246 (0.246)	Data 0.124 (0.124)	Loss 0.2121 (0.2121) ([0.069]+[0.143])	Prec@1 98.438 (98.438)
Epoch: [231][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3026 (0.2603) ([0.160]+[0.143])	Prec@1 95.312 (96.055)
Epoch: [231][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2693 (0.2632) ([0.126]+[0.143])	Prec@1 94.531 (95.973)
Epoch: [231][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3018 (0.2634) ([0.159]+[0.143])	Prec@1 93.750 (95.922)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.4464 (0.4464) ([0.303]+[0.143])	Prec@1 88.281 (88.281)
 * Prec@1 90.620
current lr 1.00000e-02
Grad=  tensor(10.4670, device='cuda:0')
Epoch: [232][0/391]	Time 0.250 (0.250)	Data 0.128 (0.128)	Loss 0.2719 (0.2719) ([0.129]+[0.143])	Prec@1 93.750 (93.750)
Epoch: [232][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2546 (0.2508) ([0.112]+[0.143])	Prec@1 95.312 (96.279)
Epoch: [232][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1934 (0.2525) ([0.051]+[0.143])	Prec@1 100.000 (96.214)
Epoch: [232][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2256 (0.2554) ([0.083]+[0.143])	Prec@1 96.875 (96.083)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.5008 (0.5008) ([0.358]+[0.143])	Prec@1 89.062 (89.062)
 * Prec@1 88.890
current lr 1.00000e-02
Grad=  tensor(11.0441, device='cuda:0')
Epoch: [233][0/391]	Time 0.243 (0.243)	Data 0.123 (0.123)	Loss 0.2890 (0.2890) ([0.146]+[0.143])	Prec@1 93.750 (93.750)
Epoch: [233][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2073 (0.2465) ([0.064]+[0.143])	Prec@1 98.438 (96.558)
Epoch: [233][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2917 (0.2498) ([0.149]+[0.143])	Prec@1 96.094 (96.346)
Epoch: [233][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2574 (0.2590) ([0.115]+[0.143])	Prec@1 96.094 (96.099)
Test: [0/79]	Time 0.153 (0.153)	Loss 0.3882 (0.3882) ([0.245]+[0.143])	Prec@1 91.406 (91.406)
 * Prec@1 89.930
current lr 1.00000e-02
Grad=  tensor(5.1513, device='cuda:0')
Epoch: [234][0/391]	Time 0.246 (0.246)	Data 0.126 (0.126)	Loss 0.2306 (0.2306) ([0.088]+[0.143])	Prec@1 97.656 (97.656)
Epoch: [234][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2535 (0.2539) ([0.111]+[0.143])	Prec@1 93.750 (96.117)
Epoch: [234][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2353 (0.2549) ([0.092]+[0.143])	Prec@1 97.656 (96.039)
Epoch: [234][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3098 (0.2572) ([0.167]+[0.143])	Prec@1 94.531 (95.998)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4975 (0.4975) ([0.355]+[0.143])	Prec@1 89.844 (89.844)
 * Prec@1 89.750
current lr 1.00000e-02
Grad=  tensor(4.8260, device='cuda:0')
Epoch: [235][0/391]	Time 0.256 (0.256)	Data 0.134 (0.134)	Loss 0.2092 (0.2092) ([0.066]+[0.143])	Prec@1 96.875 (96.875)
Epoch: [235][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.2281 (0.2491) ([0.085]+[0.143])	Prec@1 97.656 (96.457)
Epoch: [235][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2881 (0.2502) ([0.145]+[0.143])	Prec@1 95.312 (96.319)
Epoch: [235][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2762 (0.2552) ([0.133]+[0.143])	Prec@1 95.312 (96.117)
Test: [0/79]	Time 0.153 (0.153)	Loss 0.4525 (0.4525) ([0.310]+[0.143])	Prec@1 89.062 (89.062)
 * Prec@1 90.070
current lr 1.00000e-02
Grad=  tensor(8.8272, device='cuda:0')
Epoch: [236][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.2773 (0.2773) ([0.134]+[0.143])	Prec@1 94.531 (94.531)
Epoch: [236][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2114 (0.2539) ([0.069]+[0.143])	Prec@1 98.438 (96.109)
Epoch: [236][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2645 (0.2547) ([0.122]+[0.143])	Prec@1 97.656 (96.086)
Epoch: [236][300/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.2805 (0.2593) ([0.138]+[0.143])	Prec@1 94.531 (95.993)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.5864 (0.5864) ([0.443]+[0.143])	Prec@1 87.500 (87.500)
 * Prec@1 89.200
current lr 1.00000e-02
Grad=  tensor(9.6782, device='cuda:0')
Epoch: [237][0/391]	Time 0.247 (0.247)	Data 0.127 (0.127)	Loss 0.2829 (0.2829) ([0.140]+[0.143])	Prec@1 94.531 (94.531)
Epoch: [237][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2881 (0.2589) ([0.145]+[0.143])	Prec@1 95.312 (96.024)
Epoch: [237][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2312 (0.2624) ([0.088]+[0.143])	Prec@1 96.094 (95.787)
Epoch: [237][300/391]	Time 0.108 (0.111)	Data 0.000 (0.001)	Loss 0.3062 (0.2678) ([0.163]+[0.143])	Prec@1 93.750 (95.585)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4385 (0.4385) ([0.295]+[0.144])	Prec@1 91.406 (91.406)
 * Prec@1 89.780
current lr 1.00000e-02
Grad=  tensor(6.0968, device='cuda:0')
Epoch: [238][0/391]	Time 0.240 (0.240)	Data 0.120 (0.120)	Loss 0.2300 (0.2300) ([0.086]+[0.144])	Prec@1 97.656 (97.656)
Epoch: [238][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2532 (0.2563) ([0.110]+[0.143])	Prec@1 96.875 (96.024)
Epoch: [238][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2187 (0.2581) ([0.075]+[0.143])	Prec@1 99.219 (95.973)
Epoch: [238][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2185 (0.2578) ([0.075]+[0.143])	Prec@1 95.312 (96.057)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.4168 (0.4168) ([0.273]+[0.143])	Prec@1 89.844 (89.844)
 * Prec@1 88.860
current lr 1.00000e-02
Grad=  tensor(8.7859, device='cuda:0')
Epoch: [239][0/391]	Time 0.240 (0.240)	Data 0.121 (0.121)	Loss 0.2554 (0.2554) ([0.112]+[0.143])	Prec@1 96.094 (96.094)
Epoch: [239][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2508 (0.2650) ([0.107]+[0.144])	Prec@1 96.875 (95.823)
Epoch: [239][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2227 (0.2675) ([0.079]+[0.144])	Prec@1 97.656 (95.705)
Epoch: [239][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2332 (0.2673) ([0.090]+[0.144])	Prec@1 96.094 (95.730)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4154 (0.4154) ([0.272]+[0.144])	Prec@1 92.188 (92.188)
 * Prec@1 90.430
current lr 1.00000e-02
Grad=  tensor(10.7350, device='cuda:0')
Epoch: [240][0/391]	Time 0.238 (0.238)	Data 0.119 (0.119)	Loss 0.2720 (0.2720) ([0.128]+[0.144])	Prec@1 95.312 (95.312)
Epoch: [240][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2077 (0.2522) ([0.064]+[0.144])	Prec@1 97.656 (96.218)
Epoch: [240][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2968 (0.2569) ([0.153]+[0.144])	Prec@1 93.750 (96.090)
Epoch: [240][300/391]	Time 0.108 (0.109)	Data 0.000 (0.000)	Loss 0.3022 (0.2566) ([0.159]+[0.143])	Prec@1 93.750 (96.135)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.4679 (0.4679) ([0.324]+[0.144])	Prec@1 87.500 (87.500)
 * Prec@1 87.790
current lr 1.00000e-02
Grad=  tensor(5.1931, device='cuda:0')
Epoch: [241][0/391]	Time 0.247 (0.247)	Data 0.126 (0.126)	Loss 0.2290 (0.2290) ([0.085]+[0.144])	Prec@1 96.875 (96.875)
Epoch: [241][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2705 (0.2539) ([0.127]+[0.143])	Prec@1 95.312 (96.241)
Epoch: [241][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3087 (0.2514) ([0.165]+[0.143])	Prec@1 95.312 (96.323)
Epoch: [241][300/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.3612 (0.2575) ([0.218]+[0.143])	Prec@1 92.969 (96.115)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3958 (0.3958) ([0.252]+[0.143])	Prec@1 91.406 (91.406)
 * Prec@1 89.160
current lr 1.00000e-02
Grad=  tensor(7.4364, device='cuda:0')
Epoch: [242][0/391]	Time 0.241 (0.241)	Data 0.120 (0.120)	Loss 0.2433 (0.2433) ([0.100]+[0.143])	Prec@1 96.875 (96.875)
Epoch: [242][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2909 (0.2571) ([0.148]+[0.143])	Prec@1 94.531 (96.086)
Epoch: [242][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2557 (0.2544) ([0.112]+[0.143])	Prec@1 94.531 (96.171)
Epoch: [242][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2500 (0.2576) ([0.107]+[0.143])	Prec@1 95.312 (96.047)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.5035 (0.5035) ([0.360]+[0.143])	Prec@1 89.844 (89.844)
 * Prec@1 90.200
current lr 1.00000e-02
Grad=  tensor(12.0877, device='cuda:0')
Epoch: [243][0/391]	Time 0.241 (0.241)	Data 0.119 (0.119)	Loss 0.3129 (0.3129) ([0.169]+[0.143])	Prec@1 92.188 (92.188)
Epoch: [243][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2784 (0.2515) ([0.135]+[0.143])	Prec@1 93.750 (96.481)
Epoch: [243][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2015 (0.2539) ([0.058]+[0.143])	Prec@1 98.438 (96.335)
Epoch: [243][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2554 (0.2571) ([0.112]+[0.143])	Prec@1 96.094 (96.107)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.4395 (0.4395) ([0.296]+[0.143])	Prec@1 92.969 (92.969)
 * Prec@1 89.300
current lr 1.00000e-02
Grad=  tensor(5.0557, device='cuda:0')
Epoch: [244][0/391]	Time 0.250 (0.250)	Data 0.128 (0.128)	Loss 0.2195 (0.2195) ([0.076]+[0.143])	Prec@1 99.219 (99.219)
Epoch: [244][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2793 (0.2521) ([0.136]+[0.143])	Prec@1 96.875 (96.256)
Epoch: [244][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3448 (0.2609) ([0.201]+[0.143])	Prec@1 92.969 (95.923)
Epoch: [244][300/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.2731 (0.2624) ([0.130]+[0.143])	Prec@1 96.094 (95.938)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.4530 (0.4530) ([0.309]+[0.144])	Prec@1 90.625 (90.625)
 * Prec@1 88.940
current lr 1.00000e-02
Grad=  tensor(10.1970, device='cuda:0')
Epoch: [245][0/391]	Time 0.251 (0.251)	Data 0.131 (0.131)	Loss 0.3122 (0.3122) ([0.169]+[0.144])	Prec@1 92.969 (92.969)
Epoch: [245][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2753 (0.2479) ([0.132]+[0.143])	Prec@1 93.750 (96.496)
Epoch: [245][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2846 (0.2501) ([0.141]+[0.143])	Prec@1 93.750 (96.409)
Epoch: [245][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2042 (0.2513) ([0.061]+[0.143])	Prec@1 98.438 (96.330)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4749 (0.4749) ([0.332]+[0.143])	Prec@1 89.844 (89.844)
 * Prec@1 89.770
current lr 1.00000e-02
Grad=  tensor(7.6126, device='cuda:0')
Epoch: [246][0/391]	Time 0.256 (0.256)	Data 0.135 (0.135)	Loss 0.2482 (0.2482) ([0.105]+[0.143])	Prec@1 96.094 (96.094)
Epoch: [246][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2599 (0.2572) ([0.117]+[0.143])	Prec@1 96.094 (96.248)
Epoch: [246][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1986 (0.2540) ([0.055]+[0.143])	Prec@1 97.656 (96.296)
Epoch: [246][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2418 (0.2568) ([0.098]+[0.143])	Prec@1 95.312 (96.164)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.5112 (0.5112) ([0.368]+[0.144])	Prec@1 89.844 (89.844)
 * Prec@1 89.530
current lr 1.00000e-02
Grad=  tensor(8.8663, device='cuda:0')
Epoch: [247][0/391]	Time 0.238 (0.238)	Data 0.118 (0.118)	Loss 0.2524 (0.2524) ([0.109]+[0.144])	Prec@1 94.531 (94.531)
Epoch: [247][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3166 (0.2503) ([0.173]+[0.143])	Prec@1 92.188 (96.388)
Epoch: [247][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2148 (0.2550) ([0.071]+[0.143])	Prec@1 97.656 (96.179)
Epoch: [247][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2493 (0.2563) ([0.106]+[0.143])	Prec@1 96.094 (96.099)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4915 (0.4915) ([0.348]+[0.143])	Prec@1 91.406 (91.406)
 * Prec@1 90.040
current lr 1.00000e-02
Grad=  tensor(3.6198, device='cuda:0')
Epoch: [248][0/391]	Time 0.236 (0.236)	Data 0.117 (0.117)	Loss 0.2136 (0.2136) ([0.070]+[0.143])	Prec@1 96.875 (96.875)
Epoch: [248][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2143 (0.2437) ([0.071]+[0.143])	Prec@1 96.875 (96.627)
Epoch: [248][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.1984 (0.2489) ([0.055]+[0.143])	Prec@1 98.438 (96.343)
Epoch: [248][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.2356 (0.2538) ([0.092]+[0.143])	Prec@1 96.094 (96.213)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.6681 (0.6681) ([0.525]+[0.143])	Prec@1 88.281 (88.281)
 * Prec@1 87.220
current lr 1.00000e-02
Grad=  tensor(15.8710, device='cuda:0')
Epoch: [249][0/391]	Time 0.241 (0.241)	Data 0.121 (0.121)	Loss 0.3260 (0.3260) ([0.183]+[0.143])	Prec@1 94.531 (94.531)
Epoch: [249][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2625 (0.2574) ([0.119]+[0.143])	Prec@1 95.312 (96.063)
Epoch: [249][200/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.3057 (0.2590) ([0.162]+[0.143])	Prec@1 94.531 (96.004)
Epoch: [249][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.2551 (0.2599) ([0.112]+[0.143])	Prec@1 96.094 (95.993)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.4003 (0.4003) ([0.257]+[0.143])	Prec@1 93.750 (93.750)
 * Prec@1 90.390
current lr 1.00000e-03
Grad=  tensor(9.4186, device='cuda:0')
Epoch: [250][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.2667 (0.2667) ([0.123]+[0.143])	Prec@1 94.531 (94.531)
Epoch: [250][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1891 (0.2172) ([0.047]+[0.142])	Prec@1 99.219 (97.618)
Epoch: [250][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2073 (0.2080) ([0.066]+[0.142])	Prec@1 98.438 (97.928)
Epoch: [250][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.1751 (0.2021) ([0.033]+[0.142])	Prec@1 99.219 (98.168)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.3274 (0.3274) ([0.186]+[0.141])	Prec@1 95.312 (95.312)
 * Prec@1 93.060
current lr 1.00000e-03
Grad=  tensor(0.3427, device='cuda:0')
Epoch: [251][0/391]	Time 0.243 (0.243)	Data 0.121 (0.121)	Loss 0.1543 (0.1543) ([0.013]+[0.141])	Prec@1 100.000 (100.000)
Epoch: [251][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1692 (0.1784) ([0.028]+[0.141])	Prec@1 99.219 (99.002)
Epoch: [251][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1621 (0.1796) ([0.021]+[0.141])	Prec@1 99.219 (98.935)
Epoch: [251][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1627 (0.1793) ([0.022]+[0.141])	Prec@1 99.219 (98.938)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.3419 (0.3419) ([0.201]+[0.141])	Prec@1 95.312 (95.312)
 * Prec@1 93.150
current lr 1.00000e-03
Grad=  tensor(2.7220, device='cuda:0')
Epoch: [252][0/391]	Time 0.257 (0.257)	Data 0.137 (0.137)	Loss 0.1803 (0.1803) ([0.039]+[0.141])	Prec@1 98.438 (98.438)
Epoch: [252][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1756 (0.1706) ([0.035]+[0.141])	Prec@1 100.000 (99.312)
Epoch: [252][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1588 (0.1703) ([0.018]+[0.141])	Prec@1 100.000 (99.316)
Epoch: [252][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1804 (0.1701) ([0.040]+[0.140])	Prec@1 99.219 (99.291)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3249 (0.3249) ([0.185]+[0.140])	Prec@1 96.094 (96.094)
 * Prec@1 93.430
current lr 1.00000e-03
Grad=  tensor(0.5893, device='cuda:0')
Epoch: [253][0/391]	Time 0.242 (0.242)	Data 0.122 (0.122)	Loss 0.1494 (0.1494) ([0.009]+[0.140])	Prec@1 100.000 (100.000)
Epoch: [253][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1528 (0.1678) ([0.013]+[0.140])	Prec@1 100.000 (99.350)
Epoch: [253][200/391]	Time 0.112 (0.109)	Data 0.000 (0.001)	Loss 0.1656 (0.1662) ([0.025]+[0.140])	Prec@1 99.219 (99.417)
Epoch: [253][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1483 (0.1663) ([0.008]+[0.140])	Prec@1 100.000 (99.372)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.3292 (0.3292) ([0.189]+[0.140])	Prec@1 95.312 (95.312)
 * Prec@1 93.530
current lr 1.00000e-03
Grad=  tensor(1.6818, device='cuda:0')
Epoch: [254][0/391]	Time 0.246 (0.246)	Data 0.126 (0.126)	Loss 0.1579 (0.1579) ([0.018]+[0.140])	Prec@1 99.219 (99.219)
Epoch: [254][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.1733 (0.1664) ([0.034]+[0.140])	Prec@1 99.219 (99.343)
Epoch: [254][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1720 (0.1652) ([0.032]+[0.140])	Prec@1 98.438 (99.351)
Epoch: [254][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1525 (0.1652) ([0.013]+[0.139])	Prec@1 100.000 (99.367)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3536 (0.3536) ([0.214]+[0.139])	Prec@1 93.750 (93.750)
 * Prec@1 93.600
current lr 1.00000e-03
Grad=  tensor(3.3608, device='cuda:0')
Epoch: [255][0/391]	Time 0.251 (0.251)	Data 0.131 (0.131)	Loss 0.1715 (0.1715) ([0.032]+[0.139])	Prec@1 99.219 (99.219)
Epoch: [255][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.1523 (0.1620) ([0.013]+[0.139])	Prec@1 100.000 (99.482)
Epoch: [255][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1557 (0.1613) ([0.017]+[0.139])	Prec@1 100.000 (99.506)
Epoch: [255][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1576 (0.1619) ([0.019]+[0.139])	Prec@1 100.000 (99.502)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.3326 (0.3326) ([0.194]+[0.139])	Prec@1 94.531 (94.531)
 * Prec@1 93.630
current lr 1.00000e-03
Grad=  tensor(2.0680, device='cuda:0')
Epoch: [256][0/391]	Time 0.250 (0.250)	Data 0.130 (0.130)	Loss 0.1648 (0.1648) ([0.026]+[0.139])	Prec@1 99.219 (99.219)
Epoch: [256][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1788 (0.1603) ([0.040]+[0.139])	Prec@1 98.438 (99.466)
Epoch: [256][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1512 (0.1601) ([0.013]+[0.139])	Prec@1 100.000 (99.483)
Epoch: [256][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1466 (0.1606) ([0.008]+[0.139])	Prec@1 100.000 (99.486)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3313 (0.3313) ([0.193]+[0.138])	Prec@1 95.312 (95.312)
 * Prec@1 93.600
current lr 1.00000e-03
Grad=  tensor(3.4803, device='cuda:0')
Epoch: [257][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.1642 (0.1642) ([0.026]+[0.138])	Prec@1 99.219 (99.219)
Epoch: [257][100/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1598 (0.1578) ([0.021]+[0.138])	Prec@1 99.219 (99.582)
Epoch: [257][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1536 (0.1574) ([0.015]+[0.138])	Prec@1 100.000 (99.607)
Epoch: [257][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1554 (0.1580) ([0.017]+[0.138])	Prec@1 100.000 (99.577)
Test: [0/79]	Time 0.146 (0.146)	Loss 0.3487 (0.3487) ([0.211]+[0.138])	Prec@1 93.750 (93.750)
 * Prec@1 93.610
current lr 1.00000e-03
Grad=  tensor(0.4438, device='cuda:0')
Epoch: [258][0/391]	Time 0.237 (0.237)	Data 0.118 (0.118)	Loss 0.1462 (0.1462) ([0.008]+[0.138])	Prec@1 100.000 (100.000)
Epoch: [258][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1511 (0.1582) ([0.013]+[0.138])	Prec@1 100.000 (99.551)
Epoch: [258][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1620 (0.1575) ([0.024]+[0.138])	Prec@1 99.219 (99.530)
Epoch: [258][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.1632 (0.1572) ([0.026]+[0.138])	Prec@1 99.219 (99.543)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.3661 (0.3661) ([0.229]+[0.138])	Prec@1 93.750 (93.750)
 * Prec@1 93.540
current lr 1.00000e-03
Grad=  tensor(3.0264, device='cuda:0')
Epoch: [259][0/391]	Time 0.243 (0.243)	Data 0.122 (0.122)	Loss 0.1569 (0.1569) ([0.019]+[0.138])	Prec@1 99.219 (99.219)
Epoch: [259][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1537 (0.1540) ([0.016]+[0.137])	Prec@1 99.219 (99.683)
Epoch: [259][200/391]	Time 0.112 (0.110)	Data 0.000 (0.001)	Loss 0.1468 (0.1542) ([0.010]+[0.137])	Prec@1 100.000 (99.662)
Epoch: [259][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1653 (0.1545) ([0.028]+[0.137])	Prec@1 99.219 (99.655)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.3600 (0.3600) ([0.223]+[0.137])	Prec@1 94.531 (94.531)
 * Prec@1 93.500
current lr 1.00000e-03
Grad=  tensor(0.2556, device='cuda:0')
Epoch: [260][0/391]	Time 0.249 (0.249)	Data 0.130 (0.130)	Loss 0.1434 (0.1434) ([0.006]+[0.137])	Prec@1 100.000 (100.000)
Epoch: [260][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1564 (0.1525) ([0.019]+[0.137])	Prec@1 99.219 (99.698)
Epoch: [260][200/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.1426 (0.1544) ([0.006]+[0.137])	Prec@1 100.000 (99.607)
Epoch: [260][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1738 (0.1540) ([0.037]+[0.137])	Prec@1 98.438 (99.642)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.3633 (0.3633) ([0.227]+[0.137])	Prec@1 94.531 (94.531)
 * Prec@1 93.590
current lr 1.00000e-03
Grad=  tensor(0.5275, device='cuda:0')
Epoch: [261][0/391]	Time 0.239 (0.239)	Data 0.119 (0.119)	Loss 0.1463 (0.1463) ([0.010]+[0.137])	Prec@1 100.000 (100.000)
Epoch: [261][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2016 (0.1547) ([0.065]+[0.137])	Prec@1 98.438 (99.629)
Epoch: [261][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1469 (0.1533) ([0.011]+[0.136])	Prec@1 100.000 (99.674)
Epoch: [261][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.1661 (0.1527) ([0.030]+[0.136])	Prec@1 99.219 (99.686)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3472 (0.3472) ([0.211]+[0.136])	Prec@1 94.531 (94.531)
 * Prec@1 93.760
current lr 1.00000e-03
Grad=  tensor(0.5615, device='cuda:0')
Epoch: [262][0/391]	Time 0.252 (0.252)	Data 0.133 (0.133)	Loss 0.1456 (0.1456) ([0.009]+[0.136])	Prec@1 100.000 (100.000)
Epoch: [262][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1614 (0.1509) ([0.025]+[0.136])	Prec@1 99.219 (99.737)
Epoch: [262][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1675 (0.1518) ([0.032]+[0.136])	Prec@1 98.438 (99.666)
Epoch: [262][300/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.1468 (0.1516) ([0.011]+[0.136])	Prec@1 99.219 (99.670)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.3276 (0.3276) ([0.192]+[0.136])	Prec@1 94.531 (94.531)
 * Prec@1 93.690
current lr 1.00000e-03
Grad=  tensor(0.4995, device='cuda:0')
Epoch: [263][0/391]	Time 0.236 (0.236)	Data 0.115 (0.115)	Loss 0.1474 (0.1474) ([0.012]+[0.136])	Prec@1 100.000 (100.000)
Epoch: [263][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1414 (0.1513) ([0.006]+[0.136])	Prec@1 100.000 (99.691)
Epoch: [263][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1715 (0.1510) ([0.036]+[0.136])	Prec@1 97.656 (99.689)
Epoch: [263][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.1505 (0.1508) ([0.015]+[0.135])	Prec@1 100.000 (99.676)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.3559 (0.3559) ([0.221]+[0.135])	Prec@1 93.750 (93.750)
 * Prec@1 93.640
current lr 1.00000e-03
Grad=  tensor(0.3516, device='cuda:0')
Epoch: [264][0/391]	Time 0.240 (0.240)	Data 0.119 (0.119)	Loss 0.1427 (0.1427) ([0.007]+[0.135])	Prec@1 100.000 (100.000)
Epoch: [264][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1409 (0.1500) ([0.006]+[0.135])	Prec@1 100.000 (99.698)
Epoch: [264][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1412 (0.1502) ([0.006]+[0.135])	Prec@1 100.000 (99.697)
Epoch: [264][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.1430 (0.1499) ([0.008]+[0.135])	Prec@1 100.000 (99.727)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.3553 (0.3553) ([0.220]+[0.135])	Prec@1 94.531 (94.531)
 * Prec@1 93.570
current lr 1.00000e-03
Grad=  tensor(1.1217, device='cuda:0')
Epoch: [265][0/391]	Time 0.242 (0.242)	Data 0.121 (0.121)	Loss 0.1499 (0.1499) ([0.015]+[0.135])	Prec@1 99.219 (99.219)
Epoch: [265][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1398 (0.1475) ([0.005]+[0.135])	Prec@1 100.000 (99.799)
Epoch: [265][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1554 (0.1478) ([0.021]+[0.135])	Prec@1 98.438 (99.782)
Epoch: [265][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1462 (0.1485) ([0.012]+[0.135])	Prec@1 100.000 (99.790)
Test: [0/79]	Time 0.209 (0.209)	Loss 0.3592 (0.3592) ([0.225]+[0.134])	Prec@1 94.531 (94.531)
 * Prec@1 93.500
current lr 1.00000e-03
Grad=  tensor(1.3028, device='cuda:0')
Epoch: [266][0/391]	Time 0.329 (0.329)	Data 0.169 (0.169)	Loss 0.1499 (0.1499) ([0.015]+[0.134])	Prec@1 100.000 (100.000)
Epoch: [266][100/391]	Time 0.110 (0.113)	Data 0.000 (0.002)	Loss 0.1457 (0.1473) ([0.011]+[0.134])	Prec@1 100.000 (99.776)
Epoch: [266][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1436 (0.1475) ([0.009]+[0.134])	Prec@1 100.000 (99.771)
Epoch: [266][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1441 (0.1477) ([0.010]+[0.134])	Prec@1 100.000 (99.746)
Test: [0/79]	Time 0.156 (0.156)	Loss 0.3437 (0.3437) ([0.210]+[0.134])	Prec@1 94.531 (94.531)
 * Prec@1 93.690
current lr 1.00000e-03
Grad=  tensor(0.5400, device='cuda:0')
Epoch: [267][0/391]	Time 0.257 (0.257)	Data 0.134 (0.134)	Loss 0.1443 (0.1443) ([0.010]+[0.134])	Prec@1 100.000 (100.000)
Epoch: [267][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1476 (0.1477) ([0.014]+[0.134])	Prec@1 100.000 (99.768)
Epoch: [267][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1416 (0.1476) ([0.008]+[0.134])	Prec@1 100.000 (99.755)
Epoch: [267][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1379 (0.1474) ([0.004]+[0.134])	Prec@1 100.000 (99.753)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3119 (0.3119) ([0.178]+[0.134])	Prec@1 95.312 (95.312)
 * Prec@1 93.720
current lr 1.00000e-03
Grad=  tensor(1.3698, device='cuda:0')
Epoch: [268][0/391]	Time 0.244 (0.244)	Data 0.124 (0.124)	Loss 0.1468 (0.1468) ([0.013]+[0.134])	Prec@1 100.000 (100.000)
Epoch: [268][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1393 (0.1450) ([0.006]+[0.134])	Prec@1 100.000 (99.822)
Epoch: [268][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1716 (0.1465) ([0.038]+[0.133])	Prec@1 99.219 (99.740)
Epoch: [268][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1434 (0.1459) ([0.010]+[0.133])	Prec@1 100.000 (99.779)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.3335 (0.3335) ([0.200]+[0.133])	Prec@1 96.094 (96.094)
 * Prec@1 93.690
current lr 1.00000e-03
Grad=  tensor(1.7764, device='cuda:0')
Epoch: [269][0/391]	Time 0.240 (0.240)	Data 0.120 (0.120)	Loss 0.1470 (0.1470) ([0.014]+[0.133])	Prec@1 100.000 (100.000)
Epoch: [269][100/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.1391 (0.1447) ([0.006]+[0.133])	Prec@1 100.000 (99.861)
Epoch: [269][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1415 (0.1457) ([0.008]+[0.133])	Prec@1 100.000 (99.817)
Epoch: [269][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1409 (0.1454) ([0.008]+[0.133])	Prec@1 100.000 (99.800)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.3182 (0.3182) ([0.185]+[0.133])	Prec@1 95.312 (95.312)
 * Prec@1 93.850
current lr 1.00000e-03
Grad=  tensor(3.0883, device='cuda:0')
Epoch: [270][0/391]	Time 0.250 (0.250)	Data 0.128 (0.128)	Loss 0.1533 (0.1533) ([0.020]+[0.133])	Prec@1 99.219 (99.219)
Epoch: [270][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.1432 (0.1451) ([0.010]+[0.133])	Prec@1 100.000 (99.722)
Epoch: [270][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1602 (0.1446) ([0.028]+[0.133])	Prec@1 98.438 (99.778)
Epoch: [270][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1371 (0.1447) ([0.005]+[0.133])	Prec@1 100.000 (99.759)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3473 (0.3473) ([0.215]+[0.132])	Prec@1 94.531 (94.531)
 * Prec@1 93.510
current lr 1.00000e-03
Grad=  tensor(0.3471, device='cuda:0')
Epoch: [271][0/391]	Time 0.242 (0.242)	Data 0.120 (0.120)	Loss 0.1380 (0.1380) ([0.006]+[0.132])	Prec@1 100.000 (100.000)
Epoch: [271][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.1396 (0.1431) ([0.007]+[0.132])	Prec@1 100.000 (99.853)
Epoch: [271][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1382 (0.1433) ([0.006]+[0.132])	Prec@1 100.000 (99.833)
Epoch: [271][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.1390 (0.1435) ([0.007]+[0.132])	Prec@1 100.000 (99.808)
Test: [0/79]	Time 0.154 (0.154)	Loss 0.3424 (0.3424) ([0.210]+[0.132])	Prec@1 95.312 (95.312)
 * Prec@1 93.710
current lr 1.00000e-03
Grad=  tensor(0.9897, device='cuda:0')
Epoch: [272][0/391]	Time 0.256 (0.256)	Data 0.135 (0.135)	Loss 0.1438 (0.1438) ([0.012]+[0.132])	Prec@1 99.219 (99.219)
Epoch: [272][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1439 (0.1431) ([0.012]+[0.132])	Prec@1 100.000 (99.814)
Epoch: [272][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1405 (0.1427) ([0.009]+[0.132])	Prec@1 100.000 (99.817)
Epoch: [272][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1524 (0.1430) ([0.021]+[0.132])	Prec@1 99.219 (99.808)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.3446 (0.3446) ([0.213]+[0.132])	Prec@1 94.531 (94.531)
 * Prec@1 93.650
current lr 1.00000e-03
Grad=  tensor(0.5148, device='cuda:0')
Epoch: [273][0/391]	Time 0.248 (0.248)	Data 0.127 (0.127)	Loss 0.1386 (0.1386) ([0.007]+[0.132])	Prec@1 100.000 (100.000)
Epoch: [273][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1370 (0.1418) ([0.005]+[0.132])	Prec@1 100.000 (99.814)
Epoch: [273][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1428 (0.1421) ([0.011]+[0.131])	Prec@1 100.000 (99.813)
Epoch: [273][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1397 (0.1424) ([0.008]+[0.131])	Prec@1 100.000 (99.808)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.3391 (0.3391) ([0.208]+[0.131])	Prec@1 93.750 (93.750)
 * Prec@1 93.630
current lr 1.00000e-03
Grad=  tensor(2.2464, device='cuda:0')
Epoch: [274][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.1510 (0.1510) ([0.020]+[0.131])	Prec@1 100.000 (100.000)
Epoch: [274][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1362 (0.1421) ([0.005]+[0.131])	Prec@1 100.000 (99.814)
Epoch: [274][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1386 (0.1413) ([0.008]+[0.131])	Prec@1 100.000 (99.856)
Epoch: [274][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1545 (0.1413) ([0.024]+[0.131])	Prec@1 99.219 (99.852)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.3409 (0.3409) ([0.210]+[0.131])	Prec@1 94.531 (94.531)
 * Prec@1 93.760
current lr 1.00000e-03
Grad=  tensor(0.2025, device='cuda:0')
Epoch: [275][0/391]	Time 0.243 (0.243)	Data 0.121 (0.121)	Loss 0.1357 (0.1357) ([0.005]+[0.131])	Prec@1 100.000 (100.000)
Epoch: [275][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1403 (0.1403) ([0.010]+[0.131])	Prec@1 100.000 (99.845)
Epoch: [275][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1509 (0.1403) ([0.020]+[0.131])	Prec@1 99.219 (99.848)
Epoch: [275][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1466 (0.1402) ([0.016]+[0.131])	Prec@1 100.000 (99.857)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.3779 (0.3779) ([0.248]+[0.130])	Prec@1 95.312 (95.312)
 * Prec@1 93.760
current lr 1.00000e-03
Grad=  tensor(0.2531, device='cuda:0')
Epoch: [276][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.1351 (0.1351) ([0.005]+[0.130])	Prec@1 100.000 (100.000)
Epoch: [276][100/391]	Time 0.109 (0.112)	Data 0.000 (0.001)	Loss 0.1409 (0.1395) ([0.011]+[0.130])	Prec@1 100.000 (99.884)
Epoch: [276][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1342 (0.1402) ([0.004]+[0.130])	Prec@1 100.000 (99.841)
Epoch: [276][300/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.1427 (0.1403) ([0.013]+[0.130])	Prec@1 100.000 (99.839)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.3603 (0.3603) ([0.230]+[0.130])	Prec@1 94.531 (94.531)
 * Prec@1 93.700
current lr 1.00000e-03
Grad=  tensor(0.5445, device='cuda:0')
Epoch: [277][0/391]	Time 0.257 (0.257)	Data 0.136 (0.136)	Loss 0.1394 (0.1394) ([0.009]+[0.130])	Prec@1 100.000 (100.000)
Epoch: [277][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1343 (0.1390) ([0.004]+[0.130])	Prec@1 100.000 (99.876)
Epoch: [277][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1360 (0.1393) ([0.006]+[0.130])	Prec@1 100.000 (99.880)
Epoch: [277][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.1396 (0.1395) ([0.010]+[0.130])	Prec@1 100.000 (99.878)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.3370 (0.3370) ([0.207]+[0.130])	Prec@1 94.531 (94.531)
 * Prec@1 93.660
current lr 1.00000e-03
Grad=  tensor(0.3621, device='cuda:0')
Epoch: [278][0/391]	Time 0.236 (0.236)	Data 0.116 (0.116)	Loss 0.1368 (0.1368) ([0.007]+[0.130])	Prec@1 100.000 (100.000)
Epoch: [278][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1385 (0.1390) ([0.009]+[0.130])	Prec@1 100.000 (99.869)
Epoch: [278][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1340 (0.1389) ([0.005]+[0.129])	Prec@1 100.000 (99.876)
Epoch: [278][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.1359 (0.1389) ([0.007]+[0.129])	Prec@1 100.000 (99.860)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.3690 (0.3690) ([0.240]+[0.129])	Prec@1 94.531 (94.531)
 * Prec@1 93.650
current lr 1.00000e-03
Grad=  tensor(2.2495, device='cuda:0')
Epoch: [279][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.1425 (0.1425) ([0.013]+[0.129])	Prec@1 99.219 (99.219)
Epoch: [279][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1494 (0.1400) ([0.020]+[0.129])	Prec@1 99.219 (99.783)
Epoch: [279][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1368 (0.1397) ([0.008]+[0.129])	Prec@1 100.000 (99.802)
Epoch: [279][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.1356 (0.1390) ([0.007]+[0.129])	Prec@1 100.000 (99.831)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.3499 (0.3499) ([0.221]+[0.129])	Prec@1 93.750 (93.750)
 * Prec@1 93.770
current lr 1.00000e-03
Grad=  tensor(0.7581, device='cuda:0')
Epoch: [280][0/391]	Time 0.244 (0.244)	Data 0.125 (0.125)	Loss 0.1365 (0.1365) ([0.008]+[0.129])	Prec@1 100.000 (100.000)
Epoch: [280][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1389 (0.1376) ([0.010]+[0.129])	Prec@1 99.219 (99.907)
Epoch: [280][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1387 (0.1377) ([0.010]+[0.129])	Prec@1 100.000 (99.887)
Epoch: [280][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1415 (0.1377) ([0.013]+[0.129])	Prec@1 100.000 (99.878)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.3433 (0.3433) ([0.215]+[0.128])	Prec@1 96.094 (96.094)
 * Prec@1 93.650
current lr 1.00000e-03
Grad=  tensor(0.3984, device='cuda:0')
Epoch: [281][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.1355 (0.1355) ([0.007]+[0.128])	Prec@1 100.000 (100.000)
Epoch: [281][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1311 (0.1382) ([0.003]+[0.128])	Prec@1 100.000 (99.892)
Epoch: [281][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1320 (0.1375) ([0.004]+[0.128])	Prec@1 100.000 (99.903)
Epoch: [281][300/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.1336 (0.1374) ([0.005]+[0.128])	Prec@1 100.000 (99.896)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3541 (0.3541) ([0.226]+[0.128])	Prec@1 96.094 (96.094)
 * Prec@1 93.890
current lr 1.00000e-03
Grad=  tensor(0.5844, device='cuda:0')
Epoch: [282][0/391]	Time 0.243 (0.243)	Data 0.121 (0.121)	Loss 0.1351 (0.1351) ([0.007]+[0.128])	Prec@1 100.000 (100.000)
Epoch: [282][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1379 (0.1379) ([0.010]+[0.128])	Prec@1 100.000 (99.791)
Epoch: [282][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1309 (0.1377) ([0.003]+[0.128])	Prec@1 100.000 (99.817)
Epoch: [282][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1397 (0.1370) ([0.012]+[0.128])	Prec@1 99.219 (99.842)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.3565 (0.3565) ([0.229]+[0.128])	Prec@1 94.531 (94.531)
 * Prec@1 93.920
current lr 1.00000e-03
Grad=  tensor(0.2988, device='cuda:0')
Epoch: [283][0/391]	Time 0.246 (0.246)	Data 0.124 (0.124)	Loss 0.1318 (0.1318) ([0.004]+[0.128])	Prec@1 100.000 (100.000)
Epoch: [283][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1469 (0.1359) ([0.019]+[0.128])	Prec@1 99.219 (99.892)
Epoch: [283][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1401 (0.1360) ([0.013]+[0.128])	Prec@1 100.000 (99.883)
Epoch: [283][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1460 (0.1361) ([0.019]+[0.127])	Prec@1 100.000 (99.868)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.3415 (0.3415) ([0.214]+[0.127])	Prec@1 95.312 (95.312)
 * Prec@1 93.820
current lr 1.00000e-03
Grad=  tensor(0.5899, device='cuda:0')
Epoch: [284][0/391]	Time 0.236 (0.236)	Data 0.114 (0.114)	Loss 0.1352 (0.1352) ([0.008]+[0.127])	Prec@1 100.000 (100.000)
Epoch: [284][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1471 (0.1360) ([0.020]+[0.127])	Prec@1 99.219 (99.892)
Epoch: [284][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1323 (0.1359) ([0.005]+[0.127])	Prec@1 100.000 (99.868)
Epoch: [284][300/391]	Time 0.111 (0.110)	Data 0.000 (0.000)	Loss 0.1443 (0.1361) ([0.017]+[0.127])	Prec@1 99.219 (99.847)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3570 (0.3570) ([0.230]+[0.127])	Prec@1 96.094 (96.094)
 * Prec@1 93.790
current lr 1.00000e-03
Grad=  tensor(0.7734, device='cuda:0')
Epoch: [285][0/391]	Time 0.242 (0.242)	Data 0.119 (0.119)	Loss 0.1351 (0.1351) ([0.008]+[0.127])	Prec@1 100.000 (100.000)
Epoch: [285][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1304 (0.1356) ([0.004]+[0.127])	Prec@1 100.000 (99.876)
Epoch: [285][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1331 (0.1350) ([0.006]+[0.127])	Prec@1 100.000 (99.887)
Epoch: [285][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.1365 (0.1350) ([0.010]+[0.127])	Prec@1 100.000 (99.899)
Test: [0/79]	Time 0.146 (0.146)	Loss 0.3586 (0.3586) ([0.232]+[0.127])	Prec@1 93.750 (93.750)
 * Prec@1 93.760
current lr 1.00000e-03
Grad=  tensor(0.1492, device='cuda:0')
Epoch: [286][0/391]	Time 0.255 (0.255)	Data 0.133 (0.133)	Loss 0.1292 (0.1292) ([0.003]+[0.127])	Prec@1 100.000 (100.000)
Epoch: [286][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1359 (0.1343) ([0.009]+[0.126])	Prec@1 100.000 (99.892)
Epoch: [286][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1287 (0.1345) ([0.002]+[0.126])	Prec@1 100.000 (99.880)
Epoch: [286][300/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1404 (0.1343) ([0.014]+[0.126])	Prec@1 99.219 (99.891)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.3587 (0.3587) ([0.233]+[0.126])	Prec@1 93.750 (93.750)
 * Prec@1 93.820
current lr 1.00000e-03
Grad=  tensor(0.4254, device='cuda:0')
Epoch: [287][0/391]	Time 0.242 (0.242)	Data 0.121 (0.121)	Loss 0.1326 (0.1326) ([0.006]+[0.126])	Prec@1 100.000 (100.000)
Epoch: [287][100/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.1285 (0.1337) ([0.002]+[0.126])	Prec@1 100.000 (99.899)
Epoch: [287][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1312 (0.1338) ([0.005]+[0.126])	Prec@1 100.000 (99.903)
Epoch: [287][300/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.1295 (0.1338) ([0.004]+[0.126])	Prec@1 100.000 (99.907)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3837 (0.3837) ([0.258]+[0.126])	Prec@1 93.750 (93.750)
 * Prec@1 93.910
current lr 1.00000e-03
Grad=  tensor(0.2464, device='cuda:0')
Epoch: [288][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.1294 (0.1294) ([0.004]+[0.126])	Prec@1 100.000 (100.000)
Epoch: [288][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1297 (0.1338) ([0.004]+[0.126])	Prec@1 100.000 (99.930)
Epoch: [288][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1320 (0.1339) ([0.006]+[0.126])	Prec@1 100.000 (99.907)
Epoch: [288][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.1298 (0.1337) ([0.004]+[0.125])	Prec@1 100.000 (99.899)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.3603 (0.3603) ([0.235]+[0.125])	Prec@1 93.750 (93.750)
 * Prec@1 93.990
current lr 1.00000e-03
Grad=  tensor(0.3766, device='cuda:0')
Epoch: [289][0/391]	Time 0.242 (0.242)	Data 0.121 (0.121)	Loss 0.1304 (0.1304) ([0.005]+[0.125])	Prec@1 100.000 (100.000)
Epoch: [289][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1354 (0.1322) ([0.010]+[0.125])	Prec@1 100.000 (99.923)
Epoch: [289][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.1314 (0.1326) ([0.006]+[0.125])	Prec@1 100.000 (99.907)
Epoch: [289][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.1320 (0.1332) ([0.007]+[0.125])	Prec@1 100.000 (99.883)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.3670 (0.3670) ([0.242]+[0.125])	Prec@1 94.531 (94.531)
 * Prec@1 93.770
current lr 1.00000e-03
Grad=  tensor(1.5499, device='cuda:0')
Epoch: [290][0/391]	Time 0.249 (0.249)	Data 0.128 (0.128)	Loss 0.1338 (0.1338) ([0.009]+[0.125])	Prec@1 100.000 (100.000)
Epoch: [290][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1279 (0.1332) ([0.003]+[0.125])	Prec@1 100.000 (99.884)
Epoch: [290][200/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.1324 (0.1326) ([0.008]+[0.125])	Prec@1 100.000 (99.911)
Epoch: [290][300/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.1271 (0.1325) ([0.002]+[0.125])	Prec@1 100.000 (99.909)
Test: [0/79]	Time 0.153 (0.153)	Loss 0.3559 (0.3559) ([0.231]+[0.125])	Prec@1 94.531 (94.531)
 * Prec@1 93.690
current lr 1.00000e-03
Grad=  tensor(1.9322, device='cuda:0')
Epoch: [291][0/391]	Time 0.243 (0.243)	Data 0.121 (0.121)	Loss 0.1351 (0.1351) ([0.010]+[0.125])	Prec@1 100.000 (100.000)
Epoch: [291][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.1440 (0.1314) ([0.019]+[0.125])	Prec@1 99.219 (99.915)
Epoch: [291][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1313 (0.1317) ([0.007]+[0.124])	Prec@1 100.000 (99.911)
Epoch: [291][300/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1326 (0.1319) ([0.008]+[0.124])	Prec@1 100.000 (99.891)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3673 (0.3673) ([0.243]+[0.124])	Prec@1 94.531 (94.531)
 * Prec@1 93.740
current lr 1.00000e-03
Grad=  tensor(1.0517, device='cuda:0')
Epoch: [292][0/391]	Time 0.239 (0.239)	Data 0.117 (0.117)	Loss 0.1346 (0.1346) ([0.010]+[0.124])	Prec@1 100.000 (100.000)
Epoch: [292][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1291 (0.1305) ([0.005]+[0.124])	Prec@1 100.000 (99.938)
Epoch: [292][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1291 (0.1306) ([0.005]+[0.124])	Prec@1 100.000 (99.946)
Epoch: [292][300/391]	Time 0.112 (0.111)	Data 0.000 (0.000)	Loss 0.1304 (0.1309) ([0.006]+[0.124])	Prec@1 100.000 (99.927)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.3594 (0.3594) ([0.235]+[0.124])	Prec@1 94.531 (94.531)
 * Prec@1 93.660
current lr 1.00000e-03
Grad=  tensor(0.6688, device='cuda:0')
Epoch: [293][0/391]	Time 0.241 (0.241)	Data 0.119 (0.119)	Loss 0.1318 (0.1318) ([0.008]+[0.124])	Prec@1 100.000 (100.000)
Epoch: [293][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1258 (0.1303) ([0.002]+[0.124])	Prec@1 100.000 (99.915)
Epoch: [293][200/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.1310 (0.1308) ([0.007]+[0.124])	Prec@1 100.000 (99.914)
Epoch: [293][300/391]	Time 0.110 (0.110)	Data 0.000 (0.000)	Loss 0.1384 (0.1307) ([0.015]+[0.124])	Prec@1 99.219 (99.914)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.4045 (0.4045) ([0.281]+[0.124])	Prec@1 93.750 (93.750)
 * Prec@1 93.630
current lr 1.00000e-03
Grad=  tensor(1.5460, device='cuda:0')
Epoch: [294][0/391]	Time 0.238 (0.238)	Data 0.116 (0.116)	Loss 0.1318 (0.1318) ([0.008]+[0.124])	Prec@1 100.000 (100.000)
Epoch: [294][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1294 (0.1306) ([0.006]+[0.123])	Prec@1 100.000 (99.930)
Epoch: [294][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1264 (0.1310) ([0.003]+[0.123])	Prec@1 100.000 (99.891)
Epoch: [294][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1394 (0.1311) ([0.016]+[0.123])	Prec@1 100.000 (99.894)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.3829 (0.3829) ([0.260]+[0.123])	Prec@1 93.750 (93.750)
 * Prec@1 93.710
current lr 1.00000e-03
Grad=  tensor(0.5389, device='cuda:0')
Epoch: [295][0/391]	Time 0.240 (0.240)	Data 0.119 (0.119)	Loss 0.1296 (0.1296) ([0.006]+[0.123])	Prec@1 100.000 (100.000)
Epoch: [295][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1300 (0.1305) ([0.007]+[0.123])	Prec@1 100.000 (99.923)
Epoch: [295][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1387 (0.1303) ([0.016]+[0.123])	Prec@1 100.000 (99.926)
Epoch: [295][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.1317 (0.1300) ([0.009]+[0.123])	Prec@1 100.000 (99.922)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.3644 (0.3644) ([0.242]+[0.123])	Prec@1 92.969 (92.969)
 * Prec@1 93.810
current lr 1.00000e-03
Grad=  tensor(0.2221, device='cuda:0')
Epoch: [296][0/391]	Time 0.244 (0.244)	Data 0.125 (0.125)	Loss 0.1260 (0.1260) ([0.003]+[0.123])	Prec@1 100.000 (100.000)
Epoch: [296][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1381 (0.1309) ([0.015]+[0.123])	Prec@1 100.000 (99.830)
Epoch: [296][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1272 (0.1304) ([0.005]+[0.123])	Prec@1 100.000 (99.868)
Epoch: [296][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1328 (0.1300) ([0.010]+[0.122])	Prec@1 100.000 (99.886)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.3607 (0.3607) ([0.238]+[0.122])	Prec@1 94.531 (94.531)
 * Prec@1 93.710
current lr 1.00000e-03
Grad=  tensor(0.2087, device='cuda:0')
Epoch: [297][0/391]	Time 0.254 (0.254)	Data 0.133 (0.133)	Loss 0.1262 (0.1262) ([0.004]+[0.122])	Prec@1 100.000 (100.000)
Epoch: [297][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1294 (0.1290) ([0.007]+[0.122])	Prec@1 100.000 (99.938)
Epoch: [297][200/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.1453 (0.1293) ([0.023]+[0.122])	Prec@1 99.219 (99.922)
Epoch: [297][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1272 (0.1291) ([0.005]+[0.122])	Prec@1 100.000 (99.917)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.3587 (0.3587) ([0.237]+[0.122])	Prec@1 92.969 (92.969)
 * Prec@1 93.740
current lr 1.00000e-03
Grad=  tensor(0.1378, device='cuda:0')
Epoch: [298][0/391]	Time 0.247 (0.247)	Data 0.124 (0.124)	Loss 0.1239 (0.1239) ([0.002]+[0.122])	Prec@1 100.000 (100.000)
Epoch: [298][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1264 (0.1284) ([0.004]+[0.122])	Prec@1 100.000 (99.899)
Epoch: [298][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1262 (0.1286) ([0.004]+[0.122])	Prec@1 100.000 (99.899)
Epoch: [298][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1260 (0.1286) ([0.004]+[0.122])	Prec@1 100.000 (99.904)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.3583 (0.3583) ([0.237]+[0.122])	Prec@1 92.969 (92.969)
 * Prec@1 93.880
current lr 1.00000e-03
Grad=  tensor(0.6790, device='cuda:0')
Epoch: [299][0/391]	Time 0.240 (0.240)	Data 0.119 (0.119)	Loss 0.1292 (0.1292) ([0.008]+[0.122])	Prec@1 100.000 (100.000)
Epoch: [299][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1305 (0.1279) ([0.009]+[0.122])	Prec@1 100.000 (99.969)
Epoch: [299][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1237 (0.1280) ([0.002]+[0.121])	Prec@1 100.000 (99.938)
Epoch: [299][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1317 (0.1279) ([0.010]+[0.121])	Prec@1 100.000 (99.935)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.3504 (0.3504) ([0.229]+[0.121])	Prec@1 93.750 (93.750)
 * Prec@1 93.800

 Elapsed time for training  3:52:22.590003

 sparsity of   [0.0, 0.0, 0.5555555820465088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7777777910232544, 0.0, 0.0, 0.0, 0.9629629850387573, 0.9629629850387573, 0.9629629850387573, 0.5555555820465088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9629629850387573, 0.0, 0.0, 0.0, 0.9629629850387573, 0.9259259104728699, 0.0, 0.0, 0.9259259104728699, 0.7037037014961243, 0.7407407760620117, 0.0, 0.8518518805503845, 0.0, 0.8518518805503845, 0.8888888955116272, 0.0, 0.0, 0.0, 0.0, 0.9629629850387573, 0.0, 0.7407407760620117, 0.7037037014961243, 0.7407407760620117, 0.0, 0.9259259104728699, 0.0, 0.0, 0.0, 0.9629629850387573, 0.9629629850387573, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [0.984375, 0.984375, 0.0, 0.0, 0.0, 0.96875, 0.984375, 0.984375, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.984375, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.96875, 0.96875, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.96875, 0.34375, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.984375, 0.0, 0.0]

 sparsity of   [0.0, 0.9965277910232544, 0.0, 0.9982638955116272, 0.9965277910232544, 0.0, 0.9965277910232544, 0.9965277910232544, 0.9982638955116272, 0.9965277910232544, 0.0, 0.9965277910232544, 0.9965277910232544, 0.0, 0.9965277910232544, 0.9965277910232544, 0.0, 0.0, 0.0, 0.9982638955116272, 0.9982638955116272, 0.0, 0.0, 0.9965277910232544, 0.9965277910232544, 0.9982638955116272, 0.0, 0.9965277910232544, 0.0, 0.0, 0.9982638955116272, 0.0, 0.9965277910232544, 0.9965277910232544, 0.0, 0.9965277910232544, 0.9965277910232544, 0.0, 0.9965277910232544, 0.0, 0.0, 0.9982638955116272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9965277910232544, 0.0, 0.9965277910232544, 0.0, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.0, 0.0, 0.9965277910232544, 0.9965277910232544, 0.0, 0.9965277910232544, 0.0, 0.0, 0.9982638955116272]

 sparsity of   [0.0, 0.0, 0.0, 0.53125, 0.0, 0.96875, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.953125, 0.0, 0.0, 0.0, 0.0, 0.203125, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.96875, 0.96875, 0.0, 0.96875, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.546875, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.140625, 0.984375, 0.0, 0.96875, 0.0, 0.515625, 0.0, 0.0, 0.0, 0.96875, 0.09375, 0.96875, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.53125, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.109375, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.53125, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.984375, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.96875, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.453125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.453125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15625, 0.96875, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.34375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.96875, 0.0, 0.34375, 0.0, 0.0, 0.0, 0.96875, 0.96875, 0.96875, 0.34375, 0.96875, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.96875, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.96875, 0.96875, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.96875, 0.96875, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.921875, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34375, 0.984375, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.96875, 0.0, 0.34375, 0.0, 0.96875, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.34375, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.96875, 0.0, 0.0, 0.0, 0.4375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.96875, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.984375, 0.0]

 sparsity of   [0.9921875, 0.9921875, 0.0, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.22265625, 0.9921875, 0.0, 0.22265625, 0.21875, 0.22265625, 0.9921875, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.22265625, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.98828125, 0.22265625, 0.0, 0.9921875, 0.99609375, 0.22265625, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.22265625, 0.0, 0.9921875, 0.22265625, 0.9921875, 0.0, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.9965277910232544, 0.9965277910232544, 0.0, 0.0, 0.4375, 0.4375, 0.4375, 0.9965277910232544, 0.9965277910232544, 0.9982638955116272, 0.0, 0.9965277910232544, 0.9965277910232544, 0.0, 0.9965277910232544, 0.9982638955116272, 0.0, 0.9965277910232544, 0.0, 0.0, 0.0, 0.9965277910232544, 0.0, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.9982638955116272, 0.0, 0.9965277910232544, 0.0, 0.0, 0.9965277910232544, 0.0, 0.0, 0.0, 0.9965277910232544, 0.9965277910232544, 0.0, 0.9965277910232544, 0.0, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.0, 0.9982638955116272, 0.0, 0.0, 0.9965277910232544, 0.0, 0.0, 0.9965277910232544, 0.9965277910232544, 0.0, 0.0, 0.4375, 0.9965277910232544, 0.0, 0.0, 0.0, 0.9965277910232544]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.453125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.453125, 0.0, 0.0, 0.0, 0.453125, 0.0, 0.453125, 0.0, 0.0, 0.0, 0.0, 0.453125, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.453125, 0.0, 0.453125, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.453125, 0.453125, 0.0, 0.0, 0.453125, 0.453125, 0.453125, 0.0, 0.0, 0.96875, 0.0, 0.453125, 0.453125, 0.0, 0.0, 0.0, 0.0, 0.203125, 0.453125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.453125, 0.0, 0.453125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.453125, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.453125, 0.0, 0.0, 0.96875, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.453125, 0.0, 0.0, 0.453125, 0.453125, 0.0, 0.453125, 0.0, 0.0, 0.453125, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.453125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.453125, 0.96875, 0.0, 0.0, 0.453125, 0.0, 0.0, 0.0, 0.9375, 0.0, 0.0, 0.0, 0.0, 0.453125, 0.96875, 0.0, 0.0, 0.0, 0.40625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.453125, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.453125, 0.0, 0.453125, 0.0, 0.453125, 0.453125, 0.453125, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.453125, 0.0, 0.0, 0.453125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.453125]

 sparsity of   [0.0, 0.0, 0.22265625, 0.0, 0.01953125, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08984375, 0.0, 0.0, 0.0, 0.0, 0.48828125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0390625, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.12890625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6640625, 0.9921875, 0.984375, 0.9921875, 0.00390625, 0.0, 0.375, 0.0, 0.12890625, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.1015625, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0086805559694767, 0.0, 0.1128472238779068, 0.0, 0.1336805522441864, 0.0, 0.0, 0.03125, 0.0607638880610466, 0.126736119389534, 0.9461805820465088, 0.0, 0.9965277910232544, 0.0, 0.0434027798473835, 0.84375, 0.0225694440305233, 0.9982638955116272, 0.0, 0.0, 0.1822916716337204, 0.0, 0.0, 0.0, 0.0, 0.9965277910232544, 0.0, 0.02604166604578495, 0.0, 0.0, 0.0243055559694767, 0.0, 0.0, 0.0, 0.0, 0.0607638880610466, 0.0, 0.0381944440305233, 0.0, 0.0, 0.0, 0.0, 0.0434027798473835, 0.0, 0.8854166865348816, 0.0, 0.0, 0.0729166641831398, 0.013888888992369175, 0.0, 0.0, 0.0, 0.0590277798473835, 0.0, 0.0, 0.0, 0.0, 0.0225694440305233, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 0.359375, 0.0, 0.0, 0.359375, 0.0, 0.0, 0.0, 0.0, 0.359375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046875, 0.0, 0.359375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.359375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03125, 0.0, 0.359375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21875, 0.359375, 0.0, 0.0, 0.0625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.046875, 0.0, 0.359375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.359375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.359375, 0.34375, 0.0, 0.0, 0.0, 0.359375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.359375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.359375, 0.0, 0.0, 0.0, 0.359375, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.359375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.34375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.140625, 0.0, 0.0, 0.0, 0.0, 0.34375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05859375, 0.9921875, 0.0078125, 0.0, 0.01953125, 0.0, 0.0, 0.3359375, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0234375, 0.9921875, 0.3828125, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.98828125, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.98828125, 0.0, 0.0, 0.0, 0.0, 0.87890625, 0.01953125, 0.18359375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0390625, 0.99609375, 0.0, 0.0, 0.9921875, 0.01171875, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41796875, 0.0, 0.0078125, 0.0, 0.0, 0.44140625, 0.0, 0.0, 0.9921875, 0.98828125, 0.9921875, 0.0, 0.98828125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.98828125, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.78515625, 0.0, 0.0, 0.0, 0.07421875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.99609375]

 sparsity of   [0.0, 0.0, 0.02170138992369175, 0.0225694440305233, 0.9322916865348816, 0.02777777798473835, 0.0, 0.0407986119389534, 0.1189236119389534, 0.0486111119389534, 0.0434027798473835, 0.0, 0.9973958134651184, 0.0, 0.0, 0.8385416865348816, 0.8932291865348816, 0.02777777798473835, 0.0755208358168602, 0.0, 0.7838541865348816, 0.1059027761220932, 0.999131977558136, 0.0494791679084301, 0.0, 0.0086805559694767, 0.9973958134651184, 0.0, 0.0442708320915699, 0.0, 0.0173611119389534, 0.0607638880610466, 0.0, 0.0, 0.0, 0.0494791679084301, 0.9982638955116272, 0.0, 0.0, 0.0720486119389534, 0.02690972201526165, 0.9565972089767456, 0.0, 0.014756944961845875, 0.0, 0.0, 0.0555555559694767, 0.0, 0.8003472089767456, 0.0, 0.9982638955116272, 0.0, 0.0, 0.0, 0.0, 0.0399305559694767, 0.0616319440305233, 0.9982638955116272, 0.0381944440305233, 0.0303819440305233, 0.0, 0.9340277910232544, 0.1032986119389534, 0.0894097238779068, 0.9192708134651184, 0.181423619389534, 0.0, 0.0, 0.3576388955116272, 0.1362847238779068, 0.0399305559694767, 0.02864583395421505, 0.0, 0.02604166604578495, 0.02690972201526165, 0.0677083358168602, 0.8385416865348816, 0.0, 0.0, 0.0598958320915699, 0.015625, 0.0, 0.0, 0.0, 0.0520833320915699, 0.0442708320915699, 0.0303819440305233, 0.0, 0.0, 0.0703125, 0.03125, 0.0, 0.0, 0.0460069440305233, 0.9973958134651184, 0.0, 0.0, 0.9409722089767456, 0.02170138992369175, 0.0399305559694767, 0.0, 0.1059027761220932, 0.0, 0.0694444477558136, 0.0, 0.9982638955116272, 0.0, 0.0, 0.01909722201526165, 0.0, 0.0381944440305233, 0.0, 0.0, 0.0, 0.02951388992369175, 0.0, 0.0, 0.0494791679084301, 0.9114583134651184, 0.9244791865348816, 0.0, 0.0, 0.8958333134651184, 0.9982638955116272, 0.0, 0.0555555559694767, 0.9192708134651184, 0.0]

 sparsity of   [0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.078125, 0.0, 0.9765625, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.390625, 0.984375, 0.0, 0.0, 0.9765625, 0.0, 0.0, 0.984375, 0.0, 0.3984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9765625, 0.0, 0.0, 0.0, 0.5703125, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.984375, 0.9765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9765625, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.984375, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9609375, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.2734375, 0.5703125, 0.609375, 0.984375, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.5625, 0.9921875, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.4765625, 0.0, 0.0, 0.5703125, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5703125, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.5703125, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9765625, 0.5703125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.9765625, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.9921875, 0.53125, 0.9765625, 0.0, 0.9765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5703125, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.9921875, 0.984375, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.984375, 0.9921875, 0.0, 0.0, 0.0, 0.5703125, 0.0, 0.984375, 0.9921875, 0.5703125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.265625, 0.0, 0.0, 0.984375, 0.0, 0.5703125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.484375, 0.9921875, 0.0, 0.0, 0.0, 0.2734375, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.5703125, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.5703125, 0.0, 0.0, 0.0, 0.984375, 0.5703125, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.5703125, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.75, 0.0, 0.5703125, 0.984375, 0.0, 0.5703125, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.5703125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.984375, 0.9921875, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9765625, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5625, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.9921875, 0.0, 0.5703125, 0.0, 0.515625, 0.3671875, 0.3203125, 0.9921875, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.5703125, 0.5703125, 0.0, 0.0, 0.9921875, 0.0, 0.984375, 0.984375, 0.0, 0.5703125, 0.9921875, 0.984375, 0.0, 0.0, 0.9921875, 0.984375, 0.5703125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.09375, 0.984375, 0.5703125, 0.0, 0.0, 0.9921875, 0.0, 0.984375, 0.984375, 0.4296875, 0.0]

 sparsity of   [0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.99609375, 0.9921875, 0.0, 0.0, 0.9921875, 0.01953125, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.01953125, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.01953125, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.01953125, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.9921875, 0.9921875, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.9921875, 0.0, 0.01953125, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.01953125, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.01953125, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.01953125, 0.01953125, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0]

 sparsity of   [0.998046875, 0.99609375, 0.234375, 0.0, 0.234375, 0.0, 0.0, 0.998046875, 0.0, 0.234375, 0.0, 0.99609375, 0.0, 0.99609375, 0.998046875, 0.99609375, 0.994140625, 0.234375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.998046875, 0.234375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.0, 0.234375, 0.99609375, 0.234375, 0.0, 0.998046875, 0.99609375, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.234375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.234375, 0.9921875, 0.0, 0.998046875, 0.0, 0.99609375, 0.998046875, 0.998046875, 0.99609375, 0.234375, 0.0, 0.99609375, 0.998046875, 0.99609375, 0.2265625, 0.99609375, 0.994140625, 0.99609375, 0.0, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.998046875, 0.998046875, 0.99609375, 0.998046875, 0.99609375, 0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.994140625, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.234375, 0.0, 0.998046875, 0.234375, 0.99609375, 0.99609375, 0.99609375, 0.234375, 0.0, 0.99609375, 0.994140625, 0.0, 0.234375, 0.0, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.998046875, 0.99609375, 0.998046875, 0.99609375, 0.0, 0.99609375, 0.0, 0.994140625, 0.0, 0.0, 0.234375, 0.0, 0.998046875, 0.0, 0.99609375, 0.0, 0.505859375, 0.99609375]

 sparsity of   [0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.0, 0.0, 0.9982638955116272, 0.9982638955116272, 0.999131977558136, 0.9982638955116272, 0.9982638955116272, 0.999131977558136, 0.9982638955116272, 0.0, 0.9982638955116272, 0.999131977558136, 0.9982638955116272, 0.9982638955116272, 0.0, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.9982638955116272, 0.999131977558136, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.0, 0.9982638955116272, 0.9982638955116272, 0.0, 0.0, 0.0, 0.9982638955116272, 0.999131977558136, 0.0, 0.9982638955116272, 0.999131977558136, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.0, 0.9982638955116272, 0.9982638955116272, 0.0, 0.0, 0.0, 0.9982638955116272, 0.0, 0.9982638955116272, 0.999131977558136, 0.9982638955116272, 0.0, 0.0, 0.0, 0.999131977558136, 0.999131977558136, 0.9982638955116272, 0.9982638955116272, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.9982638955116272, 0.0, 0.9982638955116272, 0.9982638955116272, 0.0, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.0, 0.0, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.0, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.0, 0.999131977558136, 0.9982638955116272, 0.9982638955116272, 0.999131977558136, 0.9982638955116272, 0.0, 0.999131977558136, 0.0, 0.9982638955116272, 0.0, 0.9982638955116272, 0.0, 0.0, 0.9982638955116272, 0.999131977558136, 0.0, 0.999131977558136, 0.9982638955116272, 0.999131977558136, 0.999131977558136, 0.9982638955116272, 0.999131977558136]

 sparsity of   [0.0, 0.75, 0.0, 0.0, 0.0, 0.75, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15625, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.75, 0.0, 0.75, 0.0, 0.75, 0.0, 0.0, 0.75, 0.75, 0.0, 0.75, 0.0, 0.9921875, 0.75, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1796875, 0.9921875, 0.0, 0.75, 0.984375, 0.0, 0.75, 0.984375, 0.75, 0.984375, 0.0, 0.0, 0.0, 0.75, 0.75, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.75, 0.0, 0.0, 0.75, 0.0, 0.75, 0.0, 0.75, 0.0, 0.75, 0.0, 0.0, 0.0, 0.75, 0.0, 0.75, 0.0, 0.75, 0.75, 0.984375, 0.0, 0.75, 0.75, 0.984375, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.75, 0.0, 0.9765625, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.1015625, 0.0, 0.0, 0.9921875, 0.984375, 0.0, 0.984375, 0.0, 0.75, 0.75, 0.75, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.984375, 0.75, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.171875, 0.0, 0.75, 0.0, 0.8046875, 0.0, 0.9765625, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.75, 0.0, 0.75, 0.75, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.75, 0.0, 0.2109375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.75, 0.75, 0.0, 0.75, 0.0, 0.0546875, 0.984375, 0.75, 0.0, 0.0, 0.0, 0.984375, 0.75, 0.0, 0.0, 0.703125, 0.0, 0.75, 0.0, 0.0, 0.1484375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.75, 0.0, 0.0, 0.0, 0.75, 0.75, 0.75, 0.984375, 0.0, 0.0859375, 0.75, 0.75, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.75, 0.75, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.75, 0.0, 0.75, 0.0, 0.0, 0.0, 0.1796875, 0.7109375, 0.9765625, 0.0, 0.0, 0.0, 0.9765625, 0.0, 0.0, 0.0, 0.9765625, 0.0, 0.0, 0.0, 0.9765625, 0.0, 0.9921875, 0.75, 0.75, 0.75, 0.0, 0.0, 0.75, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.75, 0.8671875, 0.0, 0.1796875, 0.0, 0.0, 0.75, 0.0, 0.0703125, 0.0, 0.75, 0.984375, 0.0, 0.75, 0.0, 0.0, 0.0, 0.75, 0.75, 0.75, 0.0, 0.984375, 0.75, 0.75, 0.984375, 0.0, 0.0, 0.75, 0.984375, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.984375, 0.75, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.75, 0.984375, 0.75, 0.0, 0.0, 0.75, 0.75, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.984375, 0.0, 0.0, 0.75, 0.75, 0.0, 0.0, 0.9921875, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.75, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.984375, 0.1015625, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.75, 0.75, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.75, 0.9765625, 0.75, 0.75, 0.0, 0.0, 0.0, 0.34375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.109375, 0.0, 0.0, 0.0, 0.0, 0.0546875, 0.1171875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.984375, 0.328125, 0.1953125, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.4609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7890625, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.75, 0.0, 0.75, 0.7109375, 0.0, 0.9921875, 0.75, 0.0, 0.0, 0.75, 0.75, 0.0, 0.0, 0.984375, 0.0, 0.75, 0.0, 0.0, 0.75, 0.0, 0.3203125, 0.0, 0.0, 0.9765625, 0.4296875, 0.0, 0.9921875, 0.75, 0.984375, 0.75, 0.75, 0.0, 0.984375, 0.0, 0.0859375, 0.984375, 0.984375, 0.0]

 sparsity of   [0.0, 0.013671875, 0.0, 0.0, 0.0, 0.923828125, 0.0, 0.10546875, 0.158203125, 0.0859375, 0.0, 0.0, 0.0546875, 0.064453125, 0.05078125, 0.0, 0.572265625, 0.08203125, 0.0, 0.0, 0.994140625, 0.0, 0.021484375, 0.0, 0.0, 0.119140625, 0.12109375, 0.013671875, 0.0, 0.142578125, 0.0, 0.0, 0.0, 0.48828125, 0.0, 0.0, 0.033203125, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05859375, 0.0, 0.15234375, 0.98828125, 0.0, 0.0, 0.0, 0.8828125, 0.0, 0.99609375, 0.044921875, 0.0390625, 0.138671875, 0.140625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11328125, 0.0, 0.13671875, 0.14453125, 0.0, 0.0, 0.0859375, 0.99609375, 0.185546875, 0.0, 0.0, 0.998046875, 0.99609375, 0.0, 0.0, 0.0234375, 0.146484375, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.03125, 0.015625, 0.994140625, 0.0, 0.994140625, 0.01953125, 0.12890625, 0.0, 0.0, 0.08984375, 0.0, 0.994140625, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.033203125, 0.037109375, 0.0, 0.99609375, 0.021484375, 0.0, 0.0, 0.080078125, 0.078125, 0.0, 0.0, 0.0, 0.10546875, 0.0, 0.0, 0.0, 0.06640625]

 sparsity of   [0.0017361111240461469, 0.02690972201526165, 0.01215277798473835, 0.9982638955116272, 0.8472222089767456, 0.02690972201526165, 0.0, 0.1076388880610466, 0.7734375, 0.0, 0.03125, 0.01996527798473835, 0.7039930820465088, 0.8420138955116272, 0.8055555820465088, 0.01128472201526165, 0.0008680555620230734, 0.0, 0.1527777761220932, 0.0746527761220932, 0.0668402761220932, 0.0, 0.02777777798473835, 0.0590277798473835, 0.0425347238779068, 0.0, 0.0, 0.1857638955116272, 0.9392361044883728, 0.0, 0.6822916865348816, 0.0503472238779068, 0.0, 0.009548611007630825, 0.5104166865348816, 0.1883680522441864, 0.0, 0.8532986044883728, 0.0, 0.0720486119389534, 0.0390625, 0.0, 0.0, 0.0, 0.0, 0.1875, 0.9973958134651184, 0.0, 0.0, 0.1032986119389534, 0.0, 0.0399305559694767, 0.0, 0.0, 0.01822916604578495, 0.0989583358168602, 0.1189236119389534, 0.0, 0.1944444477558136, 0.0, 0.01996527798473835, 0.009548611007630825, 0.0, 0.0, 0.0, 0.0902777761220932, 0.9973958134651184, 0.2456597238779068, 0.0746527761220932, 0.02604166604578495, 0.0625, 0.0, 0.014756944961845875, 0.010416666977107525, 0.8776041865348816, 0.0, 0.0, 0.0251736119389534, 0.0729166641831398, 0.0329861119389534, 0.0668402761220932, 0.013888888992369175, 0.0, 0.0460069440305233, 0.0, 0.0720486119389534, 0.01822916604578495, 0.0, 0.125, 0.0503472238779068, 0.7630208134651184, 0.0980902761220932, 0.013020833022892475, 0.0442708320915699, 0.01822916604578495, 0.1137152761220932, 0.859375, 0.0, 0.0, 0.0720486119389534, 0.0, 0.0, 0.0, 0.010416666977107525, 0.0, 0.0, 0.013020833022892475, 0.0, 0.0052083334885537624, 0.015625, 0.0329861119389534, 0.0, 0.7508680820465088, 0.015625, 0.0, 0.0251736119389534, 0.09375, 0.0, 0.0, 0.02690972201526165, 0.0, 0.0598958320915699, 0.1684027761220932, 0.0, 0.0546875, 0.1467013955116272, 0.0564236119389534, 0.1223958358168602]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.03125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.0, 0.5703125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.0, 0.1328125, 0.0, 0.0, 0.640625, 0.9921875, 0.0, 0.640625, 0.0, 0.0, 0.0, 0.6328125, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.640625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.0, 0.6328125, 0.0, 0.640625, 0.0, 0.640625, 0.0390625, 0.0, 0.0, 0.6328125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.1796875, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.984375, 0.0, 0.640625, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.234375, 0.0, 0.984375, 0.0, 0.1015625, 0.640625, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.640625, 0.0, 0.0, 0.5234375, 0.0, 0.8125, 0.640625, 0.0, 0.0, 0.0390625, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.640625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.546875, 0.0, 0.0625, 0.640625, 0.0, 0.0, 0.640625, 0.5546875, 0.640625, 0.0, 0.0, 0.9765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.6328125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6328125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.9765625, 0.0, 0.0, 0.0, 0.9765625, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.640625, 0.640625, 0.234375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.453125, 0.0, 0.0, 0.640625, 0.0, 0.3671875, 0.0625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.640625, 0.0, 0.9921875, 0.0, 0.6328125, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.0, 0.640625, 0.0, 0.0, 0.453125, 0.0, 0.0, 0.0, 0.0, 0.6328125, 0.0, 0.640625, 0.0, 0.0, 0.640625, 0.0, 0.640625, 0.0, 0.640625, 0.0, 0.640625, 0.0, 0.640625, 0.0, 0.640625, 0.0, 0.984375, 0.640625, 0.5703125, 0.640625, 0.0, 0.0, 0.0, 0.6328125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.3359375, 0.0, 0.640625, 0.0, 0.0, 0.0, 0.046875, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.6328125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.640625, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.9921875, 0.0, 0.9921875, 0.0, 0.640625, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.6328125, 0.0, 0.0, 0.984375, 0.0, 0.984375, 0.640625, 0.0, 0.0, 0.640625, 0.640625, 0.0, 0.640625, 0.640625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.5234375, 0.828125, 0.640625, 0.640625, 0.0, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.0]

 sparsity of   [0.0078125, 0.0, 0.126953125, 0.99609375, 0.1171875, 0.0, 0.0, 0.857421875, 0.0, 0.93359375, 0.0, 0.01171875, 0.0, 0.00390625, 0.03515625, 0.048828125, 0.505859375, 0.35546875, 0.064453125, 0.01171875, 0.994140625, 0.9140625, 0.87890625, 0.845703125, 0.0, 0.99609375, 0.0, 0.0, 0.99609375, 0.919921875, 0.017578125, 0.912109375, 0.0, 0.087890625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0234375, 0.0, 0.9921875, 0.037109375, 0.099609375, 0.1328125, 0.0703125, 0.0, 0.0, 0.078125, 0.0, 0.0, 0.10546875, 0.03515625, 0.99609375, 0.037109375, 0.671875, 0.0, 0.0, 0.99609375, 0.025390625, 0.0, 0.0, 0.0, 0.033203125, 0.8828125, 0.013671875, 0.0, 0.080078125, 0.99609375, 0.060546875, 0.048828125, 0.99609375, 0.99609375, 0.0546875, 0.05078125, 0.02734375, 0.025390625, 0.173828125, 0.0859375, 0.0, 0.201171875, 0.0, 0.021484375, 0.0, 0.99609375, 0.07421875, 0.0, 0.060546875, 0.015625, 0.125, 0.052734375, 0.0, 0.013671875, 0.0234375, 0.8984375, 0.0390625, 0.005859375, 0.91015625, 0.99609375, 0.0, 0.0546875, 0.0, 0.0703125, 0.20703125, 0.00390625, 0.0625, 0.01953125, 0.994140625, 0.0, 0.173828125, 0.0, 0.037109375, 0.0, 0.041015625, 0.07421875, 0.087890625, 0.830078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0]

 sparsity of   [0.0529513880610466, 0.4131944477558136, 0.2057291716337204, 0.0442708320915699, 0.015625, 0.1059027761220932, 0.02170138992369175, 0.02170138992369175, 0.0, 0.0, 0.1111111119389534, 0.9982638955116272, 0.9001736044883728, 0.0885416641831398, 0.0, 0.6970486044883728, 0.0902777761220932, 0.0, 0.9262152910232544, 0.0460069440305233, 0.0451388880610466, 0.0, 0.02777777798473835, 0.0486111119389534, 0.0451388880610466, 0.02777777798473835, 0.02777777798473835, 0.01996527798473835, 0.0, 0.9105902910232544, 0.889756977558136, 0.0894097238779068, 0.1796875, 0.014756944961845875, 0.0225694440305233, 0.9982638955116272, 0.0, 0.0, 0.0164930559694767, 0.0460069440305233, 0.0963541641831398, 0.9973958134651184, 0.0, 0.0303819440305233, 0.0460069440305233, 0.9982638955116272, 0.0390625, 0.0, 0.0, 0.0, 0.897569477558136, 0.0, 0.0, 0.0416666679084301, 0.999131977558136, 0.078125, 0.0555555559694767, 0.03125, 0.01822916604578495, 0.02951388992369175, 0.999131977558136, 0.0, 0.1189236119389534, 0.0668402761220932, 0.9973958134651184, 0.0381944440305233, 0.9982638955116272, 0.1041666641831398, 0.999131977558136, 0.0, 0.0303819440305233, 0.0425347238779068, 0.02951388992369175, 0.0, 0.9982638955116272, 0.015625, 0.999131977558136, 0.0, 0.0859375, 0.0225694440305233, 0.0, 0.0920138880610466, 0.063368059694767, 0.9010416865348816, 0.5416666865348816, 0.157986119389534, 0.8993055820465088, 0.014756944961845875, 0.0616319440305233, 0.0, 0.01128472201526165, 0.0, 0.9166666865348816, 0.02777777798473835, 0.0434027798473835, 0.0, 0.3463541567325592, 0.9279513955116272, 0.015625, 0.0, 0.9409722089767456, 0.015625, 0.01996527798473835, 0.0164930559694767, 0.0234375, 0.0, 0.0, 0.0, 0.9982638955116272, 0.0416666679084301, 0.9322916865348816, 0.063368059694767, 0.9973958134651184, 0.02170138992369175, 0.0642361119389534, 0.0173611119389534, 0.0, 0.9140625, 0.0407986119389534, 0.975694477558136, 0.0, 0.0546875, 0.0, 0.0642361119389534, 0.046875, 0.0, 0.5703125, 0.0]

 sparsity of   [0.7265625, 0.0, 0.0, 0.7265625, 0.0, 0.7265625, 0.0, 0.0, 0.0, 0.7265625, 0.0, 0.0, 0.7265625, 0.0, 0.0, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.0, 0.0, 0.7265625, 0.0, 0.0, 0.703125, 0.7265625, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.0, 0.0, 0.0, 0.7265625, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.0, 0.0, 0.0, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.7265625, 0.0, 0.0, 0.0, 0.0, 0.7265625, 0.0859375, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.7265625, 0.0, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.0, 0.0, 0.0, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.0, 0.0, 0.0, 0.7265625, 0.71875, 0.7109375, 0.7265625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.7265625, 0.0, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7265625, 0.0, 0.0, 0.6328125, 0.0234375, 0.7265625, 0.7265625, 0.0, 0.0, 0.0, 0.0, 0.7265625, 0.0, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.0, 0.7265625, 0.0, 0.9921875, 0.0, 0.7265625, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.71875, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.6640625, 0.0, 0.0, 0.0, 0.7265625, 0.0, 0.7265625, 0.0, 0.0, 0.0, 0.7265625, 0.5546875, 0.7265625, 0.671875, 0.0, 0.7265625, 0.0, 0.5703125, 0.0, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.0546875, 0.109375, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.0, 0.0, 0.0, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.0, 0.0, 0.7265625, 0.0, 0.7265625, 0.0, 0.0, 0.140625, 0.5703125, 0.0, 0.0, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.0, 0.0, 0.0, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.0, 0.0, 0.0, 0.7265625, 0.5859375, 0.0, 0.0, 0.9921875, 0.0, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.0, 0.0, 0.078125, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.140625, 0.0, 0.0, 0.0, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.0, 0.0, 0.7265625, 0.0, 0.7265625, 0.0, 0.0, 0.8046875, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.0, 0.0, 0.0, 0.7265625, 0.0, 0.6328125, 0.7265625, 0.0, 0.0, 0.0, 0.0, 0.7265625, 0.0, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7265625, 0.0, 0.0, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.71875, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.0, 0.7265625, 0.71875, 0.7265625, 0.0, 0.6640625, 0.0, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7265625, 0.7265625, 0.0, 0.0, 0.0, 0.71875, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.0, 0.984375, 0.0, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.0, 0.0546875, 0.7265625, 0.7265625, 0.140625, 0.0, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.8046875, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.0859375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.6640625, 0.7265625, 0.0, 0.7265625, 0.0, 0.7265625, 0.7109375, 0.7265625, 0.7265625, 0.7265625, 0.6875, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.0, 0.0, 0.0, 0.0, 0.6015625, 0.09375, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.0, 0.7265625, 0.7265625, 0.7265625]

 sparsity of   [0.998046875, 0.99609375, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.0, 0.998046875, 0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.998046875, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.998046875, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.998046875, 0.99609375, 0.99609375, 0.99609375, 0.998046875, 0.99609375, 0.994140625, 0.99609375, 0.998046875, 0.99609375, 0.99609375, 0.998046875, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.994140625, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.998046875, 0.0, 0.99609375, 0.0, 0.998046875, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.998046875, 0.99609375, 0.998046875, 0.99609375, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.998046875, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.0, 0.99609375, 0.998046875, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.998046875, 0.0, 0.998046875, 0.0, 0.998046875, 0.99609375, 0.99609375, 0.015625, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.998046875, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.998046875, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.998046875, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.998046875, 0.998046875, 0.0, 0.99609375, 0.015625, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.998046875, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.015625, 0.99609375, 0.99609375, 0.0, 0.998046875, 0.998046875, 0.015625, 0.998046875, 0.99609375, 0.998046875, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.998046875, 0.0, 0.0, 0.99609375, 0.0, 0.998046875, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.0]

 sparsity of   [0.9995659589767456, 0.0, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9986979365348816, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.0, 0.9986979365348816, 0.9995659589767456, 0.9995659589767456, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.765625, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.9986979365348816, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.9995659589767456, 0.0, 0.9986979365348816, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.0, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.1276041716337204, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.0, 0.9995659589767456, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9986979365348816, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.7634548544883728, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.0, 0.9995659589767456, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.9986979365348816, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.0, 0.0, 0.999131977558136, 0.0, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.9986979365348816, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.9986979365348816, 0.0, 0.9995659589767456]

 sparsity of   [0.9921875, 0.9921875, 0.859375, 0.859375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.859375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.859375, 0.0, 0.0, 0.9921875, 0.9921875, 0.859375, 0.984375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.859375, 0.50390625, 0.0, 0.9921875, 0.9921875, 0.98828125, 0.0, 0.859375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.359375, 0.9921875, 0.859375, 0.9921875, 0.98828125, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.98828125, 0.859375, 0.9921875, 0.859375, 0.9921875, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.99609375, 0.43359375, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.859375, 0.99609375, 0.98828125, 0.859375, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.98828125, 0.9921875, 0.9921875, 0.98828125, 0.0, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.859375, 0.859375, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.859375, 0.9921875, 0.9921875, 0.0, 0.0, 0.98828125, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.98828125, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.859375, 0.99609375, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.859375, 0.859375, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.859375, 0.859375, 0.859375, 0.0, 0.859375, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.98828125, 0.0, 0.9921875, 0.99609375, 0.98828125, 0.0, 0.9921875, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.859375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.859375, 0.9921875, 0.0, 0.859375, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.859375, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.859375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.859375, 0.859375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.98828125, 0.9921875, 0.98828125, 0.0, 0.0, 0.98828125, 0.0, 0.859375, 0.0, 0.98828125, 0.859375, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.859375, 0.99609375, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.484375, 0.9921875, 0.0, 0.859375, 0.0, 0.9921875, 0.0, 0.859375, 0.859375, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.859375, 0.9921875, 0.9921875, 0.859375, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.859375, 0.9921875, 0.99609375, 0.859375, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.859375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.859375, 0.9921875, 0.9921875, 0.9921875, 0.859375, 0.0, 0.890625, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.859375, 0.9921875, 0.859375, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.36328125, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9296875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.859375, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.0, 0.859375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.859375, 0.0, 0.859375, 0.0, 0.859375, 0.0, 0.9921875, 0.859375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.859375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.98828125, 0.9921875, 0.0, 0.984375, 0.0, 0.9921875, 0.859375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.859375, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.859375, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.859375, 0.0, 0.859375, 0.0, 0.859375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.98828125, 0.859375, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.859375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.859375, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.0, 0.859375, 0.0, 0.859375, 0.46484375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.859375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.859375, 0.9921875, 0.9921875, 0.859375, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.859375, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.98828125, 0.859375, 0.859375, 0.99609375, 0.91015625, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.859375, 0.859375, 0.859375, 0.9921875, 0.859375, 0.9921875, 0.9921875, 0.0, 0.859375, 0.859375, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.859375, 0.0, 0.0, 0.859375, 0.9921875, 0.99609375, 0.4296875, 0.859375, 0.9921875, 0.99609375, 0.859375, 0.9921875, 0.99609375, 0.9921875, 0.859375, 0.0, 0.9921875, 0.859375, 0.99609375, 0.0, 0.9921875, 0.859375, 0.9921875, 0.9921875, 0.0, 0.98828125, 0.0, 0.0, 0.99609375, 0.859375, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.859375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.859375, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.984375, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.0, 0.984375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.3984375, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.98828125, 0.859375, 0.0, 0.859375, 0.0, 0.859375, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.98828125, 0.9921875, 0.859375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.859375, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.99609375, 0.0, 0.0, 0.9921875, 0.98828125, 0.9921875, 0.0, 0.0, 0.859375, 0.99609375, 0.9921875, 0.859375, 0.0, 0.99609375, 0.859375, 0.9921875, 0.984375, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.859375, 0.0, 0.0, 0.9921875, 0.99609375, 0.859375, 0.0, 0.0, 0.859375, 0.98828125, 0.0, 0.9921875, 0.0, 0.9921875, 0.859375, 0.98828125, 0.98828125, 0.859375, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.859375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.859375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.859375, 0.99609375, 0.0, 0.0, 0.859375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.859375, 0.984375, 0.0, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.984375, 0.0, 0.0, 0.9921875, 0.859375, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.859375, 0.859375, 0.0, 0.859375, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.859375, 0.9921875, 0.99609375, 0.984375, 0.99609375, 0.859375, 0.859375, 0.0, 0.9921875, 0.9921875, 0.0, 0.859375, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.859375, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.859375, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.859375, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.859375, 0.0, 0.9921875, 0.859375, 0.99609375, 0.9921875, 0.859375, 0.9921875, 0.0, 0.9921875, 0.859375, 0.859375, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.859375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.98828125, 0.0, 0.9921875, 0.98828125, 0.859375, 0.9921875, 0.9921875, 0.9921875, 0.859375, 0.859375, 0.0, 0.9921875, 0.0, 0.9921875, 0.859375, 0.0, 0.9921875, 0.0, 0.859375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.85546875, 0.9921875, 0.0, 0.0, 0.98828125, 0.9921875, 0.0, 0.859375, 0.9921875, 0.859375, 0.9921875, 0.859375, 0.9921875, 0.9921875, 0.0]

 sparsity of   [0.99609375, 0.998046875, 0.005859375, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.353515625, 0.0, 0.0, 0.994140625, 0.0, 0.083984375, 0.0, 0.03515625, 0.99609375, 0.0, 0.0, 0.0, 0.0078125, 0.99609375, 0.99609375, 0.015625, 0.99609375, 0.015625, 0.189453125, 0.396484375, 0.0, 0.0, 0.00390625, 0.0078125, 0.998046875, 0.78515625, 0.0, 0.99609375, 0.99609375, 0.998046875, 0.0, 0.99609375, 0.0, 0.783203125, 0.0, 0.072265625, 0.99609375, 0.99609375, 0.0, 0.0, 0.998046875, 0.912109375, 0.798828125, 0.0, 0.0, 0.154296875, 0.0, 0.0, 0.43359375, 0.998046875, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.005859375, 0.23046875, 0.998046875, 0.99609375, 0.0, 0.142578125, 0.998046875, 0.640625, 0.0, 0.033203125, 0.197265625, 0.99609375, 0.0, 0.994140625, 0.279296875, 0.994140625, 0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.087890625, 0.998046875, 0.994140625, 0.99609375, 0.07421875, 0.994140625, 0.0703125, 0.99609375, 0.99609375, 0.013671875, 0.0625, 0.525390625, 0.0, 0.0, 0.05859375, 0.22265625, 0.0, 0.998046875, 0.99609375, 0.99609375, 0.0, 0.0, 0.08203125, 0.0, 0.99609375, 0.0, 0.078125, 0.54296875, 0.091796875, 0.12890625, 0.0, 0.34375, 0.337890625, 0.0, 0.583984375, 0.0, 0.0625, 0.0078125, 0.091796875, 0.998046875, 0.005859375, 0.015625, 0.0, 0.0, 0.0, 0.99609375, 0.185546875, 0.0, 0.015625, 0.06640625, 0.99609375, 0.0, 0.0, 0.244140625, 0.33203125, 0.361328125, 0.0, 0.10546875, 0.904296875, 0.998046875, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.119140625, 0.0, 0.056640625, 0.99609375, 0.0, 0.041015625, 0.0, 0.31640625, 0.84765625, 0.99609375, 0.99609375, 0.08203125, 0.99609375, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.306640625, 0.994140625, 0.041015625, 0.0, 0.109375, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.216796875, 0.0, 0.177734375, 0.12109375, 0.0, 0.0, 0.01171875, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.994140625, 0.99609375, 0.0, 0.99609375, 0.0, 0.16015625, 0.1171875, 0.99609375, 0.0, 0.99609375, 0.0, 0.0, 0.99609375, 0.0, 0.998046875, 0.154296875, 0.99609375, 0.0, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.00390625, 0.99609375, 0.0, 0.009765625, 0.99609375, 0.0, 0.0, 0.0703125, 0.892578125, 0.0, 0.0, 0.0, 0.0, 0.423828125, 0.0, 0.0, 0.994140625, 0.228515625, 0.0, 0.0, 0.99609375, 0.998046875, 0.998046875, 0.0, 0.01171875, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.998046875, 0.125, 0.0, 0.0, 0.087890625, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.84375, 0.490234375, 0.0, 0.99609375, 0.99609375, 0.048828125, 0.0, 0.998046875, 0.99609375, 0.0, 0.998046875, 0.0, 0.03515625, 0.9921875, 0.99609375, 0.998046875, 0.0, 0.0, 0.0, 0.857421875, 0.783203125, 0.0, 0.0, 0.0, 0.994140625, 0.0, 0.0, 0.01171875, 0.0, 0.794921875, 0.07421875, 0.0, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.55859375, 0.001953125, 0.99609375, 0.99609375, 0.013671875, 0.0, 0.27734375, 0.998046875, 0.0, 0.99609375, 0.0, 0.0, 0.99609375, 0.998046875, 0.12109375, 0.998046875, 0.0, 0.0, 0.51171875, 0.015625, 0.0, 0.998046875, 0.134765625, 0.361328125, 0.130859375, 0.0, 0.046875, 0.0, 0.99609375, 0.16796875, 0.0, 0.076171875, 0.0, 0.0, 0.998046875, 0.0, 0.0, 0.2890625, 0.0, 0.99609375, 0.0, 0.521484375, 0.99609375, 0.302734375, 0.19921875, 0.0, 0.998046875, 0.09375, 0.01171875, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.998046875, 0.013671875, 0.99609375, 0.0, 0.99609375, 0.998046875, 0.99609375, 0.083984375, 0.07421875, 0.99609375, 0.00390625, 0.99609375, 0.681640625, 0.99609375, 0.01171875, 0.0, 0.57421875, 0.0, 0.126953125, 0.0, 0.0, 0.99609375, 0.015625, 0.998046875, 0.015625, 0.015625, 0.0, 0.0, 0.0, 0.216796875, 0.0, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.11328125, 0.0, 0.99609375, 0.00390625, 0.30859375, 0.0, 0.99609375, 0.0, 0.99609375, 0.03515625, 0.001953125, 0.99609375, 0.0, 0.03125, 0.0, 0.99609375, 0.041015625, 0.087890625, 0.99609375, 0.283203125, 0.205078125, 0.1328125, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.251953125, 0.99609375, 0.0, 0.0, 0.0, 0.99609375, 0.349609375, 0.115234375, 0.0859375, 0.0, 0.0, 0.99609375, 0.599609375, 0.0, 0.3125, 0.0, 0.99609375, 0.3515625, 0.0, 0.0, 0.0, 0.99609375, 0.0703125, 0.99609375, 0.0390625, 0.5234375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.298828125, 0.0, 0.119140625, 0.0, 0.998046875, 0.99609375, 0.0, 0.111328125, 0.99609375, 0.0, 0.0, 0.99609375, 0.009765625, 0.99609375, 0.99609375, 0.146484375, 0.0, 0.994140625, 0.041015625, 0.99609375, 0.99609375, 0.31640625, 0.99609375, 0.0, 0.0, 0.99609375, 0.001953125, 0.99609375, 0.99609375, 0.0390625, 0.99609375, 0.0, 0.99609375, 0.0, 0.99609375, 0.2890625, 0.0, 0.0, 0.880859375, 0.99609375, 0.0, 0.998046875, 0.0, 0.998046875, 0.0, 0.091796875, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.224609375, 0.0, 0.99609375, 0.0, 0.99609375, 0.353515625, 0.0, 0.185546875, 0.0, 0.998046875, 0.0, 0.998046875, 0.99609375, 0.904296875, 0.1796875, 0.158203125, 0.99609375, 0.0, 0.99609375, 0.998046875, 0.994140625, 0.0, 0.99609375, 0.0, 0.046875, 0.99609375, 0.0, 0.0, 0.24609375, 0.1015625, 0.0, 0.994140625, 0.99609375, 0.99609375, 0.4140625, 0.193359375, 0.255859375, 0.3125, 0.0, 0.0, 0.0, 0.0, 0.013671875, 0.0, 0.0, 0.0, 0.798828125, 0.99609375, 0.044921875, 0.0, 0.0, 0.0, 0.158203125, 0.994140625, 0.00390625, 0.99609375, 0.322265625, 0.0, 0.009765625, 0.5546875, 0.0, 0.080078125, 0.00390625, 0.04296875, 0.99609375, 0.076171875, 0.0, 0.0625, 0.994140625, 0.00390625, 0.99609375, 0.330078125, 0.99609375, 0.3359375, 0.99609375, 0.994140625, 0.99609375, 0.0, 0.359375, 0.029296875, 0.224609375, 0.447265625, 0.0, 0.0, 0.0, 0.0, 0.208984375, 0.115234375, 0.99609375, 0.0, 0.212890625, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.15625, 0.0, 0.99609375, 0.0, 0.162109375, 0.99609375, 0.072265625, 0.0, 0.99609375, 0.99609375, 0.0, 0.734375, 0.0, 0.994140625, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.994140625, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.091796875, 0.99609375, 0.0078125, 0.0, 0.359375, 0.341796875, 0.0, 0.0, 0.0, 0.0, 0.169921875, 0.998046875, 0.240234375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.66796875, 0.99609375, 0.0, 0.0, 0.005859375, 0.99609375, 0.0, 0.0859375, 0.994140625, 0.0, 0.0, 0.013671875, 0.0, 0.0, 0.099609375, 0.0, 0.99609375, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0390625, 0.998046875, 0.99609375, 0.001953125, 0.99609375, 0.7734375, 0.01171875, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.0, 0.99609375, 0.0, 0.22265625, 0.0, 0.99609375, 0.0, 0.99609375, 0.3359375, 0.001953125, 0.22265625, 0.0, 0.0, 0.4296875, 0.0, 0.99609375, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.99609375, 0.1328125, 0.998046875, 0.453125, 0.076171875, 0.353515625, 0.064453125, 0.99609375, 0.99609375, 0.99609375, 0.013671875, 0.04296875, 0.998046875, 0.0, 0.998046875, 0.0, 0.04296875, 0.2890625, 0.99609375, 0.001953125, 0.4140625, 0.998046875, 0.064453125, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.939453125, 0.0, 0.99609375, 0.28125, 0.728515625, 0.427734375, 0.0, 0.99609375, 0.16015625, 0.0, 0.267578125, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.0, 0.0, 0.99609375, 0.994140625, 0.0, 0.998046875, 0.248046875, 0.015625, 0.05859375, 0.99609375, 0.998046875, 0.0, 0.0, 0.09375, 0.001953125, 0.0703125, 0.99609375, 0.99609375, 0.119140625, 0.99609375, 0.0, 0.0, 0.998046875, 0.99609375, 0.166015625, 0.0, 0.0, 0.015625, 0.99609375, 0.998046875, 0.00390625, 0.0, 0.09375, 0.0, 0.046875, 0.998046875, 0.0, 0.083984375, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.015625, 0.0, 0.068359375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.115234375, 0.0, 0.900390625, 0.00390625, 0.99609375, 0.0, 0.99609375, 0.98828125, 0.001953125, 0.0, 0.99609375, 0.99609375, 0.994140625, 0.99609375, 0.0, 0.998046875, 0.087890625, 0.0, 0.091796875, 0.99609375, 0.99609375, 0.33203125, 0.99609375, 0.99609375, 0.0, 0.0, 0.99609375, 0.998046875, 0.99609375, 0.0, 0.998046875, 0.9921875, 0.453125, 0.015625, 0.0, 0.154296875, 0.07421875, 0.263671875, 0.0, 0.083984375, 0.99609375, 0.0, 0.99609375, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.005859375, 0.994140625, 0.142578125, 0.61328125, 0.0, 0.998046875, 0.013671875, 0.99609375, 0.0, 0.0, 0.0, 0.466796875, 0.0, 0.994140625, 0.52734375, 0.0, 0.041015625, 0.99609375, 0.99609375, 0.111328125, 0.0, 0.873046875, 0.0, 0.283203125, 0.0, 0.99609375, 0.2890625, 0.208984375, 0.744140625, 0.2109375, 0.193359375, 0.060546875, 0.08203125, 0.0, 0.99609375, 0.0, 0.0, 0.99609375, 0.015625, 0.0, 0.0, 0.23046875, 0.279296875, 0.0, 0.0078125, 0.005859375, 0.0, 0.015625, 0.99609375, 0.998046875, 0.99609375, 0.998046875, 0.9921875, 0.0, 0.3671875, 0.248046875, 0.99609375, 0.30078125, 0.015625, 0.001953125, 0.0, 0.037109375, 0.99609375, 0.0, 0.013671875, 0.99609375, 0.0, 0.99609375, 0.0, 0.423828125, 0.00390625, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.0, 0.05078125, 0.0, 0.0, 0.0, 0.80859375, 0.076171875, 0.0, 0.99609375, 0.318359375, 0.0, 0.99609375, 0.427734375, 0.0, 0.99609375, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.994140625, 0.376953125, 0.55078125, 0.0, 0.0, 0.404296875, 0.0, 0.28515625, 0.994140625, 0.0, 0.486328125, 0.015625, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.052734375, 0.125, 0.99609375, 0.0703125, 0.0, 0.220703125, 0.99609375, 0.99609375, 0.0, 0.0, 0.998046875, 0.0390625, 0.67578125, 0.0, 0.0, 0.0390625, 0.998046875, 0.99609375, 0.00390625, 0.173828125, 0.0, 0.99609375, 0.236328125, 0.00390625, 0.220703125, 0.1328125, 0.099609375, 0.015625, 0.015625, 0.0, 0.998046875, 0.0, 0.99609375, 0.015625, 0.0, 0.99609375, 0.0, 0.0, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.005859375, 0.0, 0.0, 0.068359375, 0.0, 0.994140625, 0.998046875, 0.0, 0.99609375, 0.201171875, 0.998046875, 0.99609375, 0.04296875, 0.998046875, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.998046875, 0.083984375, 0.0, 0.013671875, 0.998046875, 0.015625, 0.060546875, 0.005859375, 0.998046875, 0.033203125, 0.005859375]

 sparsity of   [0.5517578125, 0.0693359375, 0.9990234375, 0.548828125, 0.9970703125, 0.0322265625, 0.1806640625, 0.1025390625, 0.1240234375, 0.9990234375, 0.5595703125, 0.998046875, 0.1806640625, 0.0, 0.0703125, 0.998046875, 0.1396484375, 0.9990234375, 0.0, 0.091796875, 0.5595703125, 0.5595703125, 0.0, 0.078125, 0.9970703125, 0.998046875, 0.0478515625, 0.0859375, 0.9970703125, 0.9990234375, 0.138671875, 0.4130859375, 0.9990234375, 0.1357421875, 0.998046875, 0.0224609375, 0.494140625, 0.0, 0.078125, 0.09765625, 0.0361328125, 0.0, 0.998046875, 0.1025390625, 0.5595703125, 0.0, 0.17578125, 0.044921875, 0.0908203125, 0.998046875, 0.0595703125, 0.0966796875, 0.0, 0.998046875, 0.0, 0.4697265625, 0.9990234375, 0.9990234375, 0.5595703125, 0.5361328125, 0.998046875, 0.5458984375, 0.0, 0.47265625, 0.0, 0.9990234375, 0.5419921875, 0.0, 0.0, 0.76953125, 0.029296875, 0.033203125, 0.1953125, 0.07421875, 0.9990234375, 0.0, 0.0556640625, 0.5595703125, 0.9970703125, 0.0537109375, 0.0, 0.103515625, 0.0, 0.08984375, 0.068359375, 0.0, 0.2451171875, 0.0, 0.998046875, 0.9970703125, 0.1650390625, 0.0, 0.9951171875, 0.998046875, 0.0869140625, 0.9990234375, 0.0, 0.095703125, 0.9990234375, 0.9990234375, 0.9990234375, 0.09765625, 0.8486328125, 0.04296875, 0.1923828125, 0.0302734375, 0.998046875, 0.2509765625, 0.056640625, 0.0, 0.998046875, 0.9990234375, 0.9990234375, 0.0, 0.537109375, 0.4951171875, 0.0, 0.048828125, 0.998046875, 0.53515625, 0.0, 0.0654296875, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.533203125, 0.0, 0.9970703125, 0.037109375, 0.041015625, 0.998046875, 0.998046875, 0.857421875, 0.998046875, 0.0244140625, 0.5595703125, 0.0, 0.3466796875, 0.0419921875, 0.5595703125, 0.1201171875, 0.5595703125, 0.0, 0.0, 0.1064453125, 0.1728515625, 0.0, 0.5341796875, 0.9990234375, 0.9970703125, 0.998046875, 0.0, 0.5400390625, 0.0, 0.994140625, 0.9990234375, 0.052734375, 0.0361328125, 0.0546875, 0.998046875, 0.9990234375, 0.052734375, 0.4853515625, 0.5595703125, 0.99609375, 0.0, 0.1181640625, 0.0, 0.875, 0.087890625, 0.998046875, 0.03515625, 0.1943359375, 0.998046875, 0.06640625, 0.8974609375, 0.0576171875, 0.9990234375, 0.5595703125, 0.998046875, 0.9970703125, 0.2099609375, 0.1337890625, 0.998046875, 0.0517578125, 0.9970703125, 0.5595703125, 0.0, 0.998046875, 0.998046875, 0.9990234375, 0.05859375, 0.0, 0.8349609375, 0.0556640625, 0.5546875, 0.0673828125, 0.1787109375, 0.9970703125, 0.0576171875, 0.998046875, 0.162109375, 0.5595703125, 0.130859375, 0.0, 0.5458984375, 0.0, 0.0, 0.8369140625, 0.998046875, 0.5400390625, 0.0419921875, 0.9990234375, 0.0, 0.3154296875, 0.5595703125, 0.0, 0.0, 0.0, 0.998046875, 0.0478515625, 0.0, 0.53515625, 0.3388671875, 0.0, 0.228515625, 0.3125, 0.998046875, 0.080078125, 0.1142578125, 0.0, 0.0322265625, 0.998046875, 0.0, 0.998046875, 0.998046875, 0.0, 0.064453125, 0.9990234375, 0.0, 0.0380859375, 0.998046875, 0.09765625, 0.8857421875, 0.046875, 0.998046875, 0.0, 0.998046875, 0.0185546875, 0.0, 0.1591796875, 0.9970703125, 0.9990234375, 0.9970703125]

 sparsity of   [0.0, 0.0, 0.9986979365348816, 0.9986979365348816, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.9986979365348816, 0.0, 0.9986979365348816, 0.106336809694767, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9982638955116272, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.9995659589767456, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.3142361044883728, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.9995659589767456, 0.0, 0.999131977558136, 0.9995659589767456, 0.3485243022441864, 0.9995659589767456, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.3328993022441864, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9986979365348816, 0.9995659589767456, 0.331597238779068, 0.999131977558136, 0.9995659589767456, 0.9986979365348816, 0.0, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.9986979365348816, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.0, 0.9995659589767456, 0.999131977558136, 0.0, 0.0, 0.9995659589767456, 0.0, 0.9995659589767456, 0.9986979365348816, 0.999131977558136, 0.9986979365348816, 0.9995659589767456, 0.0, 0.999131977558136, 0.3211805522441864, 0.0, 0.0, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.0, 0.0, 0.999131977558136, 0.15625, 0.999131977558136, 0.0, 0.9995659589767456, 0.0, 0.9995659589767456, 0.2921006977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.1440972238779068, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.0, 0.999131977558136, 0.9995659589767456, 0.3389756977558136, 0.0, 0.9986979365348816, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.1605902761220932, 0.9995659589767456, 0.0, 0.9995659589767456, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.9986979365348816, 0.0, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.0, 0.3463541567325592, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.0, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.3350694477558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.0, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.9986979365348816, 0.999131977558136, 0.1341145783662796, 0.9986979365348816, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.9986979365348816, 0.0, 0.9995659589767456, 0.9986979365348816, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.0, 0.3454861044883728, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9986979365348816, 0.0, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.0, 0.9995659589767456]

 sparsity of   [0.99609375, 0.9921875, 0.9921875, 0.79296875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.79296875, 0.0, 0.0, 0.0, 0.79296875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.79296875, 0.9921875, 0.9921875, 0.79296875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.79296875, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.99609375, 0.79296875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.79296875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.79296875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.79296875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.79296875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.79296875, 0.9921875, 0.98828125, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.79296875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.79296875, 0.0, 0.79296875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.79296875, 0.9921875, 0.79296875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.79296875, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.79296875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.79296875, 0.79296875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.79296875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.79296875, 0.0, 0.9921875, 0.79296875, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.79296875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.79296875, 0.9921875, 0.79296875, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.79296875, 0.98828125, 0.9921875, 0.0, 0.99609375, 0.79296875, 0.9921875, 0.0, 0.79296875, 0.0, 0.9921875, 0.9921875, 0.79296875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.79296875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.79296875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.79296875, 0.79296875, 0.0, 0.0, 0.9921875, 0.79296875, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.0, 0.79296875, 0.9921875, 0.79296875, 0.0, 0.9921875, 0.79296875, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.79296875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.79296875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.79296875, 0.79296875, 0.79296875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.79296875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.79296875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.79296875, 0.0, 0.79296875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.79296875, 0.0, 0.79296875, 0.9921875, 0.79296875, 0.9921875, 0.79296875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.79296875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.79296875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.79296875, 0.0, 0.79296875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.79296875, 0.0, 0.99609375, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.79296875, 0.9921875, 0.9921875, 0.0, 0.79296875, 0.79296875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.79296875, 0.79296875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.79296875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.79296875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.79296875, 0.9921875, 0.0, 0.98828125, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.76171875, 0.0, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.79296875, 0.98828125, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.99609375, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.79296875, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.9921875, 0.79296875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.79296875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.79296875, 0.0, 0.9921875, 0.0, 0.0, 0.99609375, 0.79296875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.79296875, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.79296875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.79296875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.79296875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.79296875, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.79296875, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.99609375, 0.79296875, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.79296875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.79296875]

 sparsity of   [0.0, 0.998046875, 0.9990234375, 0.1103515625, 0.0, 0.998046875, 0.9990234375, 0.0, 0.0, 0.998046875, 0.998046875, 0.0, 0.9990234375, 0.0, 0.9990234375, 0.087890625, 0.998046875, 0.0, 0.0, 0.484375, 0.9970703125, 0.1171875, 0.0, 0.9990234375, 0.0, 0.501953125, 0.998046875, 0.0869140625, 0.0, 0.0, 0.998046875, 0.1162109375, 0.0, 0.828125, 0.998046875, 0.0, 0.0, 0.0, 0.0419921875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.0, 0.0, 0.3056640625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9990234375, 0.0, 0.9990234375, 0.0, 0.998046875, 0.4853515625, 0.998046875, 0.0712890625, 0.9990234375, 0.0, 0.033203125, 0.0, 0.0, 0.998046875, 0.998046875, 0.0, 0.5, 0.0, 0.0, 0.0, 0.501953125, 0.5, 0.998046875, 0.1220703125, 0.998046875, 0.9990234375, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.9990234375, 0.0, 0.998046875, 0.9990234375, 0.0, 0.0869140625, 0.998046875, 0.0, 0.0, 0.9990234375, 0.9990234375, 0.998046875, 0.0, 0.0, 0.0, 0.1611328125, 0.0, 0.0, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.0, 0.0, 0.998046875, 0.060546875, 0.0, 0.0, 0.1025390625, 0.0, 0.4541015625, 0.0, 0.998046875, 0.0, 0.998046875, 0.9990234375, 0.9990234375, 0.0263671875, 0.998046875, 0.0, 0.998046875, 0.0, 0.9990234375, 0.998046875, 0.998046875, 0.0, 0.998046875, 0.0, 0.9990234375, 0.0, 0.0, 0.0, 0.9990234375, 0.0, 0.0, 0.0, 0.1162109375, 0.9990234375, 0.998046875, 0.0, 0.0, 0.998046875, 0.998046875, 0.998046875, 0.0, 0.9990234375, 0.33203125, 0.9990234375, 0.125, 0.4775390625, 0.998046875, 0.0, 0.09765625, 0.4873046875, 0.099609375, 0.0, 0.0, 0.998046875, 0.9970703125, 0.0, 0.998046875, 0.998046875, 0.9990234375, 0.470703125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.142578125, 0.9990234375, 0.998046875, 0.2529296875, 0.9990234375, 0.0, 0.0, 0.0, 0.998046875, 0.998046875, 0.0, 0.9990234375, 0.9990234375, 0.9970703125, 0.998046875, 0.0, 0.998046875, 0.0, 0.0, 0.0, 0.9970703125, 0.0, 0.3173828125, 0.0, 0.0, 0.998046875, 0.0, 0.998046875, 0.0, 0.0, 0.998046875, 0.2099609375, 0.9970703125, 0.998046875, 0.0693359375, 0.0859375, 0.0, 0.998046875, 0.3193359375, 0.5009765625, 0.0, 0.9970703125, 0.501953125, 0.0, 0.998046875, 0.9990234375, 0.0, 0.0, 0.9990234375, 0.0, 0.998046875, 0.0, 0.0791015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.0, 0.0, 0.0361328125, 0.0, 0.0, 0.998046875, 0.0, 0.9970703125, 0.0, 0.998046875, 0.0, 0.0908203125, 0.9990234375, 0.0, 0.998046875, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 0.0442708320915699, 0.0282118059694767, 0.0316840298473835, 0.0616319440305233, 0.0516493059694767, 0.0, 0.9995659589767456, 0.02734375, 0.0225694440305233, 0.0, 0.0, 0.0078125, 0.013454861007630825, 0.0412326380610466, 0.03515625, 0.0616319440305233, 0.0, 0.0173611119389534, 0.9652777910232544, 0.0243055559694767, 0.013454861007630825, 0.62890625, 0.9001736044883728, 0.0, 0.0, 0.0316840298473835, 0.0, 0.66796875, 0.0421006940305233, 0.0386284738779068, 0.1019965261220932, 0.0724826380610466, 0.010416666977107525, 0.0, 0.0525173619389534, 0.0, 0.0, 0.3385416567325592, 0.0, 0.0, 0.009982638992369175, 0.02213541604578495, 0.063368059694767, 0.6974826455116272, 0.9986979365348816, 0.0008680555620230734, 0.7287326455116272, 0.0303819440305233, 0.0, 0.999131977558136, 0.1432291716337204, 0.0, 0.08203125, 0.1545138955116272, 0.9986979365348816, 0.125, 0.0677083358168602, 0.0481770820915699, 0.0, 0.55078125, 0.0, 0.0, 0.0, 0.01692708395421505, 0.078993059694767, 0.009982638992369175, 0.0, 0.0421006940305233, 0.0, 0.0, 0.0, 0.01519097201526165, 0.503038227558136, 0.0, 0.046875, 0.0, 0.02300347201526165, 0.7547743320465088, 0.0, 0.0303819440305233, 0.106336809694767, 0.0, 0.02951388992369175, 0.01215277798473835, 0.0386284738779068, 0.1041666641831398, 0.0980902761220932, 0.0, 0.1145833358168602, 0.9036458134651184, 0.0, 0.0069444444961845875, 0.1458333283662796, 0.0, 0.01605902798473835, 0.0, 0.0659722238779068, 0.1510416716337204, 0.08203125, 0.362847238779068, 0.009548611007630825, 0.0447048619389534, 0.0, 0.0, 0.0, 0.6440972089767456, 0.013020833022892475, 0.1293402761220932, 0.0685763880610466, 0.02473958395421505, 0.01953125, 0.02734375, 0.02560763992369175, 0.0, 0.0, 0.02994791604578495, 0.0065104165114462376, 0.0798611119389534, 0.02083333395421505, 0.8745659589767456, 0.02994791604578495, 0.1549479216337204, 0.0, 0.02213541604578495, 0.0911458358168602, 0.0, 0.014756944961845875, 0.0173611119389534, 0.1067708358168602, 0.1861979216337204, 0.013020833022892475, 0.9995659589767456, 0.0, 0.0243055559694767, 0.0, 0.65234375, 0.0, 0.0368923619389534, 0.0, 0.999131977558136, 0.03515625, 0.1388888955116272, 0.0, 0.0902777761220932, 0.1006944477558136, 0.04296875, 0.02604166604578495, 0.0, 0.0164930559694767, 0.0, 0.01605902798473835, 0.0355902798473835, 0.013454861007630825, 0.0290798619389534, 0.0, 0.0, 0.0329861119389534, 0.0186631940305233, 0.0, 0.009114583022892475, 0.0876736119389534, 0.9986979365348816, 0.0394965298473835, 0.0, 0.1076388880610466, 0.999131977558136, 0.8923611044883728, 0.0, 0.0, 0.1019965261220932, 0.02994791604578495, 0.0, 0.0407986119389534, 0.0360243059694767, 0.01171875, 0.0716145858168602, 0.0, 0.7877604365348816, 0.0, 0.013454861007630825, 0.0173611119389534, 0.006076388992369175, 0.9153645634651184, 0.0, 0.0, 0.9986979365348816, 0.0, 0.862413227558136, 0.0290798619389534, 0.0, 0.2469618022441864, 0.0, 0.0, 0.897569477558136, 0.013888888992369175, 0.9995659589767456, 0.9995659589767456, 0.9986979365348816, 0.2113715261220932, 0.1223958358168602, 0.6909722089767456, 0.0243055559694767, 0.009548611007630825, 0.0078125, 0.7243923544883728, 0.9552951455116272, 0.0, 0.8875868320465088, 0.999131977558136, 0.02734375, 0.009548611007630825, 0.1640625, 0.0, 0.009982638992369175, 0.0, 0.1011284738779068, 0.0533854179084301, 0.0, 0.02777777798473835, 0.046875, 0.0234375, 0.0, 0.9995659589767456, 0.00824652798473835, 0.0243055559694767, 0.0, 0.0421006940305233, 0.0460069440305233, 0.0, 0.0993923619389534, 0.9995659589767456, 0.01953125, 0.086805559694767, 0.0, 0.842881977558136, 0.1597222238779068, 0.6215277910232544, 0.0, 0.010850694961845875, 0.0, 0.0616319440305233, 0.0186631940305233, 0.8541666865348816, 0.0516493059694767, 0.0833333358168602, 0.071180559694767, 0.0, 0.0716145858168602, 0.0377604179084301, 0.0481770820915699, 0.0, 0.02473958395421505, 0.010416666977107525, 0.0321180559694767, 0.046875]

 sparsity of   [0.71875, 0.9921875, 0.70703125, 0.71875, 0.703125, 0.0, 0.0, 0.71875, 0.0390625, 0.0, 0.5078125, 0.0, 0.71875, 0.71875, 0.0, 0.875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.9921875, 0.62109375, 0.17578125, 0.04296875, 0.75390625, 0.71875, 0.0, 0.71875, 0.71875, 0.0, 0.765625, 0.7265625, 0.0, 0.69921875, 0.69921875, 0.71875, 0.71875, 0.078125, 0.0, 0.828125, 0.71875, 0.9921875, 0.890625, 0.69921875, 0.71875, 0.0625, 0.671875, 0.6640625, 0.93359375, 0.0, 0.0, 0.9921875, 0.0, 0.71875, 0.0, 0.90234375, 0.7421875, 0.0, 0.9921875, 0.8515625, 0.99609375, 0.71875, 0.0, 0.68359375, 0.0, 0.70703125, 0.03125, 0.8203125, 0.0, 0.9921875, 0.9921875, 0.0, 0.6953125, 0.0859375, 0.0, 0.71875, 0.71484375, 0.98828125, 0.02734375, 0.9921875, 0.71875, 0.0, 0.68359375, 0.0, 0.0, 0.98828125, 0.9921875, 0.9921875, 0.70703125, 0.71875, 0.9921875, 0.1875, 0.9921875, 0.9921875, 0.21484375, 0.99609375, 0.2890625, 0.0, 0.0, 0.0, 0.05859375, 0.0, 0.9921875, 0.99609375, 0.0859375, 0.0, 0.0, 0.71484375, 0.22265625, 0.9921875, 0.0, 0.69140625, 0.72265625, 0.9921875, 0.99609375, 0.71875, 0.796875, 0.26953125, 0.0, 0.79296875, 0.71875, 0.74609375, 0.66796875, 0.9921875, 0.09375, 0.73828125, 0.98828125, 0.0, 0.0, 0.0, 0.0234375, 0.05078125, 0.0, 0.6875, 0.9921875, 0.1328125, 0.0, 0.08984375, 0.125, 0.9921875, 0.6875, 0.0, 0.98828125, 0.15234375, 0.99609375, 0.828125, 0.0, 0.71875, 0.6953125, 0.9921875, 0.0, 0.6015625, 0.99609375, 0.0, 0.99609375, 0.0, 0.99609375, 0.046875, 0.71875, 0.0625, 0.71484375, 0.7109375, 0.0, 0.71875, 0.71875, 0.0, 0.0, 0.98828125, 0.70703125, 0.734375, 0.0, 0.0546875, 0.0, 0.0, 0.0, 0.0, 0.6875, 0.9921875, 0.0, 0.09765625, 0.8671875, 0.0, 0.0, 0.71875, 0.0, 0.6796875, 0.703125, 0.0, 0.0, 0.09765625, 0.359375, 0.10546875, 0.9921875, 0.0, 0.9921875, 0.75390625, 0.7109375, 0.71875, 0.0, 0.0, 0.0, 0.71875, 0.0, 0.71484375, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.7109375, 0.08203125, 0.703125, 0.01171875, 0.6875, 0.6953125, 0.6875, 0.6796875, 0.6796875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.70703125, 0.87109375, 0.0, 0.71875, 0.68359375, 0.69921875, 0.41015625, 0.0, 0.0, 0.765625, 0.99609375, 0.0, 0.98828125, 0.71875, 0.0, 0.9921875, 0.6484375, 0.0, 0.9921875, 0.78125, 0.171875, 0.0, 0.0, 0.99609375, 0.0, 0.71875, 0.0, 0.703125, 0.99609375, 0.05078125, 0.9921875, 0.0, 0.70703125, 0.7109375, 0.03125, 0.6953125, 0.71484375, 0.71484375, 0.68359375, 0.99609375, 0.0, 0.9921875, 0.82421875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.08984375, 0.1171875, 0.0, 0.91015625, 0.0, 0.6875, 0.109375, 0.0, 0.9921875, 0.66796875, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.59765625, 0.9921875, 0.0703125, 0.05078125, 0.68359375, 0.99609375, 0.0, 0.0, 0.61328125, 0.0, 0.0, 0.73046875, 0.9921875, 0.0, 0.98828125, 0.0, 0.0, 0.74609375, 0.7109375, 0.0, 0.0859375, 0.8203125, 0.734375, 0.0, 0.0, 0.71875, 0.0, 0.9921875, 0.99609375, 0.0, 0.6953125, 0.0, 0.68359375, 0.72265625, 0.0, 0.0, 0.1171875, 0.62890625, 0.0, 0.0, 0.99609375, 0.9921875, 0.75390625, 0.7578125, 0.71875, 0.03125, 0.9921875, 0.6796875, 0.99609375, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.0, 0.0546875, 0.99609375, 0.98828125, 0.8046875, 0.9921875, 0.0390625, 0.99609375, 0.67578125, 0.67578125, 0.9921875, 0.0, 0.71875, 0.0, 0.11328125, 0.0, 0.6953125, 0.9921875, 0.94140625, 0.9921875, 0.9921875, 0.65234375, 0.0, 0.71875, 0.71875, 0.99609375, 0.62890625, 0.98828125, 0.0, 0.81640625, 0.71875, 0.15234375, 0.0, 0.71875, 0.71875, 0.64453125, 0.0, 0.703125, 0.0, 0.7734375, 0.9921875, 0.0, 0.9921875, 0.0, 0.98828125, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.07421875, 0.03125, 0.55078125, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.64453125, 0.0859375, 0.70703125, 0.0, 0.71875, 0.0, 0.9921875, 0.71875, 0.77734375, 0.71875, 0.0, 0.0, 0.7109375, 0.859375, 0.109375, 0.13671875, 0.0, 0.71875, 0.0, 0.0, 0.70703125, 0.0, 0.9921875, 0.70703125, 0.71875, 0.71875, 0.25, 0.0, 0.0, 0.66796875, 0.0, 0.71875, 0.67578125, 0.984375, 0.65234375, 0.86328125, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.05859375, 0.0, 0.99609375, 0.99609375, 0.91015625, 0.0, 0.0, 0.79296875, 0.0, 0.9921875, 0.98828125, 0.0, 0.0, 0.71875, 0.21875, 0.70703125, 0.9921875, 0.71484375, 0.9921875, 0.19921875, 0.0, 0.05859375, 0.0, 0.71875, 0.703125, 0.0, 0.0, 0.70703125, 0.98828125, 0.0, 0.06640625, 0.71875, 0.71484375, 0.71875, 0.6953125, 0.9921875, 0.0, 0.859375, 0.70703125, 0.72265625, 0.0, 0.75, 0.0, 0.9921875, 0.0, 0.71875, 0.84375, 0.0, 0.71875, 0.71875, 0.02734375, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.6953125, 0.0, 0.98828125, 0.76953125, 0.02734375, 0.0, 0.0, 0.0, 0.9921875, 0.25, 0.69140625, 0.71875, 0.9921875, 0.75390625, 0.71875, 0.9921875, 0.08984375, 0.12109375, 0.0, 0.3671875, 0.0, 0.36328125, 0.0, 0.0, 0.0, 0.0, 0.08984375, 0.0, 0.71875, 0.0, 0.0078125, 0.9921875, 0.19921875, 0.0, 0.0, 0.0, 0.08984375, 0.99609375, 0.0234375, 0.6328125, 0.69921875, 0.0, 0.71875, 0.9921875, 0.0, 0.0625, 0.06640625, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.71875, 0.9921875, 0.23046875, 0.9921875, 0.68359375, 0.98828125, 0.6953125, 0.9921875, 0.71875, 0.73828125, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.86328125, 0.88671875, 0.9921875, 0.0, 0.71484375, 0.0, 0.25390625, 0.0390625, 0.71875, 0.0, 0.0, 0.0, 0.0, 0.828125, 0.0, 0.04296875, 0.09765625, 0.08203125, 0.71875, 0.05078125, 0.0, 0.71875, 0.9921875, 0.0, 0.98828125, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9296875, 0.99609375, 0.0, 0.67578125, 0.0, 0.0, 0.0, 0.6875, 0.9375, 0.7890625, 0.703125, 0.7109375, 0.71875, 0.0, 0.0, 0.015625, 0.0, 0.921875, 0.2734375, 0.9921875, 0.0, 0.9921875, 0.8203125, 0.0, 0.70703125, 0.6953125, 0.71875, 0.0, 0.71484375, 0.69921875, 0.21875, 0.07421875, 0.65625, 0.0, 0.71875, 0.6875, 0.0, 0.0, 0.01171875, 0.0, 0.9921875, 0.765625, 0.0, 0.0, 0.0, 0.70703125, 0.71875, 0.0, 0.71875, 0.15234375, 0.6796875, 0.9921875, 0.79296875, 0.98046875, 0.9921875, 0.9921875, 0.0625, 0.75390625, 0.171875, 0.03125, 0.109375, 0.99609375, 0.71875, 0.65625, 0.0, 0.70703125, 0.69921875, 0.4140625, 0.25, 0.69921875, 0.99609375, 0.0, 0.0, 0.0, 0.69921875, 0.7109375, 0.0, 0.046875, 0.70703125, 0.16015625, 0.03515625, 0.71875, 0.0, 0.0, 0.0, 0.9921875, 0.71875, 0.9921875, 0.73046875, 0.98828125, 0.99609375, 0.9921875, 0.99609375, 0.296875, 0.65234375, 0.9921875, 0.71875, 0.99609375, 0.0, 0.99609375, 0.73828125, 0.7109375, 0.71875, 0.703125, 0.0, 0.9921875, 0.828125, 0.828125, 0.0, 0.703125, 0.0, 0.69921875, 0.6796875, 0.6953125, 0.9921875, 0.71875, 0.0, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.62890625, 0.0, 0.0, 0.71875, 0.0, 0.98828125, 0.0, 0.0, 0.71484375, 0.9921875, 0.71875, 0.59765625, 0.98828125, 0.9921875, 0.9921875, 0.7265625, 0.98828125, 0.0, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.87109375, 0.73046875, 0.6953125, 0.69921875, 0.703125, 0.70703125, 0.0, 0.99609375, 0.0, 0.0, 0.15625, 0.17578125, 0.09375, 0.75, 0.0, 0.9921875, 0.46484375, 0.99609375, 0.66796875, 0.0, 0.8828125, 0.0, 0.0, 0.75, 0.71484375, 0.9921875, 0.6484375, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.69921875, 0.0, 0.71875, 0.0, 0.99609375, 0.71875, 0.71875, 0.71875, 0.9921875, 0.9921875, 0.9921875, 0.6875, 0.68359375, 0.1171875, 0.99609375, 0.17578125, 0.0, 0.9921875, 0.98828125, 0.0, 0.0625, 0.65625, 0.0, 0.9921875, 0.98828125, 0.98828125, 0.0, 0.71484375, 0.0, 0.71875, 0.1328125, 0.0, 0.69921875, 0.9921875, 0.1875, 0.30078125, 0.0, 0.7265625, 0.69921875, 0.98828125, 0.0, 0.9921875, 0.5703125, 0.0, 0.81640625, 0.0, 0.0, 0.71875, 0.0, 0.08203125, 0.640625, 0.9921875, 0.9921875, 0.796875, 0.0, 0.16015625, 0.9921875, 0.9921875, 0.0, 0.0, 0.69140625, 0.0, 0.0, 0.12890625, 0.71875, 0.0, 0.05078125, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.7578125, 0.71875, 0.71875, 0.0, 0.7734375, 0.70703125, 0.29296875, 0.9921875, 0.6953125, 0.7109375, 0.703125, 0.9921875, 0.0, 0.75390625, 0.59375, 0.0, 0.69140625, 0.9921875, 0.0, 0.0, 0.0, 0.73046875, 0.69921875, 0.9921875, 0.25390625, 0.0, 0.9921875, 0.98828125, 0.70703125, 0.140625, 0.34375, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.71875, 0.71875, 0.0, 0.71875, 0.7109375, 0.0, 0.6953125, 0.14453125, 0.0, 0.0, 0.0, 0.71484375, 0.9921875, 0.71875, 0.71875, 0.0, 0.0390625, 0.0, 0.22265625, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.71875, 0.328125, 0.0, 0.0, 0.71875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.01171875, 0.9921875, 0.0, 0.0, 0.6484375, 0.99609375, 0.9921875, 0.71875, 0.0, 0.99609375, 0.71875, 0.17578125, 0.73828125, 0.8046875, 0.9921875, 0.71875, 0.9921875, 0.71875, 0.0, 0.0, 0.0, 0.84375, 0.9921875, 0.71875, 0.671875, 0.71875, 0.0625, 0.0, 0.9921875, 0.16796875, 0.0, 0.6640625, 0.9921875, 0.98828125, 0.12890625, 0.0, 0.0, 0.19921875, 0.2109375, 0.9921875, 0.71484375, 0.8515625, 0.0, 0.703125, 0.0, 0.99609375, 0.265625, 0.0, 0.078125, 0.05078125, 0.2265625, 0.0, 0.9921875, 0.70703125, 0.9921875, 0.71875, 0.0, 0.9921875, 0.67578125, 0.0, 0.99609375, 0.0, 0.6796875, 0.9921875, 0.78125, 0.71875, 0.0, 0.0, 0.0390625, 0.0, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.71875, 0.06640625, 0.9921875, 0.0, 0.2265625, 0.71875, 0.71875, 0.70703125, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.07421875, 0.82421875, 0.9921875, 0.0546875, 0.9921875, 0.7265625, 0.9921875, 0.33203125]

 sparsity of   [0.05078125, 0.0205078125, 0.1650390625, 0.013671875, 0.005859375, 0.3408203125, 0.0205078125, 0.630859375, 0.0107421875, 0.01953125, 0.0595703125, 0.068359375, 0.0546875, 0.046875, 0.0302734375, 0.0419921875, 0.0849609375, 0.0400390625, 0.05859375, 0.021484375, 0.0146484375, 0.408203125, 0.3505859375, 0.015625, 0.0224609375, 0.4521484375, 0.3017578125, 0.791015625, 0.0, 0.9658203125, 0.0, 0.0908203125, 0.181640625, 0.1875, 0.0185546875, 0.091796875, 0.267578125, 0.015625, 0.0, 0.0244140625, 0.0166015625, 0.025390625, 0.013671875, 0.02734375, 0.0205078125, 0.0185546875, 0.0947265625, 0.080078125, 0.005859375, 0.0908203125, 0.0283203125, 0.1142578125, 0.0146484375, 0.0, 0.017578125, 0.212890625, 0.681640625, 0.0, 0.0078125, 0.0546875, 0.0, 0.0, 0.013671875, 0.3369140625, 0.0576171875, 0.1103515625, 0.720703125, 0.998046875, 0.0361328125, 0.017578125, 0.31640625, 0.9970703125, 0.021484375, 0.0244140625, 0.064453125, 0.0087890625, 0.453125, 0.998046875, 0.03125, 0.2236328125, 0.2373046875, 0.0224609375, 0.865234375, 0.0, 0.0361328125, 0.0107421875, 0.0166015625, 0.0, 0.05078125, 0.7685546875, 0.0322265625, 0.013671875, 0.03515625, 0.0224609375, 0.0380859375, 0.0302734375, 0.0, 0.0498046875, 0.009765625, 0.0, 0.052734375, 0.1259765625, 0.0400390625, 0.0, 0.3466796875, 0.0771484375, 0.0859375, 0.1328125, 0.103515625, 0.041015625, 0.0126953125, 0.021484375, 0.1259765625, 0.017578125, 0.0, 0.0546875, 0.89453125, 0.3037109375, 0.779296875, 0.181640625, 0.0283203125, 0.3515625, 0.017578125, 0.021484375, 0.83203125, 0.0390625, 0.0, 0.0205078125, 0.0185546875, 0.0263671875, 0.0625, 0.171875, 0.0, 0.013671875, 0.103515625, 0.0634765625, 0.240234375, 0.0224609375, 0.0966796875, 0.08203125, 0.0107421875, 0.080078125, 0.0537109375, 0.390625, 0.0087890625, 0.021484375, 0.0, 0.662109375, 0.0703125, 0.1416015625, 0.1748046875, 0.1005859375, 0.7939453125, 0.0908203125, 0.017578125, 0.9208984375, 0.001953125, 0.0, 0.1044921875, 0.0126953125, 0.5263671875, 0.0556640625, 0.1044921875, 0.0166015625, 0.015625, 0.0078125, 0.6748046875, 0.0205078125, 0.0126953125, 0.0, 0.03515625, 0.3212890625, 0.126953125, 0.02734375, 0.01171875, 0.0322265625, 0.0361328125, 0.0, 0.0, 0.078125, 0.029296875, 0.015625, 0.052734375, 0.9951171875, 0.0859375, 0.0341796875, 0.0341796875, 0.4521484375, 0.765625, 0.02734375, 0.947265625, 0.0732421875, 0.923828125, 0.0234375, 0.029296875, 0.0439453125, 0.7001953125, 0.0517578125, 0.0087890625, 0.046875, 0.0146484375, 0.0078125, 0.0146484375, 0.0009765625, 0.0224609375, 0.0185546875, 0.095703125, 0.033203125, 0.0244140625, 0.451171875, 0.037109375, 0.4716796875, 0.9599609375, 0.015625, 0.0, 0.01953125, 0.0146484375, 0.0380859375, 0.0, 0.7353515625, 0.03515625, 0.0263671875, 0.0166015625, 0.099609375, 0.0224609375, 0.0, 0.1708984375, 0.013671875, 0.1708984375, 0.78515625, 0.2001953125, 0.4501953125, 0.044921875, 0.0615234375, 0.9638671875, 0.3232421875, 0.4267578125, 0.0126953125, 0.8505859375, 0.8232421875, 0.0078125, 0.740234375, 0.05859375, 0.017578125, 0.001953125, 0.0244140625, 0.0302734375, 0.0234375, 0.017578125, 0.271484375, 0.03515625, 0.0322265625, 0.03125, 0.017578125, 0.3330078125, 0.0146484375]

 sparsity of   [0.1032986119389534, 0.009982638992369175, 0.01996527798473835, 0.308159738779068, 0.02734375, 0.0503472238779068, 0.01822916604578495, 0.0407986119389534, 0.3181423544883728, 0.171875, 0.0460069440305233, 0.0, 0.1319444477558136, 0.0503472238779068, 0.0364583320915699, 0.1128472238779068, 0.1098090261220932, 0.0386284738779068, 0.2118055522441864, 0.01519097201526165, 0.04296875, 0.4110243022441864, 0.1792534738779068, 0.0885416641831398, 0.02300347201526165, 0.0520833320915699, 0.631944477558136, 0.0338541679084301, 0.0008680555620230734, 0.216579869389534, 0.2834201455116272, 0.0733506977558136, 0.02864583395421505, 0.01822916604578495, 0.0460069440305233, 0.0, 0.0442708320915699, 0.28125, 0.0004340277810115367, 0.0481770820915699, 0.0412326380610466, 0.01822916604578495, 0.01215277798473835, 0.0243055559694767, 0.0568576380610466, 0.0690104141831398, 0.0, 0.0737847238779068, 0.0490451380610466, 0.0338541679084301, 0.3515625, 0.1124131977558136, 0.0342881940305233, 0.0520833320915699, 0.4249131977558136, 0.0264756940305233, 0.0412326380610466, 0.0989583358168602, 0.063368059694767, 0.0355902798473835, 0.0373263880610466, 0.1002604141831398, 0.0421006940305233, 0.03125, 0.1085069477558136, 0.5416666865348816, 0.01692708395421505, 0.03125, 0.0412326380610466, 0.0434027798473835, 0.0455729179084301, 0.0212673619389534, 0.06640625, 0.078125, 0.157986119389534, 0.0290798619389534, 0.02994791604578495, 0.0360243059694767, 0.0173611119389534, 0.0412326380610466, 0.0364583320915699, 0.0399305559694767, 0.0941840261220932, 0.0065104165114462376, 0.9995659589767456, 0.1388888955116272, 0.7478298544883728, 0.56640625, 0.0008680555620230734, 0.0655381977558136, 0.0967881977558136, 0.009548611007630825, 0.1935763955116272, 0.0251736119389534, 0.0386284738779068, 0.1006944477558136, 0.1644965261220932, 0.0290798619389534, 0.0455729179084301, 0.9665798544883728, 0.0473090298473835, 0.01215277798473835, 0.0, 0.1263020783662796, 0.7777777910232544, 0.0525173619389534, 0.03515625, 0.0581597238779068, 0.1197916641831398, 0.010850694961845875, 0.01128472201526165, 0.189236119389534, 0.12109375, 0.0911458358168602, 0.3289930522441864, 0.0047743055038154125, 0.0481770820915699, 0.0698784738779068, 0.0473090298473835, 0.1888020783662796, 0.1922743022441864, 0.00824652798473835, 0.0486111119389534, 0.0264756940305233, 0.0303819440305233, 0.0959201380610466, 0.0386284738779068, 0.0668402761220932, 0.0347222238779068, 0.0490451380610466, 0.0685763880610466, 0.02994791604578495, 0.0282118059694767, 0.0086805559694767, 0.0559895820915699, 0.0668402761220932, 0.7912326455116272, 0.6263020634651184, 0.0434027798473835, 0.0052083334885537624, 0.0802951380610466, 0.0668402761220932, 0.0243055559694767, 0.009114583022892475, 0.02300347201526165, 0.0, 0.2265625, 0.0412326380610466, 0.01215277798473835, 0.075086809694767, 0.0568576380610466, 0.0, 0.0, 0.0460069440305233, 0.1106770858168602, 0.0894097238779068, 0.0807291641831398, 0.0924479141831398, 0.0, 0.0, 0.0, 0.0, 0.146267369389534, 0.0282118059694767, 0.0, 0.0, 0.4574652910232544, 0.0924479141831398, 0.1671006977558136, 0.0, 0.0329861119389534, 0.0316840298473835, 0.067274309694767, 0.1167534738779068, 0.0008680555620230734, 0.0004340277810115367, 0.0, 0.02604166604578495, 0.0078125, 0.0316840298473835, 0.01909722201526165, 0.075086809694767, 0.0355902798473835, 0.0004340277810115367, 0.3923611044883728, 0.1341145783662796, 0.009548611007630825, 0.0798611119389534, 0.0264756940305233, 0.0412326380610466, 0.07421875, 0.014756944961845875, 0.2139756977558136, 0.01605902798473835, 0.01822916604578495, 0.01171875, 0.02170138992369175, 0.02777777798473835, 0.1280381977558136, 0.0347222238779068, 0.5407986044883728, 0.0368923619389534, 0.0546875, 0.1128472238779068, 0.3732638955116272, 0.0368923619389534, 0.0668402761220932, 0.0364583320915699, 0.01779513992369175, 0.0, 0.6918402910232544, 0.0451388880610466, 0.0, 0.1310763955116272, 0.0425347238779068, 0.090711809694767, 0.4969618022441864, 0.109375, 0.0338541679084301, 0.2465277761220932, 0.0, 0.7834201455116272, 0.0416666679084301, 0.0368923619389534, 0.02560763992369175, 0.02951388992369175, 0.067274309694767, 0.0564236119389534, 0.1150173619389534, 0.0924479141831398, 0.0013020833721384406, 0.0243055559694767, 0.8598090410232544, 0.0542534738779068, 0.0546875, 0.181423619389534, 0.1154513880610466, 0.02951388992369175, 0.0993923619389534, 0.3932291567325592, 0.0464409738779068, 0.02473958395421505, 0.02083333395421505, 0.014756944961845875, 0.0017361111240461469, 0.0173611119389534, 0.1510416716337204, 0.0017361111240461469, 0.0963541641831398, 0.0125868059694767, 0.0334201380610466, 0.01822916604578495, 0.013454861007630825, 0.374565988779068, 0.0833333358168602, 0.3815104067325592]

 sparsity of   [0.703125, 0.6875, 0.9921875, 0.796875, 0.71484375, 0.67578125, 0.72265625, 0.1015625, 0.77734375, 0.578125, 0.6640625, 0.5859375, 0.7734375, 0.62890625, 0.0, 0.94921875, 0.90625, 0.77734375, 0.75, 0.15625, 0.6484375, 0.609375, 0.79296875, 0.90625, 0.92578125, 0.90625, 0.62890625, 0.78515625, 0.53125, 0.73828125, 0.74609375, 0.90625, 0.9921875, 0.67578125, 0.29296875, 0.70703125, 0.9921875, 0.70703125, 0.734375, 0.99609375, 0.05859375, 0.70703125, 0.90625, 0.9921875, 0.6640625, 0.6015625, 0.73046875, 0.765625, 0.97265625, 0.9921875, 0.6953125, 0.90625, 0.90625, 0.9921875, 0.8125, 0.76953125, 0.015625, 0.99609375, 0.77734375, 0.58203125, 0.11328125, 0.99609375, 0.0390625, 0.734375, 0.0, 0.6328125, 0.34765625, 0.91015625, 0.77734375, 0.7265625, 0.01171875, 0.16015625, 0.625, 0.04296875, 0.75390625, 0.80859375, 0.72265625, 0.65234375, 0.6484375, 0.90625, 0.74609375, 0.625, 0.90625, 0.8515625, 0.8984375, 0.0, 0.0, 0.08984375, 0.67578125, 0.99609375, 0.7265625, 0.75390625, 0.9921875, 0.99609375, 0.0390625, 0.6328125, 0.625, 0.90234375, 0.99609375, 0.90625, 0.0, 0.86328125, 0.64453125, 0.90625, 0.63671875, 0.609375, 0.625, 0.90625, 0.0078125, 0.01171875, 0.90625, 0.60546875, 0.71875, 0.0, 0.90625, 0.7421875, 0.65234375, 0.57421875, 0.90625, 0.90625, 0.55078125, 0.77734375, 0.6953125, 0.671875, 0.87890625, 0.9921875, 0.9921875, 0.8203125, 0.99609375, 0.0078125, 0.8359375, 0.04296875, 0.6328125, 0.8046875, 0.83984375, 0.1171875, 0.62890625, 0.7265625, 0.90234375, 0.80078125, 0.01171875, 0.0, 0.90625, 0.0, 0.0, 0.9921875, 0.921875, 0.71875, 0.0, 0.58984375, 0.65234375, 0.8671875, 0.109375, 0.74609375, 0.3125, 0.90625, 0.9921875, 0.90625, 0.6015625, 0.95703125, 0.671875, 0.0390625, 0.0625, 0.74609375, 0.8203125, 0.73046875, 0.90625, 0.55078125, 0.58984375, 0.99609375, 0.87109375, 0.70703125, 0.0, 0.9921875, 0.90625, 0.796875, 0.3359375, 0.0, 0.7421875, 0.77734375, 0.5234375, 0.80078125, 0.9921875, 0.79296875, 0.8203125, 0.7734375, 0.0078125, 0.7109375, 0.90625, 0.0, 0.41796875, 0.6953125, 0.9921875, 0.8359375, 0.9921875, 0.90625, 0.0703125, 0.78125, 0.9921875, 0.6796875, 0.046875, 0.5625, 0.62109375, 0.75390625, 0.0, 0.66796875, 0.98046875, 0.73046875, 0.578125, 0.90625, 0.17578125, 0.77734375, 0.703125, 0.90625, 0.546875, 0.63671875, 0.12109375, 0.73828125, 0.12890625, 0.66796875, 0.60546875, 0.78515625, 0.75, 0.71875, 0.58203125, 0.57421875, 0.7890625, 0.65234375, 0.04296875, 0.72265625, 0.73046875, 0.90625, 0.90625, 0.828125, 0.67578125, 0.6953125, 0.5859375, 0.0703125, 0.8046875, 0.8203125, 0.90625, 0.69140625, 0.23046875, 0.88671875, 0.6875, 0.80078125, 0.9921875, 0.5546875, 0.07421875, 0.64453125, 0.0234375, 0.8125, 0.56640625, 0.76953125, 0.9921875, 0.1484375, 0.640625, 0.51171875, 0.69140625, 0.765625, 0.796875, 0.8125, 0.90625, 0.90625, 0.8203125, 0.90625, 0.60546875, 0.1796875, 0.9921875, 0.65234375, 0.87109375, 0.90625, 0.890625, 0.6953125, 0.9921875, 0.87109375, 0.02734375, 0.90625, 0.9921875, 0.70703125, 0.90625, 0.69140625, 0.84765625, 0.69921875, 0.65234375, 0.5859375, 0.7578125, 0.0, 0.6484375, 0.1015625, 0.6484375, 0.04296875, 0.6640625, 0.90625, 0.7265625, 0.71484375, 0.875, 0.90625, 0.6484375, 0.9765625, 0.671875, 0.828125, 0.78515625, 0.07421875, 0.82421875, 0.6171875, 0.65234375, 0.0390625, 0.62109375, 0.90234375, 0.01953125, 0.98828125, 0.80078125, 0.61328125, 0.99609375, 0.90625, 0.609375, 0.05078125, 0.20703125, 0.90625, 0.5390625, 0.6171875, 0.76171875, 0.90625, 0.66015625, 0.99609375, 0.56640625, 0.64453125, 0.85546875, 0.6015625, 0.07421875, 0.90625, 0.8984375, 0.9921875, 0.0, 0.00390625, 0.515625, 0.734375, 0.58984375, 0.69921875, 0.734375, 0.6953125, 0.9921875, 0.7421875, 0.65234375, 0.9921875, 0.59765625, 0.70703125, 0.62890625, 0.796875, 0.0, 0.66015625, 0.5625, 0.9921875, 0.73828125, 0.79296875, 0.99609375, 0.9921875, 0.08203125, 0.8671875, 0.0234375, 0.2109375, 0.9921875, 0.7265625, 0.796875, 0.9921875, 0.69921875, 0.85546875, 0.90234375, 0.671875, 0.71875, 0.7265625, 0.03515625, 0.765625, 0.9921875, 0.9921875, 0.59765625, 0.48828125, 0.7421875, 0.78125, 0.66796875, 0.6875, 0.9921875, 0.59375, 0.99609375, 0.8671875, 0.65234375, 0.5625, 0.55859375, 0.73046875, 0.94921875, 0.7734375, 0.7421875, 0.0, 0.9921875, 0.6171875, 0.6640625, 0.0625, 0.58984375, 0.01953125, 0.61328125, 0.90625, 0.765625, 0.76171875, 0.86328125, 0.0625, 0.9296875, 0.96484375, 0.71484375, 0.9921875, 0.734375, 0.58984375, 0.7265625, 0.6328125, 0.9375, 0.66015625, 0.8046875, 0.54296875, 0.67578125, 0.90625, 0.0234375, 0.8125, 0.6484375, 0.0, 0.90234375, 0.72265625, 0.90625, 0.60546875, 0.0, 0.99609375, 0.6015625, 0.0, 0.734375, 0.02734375, 0.73046875, 0.90625, 0.5703125, 0.90625, 0.734375, 0.0, 0.078125, 0.90625, 0.609375, 0.26953125, 0.90625, 0.0546875, 0.75390625, 0.6953125, 0.66796875, 0.6875, 0.7421875, 0.6875, 0.67578125, 0.66796875, 0.90234375, 0.37109375, 0.78125, 0.8515625, 0.02734375, 0.9921875, 0.73046875, 0.0, 0.65625, 0.3359375, 0.73046875, 0.0546875, 0.77734375, 0.0, 0.1171875, 0.6796875, 0.6015625, 0.7578125, 0.9921875, 0.77734375, 0.171875, 0.76171875, 0.69921875, 0.828125, 0.49609375, 0.9921875, 0.75, 0.0859375, 0.5859375, 0.625, 0.0546875, 0.5859375, 0.734375, 0.71875, 0.76171875, 0.859375, 0.6875, 0.90625, 0.0, 0.6484375, 0.7578125, 0.640625, 0.28125, 0.0390625, 0.859375, 0.9921875, 0.53125, 0.7890625, 0.9921875, 0.5625, 0.234375, 0.0859375, 0.71875, 0.9921875, 0.9921875, 0.90625, 0.55078125, 0.70703125, 0.578125, 0.6484375, 0.640625, 0.65625, 0.734375, 0.88671875, 0.58203125, 0.68359375, 0.046875, 0.90625, 0.80078125, 0.9921875, 0.9921875, 0.796875, 0.828125, 0.76171875, 0.01953125, 0.3515625, 0.0, 0.671875, 0.0, 0.6328125, 0.0859375, 0.6875, 0.0, 0.7109375, 0.52734375, 0.7578125, 0.01953125, 0.8125, 0.546875, 0.9921875, 0.76171875, 0.90625, 0.859375, 0.78515625, 0.9921875, 0.99609375, 0.76953125, 0.8359375, 0.80078125, 0.7109375, 0.05859375, 0.00390625, 0.9921875, 0.90625, 0.00390625, 0.99609375, 0.109375, 0.90625, 0.7109375, 0.73828125, 0.0859375, 0.5859375, 0.82421875, 0.1328125, 0.86328125, 0.66796875, 0.734375, 0.72265625, 0.83984375, 0.05078125, 0.89453125, 0.99609375, 0.6875, 0.90625, 0.54296875, 0.69921875, 0.40234375, 0.6484375, 0.796875, 0.62109375, 0.0, 0.81640625, 0.015625, 0.9921875, 0.734375, 0.78125, 0.671875, 0.55859375, 0.0, 0.90234375, 0.73828125, 0.8359375, 0.6953125, 0.99609375, 0.84765625, 0.90625, 0.99609375, 0.90234375, 0.72265625, 0.9921875, 0.0, 0.70703125, 0.796875, 0.62109375, 0.6875, 0.796875, 0.61328125, 0.9921875, 0.9921875, 0.23046875, 0.828125, 0.0, 0.77734375, 0.54296875, 0.9921875, 0.8203125, 0.65234375, 0.70703125, 0.05859375, 0.90625, 0.79296875, 0.5625, 0.73828125, 0.703125, 0.82421875, 0.9921875, 0.6328125, 0.58203125, 0.9921875, 0.86328125, 0.578125, 0.2890625, 0.05859375, 0.80078125, 0.33984375, 0.66796875, 0.62109375, 0.0859375, 0.14453125, 0.0, 0.0, 0.7734375, 0.703125, 0.703125, 0.6640625, 0.02734375, 0.90625, 0.98828125, 0.8984375, 0.90625, 0.0, 0.0, 0.6875, 0.7265625, 0.7421875, 0.69140625, 0.80859375, 0.63671875, 0.99609375, 0.23046875, 0.99609375, 0.71484375, 0.06640625, 0.99609375, 0.76171875, 0.01953125, 0.76953125, 0.78515625, 0.72265625, 0.90625, 0.6953125, 0.578125, 0.90625, 0.5859375, 0.90625, 0.85546875, 0.90625, 0.61328125, 0.60546875, 0.609375, 0.78515625, 0.6953125, 0.90625, 0.59375, 0.796875, 0.90625, 0.734375, 0.90234375, 0.03125, 0.0, 0.23828125, 0.015625, 0.99609375, 0.66015625, 0.14453125, 0.75, 0.73828125, 0.99609375, 0.9921875, 0.9921875, 0.625, 0.55859375, 0.8046875, 0.69921875, 0.6484375, 0.734375, 0.59765625, 0.015625, 0.14453125, 0.90625, 0.73046875, 0.046875, 0.9921875, 0.12109375, 0.9921875, 0.59765625, 0.90625, 0.90625, 0.90625, 0.9921875, 0.90625, 0.03125, 0.5, 0.61328125, 0.0546875, 0.99609375, 0.0, 0.015625, 0.63671875, 0.68359375, 0.62109375, 0.79296875, 0.328125, 0.140625, 0.0, 0.0, 0.78515625, 0.63671875, 0.62109375, 0.6796875, 0.71484375, 0.640625, 0.7890625, 0.03515625, 0.9921875, 0.49609375, 0.0390625, 0.69921875, 0.09765625, 0.9921875, 0.6015625, 0.83984375, 0.99609375, 0.68359375, 0.60546875, 0.90625, 0.01953125, 0.01953125, 0.7421875, 0.90625, 0.6171875, 0.90625, 0.9921875, 0.9609375, 0.65234375, 0.0546875, 0.9921875, 0.81640625, 0.90625, 0.99609375, 0.421875, 0.27734375, 0.0, 0.90234375, 0.0625, 0.03125, 0.75390625, 0.64453125, 0.2421875, 0.67578125, 0.9921875, 0.90625, 0.90625, 0.9921875, 0.77734375, 0.90625, 0.75390625, 0.08203125, 0.734375, 0.60546875, 0.73828125, 0.67578125, 0.0625, 0.9921875, 0.90234375, 0.296875, 0.0, 0.03125, 0.05859375, 0.0703125, 0.9921875, 0.90625, 0.0, 0.90625, 0.765625, 0.62890625, 0.96484375, 0.6640625, 0.90625, 0.90625, 0.99609375, 0.90625, 0.8046875, 0.0625, 0.03125, 0.8984375, 0.75, 0.73828125, 0.80859375, 0.55078125, 0.9921875, 0.85546875, 0.0703125, 0.73046875, 0.62890625, 0.7421875, 0.05859375, 0.66015625, 0.671875, 0.70703125, 0.76171875, 0.1796875, 0.90625, 0.9921875, 0.90625, 0.390625, 0.6796875, 0.0, 0.671875, 0.578125, 0.6328125, 0.70703125, 0.890625, 0.66015625, 0.72265625, 0.0, 0.9921875, 0.90234375, 0.0234375, 0.65625, 0.2109375, 0.9921875, 0.9921875, 0.546875, 0.93359375, 0.734375, 0.0234375, 0.00390625, 0.09375, 0.90234375, 0.8671875, 0.609375, 0.7890625, 0.85546875, 0.63671875, 0.625, 0.90625, 0.8125, 0.83984375, 0.0, 0.0546875, 0.56640625, 0.515625, 0.90625, 0.59375, 0.73046875, 0.13671875, 0.05078125, 0.62890625, 0.0, 0.9921875, 0.99609375, 0.0546875, 0.10546875, 0.9921875, 0.5703125, 0.90234375, 0.9921875, 0.6953125, 0.8359375, 0.31640625, 0.82421875, 0.625, 0.0078125, 0.625, 0.69921875, 0.6640625, 0.8203125, 0.86328125, 0.01953125, 0.90625, 0.09375, 0.6953125, 0.25, 0.82421875, 0.90234375, 0.60546875, 0.9921875, 0.01171875, 0.80859375, 0.05078125, 0.0, 0.7421875, 0.19140625, 0.82421875, 0.8359375, 0.78515625, 0.515625, 0.015625, 0.7265625, 0.91015625, 0.70703125, 0.03515625, 0.08984375, 0.3046875, 0.79296875, 0.98828125, 0.90625, 0.3828125, 0.7578125, 0.6171875, 0.66015625, 0.65625, 0.5, 0.55078125, 0.734375, 0.0234375, 0.66015625, 0.56640625, 0.64453125, 0.82421875, 0.63671875, 0.7109375, 0.71875, 0.0, 0.0703125, 0.98828125, 0.8046875, 0.0703125, 0.88671875, 0.9921875, 0.0390625, 0.0, 0.5859375, 0.03515625, 0.5234375, 0.25390625, 0.70703125, 0.7890625, 0.90234375, 0.74609375, 0.05078125, 0.03125, 0.625, 0.73046875, 0.71875, 0.9296875, 0.0078125, 0.01953125, 0.86328125, 0.29296875, 0.9921875, 0.890625, 0.05859375, 0.81640625, 0.89453125, 0.01953125, 0.0234375, 0.765625, 0.9921875, 0.63671875, 0.7421875, 0.65625, 0.09375, 0.90625, 0.8984375, 0.0, 0.90625, 0.90625, 0.9921875, 0.0078125, 0.0625, 0.7578125, 0.015625, 0.9921875, 0.9921875, 0.9609375, 0.7421875, 0.63671875, 0.53125, 0.69140625, 0.99609375, 0.00390625, 0.953125, 0.90625, 0.73046875, 0.83203125, 0.0, 0.0546875, 0.16796875, 0.13671875, 0.00390625, 0.08984375, 0.9921875, 0.90625, 0.99609375, 0.90625, 0.625, 0.9921875, 0.671875]

 sparsity of   [0.6865234375, 0.998046875, 0.017578125, 0.9990234375, 0.8955078125, 0.0390625, 0.029296875, 0.0146484375, 0.8818359375, 0.9990234375, 0.0302734375, 0.03125, 0.826171875, 0.0556640625, 0.998046875, 0.8720703125, 0.9375, 0.03515625, 0.982421875, 0.00390625, 0.015625, 0.0283203125, 0.048828125, 0.060546875, 0.2900390625, 0.9970703125, 0.9990234375, 0.013671875, 0.01953125, 0.0478515625, 0.0546875, 0.08203125, 0.0673828125, 0.025390625, 0.0390625, 0.0, 0.083984375, 0.017578125, 0.1943359375, 0.0244140625, 0.9658203125, 0.0673828125, 0.0, 0.0439453125, 0.9267578125, 0.076171875, 0.1474609375, 0.0205078125, 0.1337890625, 0.0634765625, 0.01953125, 0.0146484375, 0.009765625, 0.998046875, 0.25390625, 0.0166015625, 0.9990234375, 0.1513671875, 0.9990234375, 0.1025390625, 0.0849609375, 0.0615234375, 0.9130859375, 0.0478515625, 0.0478515625, 0.9970703125, 0.0, 0.0400390625, 0.0537109375, 0.0146484375, 0.8818359375, 0.9365234375, 0.025390625, 0.1259765625, 0.02734375, 0.05078125, 0.072265625, 0.0283203125, 0.91015625, 0.1416015625, 0.1181640625, 0.0341796875, 0.9189453125, 0.998046875, 0.080078125, 0.9990234375, 0.0126953125, 0.015625, 0.9990234375, 0.0107421875, 0.9970703125, 0.0751953125, 0.998046875, 0.083984375, 0.1455078125, 0.998046875, 0.00390625, 0.802734375, 0.880859375, 0.919921875, 0.9765625, 0.7451171875, 0.0224609375, 0.0244140625, 0.04296875, 0.0498046875, 0.966796875, 0.0400390625, 0.0, 0.9072265625, 0.0283203125, 0.021484375, 0.900390625, 0.009765625, 0.9423828125, 0.0322265625, 0.0283203125, 0.091796875, 0.0556640625, 0.0390625, 0.0390625, 0.998046875, 0.0322265625, 0.0029296875, 0.05078125, 0.0419921875, 0.044921875, 0.0087890625, 0.998046875, 0.064453125, 0.0185546875, 0.9970703125, 0.9765625, 0.0517578125, 0.1806640625, 0.0205078125, 0.91015625, 0.9990234375, 0.0166015625, 0.041015625, 0.0302734375, 0.01171875, 0.0380859375, 0.04296875, 0.220703125, 0.0107421875, 0.8515625, 0.2392578125, 0.00390625, 0.8232421875, 0.0244140625, 0.07421875, 0.009765625, 0.0693359375, 0.03515625, 0.9990234375, 0.90625, 0.015625, 0.046875, 0.9970703125, 0.068359375, 0.0166015625, 0.998046875, 0.9287109375, 0.009765625, 0.0234375, 0.740234375, 0.0234375, 0.087890625, 0.0185546875, 0.8466796875, 0.107421875, 0.0302734375, 0.9443359375, 0.0107421875, 0.03125, 0.01171875, 0.0146484375, 0.82421875, 0.8291015625, 0.998046875, 0.0888671875, 0.03515625, 0.126953125, 0.9287109375, 0.072265625, 0.998046875, 0.1728515625, 0.01171875, 0.998046875, 0.1220703125, 0.0908203125, 0.07421875, 0.4912109375, 0.044921875, 0.0986328125, 0.0263671875, 0.6650390625, 0.0068359375, 0.0185546875, 0.998046875, 0.0224609375, 0.025390625, 0.0703125, 0.0966796875, 0.9580078125, 0.0673828125, 0.046875, 0.0986328125, 0.998046875, 0.1708984375, 0.076171875, 0.9248046875, 0.046875, 0.142578125, 0.138671875, 0.0107421875, 0.0341796875, 0.0224609375, 0.0224609375, 0.998046875, 0.0517578125, 0.892578125, 0.078125, 0.0654296875, 0.1103515625, 0.9521484375, 0.013671875, 0.021484375, 0.01171875, 0.10546875, 0.3076171875, 0.8388671875, 0.1025390625, 0.0283203125, 0.03125, 0.0263671875, 0.1005859375, 0.998046875, 0.119140625, 0.044921875, 0.998046875, 0.8408203125, 0.0322265625, 0.9462890625, 0.1474609375, 0.01171875, 0.9970703125, 0.0361328125, 0.7919921875, 0.0869140625, 0.0380859375, 0.0966796875, 0.0166015625, 0.03515625, 0.009765625]

 sparsity of   [0.0212673619389534, 0.02734375, 0.02170138992369175, 0.0668402761220932, 0.03515625, 0.1610243022441864, 0.5533854365348816, 0.0455729179084301, 0.0338541679084301, 0.9535590410232544, 0.0334201380610466, 0.0282118059694767, 0.7534722089767456, 0.02604166604578495, 0.02170138992369175, 0.0364583320915699, 0.0607638880610466, 0.0850694477558136, 0.02213541604578495, 0.0638020858168602, 0.0347222238779068, 0.02951388992369175, 0.9635416865348816, 0.0212673619389534, 0.0243055559694767, 0.01519097201526165, 0.1614583283662796, 0.0251736119389534, 0.1796875, 0.1002604141831398, 0.12109375, 0.323784738779068, 0.13671875, 0.7309027910232544, 0.0078125, 0.2348090261220932, 0.0546875, 0.01171875, 0.5438368320465088, 0.5755208134651184, 0.0290798619389534, 0.0377604179084301, 0.01953125, 0.0373263880610466, 0.1163194477558136, 0.0681423619389534, 0.0342881940305233, 0.046875, 0.0572916679084301, 0.2734375, 0.0086805559694767, 0.0894097238779068, 0.9986979365348816, 0.0577256940305233, 0.01996527798473835, 0.702256977558136, 0.02951388992369175, 0.0386284738779068, 0.2378472238779068, 0.9986979365348816, 0.5724826455116272, 0.0282118059694767, 0.9314236044883728, 0.1553819477558136, 0.0364583320915699, 0.0438368059694767, 0.1749131977558136, 0.0234375, 0.04296875, 0.1041666641831398, 0.0243055559694767, 0.7391493320465088, 0.2296006977558136, 0.9427083134651184, 0.0234375, 0.1002604141831398, 0.0329861119389534, 0.0967881977558136, 0.185329869389534, 0.0568576380610466, 0.0386284738779068, 0.106336809694767, 0.1193576380610466, 0.8754340410232544, 0.0494791679084301, 0.0164930559694767, 0.0377604179084301, 0.0377604179084301, 0.0186631940305233, 0.16015625, 0.173611119389534, 0.03081597201526165, 0.0368923619389534, 0.44921875, 0.0499131940305233, 0.0251736119389534, 0.2582465410232544, 0.0, 0.1675347238779068, 0.078125, 0.01215277798473835, 0.1393229216337204, 0.0316840298473835, 0.014756944961845875, 0.0941840261220932, 0.7604166865348816, 0.0768229141831398, 0.67578125, 0.0759548619389534, 0.0559895820915699, 0.0525173619389534, 0.00824652798473835, 0.00434027798473835, 0.02387152798473835, 0.01605902798473835, 0.0924479141831398, 0.0282118059694767, 0.62109375, 0.0338541679084301, 0.9995659589767456, 0.6931423544883728, 0.013020833022892475, 0.00824652798473835, 0.0746527761220932, 0.1935763955116272, 0.0842013880610466, 0.0052083334885537624, 0.0234375, 0.134548619389534, 0.01519097201526165, 0.9036458134651184, 0.0434027798473835, 0.0642361119389534, 0.8185763955116272, 0.0364583320915699, 0.013020833022892475, 0.0568576380610466, 0.0933159738779068, 0.53515625, 0.0164930559694767, 0.0603298619389534, 0.8932291865348816, 0.999131977558136, 0.006076388992369175, 0.0425347238779068, 0.010850694961845875, 0.0290798619389534, 0.1480034738779068, 0.5447048544883728, 0.0338541679084301, 0.0234375, 0.0768229141831398, 0.063368059694767, 0.0447048619389534, 0.6935763955116272, 0.8984375, 0.1631944477558136, 0.9986979365348816, 0.1410590261220932, 0.014756944961845875, 0.0486111119389534, 0.0863715261220932, 0.1744791716337204, 0.5082465410232544, 0.00390625, 0.1688368022441864, 0.067274309694767, 0.02604166604578495, 0.7795138955116272, 0.0416666679084301, 0.0902777761220932, 0.02951388992369175, 0.1032986119389534, 0.0125868059694767, 0.02473958395421505, 0.7439236044883728, 0.0251736119389534, 0.0503472238779068, 0.0203993059694767, 0.9422743320465088, 0.1354166716337204, 0.01605902798473835, 0.01996527798473835, 0.2191840261220932, 0.9361979365348816, 0.013888888992369175, 0.04296875, 0.02734375, 0.8793402910232544, 0.5056423544883728, 0.0212673619389534, 0.8259548544883728, 0.02300347201526165, 0.9496527910232544, 0.4986979067325592, 0.0030381944961845875, 0.0399305559694767, 0.02951388992369175, 0.03515625, 0.01822916604578495, 0.01215277798473835, 0.177517369389534, 0.0542534738779068, 0.0173611119389534, 0.0590277798473835, 0.7417534589767456, 0.02604166604578495, 0.014756944961845875, 0.02864583395421505, 0.014756944961845875, 0.02690972201526165, 0.5360243320465088, 0.8580729365348816, 0.02213541604578495, 0.02473958395421505, 0.015625, 0.0377604179084301, 0.7816840410232544, 0.5954861044883728, 0.02994791604578495, 0.009548611007630825, 0.082899309694767, 0.0251736119389534, 0.7717013955116272, 0.0, 0.0264756940305233, 0.7135416865348816, 0.01996527798473835, 0.0928819477558136, 0.078125, 0.0173611119389534, 0.7990451455116272, 0.0842013880610466, 0.02473958395421505, 0.862413227558136, 0.03125, 0.090711809694767, 0.1553819477558136, 0.0399305559694767, 0.9995659589767456, 0.014322916977107525, 0.1193576380610466, 0.02300347201526165, 0.013888888992369175, 0.0360243059694767, 0.02387152798473835, 0.0503472238779068, 0.6701388955116272, 0.0243055559694767, 0.03515625, 0.7018229365348816, 0.1072048619389534, 0.0321180559694767, 0.0681423619389534, 0.046875, 0.0759548619389534]

 sparsity of   [0.984375, 0.9921875, 0.99609375, 0.8984375, 0.9921875, 0.9921875, 0.984375, 0.98828125, 0.82421875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.90234375, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.89453125, 0.90234375, 0.9921875, 0.98828125, 0.95703125, 0.9921875, 0.99609375, 0.9921875, 0.984375, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.984375, 0.9921875, 0.9921875, 0.90625, 0.8984375, 0.88671875, 0.92578125, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.99609375, 0.9375, 0.98828125, 0.9140625, 0.9921875, 0.99609375, 0.99609375, 0.921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9140625, 0.99609375, 0.9921875, 0.98828125, 0.0625, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.90234375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.0, 0.99609375, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.90234375, 0.9453125, 0.9921875, 0.9921875, 0.98828125, 0.98828125, 0.99609375, 0.9921875, 0.89453125, 0.203125, 0.99609375, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.99609375, 0.05078125, 0.9453125, 0.9921875, 0.98828125, 0.99609375, 0.99609375, 0.98828125, 0.92578125, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.91796875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.9140625, 0.92578125, 0.9296875, 0.99609375, 0.99609375, 0.9921875, 0.98828125, 0.99609375, 0.9921875, 0.85546875, 0.99609375, 0.9921875, 0.9921875, 0.9453125, 0.9921875, 0.9921875, 0.9921875, 0.984375, 0.84765625, 0.9921875, 0.9921875, 0.9921875, 0.91796875, 0.9921875, 0.9921875, 0.9921875, 0.94140625, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.06640625, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.8046875, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.99609375, 0.90234375, 0.99609375, 0.9921875, 0.98828125, 0.91015625, 0.9921875, 0.9921875, 0.9921875, 0.9296875, 0.98828125, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.953125, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.8828125, 0.93359375, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.98828125, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9453125, 0.96484375, 0.9921875, 0.89453125, 0.9921875, 0.9921875, 0.98828125, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.91015625, 0.98828125, 0.9921875, 0.99609375, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.8984375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.99609375, 0.9921875, 0.9921875, 0.8984375, 0.99609375, 0.0703125, 0.9921875, 0.93359375, 0.9921875, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.98828125, 0.99609375, 0.9921875, 0.90625, 0.8984375, 0.8984375, 0.8984375, 0.9921875, 0.9921875, 0.98828125, 0.99609375, 0.9921875, 0.94140625, 0.98828125, 0.9140625, 0.9921875, 0.92578125, 0.9921875, 0.9921875, 0.99609375, 0.98828125, 0.91015625, 0.98828125, 0.984375, 0.9921875, 0.94921875, 0.92578125, 0.9921875, 0.90234375, 0.9921875, 0.9921875, 0.98828125, 0.99609375, 0.9921875, 0.99609375, 0.921875, 0.98828125, 0.9921875, 0.99609375, 0.9296875, 0.984375, 0.05859375, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.8984375, 0.9921875, 0.9921875, 0.12109375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.984375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.98828125, 0.921875, 0.9921875, 0.9921875, 0.90625, 0.91015625, 0.9921875, 0.9921875, 0.99609375, 0.984375, 0.84375, 0.9921875, 0.890625, 0.06640625, 0.984375, 0.9921875, 0.99609375, 0.9921875, 0.1328125, 0.9921875, 0.9921875, 0.9375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.98828125, 0.95703125, 0.98828125, 0.9921875, 0.90234375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.86328125, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.8984375, 0.92578125, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.921875, 0.99609375, 0.99609375, 0.9921875, 0.90234375, 0.9921875, 0.98828125, 0.99609375, 0.9921875, 0.93359375, 0.9921875, 0.9921875, 0.9296875, 0.9921875, 0.91796875, 0.9921875, 0.8359375, 0.98828125, 0.9921875, 0.078125, 0.9296875, 0.99609375, 0.98828125, 0.1953125, 0.98828125, 0.9921875, 0.8984375, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.99609375, 0.98828125, 0.91796875, 0.9296875, 0.8828125, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.1640625, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.984375, 0.9921875, 0.99609375, 0.9921875, 0.91015625, 0.93359375, 0.9921875, 0.99609375, 0.1171875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.94140625, 0.9921875, 0.9921875, 0.98828125, 0.99609375, 0.9921875, 0.93359375, 0.98828125, 0.9921875, 0.99609375, 0.96484375, 0.921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9140625, 0.23046875, 0.99609375, 0.98828125, 0.99609375, 0.9375, 0.89453125, 0.98828125, 0.99609375, 0.9921875, 0.92578125, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.91015625, 0.9921875, 0.9921875, 0.90234375, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.98828125, 0.0, 0.9921875, 0.92578125, 0.9921875, 0.10546875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.90234375, 0.98828125, 0.9921875, 0.9921875, 0.9375, 0.984375, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.90234375, 0.98828125, 0.8984375, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.94140625, 0.98828125, 0.9921875, 0.1875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.25, 0.9921875, 0.92578125, 0.9921875, 0.0859375, 0.99609375, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.0703125, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.984375, 0.9921875, 0.9921875, 0.984375, 0.9921875, 0.9921875, 0.98828125, 0.91796875, 0.98828125, 0.15234375, 0.9921875, 0.16796875, 0.9921875, 0.98828125, 0.9921875, 0.95703125, 0.9921875, 0.9921875, 0.9921875, 0.9140625, 0.99609375, 0.99609375, 0.9375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.92578125, 0.9921875, 0.98828125, 0.8984375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.90234375, 0.95703125, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.98828125, 0.90625, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.8828125, 0.9921875, 0.9453125, 0.8984375, 0.0, 0.99609375, 0.984375, 0.9921875, 0.984375, 0.9921875, 0.94140625, 0.9375, 0.90625, 0.98828125, 0.9921875, 0.8984375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.8984375, 0.9921875, 0.984375, 0.984375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.89453125, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.87890625, 0.9921875, 0.98828125, 0.98828125, 0.94921875, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.91015625, 0.99609375, 0.9921875, 0.98828125, 0.9140625, 0.99609375, 0.98828125, 0.9921875, 0.98828125, 0.99609375, 0.91796875, 0.90234375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.890625, 0.9921875, 0.9921875, 0.8828125, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.99609375, 0.1171875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.484375, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.90625, 0.09375, 0.7734375, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.04296875, 0.9921875, 0.9921875, 0.9921875, 0.8125, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9296875, 0.99609375, 0.9921875, 0.9921875, 0.7734375, 0.9921875, 0.98828125, 0.98828125, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.984375, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.953125, 0.98828125, 0.9921875, 0.88671875, 0.98828125, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.984375, 0.99609375, 0.98828125, 0.90234375, 0.90234375, 0.9921875, 0.9921875, 0.9921875, 0.921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.8828125, 0.98828125, 0.9921875, 0.9140625, 0.99609375, 0.98828125, 0.99609375, 0.890625, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.984375, 0.9921875, 0.9140625, 0.9921875, 0.984375, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.98828125, 0.98828125, 0.9140625, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.23828125, 0.9921875, 0.9921875, 0.9921875, 0.984375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.10546875, 0.98828125, 0.96484375, 0.98046875, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.984375, 0.8671875, 0.9921875, 0.99609375, 0.984375, 0.9921875, 0.99609375, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.91015625, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.921875, 0.984375, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.9140625, 0.1796875, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.8984375, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.171875, 0.90625, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.984375, 0.9921875, 0.99609375, 0.87890625, 0.20703125, 0.98828125, 0.99609375, 0.984375, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.91796875, 0.9921875, 0.9375, 0.94921875, 0.98828125, 0.96484375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.1953125, 0.984375, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.0546875, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.984375, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.91796875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.89453125, 0.9921875, 0.9921875, 0.9921875, 0.91796875, 0.98828125, 0.94140625, 0.9921875, 0.9921875, 0.984375, 0.77734375, 0.99609375, 0.9921875]

 sparsity of   [0.9970703125, 0.083984375, 0.123046875, 0.99609375, 0.9970703125, 0.1640625, 0.0341796875, 0.998046875, 0.07421875, 0.015625, 0.998046875, 0.7939453125, 0.0146484375, 0.998046875, 0.998046875, 0.9423828125, 0.0439453125, 0.0029296875, 0.0537109375, 0.91796875, 0.998046875, 0.037109375, 0.998046875, 0.07421875, 0.06640625, 0.9990234375, 0.998046875, 0.8427734375, 0.0888671875, 0.130859375, 0.998046875, 0.0791015625, 0.1591796875, 0.9970703125, 0.0498046875, 0.251953125, 0.03125, 0.998046875, 0.033203125, 0.0244140625, 0.998046875, 0.0390625, 0.998046875, 0.111328125, 0.1171875, 0.0302734375, 0.056640625, 0.998046875, 0.2412109375, 0.09375, 0.998046875, 0.0625, 0.998046875, 0.9228515625, 0.998046875, 0.1025390625, 0.0498046875, 0.3994140625, 0.0576171875, 0.169921875, 0.1845703125, 0.0361328125, 0.8916015625, 0.9970703125, 0.2607421875, 0.99609375, 0.775390625, 0.9970703125, 0.771484375, 0.998046875, 0.08203125, 0.9970703125, 0.0263671875, 0.0302734375, 0.998046875, 0.998046875, 0.181640625, 0.0087890625, 0.9990234375, 0.998046875, 0.998046875, 0.890625, 0.0361328125, 0.158203125, 0.84765625, 0.998046875, 0.9013671875, 0.0, 0.1083984375, 0.1708984375, 0.0439453125, 0.0673828125, 0.09375, 0.1474609375, 0.998046875, 0.78515625, 0.1220703125, 0.0947265625, 0.0322265625, 0.052734375, 0.998046875, 0.998046875, 0.998046875, 0.0302734375, 0.07421875, 0.9970703125, 0.1201171875, 0.052734375, 0.9111328125, 0.1142578125, 0.0283203125, 0.03515625, 0.041015625, 0.1064453125, 0.0322265625, 0.1591796875, 0.0087890625, 0.91015625, 0.109375, 0.1943359375, 0.998046875, 0.998046875, 0.9072265625, 0.0703125, 0.998046875, 0.171875, 0.15625, 0.0498046875, 0.08984375, 0.052734375, 0.048828125, 0.0771484375, 0.9970703125, 0.998046875, 0.9970703125, 0.998046875, 0.921875, 0.0693359375, 0.2099609375, 0.1064453125, 0.0634765625, 0.048828125, 0.9970703125, 0.947265625, 0.998046875, 0.115234375, 0.119140625, 0.998046875, 0.9970703125, 0.998046875, 0.236328125, 0.998046875, 0.8583984375, 0.0517578125, 0.09375, 0.8896484375, 0.998046875, 0.2099609375, 0.9970703125, 0.0751953125, 0.99609375, 0.181640625, 0.0283203125, 0.998046875, 0.998046875, 0.1279296875, 0.029296875, 0.998046875, 0.998046875, 0.9970703125, 0.2021484375, 0.099609375, 0.0322265625, 0.998046875, 0.9990234375, 0.02734375, 0.1982421875, 0.998046875, 0.998046875, 0.2060546875, 0.998046875, 0.1318359375, 0.201171875, 0.0693359375, 0.9541015625, 0.052734375, 0.0517578125, 0.90625, 0.998046875, 0.09375, 0.21875, 0.0546875, 0.03125, 0.998046875, 0.033203125, 0.0, 0.1416015625, 0.77734375, 0.8310546875, 0.0224609375, 0.998046875, 0.99609375, 0.9970703125, 0.20703125, 0.998046875, 0.431640625, 0.041015625, 0.0341796875, 0.0654296875, 0.9208984375, 0.078125, 0.029296875, 0.0615234375, 0.0341796875, 0.7861328125, 0.1474609375, 0.998046875, 0.1103515625, 0.0791015625, 0.0380859375, 0.998046875, 0.1181640625, 0.40234375, 0.115234375, 0.998046875, 0.009765625, 0.03515625, 0.046875, 0.07421875, 0.998046875, 0.0390625, 0.033203125, 0.064453125, 0.998046875, 0.9970703125, 0.1962890625, 0.998046875, 0.0771484375, 0.0126953125, 0.095703125, 0.09765625, 0.091796875, 0.0400390625, 0.998046875, 0.1552734375, 0.1015625, 0.0390625, 0.9970703125, 0.0126953125, 0.0185546875, 0.9384765625, 0.998046875, 0.0400390625, 0.0498046875, 0.9169921875, 0.998046875]

 sparsity of   [0.0872395858168602, 0.013888888992369175, 0.0842013880610466, 0.0785590261220932, 0.1649305522441864, 0.013020833022892475, 0.8910590410232544, 0.0755208358168602, 0.1336805522441864, 0.7782118320465088, 0.0755208358168602, 0.0164930559694767, 0.013020833022892475, 0.01996527798473835, 0.1740451455116272, 0.1432291716337204, 0.1015625, 0.0303819440305233, 0.9995659589767456, 0.01171875, 0.0338541679084301, 0.0399305559694767, 0.098524309694767, 0.0251736119389534, 0.0225694440305233, 0.007378472480922937, 0.0, 0.1414930522441864, 0.999131977558136, 0.005642361007630825, 0.0451388880610466, 0.02994791604578495, 0.02560763992369175, 0.02994791604578495, 0.0225694440305233, 0.9496527910232544, 0.0525173619389534, 0.1401909738779068, 0.02083333395421505, 0.0386284738779068, 0.0824652761220932, 0.83203125, 0.067274309694767, 0.03125, 0.02300347201526165, 0.0577256940305233, 0.694444477558136, 0.0416666679084301, 0.09375, 0.0442708320915699, 0.9995659589767456, 0.0737847238779068, 0.0863715261220932, 0.010850694961845875, 0.1380208283662796, 0.8415798544883728, 0.1276041716337204, 0.010416666977107525, 0.0434027798473835, 0.009982638992369175, 0.5208333134651184, 0.013888888992369175, 0.0542534738779068, 0.0859375, 0.0737847238779068, 0.014756944961845875, 0.0321180559694767, 0.0642361119389534, 0.1284722238779068, 0.7925347089767456, 0.0316840298473835, 0.0950520858168602, 0.76171875, 0.936631977558136, 0.16796875, 0.53125, 0.6636284589767456, 0.0720486119389534, 0.01996527798473835, 0.0173611119389534, 0.0243055559694767, 0.0755208358168602, 0.0125868059694767, 0.0416666679084301, 0.0251736119389534, 0.0338541679084301, 0.20703125, 0.9995659589767456, 0.9995659589767456, 0.0625, 0.999131977558136, 0.1137152761220932, 0.0598958320915699, 0.0303819440305233, 0.999131977558136, 0.0629340261220932, 0.0065104165114462376, 0.0703125, 0.9153645634651184, 0.013020833022892475, 0.082899309694767, 0.0455729179084301, 0.006076388992369175, 0.01605902798473835, 0.03081597201526165, 0.00390625, 0.7013888955116272, 0.0434027798473835, 0.1354166716337204, 0.8845486044883728, 0.0698784738779068, 0.1553819477558136, 0.0763888880610466, 0.02951388992369175, 0.0546875, 0.9995659589767456, 0.0525173619389534, 0.0034722222480922937, 0.02083333395421505, 0.729600727558136, 0.1080729141831398, 0.0338541679084301, 0.0677083358168602, 0.0625, 0.02994791604578495, 0.0164930559694767, 0.8919270634651184, 0.1493055522441864, 0.7977430820465088, 0.0685763880610466, 0.0412326380610466, 0.0364583320915699, 0.0264756940305233, 0.9995659589767456, 0.1584201455116272, 0.1545138955116272, 0.013888888992369175, 0.9986979365348816, 0.0533854179084301, 0.8198784589767456, 0.0381944440305233, 0.0555555559694767, 0.0503472238779068, 0.01779513992369175, 0.0768229141831398, 0.0477430559694767, 0.0477430559694767, 0.1605902761220932, 0.0225694440305233, 0.007378472480922937, 0.0065104165114462376, 0.010850694961845875, 0.9461805820465088, 0.0477430559694767, 0.0342881940305233, 0.015625, 0.2621527910232544, 0.0815972238779068, 0.0186631940305233, 0.03515625, 0.02734375, 0.0933159738779068, 0.83984375, 0.013888888992369175, 0.0902777761220932, 0.0529513880610466, 0.0334201380610466, 0.0234375, 0.0282118059694767, 0.999131977558136, 0.01215277798473835, 0.0486111119389534, 0.0594618059694767, 0.881944477558136, 0.0065104165114462376, 0.9418402910232544, 0.0924479141831398, 0.0212673619389534, 0.01171875, 0.7664930820465088, 0.01128472201526165, 0.03081597201526165, 0.0373263880610466, 0.01909722201526165, 0.01605902798473835, 0.0368923619389534, 0.1328125, 0.0394965298473835, 0.9995659589767456, 0.2039930522441864, 0.01215277798473835, 0.03515625, 0.0355902798473835, 0.03125, 0.0434027798473835, 0.0342881940305233, 0.007378472480922937, 0.1041666641831398, 0.999131977558136, 0.0611979179084301, 0.0655381977558136, 0.01909722201526165, 0.00434027798473835, 0.0390625, 0.075086809694767, 0.0360243059694767, 0.1046006977558136, 0.0434027798473835, 0.3185763955116272, 0.0559895820915699, 0.0347222238779068, 0.1202256977558136, 0.1597222238779068, 0.01519097201526165, 0.0915798619389534, 0.0486111119389534, 0.0403645820915699, 0.0724826380610466, 0.1184895858168602, 0.0, 0.01128472201526165, 0.1189236119389534, 0.01822916604578495, 0.01605902798473835, 0.1197916641831398, 0.009114583022892475, 0.0377604179084301, 0.0403645820915699, 0.0264756940305233, 0.0403645820915699, 0.01779513992369175, 0.0325520820915699, 0.0203993059694767, 0.1545138955116272, 0.0642361119389534, 0.0607638880610466, 0.0386284738779068, 0.01692708395421505, 0.009982638992369175, 0.13671875, 0.0251736119389534, 0.0069444444961845875, 0.071180559694767, 0.071180559694767, 0.9995659589767456, 0.0086805559694767, 0.0460069440305233, 0.2170138955116272, 0.19140625, 0.0290798619389534, 0.00390625, 0.02604166604578495, 0.08203125, 0.02951388992369175, 0.7252604365348816, 0.999131977558136]

 sparsity of   [0.98828125, 0.2109375, 0.45703125, 0.9921875, 0.27734375, 0.06640625, 0.98828125, 0.0, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.98828125, 0.03125, 0.97265625, 0.76171875, 0.37890625, 0.8359375, 0.109375, 0.98828125, 0.9921875, 0.0546875, 0.078125, 0.98828125, 0.28125, 0.98828125, 0.8828125, 0.85546875, 0.109375, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.12109375, 0.98828125, 0.29296875, 0.1796875, 0.03515625, 0.9921875, 0.98828125, 0.328125, 0.20703125, 0.98828125, 0.98828125, 0.03125, 0.2578125, 0.9921875, 0.98828125, 0.234375, 0.046875, 0.046875, 0.10546875, 0.234375, 0.9921875, 0.98828125, 0.06640625, 0.9921875, 0.47265625, 0.98828125, 0.99609375, 0.98828125, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.0859375, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.125, 0.09375, 0.9921875, 0.9921875, 0.98828125, 0.984375, 0.98828125, 0.0, 0.08984375, 0.98828125, 0.9921875, 0.05859375, 0.07421875, 0.0, 0.98828125, 0.9921875, 0.328125, 0.9921875, 0.0546875, 0.984375, 0.98828125, 0.0703125, 0.359375, 0.9921875, 0.13671875, 0.984375, 0.98828125, 0.984375, 0.09765625, 0.98828125, 0.98828125, 0.0859375, 0.98828125, 0.98828125, 0.17578125, 0.13671875, 0.984375, 0.98828125, 0.0, 0.44140625, 0.98828125, 0.98828125, 0.99609375, 0.19140625, 0.99609375, 0.046875, 0.109375, 0.09765625, 0.98828125, 0.046875, 0.98828125, 0.98828125, 0.13671875, 0.9921875, 0.80859375, 0.98828125, 0.9921875, 0.0546875, 0.9921875, 0.9921875, 0.98828125, 0.98828125, 0.85546875, 0.98828125, 0.98828125, 0.01953125, 0.9921875, 0.0546875, 0.04296875, 0.984375, 0.015625, 0.78125, 0.80078125, 0.98828125, 0.78515625, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.984375, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.98828125, 0.73828125, 0.98828125, 0.98828125, 0.9921875, 0.98828125, 0.984375, 0.98828125, 0.984375, 0.10546875, 0.9921875, 0.16015625, 0.09375, 0.5, 0.98828125, 0.23046875, 0.98828125, 0.98828125, 0.0390625, 0.98828125, 0.51171875, 0.98828125, 0.98828125, 0.984375, 0.98828125, 0.984375, 0.98828125, 0.99609375, 0.98828125, 0.05859375, 0.98828125, 0.046875, 0.0546875, 0.98828125, 0.125, 0.3671875, 0.98828125, 0.9921875, 0.9921875, 0.078125, 0.9921875, 0.98828125, 0.9921875, 0.87109375, 0.98828125, 0.9921875, 0.98828125, 0.84375, 0.9921875, 0.9921875, 0.984375, 0.98828125, 0.98828125, 0.9921875, 0.26953125, 0.98828125, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.984375, 0.05859375, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.98828125, 0.984375, 0.98828125, 0.0859375, 0.046875, 0.83984375, 0.98828125, 0.98828125, 0.078125, 0.9921875, 0.98828125, 0.1796875, 0.2890625, 0.99609375, 0.9921875, 0.98828125, 0.05078125, 0.890625, 0.0078125, 0.1015625, 0.98828125, 0.484375, 0.3828125, 0.9921875, 0.9921875, 0.296875, 0.265625, 0.83984375, 0.03515625, 0.15625, 0.98828125, 0.06640625, 0.98828125, 0.07421875, 0.00390625, 0.99609375, 0.00390625, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.28125, 0.9921875, 0.98828125, 0.984375, 0.09765625, 0.984375, 0.08203125, 0.98828125, 0.9921875, 0.4921875, 0.98828125, 0.98828125, 0.140625, 0.98828125, 0.98828125, 0.984375, 0.9921875, 0.984375, 0.984375, 0.98828125, 0.3984375, 0.98828125, 0.03515625, 0.07421875, 0.98828125, 0.9921875, 0.9921875, 0.078125, 0.0078125, 0.125, 0.98828125, 0.046875, 0.5625, 0.10546875, 0.99609375, 0.984375, 0.03125, 0.9921875, 0.9921875, 0.98828125, 0.0625, 0.98828125, 0.9921875, 0.14453125, 0.29296875, 0.9921875, 0.9921875, 0.5078125, 0.09765625, 0.98828125, 0.9921875, 0.98828125, 0.0, 0.98828125, 0.046875, 0.984375, 0.9921875, 0.0625, 0.984375, 0.23046875, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.98828125, 0.984375, 0.0703125, 0.0, 0.98828125, 0.08203125, 0.453125, 0.984375, 0.98828125, 0.0, 0.98828125, 0.12109375, 0.984375, 0.98828125, 0.98828125, 0.453125, 0.06640625, 0.98828125, 0.07421875, 0.08203125, 0.984375, 0.109375, 0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.984375, 0.03515625, 0.98828125, 0.9921875, 0.9921875, 0.2421875, 0.98828125, 0.99609375, 0.98828125, 0.0703125, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.984375, 0.98828125, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.984375, 0.98828125, 0.33203125, 0.32421875, 0.0390625, 0.86328125, 0.10546875, 0.984375, 0.9921875, 0.98828125, 0.98828125, 0.8671875, 0.9921875, 0.98828125, 0.98828125, 0.984375, 0.84765625, 0.98828125, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.98828125, 0.2265625, 0.03125, 0.29296875, 0.79296875, 0.0390625, 0.98828125, 0.98828125, 0.99609375, 0.984375, 0.3359375, 0.984375, 0.98828125, 0.10546875, 0.33984375, 0.08984375, 0.04296875, 0.98828125, 0.98828125, 0.078125, 0.98828125, 0.984375, 0.98828125, 0.21484375, 0.98828125, 0.17578125, 0.98828125, 0.98828125, 0.98828125, 0.1953125, 0.20703125, 0.1015625, 0.9921875, 0.98828125, 0.28125, 0.81640625, 0.89453125, 0.9921875, 0.87109375, 0.2734375, 0.00390625, 0.98828125, 0.03515625, 0.0, 0.984375, 0.984375, 0.99609375, 0.9921875, 0.0859375, 0.5078125, 0.01953125, 0.99609375, 0.98828125, 0.98828125, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.984375, 0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.9921875, 0.98828125, 0.984375, 0.30078125, 0.9921875, 0.98828125, 0.4375, 0.984375, 0.796875, 0.9921875, 0.921875, 0.23828125, 0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.046875, 0.0546875, 0.984375, 0.984375, 0.98828125, 0.9921875, 0.98828125, 0.984375, 0.98828125, 0.8359375, 0.9921875, 0.98828125, 0.98828125, 0.99609375, 0.98828125, 0.98828125, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.1953125, 0.98828125, 0.9921875, 0.16015625, 0.140625, 0.19140625, 0.10546875, 0.13671875, 0.9921875, 0.10546875, 0.98828125, 0.99609375, 0.9921875, 0.0625, 0.9921875, 0.05078125, 0.984375, 0.44140625, 0.0703125, 0.984375, 0.98828125, 0.28125, 0.984375, 0.01953125, 0.08984375, 0.9921875, 0.23828125, 0.984375, 0.98828125, 0.1015625, 0.05078125, 0.015625, 0.98828125, 0.66796875, 0.00390625, 0.98828125, 0.98828125, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.1328125, 0.98828125, 0.9765625, 0.984375, 0.984375, 0.98828125, 0.98828125, 0.99609375, 0.9921875, 0.078125, 0.00390625, 0.0390625, 0.13671875, 0.08203125, 0.98828125, 0.10546875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.98828125, 0.98828125, 0.984375, 0.91015625, 0.98828125, 0.99609375, 0.98828125, 0.98828125, 0.98828125, 0.4921875, 0.98828125, 0.98828125, 0.984375, 0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.9921875, 0.796875, 0.33203125, 0.13671875, 0.9921875, 0.9921875, 0.9921875, 0.4609375, 0.0390625, 0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.11328125, 0.9921875, 0.25, 0.984375, 0.98828125, 0.99609375, 0.99609375, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.98828125, 0.10546875, 0.0859375, 0.98828125, 0.9921875, 0.9921875, 0.2578125, 0.9921875, 0.0625, 0.9921875, 0.0, 0.14453125, 0.9921875, 0.99609375, 0.4609375, 0.06640625, 0.99609375, 0.06640625, 0.98828125, 0.98828125, 0.9921875, 0.0, 0.09765625, 0.26171875, 0.98828125, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.984375, 0.78125, 0.98828125, 0.98828125, 0.98828125, 0.2890625, 0.98828125, 0.9921875, 0.9921875, 0.15625, 0.09375, 0.98828125, 0.9921875, 0.98828125, 0.99609375, 0.05078125, 0.9921875, 0.98828125, 0.9921875, 0.796875, 0.0546875, 0.05078125, 0.44921875, 0.98828125, 0.0703125, 0.98828125, 0.98828125, 0.98828125, 0.1953125, 0.99609375, 0.98828125, 0.88671875, 0.98828125, 0.16796875, 0.984375, 0.984375, 0.3984375, 0.11328125, 0.98828125, 0.17578125, 0.04296875, 0.98828125, 0.04296875, 0.9921875, 0.08984375, 0.9921875, 0.05859375, 0.9921875, 0.9921875, 0.99609375, 0.984375, 0.98828125, 0.98828125, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.98828125, 0.0625, 0.02734375, 0.43359375, 0.98828125, 0.00390625, 0.98828125, 0.98828125, 0.98828125, 0.1640625, 0.18359375, 0.984375, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.984375, 0.8046875, 0.98828125, 0.0625, 0.984375, 0.98828125, 0.9921875, 0.9921875, 0.8671875, 0.078125, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.0703125, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.45703125, 0.9921875, 0.9921875, 0.98828125, 0.3125, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.37890625, 0.9921875, 0.99609375, 0.98828125, 0.98828125, 0.15234375, 0.98828125, 0.984375, 0.0625, 0.0, 0.98828125, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.984375, 0.9921875, 0.296875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.28125, 0.9921875, 0.0, 0.9921875, 0.328125, 0.984375, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.13671875, 0.0546875, 0.9921875, 0.98828125, 0.9921875, 0.00390625, 0.98828125, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.98828125, 0.00390625, 0.98828125, 0.00390625, 0.9921875, 0.98828125, 0.078125, 0.9921875, 0.9921875, 0.11328125, 0.05078125, 0.02734375, 0.98828125, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.140625, 0.03515625, 0.98828125, 0.98828125, 0.98828125, 0.9921875, 0.078125, 0.98828125, 0.9921875, 0.1015625, 0.98828125, 0.98828125, 0.984375, 0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.9921875, 0.984375, 0.39453125, 0.04296875, 0.2265625, 0.07421875, 0.9921875, 0.30859375, 0.99609375, 0.9921875, 0.9921875, 0.984375, 0.98828125, 0.0546875, 0.9921875, 0.03515625, 0.2578125, 0.984375, 0.98828125, 0.05859375, 0.98828125, 0.9921875, 0.06640625, 0.9921875, 0.98828125, 0.98828125, 0.984375, 0.16796875, 0.98828125, 0.984375, 0.0234375, 0.9921875, 0.98828125, 0.98828125, 0.05078125, 0.98828125, 0.03515625, 0.98828125, 0.0, 0.984375, 0.875, 0.1328125, 0.98828125, 0.1328125, 0.9921875, 0.9921875, 0.0390625, 0.9921875, 0.98828125, 0.0546875, 0.9921875, 0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.29296875, 0.04296875, 0.99609375, 0.23828125, 0.4375, 0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.015625, 0.98828125, 0.1015625, 0.98828125, 0.33203125, 0.98828125, 0.98828125, 0.9921875, 0.09765625, 0.0, 0.15625, 0.9921875, 0.9921875, 0.9921875, 0.34375, 0.9921875, 0.98828125, 0.00390625, 0.0546875, 0.99609375, 0.171875, 0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.01953125, 0.9921875, 0.00390625, 0.98828125, 0.0, 0.11328125, 0.98828125, 0.18359375, 0.98828125, 0.984375, 0.99609375, 0.984375, 0.98828125, 0.9921875, 0.984375, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.046875, 0.9921875, 0.984375, 0.07421875, 0.98828125, 0.98828125, 0.984375, 0.0390625, 0.98828125, 0.15234375, 0.0390625, 0.984375, 0.15234375, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.859375, 0.9921875, 0.3203125, 0.984375, 0.09375, 0.1796875, 0.98828125, 0.89453125, 0.9921875, 0.98828125, 0.08203125, 0.375, 0.98828125, 0.796875, 0.9921875, 0.98828125, 0.99609375, 0.98828125, 0.9921875, 0.984375, 0.19140625, 0.98828125, 0.9921875, 0.98828125, 0.28125, 0.98828125, 0.98828125, 0.984375, 0.98046875, 0.9921875, 0.53125, 0.984375, 0.984375, 0.98828125, 0.9921875, 0.98828125, 0.23046875, 0.046875, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.0625, 0.98828125, 0.0625, 0.9921875, 0.0625, 0.1015625, 0.98828125, 0.98828125, 0.16015625, 0.421875, 0.38671875, 0.98828125, 0.98828125, 0.08203125, 0.98828125, 0.05859375, 0.9921875]

 sparsity of   [0.998046875, 0.142578125, 0.998046875, 0.998046875, 0.0, 0.998046875, 0.998046875, 0.9970703125, 0.087890625, 0.9990234375, 0.998046875, 0.9970703125, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.9970703125, 0.9970703125, 0.998046875, 0.158203125, 0.998046875, 0.9970703125, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.1943359375, 0.9990234375, 0.9970703125, 0.9990234375, 0.9970703125, 0.998046875, 0.1337890625, 0.998046875, 0.9990234375, 0.140625, 0.998046875, 0.998046875, 0.119140625, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.51171875, 0.0, 0.0966796875, 0.4501953125, 0.998046875, 0.9990234375, 0.12890625, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.501953125, 0.9970703125, 0.9970703125, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.9970703125, 0.998046875, 0.9990234375, 0.998046875, 0.0, 0.1083984375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.859375, 0.998046875, 0.9990234375, 0.998046875, 0.9990234375, 0.998046875, 0.142578125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.0, 0.998046875, 0.998046875, 0.9990234375, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.0, 0.998046875, 0.9970703125, 0.998046875, 0.1279296875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.0, 0.99609375, 0.998046875, 0.998046875, 0.30859375, 0.9990234375, 0.9970703125, 0.4697265625, 0.998046875, 0.998046875, 0.1640625, 0.9990234375, 0.998046875, 0.9970703125, 0.109375, 0.0, 0.0, 0.9990234375, 0.9990234375, 0.998046875, 0.1318359375, 0.998046875, 0.9990234375, 0.998046875, 0.169921875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.1240234375, 0.46484375, 0.998046875, 0.447265625, 0.0390625, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.11328125, 0.998046875, 0.998046875, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.369140625, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9970703125, 0.4482421875, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.9990234375, 0.1279296875, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.9990234375, 0.8447265625, 0.9990234375, 0.998046875, 0.1484375, 0.9990234375, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.4501953125, 0.5537109375, 0.9970703125, 0.998046875, 0.9970703125, 0.0, 0.998046875, 0.9990234375, 0.0, 0.1240234375, 0.0966796875, 0.9990234375, 0.4765625, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.0, 0.07421875, 0.998046875, 0.0, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.9990234375, 0.4267578125, 0.4609375, 0.9990234375, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.9970703125, 0.0341796875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.0, 0.453125, 0.9970703125, 0.998046875, 0.9990234375, 0.9970703125, 0.9990234375, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.453125, 0.998046875, 0.9990234375, 0.455078125, 0.9990234375, 0.99609375, 0.1240234375, 0.998046875, 0.998046875, 0.1298828125, 0.9990234375, 0.998046875, 0.9970703125, 0.9990234375, 0.0, 0.99609375, 0.998046875, 0.9990234375, 0.1572265625, 0.998046875, 0.9970703125, 0.9970703125, 0.9990234375, 0.998046875, 0.9970703125, 0.998046875, 0.9990234375, 0.453125, 0.998046875, 0.1044921875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.1337890625, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.0, 0.9990234375, 0.9970703125, 0.9990234375, 0.4921875, 0.9990234375, 0.998046875, 0.998046875, 0.9970703125, 0.078125, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9970703125, 0.9970703125, 0.4375, 0.998046875, 0.091796875, 0.998046875, 0.9990234375, 0.9970703125, 0.1279296875, 0.9990234375, 0.0869140625, 0.998046875, 0.4736328125, 0.9990234375, 0.998046875, 0.9990234375, 0.0859375, 0.0, 0.998046875, 0.451171875, 0.9990234375, 0.1650390625, 0.861328125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.1826171875, 0.9970703125, 0.9970703125, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.115234375, 0.9990234375, 0.9990234375, 0.998046875, 0.9970703125, 0.9990234375, 0.998046875, 0.998046875, 0.1748046875, 0.9990234375, 0.11328125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.0, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.1279296875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.99609375, 0.9990234375, 0.9990234375, 0.998046875, 0.9990234375, 0.9990234375, 0.998046875, 0.123046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9970703125, 0.49609375, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.47265625, 0.9990234375, 0.998046875, 0.9990234375, 0.9990234375, 0.998046875, 0.4677734375, 0.998046875, 0.078125, 0.9990234375, 0.998046875, 0.9990234375, 0.9970703125, 0.9990234375, 0.9990234375, 0.462890625, 0.998046875, 0.130859375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.99609375, 0.0, 0.9990234375, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.9970703125, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.0, 0.4462890625, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.9990234375, 0.998046875, 0.193359375, 0.9990234375, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.0, 0.439453125, 0.9990234375, 0.9990234375, 0.0732421875, 0.9970703125, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.447265625]

 sparsity of   [0.322265625, 0.4641927182674408, 0.2369791716337204, 0.1649305522441864, 0.0983072891831398, 0.787109375, 0.9997829794883728, 0.1486545205116272, 0.8079426884651184, 0.1714409738779068, 0.0572916679084301, 0.9995659589767456, 0.10546875, 0.0959201380610466, 0.9848090410232544, 0.9995659589767456, 0.118055559694767, 0.1156684011220932, 0.9533420205116272, 0.12109375, 0.052734375, 0.0542534738779068, 0.9157986044883728, 0.8706597089767456, 0.9995659589767456, 0.02170138992369175, 0.060546875, 0.0381944440305233, 0.0904947891831398, 0.0490451380610466, 0.9995659589767456, 0.2094184011220932, 0.0614149309694767, 0.2241753488779068, 0.9995659589767456, 0.0483940988779068, 0.046875, 0.8348524570465088, 0.1263020783662796, 0.8407118320465088, 0.9995659589767456, 0.0427517369389534, 0.9381510615348816, 0.9997829794883728, 0.0729166641831398, 0.02756076492369175, 0.111328125, 0.0431857630610466, 0.0399305559694767, 0.0319010429084301, 0.9644097089767456, 0.9995659589767456, 0.9162326455116272, 0.1174045130610466, 0.084852434694767, 0.981553852558136, 0.9887152910232544, 0.8823784589767456, 0.971788227558136, 0.9993489384651184, 0.5766059160232544, 0.0998263880610466, 0.086805559694767, 0.8669704794883728, 0.0991753488779068, 0.9995659589767456, 0.1128472238779068, 0.0444878488779068, 0.778428852558136, 0.05859375, 0.0529513880610466, 0.9086371660232544, 0.9995659589767456, 0.0355902798473835, 0.9372829794883728, 0.0930989608168602, 0.0338541679084301, 0.9314236044883728, 0.364800363779068, 0.7719184160232544, 0.0, 0.9995659589767456, 0.9691840410232544, 0.0709635391831398, 0.7981770634651184, 0.0414496548473835, 0.0418836809694767, 0.1167534738779068, 0.9296875, 0.4071180522441864, 0.2259114533662796, 0.9995659589767456, 0.8949652910232544, 0.8383246660232544, 0.0466579869389534, 0.9379340410232544, 0.9995659589767456, 0.103515625, 0.080078125, 0.955078125, 0.9997829794883728, 0.8307291865348816, 0.1710069477558136, 0.0475260429084301, 0.0349392369389534, 0.8999565839767456, 0.0581597238779068, 0.7944878339767456, 0.1256510466337204, 0.9694010615348816, 0.8305121660232544, 0.1788194477558136, 0.9995659589767456, 0.0598958320915699, 0.0384114570915699, 0.0447048619389534, 0.1440972238779068, 0.0726996511220932, 0.0796440988779068, 0.1187065988779068, 0.9997829794883728, 0.9997829794883728, 0.9895833134651184, 0.978515625, 0.0961371511220932, 0.9592013955116272, 0.2319878488779068, 0.408203125, 0.9134114384651184, 0.0746527761220932, 0.8791232705116272, 0.8452690839767456, 0.0798611119389534, 0.0933159738779068, 0.1195746511220932, 0.0392795130610466, 0.0340711809694767, 0.9090712070465088, 0.0514322929084301, 0.0796440988779068, 0.3702256977558136, 0.0670572891831398, 0.02018229104578495, 0.9995659589767456, 0.1467013955116272, 0.9995659589767456, 0.0460069440305233, 0.7762587070465088, 0.955078125, 0.1883680522441864, 0.0366753488779068, 0.9995659589767456, 0.0575086809694767, 0.921875, 0.9754774570465088, 0.841796875, 0.9826388955116272, 0.9631076455116272, 0.9837239384651184, 0.0603298619389534, 0.0657552108168602, 0.8845486044883728, 0.0496961809694767, 0.3986545205116272, 0.9995659589767456, 0.0447048619389534, 0.0570746548473835, 0.0421006940305233, 0.9704861044883728, 0.080078125, 0.9733073115348816, 0.89453125, 0.0336371548473835, 0.087890625, 0.0720486119389534, 0.0588107630610466, 0.9689670205116272, 0.1254340261220932, 0.9574652910232544, 0.9993489384651184, 0.0598958320915699, 0.7879774570465088, 0.0870225727558136, 0.0980902761220932, 0.9995659589767456, 0.0952690988779068, 0.0536024309694767, 0.9689670205116272, 0.9995659589767456, 0.9995659589767456, 0.0, 0.0538194440305233, 0.9279513955116272, 0.958984375, 0.2215711772441864, 0.0364583320915699, 0.9993489384651184, 0.134765625, 0.978515625, 0.9789496660232544, 0.1076388880610466, 0.0, 0.08203125, 0.0629340261220932, 0.9583333134651184, 0.0640190988779068, 0.9563801884651184, 0.9674479365348816, 0.2248263955116272, 0.7430555820465088, 0.9995659589767456, 0.0392795130610466, 0.0323350690305233, 0.9995659589767456, 0.0384114570915699, 0.987413227558136, 0.0668402761220932, 0.0362413190305233, 0.1245659738779068, 0.1341145783662796, 0.140407994389534, 0.1039496511220932, 0.9995659589767456, 0.9993489384651184, 0.9997829794883728, 0.9995659589767456, 0.1026475727558136, 0.1206597238779068, 0.136501744389534, 0.9995659589767456, 0.8778212070465088, 0.0640190988779068, 0.9995659589767456, 0.0455729179084301, 0.0536024309694767, 0.2912326455116272, 0.048828125, 0.0785590261220932, 0.958116352558136, 0.9702690839767456, 0.9995659589767456, 0.0622829869389534, 0.9995659589767456, 0.98046875, 0.8305121660232544, 0.1729600727558136, 0.9995659589767456, 0.4188368022441864, 0.9995659589767456, 0.825303852558136, 0.0635850727558136, 0.1733940988779068, 0.0509982630610466, 0.0225694440305233, 0.0952690988779068, 0.2152777761220932, 0.9995659589767456, 0.03059895895421505, 0.8368055820465088, 0.9995659589767456, 0.126953125, 0.0375434048473835, 0.9995659589767456, 0.0562065988779068, 0.85546875, 0.9733073115348816, 0.9997829794883728, 0.8333333134651184, 0.0870225727558136, 0.0544704869389534, 0.1134982630610466, 0.9997829794883728, 0.123914934694767, 0.0264756940305233, 0.02669270895421505, 0.9828559160232544, 0.4626736044883728, 0.9995659589767456, 0.916015625, 0.02105034701526165, 0.9995659589767456, 0.0, 0.9995659589767456, 0.8309462070465088, 0.881944477558136, 0.9993489384651184, 0.1234809011220932, 0.0243055559694767, 0.06640625, 0.9995659589767456, 0.2354600727558136, 0.0698784738779068, 0.9733073115348816, 0.0421006940305233, 0.0316840298473835, 0.18359375, 0.9995659589767456, 0.0232204869389534, 0.1065538227558136, 0.9995659589767456, 0.9995659589767456, 0.9691840410232544, 0.1870659738779068, 0.9774305820465088, 0.9778645634651184, 0.0562065988779068, 0.2712673544883728, 0.0368923619389534, 0.0546875, 0.2645399272441864, 0.0451388880610466, 0.0377604179084301, 0.9993489384651184, 0.9995659589767456, 0.0, 0.9680989384651184, 0.0483940988779068, 0.102430559694767, 0.10546875, 0.0826822891831398, 0.060546875, 0.9997829794883728, 0.9720051884651184, 0.9995659589767456, 0.1529947966337204, 0.2135416716337204, 0.870225727558136, 0.978515625, 0.9995659589767456, 0.0516493059694767, 0.9995659589767456, 0.234157994389534, 0.0857204869389534, 0.958984375, 0.1169704869389534, 0.930772602558136, 0.1000434011220932, 0.1553819477558136, 0.0635850727558136, 0.1671006977558136, 0.2588975727558136, 0.296875, 0.0405815988779068, 0.0338541679084301, 0.0687934011220932, 0.0444878488779068, 0.1232638880610466, 0.9535590410232544, 0.9993489384651184, 0.9995659589767456, 0.9652777910232544, 0.9594184160232544, 0.9149305820465088, 0.0924479141831398, 0.1108940988779068, 0.9767795205116272, 0.0457899309694767, 0.9995659589767456, 0.9060329794883728, 0.0603298619389534, 0.876085102558136, 0.9997829794883728, 0.060546875, 0.0757378488779068, 0.9774305820465088, 0.9058159589767456, 0.9995659589767456, 0.965928852558136, 0.8563368320465088, 0.0262586809694767, 0.9585503339767456, 0.9772135615348816, 0.9995659589767456, 0.0627170130610466, 0.9741753339767456, 0.9646267294883728, 0.9995659589767456, 0.0444878488779068, 0.9598524570465088, 0.7141926884651184, 0.9830729365348816, 0.7973090410232544, 0.063368059694767, 0.971788227558136, 0.0284288190305233, 0.02604166604578495, 0.8708767294883728, 0.0959201380610466, 0.0581597238779068, 0.0815972238779068, 0.0959201380610466, 0.0744357630610466, 0.2332899272441864, 0.0479600690305233, 0.9817708134651184, 0.1000434011220932, 0.0583767369389534, 0.3246527910232544, 0.0347222238779068, 0.0551215298473835, 0.958984375, 0.8502604365348816, 0.1612413227558136, 0.1573350727558136, 0.845703125, 0.9548611044883728, 0.8452690839767456, 0.8509114384651184, 0.9995659589767456, 0.9995659589767456, 0.9898003339767456, 0.0494791679084301, 0.0444878488779068, 0.0347222238779068, 0.0813802108168602, 0.8036024570465088, 0.9997829794883728, 0.0377604179084301, 0.0223524309694767, 0.119140625, 0.1108940988779068, 0.029296875, 0.1028645858168602, 0.0978732630610466, 0.0776909738779068, 0.9060329794883728, 0.9644097089767456, 0.0846354141831398, 0.0618489570915699, 0.9685329794883728, 0.0735677108168602, 0.9995659589767456, 0.9750434160232544, 0.0792100727558136, 0.0549045130610466, 0.9995659589767456, 0.9765625, 0.9281684160232544, 0.0774739608168602, 0.0483940988779068, 0.9997829794883728, 0.0342881940305233, 0.8296440839767456, 0.130642369389534, 0.9995659589767456, 0.0952690988779068, 0.87890625, 0.9029948115348816, 0.0442708320915699, 0.8187934160232544, 0.02669270895421505, 0.9993489384651184, 0.811631977558136, 0.138671875, 0.0993923619389534, 0.03125, 0.7463107705116272, 0.6137152910232544, 0.9995659589767456, 0.0594618059694767, 0.7847222089767456, 0.7411024570465088, 0.0631510391831398, 0.9997829794883728, 0.0381944440305233, 0.9915364384651184, 0.999131977558136, 0.9995659589767456, 0.0440538190305233, 0.9142795205116272, 0.167751744389534, 0.9995659589767456, 0.05078125, 0.0397135429084301, 0.9995659589767456, 0.07421875, 0.0514322929084301, 0.0824652761220932, 0.9845920205116272, 0.9997829794883728, 0.8639323115348816, 0.9995659589767456, 0.0319010429084301, 0.0590277798473835, 0.0542534738779068, 0.9670138955116272, 0.9995659589767456, 0.2506510317325592, 0.9995659589767456, 0.0397135429084301, 0.0444878488779068, 0.046875, 0.756944477558136, 0.0425347238779068, 0.0815972238779068, 0.01996527798473835, 0.9761284589767456, 0.9665798544883728, 0.0, 0.9993489384651184, 0.2434895783662796, 0.8198784589767456, 0.8619791865348816, 0.0607638880610466, 0.05078125, 0.0564236119389534, 0.08203125, 0.0551215298473835, 0.8802083134651184, 0.0787760391831398, 0.0700954869389534, 0.1612413227558136]

 sparsity of   [0.0390625, 0.99609375, 0.234375, 0.201171875, 0.05859375, 0.009765625, 0.01953125, 0.0, 0.095703125, 0.005859375, 0.140625, 0.0234375, 0.01171875, 0.826171875, 0.2265625, 0.041015625, 0.046875, 0.00390625, 0.912109375, 0.056640625, 0.947265625, 0.10546875, 0.18359375, 0.01171875, 0.607421875, 0.0390625, 0.2109375, 0.830078125, 0.017578125, 0.9765625, 0.095703125, 0.025390625, 0.154296875, 0.369140625, 0.171875, 0.02734375, 0.076171875, 0.810546875, 0.0234375, 0.015625, 0.0234375, 0.009765625, 0.12890625, 0.015625, 0.017578125, 0.91796875, 0.01953125, 0.0625, 0.05078125, 0.01953125, 0.20703125, 0.677734375, 0.021484375, 0.09375, 0.021484375, 0.609375, 0.033203125, 0.0, 0.01171875, 0.6796875, 0.21484375, 0.103515625, 0.470703125, 0.119140625, 0.029296875, 0.083984375, 0.0703125, 0.2109375, 0.0234375, 0.546875, 0.87109375, 0.26171875, 0.025390625, 0.994140625, 0.048828125, 0.21875, 0.794921875, 0.56640625, 0.01171875, 0.8984375, 0.34765625, 0.0390625, 0.0, 0.033203125, 0.12890625, 0.052734375, 0.6953125, 0.037109375, 0.337890625, 0.18359375, 0.275390625, 0.013671875, 0.1875, 0.216796875, 0.30859375, 0.998046875, 0.314453125, 0.037109375, 0.4140625, 0.12109375, 0.947265625, 0.9140625, 0.873046875, 0.109375, 0.21875, 0.162109375, 0.69140625, 0.513671875, 0.041015625, 0.0390625, 0.2890625, 0.017578125, 0.07421875, 0.373046875, 0.072265625, 0.0, 0.0234375, 0.00390625, 0.330078125, 0.029296875, 0.08984375, 0.091796875, 0.091796875, 0.99609375, 0.001953125, 0.18359375, 0.734375, 0.08984375, 0.947265625, 0.0234375, 0.1484375, 0.021484375, 0.998046875, 0.341796875, 0.103515625, 0.994140625, 0.029296875, 0.740234375, 0.017578125, 0.0, 0.775390625, 0.07421875, 0.115234375, 0.375, 0.021484375, 0.99609375, 0.91796875, 0.91015625, 0.029296875, 0.056640625, 0.384765625, 0.5, 0.486328125, 0.86328125, 0.109375, 0.423828125, 0.99609375, 0.99609375, 0.0234375, 0.20703125, 0.16796875, 0.255859375, 0.701171875, 0.060546875, 0.056640625, 0.37109375, 0.896484375, 0.06640625, 0.005859375, 0.103515625, 0.025390625, 0.033203125, 0.048828125, 0.009765625, 0.421875, 0.0078125, 0.0859375, 0.06640625, 0.033203125, 0.017578125, 0.037109375, 0.037109375, 0.037109375, 0.962890625, 0.791015625, 0.099609375, 0.0, 0.30859375, 0.0234375, 0.076171875, 0.0234375, 0.095703125, 0.0078125, 0.951171875, 0.078125, 0.07421875, 0.99609375, 0.013671875, 0.029296875, 0.2109375, 0.568359375, 0.28515625, 0.87890625, 0.01171875, 0.037109375, 0.021484375, 0.16796875, 0.091796875, 0.171875, 0.015625, 0.01953125, 0.25390625, 0.025390625, 0.7578125, 0.029296875, 0.017578125, 0.251953125, 0.1640625, 0.06640625, 0.197265625, 0.083984375, 0.052734375, 0.017578125, 0.103515625, 0.111328125, 0.015625, 0.056640625, 0.017578125, 0.130859375, 0.03125, 0.767578125, 0.037109375, 0.017578125, 0.07421875, 0.19921875, 0.029296875, 0.05078125, 0.013671875, 0.1640625, 0.083984375, 0.033203125, 0.08203125, 0.0234375, 0.013671875, 0.958984375, 0.05078125, 0.21484375, 0.033203125, 0.453125, 0.142578125, 0.005859375, 0.912109375, 0.2578125, 0.052734375, 0.46875, 0.224609375, 0.24609375, 0.0390625, 0.02734375, 0.041015625, 0.5390625, 0.025390625, 0.740234375, 0.06640625, 0.04296875, 0.03515625, 0.015625, 0.068359375, 0.30859375, 0.078125, 0.51953125, 0.01953125, 0.009765625, 0.619140625, 0.037109375, 0.90234375, 0.021484375, 0.330078125, 0.525390625, 0.173828125, 0.25, 0.013671875, 0.953125, 0.080078125, 0.08984375, 0.306640625, 0.845703125, 0.28125, 0.044921875, 0.00390625, 0.06640625, 0.173828125, 0.138671875, 0.025390625, 0.103515625, 0.009765625, 0.015625, 0.0, 0.048828125, 0.109375, 0.99609375, 0.099609375, 0.2265625, 0.0234375, 0.9453125, 0.2734375, 0.951171875, 0.177734375, 0.458984375, 0.00390625, 0.021484375, 0.80078125, 0.0, 0.19140625, 0.869140625, 0.068359375, 0.041015625, 0.021484375, 0.109375, 0.025390625, 0.01953125, 0.7421875, 0.1015625, 0.755859375, 0.03125, 0.03125, 0.0, 0.013671875, 0.5546875, 0.94140625, 0.0546875, 0.041015625, 0.0, 0.296875, 0.005859375, 0.037109375, 0.150390625, 0.66796875, 0.271484375, 0.99609375, 0.224609375, 0.072265625, 0.17578125, 0.076171875, 0.9375, 0.052734375, 0.0625, 0.103515625, 0.021484375, 0.3125, 0.900390625, 0.302734375, 0.033203125, 0.998046875, 0.310546875, 0.8671875, 0.123046875, 0.783203125, 0.609375, 0.931640625, 0.19140625, 0.158203125, 0.041015625, 0.9140625, 0.947265625, 0.998046875, 0.0078125, 0.859375, 0.138671875, 0.0, 0.00390625, 0.892578125, 0.078125, 0.080078125, 0.021484375, 0.0234375, 0.287109375, 0.376953125, 0.005859375, 0.033203125, 0.994140625, 0.078125, 0.162109375, 0.328125, 0.599609375, 0.0078125, 0.2578125, 0.072265625, 0.0234375, 0.99609375, 0.03125, 0.001953125, 0.13671875, 0.84375, 0.021484375, 0.18359375, 0.015625, 0.306640625, 0.015625, 0.01171875, 0.015625, 0.00390625, 0.01171875, 0.021484375, 0.40625, 0.080078125, 0.0234375, 0.0625, 0.02734375, 0.080078125, 0.033203125, 0.767578125, 0.013671875, 0.013671875, 0.919921875, 0.06640625, 0.0234375, 0.00390625, 0.013671875, 0.130859375, 0.947265625, 0.857421875, 0.052734375, 0.01953125, 0.99609375, 0.201171875, 0.015625, 0.025390625, 0.267578125, 0.01953125, 0.0390625, 0.185546875, 0.462890625, 0.0, 0.0078125, 0.33984375, 0.025390625, 0.267578125, 0.033203125, 0.9296875, 0.03125, 0.998046875, 0.009765625, 0.009765625, 0.55859375, 0.0234375, 0.0546875, 0.056640625, 0.947265625, 0.17578125, 0.578125, 0.5390625, 0.658203125, 0.439453125, 0.015625, 0.865234375, 0.0, 0.91796875, 0.15625, 0.046875, 0.869140625, 0.0546875, 0.02734375, 0.080078125, 0.126953125, 0.037109375, 0.029296875, 0.001953125, 0.189453125, 0.134765625, 0.052734375, 0.017578125, 0.236328125, 0.025390625, 0.19921875, 0.01953125, 0.58203125, 0.083984375, 0.013671875, 0.0234375, 0.6875, 0.013671875, 0.099609375, 0.0703125, 0.064453125, 0.041015625, 0.107421875, 0.046875, 0.91796875, 0.26171875, 0.041015625, 0.0, 0.126953125, 0.009765625, 0.22265625, 0.041015625, 0.19140625, 0.056640625, 0.08984375, 0.03125, 0.0, 0.5390625, 0.859375, 0.064453125, 0.029296875, 0.82421875, 0.119140625, 0.548828125, 0.265625, 0.88671875, 0.763671875, 0.001953125, 0.076171875, 0.029296875, 0.9921875, 0.01171875, 0.8359375, 0.869140625, 0.384765625, 0.92578125, 0.296875, 0.220703125, 0.046875, 0.890625, 0.076171875, 0.19140625, 0.029296875, 0.43359375, 0.0234375, 0.607421875, 0.25390625, 0.078125, 0.923828125, 0.8671875, 0.01953125, 0.10546875, 0.009765625, 0.013671875, 0.67578125, 0.013671875, 0.01171875, 0.873046875, 0.318359375, 0.03125, 0.224609375, 0.041015625, 0.046875, 0.064453125, 0.00390625, 0.048828125, 0.072265625, 0.03125, 0.052734375, 0.013671875, 0.078125, 0.01953125, 0.033203125, 0.189453125, 0.84765625, 0.91015625, 0.119140625, 0.99609375, 0.0234375, 0.025390625, 0.611328125, 0.994140625, 0.87109375, 0.025390625, 0.048828125, 0.322265625, 0.4765625, 0.703125, 0.08203125, 0.8828125, 0.19140625, 0.603515625, 0.267578125, 0.09765625, 0.076171875, 0.037109375, 0.169921875, 0.005859375, 0.013671875, 0.88671875, 0.216796875, 0.04296875, 0.107421875, 0.04296875, 0.03515625, 0.091796875, 0.0546875, 0.009765625, 0.185546875, 0.373046875, 0.04296875, 0.021484375, 0.072265625, 0.041015625, 0.052734375, 0.0, 0.029296875, 0.208984375, 0.037109375, 0.052734375, 0.0234375, 0.203125, 0.947265625, 0.0, 0.025390625, 0.017578125, 0.068359375, 0.994140625, 0.025390625, 0.029296875, 0.0703125, 0.177734375, 0.046875, 0.953125, 0.013671875, 0.048828125, 0.1953125, 0.04296875, 0.791015625, 0.01953125, 0.017578125, 0.99609375, 0.0078125, 0.06640625, 0.078125, 0.99609375, 0.33203125, 0.09375, 0.0078125, 0.001953125, 0.962890625, 0.486328125, 0.99609375, 0.083984375, 0.08203125, 0.15625, 0.0, 0.01171875, 0.01171875, 0.009765625, 0.0, 0.265625, 0.09765625, 0.099609375, 0.05859375, 0.033203125, 0.8359375, 0.08984375, 0.076171875, 0.025390625, 0.638671875, 0.017578125, 0.1484375, 0.998046875, 0.14453125, 0.03125, 0.02734375, 0.015625, 0.869140625, 0.11328125, 0.62109375, 0.029296875, 0.318359375, 0.283203125, 0.08984375, 0.6953125, 0.046875, 0.076171875, 0.06640625, 0.0234375, 0.9296875, 0.18359375, 0.048828125, 0.306640625, 0.025390625, 0.888671875, 0.869140625, 0.884765625, 0.09375, 0.099609375, 0.0390625, 0.041015625, 0.064453125, 0.0390625, 0.939453125, 0.828125, 0.064453125, 0.208984375, 0.013671875, 0.080078125, 0.03515625, 0.22265625, 0.29296875, 0.0234375, 0.029296875, 0.220703125, 0.0703125, 0.646484375, 0.173828125, 0.01171875, 0.23046875, 0.947265625, 0.166015625, 0.921875, 0.013671875, 0.203125, 0.552734375, 0.021484375, 0.048828125, 0.025390625, 0.0234375, 0.103515625, 0.017578125, 0.994140625, 0.076171875, 0.0390625, 0.140625, 0.146484375, 0.025390625, 0.7109375, 0.833984375, 0.0, 0.8359375, 0.02734375, 0.1875, 0.947265625, 0.072265625, 0.046875, 0.3671875, 0.224609375, 0.1015625, 0.025390625, 0.015625, 0.103515625, 0.02734375, 0.013671875, 0.68359375, 0.033203125, 0.328125, 0.123046875, 0.392578125, 0.005859375, 0.17578125, 0.01171875, 0.306640625, 0.015625, 0.21875, 0.083984375, 0.9296875, 0.017578125, 0.03515625, 0.033203125, 0.01953125, 0.037109375, 0.638671875, 0.044921875, 0.181640625, 0.044921875, 0.046875, 0.314453125, 0.154296875, 0.05078125, 0.15625, 0.078125, 0.021484375, 0.029296875, 0.015625, 0.10546875, 0.9375, 0.2109375, 0.0546875, 0.0390625, 0.306640625, 0.115234375, 0.958984375, 0.4609375, 0.03515625, 0.021484375, 0.17578125, 0.009765625, 0.015625, 0.380859375, 0.0, 0.05078125, 0.0234375, 0.828125, 0.17578125, 0.009765625, 0.02734375, 0.625, 0.046875, 0.8828125, 0.029296875, 0.28125, 0.919921875, 0.365234375, 0.18359375, 0.0390625, 0.01953125, 0.017578125, 0.03515625, 0.412109375, 0.0, 0.04296875, 0.02734375, 0.056640625, 0.01953125, 0.021484375, 0.99609375, 0.083984375, 0.994140625, 0.021484375, 0.22265625, 0.240234375, 0.0390625, 0.703125, 0.3359375, 0.10546875, 0.03515625, 0.08203125, 0.359375, 0.326171875, 0.630859375, 0.86328125, 0.99609375, 0.265625, 0.013671875, 0.755859375, 0.0546875, 0.84765625, 0.462890625, 0.912109375, 0.021484375, 0.193359375, 0.88671875, 0.998046875, 0.767578125, 0.69140625, 0.03125, 0.01171875, 0.513671875, 0.052734375, 0.00390625, 0.16796875, 0.888671875, 0.095703125, 0.0546875, 0.099609375, 0.072265625, 0.017578125, 0.044921875, 0.01953125, 0.01953125, 0.94921875, 0.177734375, 0.009765625, 0.947265625, 0.033203125, 0.947265625, 0.025390625, 0.1875, 0.564453125, 0.02734375, 0.025390625, 0.03125, 0.232421875, 0.185546875, 0.037109375, 0.044921875, 0.01171875, 0.142578125, 0.642578125, 0.072265625, 0.125, 0.099609375, 0.0703125, 0.05078125, 0.369140625, 0.453125, 0.548828125, 0.044921875, 0.037109375, 0.0234375, 0.03515625, 0.947265625, 0.001953125, 0.998046875, 0.818359375, 0.20703125, 0.091796875, 0.2109375, 0.16015625, 0.935546875, 0.654296875, 0.947265625, 0.0, 0.013671875, 0.044921875, 0.11328125, 0.021484375, 0.01953125, 0.072265625, 0.03125, 0.263671875, 0.2109375, 0.7421875, 0.80859375, 0.03125, 0.064453125, 0.99609375, 0.6484375, 0.01171875, 0.888671875, 0.0625, 0.1796875, 0.009765625, 0.150390625, 0.53515625, 0.017578125, 0.0234375, 0.025390625, 0.1484375, 0.755859375, 0.349609375, 0.201171875, 0.1484375, 0.013671875, 0.03515625, 0.041015625, 0.025390625, 0.947265625, 0.904296875, 0.015625, 0.158203125, 0.904296875, 0.0390625, 0.15234375, 0.07421875, 0.3515625, 0.240234375, 0.927734375, 0.0546875, 0.87890625, 0.232421875, 0.0546875, 0.025390625, 0.072265625, 0.0703125, 0.734375, 0.0234375, 0.998046875, 0.197265625, 0.078125, 0.318359375, 0.056640625, 0.001953125, 0.048828125, 0.0234375, 0.77734375, 0.14453125, 0.947265625, 0.080078125, 0.998046875, 0.041015625, 0.05859375, 0.0, 0.94921875, 0.94921875, 0.091796875, 0.99609375, 0.9609375, 0.283203125, 0.078125, 0.0625, 0.140625, 0.287109375, 0.0, 0.962890625, 0.998046875, 0.091796875, 0.140625, 0.025390625, 0.06640625, 0.08203125, 0.234375, 0.1328125, 0.087890625, 0.091796875, 0.013671875, 0.0234375, 0.998046875, 0.072265625, 0.712890625, 0.7890625, 0.8828125, 0.474609375, 0.142578125, 0.048828125, 0.060546875, 0.77734375, 0.029296875, 0.326171875, 0.01171875, 0.7109375, 0.03125, 0.05859375, 0.349609375, 0.029296875, 0.05078125, 0.029296875, 0.005859375, 0.091796875, 0.9140625, 0.51171875, 0.09375, 0.01953125, 0.01953125, 0.083984375, 0.478515625, 0.021484375, 0.0234375, 0.04296875, 0.693359375, 0.236328125, 0.017578125, 0.01953125, 0.298828125, 0.99609375, 0.947265625, 0.236328125, 0.95703125, 0.201171875, 0.021484375, 0.095703125, 0.05859375, 0.00390625, 0.025390625, 0.05078125, 0.05859375, 0.072265625, 0.91796875, 0.2265625, 0.298828125, 0.015625, 0.029296875, 0.015625, 0.083984375, 0.205078125, 0.05078125, 0.04296875, 0.947265625, 0.328125, 0.029296875, 0.052734375, 0.08203125, 0.53515625, 0.05078125, 0.48828125, 0.013671875, 0.001953125, 0.080078125, 0.998046875, 0.046875, 0.013671875, 0.044921875, 0.017578125, 0.013671875, 0.0234375, 0.994140625, 0.01953125, 0.125, 0.0078125, 0.12890625, 0.033203125, 0.3046875, 0.58984375, 0.044921875, 0.04296875, 0.033203125, 0.2734375, 0.994140625, 0.013671875, 0.875, 0.953125, 0.0390625, 0.025390625, 0.12109375, 0.033203125, 0.0, 0.03125, 0.33203125, 0.01171875, 0.0859375, 0.99609375, 0.01171875, 0.720703125, 0.158203125, 0.138671875, 0.03125, 0.03515625, 0.361328125, 0.205078125, 0.447265625, 0.0390625, 0.017578125, 0.150390625, 0.03515625, 0.1875, 0.0703125, 0.041015625, 0.044921875, 0.8671875, 0.025390625, 0.16796875, 0.947265625, 0.03125, 0.0703125, 0.0234375, 0.01953125, 0.2421875, 0.99609375, 0.0, 0.078125, 0.203125, 0.013671875, 0.08984375, 0.13671875, 0.0, 0.08203125, 0.1875, 0.232421875, 0.1796875, 0.0234375, 0.189453125, 0.23828125, 0.189453125, 0.20703125, 0.236328125, 0.09765625, 0.8671875, 0.0234375, 0.03125, 0.935546875, 0.048828125, 0.921875, 0.189453125, 0.015625, 0.0390625, 0.951171875, 0.205078125, 0.51953125, 0.015625, 0.01953125, 0.275390625, 0.03515625, 0.076171875, 0.87109375, 0.94921875, 0.998046875, 0.99609375, 0.859375, 0.998046875, 0.02734375, 0.072265625, 0.912109375, 0.0390625, 0.02734375, 0.076171875, 0.43359375, 0.01953125, 0.021484375, 0.08984375, 0.05078125, 0.015625, 0.89453125, 0.998046875, 0.271484375, 0.935546875, 0.275390625, 0.03125, 0.82421875, 0.076171875, 0.046875, 0.271484375, 0.287109375, 0.189453125, 0.951171875, 0.060546875, 0.5390625, 0.76171875, 0.017578125, 0.109375, 0.21484375, 0.634765625, 0.021484375, 0.966796875, 0.861328125, 0.99609375, 0.05859375, 0.947265625, 0.1640625, 0.947265625, 0.048828125, 0.076171875, 0.03515625, 0.01953125, 0.138671875, 0.05859375, 0.02734375, 0.3046875, 0.05859375, 0.9140625, 0.171875, 0.5703125, 0.3046875, 0.130859375, 0.99609375, 0.88671875, 0.1640625, 0.013671875, 0.90625, 0.046875, 0.998046875, 0.0, 0.103515625, 0.634765625, 0.044921875, 0.01171875, 0.154296875, 0.01953125, 0.021484375, 0.021484375, 0.03125, 0.40625, 0.0, 0.99609375, 0.16015625, 0.158203125, 0.328125, 0.080078125, 0.166015625, 0.025390625, 0.630859375, 0.0078125, 0.060546875, 0.017578125, 0.09765625, 0.625, 0.021484375, 0.951171875, 0.001953125, 0.912109375, 0.041015625, 0.044921875, 0.08984375, 0.064453125, 0.03125, 0.818359375, 0.462890625, 0.0, 0.009765625, 0.08203125, 0.171875, 0.015625, 0.109375, 0.072265625, 0.052734375, 0.087890625, 0.18359375, 0.009765625, 0.99609375, 0.015625, 0.044921875, 0.15234375, 0.09765625, 0.080078125, 0.087890625, 0.03125, 0.0, 0.99609375, 0.01171875, 0.912109375, 0.033203125, 0.017578125, 0.09375, 0.158203125, 0.01953125, 0.04296875, 0.998046875, 0.97265625, 0.0390625, 0.0234375, 0.00390625, 0.2734375, 0.021484375, 0.0234375, 0.005859375, 0.03125, 0.43359375, 0.041015625, 0.02734375, 0.169921875, 0.55859375, 0.08203125, 0.318359375, 0.025390625, 0.294921875, 0.1484375, 0.046875, 0.580078125, 0.16796875, 0.208984375, 0.091796875, 0.021484375, 0.025390625, 0.0390625, 0.5546875, 0.017578125, 0.900390625, 0.041015625, 0.0234375, 0.330078125, 0.654296875, 0.025390625, 0.2734375, 0.025390625, 0.029296875, 0.171875, 0.01171875, 0.18359375, 0.09375, 0.576171875, 0.01171875, 0.298828125, 0.62890625, 0.025390625, 0.947265625, 0.021484375, 0.03515625, 0.087890625, 0.021484375, 0.322265625, 0.08203125, 0.146484375, 0.845703125, 0.076171875, 0.021484375, 0.27734375, 0.4375, 0.0078125, 0.42578125, 0.09765625, 0.8984375, 0.21484375, 0.044921875, 0.1015625, 0.13671875, 0.17578125, 0.05859375, 0.919921875, 0.021484375, 0.998046875, 0.060546875, 0.23046875, 0.154296875, 0.994140625, 0.078125, 0.5546875, 0.99609375, 0.17578125, 0.998046875, 0.03125, 0.107421875, 0.302734375, 0.015625, 0.013671875, 0.859375, 0.115234375, 0.03515625, 0.0390625, 0.02734375, 0.123046875, 0.1796875, 0.06640625, 0.021484375, 0.943359375, 0.056640625, 0.064453125, 0.150390625, 0.947265625, 0.8828125, 0.033203125, 0.076171875, 0.275390625, 0.314453125, 0.009765625, 0.013671875, 0.041015625, 0.0, 0.947265625, 0.26171875, 0.0390625, 0.78125, 0.947265625, 0.052734375, 0.58984375, 0.087890625, 0.25390625, 0.880859375, 0.052734375, 0.013671875, 0.021484375, 0.109375, 0.087890625, 0.654296875, 0.052734375, 0.052734375, 0.283203125, 0.03125, 0.16796875, 0.724609375, 0.0234375, 0.998046875, 0.03515625, 0.15234375, 0.3125, 0.99609375, 0.078125, 0.015625, 0.044921875, 0.009765625, 0.021484375, 0.046875, 0.046875, 0.162109375, 0.91796875, 0.041015625, 0.3046875, 0.09375, 0.078125, 0.998046875, 0.080078125, 0.189453125, 0.03125, 0.1484375, 0.4609375, 0.994140625, 0.181640625, 0.025390625, 0.060546875, 0.673828125, 0.8828125, 0.251953125, 0.046875, 0.021484375, 0.021484375, 0.083984375, 0.724609375, 0.78515625, 0.06640625, 0.01953125, 0.025390625, 0.14453125, 0.08203125, 0.279296875, 0.080078125, 0.5234375, 0.158203125, 0.234375, 0.779296875, 0.357421875, 0.0234375, 0.0390625, 0.748046875, 0.873046875, 0.583984375, 0.033203125, 0.01171875, 0.599609375, 0.025390625, 0.2421875, 0.060546875, 0.20703125, 0.185546875, 0.13671875, 0.935546875, 0.15625, 0.4609375, 0.033203125, 0.01953125, 0.701171875, 0.052734375, 0.15625, 0.05859375, 0.736328125, 0.05078125, 0.025390625, 0.087890625, 0.021484375, 0.0078125, 0.05078125, 0.75, 0.681640625, 0.02734375, 0.01171875, 0.73828125, 0.044921875, 0.294921875, 0.037109375, 0.998046875, 0.03515625, 0.01953125, 0.2265625, 0.947265625, 0.140625, 0.3046875, 0.826171875, 0.724609375, 0.013671875, 0.3046875, 0.19140625, 0.0234375, 0.076171875, 0.47265625, 0.234375, 0.111328125, 0.04296875, 0.048828125, 0.06640625, 0.017578125, 0.216796875, 0.017578125, 0.212890625, 0.1484375, 0.03515625, 0.03125, 0.912109375, 0.111328125, 0.015625, 0.01171875, 0.18359375, 0.03515625, 0.607421875, 0.99609375, 0.017578125, 0.927734375, 0.1484375, 0.5390625, 0.28515625, 0.99609375, 0.046875, 0.03125, 0.53125, 0.0546875, 0.703125, 0.0625, 0.0390625, 0.046875, 0.294921875, 0.076171875, 0.14453125, 0.06640625, 0.095703125, 0.142578125, 0.021484375, 0.69140625, 0.001953125, 0.021484375, 0.013671875, 0.396484375, 0.029296875, 0.23046875, 0.078125, 0.22265625, 0.900390625, 0.0078125, 0.0, 0.0234375, 0.99609375, 0.2265625, 0.876953125, 0.107421875, 0.021484375, 0.0546875, 0.232421875, 0.943359375, 0.0078125, 0.0, 0.09375, 0.01953125, 0.021484375, 0.013671875, 0.326171875, 0.30859375, 0.009765625, 0.349609375, 0.9609375, 0.296875, 0.009765625, 0.029296875, 0.037109375, 0.08203125, 0.939453125, 0.068359375, 0.171875, 0.021484375, 0.017578125, 0.029296875, 0.0625, 0.01953125, 0.033203125, 0.583984375, 0.044921875, 0.03125, 0.009765625, 0.69921875, 0.099609375, 0.029296875, 0.576171875, 0.0703125, 0.99609375, 0.33984375, 0.328125, 0.021484375, 0.498046875, 0.078125, 0.19140625, 0.234375, 0.171875, 0.1484375, 0.140625, 0.779296875, 0.99609375, 0.087890625, 0.189453125, 0.482421875, 0.0546875, 0.220703125, 0.03125, 0.05859375, 0.091796875, 0.0, 0.2109375, 0.00390625, 0.052734375, 0.099609375, 0.04296875, 0.185546875, 0.06640625, 0.109375, 0.54296875, 0.015625, 0.130859375, 0.025390625, 0.927734375, 0.947265625, 0.025390625, 0.0703125, 0.17578125, 0.201171875, 0.27734375, 0.734375, 0.1953125, 0.94140625, 0.0078125, 0.123046875, 0.041015625, 0.927734375, 0.00390625, 0.333984375, 0.001953125, 0.8671875, 0.99609375, 0.119140625, 0.34375, 0.033203125, 0.064453125, 0.12109375, 0.287109375, 0.005859375, 0.04296875, 0.9453125, 0.19140625, 0.037109375, 0.046875, 0.052734375, 0.03515625, 0.880859375, 0.04296875, 0.474609375, 0.021484375, 0.693359375, 0.0, 0.01953125, 0.265625, 0.884765625, 0.6015625, 0.947265625, 0.03125, 0.99609375, 0.03125, 0.955078125, 0.39453125, 0.0234375, 0.044921875, 0.03125, 0.02734375, 0.046875, 0.056640625, 0.189453125, 0.037109375, 0.087890625, 0.037109375, 0.060546875, 0.181640625, 0.013671875, 0.947265625, 0.013671875, 0.453125, 0.369140625, 0.158203125, 0.033203125, 0.091796875, 0.0546875, 0.01953125, 0.107421875, 0.927734375, 0.021484375, 0.0390625, 0.083984375, 0.03515625, 0.11328125, 0.017578125, 0.900390625, 0.2578125, 0.001953125, 0.01953125, 0.013671875, 0.27734375, 0.95703125, 0.63671875, 0.07421875, 0.162109375, 0.220703125, 0.037109375, 0.076171875, 0.25, 0.998046875, 0.451171875, 0.89453125, 0.2734375, 0.03125, 0.99609375, 0.052734375, 0.99609375, 0.2734375, 0.0859375, 0.310546875, 0.029296875, 0.0, 0.2265625, 0.01171875, 0.0, 0.04296875, 0.0625, 0.994140625, 0.044921875, 0.296875, 0.05078125, 0.9609375, 0.998046875, 0.009765625, 0.0, 0.017578125, 0.029296875, 0.130859375, 0.04296875, 0.064453125, 0.03515625, 0.7734375, 0.05859375, 0.189453125, 0.203125, 0.078125, 0.373046875, 0.048828125, 0.017578125, 0.02734375, 0.5625, 0.0859375, 0.91796875, 0.37890625, 0.068359375, 0.017578125, 0.060546875, 0.189453125, 0.111328125, 0.02734375, 0.03515625, 0.994140625, 0.044921875, 0.369140625, 0.029296875, 0.021484375, 0.00390625, 0.359375, 0.138671875, 0.03515625, 0.193359375, 0.1875, 0.080078125, 0.2734375, 0.1171875, 0.025390625, 0.181640625, 0.8203125, 0.853515625, 0.033203125, 0.0234375, 0.365234375, 0.0390625, 0.3359375, 0.603515625, 0.0, 0.01171875, 0.99609375, 0.396484375, 0.08984375, 0.212890625, 0.705078125, 0.033203125, 0.021484375, 0.04296875, 0.859375, 0.013671875, 0.03125, 0.021484375, 0.03125, 0.01171875, 0.021484375, 0.203125, 0.109375, 0.16015625, 0.20703125, 0.0546875, 0.947265625, 0.17578125, 0.810546875, 0.99609375, 0.0234375, 0.2890625, 0.001953125, 0.009765625, 0.04296875, 0.0546875, 0.068359375, 0.0234375, 0.056640625, 0.267578125, 0.01953125, 0.310546875, 0.099609375, 0.75390625, 0.037109375, 0.0, 0.95703125, 0.595703125, 0.138671875, 0.02734375, 0.90625, 0.03125, 0.05078125, 0.1796875, 0.03125, 0.99609375, 0.91015625, 0.330078125, 0.041015625, 0.447265625, 0.017578125, 0.201171875, 0.025390625, 0.166015625, 0.029296875, 0.078125, 0.173828125, 0.01953125, 0.01171875, 0.0546875, 0.033203125, 0.998046875, 0.947265625, 0.927734375, 0.03515625, 0.33203125, 0.150390625, 0.07421875, 0.025390625, 0.162109375, 0.025390625, 0.923828125, 0.02734375, 0.015625, 0.08203125, 0.025390625, 0.02734375, 0.181640625, 0.029296875, 0.689453125, 0.82421875, 0.994140625, 0.234375, 0.646484375, 0.21484375, 0.177734375, 0.013671875, 0.0078125, 0.912109375, 0.787109375, 0.16796875, 0.19921875, 0.240234375, 0.5703125, 0.87109375, 0.169921875, 0.00390625, 0.357421875, 0.07421875, 0.169921875, 0.341796875, 0.03125, 0.021484375, 0.26171875, 0.947265625, 0.025390625, 0.001953125, 0.033203125, 0.0, 0.166015625, 0.029296875, 0.251953125, 0.095703125, 0.0546875, 0.041015625, 0.03515625, 0.740234375, 0.2421875, 0.05078125, 0.07421875, 0.9375, 0.12109375, 0.017578125, 0.998046875, 0.013671875, 0.162109375, 0.359375, 0.0, 0.01953125, 0.1796875, 0.013671875, 0.994140625, 0.14453125, 0.99609375, 0.009765625, 0.025390625, 0.04296875, 0.89453125, 0.1328125, 0.0390625, 0.03125, 0.326171875, 0.267578125, 0.19140625, 0.15234375, 0.052734375, 0.076171875, 0.078125, 0.03515625, 0.14453125, 0.021484375, 0.01953125, 0.005859375, 0.150390625, 0.2109375, 0.220703125, 0.033203125, 0.015625, 0.015625, 0.017578125, 0.994140625, 0.884765625, 0.765625, 0.5, 0.912109375, 0.021484375, 0.1875, 0.115234375, 0.228515625, 0.728515625, 0.998046875, 0.041015625, 0.46484375, 0.01171875, 0.0390625, 0.015625, 0.74609375, 0.99609375, 0.017578125, 0.0390625, 0.373046875, 0.333984375, 0.328125, 0.009765625, 0.095703125, 0.994140625, 0.064453125, 0.03125, 0.017578125, 0.763671875, 0.150390625, 0.814453125, 0.009765625, 0.083984375, 0.03515625, 0.833984375, 0.158203125, 0.134765625, 0.716796875, 0.041015625, 0.490234375, 0.037109375, 0.99609375, 0.8828125, 0.009765625, 0.001953125, 0.650390625, 0.798828125, 0.02734375, 0.02734375, 0.080078125, 0.033203125, 0.998046875, 0.009765625, 0.01171875]

 sparsity of   [0.86328125, 0.0205078125, 0.0107421875, 0.818359375, 0.0390625, 0.15625, 0.9970703125, 0.0, 0.025390625, 0.5810546875, 0.1435546875, 0.8515625, 0.8759765625, 0.0244140625, 0.0830078125, 0.82421875, 0.0615234375, 0.8837890625, 0.361328125, 0.0986328125, 0.138671875, 0.0830078125, 0.12890625, 0.44921875, 0.0361328125, 0.1171875, 0.0126953125, 0.0595703125, 0.0302734375, 0.021484375, 0.0048828125, 0.001953125, 0.087890625, 0.130859375, 0.138671875, 0.0380859375, 0.1201171875, 0.1552734375, 0.8388671875, 0.0, 0.9990234375, 0.060546875, 0.923828125, 0.05078125, 0.015625, 0.8974609375, 0.0205078125, 0.9970703125, 0.0185546875, 0.041015625, 0.0078125, 0.08203125, 0.267578125, 0.009765625, 0.0146484375, 0.05078125, 0.16015625, 0.0107421875, 0.1572265625, 0.166015625, 0.0634765625, 0.01171875, 0.0185546875, 0.0419921875, 0.9072265625, 0.01953125, 0.005859375, 0.0107421875, 0.998046875, 0.009765625, 0.6611328125, 0.015625, 0.021484375, 0.111328125, 0.013671875, 0.0263671875, 0.0478515625, 0.0087890625, 0.2080078125, 0.130859375, 0.212890625, 0.103515625, 0.0, 0.0390625, 0.1630859375, 0.7373046875, 0.1787109375, 0.013671875, 0.0625, 0.0166015625, 0.1455078125, 0.107421875, 0.02734375, 0.033203125, 0.1552734375, 0.046875, 0.01171875, 0.033203125, 0.1396484375, 0.01171875, 0.0048828125, 0.013671875, 0.0, 0.03515625, 0.015625, 0.1591796875, 0.162109375, 0.021484375, 0.048828125, 0.841796875, 0.0166015625, 0.04296875, 0.7783203125, 0.041015625, 0.9970703125, 0.8017578125, 0.0419921875, 0.07421875, 0.1640625, 0.068359375, 0.0224609375, 0.890625, 0.7412109375, 0.8232421875, 0.0830078125, 0.0712890625, 0.0146484375, 0.0703125, 0.0234375, 0.052734375, 0.6708984375, 0.03125, 0.5849609375, 0.1630859375, 0.03125, 0.146484375, 0.06640625, 0.158203125, 0.3232421875, 0.02734375, 0.1279296875, 0.0146484375, 0.0126953125, 0.599609375, 0.2314453125, 0.0126953125, 0.01953125, 0.0390625, 0.0078125, 0.0244140625, 0.0654296875, 0.1396484375, 0.0126953125, 0.044921875, 0.0908203125, 0.1455078125, 0.0283203125, 0.005859375, 0.6396484375, 0.0048828125, 0.072265625, 0.091796875, 0.0419921875, 0.845703125, 0.0703125, 0.25, 0.9072265625, 0.3515625, 0.0048828125, 0.1630859375, 0.1376953125, 0.0146484375, 0.19140625, 0.01953125, 0.01171875, 0.6083984375, 0.1181640625, 0.01953125, 0.033203125, 0.9208984375, 0.111328125, 0.060546875, 0.02734375, 0.08203125, 0.013671875, 0.041015625, 0.0, 0.017578125, 0.9970703125, 0.041015625, 0.0322265625, 0.0234375, 0.0732421875, 0.01171875, 0.1240234375, 0.13671875, 0.6611328125, 0.1630859375, 0.0341796875, 0.0810546875, 0.1142578125, 0.458984375, 0.033203125, 0.0888671875, 0.0205078125, 0.998046875, 0.1796875, 0.0, 0.14453125, 0.0087890625, 0.9970703125, 0.095703125, 0.9970703125, 0.0087890625, 0.6982421875, 0.0, 0.828125, 0.134765625, 0.0498046875, 0.005859375, 0.115234375, 0.091796875, 0.830078125, 0.0361328125, 0.0478515625, 0.951171875, 0.0263671875, 0.03125, 0.1123046875, 0.8759765625, 0.0244140625, 0.318359375, 0.2080078125, 0.0244140625, 0.009765625, 0.7705078125, 0.123046875, 0.0556640625, 0.0791015625, 0.0146484375, 0.3359375, 0.92578125, 0.0205078125, 0.8359375, 0.0859375, 0.0322265625, 0.5478515625, 0.041015625, 0.0146484375, 0.00390625, 0.03515625, 0.3935546875, 0.0595703125, 0.9990234375, 0.1650390625, 0.095703125, 0.3564453125, 0.0341796875, 0.0244140625, 0.1650390625, 0.150390625, 0.044921875, 0.873046875, 0.0341796875, 0.0146484375, 0.6171875, 0.04296875, 0.099609375, 0.095703125, 0.0087890625, 0.0087890625, 0.0634765625, 0.029296875, 0.9677734375, 0.0146484375, 0.1123046875, 0.0439453125, 0.0087890625, 0.0078125, 0.169921875, 0.5068359375, 0.0322265625, 0.009765625, 0.0283203125, 0.9091796875, 0.1240234375, 0.0068359375, 0.1064453125, 0.044921875, 0.0126953125, 0.9990234375, 0.0078125, 0.0185546875, 0.01171875, 0.998046875, 0.0283203125, 0.0029296875, 0.9970703125, 0.0703125, 0.0234375, 0.0380859375, 0.0732421875, 0.0107421875, 0.0361328125, 0.021484375, 0.0009765625, 0.9970703125, 0.0302734375, 0.1123046875, 0.0078125, 0.0654296875, 0.791015625, 0.0, 0.0439453125, 0.0830078125, 0.1103515625, 0.0625, 0.9365234375, 0.095703125, 0.0166015625, 0.9541015625, 0.0205078125, 0.7841796875, 0.00390625, 0.1318359375, 0.08203125, 0.0, 0.013671875, 0.0380859375, 0.0537109375, 0.9970703125, 0.03125, 0.0, 0.033203125, 0.0068359375, 0.03125, 0.9990234375, 0.162109375, 0.1904296875, 0.0185546875, 0.1328125, 0.068359375, 0.0107421875, 0.05859375, 0.0107421875, 0.0126953125, 0.0029296875, 0.001953125, 0.998046875, 0.0107421875, 0.951171875, 0.01171875, 0.029296875, 0.97265625, 0.0107421875, 0.044921875, 0.029296875, 0.0302734375, 0.7197265625, 0.037109375, 0.0595703125, 0.0224609375, 0.0419921875, 0.017578125, 0.083984375, 0.744140625, 0.041015625, 0.0078125, 0.04296875, 0.0126953125, 0.08984375, 0.0693359375, 0.0185546875, 0.0166015625, 0.9970703125, 0.8583984375, 0.0185546875, 0.00390625, 0.0224609375, 0.033203125, 0.7236328125, 0.0068359375, 0.998046875, 0.1396484375, 0.0283203125, 0.0458984375, 0.1513671875, 0.02734375, 0.046875, 0.01953125, 0.0302734375, 0.0, 0.1806640625, 0.0234375, 0.7841796875, 0.1298828125, 0.0263671875, 0.154296875, 0.046875, 0.0693359375, 0.0185546875, 0.0224609375, 0.029296875, 0.0048828125, 0.0341796875, 0.2880859375, 0.791015625, 0.005859375, 0.998046875, 0.0205078125, 0.009765625, 0.04296875, 0.0380859375, 0.9287109375, 0.01953125, 0.34375, 0.01171875, 0.9228515625, 0.0380859375, 0.009765625, 0.0, 0.9990234375, 0.01171875, 0.7373046875, 0.1796875, 0.125, 0.01953125, 0.8876953125, 0.1015625, 0.0107421875, 0.01953125, 0.04296875, 0.138671875, 0.0068359375, 0.02734375, 0.12109375, 0.6162109375, 0.9970703125, 0.021484375, 0.9091796875, 0.0849609375, 0.1650390625, 0.806640625, 0.0205078125, 0.009765625, 0.0810546875, 0.1240234375, 0.064453125, 0.029296875, 0.0126953125, 0.08984375, 0.896484375, 0.041015625, 0.5107421875, 0.0205078125, 0.0302734375, 0.0390625, 0.9970703125, 0.099609375, 0.6943359375, 0.0283203125, 0.8984375, 0.021484375, 0.0068359375, 0.068359375, 0.0380859375, 0.2490234375, 0.1005859375, 0.0107421875, 0.1474609375, 0.9970703125, 0.01953125, 0.0810546875, 0.7333984375, 0.107421875, 0.0263671875, 0.1943359375, 0.0, 0.064453125, 0.1044921875, 0.0048828125, 0.0869140625, 0.021484375, 0.048828125, 0.064453125, 0.009765625, 0.0810546875, 0.9970703125, 0.611328125, 0.017578125, 0.9423828125, 0.2509765625, 0.0341796875, 0.0888671875, 0.998046875, 0.0390625, 0.0068359375, 0.7060546875, 0.11328125, 0.873046875, 0.0, 0.015625, 0.9970703125, 0.0087890625, 0.02734375, 0.0595703125, 0.0009765625, 0.0478515625, 0.0078125, 0.0986328125, 0.1376953125, 0.53515625, 0.0322265625, 0.1240234375, 0.9990234375, 0.150390625, 0.04296875, 0.033203125, 0.0185546875, 0.0302734375, 0.0517578125, 0.08203125, 0.01953125, 0.0, 0.1171875, 0.0185546875, 0.5537109375, 0.0107421875, 0.01953125, 0.025390625, 0.9375, 0.0380859375, 0.04296875, 0.1767578125, 0.0302734375, 0.2724609375, 0.53515625, 0.0556640625, 0.1484375, 0.255859375, 0.00390625, 0.4228515625, 0.009765625, 0.0380859375, 0.095703125, 0.03515625, 0.9990234375, 0.138671875, 0.9970703125, 0.4306640625, 0.0185546875, 0.0244140625, 0.095703125, 0.0537109375, 0.9970703125, 0.9970703125, 0.0673828125, 0.02734375, 0.3251953125, 0.880859375, 0.0302734375, 0.181640625, 0.0830078125, 0.0595703125, 0.2822265625, 0.0244140625, 0.759765625, 0.0126953125, 0.6376953125, 0.0302734375, 0.01953125, 0.8603515625, 0.03515625, 0.044921875, 0.00390625, 0.103515625, 0.0400390625, 0.099609375, 0.0048828125, 0.01171875, 0.1552734375, 0.0771484375, 0.640625, 0.12109375, 0.0146484375, 0.810546875, 0.1787109375, 0.0771484375, 0.0546875, 0.0458984375, 0.26171875, 0.02734375, 0.0341796875, 0.1552734375, 0.998046875, 0.0126953125, 0.0498046875, 0.0185546875, 0.0302734375, 0.0, 0.02734375, 0.009765625, 0.0185546875, 0.0087890625, 0.0224609375, 0.0048828125, 0.998046875, 0.9990234375, 0.0458984375, 0.9990234375, 0.01953125, 0.998046875, 0.080078125, 0.0048828125, 0.8173828125, 0.04296875, 0.9716796875, 0.2900390625, 0.013671875, 0.998046875, 0.56640625, 0.5869140625, 0.095703125, 0.11328125, 0.0126953125, 0.18359375, 0.0234375, 0.65234375, 0.8134765625, 0.1171875, 0.009765625, 0.3935546875, 0.03515625, 0.07421875, 0.0654296875, 0.02734375, 0.0185546875, 0.0458984375, 0.03125, 0.1279296875, 0.0, 0.025390625, 0.3515625, 0.0439453125, 0.0283203125, 0.14453125, 0.0322265625, 0.0166015625, 0.787109375, 0.0302734375, 0.0244140625, 0.0791015625, 0.0146484375, 0.251953125, 0.0810546875, 0.0302734375, 0.033203125, 0.0771484375, 0.0205078125, 0.9990234375, 0.07421875, 0.12890625, 0.9970703125, 0.2880859375, 0.0927734375, 0.1806640625, 0.021484375, 0.1123046875, 0.0185546875, 0.0087890625, 0.03125, 0.1884765625, 0.1328125, 0.0341796875, 0.12109375, 0.0234375, 0.052734375, 0.0146484375, 0.0771484375, 0.037109375, 0.025390625, 0.66796875, 0.017578125, 0.1630859375, 0.0146484375, 0.890625, 0.1484375, 0.029296875, 0.9326171875, 0.283203125, 0.951171875, 0.11328125, 0.94140625, 0.0390625, 0.044921875, 0.0068359375, 0.14453125, 0.734375, 0.0849609375, 0.005859375, 0.181640625, 0.0185546875, 0.0126953125, 0.0166015625, 0.162109375, 0.1259765625, 0.9140625, 0.12890625, 0.560546875, 0.23046875, 0.1455078125, 0.9970703125, 0.08203125, 0.2080078125, 0.576171875, 0.9970703125, 0.923828125, 0.1123046875, 0.18359375, 0.5205078125, 0.998046875, 0.1591796875, 0.0517578125, 0.9970703125, 0.2021484375, 0.0, 0.0361328125, 0.078125, 0.013671875, 0.0107421875, 0.0166015625, 0.9970703125, 0.123046875, 0.0380859375, 0.0673828125, 0.01953125, 0.0380859375, 0.017578125, 0.2109375, 0.0185546875, 0.0068359375, 0.140625, 0.150390625, 0.0087890625, 0.26953125, 0.6630859375, 0.0048828125, 0.0107421875, 0.0439453125, 0.0703125, 0.9970703125, 0.0712890625, 0.888671875, 0.7109375, 0.9326171875, 0.904296875, 0.0185546875, 0.6591796875, 0.1025390625, 0.009765625, 0.0625, 0.1845703125, 0.9970703125, 0.0107421875, 0.0126953125, 0.134765625, 0.998046875, 0.05078125, 0.94140625, 0.1923828125, 0.021484375, 0.9970703125, 0.06640625, 0.15625, 0.025390625, 0.5244140625, 0.0244140625, 0.01953125, 0.0224609375, 0.130859375, 0.05078125, 0.03125, 0.1318359375, 0.0849609375, 0.9970703125, 0.1484375, 0.04296875, 0.0791015625, 0.9990234375, 0.0341796875, 0.421875, 0.029296875, 0.0146484375, 0.0205078125, 0.0234375, 0.01953125, 0.013671875, 0.1787109375, 0.955078125, 0.0234375, 0.0693359375, 0.0673828125, 0.0078125, 0.015625, 0.900390625, 0.1298828125, 0.0, 0.0205078125, 0.0791015625, 0.06640625, 0.080078125, 0.0361328125, 0.9970703125, 0.0732421875, 0.5068359375, 0.0107421875, 0.1943359375, 0.0537109375, 0.0830078125, 0.166015625, 0.1259765625, 0.9189453125, 0.1171875, 0.1669921875, 0.029296875, 0.1474609375, 0.1728515625, 0.037109375, 0.033203125, 0.0048828125, 0.0087890625, 0.0078125, 0.09765625, 0.0166015625, 0.0, 0.30078125, 0.158203125, 0.017578125, 0.9130859375, 0.09375, 0.1572265625, 0.935546875, 0.8017578125, 0.2685546875, 0.1826171875, 0.91015625, 0.03515625, 0.1728515625, 0.9150390625, 0.1103515625, 0.0, 0.3408203125, 0.0068359375, 0.998046875, 0.0185546875, 0.279296875, 0.009765625, 0.9970703125, 0.0087890625, 0.8818359375, 0.005859375, 0.0087890625, 0.017578125, 0.0791015625, 0.7333984375, 0.05078125, 0.9970703125, 0.048828125, 0.01171875, 0.0498046875, 0.1474609375, 0.1455078125, 0.0322265625, 0.07421875, 0.0458984375, 0.0302734375, 0.0654296875, 0.0771484375, 0.009765625, 0.10546875, 0.150390625, 0.05078125, 0.361328125, 0.166015625, 0.1416015625, 0.052734375, 0.0234375, 0.0390625, 0.193359375, 0.01171875, 0.84375, 0.0400390625, 0.376953125, 0.0146484375, 0.111328125, 0.171875, 0.0244140625, 0.0068359375, 0.0068359375, 0.0283203125, 0.0263671875, 0.2646484375, 0.1845703125, 0.998046875, 0.0380859375, 0.1337890625, 0.0361328125, 0.0107421875, 0.01171875, 0.0, 0.08984375, 0.3203125, 0.01953125, 0.1298828125, 0.7216796875, 0.0166015625, 0.0712890625, 0.0859375, 0.095703125, 0.962890625, 0.005859375, 0.0810546875, 0.072265625, 0.9970703125, 0.0048828125, 0.19140625, 0.0556640625, 0.0029296875, 0.158203125, 0.0166015625, 0.017578125, 0.1044921875, 0.8154296875, 0.751953125, 0.0185546875, 0.1220703125, 0.017578125, 0.0048828125, 0.8916015625, 0.119140625, 0.158203125, 0.01171875, 0.1279296875, 0.095703125, 0.998046875, 0.0126953125, 0.130859375, 0.44921875, 0.9072265625, 0.0234375, 0.9248046875, 0.0712890625, 0.1484375, 0.02734375, 0.0537109375, 0.0244140625, 0.111328125, 0.015625, 0.017578125, 0.0859375, 0.015625, 0.9677734375, 0.025390625, 0.21484375, 0.009765625, 0.2392578125, 0.0537109375, 0.0166015625, 0.01953125, 0.9970703125, 0.302734375, 0.04296875, 0.1640625, 0.0146484375, 0.048828125, 0.1572265625, 0.9296875, 0.0400390625, 0.083984375, 0.087890625, 0.0, 0.9775390625, 0.1669921875, 0.23828125, 0.998046875, 0.0341796875, 0.0556640625, 0.0390625, 0.0224609375, 0.021484375, 0.0595703125, 0.013671875, 0.0078125, 0.017578125, 0.19921875, 0.2060546875, 0.0166015625, 0.859375, 0.009765625, 0.01171875, 0.130859375, 0.107421875, 0.103515625, 0.0732421875, 0.1865234375, 0.037109375, 0.111328125, 0.02734375, 0.060546875, 0.013671875, 0.4189453125, 0.013671875, 0.029296875, 0.013671875, 0.1025390625, 0.0224609375, 0.0283203125, 0.9970703125, 0.005859375, 0.8525390625, 0.0390625, 0.2041015625, 0.0927734375, 0.0302734375, 0.017578125, 0.9970703125, 0.0927734375, 0.0361328125, 0.0107421875, 0.9560546875, 0.13671875, 0.009765625, 0.03515625, 0.794921875, 0.041015625, 0.0107421875, 0.0283203125, 0.310546875, 0.0126953125, 0.18359375, 0.0185546875, 0.0166015625, 0.37890625, 0.0380859375, 0.044921875, 0.9990234375, 0.12890625, 0.16015625, 0.1083984375, 0.0341796875, 0.009765625, 0.009765625, 0.0244140625, 0.0146484375, 0.0244140625, 0.9453125, 0.0634765625, 0.01171875, 0.689453125, 0.0234375, 0.1064453125, 0.0224609375, 0.2294921875, 0.998046875, 0.0673828125, 0.04296875, 0.423828125, 0.015625, 0.125, 0.08203125, 0.0322265625, 0.0166015625, 0.037109375, 0.490234375, 0.0078125, 0.041015625, 0.95703125, 0.8447265625, 0.1572265625, 0.3828125, 0.2138671875, 0.0, 0.123046875, 0.1396484375, 0.15234375, 0.0107421875, 0.0048828125, 0.8291015625, 0.9970703125, 0.2392578125, 0.4912109375, 0.9091796875, 0.0, 0.068359375, 0.083984375, 0.0224609375, 0.0048828125, 0.9970703125, 0.025390625, 0.0009765625, 0.9111328125, 0.17578125, 0.0380859375, 0.00390625, 0.0234375, 0.0146484375, 0.0693359375, 0.015625, 0.021484375, 0.0166015625, 0.0927734375, 0.0068359375, 0.0888671875, 0.017578125, 0.0185546875, 0.060546875, 0.060546875, 0.1123046875, 0.0283203125, 0.958984375, 0.1015625, 0.0234375, 0.123046875, 0.0185546875, 0.0244140625, 0.0, 0.041015625, 0.162109375, 0.00390625, 0.1806640625, 0.9267578125, 0.0, 0.7470703125, 0.0732421875, 0.02734375, 0.0859375, 0.9345703125, 0.033203125, 0.1884765625, 0.095703125, 0.0908203125, 0.1318359375, 0.025390625, 0.0302734375, 0.095703125, 0.033203125, 0.9970703125, 0.8486328125, 0.0478515625, 0.015625, 0.0166015625, 0.048828125, 0.0341796875, 0.0068359375, 0.0234375, 0.0048828125, 0.0283203125, 0.0166015625, 0.9970703125, 0.0751953125, 0.955078125, 0.0576171875, 0.244140625, 0.0244140625, 0.03125, 0.1025390625, 0.0263671875, 0.2744140625, 0.169921875, 0.4443359375, 0.0908203125, 0.998046875, 0.0888671875, 0.0283203125, 0.00390625, 0.1650390625, 0.099609375, 0.0078125, 0.099609375, 0.2041015625, 0.0234375, 0.0341796875, 0.193359375, 0.076171875, 0.8408203125, 0.3671875, 0.017578125, 0.0244140625, 0.072265625, 0.412109375, 0.0263671875, 0.8486328125, 0.0078125, 0.013671875, 0.111328125, 0.0, 0.111328125, 0.05078125, 0.0205078125, 0.0908203125, 0.9990234375, 0.060546875, 0.025390625, 0.0029296875, 0.0107421875, 0.0087890625, 0.9970703125, 0.01953125, 0.0244140625, 0.2548828125, 0.033203125, 0.0283203125, 0.8994140625, 0.01171875, 0.0224609375, 0.146484375, 0.1357421875, 0.0029296875, 0.01171875, 0.0361328125, 0.017578125, 0.046875, 0.0048828125, 0.0244140625, 0.0498046875, 0.02734375, 0.6357421875, 0.0, 0.4921875, 0.0751953125, 0.998046875, 0.015625, 0.080078125, 0.8837890625, 0.728515625, 0.0576171875, 0.669921875, 0.14453125, 0.0302734375, 0.076171875, 0.05859375, 0.005859375, 0.01171875, 0.07421875, 0.130859375, 0.017578125, 0.0205078125, 0.01171875, 0.021484375, 0.97265625, 0.1171875, 0.0263671875, 0.0078125, 0.0390625, 0.998046875, 0.0615234375, 0.08984375, 0.091796875, 0.0791015625, 0.0205078125, 0.076171875, 0.01953125, 0.01171875, 0.0, 0.0166015625, 0.734375, 0.2236328125, 0.0029296875, 0.0, 0.0087890625, 0.06640625, 0.099609375, 0.0087890625, 0.0068359375, 0.109375, 0.9150390625, 0.0234375, 0.013671875, 0.0625, 0.072265625, 0.0205078125, 0.0234375, 0.0, 0.0869140625, 0.818359375, 0.0107421875, 0.0419921875, 0.0283203125, 0.10546875, 0.0244140625, 0.345703125, 0.0224609375, 0.86328125, 0.056640625, 0.005859375, 0.03515625, 0.0, 0.0546875, 0.044921875, 0.0478515625, 0.7958984375, 0.05859375, 0.1904296875, 0.009765625, 0.744140625, 0.42578125, 0.037109375, 0.09765625, 0.04296875, 0.0224609375, 0.0859375, 0.2470703125, 0.1435546875, 0.05078125, 0.0146484375, 0.146484375, 0.025390625, 0.109375, 0.0078125, 0.0244140625, 0.0166015625, 0.0029296875, 0.0908203125, 0.0146484375, 0.064453125, 0.001953125, 0.0078125, 0.01953125, 0.01171875, 0.0185546875, 0.0, 0.0078125, 0.013671875, 0.01171875, 0.0341796875, 0.9619140625, 0.0341796875, 0.5625, 0.123046875, 0.908203125, 0.0361328125, 0.10546875, 0.0185546875, 0.0859375, 0.80078125, 0.15234375, 0.0341796875, 0.263671875, 0.9970703125, 0.0498046875, 0.9990234375, 0.013671875, 0.0166015625, 0.013671875, 0.0478515625, 0.0380859375, 0.0087890625, 0.11328125, 0.8232421875, 0.103515625, 0.1162109375, 0.21484375, 0.0439453125, 0.0478515625, 0.02734375, 0.017578125, 0.0205078125, 0.0927734375, 0.056640625, 0.017578125, 0.0341796875, 0.01171875, 0.033203125, 0.0322265625, 0.0556640625, 0.962890625, 0.009765625, 0.140625, 0.9072265625, 0.048828125, 0.0048828125, 0.0380859375, 0.8759765625, 0.09765625, 0.05859375, 0.0390625, 0.013671875, 0.0654296875, 0.5859375, 0.16015625, 0.0810546875, 0.0068359375, 0.109375, 0.1943359375, 0.0869140625, 0.017578125, 0.9501953125, 0.107421875, 0.0107421875, 0.1201171875, 0.921875, 0.0576171875, 0.017578125, 0.013671875, 0.076171875, 0.0390625, 0.0244140625, 0.0595703125, 0.0302734375, 0.03515625, 0.0244140625, 0.0078125, 0.0087890625, 0.0087890625, 0.9970703125, 0.0234375, 0.1650390625, 0.158203125, 0.1650390625, 0.275390625, 0.169921875, 0.1201171875, 0.009765625, 0.998046875, 0.0439453125, 0.0244140625, 0.224609375, 0.0517578125, 0.9970703125, 0.052734375, 0.7626953125, 0.8681640625, 0.1435546875, 0.951171875, 0.041015625, 0.166015625, 0.9970703125, 0.064453125, 0.0126953125, 0.02734375, 0.9970703125, 0.1494140625, 0.0546875, 0.0947265625, 0.0390625, 0.0498046875, 0.037109375, 0.1103515625, 0.029296875, 0.044921875, 0.0126953125, 0.0146484375, 0.7705078125, 0.298828125, 0.0361328125, 0.0224609375, 0.0185546875, 0.140625, 0.2724609375, 0.0439453125, 0.27734375, 0.0263671875, 0.130859375, 0.859375, 0.1142578125, 0.015625, 0.0126953125, 0.0576171875, 0.1025390625, 0.0224609375, 0.017578125, 0.0048828125, 0.0107421875, 0.1826171875, 0.34375, 0.0576171875, 0.03515625, 0.04296875, 0.5654296875, 0.0234375, 0.8037109375, 0.0263671875, 0.501953125, 0.5869140625, 0.1748046875, 0.01171875, 0.01171875, 0.017578125, 0.9970703125, 0.015625, 0.00390625, 0.0029296875, 0.048828125, 0.158203125, 0.1787109375, 0.099609375, 0.0419921875, 0.26171875, 0.08203125, 0.998046875, 0.19921875, 0.408203125, 0.001953125, 0.01953125, 0.0205078125, 0.0146484375, 0.1396484375, 0.1015625, 0.998046875, 0.322265625, 0.0283203125, 0.01171875, 0.0615234375, 0.0244140625, 0.0126953125, 0.08203125, 0.015625, 0.0654296875, 0.005859375, 0.009765625, 0.1982421875, 0.0283203125, 0.013671875, 0.021484375, 0.0322265625, 0.029296875, 0.060546875, 0.0068359375, 0.0068359375, 0.03125, 0.3154296875, 0.013671875, 0.08203125, 0.7080078125, 0.2763671875, 0.197265625, 0.0341796875, 0.0087890625, 0.7353515625, 0.0654296875, 0.8779296875, 0.0205078125, 0.0166015625, 0.02734375, 0.998046875, 0.0107421875, 0.0263671875, 0.0234375, 0.1064453125, 0.7880859375, 0.03125, 0.185546875, 0.017578125, 0.7177734375, 0.0478515625, 0.048828125, 0.1640625, 0.0712890625, 0.4541015625, 0.9970703125, 0.0595703125, 0.1357421875, 0.00390625, 0.0283203125, 0.2275390625, 0.9306640625, 0.0400390625, 0.0087890625, 0.076171875, 0.0234375, 0.998046875, 0.072265625, 0.0283203125, 0.013671875, 0.025390625, 0.1240234375, 0.4521484375, 0.0078125, 0.03515625, 0.0185546875, 0.31640625, 0.05078125, 0.013671875, 0.01171875, 0.869140625, 0.029296875, 0.0205078125, 0.0048828125, 0.001953125, 0.0107421875, 0.0263671875, 0.01171875, 0.0126953125, 0.0048828125, 0.0400390625, 0.0205078125, 0.0849609375, 0.009765625, 0.0439453125, 0.158203125, 0.755859375, 0.0361328125, 0.9423828125, 0.326171875, 0.021484375, 0.0166015625, 0.083984375, 0.017578125, 0.1591796875, 0.033203125, 0.0087890625, 0.646484375, 0.291015625, 0.1630859375, 0.00390625, 0.0888671875, 0.041015625, 0.0244140625, 0.15234375, 0.861328125, 0.310546875, 0.03125, 0.0888671875, 0.0234375, 0.009765625, 0.0380859375, 0.017578125, 0.16796875, 0.0166015625, 0.0078125, 0.1044921875, 0.0283203125, 0.0625, 0.1142578125, 0.044921875, 0.9970703125, 0.013671875, 0.09375, 0.0078125, 0.01171875, 0.025390625, 0.0146484375, 0.0244140625, 0.0361328125, 0.0791015625, 0.0, 0.0634765625, 0.0322265625, 0.09375, 0.0361328125, 0.0546875, 0.0322265625, 0.0263671875, 0.0146484375, 0.01953125, 0.0849609375, 0.1064453125, 0.099609375, 0.01171875, 0.037109375, 0.52734375, 0.015625, 0.0126953125, 0.0361328125, 0.2021484375, 0.607421875, 0.0712890625, 0.0107421875, 0.001953125, 0.17578125, 0.0576171875, 0.0185546875, 0.0166015625, 0.0322265625, 0.1083984375, 0.0283203125, 0.9970703125, 0.0380859375, 0.013671875, 0.009765625, 0.0166015625, 0.6494140625, 0.005859375, 0.0732421875, 0.955078125, 0.0078125, 0.9970703125, 0.9970703125, 0.025390625, 0.9970703125, 0.9970703125, 0.759765625, 0.0615234375, 0.1162109375, 0.2490234375, 0.15625, 0.0, 0.0205078125, 0.1337890625, 0.1318359375, 0.0810546875, 0.0087890625, 0.0419921875, 0.02734375, 0.013671875, 0.0126953125, 0.013671875, 0.021484375, 0.02734375, 0.998046875, 0.0615234375, 0.1552734375, 0.0185546875, 0.134765625, 0.134765625, 0.0595703125, 0.041015625, 0.064453125, 0.0244140625, 0.0048828125, 0.0732421875, 0.9326171875, 0.1513671875, 0.0087890625, 0.2587890625, 0.5400390625, 0.02734375, 0.796875, 0.9970703125, 0.2255859375, 0.0400390625, 0.9697265625, 0.0830078125, 0.029296875, 0.052734375, 0.6787109375, 0.0400390625, 0.953125, 0.0283203125, 0.0517578125, 0.3173828125, 0.064453125, 0.0126953125, 0.0380859375, 0.0087890625, 0.1904296875, 0.033203125, 0.9970703125, 0.0361328125, 0.724609375, 0.1640625, 0.0068359375, 0.09375, 0.0283203125, 0.1474609375, 0.029296875, 0.07421875, 0.9755859375, 0.0166015625, 0.0400390625, 0.080078125, 0.0166015625, 0.0205078125, 0.0, 0.203125, 0.998046875, 0.0, 0.998046875, 0.095703125, 0.068359375, 0.9501953125, 0.017578125, 0.0185546875, 0.787109375, 0.234375, 0.0947265625, 0.6748046875, 0.0234375, 0.564453125, 0.998046875, 0.029296875, 0.060546875, 0.6015625, 0.22265625, 0.08984375, 0.16796875, 0.1005859375, 0.134765625, 0.1484375, 0.0390625, 0.033203125, 0.93359375, 0.072265625, 0.9970703125, 0.0556640625, 0.009765625, 0.046875, 0.0263671875, 0.0830078125, 0.1201171875, 0.0478515625, 0.95703125, 0.998046875, 0.03515625, 0.9033203125, 0.021484375, 0.068359375, 0.0205078125, 0.0732421875, 0.1708984375, 0.033203125, 0.0048828125, 0.017578125, 0.119140625, 0.998046875, 0.0361328125, 0.8642578125, 0.013671875, 0.0029296875, 0.095703125, 0.017578125, 0.1865234375, 0.0126953125, 0.0224609375, 0.0517578125, 0.1650390625, 0.623046875, 0.0087890625, 0.041015625, 0.0322265625, 0.017578125, 0.1005859375, 0.0166015625, 0.03515625, 0.0771484375, 0.0888671875, 0.0869140625, 0.7734375, 0.0283203125, 0.0458984375, 0.0166015625, 0.111328125, 0.14453125, 0.2158203125, 0.009765625, 0.0068359375, 0.0048828125, 0.025390625, 0.9970703125, 0.0283203125, 0.0146484375, 0.0537109375, 0.017578125, 0.19140625, 0.1376953125, 0.0302734375, 0.03515625, 0.0185546875, 0.0244140625, 0.0029296875, 0.0244140625, 0.0791015625, 0.0068359375, 0.1015625, 0.1328125, 0.0166015625, 0.06640625, 0.4814453125, 0.9970703125, 0.9990234375, 0.0654296875, 0.4638671875, 0.025390625, 0.0283203125, 0.037109375, 0.0205078125, 0.0185546875, 0.8662109375, 0.94140625, 0.6025390625, 0.00390625, 0.755859375, 0.01953125, 0.884765625, 0.1875, 0.0986328125, 0.03125, 0.017578125, 0.015625, 0.0302734375, 0.0224609375, 0.017578125, 0.814453125, 0.03515625, 0.216796875, 0.033203125, 0.0283203125, 0.16796875, 0.0322265625, 0.5419921875, 0.314453125, 0.27734375, 0.03515625, 0.8505859375, 0.2373046875, 0.609375, 0.0361328125, 0.4384765625, 0.0498046875, 0.064453125, 0.16796875, 0.8291015625, 0.9970703125, 0.0205078125, 0.0439453125, 0.025390625, 0.8828125, 0.6728515625, 0.0146484375, 0.1181640625, 0.0166015625, 0.9970703125, 0.8515625, 0.1943359375, 0.259765625, 0.0107421875, 0.005859375, 0.009765625, 0.060546875, 0.9130859375, 0.0966796875, 0.0556640625, 0.0166015625, 0.1435546875, 0.6923828125, 0.05859375, 0.2333984375, 0.041015625, 0.30078125, 0.71484375, 0.9970703125, 0.0, 0.0234375, 0.09375, 0.37890625, 0.7490234375, 0.0263671875, 0.0146484375, 0.0224609375, 0.0341796875, 0.1435546875, 0.05078125, 0.013671875, 0.1484375, 0.0, 0.0166015625, 0.0244140625, 0.2275390625, 0.01171875, 0.193359375, 0.0, 0.1201171875, 0.0302734375, 0.1318359375, 0.623046875, 0.103515625, 0.0830078125, 0.06640625, 0.6279296875, 0.998046875, 0.3818359375, 0.0, 0.0537109375, 0.9609375, 0.037109375, 0.015625, 0.0107421875, 0.0439453125, 0.021484375, 0.0166015625, 0.177734375, 0.91796875, 0.0517578125, 0.1279296875, 0.0634765625, 0.0087890625, 0.0205078125, 0.017578125, 0.142578125, 0.052734375, 0.0712890625, 0.056640625, 0.595703125, 0.869140625, 0.3173828125, 0.4384765625, 0.0341796875, 0.9970703125, 0.01953125, 0.03515625, 0.0048828125, 0.009765625, 0.6123046875, 0.103515625, 0.025390625, 0.107421875, 0.0234375, 0.0283203125, 0.15625, 0.013671875, 0.02734375, 0.0166015625, 0.0849609375, 0.0078125, 0.697265625, 0.013671875, 0.916015625, 0.998046875, 0.0361328125, 0.15625, 0.0439453125, 0.3115234375, 0.0712890625, 0.017578125, 0.0439453125, 0.0146484375, 0.8642578125, 0.0029296875, 0.255859375, 0.150390625, 0.0302734375, 0.0419921875, 0.912109375, 0.0107421875, 0.8017578125, 0.0771484375, 0.0419921875, 0.099609375, 0.998046875, 0.005859375, 0.322265625, 0.01953125, 0.0361328125, 0.013671875, 0.2509765625, 0.0166015625, 0.2294921875, 0.8251953125]

 sparsity of   [0.0517578125, 0.12451171875, 0.13916015625, 0.06689453125, 0.03466796875, 0.54248046875, 0.02685546875, 0.84375, 0.13916015625, 0.0556640625, 0.02197265625, 0.884765625, 0.0400390625, 0.04541015625, 0.72119140625, 0.05517578125, 0.626953125, 0.04052734375, 0.03662109375, 0.060546875, 0.0283203125, 0.05078125, 0.6201171875, 0.18212890625, 0.2373046875, 0.63818359375, 0.96142578125, 0.0107421875, 0.10791015625, 0.0888671875, 0.201171875, 0.794921875, 0.88330078125, 0.07470703125, 0.044921875, 0.03173828125, 0.03076171875, 0.6953125, 0.03125, 0.6396484375, 0.08154296875, 0.1328125, 0.53759765625, 0.10498046875, 0.07666015625, 0.06689453125, 0.01806640625, 0.037109375, 0.08642578125, 0.080078125, 0.01806640625, 0.05078125, 0.08154296875, 0.05419921875, 0.052734375, 0.123046875, 0.1162109375, 0.03857421875, 0.0302734375, 0.12890625, 0.671875, 0.67431640625, 0.0302734375, 0.64306640625, 0.99951171875, 0.0498046875, 0.03955078125, 0.72509765625, 0.072265625, 0.044921875, 0.048828125, 0.642578125, 0.03955078125, 0.064453125, 0.0986328125, 0.15234375, 0.1474609375, 0.05322265625, 0.04052734375, 0.890625, 0.02099609375, 0.62451171875, 0.6015625, 0.77099609375, 0.03564453125, 0.04248046875, 0.10498046875, 0.056640625, 0.638671875, 0.02880859375, 0.06494140625, 0.5576171875, 0.70361328125, 0.58447265625, 0.0859375, 0.77294921875, 0.6552734375, 0.75537109375, 0.74462890625, 0.03076171875, 0.0341796875, 0.05712890625, 0.03271484375, 0.0537109375, 0.28857421875, 0.76953125, 0.072265625, 0.0234375, 0.10595703125, 0.08544921875, 0.150390625, 0.01318359375, 0.0400390625, 0.05712890625, 0.08203125, 0.20751953125, 0.6767578125, 0.05029296875, 0.091796875, 0.4873046875, 0.16748046875, 0.01171875, 0.99853515625, 0.63916015625, 0.01123046875, 0.09521484375, 0.03564453125, 0.0517578125, 0.0185546875, 0.02978515625, 0.11669921875, 0.05419921875, 0.77685546875, 0.5947265625, 0.05517578125, 0.03955078125, 0.04296875, 0.64697265625, 0.57470703125, 0.04345703125, 0.99951171875, 0.115234375, 0.01220703125, 0.12548828125, 0.10302734375, 0.0439453125, 0.1103515625, 0.04736328125, 0.05712890625, 0.037109375, 0.7607421875, 0.0380859375, 0.05078125, 0.85888671875, 0.0712890625, 0.02734375, 0.03173828125, 0.0791015625, 0.10107421875, 0.20458984375, 0.083984375, 0.10546875, 0.8125, 0.81591796875, 0.04150390625, 0.05224609375, 0.15283203125, 0.2744140625, 0.6337890625, 0.88232421875, 0.99853515625, 0.0, 0.20751953125, 0.0302734375, 0.16748046875, 0.04833984375, 0.01416015625, 0.04833984375, 0.02880859375, 0.03662109375, 0.03515625, 0.037109375, 0.0537109375, 0.796875, 0.2490234375, 0.7021484375, 0.12890625, 0.06103515625, 0.03857421875, 0.0576171875, 0.23095703125, 0.052734375, 0.052734375, 0.01904296875, 0.75244140625, 0.38037109375, 0.81005859375, 0.03125, 0.0478515625, 0.654296875, 0.46044921875, 0.591796875, 0.01953125, 0.17919921875, 0.03955078125, 0.6103515625, 0.05908203125, 0.1337890625, 0.0380859375, 0.015625, 0.0146484375, 0.6865234375, 0.61181640625, 0.09326171875, 0.0205078125, 0.05859375, 0.1513671875, 0.17138671875, 0.0, 0.05517578125, 0.03125, 0.02294921875, 0.15869140625, 0.064453125, 0.0732421875, 0.0185546875, 0.03125, 0.52587890625, 0.083984375, 0.0712890625, 0.07568359375, 0.60400390625, 0.99951171875, 0.77099609375, 0.5302734375, 0.1572265625, 0.01171875, 0.06689453125, 0.009765625, 0.59765625, 0.72314453125, 0.099609375, 0.07666015625, 0.0390625, 0.0205078125, 0.0966796875, 0.11865234375, 0.1748046875, 0.0126953125, 0.634765625, 0.83544921875, 0.5615234375, 0.1279296875, 0.11669921875, 0.767578125, 0.03466796875, 0.60302734375, 0.04150390625, 0.19775390625, 0.64306640625, 0.0830078125, 0.05517578125, 0.02587890625, 0.10498046875, 0.07421875, 0.052734375, 0.1005859375, 0.017578125, 0.11328125, 0.60400390625, 0.1376953125, 0.04833984375, 0.87548828125, 0.064453125, 0.03955078125, 0.06689453125, 0.6279296875, 0.064453125, 0.80224609375, 0.18896484375, 0.01611328125, 0.08837890625, 0.0478515625, 0.03564453125, 0.02197265625, 0.9990234375, 0.103515625, 0.19775390625, 0.06591796875, 0.0791015625, 0.19921875, 0.66357421875, 0.66748046875, 0.03564453125, 0.6142578125, 0.2373046875, 0.06005859375, 0.6708984375, 0.05908203125, 0.02685546875, 0.66796875, 0.57861328125, 0.1611328125, 0.09765625, 0.74755859375, 0.01171875, 0.037109375, 0.72412109375, 0.78759765625, 0.54833984375, 0.06103515625, 0.078125, 0.03125, 0.0634765625, 0.0, 0.15576171875, 0.095703125, 0.03271484375, 0.1171875, 0.6689453125, 0.01318359375, 0.0, 0.0712890625, 0.12939453125, 0.0830078125, 0.04833984375, 0.0400390625, 0.12158203125, 0.015625, 0.736328125, 0.08251953125, 0.041015625, 0.08935546875, 0.03662109375, 0.04052734375, 0.267578125, 0.02880859375, 0.67578125, 0.6865234375, 0.09619140625, 0.06884765625, 0.06591796875, 0.08447265625, 0.65966796875, 0.01953125, 0.02001953125, 0.130859375, 0.044921875, 0.06982421875, 0.0478515625, 0.02734375, 0.03466796875, 0.0078125, 0.08056640625, 0.01953125, 0.02001953125, 0.99951171875, 0.0869140625, 0.0849609375, 0.0751953125, 0.46875, 0.01806640625, 0.203125, 0.04638671875, 0.1435546875, 0.46484375, 0.591796875, 0.08740234375, 0.0830078125, 0.04345703125, 0.70068359375, 0.04443359375, 0.009765625, 0.02001953125, 0.02392578125, 0.0869140625, 0.060546875, 0.1337890625, 0.1015625, 0.01513671875, 0.58935546875, 0.0087890625, 0.0634765625, 0.47802734375, 0.03271484375, 0.67822265625, 0.22021484375, 0.06494140625, 0.072265625, 0.66259765625, 0.72998046875, 0.09765625, 0.08544921875, 0.21435546875, 0.56982421875, 0.66259765625, 0.15380859375, 0.037109375, 0.01708984375, 0.15771484375, 0.07373046875, 0.99951171875, 0.09912109375, 0.654296875, 0.0576171875, 0.5947265625, 0.04443359375, 0.04931640625, 0.0869140625, 0.140625, 0.77099609375, 0.02685546875, 0.0302734375, 0.03173828125, 0.99853515625, 0.8779296875, 0.76171875, 0.13623046875, 0.11572265625, 0.07080078125, 0.05908203125, 0.0, 0.0625, 0.03759765625, 0.5673828125, 0.0361328125, 0.8525390625, 0.65771484375, 0.0771484375, 0.05615234375, 0.01416015625, 0.29296875, 0.06640625, 0.04638671875, 0.15087890625, 0.99951171875, 0.64501953125, 0.67724609375, 0.17724609375, 0.76708984375, 0.212890625, 0.49072265625, 0.01220703125, 0.03173828125, 0.85888671875, 0.7080078125, 0.15087890625, 0.53173828125, 0.03076171875, 0.04833984375, 0.0302734375, 0.671875, 0.01953125, 0.17626953125, 0.03564453125, 0.775390625, 0.06689453125, 0.0185546875, 0.0263671875, 0.02734375, 0.72509765625, 0.1025390625, 0.04931640625, 0.15087890625, 0.79541015625, 0.0, 0.0, 0.2294921875, 0.01171875, 0.61962890625, 0.09033203125, 0.77099609375, 0.0732421875, 0.07666015625, 0.0419921875, 0.07568359375, 0.02001953125, 0.66162109375, 0.10205078125, 0.712890625, 0.05517578125, 0.0302734375, 0.0771484375, 0.0380859375, 0.03076171875, 0.10302734375, 0.06787109375, 0.09375, 0.03515625, 0.08251953125, 0.03515625, 0.6298828125, 0.09375, 0.07080078125, 0.42041015625, 0.02734375, 0.0947265625, 0.078125, 0.7587890625, 0.03173828125, 0.10009765625, 0.01123046875, 0.22509765625, 0.78271484375, 0.0517578125, 0.08642578125, 0.58837890625, 0.10546875, 0.59619140625, 0.15576171875, 0.505859375, 0.25]

 sparsity of   [0.009982638992369175, 0.0, 0.02886284701526165, 0.01627604104578495, 0.9869791865348816, 0.009982638992369175, 0.007595486007630825, 0.0164930559694767, 0.009765625, 0.00021701389050576836, 0.0013020833721384406, 0.0, 0.029296875, 0.0, 0.0390625, 0.00933159701526165, 0.0, 0.0, 0.012803819961845875, 0.007595486007630825, 0.011935763992369175, 0.0232204869389534, 0.0, 0.0225694440305233, 0.01996527798473835, 0.0362413190305233, 0.0, 0.6041666865348816, 0.0421006940305233, 0.01909722201526165, 0.014973958022892475, 0.011067708022892475, 0.0520833320915699, 0.0, 0.008029513992369175, 0.0536024309694767, 0.010850694961845875, 0.0, 0.0232204869389534, 0.0049913194961845875, 0.01627604104578495, 0.0212673619389534, 0.00021701389050576836, 0.03515625, 0.0516493059694767, 0.0052083334885537624, 0.009548611007630825, 0.015407986007630825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005859375, 0.0223524309694767, 0.0, 0.013020833022892475, 0.0, 0.0, 0.0, 0.02408854104578495, 0.0203993059694767, 0.0049913194961845875, 0.0, 0.00021701389050576836, 0.0425347238779068, 0.014322916977107525, 0.630859375, 0.0, 0.0, 0.2352430522441864, 0.0, 0.00629340298473835, 0.011501736007630825, 0.0681423619389534, 0.0440538190305233, 0.0, 0.0271267369389534, 0.0, 0.004123263992369175, 0.0, 0.0047743055038154125, 0.0, 0.0010850694961845875, 0.048828125, 0.0405815988779068, 0.0, 0.0167100690305233, 0.007595486007630825, 0.01519097201526165, 0.0193142369389534, 0.0, 0.0023871527519077063, 0.0, 0.0323350690305233, 0.02734375, 0.0540364570915699, 0.0184461809694767, 0.0067274305038154125, 0.02473958395421505, 0.0, 0.0, 0.002170138992369175, 0.02365451492369175, 0.0, 0.3548177182674408, 0.00824652798473835, 0.072265625, 0.0340711809694767, 0.0, 0.0, 0.029296875, 0.5210503339767456, 0.0668402761220932, 0.0512152798473835, 0.0223524309694767, 0.0, 0.02105034701526165, 0.0, 0.00021701389050576836, 0.03059895895421505, 0.0, 0.9563801884651184, 0.0010850694961845875, 0.075086809694767, 0.01692708395421505, 0.0, 0.1039496511220932, 0.0, 0.037109375, 0.0212673619389534, 0.010850694961845875, 0.01171875, 0.1712239533662796, 0.0, 0.0514322929084301, 0.02083333395421505, 0.9997829794883728, 0.05859375, 0.01801215298473835, 0.01605902798473835, 0.0407986119389534, 0.02191840298473835, 0.0, 0.009982638992369175, 0.00021701389050576836, 0.0, 0.0, 0.01909722201526165, 0.00021701389050576836, 0.0349392369389534, 0.0568576380610466, 0.013454861007630825, 0.0065104165114462376, 0.0, 0.0262586809694767, 0.0, 0.0598958320915699, 0.0045572915114462376, 0.0065104165114462376, 0.0314670130610466, 0.025390625, 0.0193142369389534, 0.03059895895421505, 0.0325520820915699, 0.0425347238779068, 0.0243055559694767, 0.2914496660232544, 0.0423177070915699, 0.0427517369389534, 0.02734375, 0.012803819961845875, 0.0520833320915699, 0.0846354141831398, 0.00933159701526165, 0.0, 0.0, 0.0373263880610466, 0.0466579869389534, 0.0004340277810115367, 0.02213541604578495, 0.01714409701526165, 0.02083333395421505, 0.0164930559694767, 0.0557725690305233, 0.00021701389050576836, 0.02560763992369175, 0.010850694961845875, 0.0403645820915699, 0.0, 0.0394965298473835, 0.002170138992369175, 0.0394965298473835, 0.0447048619389534, 0.0763888880610466, 0.01692708395421505, 0.0, 0.01128472201526165, 0.0203993059694767, 0.667100727558136, 0.0373263880610466, 0.0036892362404614687, 0.02756076492369175, 0.0646701380610466, 0.0329861119389534, 0.077039934694767, 0.0078125, 0.0, 0.999131977558136, 0.0, 0.0, 0.0329861119389534, 0.009548611007630825, 0.0442708320915699, 0.005642361007630825, 0.02213541604578495, 0.0397135429084301, 0.00434027798473835, 0.0303819440305233, 0.0338541679084301, 0.0349392369389534, 0.0, 0.0518663190305233, 0.0173611119389534, 0.0206163190305233, 0.8044704794883728, 0.0, 0.0232204869389534, 0.0, 0.03081597201526165, 0.011935763992369175, 0.0032552082557231188, 0.014322916977107525, 0.0251736119389534, 0.0049913194961845875, 0.011935763992369175, 0.03081597201526165, 0.0440538190305233, 0.0577256940305233, 0.0, 0.014756944961845875, 0.01953125, 0.0, 0.0392795130610466, 0.013671875, 0.0167100690305233, 0.0, 0.011501736007630825, 0.007595486007630825, 0.0, 0.0, 0.0362413190305233, 0.0568576380610466, 0.02582465298473835, 0.0546875, 0.0323350690305233, 0.0069444444961845875, 0.041015625, 0.0, 0.0407986119389534, 0.0106336809694767, 0.05078125, 0.0319010429084301, 0.0284288190305233, 0.02777777798473835, 0.0086805559694767, 0.0, 0.0509982630610466, 0.01019965298473835, 0.0052083334885537624, 0.0017361111240461469, 0.0, 0.0086805559694767, 0.0325520820915699, 0.0, 0.0, 0.011067708022892475, 0.0412326380610466, 0.0, 0.01779513992369175, 0.01953125, 0.0609809048473835, 0.01584201492369175, 0.0375434048473835, 0.0340711809694767, 0.0245225690305233, 0.0859375, 0.0, 0.9993489384651184, 0.0262586809694767, 0.0010850694961845875, 0.02365451492369175, 0.009982638992369175, 0.0349392369389534, 0.0, 0.0, 0.0323350690305233, 0.0008680555620230734, 0.0008680555620230734, 0.01996527798473835, 0.0, 0.0536024309694767, 0.0444878488779068, 0.0, 0.0, 0.00021701389050576836, 0.00021701389050576836, 0.02018229104578495, 0.0, 0.0, 0.01779513992369175, 0.00021701389050576836, 0.1393229216337204, 0.0045572915114462376, 0.01605902798473835, 0.0004340277810115367, 0.0, 0.0, 0.010416666977107525, 0.02495659701526165, 0.0377604179084301, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.084852434694767, 0.0010850694961845875, 0.02191840298473835, 0.010850694961845875, 0.012803819961845875, 0.01215277798473835, 0.0, 0.02560763992369175, 0.0479600690305233, 0.0, 0.0, 0.0405815988779068, 0.1254340261220932, 0.02278645895421505, 0.0540364570915699, 0.0067274305038154125, 0.02365451492369175, 0.0, 0.052734375, 0.0972222238779068, 0.015407986007630825, 0.0314670130610466, 0.1002604141831398, 0.0184461809694767, 0.0, 0.02734375, 0.008029513992369175, 0.014973958022892475, 0.008463541977107525, 0.0518663190305233, 0.0403645820915699, 0.0, 0.005859375, 0.0, 0.0531684048473835, 0.02408854104578495, 0.0, 0.0, 0.01128472201526165, 0.1245659738779068, 0.0049913194961845875, 0.033203125, 0.0015190972480922937, 0.0596788190305233, 0.0106336809694767, 0.0234375, 0.0, 0.0, 0.0496961809694767, 0.008029513992369175, 0.00434027798473835, 0.1156684011220932, 0.0, 0.02365451492369175, 0.006076388992369175, 0.0, 0.02690972201526165, 0.025390625, 0.0, 0.0438368059694767, 0.0418836809694767, 0.01323784701526165, 0.0, 0.0568576380610466, 0.0052083334885537624, 0.0, 0.0, 0.03081597201526165, 0.0, 0.0544704869389534, 0.02408854104578495, 0.0052083334885537624, 0.00390625, 0.01714409701526165, 0.0377604179084301, 0.012369791977107525, 0.0, 0.0284288190305233, 0.010850694961845875, 0.041015625, 0.009982638992369175, 0.0, 0.0, 0.01323784701526165, 0.01519097201526165, 0.01779513992369175, 0.5687934160232544, 0.0475260429084301, 0.0, 0.0, 0.0, 0.0, 0.01410590298473835, 0.0303819440305233, 0.0023871527519077063, 0.0373263880610466, 0.0, 0.0, 0.0023871527519077063, 0.3396267294883728, 0.0164930559694767, 0.001953125, 0.0, 0.0466579869389534, 0.0004340277810115367, 0.0512152798473835, 0.9780815839767456, 0.0045572915114462376, 0.9997829794883728, 0.03059895895421505, 0.9986979365348816, 0.0423177070915699, 0.012369791977107525, 0.0, 0.0434027798473835, 0.017578125, 0.0, 0.0030381944961845875, 0.0427517369389534, 0.0360243059694767, 0.4685329794883728, 0.9997829794883728, 0.0052083334885537624, 0.0145399309694767, 0.0, 0.0262586809694767, 0.0023871527519077063, 0.0047743055038154125, 0.005642361007630825, 0.00629340298473835, 0.0512152798473835, 0.037109375, 0.0334201380610466, 0.010850694961845875, 0.0, 0.008029513992369175, 0.01215277798473835, 0.0047743055038154125, 0.0030381944961845875, 0.0460069440305233, 0.01627604104578495, 0.01605902798473835, 0.0026041667442768812, 0.0, 0.0, 0.0503472238779068, 0.510850727558136, 0.01909722201526165, 0.01953125, 0.0696614608168602, 0.1098090261220932, 0.6540798544883728, 0.004123263992369175, 0.8138020634651184, 0.0262586809694767, 0.9993489384651184, 0.9989149570465088, 0.6775173544883728, 0.0, 0.02473958395421505, 0.0, 0.007378472480922937, 0.0, 0.02213541604578495, 0.2703993022441864, 0.0006510416860692203, 0.0, 0.0028211805038154125, 0.0377604179084301, 0.0212673619389534, 0.0184461809694767, 0.0, 0.144314244389534, 0.0026041667442768812, 0.02408854104578495, 0.0, 0.00021701389050576836, 0.0, 0.012369791977107525, 0.01019965298473835, 0.00434027798473835, 0.0520833320915699, 0.0, 0.0, 0.0049913194961845875]

 sparsity of   [0.0, 0.001953125, 0.03515625, 0.013671875, 0.0, 0.08203125, 0.4453125, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0234375, 0.0, 0.037109375, 0.001953125, 0.00390625, 0.005859375, 0.1015625, 0.0, 0.005859375, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.03125, 0.017578125, 0.0, 0.046875, 0.193359375, 0.02734375, 0.0, 0.0, 0.068359375, 0.0, 0.0, 0.04296875, 0.025390625, 0.017578125, 0.0, 0.001953125, 0.0, 0.0, 0.033203125, 0.015625, 0.0, 0.015625, 0.0, 0.00390625, 0.0078125, 0.0, 0.0078125, 0.017578125, 0.0, 0.0, 0.009765625, 0.0078125, 0.0, 0.021484375, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.02734375, 0.0, 0.0, 0.037109375, 0.0078125, 0.0234375, 0.0, 0.0, 0.0234375, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02734375, 0.0078125, 0.015625, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.001953125, 0.998046875, 0.0078125, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.00390625, 0.021484375, 0.00390625, 0.14453125, 0.994140625, 0.0078125, 0.021484375, 0.0, 0.0, 0.013671875, 0.013671875, 0.001953125, 0.041015625, 0.0, 0.009765625, 0.0, 0.033203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013671875, 0.0, 0.02734375, 0.0, 0.001953125, 0.0, 0.0, 0.00390625, 0.0, 0.001953125, 0.0, 0.00390625, 0.0, 0.001953125, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0390625, 0.0, 0.0, 0.02734375, 0.015625, 0.0, 0.0, 0.009765625, 0.001953125, 0.0, 0.0, 0.03515625, 0.0, 0.0390625, 0.0, 0.0, 0.0, 0.0, 0.037109375, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.0, 0.001953125, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.013671875, 0.994140625, 0.0, 0.0, 0.0, 0.08984375, 0.0, 0.0, 0.0, 0.0, 0.009765625, 0.0, 0.033203125, 0.0, 0.0, 0.0, 0.025390625, 0.04296875, 0.0078125, 0.0, 0.0, 0.001953125, 0.025390625, 0.0, 0.009765625, 0.0, 0.021484375, 0.017578125, 0.00390625, 0.0, 0.0, 0.01953125, 0.04296875, 0.0, 0.001953125, 0.013671875, 0.01171875, 0.009765625, 0.994140625, 0.0, 0.009765625, 0.0, 0.125, 0.0, 0.0, 0.0, 0.021484375, 0.0, 0.0, 0.0, 0.02734375, 0.005859375, 0.013671875, 0.0, 0.013671875, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.01171875, 0.97265625, 0.0, 0.0390625, 0.0, 0.0, 0.013671875, 0.00390625, 0.005859375, 0.009765625, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.01953125, 0.0, 0.0, 0.109375, 0.0, 0.142578125, 0.00390625, 0.0, 0.083984375, 0.009765625, 0.0, 0.0, 0.0, 0.005859375, 0.015625, 0.03125, 0.0, 0.009765625, 0.009765625, 0.009765625, 0.103515625, 0.0078125, 0.0, 0.06640625, 0.0, 0.013671875, 0.0, 0.994140625, 0.01171875, 0.03125, 0.001953125, 0.0, 0.01953125, 0.013671875, 0.0, 0.0, 0.0, 0.0234375, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.56640625, 0.0, 0.025390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009765625, 0.001953125, 0.0, 0.02734375, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.0234375, 0.0, 0.029296875, 0.0, 0.0, 0.0, 0.025390625, 0.0234375, 0.001953125, 0.017578125, 0.001953125, 0.001953125, 0.013671875, 0.015625, 0.001953125, 0.0, 0.009765625, 0.0, 0.001953125, 0.001953125, 0.552734375, 0.0390625, 0.005859375, 0.00390625, 0.0, 0.009765625, 0.056640625, 0.0, 0.0, 0.04296875, 0.0078125, 0.00390625, 0.994140625, 0.021484375, 0.005859375, 0.0, 0.001953125, 0.0703125, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0234375, 0.0, 0.0, 0.0, 0.017578125, 0.0, 0.013671875, 0.009765625, 0.0, 0.029296875, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.021484375, 0.0, 0.02734375, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009765625, 0.103515625, 0.0, 0.0625, 0.0, 0.025390625, 0.0, 0.0, 0.021484375, 0.0, 0.009765625, 0.009765625, 0.0, 0.0, 0.02734375, 0.0, 0.0, 0.0, 0.0, 0.048828125, 0.0, 0.0078125, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.064453125, 0.0, 0.0, 0.15234375, 0.0, 0.0, 0.01171875, 0.0, 0.017578125, 0.0, 0.001953125, 0.02734375, 0.013671875, 0.029296875, 0.0, 0.01953125, 0.015625, 0.0, 0.029296875, 0.009765625, 0.025390625, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.06640625, 0.0, 0.994140625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0625, 0.017578125, 0.02734375, 0.009765625, 0.0, 0.029296875, 0.0, 0.0, 0.0, 0.033203125, 0.0, 0.064453125, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.001953125, 0.009765625, 0.056640625, 0.021484375, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0234375, 0.01953125, 0.0, 0.0, 0.0, 0.0, 0.064453125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021484375, 0.013671875, 0.0, 0.6796875, 0.033203125, 0.05859375, 0.990234375, 0.0, 0.001953125, 0.0, 0.0, 0.01171875, 0.0, 0.009765625, 0.009765625, 0.0, 0.025390625, 0.009765625, 0.005859375, 0.0, 0.048828125, 0.03125, 0.09375, 0.005859375, 0.001953125, 0.021484375, 0.00390625, 0.0, 0.005859375, 0.0, 0.0, 0.037109375, 0.0, 0.0, 0.0, 0.0, 0.1953125, 0.02734375, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.013671875, 0.001953125, 0.0, 0.0, 0.0, 0.998046875, 0.013671875, 0.0, 0.0, 0.0, 0.017578125, 0.001953125, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.994140625, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.99609375, 0.001953125, 0.01171875, 0.02734375, 0.0, 0.001953125, 0.0, 0.015625, 0.02734375, 0.0, 0.0, 0.001953125, 0.001953125, 0.009765625, 0.01953125, 0.0, 0.0, 0.0, 0.021484375, 0.0, 0.0, 0.001953125, 0.001953125, 0.0, 0.998046875, 0.0, 0.06640625, 0.017578125, 0.150390625, 0.0, 0.0, 0.0390625, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05859375, 0.0, 0.005859375, 0.0, 0.052734375, 0.0, 0.04296875, 0.00390625, 0.0, 0.0, 0.01953125, 0.0, 0.0078125, 0.1953125, 0.04296875, 0.0, 0.0, 0.0, 0.009765625, 0.0078125, 0.01171875, 0.01953125, 0.0, 0.0, 0.03125, 0.0, 0.056640625, 0.01953125, 0.029296875, 0.0, 0.04296875, 0.001953125, 0.0, 0.013671875, 0.998046875, 0.0, 0.01953125, 0.0, 0.01171875, 0.0, 0.5234375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.009765625, 0.029296875, 0.0, 0.248046875, 0.974609375, 0.0, 0.0, 0.0, 0.048828125, 0.0, 0.029296875, 0.0, 0.033203125, 0.001953125, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.05078125, 0.0, 0.0, 0.0, 0.99609375, 0.02734375, 0.0, 0.0234375, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013671875, 0.017578125, 0.0078125, 0.0, 0.0, 0.15234375, 0.0, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.05078125, 0.01171875, 0.0, 0.015625, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.01953125, 0.0, 0.0234375, 0.048828125, 0.03125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.005859375, 0.029296875, 0.0, 0.001953125, 0.017578125, 0.00390625, 0.0, 0.015625, 0.0234375, 0.0, 0.0234375, 0.0, 0.0546875, 0.0, 0.001953125, 0.001953125, 0.0, 0.00390625, 0.021484375, 0.025390625, 0.0, 0.017578125, 0.0, 0.005859375, 0.0, 0.064453125, 0.0, 0.0078125, 0.0, 0.0, 0.046875, 0.0, 0.0, 0.00390625, 0.0, 0.044921875, 0.017578125, 0.0, 0.0, 0.0, 0.0, 0.025390625, 0.0, 0.0, 0.005859375, 0.0, 0.037109375, 0.0078125, 0.0078125, 0.0, 0.00390625, 0.005859375, 0.001953125, 0.009765625, 0.015625, 0.033203125, 0.0, 0.0, 0.001953125, 0.02734375, 0.0, 0.0, 0.056640625, 0.0, 0.0, 0.0, 0.0, 0.02734375, 0.0, 0.994140625, 0.00390625, 0.001953125, 0.0, 0.029296875, 0.0, 0.0, 0.021484375, 0.0, 0.001953125, 0.0546875, 0.01171875, 0.0, 0.01953125, 0.0, 0.0, 0.080078125, 0.041015625, 0.0, 0.0, 0.0, 0.072265625, 0.693359375, 0.013671875, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0234375, 0.00390625, 0.1015625, 0.23046875, 0.0, 0.0, 0.0, 0.876953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.009765625, 0.0, 0.0, 0.00390625, 0.0, 0.033203125, 0.0, 0.0, 0.021484375, 0.015625, 0.00390625, 0.00390625, 0.103515625, 0.0, 0.0, 0.01953125, 0.0, 0.009765625, 0.0, 0.021484375, 0.001953125, 0.02734375, 0.0, 0.619140625, 0.005859375, 0.0, 0.021484375, 0.001953125, 0.0, 0.0, 0.0, 0.033203125, 0.021484375, 0.0, 0.0, 0.0078125, 0.013671875, 0.017578125, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.009765625, 0.01953125, 0.0, 0.0, 0.015625, 0.00390625, 0.0, 0.013671875, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.201171875, 0.001953125, 0.0, 0.0, 0.00390625, 0.0234375, 0.0078125, 0.080078125, 0.0, 0.736328125, 0.0, 0.0, 0.009765625, 0.037109375, 0.00390625, 0.07421875, 0.025390625, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.98828125, 0.0, 0.0078125, 0.0, 0.01953125, 0.013671875, 0.0, 0.033203125, 0.107421875, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.083984375, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.05859375, 0.0, 0.001953125, 0.017578125, 0.01171875, 0.119140625, 0.0, 0.02734375, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05078125, 0.0, 0.0, 0.0, 0.01953125, 0.017578125, 0.0, 0.0, 0.0, 0.025390625, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.01171875, 0.0, 0.015625, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.001953125, 0.0, 0.025390625, 0.0, 0.05078125, 0.0, 0.0, 0.001953125, 0.0, 0.033203125, 0.0, 0.013671875, 0.0078125, 0.01953125, 0.994140625, 0.001953125, 0.001953125, 0.037109375, 0.01953125, 0.0, 0.01953125, 0.03515625, 0.0, 0.04296875, 0.0, 0.009765625, 0.021484375, 0.0, 0.03515625, 0.0, 0.0, 0.001953125, 0.0, 0.00390625, 0.0, 0.0, 0.01953125, 0.0, 0.033203125, 0.025390625, 0.0078125, 0.0, 0.01171875, 0.0, 0.15234375, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.080078125, 0.0, 0.0, 0.0234375, 0.013671875, 0.0078125, 0.0, 0.009765625, 0.005859375, 0.048828125, 0.017578125, 0.0, 0.01953125, 0.025390625, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.025390625, 0.0, 0.00390625, 0.05078125, 0.0, 0.0, 0.021484375, 0.0, 0.013671875, 0.025390625, 0.0, 0.0, 0.01171875, 0.009765625, 0.0078125, 0.009765625, 0.0, 0.12109375, 0.013671875, 0.0, 0.97265625, 0.029296875, 0.0, 0.01171875, 0.0078125, 0.001953125, 0.0546875, 0.0, 0.02734375, 0.0, 0.0, 0.005859375, 0.00390625, 0.197265625, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.1015625, 0.0, 0.0, 0.015625, 0.0, 0.03125, 0.005859375, 0.0, 0.0, 0.015625, 0.037109375, 0.0, 0.0, 0.0, 0.064453125, 0.0, 0.013671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009765625, 0.068359375, 0.0, 0.052734375, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02734375, 0.974609375, 0.0, 0.0, 0.001953125, 0.0, 0.0078125, 0.0, 0.0, 0.01171875, 0.013671875, 0.021484375, 0.0078125, 0.021484375, 0.048828125, 0.001953125, 0.048828125, 0.005859375, 0.0, 0.037109375, 0.009765625, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025390625, 0.0, 0.00390625, 0.0, 0.0234375, 0.0, 0.0078125, 0.0, 0.005859375, 0.0, 0.0, 0.017578125, 0.57421875, 0.0, 0.072265625, 0.041015625, 0.029296875, 0.0, 0.0, 0.0, 0.0, 0.025390625, 0.0, 0.00390625, 0.0, 0.994140625, 0.0, 0.0, 0.0, 0.04296875, 0.013671875, 0.0, 0.03515625, 0.015625, 0.01953125, 0.099609375, 0.0, 0.0, 0.0, 0.0234375, 0.01171875, 0.0234375, 0.0, 0.01953125, 0.005859375, 0.01171875, 0.0, 0.0, 0.236328125, 0.0, 0.03515625, 0.0, 0.01171875, 0.048828125, 0.0, 0.0, 0.009765625, 0.99609375, 0.0, 0.0, 0.00390625, 0.001953125, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041015625, 0.001953125, 0.001953125, 0.71875, 0.0, 0.02734375, 0.0078125, 0.02734375, 0.044921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005859375, 0.001953125, 0.0, 0.00390625, 0.044921875, 0.0, 0.0, 0.00390625, 0.005859375, 0.0, 0.0, 0.0, 0.998046875, 0.013671875, 0.01953125, 0.025390625, 0.0, 0.859375, 0.0, 0.025390625, 0.033203125, 0.013671875, 0.0, 0.0, 0.0, 0.037109375, 0.009765625, 0.0, 0.0, 0.0, 0.009765625, 0.021484375, 0.0, 0.0, 0.0, 0.041015625, 0.0, 0.021484375, 0.0, 0.0, 0.0, 0.0, 0.046875, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.001953125, 0.0, 0.02734375, 0.0390625, 0.02734375, 0.068359375, 0.0, 0.03125, 0.0, 0.009765625, 0.0, 0.048828125, 0.017578125, 0.0, 0.00390625, 0.046875, 0.01953125, 0.0, 0.029296875, 0.037109375, 0.009765625, 0.001953125, 0.021484375, 0.005859375, 0.001953125, 0.021484375, 0.0, 0.0, 0.0, 0.0, 0.017578125, 0.005859375, 0.001953125, 0.0, 0.02734375, 0.0, 0.0, 0.07421875, 0.0, 0.0, 0.01171875, 0.1484375, 0.0, 0.0, 0.017578125, 0.509765625, 0.0, 0.0, 0.013671875, 0.021484375, 0.0, 0.00390625, 0.0, 0.0, 0.0078125, 0.029296875, 0.0, 0.013671875, 0.0, 0.0, 0.001953125, 0.005859375, 0.0, 0.0, 0.0, 0.0, 0.025390625, 0.0, 0.005859375, 0.005859375, 0.013671875, 0.001953125, 0.01953125, 0.0, 0.994140625, 0.005859375, 0.09375, 0.015625, 0.0, 0.009765625, 0.001953125, 0.001953125, 0.013671875, 0.0078125, 0.11328125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005859375, 0.001953125, 0.0078125, 0.0, 0.001953125, 0.0, 0.01953125, 0.056640625, 0.0, 0.0390625, 0.0, 0.0, 0.021484375, 0.0, 0.0, 0.0, 0.0234375, 0.033203125, 0.0, 0.02734375, 0.013671875, 0.005859375, 0.033203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017578125, 0.01171875, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.025390625, 0.01171875, 0.02734375, 0.48046875, 0.0, 0.009765625, 0.0, 0.0, 0.01171875, 0.0, 0.005859375, 0.0, 0.0, 0.7421875, 0.0, 0.0, 0.01171875, 0.025390625, 0.0, 0.03125, 0.0078125, 0.0, 0.0, 0.09375, 0.0, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.001953125, 0.005859375, 0.0, 0.00390625, 0.0, 0.029296875, 0.0, 0.01953125, 0.0, 0.00390625, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.021484375, 0.02734375, 0.02734375, 0.017578125, 0.01953125, 0.0, 0.009765625, 0.0, 0.109375, 0.0, 0.02734375, 0.0, 0.0234375, 0.041015625, 0.0, 0.017578125, 0.017578125, 0.0078125, 0.0, 0.03515625, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.044921875, 0.0, 0.0, 0.001953125, 0.03515625, 0.00390625, 0.029296875, 0.0, 0.0234375, 0.0, 0.080078125, 0.005859375, 0.0, 0.072265625, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.07421875, 0.00390625, 0.0, 0.00390625, 0.0, 0.009765625, 0.0, 0.005859375, 0.0, 0.015625, 0.041015625, 0.03125, 0.001953125, 0.0, 0.017578125, 0.0078125, 0.0, 0.0, 0.0, 0.0078125, 0.5546875, 0.005859375, 0.0, 0.00390625, 0.0, 0.02734375, 0.0, 0.0, 0.001953125, 0.0234375, 0.025390625, 0.025390625, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.001953125, 0.0, 0.00390625, 0.0, 0.0, 0.001953125, 0.00390625, 0.0, 0.017578125, 0.00390625, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.00390625, 0.0, 0.03125, 0.0078125, 0.0, 0.0078125, 0.0, 0.029296875, 0.796875, 0.01171875, 0.001953125, 0.0078125, 0.01171875, 0.0, 0.009765625, 0.009765625, 0.001953125, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0078125, 0.0, 0.009765625, 0.005859375, 0.0, 0.001953125, 0.04296875, 0.0234375, 0.0, 0.0, 0.01171875, 0.0078125, 0.0, 0.97265625, 0.01953125, 0.0, 0.0, 0.01953125, 0.0, 0.001953125, 0.041015625, 0.048828125, 0.0, 0.0, 0.03125, 0.001953125, 0.0, 0.0, 0.025390625, 0.017578125, 0.0, 0.0, 0.015625, 0.005859375, 0.119140625, 0.01171875, 0.0, 0.0, 0.037109375, 0.00390625, 0.01171875, 0.0, 0.02734375, 0.0, 0.025390625, 0.015625, 0.0078125, 0.0, 0.0390625, 0.0, 0.0, 0.68359375, 0.01953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.888671875, 0.009765625, 0.0, 0.0234375, 0.0, 0.0, 0.994140625, 0.0, 0.0078125, 0.0234375, 0.0078125, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021484375, 0.0, 0.01171875, 0.0, 0.0, 0.025390625, 0.052734375, 0.0, 0.0, 0.0, 0.18359375, 0.01953125, 0.029296875, 0.05859375, 0.076171875, 0.044921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.162109375, 0.0, 0.015625, 0.0, 0.005859375, 0.0, 0.990234375, 0.0, 0.013671875, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.02734375, 0.0, 0.0, 0.0, 0.01171875, 0.001953125, 0.01953125, 0.0, 0.0, 0.0, 0.013671875, 0.0, 0.0, 0.0234375, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0078125, 0.009765625, 0.021484375, 0.00390625, 0.013671875, 0.001953125, 0.09765625, 0.0, 0.01171875, 0.0, 0.0, 0.0390625, 0.017578125, 0.0, 0.0078125, 0.01953125, 0.0, 0.0, 0.0, 0.001953125, 0.013671875, 0.0078125, 0.041015625, 0.001953125, 0.001953125, 0.0, 0.044921875, 0.0, 0.087890625, 0.0, 0.00390625, 0.0078125, 0.00390625, 0.0234375, 0.0, 0.0, 0.001953125, 0.04296875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02734375, 0.0, 0.0, 0.01953125, 0.015625, 0.029296875, 0.048828125, 0.0, 0.0, 0.0, 0.0, 0.02734375, 0.0, 0.01953125, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.03125, 0.001953125, 0.0, 0.013671875, 0.025390625, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.00390625, 0.041015625, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.609375, 0.0, 0.04296875, 0.0, 0.044921875, 0.02734375, 0.0, 0.001953125, 0.001953125, 0.03125, 0.0, 0.017578125, 0.0, 0.0078125, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.21484375, 0.0, 0.0, 0.001953125, 0.017578125, 0.0, 0.03515625, 0.0, 0.271484375, 0.017578125, 0.001953125, 0.005859375, 0.0, 0.0234375, 0.0, 0.015625, 0.017578125, 0.01171875, 0.0234375, 0.0078125, 0.998046875, 0.0, 0.0, 0.009765625, 0.0, 0.0, 0.99609375, 0.0, 0.01171875, 0.01953125, 0.857421875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.013671875, 0.017578125, 0.021484375, 0.00390625, 0.04296875, 0.025390625, 0.037109375, 0.001953125, 0.01171875, 0.0, 0.001953125, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.041015625, 0.0, 0.0, 0.013671875, 0.0, 0.005859375, 0.0, 0.0234375, 0.0390625, 0.9921875, 0.001953125, 0.013671875, 0.0, 0.001953125, 0.001953125, 0.0, 0.001953125, 0.0, 0.005859375, 0.013671875, 0.0, 0.0, 0.009765625, 0.0, 0.0, 0.02734375, 0.0, 0.0, 0.029296875, 0.005859375, 0.0390625, 0.0, 0.0, 0.013671875, 0.0, 0.0, 0.009765625, 0.0390625, 0.01953125, 0.0, 0.0, 0.021484375, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.015625, 0.0, 0.001953125, 0.994140625, 0.0, 0.0, 0.005859375, 0.015625, 0.0, 0.01171875, 0.994140625, 0.005859375, 0.0, 0.021484375, 0.021484375, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.572265625, 0.0, 0.01171875, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.025390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.810546875, 0.0546875, 0.04296875, 0.001953125, 0.0, 0.0, 0.041015625, 0.0, 0.0, 0.064453125, 0.0, 0.0, 0.021484375, 0.001953125, 0.001953125, 0.0]

 sparsity of   [0.02783203125, 0.99951171875, 0.0361328125, 0.03369140625, 0.01904296875, 0.0556640625, 0.0126953125, 0.00927734375, 0.0537109375, 0.048828125, 0.0205078125, 0.01708984375, 0.0126953125, 0.08740234375, 0.5146484375, 0.00634765625, 0.03857421875, 0.0458984375, 0.12109375, 0.04248046875, 0.041015625, 0.048828125, 0.0234375, 0.08544921875, 0.99951171875, 0.01123046875, 0.06494140625, 0.53759765625, 0.10791015625, 0.0341796875, 0.044921875, 0.0263671875, 0.0146484375, 0.0166015625, 0.044921875, 0.06005859375, 0.00048828125, 0.03662109375, 0.01708984375, 0.0166015625, 0.02783203125, 0.99951171875, 0.03564453125, 0.03759765625, 0.05078125, 0.01171875, 0.02783203125, 0.05322265625, 0.02392578125, 0.01611328125, 0.025390625, 0.05029296875, 0.0244140625, 0.03515625, 0.04736328125, 0.01025390625, 0.0185546875, 0.0, 0.005859375, 0.01953125, 0.056640625, 0.01806640625, 0.037109375, 0.06103515625, 0.01611328125, 0.00048828125, 0.01123046875, 0.1044921875, 0.9541015625, 0.228515625, 0.0244140625, 0.01611328125, 0.0087890625, 0.0126953125, 0.02880859375, 0.07958984375, 0.01708984375, 0.0146484375, 0.02001953125, 0.03662109375, 0.07666015625, 0.0458984375, 0.08740234375, 0.08447265625, 0.03369140625, 0.03125, 0.0341796875, 0.021484375, 0.01806640625, 0.0087890625, 0.01513671875, 0.0263671875, 0.0283203125, 0.9990234375, 0.00732421875, 0.00244140625, 0.06201171875, 0.00927734375, 0.046875, 0.0234375, 0.02734375, 0.029296875, 0.029296875, 0.06787109375, 0.0810546875, 0.0, 0.009765625, 0.0087890625, 0.10693359375, 0.14599609375, 0.029296875, 0.02880859375, 0.05029296875, 0.0185546875, 0.01708984375, 0.0703125, 0.00341796875, 0.05908203125, 0.0205078125, 0.0419921875, 0.056640625, 0.01318359375, 0.009765625, 0.00732421875, 0.01416015625, 0.01171875, 0.04052734375, 0.02685546875, 0.11376953125, 0.0341796875, 0.06005859375, 0.00634765625, 0.01416015625, 0.0546875, 0.99609375, 0.025390625, 0.15625, 0.01904296875, 0.02490234375, 0.38427734375, 0.55810546875, 0.02978515625, 0.05126953125, 0.0224609375, 0.00390625, 0.01416015625, 0.02490234375, 0.01513671875, 0.01220703125, 0.02685546875, 0.015625, 0.0, 0.00927734375, 0.00048828125, 0.0224609375, 0.041015625, 0.01513671875, 0.0556640625, 0.02587890625, 0.0, 0.0400390625, 0.03564453125, 0.01513671875, 0.02197265625, 0.04443359375, 0.0, 0.0, 0.01904296875, 0.0, 0.05078125, 0.02734375, 0.02294921875, 0.06298828125, 0.015625, 0.09521484375, 0.02783203125, 0.0, 0.0537109375, 0.0224609375, 0.046875, 0.02099609375, 0.02001953125, 0.02587890625, 0.0166015625, 0.0224609375, 0.01953125, 0.03564453125, 0.06103515625, 0.03369140625, 0.02734375, 0.0517578125, 0.01904296875, 0.021484375, 0.03515625, 0.0361328125, 0.02197265625, 0.21435546875, 0.0517578125, 0.01513671875, 0.02294921875, 0.02490234375, 0.0244140625, 0.041015625, 0.009765625, 0.0244140625, 0.017578125, 0.04638671875, 0.87255859375, 0.02490234375, 0.12451171875, 0.0, 0.99853515625, 0.02880859375, 0.0234375, 0.02099609375, 0.07177734375, 0.02392578125, 0.5537109375, 0.93017578125, 0.0205078125, 0.01806640625, 0.06591796875, 0.03076171875, 0.02685546875, 0.03076171875, 0.0185546875, 0.09228515625, 0.8720703125, 0.04248046875, 0.0, 0.025390625, 0.0068359375, 0.00146484375, 0.04150390625, 0.0087890625, 0.02001953125, 0.01220703125, 0.08642578125, 0.09130859375, 0.10791015625, 0.083984375, 0.0, 0.06689453125, 0.0234375, 0.0322265625, 0.0205078125, 0.0439453125, 0.630859375, 0.00537109375, 0.0322265625, 0.0390625, 0.029296875, 0.03076171875, 0.0009765625, 0.01708984375, 0.0654296875, 0.0400390625, 0.0146484375, 0.00048828125, 0.013671875, 0.0537109375, 0.06640625, 0.0546875, 0.02978515625, 0.0771484375, 0.55029296875, 0.01611328125, 0.01806640625, 0.01953125, 0.01318359375, 0.03466796875, 0.17529296875, 0.0, 0.1728515625, 0.0166015625, 0.0107421875, 0.037109375, 0.06787109375, 0.0302734375, 0.025390625, 0.02197265625, 0.0283203125, 0.029296875, 0.00927734375, 0.0302734375, 0.07177734375, 0.07275390625, 0.0205078125, 0.01123046875, 0.0341796875, 0.05322265625, 0.0, 0.41259765625, 0.04833984375, 0.02978515625, 0.05615234375, 0.03369140625, 0.0068359375, 0.017578125, 0.02294921875, 0.1943359375, 0.06640625, 0.03515625, 0.29150390625, 0.05078125, 0.0, 0.07275390625, 0.02587890625, 0.02197265625, 0.033203125, 0.01611328125, 0.02978515625, 0.06494140625, 0.03173828125, 0.00048828125, 0.0595703125, 0.0, 0.064453125, 0.05126953125, 0.01513671875, 0.0, 0.0224609375, 0.0, 0.00048828125, 0.01513671875, 0.33447265625, 0.03369140625, 0.94677734375, 0.01708984375, 0.01953125, 0.18115234375, 0.0126953125, 0.02880859375, 0.0927734375, 0.0, 0.0517578125, 0.00048828125, 0.02099609375, 0.0205078125, 0.02587890625, 0.00048828125, 0.037109375, 0.09326171875, 0.9130859375, 0.08837890625, 0.0634765625, 0.03955078125, 0.06298828125, 0.0, 0.06103515625, 0.0, 0.14892578125, 0.01416015625, 0.02783203125, 0.00732421875, 0.0068359375, 0.0234375, 0.0009765625, 0.02099609375, 0.01904296875, 0.02294921875, 0.421875, 0.0, 0.044921875, 0.11083984375, 0.0, 0.013671875, 0.091796875, 0.02685546875, 0.01513671875, 0.55712890625, 0.03564453125, 0.06005859375, 0.0244140625, 0.06640625, 0.02197265625, 0.875, 0.02001953125, 0.08544921875, 0.0, 0.06298828125, 0.01806640625, 0.25, 0.0263671875, 0.03369140625, 0.0205078125, 0.181640625, 0.025390625, 0.03466796875, 0.01611328125, 0.0595703125, 0.05029296875, 0.0087890625, 0.0390625, 0.01953125, 0.01220703125, 0.04541015625, 0.03076171875, 0.99951171875, 0.0029296875, 0.03955078125, 0.99951171875, 0.05126953125, 0.39306640625, 0.0, 0.029296875, 0.01123046875, 0.04248046875, 0.0322265625, 0.1171875, 0.052734375, 0.0361328125, 0.05224609375, 0.017578125, 0.68798828125, 0.0166015625, 0.05126953125, 0.044921875, 0.03564453125, 0.01123046875, 0.09375, 0.00244140625, 0.015625, 0.052734375, 0.04052734375, 0.04345703125, 0.00048828125, 0.04541015625, 0.02587890625, 0.00390625, 0.015625, 0.30322265625, 0.02978515625, 0.5458984375, 0.4697265625, 0.49755859375, 0.01220703125, 0.00048828125, 0.01953125, 0.03173828125, 0.12646484375, 0.07763671875, 0.03271484375, 0.02001953125, 0.02490234375, 0.04248046875, 0.0390625, 0.08056640625, 0.06884765625, 0.02099609375, 0.0361328125, 0.03955078125, 0.0458984375, 0.0, 0.041015625, 0.08349609375, 0.0927734375, 0.0, 0.0185546875, 0.02734375, 0.03564453125, 0.2490234375, 0.0966796875, 0.03857421875, 0.013671875, 0.04248046875, 0.02197265625, 0.89501953125, 0.00634765625, 0.02978515625, 0.9833984375, 0.99658203125, 0.00048828125, 0.01123046875, 0.005859375, 0.033203125, 0.04833984375, 0.0458984375, 0.07275390625, 0.28076171875, 0.0, 0.01025390625, 0.01513671875, 0.02783203125, 0.037109375, 0.02197265625, 0.03662109375, 0.23779296875, 0.90576171875, 0.0380859375, 0.10302734375, 0.02392578125, 0.04052734375, 0.00537109375, 0.02099609375, 0.02392578125, 0.0390625, 0.0048828125, 0.03662109375, 0.0078125, 0.333984375, 0.046875, 0.0400390625, 0.10888671875, 0.02099609375, 0.6689453125, 0.04052734375, 0.02294921875, 0.0380859375, 0.0205078125, 0.03564453125, 0.05908203125]

 sparsity of   [0.0, 0.0353732630610466, 0.1427951455116272, 0.3235677182674408, 0.0, 0.007595486007630825, 0.0, 0.0572916679084301, 0.0512152798473835, 0.0, 0.029296875, 0.00021701389050576836, 0.0494791679084301, 0.017578125, 0.6901041865348816, 0.0, 0.00021701389050576836, 0.0067274305038154125, 0.02582465298473835, 0.0, 0.01779513992369175, 0.0245225690305233, 0.0, 0.2825520932674408, 0.0735677108168602, 0.1616753488779068, 0.0, 0.0212673619389534, 0.007378472480922937, 0.0, 0.0052083334885537624, 0.0, 0.01888020895421505, 0.0069444444961845875, 0.0423177070915699, 0.01692708395421505, 0.05859375, 0.0, 0.0, 0.0505642369389534, 0.9995659589767456, 0.01627604104578495, 0.0251736119389534, 0.0418836809694767, 0.029296875, 0.0338541679084301, 0.002170138992369175, 0.01323784701526165, 0.1037326380610466, 0.033203125, 0.068359375, 0.0, 0.0718315988779068, 0.0004340277810115367, 0.0462239570915699, 0.0251736119389534, 0.048828125, 0.0303819440305233, 0.0416666679084301, 0.0551215298473835, 0.0036892362404614687, 0.00021701389050576836, 0.0666232630610466, 0.0004340277810115367, 0.0, 0.02018229104578495, 0.0416666679084301, 0.0540364570915699, 0.0405815988779068, 0.0, 0.0609809048473835, 0.0184461809694767, 0.00021701389050576836, 0.0679253488779068, 0.03059895895421505, 0.0, 0.0690104141831398, 0.00933159701526165, 0.001953125, 0.00021701389050576836, 0.0642361119389534, 0.0, 0.0, 0.0010850694961845875, 0.9010416865348816, 0.0620659738779068, 0.03081597201526165, 0.02777777798473835, 0.02756076492369175, 0.0336371548473835, 0.0167100690305233, 0.0891927108168602, 0.00021701389050576836, 0.0492621548473835, 0.0004340277810115367, 0.132595494389534, 0.0377604179084301, 0.0, 0.1134982630610466, 0.0, 0.00021701389050576836, 0.0325520820915699, 0.0, 0.0562065988779068, 0.0386284738779068, 0.0086805559694767, 0.00021701389050576836, 0.0518663190305233, 0.0010850694961845875, 0.255859375, 0.7376301884651184, 0.0, 0.0338541679084301, 0.0, 0.0, 0.0401475690305233, 0.0, 0.0203993059694767, 0.0622829869389534, 0.01171875, 0.0, 0.0, 0.1510416716337204, 0.0006510416860692203, 0.076171875, 0.0006510416860692203, 0.0, 0.0262586809694767, 0.0, 0.0368923619389534, 0.0729166641831398, 0.0006510416860692203, 0.0, 0.1851128488779068, 0.6343315839767456, 0.0, 0.912109375, 0.0944010391831398, 0.0006510416860692203, 0.0, 0.0, 0.0581597238779068, 0.0, 0.7046440839767456, 0.03081597201526165, 0.1137152761220932, 0.00021701389050576836, 0.0, 0.00021701389050576836, 0.0167100690305233, 0.0, 0.0078125, 0.0425347238779068, 0.0, 0.02973090298473835, 0.01410590298473835, 0.0, 0.02951388992369175, 0.0, 0.002170138992369175, 0.162109375, 0.0577256940305233, 0.416015625, 0.0364583320915699, 0.0, 0.0010850694961845875, 0.0, 0.0694444477558136, 0.007595486007630825, 0.1223958358168602, 0.0, 0.1104600727558136, 0.0, 0.0, 0.078993059694767, 0.0, 0.00021701389050576836, 0.0004340277810115367, 0.0, 0.0405815988779068, 0.00021701389050576836, 0.00021701389050576836, 0.0, 0.0401475690305233, 0.9984809160232544, 0.00021701389050576836, 0.01171875, 0.0, 0.0015190972480922937, 0.02278645895421505, 0.2823350727558136, 0.0481770820915699, 0.0466579869389534, 0.0553385429084301, 0.9993489384651184, 0.00021701389050576836, 0.0609809048473835, 0.0004340277810115367, 0.0, 0.0440538190305233, 0.0, 0.014973958022892475, 0.0677083358168602, 0.0, 0.0193142369389534, 0.0, 0.04296875, 0.0, 0.0013020833721384406, 0.02951388992369175, 0.1330295205116272, 0.005859375, 0.007378472480922937, 0.0, 0.005859375, 0.0212673619389534, 0.0, 0.0004340277810115367, 0.0, 0.0, 0.1848958283662796, 0.0023871527519077063, 0.0078125, 0.0423177070915699, 0.03125, 0.0, 0.2393663227558136, 0.01953125, 0.00021701389050576836, 0.008029513992369175, 0.1866319477558136, 0.0460069440305233, 0.0553385429084301, 0.0184461809694767, 0.0703125, 0.0026041667442768812, 0.0032552082557231188, 0.0086805559694767, 0.013671875, 0.0779079869389534, 0.013888888992369175, 0.0562065988779068, 0.0, 0.00021701389050576836, 0.006076388992369175, 0.00021701389050576836, 0.01953125, 0.005642361007630825, 0.464409738779068, 0.0, 0.0, 0.0049913194961845875, 0.0520833320915699, 0.112196184694767, 0.0145399309694767, 0.00021701389050576836, 0.0026041667442768812, 0.0, 0.4496527910232544, 0.0989583358168602, 0.0553385429084301, 0.0, 0.1354166716337204, 0.0753038227558136, 0.00824652798473835, 0.0193142369389534, 0.0010850694961845875, 0.0536024309694767, 0.02365451492369175, 0.0915798619389534, 0.00021701389050576836, 0.007378472480922937, 0.0, 0.01692708395421505, 0.0, 0.0, 0.0008680555620230734, 0.0998263880610466, 0.3370225727558136, 0.0, 0.0, 0.766710102558136, 0.0032552082557231188, 0.0, 0.0579427070915699, 0.0948350727558136, 0.0086805559694767, 0.0, 0.0, 0.0453559048473835, 0.0, 0.02973090298473835, 0.013888888992369175, 0.006076388992369175, 0.005642361007630825, 0.025390625, 0.0004340277810115367, 0.08203125, 0.0, 0.0, 0.0023871527519077063, 0.00021701389050576836, 0.0, 0.0049913194961845875, 0.0, 0.0440538190305233, 0.00021701389050576836, 0.0, 0.3077256977558136, 0.0, 0.048828125, 0.0, 0.0, 0.0, 0.02582465298473835, 0.0460069440305233, 0.9982638955116272, 0.0390625, 0.0525173619389534, 0.0184461809694767, 0.00021701389050576836, 0.0010850694961845875, 0.0, 0.0583767369389534, 0.0418836809694767, 0.0694444477558136, 0.11328125, 0.0, 0.0477430559694767, 0.0, 0.0336371548473835, 0.0319010429084301, 0.00021701389050576836, 0.0340711809694767, 0.9997829794883728, 0.0, 0.0303819440305233, 0.5438368320465088, 0.01323784701526165, 0.02408854104578495, 0.0203993059694767, 0.00390625, 0.0010850694961845875, 0.01605902798473835, 0.0010850694961845875, 0.0, 0.0, 0.01215277798473835, 0.1434461772441864, 0.0010850694961845875, 0.0, 0.0026041667442768812, 0.0290798619389534, 0.0338541679084301, 0.00434027798473835, 0.0479600690305233, 0.0813802108168602, 0.0726996511220932, 0.181423619389534, 0.02365451492369175, 0.01974826492369175, 0.9895833134651184, 0.029296875, 0.1729600727558136, 0.00021701389050576836, 0.0, 0.005425347480922937, 0.0, 0.0857204869389534, 0.01822916604578495, 0.0564236119389534, 0.03059895895421505, 0.0896267369389534, 0.0008680555620230734, 0.0, 0.00021701389050576836, 0.0, 0.0193142369389534, 0.0, 0.02278645895421505, 0.3142361044883728, 0.0, 0.0, 0.0, 0.0, 0.004123263992369175, 0.01171875, 0.004123263992369175, 0.0, 0.0030381944961845875, 0.014756944961845875, 0.0, 0.02213541604578495, 0.0, 0.0023871527519077063, 0.00021701389050576836, 0.0223524309694767, 0.0, 0.0950520858168602, 0.009765625, 0.5633680820465088, 0.01953125, 0.00021701389050576836, 0.009765625, 0.0004340277810115367, 0.0520833320915699, 0.0746527761220932, 0.00390625, 0.02994791604578495, 0.01953125, 0.01974826492369175, 0.0483940988779068, 0.0030381944961845875, 0.0145399309694767, 0.0008680555620230734, 0.0004340277810115367, 0.0, 0.0, 0.0325520820915699, 0.0034722222480922937, 0.011501736007630825, 0.0, 0.002170138992369175, 0.0004340277810115367, 0.004123263992369175, 0.005425347480922937, 0.2335069477558136, 0.0010850694961845875, 0.0533854179084301, 0.006076388992369175, 0.00021701389050576836, 0.0047743055038154125, 0.162109375, 0.0922309011220932, 0.0, 0.9572482705116272, 0.00021701389050576836, 0.086805559694767, 0.0052083334885537624, 0.0006510416860692203, 0.123914934694767, 0.0, 0.0008680555620230734, 0.0470920130610466, 0.0355902798473835, 0.0553385429084301, 0.0983072891831398, 0.00021701389050576836, 0.0, 0.0, 0.0, 0.0, 0.0423177070915699, 0.01410590298473835, 0.0, 0.001953125, 0.0407986119389534, 0.02604166604578495, 0.00629340298473835, 0.6833767294883728, 0.0421006940305233, 0.0, 0.1640625, 0.052734375, 0.005425347480922937, 0.1401909738779068, 0.01215277798473835, 0.1846788227558136, 0.02083333395421505, 0.0028211805038154125, 0.011935763992369175, 0.013454861007630825, 0.0470920130610466, 0.01888020895421505, 0.0164930559694767, 0.0744357630610466, 0.0, 0.0006510416860692203, 0.00021701389050576836, 0.02886284701526165, 0.0618489570915699, 0.0047743055038154125, 0.02799479104578495, 0.007378472480922937, 0.0512152798473835, 0.1497395783662796, 0.0, 0.0006510416860692203, 0.0353732630610466, 0.01801215298473835, 0.013454861007630825, 0.00021701389050576836, 0.03125, 0.0659722238779068, 0.0004340277810115367, 0.1106770858168602, 0.0, 0.0, 0.8943142294883728, 0.1124131977558136, 0.0, 0.0047743055038154125, 0.1078559011220932, 0.0, 0.002170138992369175, 0.0004340277810115367, 0.0501302070915699, 0.0928819477558136, 0.064453125, 0.0479600690305233, 0.0319010429084301, 0.0]

 sparsity of   [0.048828125, 0.052734375, 0.068359375, 0.005859375, 0.068359375, 0.11328125, 0.017578125, 0.01171875, 0.064453125, 0.921875, 0.021484375, 0.015625, 0.033203125, 0.53515625, 0.994140625, 0.025390625, 0.017578125, 0.12109375, 0.884765625, 0.115234375, 0.013671875, 0.107421875, 0.974609375, 0.14453125, 0.138671875, 0.001953125, 0.08203125, 0.31640625, 0.11328125, 0.05078125, 0.33203125, 0.93359375, 0.09375, 0.994140625, 0.01171875, 0.056640625, 0.251953125, 0.568359375, 0.041015625, 0.0, 0.05859375, 0.794921875, 0.015625, 0.111328125, 0.91015625, 0.017578125, 0.046875, 0.994140625, 0.865234375, 0.8203125, 0.033203125, 0.025390625, 0.07421875, 0.08984375, 0.001953125, 0.001953125, 0.0, 0.1484375, 0.12109375, 0.716796875, 0.7265625, 0.013671875, 0.513671875, 0.03125, 0.017578125, 0.087890625, 0.203125, 0.005859375, 0.029296875, 0.12109375, 0.015625, 0.697265625, 0.015625, 0.076171875, 0.185546875, 0.0625, 0.029296875, 0.03125, 0.021484375, 0.009765625, 0.5625, 0.15234375, 0.06640625, 0.01171875, 0.142578125, 0.58984375, 0.01171875, 0.28125, 0.013671875, 0.013671875, 0.078125, 0.0390625, 0.0234375, 0.00390625, 0.16015625, 0.00390625, 0.033203125, 0.015625, 0.1015625, 0.146484375, 0.056640625, 0.01953125, 0.03515625, 0.06640625, 0.99609375, 0.00390625, 0.994140625, 0.0625, 0.03515625, 0.021484375, 0.0859375, 0.90625, 0.005859375, 0.0390625, 0.26953125, 0.0703125, 0.783203125, 0.20703125, 0.07421875, 0.994140625, 0.01171875, 0.95703125, 0.99609375, 0.08203125, 0.080078125, 0.08203125, 0.06640625, 0.251953125, 0.013671875, 0.291015625, 0.015625, 0.181640625, 0.578125, 0.029296875, 0.03125, 0.048828125, 0.029296875, 0.08984375, 0.1484375, 0.294921875, 0.0390625, 0.04296875, 0.013671875, 0.078125, 0.025390625, 0.041015625, 0.033203125, 0.013671875, 0.54296875, 0.025390625, 0.23828125, 0.029296875, 0.013671875, 0.03515625, 0.060546875, 0.060546875, 0.140625, 0.015625, 0.994140625, 0.84765625, 0.0234375, 0.052734375, 0.03515625, 0.01953125, 0.0234375, 0.064453125, 0.994140625, 0.0078125, 0.052734375, 0.033203125, 0.021484375, 0.025390625, 0.052734375, 0.00390625, 0.99609375, 0.123046875, 0.166015625, 0.822265625, 0.03515625, 0.0234375, 0.0078125, 0.087890625, 0.0234375, 0.65625, 0.017578125, 0.0078125, 0.068359375, 0.021484375, 0.021484375, 0.056640625, 0.693359375, 0.998046875, 0.060546875, 0.01171875, 0.169921875, 0.220703125, 0.568359375, 0.046875, 0.00390625, 0.021484375, 0.01953125, 0.048828125, 0.240234375, 0.712890625, 0.03515625, 0.00390625, 0.994140625, 0.859375, 0.048828125, 0.294921875, 0.4921875, 0.02734375, 0.447265625, 0.0390625, 0.01953125, 0.00390625, 0.171875, 0.033203125, 0.12890625, 0.03125, 0.02734375, 0.037109375, 0.236328125, 0.013671875, 0.99609375, 0.03125, 0.994140625, 0.048828125, 0.111328125, 0.0234375, 0.05078125, 0.029296875, 0.083984375, 0.025390625, 0.046875, 0.06640625, 0.048828125, 0.021484375, 0.052734375, 0.01171875, 0.041015625, 0.03515625, 0.01171875, 0.078125, 0.85546875, 0.04296875, 0.041015625, 0.041015625, 0.044921875, 0.015625, 0.193359375, 0.119140625, 0.02734375, 0.05078125, 0.03515625, 0.07421875, 0.05859375, 0.037109375, 0.0, 0.037109375, 0.001953125, 0.03125, 0.087890625, 0.021484375, 0.087890625, 0.068359375, 0.017578125, 0.009765625, 0.068359375, 0.515625, 0.02734375, 0.076171875, 0.033203125, 0.064453125, 0.99609375, 0.0390625, 0.03515625, 0.03125, 0.046875, 0.044921875, 0.107421875, 0.14453125, 0.009765625, 0.00390625, 0.056640625, 0.048828125, 0.025390625, 0.04296875, 0.994140625, 0.994140625, 0.017578125, 0.064453125, 0.029296875, 0.03125, 0.998046875, 0.994140625, 0.048828125, 0.3828125, 0.03515625, 0.166015625, 0.107421875, 0.03125, 0.08984375, 0.08203125, 0.244140625, 0.02734375, 0.076171875, 0.572265625, 0.03125, 0.0078125, 0.962890625, 0.033203125, 0.044921875, 0.04296875, 0.015625, 0.025390625, 0.046875, 0.916015625, 0.056640625, 0.01171875, 0.01953125, 0.029296875, 0.154296875, 0.04296875, 0.013671875, 0.05859375, 0.044921875, 0.99609375, 0.646484375, 0.068359375, 0.015625, 0.02734375, 0.05078125, 0.048828125, 0.05859375, 0.064453125, 0.712890625, 0.025390625, 0.009765625, 0.021484375, 0.994140625, 0.060546875, 0.021484375, 0.01953125, 0.021484375, 0.00390625, 0.16015625, 0.00390625, 0.087890625, 0.06640625, 0.912109375, 0.447265625, 0.08203125, 0.0, 0.044921875, 0.0078125, 0.041015625, 0.021484375, 0.0546875, 0.072265625, 0.033203125, 0.068359375, 0.037109375, 0.037109375, 0.0234375, 0.056640625, 0.03125, 0.001953125, 0.0, 0.033203125, 0.09375, 0.9140625, 0.681640625, 0.041015625, 0.529296875, 0.01171875, 0.013671875, 0.0390625, 0.958984375, 0.130859375, 0.052734375, 0.0390625, 0.666015625, 0.03125, 0.994140625, 0.310546875, 0.99609375, 0.021484375, 0.03125, 0.05078125, 0.091796875, 0.01171875, 0.0234375, 0.017578125, 0.01953125, 0.111328125, 0.80859375, 0.0234375, 0.755859375, 0.931640625, 0.234375, 0.056640625, 0.0234375, 0.08984375, 0.001953125, 0.029296875, 0.998046875, 0.197265625, 0.99609375, 0.015625, 0.1171875, 0.037109375, 0.021484375, 0.017578125, 0.73046875, 0.025390625, 0.02734375, 0.1015625, 0.033203125, 0.025390625, 0.087890625, 0.998046875, 0.869140625, 0.048828125, 0.05859375, 0.08984375, 0.123046875, 0.009765625, 0.013671875, 0.154296875, 0.998046875, 0.056640625, 0.03515625, 0.798828125, 0.021484375, 0.125, 0.0078125, 0.044921875, 0.244140625, 0.060546875, 0.0078125, 0.0234375, 0.0234375, 0.041015625, 0.03125, 0.009765625, 0.033203125, 0.01171875, 0.044921875, 0.927734375, 0.033203125, 0.04296875, 0.822265625, 0.22265625, 0.125, 0.013671875, 0.05859375, 0.06640625, 0.0, 0.013671875, 0.16796875, 0.73828125, 0.2265625, 0.048828125, 0.994140625, 0.044921875, 0.06640625, 0.0234375, 0.994140625, 0.017578125, 0.048828125, 0.04296875, 0.00390625, 0.998046875, 0.0546875, 0.07421875, 0.0390625, 0.134765625, 0.08984375, 0.5859375, 0.900390625, 0.07421875, 0.775390625, 0.365234375, 0.037109375, 0.091796875, 0.001953125, 0.037109375, 0.111328125, 0.005859375, 0.017578125, 0.009765625, 0.423828125, 0.04296875, 0.08203125, 0.193359375, 0.005859375, 0.0625, 0.18359375, 0.0546875, 0.076171875, 0.994140625, 0.033203125, 0.087890625, 0.8515625, 0.0703125, 0.060546875, 0.013671875, 0.021484375, 0.044921875, 0.041015625, 0.02734375, 0.015625, 0.009765625, 0.05078125, 0.080078125, 0.0078125, 0.0859375, 0.037109375, 0.005859375, 0.58984375, 0.779296875, 0.0234375, 0.015625, 0.021484375, 0.025390625, 0.623046875, 0.107421875, 0.052734375, 0.998046875, 0.087890625, 0.166015625, 0.05859375, 0.017578125, 0.021484375, 0.08203125, 0.189453125, 0.041015625, 0.04296875, 0.017578125, 0.046875, 0.009765625, 0.05078125, 0.072265625, 0.07421875, 0.033203125, 0.041015625, 0.046875, 0.138671875, 0.56640625, 0.044921875, 0.98046875, 0.12890625, 0.01171875, 0.998046875, 0.998046875, 0.0546875, 0.0546875, 0.994140625, 0.009765625, 0.0625, 0.064453125, 0.01171875, 0.013671875, 0.10546875, 0.994140625, 0.021484375, 0.01171875, 0.103515625, 0.072265625, 0.0546875, 0.033203125, 0.87890625, 0.65234375, 0.005859375, 0.025390625, 0.0625, 0.7734375, 0.09765625, 0.00390625, 0.05078125, 0.228515625, 0.02734375, 0.13671875, 0.125, 0.20703125, 0.091796875, 0.994140625, 0.12109375, 0.0234375, 0.0546875, 0.076171875, 0.03125, 0.08203125, 0.013671875, 0.029296875, 0.05859375, 0.009765625, 0.0078125, 0.00390625, 0.056640625, 0.03515625, 0.021484375, 0.0546875, 0.013671875, 0.013671875, 0.025390625, 0.01171875, 0.005859375, 0.994140625, 0.048828125, 0.640625, 0.06640625, 0.0859375, 0.337890625, 0.060546875, 0.12109375, 0.16015625, 0.009765625, 0.0390625, 0.04296875, 0.076171875, 0.046875, 0.04296875, 0.06640625, 0.017578125, 0.046875, 0.001953125, 0.015625, 0.02734375, 0.79296875, 0.01953125, 0.025390625, 0.220703125, 0.056640625, 0.0234375, 0.017578125, 0.154296875, 0.00390625, 0.99609375, 0.12890625, 0.05078125, 0.01953125, 0.02734375, 0.71484375, 0.033203125, 0.05078125, 0.72265625, 0.99609375, 0.009765625, 0.072265625, 0.720703125, 0.265625, 0.0, 0.654296875, 0.48828125, 0.05078125, 0.001953125, 0.998046875, 0.26171875, 0.865234375, 0.033203125, 0.0078125, 0.041015625, 0.03515625, 0.044921875, 0.02734375, 0.0234375, 0.994140625, 0.03515625, 0.998046875, 0.3828125, 0.03515625, 0.666015625, 0.0390625, 0.056640625, 0.21875, 0.083984375, 0.99609375, 0.001953125, 0.166015625, 0.0625, 0.072265625, 0.578125, 0.1015625, 0.111328125, 0.705078125, 0.05078125, 0.11328125, 0.046875, 0.00390625, 0.189453125, 0.044921875, 0.021484375, 0.02734375, 0.025390625, 0.087890625, 0.994140625, 0.046875, 0.490234375, 0.0078125, 0.078125, 0.06640625, 0.189453125, 0.06640625, 0.025390625, 0.107421875, 0.306640625, 0.521484375, 0.0546875, 0.02734375, 0.052734375, 0.044921875, 0.021484375, 0.14453125, 0.060546875, 0.09375, 0.623046875, 0.056640625, 0.19921875, 0.517578125, 0.45703125, 0.130859375, 0.060546875, 0.0390625, 0.076171875, 0.001953125, 0.0234375, 0.109375, 0.0, 0.759765625, 0.02734375, 0.044921875, 0.02734375, 0.267578125, 0.994140625, 0.033203125, 0.060546875, 0.013671875, 0.021484375, 0.037109375, 0.62890625, 0.044921875, 0.068359375, 0.005859375, 0.017578125, 0.029296875, 0.16796875, 0.08203125, 0.16015625, 0.056640625, 0.09375, 0.03125, 0.994140625, 0.029296875, 0.015625, 0.033203125, 0.03125, 0.044921875, 0.005859375, 0.994140625, 0.03125, 0.935546875, 0.806640625, 0.224609375, 0.0625, 0.087890625, 0.08984375, 0.09375, 0.017578125, 0.017578125, 0.048828125, 0.03125, 0.994140625, 0.009765625, 0.162109375, 0.076171875, 0.068359375, 0.080078125, 0.25390625, 0.01171875, 0.71484375, 0.00390625, 0.30078125, 0.125, 0.005859375, 0.880859375, 0.056640625, 0.048828125, 0.03125, 0.017578125, 0.67578125, 0.009765625, 0.005859375, 0.00390625, 0.59765625, 0.8046875, 0.0625, 0.013671875, 0.001953125, 0.03515625, 0.01171875, 0.0390625, 0.013671875, 0.037109375, 0.068359375, 0.005859375, 0.171875, 0.078125, 0.12890625, 0.005859375, 0.099609375, 0.068359375, 0.259765625, 0.998046875, 0.009765625, 0.068359375, 0.064453125, 0.037109375, 0.998046875, 0.07421875, 0.072265625, 0.08984375, 0.998046875, 0.080078125, 0.015625, 0.076171875, 0.029296875, 0.10546875, 0.05078125, 0.044921875, 0.04296875, 0.03125, 0.994140625, 0.02734375, 0.03125, 0.994140625, 0.08984375, 0.994140625, 0.255859375, 0.048828125, 0.0703125, 0.244140625, 0.068359375, 0.060546875, 0.06640625, 0.099609375, 0.03125, 0.015625, 0.03125, 0.05078125, 0.025390625, 0.0, 0.03515625, 0.01171875, 0.0546875, 0.09765625, 0.03125, 0.04296875, 0.0390625, 0.03125, 0.0234375, 0.046875, 0.06640625, 0.05078125, 0.216796875, 0.11328125, 0.0, 0.662109375, 0.09375, 0.021484375, 0.138671875, 0.107421875, 0.03515625, 0.560546875, 0.150390625, 0.017578125, 0.16015625, 0.02734375, 0.994140625, 0.0703125, 0.01171875, 0.00390625, 0.046875, 0.025390625, 0.068359375, 0.123046875, 0.11328125, 0.310546875, 0.03125, 0.02734375, 0.505859375, 0.923828125, 0.138671875, 0.076171875, 0.0234375, 0.994140625, 0.66015625, 0.298828125, 0.095703125, 0.017578125, 0.046875, 0.646484375, 0.033203125, 0.994140625, 0.64453125, 0.056640625, 0.119140625, 0.033203125, 0.0625, 0.01953125, 0.01171875, 0.013671875, 0.060546875, 0.048828125, 0.12890625, 0.9140625, 0.033203125, 0.02734375, 0.12109375, 0.01171875, 0.046875, 0.013671875, 0.232421875, 0.08984375, 0.09765625, 0.044921875, 0.083984375, 0.013671875, 0.021484375, 0.01953125, 0.01953125, 0.0625, 0.169921875, 0.03125, 0.052734375, 0.03515625, 0.841796875, 0.314453125, 0.150390625, 0.05078125, 0.0078125, 0.048828125, 0.994140625, 0.0234375, 0.017578125, 0.154296875, 0.037109375, 0.05859375, 0.08203125, 0.03125, 0.01171875, 0.015625, 0.064453125, 0.041015625, 0.009765625, 0.017578125, 0.779296875, 0.111328125, 0.044921875, 0.005859375, 0.00390625, 0.07421875, 0.033203125, 0.15625, 0.013671875, 0.0703125, 0.0703125, 0.048828125, 0.423828125, 0.029296875, 0.0859375, 0.02734375, 0.013671875, 0.083984375, 0.00390625, 0.029296875, 0.716796875, 0.03515625, 0.021484375, 0.025390625, 0.994140625, 0.0234375, 0.013671875, 0.021484375, 0.15234375, 0.892578125, 0.009765625, 0.0390625, 0.068359375, 0.06640625, 0.583984375, 0.029296875, 0.04296875, 0.462890625, 0.482421875, 0.12109375, 0.0234375, 0.708984375, 0.03125, 0.05859375, 0.1640625, 0.111328125, 0.04296875, 0.013671875, 0.04296875, 0.060546875, 0.99609375, 0.080078125, 0.103515625, 0.025390625, 0.060546875, 0.048828125, 0.056640625, 0.07421875, 0.033203125, 0.048828125, 0.072265625, 0.033203125, 0.0625, 0.015625, 0.001953125, 0.125, 0.015625, 0.994140625, 0.001953125, 0.99609375, 0.154296875, 0.82421875, 0.009765625, 0.19921875, 0.880859375, 0.001953125, 0.021484375, 0.02734375, 0.009765625, 0.259765625, 0.05859375, 0.0078125, 0.87890625, 0.033203125, 0.107421875, 0.19140625, 0.09765625, 0.048828125, 0.2109375, 0.90234375, 0.994140625, 0.04296875, 0.08203125, 0.033203125, 0.029296875, 0.998046875, 0.013671875, 0.00390625, 0.8046875, 0.05078125, 0.01171875, 0.025390625, 0.044921875, 0.177734375, 0.064453125, 0.134765625, 0.599609375, 0.123046875, 0.046875, 0.119140625, 0.0, 0.017578125, 0.025390625, 0.140625, 0.0234375, 0.04296875, 0.30078125, 0.595703125, 0.0234375, 0.01953125, 0.875, 0.599609375, 0.044921875, 0.06640625, 0.607421875, 0.998046875, 0.044921875, 0.041015625, 0.408203125, 0.83203125, 0.99609375, 0.861328125, 0.1796875, 0.951171875, 0.0234375, 0.216796875, 0.994140625, 0.015625, 0.037109375, 0.99609375, 0.0390625, 0.05078125, 0.046875, 0.2734375, 0.0859375, 0.9140625, 0.009765625, 0.060546875, 0.90234375, 0.03515625, 0.037109375, 0.994140625, 0.009765625, 0.1015625, 0.046875, 0.080078125, 0.048828125, 0.373046875, 0.32421875, 0.294921875, 0.015625, 0.6875, 0.025390625, 0.119140625, 0.037109375, 0.75390625, 0.037109375, 0.03125, 0.0, 0.01953125, 0.0, 0.078125, 0.029296875, 0.078125, 0.0, 0.01953125, 0.998046875, 0.017578125, 0.173828125, 0.994140625, 0.0859375, 0.26953125, 0.126953125, 0.015625, 0.07421875, 0.01953125, 0.091796875, 0.02734375, 0.041015625, 0.111328125, 0.88671875, 0.115234375, 0.005859375, 0.037109375, 0.78125, 0.0078125, 0.064453125, 0.013671875, 0.017578125, 0.009765625, 0.005859375, 0.138671875, 0.0546875, 0.0234375, 0.00390625, 0.01171875, 0.021484375, 0.052734375, 0.0078125, 0.017578125, 0.994140625, 0.24609375, 0.033203125, 0.43359375, 0.013671875, 0.0078125, 0.03125, 0.017578125, 0.103515625, 0.99609375, 0.013671875, 0.0859375, 0.431640625, 0.05078125, 0.017578125, 0.03125, 0.0546875, 0.060546875, 0.13671875, 0.0234375, 0.056640625, 0.99609375, 0.15625, 0.015625, 0.08203125, 0.0625, 0.05078125, 0.107421875, 0.052734375, 0.99609375, 0.994140625, 0.068359375, 0.03125, 0.099609375, 0.0234375, 0.994140625, 0.0390625, 0.994140625, 0.162109375, 0.001953125, 0.05859375, 0.994140625, 0.02734375, 0.130859375, 0.033203125, 0.416015625, 0.01953125, 0.005859375, 0.08203125, 0.08203125, 0.0078125, 0.001953125, 0.02734375, 0.017578125, 0.025390625, 0.10546875, 0.056640625, 0.076171875, 0.85546875, 0.033203125, 0.119140625, 0.041015625, 0.18359375, 0.01171875, 0.044921875, 0.638671875, 0.056640625, 0.05078125, 0.994140625, 0.14453125, 0.1328125, 0.724609375, 0.091796875, 0.30078125, 0.326171875, 0.6328125, 0.009765625, 0.03125, 0.021484375, 0.015625, 0.00390625, 0.251953125, 0.025390625, 0.044921875, 0.015625, 0.109375, 0.07421875, 0.892578125, 0.99609375, 0.068359375, 0.650390625, 0.12109375, 0.044921875, 0.052734375, 0.0, 0.05078125, 0.4921875, 0.0390625, 0.658203125, 0.05078125, 0.021484375, 0.03125, 0.02734375, 0.015625, 0.080078125, 0.056640625, 0.09765625, 0.994140625, 0.0546875, 0.765625, 0.2109375, 0.06640625, 0.638671875, 0.064453125, 0.0703125, 0.607421875, 0.99609375, 0.017578125, 0.806640625, 0.0234375, 0.814453125, 0.0390625, 0.103515625, 0.40234375, 0.013671875, 0.09375, 0.01171875, 0.056640625, 0.0625, 0.076171875, 0.142578125, 0.0234375, 0.05078125, 0.01171875, 0.03125, 0.009765625, 0.009765625, 0.255859375, 0.06640625, 0.99609375, 0.009765625, 0.99609375, 0.00390625, 0.255859375, 0.1171875, 0.0703125, 0.546875, 0.01171875, 0.056640625, 0.46875, 0.01953125, 0.16796875, 0.03515625, 0.125, 0.037109375, 0.15234375, 0.083984375, 0.53515625, 0.0078125, 0.267578125, 0.01171875, 0.00390625, 0.0234375, 0.869140625, 0.994140625, 0.337890625, 0.193359375, 0.017578125, 0.029296875, 0.013671875, 0.041015625, 0.009765625, 0.037109375, 0.021484375, 0.029296875, 0.09765625, 0.021484375, 0.09375, 0.994140625, 0.052734375, 0.041015625, 0.033203125, 0.994140625, 0.01171875, 0.001953125, 0.0078125, 0.03125, 0.01953125, 0.01171875, 0.015625, 0.466796875, 0.798828125, 0.158203125, 0.001953125, 0.0546875, 0.03515625, 0.046875, 0.0234375, 0.15625, 0.013671875, 0.0390625, 0.74609375, 0.033203125, 0.08203125, 0.03125, 0.173828125, 0.677734375, 0.99609375, 0.060546875, 0.015625, 0.291015625, 0.009765625, 0.166015625, 0.134765625, 0.177734375, 0.93359375, 0.091796875, 0.095703125, 0.044921875, 0.1171875, 0.025390625, 0.03515625, 0.994140625, 0.99609375, 0.28515625, 0.0234375, 0.607421875, 0.994140625, 0.060546875, 0.265625, 0.060546875, 0.009765625, 0.80078125, 0.005859375, 0.037109375, 0.064453125, 0.0234375, 0.078125, 0.041015625, 0.044921875, 0.46484375, 0.119140625, 0.02734375, 0.01953125, 0.072265625, 0.107421875, 0.005859375, 0.021484375, 0.015625, 0.46484375, 0.0234375, 0.251953125, 0.248046875, 0.296875, 0.044921875, 0.033203125, 0.037109375, 0.033203125, 0.994140625, 0.404296875, 0.091796875, 0.1015625, 0.189453125, 0.021484375, 0.041015625, 0.09765625, 0.220703125, 0.3203125, 0.017578125, 0.033203125, 0.525390625, 0.0546875, 0.0703125, 0.28515625, 0.994140625, 0.0390625, 0.619140625, 0.044921875, 0.06640625, 0.0390625, 0.00390625, 0.119140625, 0.0234375, 0.02734375, 0.064453125, 0.0390625, 0.04296875, 0.001953125, 0.099609375, 0.037109375, 0.00390625, 0.056640625, 0.017578125, 0.015625, 0.015625, 0.0234375, 0.037109375, 0.056640625, 0.041015625, 0.03125, 0.013671875, 0.044921875, 0.078125, 0.04296875, 0.029296875, 0.025390625, 0.02734375, 0.017578125, 0.1328125, 0.185546875, 0.087890625, 0.681640625, 0.01171875, 0.05859375, 0.037109375, 0.029296875, 0.0390625, 0.025390625, 0.078125, 0.087890625, 0.134765625, 0.0625, 0.837890625, 0.99609375, 0.115234375, 0.025390625, 0.89453125, 0.02734375, 0.181640625, 0.154296875, 0.66015625, 0.169921875, 0.01171875, 0.11328125, 0.99609375, 0.0234375, 0.021484375, 0.009765625, 0.00390625, 0.236328125, 0.041015625, 0.005859375, 0.03125, 0.0234375, 0.0234375, 0.1484375, 0.046875, 0.08984375, 0.017578125, 0.39453125, 0.1640625, 0.13671875, 0.041015625, 0.013671875, 0.076171875, 0.02734375, 0.0390625, 0.1015625, 0.025390625, 0.107421875, 0.310546875, 0.025390625, 0.080078125, 0.056640625, 0.71484375, 0.890625, 0.02734375, 0.28515625, 0.95703125, 0.021484375, 0.017578125, 0.763671875, 0.8046875, 0.02734375, 0.994140625, 0.138671875, 0.056640625, 0.091796875, 0.029296875, 0.396484375, 0.0546875, 0.94140625, 0.03125, 0.26953125, 0.994140625, 0.021484375, 0.1015625, 0.03125, 0.0234375, 0.05859375, 0.107421875, 0.423828125, 0.056640625, 0.78515625, 0.001953125, 0.048828125, 0.03125, 0.58203125, 0.033203125, 0.0078125, 0.072265625, 0.05078125, 0.02734375, 0.9609375, 0.662109375, 0.47265625, 0.08203125, 0.185546875, 0.03125, 0.0234375, 0.037109375, 0.125, 0.037109375, 0.025390625, 0.015625, 0.009765625, 0.65625, 0.00390625, 0.056640625, 0.115234375, 0.04296875, 0.00390625, 0.013671875, 0.048828125, 0.03125, 0.0703125, 0.103515625, 0.205078125, 0.1484375, 0.103515625, 0.107421875, 0.037109375, 0.04296875, 0.029296875, 0.02734375, 0.021484375, 0.072265625, 0.021484375, 0.00390625, 0.18359375, 0.041015625, 0.017578125, 0.109375, 0.02734375, 0.998046875, 0.033203125, 0.060546875, 0.99609375, 0.0, 0.0078125, 0.0625, 0.31640625, 0.029296875, 0.01953125, 0.994140625, 0.03515625, 0.89453125, 0.080078125, 0.994140625, 0.041015625, 0.064453125, 0.16796875, 0.005859375, 0.005859375, 0.0, 0.111328125, 0.07421875, 0.017578125, 0.919921875, 0.029296875, 0.12109375, 0.0390625, 0.03125, 0.0625, 0.994140625, 0.80078125, 0.025390625, 0.068359375, 0.052734375, 0.005859375, 0.048828125, 0.068359375, 0.025390625, 0.033203125, 0.59765625, 0.041015625, 0.048828125, 0.083984375, 0.0234375, 0.994140625, 0.025390625, 0.20703125, 0.037109375, 0.009765625, 0.041015625, 0.044921875, 0.05078125, 0.068359375, 0.7265625, 0.048828125, 0.6015625, 0.892578125, 0.029296875, 0.083984375, 0.009765625, 0.431640625, 0.794921875, 0.5859375, 0.025390625, 0.10546875, 0.0234375, 0.017578125, 0.0, 0.009765625, 0.998046875, 0.021484375, 0.078125, 0.0234375, 0.662109375, 0.994140625, 0.994140625, 0.025390625, 0.572265625, 0.009765625, 0.0625, 0.2578125, 0.732421875, 0.037109375, 0.001953125, 0.728515625, 0.03515625, 0.029296875, 0.771484375, 0.03125, 0.044921875, 0.185546875, 0.001953125, 0.046875, 0.994140625, 0.998046875, 0.01953125, 0.044921875, 0.0078125, 0.35546875, 0.03515625, 0.015625, 0.08984375, 0.048828125, 0.029296875, 0.009765625, 0.0859375, 0.013671875, 0.0859375, 0.0546875, 0.99609375, 0.046875, 0.208984375, 0.068359375, 0.123046875, 0.0625, 0.064453125, 0.029296875, 0.021484375, 0.994140625, 0.587890625, 0.060546875, 0.033203125, 0.078125, 0.1015625, 0.015625, 0.01953125, 0.064453125, 0.201171875, 0.05859375, 0.076171875, 0.03515625, 0.01171875, 0.021484375, 0.017578125, 0.16796875, 0.02734375, 0.994140625, 0.05078125, 0.275390625, 0.052734375, 0.0390625, 0.3125, 0.994140625, 0.015625, 0.15234375, 0.99609375, 0.0859375, 0.05078125, 0.37890625, 0.103515625, 0.02734375, 0.037109375, 0.076171875, 0.005859375, 0.2578125, 0.017578125, 0.595703125, 0.6796875, 0.03515625, 0.05859375, 0.060546875, 0.53515625, 0.771484375, 0.060546875, 0.515625, 0.013671875, 0.02734375, 0.025390625, 0.015625, 0.189453125, 0.02734375, 0.025390625, 0.04296875, 0.02734375, 0.083984375, 0.66015625, 0.3125, 0.017578125, 0.00390625, 0.14453125, 0.064453125, 0.01171875, 0.025390625, 0.20703125, 0.037109375, 0.037109375, 0.056640625, 0.99609375, 0.111328125, 0.056640625, 0.3203125, 0.185546875, 0.173828125, 0.11328125, 0.017578125, 0.99609375, 0.005859375, 0.025390625, 0.005859375, 0.455078125, 0.078125, 0.0, 0.123046875, 0.255859375, 0.0390625, 0.029296875, 0.04296875, 0.015625, 0.0078125, 0.0390625, 0.009765625, 0.00390625, 0.01953125, 0.10546875, 0.01171875, 0.078125, 0.83203125, 0.12109375, 0.14453125, 0.0078125, 0.291015625, 0.03125, 0.28125, 0.02734375, 0.99609375, 0.033203125, 0.291015625, 0.0078125, 0.017578125, 0.919921875, 0.0390625, 0.068359375, 0.0859375, 0.63671875, 0.021484375, 0.046875, 0.015625, 0.029296875, 0.2421875, 0.994140625, 0.095703125, 0.04296875, 0.05859375, 0.107421875, 0.025390625, 0.1015625, 0.015625, 0.03125, 0.04296875, 0.025390625, 0.05078125, 0.6953125, 0.0703125, 0.240234375, 0.02734375, 0.064453125, 0.00390625, 0.005859375, 0.029296875, 0.06640625, 0.994140625, 0.994140625, 0.025390625, 0.087890625, 0.892578125, 0.859375, 0.044921875, 0.017578125, 0.0390625, 0.751953125, 0.521484375, 0.04296875, 0.998046875, 0.0, 0.828125, 0.24609375, 0.150390625, 0.068359375, 0.046875, 0.08984375, 0.0390625, 0.044921875, 0.01953125, 0.02734375, 0.0234375, 0.0234375, 0.09375, 0.751953125, 0.03515625, 0.037109375, 0.052734375, 0.0390625, 0.02734375, 0.04296875, 0.00390625, 0.087890625, 0.029296875, 0.994140625, 0.015625, 0.060546875, 0.99609375, 0.126953125, 0.11328125, 0.25390625, 0.015625, 0.0546875, 0.076171875, 0.03125, 0.724609375, 0.01953125, 0.0078125, 0.025390625, 0.01953125, 0.298828125, 0.017578125, 0.01953125, 0.052734375, 0.015625, 0.05078125, 0.119140625, 0.263671875, 0.1015625, 0.01171875, 0.068359375, 0.0234375, 0.009765625, 0.291015625, 0.001953125, 0.02734375, 0.0546875, 0.03125, 0.013671875, 0.064453125, 0.849609375, 0.130859375, 0.126953125, 0.052734375, 0.0234375, 0.513671875, 0.45703125, 0.013671875, 0.0234375, 0.025390625, 0.01171875, 0.150390625, 0.400390625, 0.068359375, 0.994140625, 0.009765625, 0.03515625, 0.0390625, 0.03125, 0.205078125, 0.994140625, 0.017578125, 0.009765625, 0.017578125, 0.060546875, 0.75, 0.763671875, 0.025390625, 0.01953125, 0.005859375, 0.0390625, 0.03515625, 0.23828125, 0.0859375, 0.05078125, 0.994140625, 0.625, 0.04296875, 0.720703125, 0.10546875, 0.994140625, 0.08203125, 0.69140625, 0.064453125, 0.978515625, 0.994140625, 0.021484375, 0.072265625, 0.955078125, 0.140625, 0.029296875, 0.1171875, 0.0703125, 0.998046875, 0.095703125, 0.021484375, 0.06640625, 0.99609375, 0.015625, 0.00390625, 0.130859375, 0.05859375, 0.015625, 0.12890625, 0.01953125, 0.09375, 0.009765625, 0.005859375, 0.05078125, 0.0078125, 0.044921875, 0.994140625, 0.009765625, 0.99609375, 0.052734375, 0.884765625, 0.0078125, 0.013671875, 0.0234375, 0.03515625, 0.173828125, 0.177734375, 0.06640625, 0.02734375, 0.189453125, 0.01171875, 0.126953125, 0.994140625, 0.04296875, 0.611328125, 0.013671875, 0.025390625, 0.05859375, 0.01171875, 0.013671875, 0.111328125, 0.01171875, 0.1171875, 0.0234375, 0.072265625, 0.21484375, 0.037109375, 0.009765625]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Total parameter pruned: 6740035.025519401 (unstructured) 0 (structured)

max weight is  tensor([4.3653e-01, 2.9412e-02, 2.7691e-09, 1.8591e-01, 7.8363e-02, 3.3174e-01,
        3.4396e-01, 1.4222e-01, 1.4231e-01, 1.9128e-02, 4.7246e-09, 2.2390e-01,
        3.8592e-01, 8.7787e-01, 4.8289e-09, 4.9995e-09, 4.9281e-09, 2.9007e-09,
        2.5691e-01, 1.1101e-01, 4.5556e-01, 1.6708e-01, 3.9350e-01, 4.9063e-02,
        1.2513e-01, 9.6796e-04, 3.2386e-02, 7.1689e-01, 4.9995e-09, 3.1085e-01,
        9.1341e-02, 3.2374e-01, 4.3219e-09, 7.3781e-09, 5.8077e-02, 9.4392e-03,
        3.0968e-09, 2.9007e-09, 3.1036e-09, 3.6575e-01, 1.7752e-09, 2.5016e-01,
        2.8509e-09, 4.7480e-09, 3.3717e-02, 2.7779e-02, 1.7224e-02, 4.6155e-03,
        1.1316e-09, 4.3268e-02, 2.9007e-09, 4.7454e-09, 4.4278e-09, 2.1682e-02,
        1.7424e-09, 9.0239e-02, 2.6654e-01, 9.1154e-02, 4.7756e-09, 4.2809e-09,
        4.6893e-02, 4.5713e-01, 5.9007e-02, 3.2122e-01], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([1.4860e-08, 5.3964e-08, 1.7912e-01, 4.1242e-02, 9.2544e-02, 1.3983e-08,
        1.2549e-08, 1.4860e-08, 1.6234e-01, 3.6305e-02, 2.7973e-08, 8.9756e-02,
        7.8086e-02, 1.3404e-08, 4.6740e-02, 7.7789e-02, 2.7874e-01, 1.8964e-01,
        1.5132e-01, 4.2388e-08, 1.4860e-08, 2.5992e-08, 1.5736e-01, 1.1816e-01,
        1.5407e-01, 1.8099e-01, 1.6999e-01, 7.7402e-02, 7.6867e-02, 1.6259e-01,
        2.8063e-01, 1.0351e-01, 2.4700e-01, 1.6199e-01, 1.6381e-01, 1.2112e-01,
        4.6911e-02, 3.8185e-08, 1.2746e-01, 1.0529e-01, 6.5810e-02, 1.6024e-01,
        4.5040e-02, 2.1953e-08, 9.4850e-02, 2.3257e-08, 1.3983e-08, 1.7840e-01,
        1.0795e-01, 1.2640e-01, 1.6320e-09, 2.1648e-01, 6.5093e-02, 8.8840e-09,
        2.1943e-08, 1.7911e-01, 1.6276e-01, 5.2685e-02, 7.9945e-02, 3.8185e-08,
        2.5102e-01, 6.6229e-08, 1.7403e-01, 1.4491e-01], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([1.8291e-01, 2.2384e-07, 1.6840e-01, 2.7498e-07, 4.2017e-07, 5.6810e-02,
        2.8173e-07, 6.0630e-07, 1.7681e-07, 1.8609e-07, 1.4007e-02, 4.8865e-07,
        9.2380e-07, 1.0756e-01, 5.1352e-07, 4.0052e-07, 9.3471e-02, 3.0490e-02,
        3.9146e-03, 7.8719e-07, 1.4481e-07, 5.5494e-02, 1.6164e-01, 9.2380e-07,
        7.6183e-07, 2.9184e-07, 9.8324e-02, 4.9214e-07, 2.9468e-02, 7.9761e-02,
        9.0153e-07, 1.4828e-01, 9.2380e-07, 3.3206e-07, 4.5529e-02, 4.0052e-07,
        1.6603e-07, 7.3509e-02, 2.2384e-07, 1.9927e-01, 9.9775e-02, 1.7348e-07,
        3.6918e-02, 8.4015e-02, 5.6213e-02, 8.1278e-02, 3.1219e-02, 2.2633e-07,
        8.3031e-02, 4.2017e-07, 7.5435e-02, 6.0630e-07, 2.8173e-07, 4.2017e-07,
        7.3754e-07, 8.6754e-02, 7.7425e-02, 4.8725e-07, 4.9214e-07, 4.6493e-02,
        6.0630e-07, 1.6825e-01, 1.3830e-01, 2.9184e-07], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([3.3856e-02, 3.6113e-02, 1.1087e-02, 7.5101e-08, 5.7233e-02, 5.6663e-08,
        2.4106e-02, 6.6079e-08, 1.5313e-02, 4.6357e-02, 1.4659e-01, 5.6379e-08,
        1.8026e-01, 1.2737e-01, 1.1021e-01, 2.0852e-02, 2.4035e-08, 1.9044e-02,
        6.8497e-02, 3.3434e-08, 4.6130e-02, 9.4370e-02, 4.0455e-08, 8.7705e-02,
        7.1777e-02, 4.4818e-02, 8.6311e-02, 7.6938e-02, 9.5267e-02, 8.1975e-02,
        3.3709e-02, 3.5314e-02, 2.1258e-02, 5.9765e-08, 2.5744e-02, 1.9205e-01,
        3.4284e-02, 1.3194e-02, 1.2533e-02, 3.6585e-08, 2.8284e-02, 3.3361e-03,
        5.8217e-02, 2.1751e-08, 5.0211e-02, 1.3420e-01, 1.8190e-08, 3.5040e-02,
        2.9135e-02, 2.9487e-02, 3.4486e-02, 1.8777e-01, 1.5856e-01, 1.4519e-02,
        1.6050e-02, 1.0757e-02, 9.2795e-09, 5.5457e-02, 2.8943e-02, 3.3104e-02,
        3.8536e-02, 5.4261e-02, 5.7959e-02, 2.5861e-08, 1.5901e-01, 7.7990e-02,
        2.2437e-01, 1.7315e-01, 2.0847e-01, 2.4919e-02, 2.5697e-08, 1.1896e-02,
        2.6294e-07, 5.6980e-02, 2.1409e-02, 6.1733e-02, 2.4827e-02, 6.5444e-02,
        5.1546e-02, 2.3545e-02, 1.1407e-07, 2.5231e-08, 2.6396e-02, 9.4139e-02,
        4.0391e-02, 9.5237e-02, 3.5628e-02, 3.8772e-08, 2.5231e-08, 2.6711e-08,
        1.8206e-02, 8.0711e-08, 2.8403e-02, 1.3802e-01, 4.0183e-08, 5.5701e-02,
        2.2454e-02, 2.5682e-08, 3.7992e-02, 3.8187e-02, 3.8461e-02, 1.9770e-01,
        1.5831e-01, 8.6940e-02, 4.8439e-02, 1.0085e-01, 1.9599e-02, 7.8429e-02,
        1.7798e-01, 2.7477e-02, 1.9549e-01, 1.6832e-01, 8.6793e-02, 7.8100e-02,
        3.6585e-08, 5.4506e-08, 6.4245e-08, 8.2601e-02, 4.1417e-02, 1.3687e-01,
        1.6804e-01, 4.9846e-02, 2.6711e-08, 3.8762e-08, 3.3487e-08, 4.8095e-02,
        3.8772e-08, 1.3424e-01, 6.6010e-03, 1.3521e-01, 2.3458e-01, 2.4313e-02,
        2.9412e-08, 2.4035e-08, 5.5031e-08, 9.3348e-02, 1.1407e-07, 2.8633e-02,
        2.8694e-02, 7.5166e-02, 3.6344e-02, 2.6711e-08, 4.7567e-02, 1.5818e-01,
        5.6374e-02, 1.2516e-07, 7.3326e-02, 7.4962e-08, 1.5610e-01, 1.3522e-01,
        2.5249e-01, 2.2571e-01, 1.7867e-01, 2.4400e-08, 2.6711e-08, 7.4797e-02,
        2.7249e-02, 3.0120e-02, 6.6943e-02, 3.3184e-02, 1.8642e-01, 6.9548e-02,
        1.0307e-01, 9.1708e-02, 4.0036e-02, 5.6663e-08, 7.1220e-02, 4.4904e-02,
        5.7948e-02, 7.8871e-08, 6.2766e-02, 1.2516e-07, 8.2041e-02, 5.8122e-02,
        1.2552e-01, 3.4499e-08, 9.1148e-02, 8.0711e-08, 7.7447e-02, 1.9753e-02,
        2.1193e-01, 5.0074e-02, 3.3127e-08, 1.1595e-01, 5.5785e-02, 3.3064e-02,
        7.1814e-08, 1.1200e-02, 4.6836e-02, 5.0026e-08, 7.7935e-02, 6.3297e-02,
        6.4454e-02, 4.0183e-08, 1.5938e-01, 1.4173e-01, 4.9433e-02, 3.5828e-02,
        3.8772e-08, 4.6621e-08, 1.5808e-01, 6.9622e-02, 5.7703e-02, 5.4074e-08,
        5.2859e-02, 7.7226e-02, 5.1995e-02, 2.6852e-01, 1.0131e-01, 3.1979e-02,
        4.0183e-08, 2.3516e-01, 1.6902e-02, 2.4244e-02, 1.6158e-02, 5.6663e-08,
        5.4870e-02, 1.5126e-07, 9.6724e-02, 1.6289e-02, 3.6671e-02, 3.5139e-02,
        1.3242e-02, 1.5168e-01, 3.5889e-02, 1.8622e-02, 5.4461e-02, 1.8934e-02,
        4.5141e-02, 1.9263e-08, 6.5144e-02, 6.3504e-02, 3.0258e-08, 2.5231e-08,
        1.2914e-02, 5.4536e-03, 4.8489e-02, 1.5167e-01, 5.4074e-08, 1.2020e-02,
        2.2079e-01, 2.2575e-01, 3.6861e-02, 1.9936e-02, 8.2010e-02, 3.2122e-08,
        2.8256e-02, 2.3881e-02, 2.7322e-02, 7.7502e-02, 6.1473e-02, 1.0131e-01,
        2.2434e-01, 5.3713e-08, 2.5231e-08, 1.4093e-02], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([2.0579e-01, 1.4348e-01, 1.1491e-01, 2.3898e-03, 1.0101e-01, 1.4199e-08,
        6.3592e-03, 1.4199e-08, 1.5975e-01, 1.2113e-01, 7.2474e-02, 1.9226e-08,
        3.4613e-02, 9.6349e-02, 1.9823e-02, 7.3403e-02, 1.9226e-08, 1.1296e-01,
        5.9386e-02, 1.4199e-08, 5.6328e-02, 5.8273e-02, 1.4199e-08, 1.4857e-01,
        5.9662e-02, 2.5989e-02, 1.5114e-02, 8.0274e-02, 7.2416e-02, 1.5502e-01,
        1.4668e-01, 1.8809e-01, 1.5209e-01, 7.7660e-09, 6.7402e-02, 1.5715e-02,
        3.8827e-02, 1.3494e-01, 7.4873e-02, 1.4199e-08, 9.4928e-02, 7.5547e-02,
        7.0296e-02, 2.2389e-08, 7.9909e-02, 1.8091e-02, 1.9226e-08, 1.5214e-01,
        2.9520e-02, 1.3280e-01, 1.0303e-01, 1.4065e-01, 3.2633e-02, 1.5125e-02,
        9.7740e-02, 1.6278e-01, 1.9226e-08, 9.3819e-02, 6.5465e-02, 2.2783e-02,
        5.5130e-02, 6.6539e-02, 2.2903e-02, 1.9226e-08, 6.1438e-02, 2.3843e-01,
        5.2493e-02, 1.2946e-01, 2.7765e-02, 1.7195e-01, 1.9226e-08, 9.0458e-02,
        1.5866e-06, 9.9470e-09, 7.6204e-02, 7.6126e-02, 7.7942e-02, 1.4306e-01,
        6.2672e-02, 1.0655e-01, 3.3299e-09, 2.0888e-08, 2.9019e-01, 1.5102e-08,
        7.4642e-02, 1.1660e-02, 5.2388e-02, 1.4199e-08, 2.6288e-08, 1.9226e-08,
        9.2271e-09, 1.4199e-08, 2.4368e-01, 1.0758e-01, 6.4797e-08, 1.2261e-01,
        1.5880e-01, 1.4199e-08, 6.6132e-02, 2.3137e-01, 1.7936e-01, 2.4295e-02,
        7.5912e-02, 5.2491e-02, 1.3979e-01, 8.9829e-02, 1.3564e-01, 6.2647e-02,
        1.1916e-02, 1.1862e-01, 9.2886e-02, 1.3544e-01, 8.8051e-02, 6.2933e-02,
        2.3579e-08, 1.4199e-08, 1.4199e-08, 1.0925e-01, 7.7691e-02, 6.8841e-02,
        4.9872e-02, 1.0492e-01, 2.1489e-08, 1.4199e-08, 1.4199e-08, 1.4402e-01,
        2.0888e-08, 9.5394e-02, 5.7510e-02, 1.4506e-01, 1.8437e-01, 1.0400e-01,
        1.0871e-08, 1.6025e-08, 1.9226e-08, 7.3477e-02, 1.4199e-08, 2.1561e-01,
        9.8170e-02, 7.0721e-02, 1.2036e-01, 2.6073e-08, 8.0775e-02, 2.9928e-02,
        5.8384e-02, 1.0631e-08, 1.3387e-02, 2.0083e-08, 1.7960e-02, 8.7379e-02,
        3.7945e-02, 5.3029e-02, 2.2144e-02, 8.6033e-02, 2.3579e-08, 9.9923e-02,
        2.3620e-02, 8.3090e-03, 4.2566e-02, 2.5672e-01, 1.4645e-01, 6.1894e-02,
        3.8680e-02, 4.8964e-02, 1.1719e-08, 2.6073e-08, 8.0524e-02, 1.2554e-01,
        5.6080e-02, 1.4199e-08, 6.1437e-03, 2.0888e-08, 8.5458e-02, 1.2411e-08,
        1.9083e-02, 2.0888e-08, 4.3258e-02, 1.3917e-08, 1.3194e-01, 2.6160e-01,
        1.5459e-01, 1.0429e-01, 2.0888e-08, 1.1003e-01, 9.4796e-02, 1.0465e-01,
        1.4199e-08, 1.9656e-02, 9.3153e-02, 1.3338e-08, 1.2874e-01, 4.5118e-02,
        6.1328e-02, 2.0888e-08, 4.0068e-02, 7.6284e-02, 3.9431e-02, 1.7849e-02,
        2.6694e-08, 1.4199e-08, 3.8712e-02, 6.9693e-02, 7.7611e-02, 9.1751e-09,
        6.9751e-02, 1.2959e-02, 3.2922e-02, 1.6006e-01, 2.1334e-02, 5.3699e-02,
        1.4199e-08, 3.3363e-02, 1.0984e-01, 1.2433e-01, 1.1520e-01, 1.9226e-08,
        8.7628e-02, 1.4199e-08, 9.6949e-02, 1.0375e-01, 5.3840e-03, 8.5186e-02,
        9.7035e-02, 5.5430e-02, 1.3626e-01, 1.2440e-01, 7.3556e-02, 2.0254e-02,
        2.8644e-02, 2.0888e-08, 1.0442e-01, 2.7104e-02, 1.4199e-08, 1.4199e-08,
        6.1815e-03, 4.9222e-02, 1.3457e-01, 7.0379e-02, 2.3579e-08, 1.6206e-02,
        3.0334e-02, 1.6527e-01, 2.1537e-01, 1.1146e-01, 5.9749e-02, 1.4199e-08,
        1.4269e-01, 1.6744e-01, 9.6442e-02, 8.2281e-02, 8.9821e-02, 1.5562e-02,
        4.0617e-02, 1.4199e-08, 1.3917e-08, 4.1671e-02], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([7.5583e-08, 2.1644e-07, 8.1597e-02, 7.1899e-02, 1.5355e-07, 1.0046e-07,
        7.5583e-08, 1.9599e-02, 4.5222e-02, 3.0082e-02, 8.9756e-08, 1.5638e-07,
        7.2026e-02, 6.9972e-08, 3.8474e-07, 2.2887e-07, 2.2189e-07, 5.4488e-02,
        3.7337e-02, 4.9532e-08, 2.2311e-02, 3.5606e-07, 5.7881e-02, 1.8418e-02,
        6.5458e-02, 1.7707e-07, 5.3281e-02, 2.2189e-07, 5.6420e-02, 4.8235e-07,
        1.0046e-07, 1.5638e-07, 7.5295e-02, 4.6831e-02, 1.6574e-07, 1.8282e-07,
        1.6744e-07, 2.2189e-07, 3.7729e-02, 1.5638e-07, 1.1975e-07, 5.3069e-08,
        1.6574e-07, 4.8927e-08, 1.5142e-07, 9.0358e-08, 5.5967e-02, 4.7316e-08,
        6.4142e-02, 6.3131e-02, 1.0896e-07, 1.0722e-01, 5.6152e-02, 6.4706e-02,
        4.8235e-07, 1.2209e-01, 8.0945e-08, 2.2189e-07, 1.0895e-02, 9.3196e-08,
        7.5583e-08, 2.2887e-07, 5.3108e-02, 5.5629e-02], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([9.2981e-02, 1.1645e-01, 7.3736e-02, 7.5467e-02, 6.9328e-07, 2.3128e-07,
        8.6261e-02, 6.7010e-02, 1.3874e-07, 2.1011e-07, 6.9328e-07, 3.8236e-07,
        1.2362e-07, 6.7374e-07, 5.3250e-02, 3.8236e-07, 2.3128e-07, 5.5549e-02,
        2.7260e-07, 6.4597e-07, 6.2007e-02, 2.1011e-07, 3.8578e-02, 1.1377e-01,
        5.4977e-02, 5.3795e-07, 6.1282e-02, 5.0109e-07, 4.1936e-07, 3.8236e-07,
        8.7183e-07, 4.8536e-02, 4.1936e-07, 8.3549e-02, 1.0995e-01, 2.1011e-07,
        8.7369e-02, 5.8259e-02, 7.0817e-02, 6.2879e-08, 1.2362e-07, 6.4762e-02,
        2.1011e-07, 4.7023e-02, 3.8236e-07, 1.4360e-07, 3.8236e-07, 6.2834e-02,
        6.2879e-08, 2.1586e-02, 2.6519e-02, 7.3691e-07, 9.0874e-02, 4.3444e-02,
        2.3128e-07, 4.1936e-07, 6.0803e-02, 1.0293e-01, 2.1011e-07, 5.6881e-07,
        2.7657e-02, 7.4345e-02, 6.6446e-02, 2.6321e-07], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([9.6160e-02, 2.5185e-02, 1.7353e-02, 7.1917e-03, 8.0473e-02, 2.8669e-02,
        2.0716e-02, 7.5174e-02, 1.4667e-02, 4.4804e-02, 8.6219e-03, 7.9910e-02,
        6.5097e-02, 3.3116e-02, 9.5609e-03, 9.2582e-03, 5.3701e-08, 9.3457e-03,
        6.6005e-02, 7.4894e-09, 2.9370e-02, 2.1939e-02, 4.2636e-02, 1.1172e-02,
        5.8456e-02, 6.5684e-03, 4.4047e-08, 1.4144e-02, 1.0895e-02, 8.3704e-03,
        1.7317e-02, 1.3493e-02, 2.0747e-02, 1.4629e-01, 7.5343e-08, 3.1758e-02,
        3.1065e-02, 4.3241e-02, 2.1702e-08, 3.7744e-02, 2.3784e-08, 4.4267e-03,
        4.6779e-02, 2.8225e-02, 8.5951e-03, 3.6432e-08, 1.5841e-08, 6.5945e-02,
        5.2674e-02, 1.6411e-02, 1.7672e-02, 8.7737e-02, 1.1096e-01, 9.7661e-03,
        5.8082e-02, 7.2654e-02, 3.3142e-08, 1.3232e-02, 4.0377e-08, 2.2311e-02,
        3.4179e-08, 3.9337e-02, 8.8365e-02, 2.9170e-08, 2.0619e-02, 8.3303e-02,
        3.7412e-02, 1.8597e-02, 2.1236e-02, 2.0104e-02, 8.2473e-02, 1.2386e-02,
        4.0130e-08, 5.2119e-08, 2.8168e-02, 3.3315e-02, 1.1570e-07, 3.7424e-08,
        4.9553e-08, 2.9041e-02, 3.4316e-02, 5.3701e-08, 3.5984e-02, 3.4071e-08,
        1.7477e-08, 4.4274e-02, 4.7940e-03, 7.4475e-02, 1.2350e-01, 7.4166e-08,
        4.3319e-08, 4.7979e-02, 1.4227e-02, 2.4704e-02, 1.8064e-01, 1.7728e-02,
        1.8717e-02, 6.2392e-02, 4.6027e-08, 1.3288e-02, 6.9574e-08, 8.1050e-02,
        1.1421e-02, 2.0040e-02, 2.7579e-02, 1.3685e-02, 1.7547e-02, 3.0050e-02,
        2.4247e-02, 1.0190e-02, 6.8106e-02, 7.2692e-02, 3.2928e-02, 5.7997e-03,
        1.0270e-07, 5.0277e-08, 1.1960e-07, 7.3640e-03, 1.9976e-02, 5.8967e-02,
        1.6962e-02, 3.8436e-08, 2.8057e-02, 1.0524e-01, 1.5372e-08, 8.4549e-03,
        4.7512e-08, 3.8937e-02, 1.3346e-01, 5.0738e-02, 7.5072e-02, 1.7221e-02,
        1.1960e-07, 4.3528e-02, 1.5452e-01, 3.0304e-02, 1.0503e-07, 2.4383e-02,
        1.5639e-02, 1.9746e-02, 6.1569e-02, 7.5825e-04, 8.5145e-03, 3.2413e-02,
        1.4789e-02, 4.4564e-02, 6.3675e-03, 4.1117e-02, 6.8293e-03, 1.5538e-01,
        1.8557e-02, 1.0239e-01, 1.5204e-02, 6.8982e-03, 3.4166e-02, 3.7550e-02,
        1.2193e-02, 4.3086e-02, 5.5744e-02, 1.8998e-02, 1.2716e-02, 2.9732e-08,
        1.5189e-02, 3.2414e-02, 1.2038e-07, 3.4194e-08, 3.3599e-02, 4.7967e-08,
        2.9590e-02, 6.7620e-02, 6.4890e-08, 4.9467e-08, 1.1689e-02, 2.0295e-02,
        1.9833e-02, 2.3278e-08, 1.0328e-02, 2.2476e-08, 5.4906e-02, 5.2598e-02,
        1.0643e-01, 1.0749e-02, 4.5810e-02, 5.4895e-02, 2.1064e-02, 2.2473e-08,
        5.7134e-08, 1.0052e-01, 6.6928e-02, 4.7286e-08, 1.5117e-02, 4.5444e-02,
        2.2632e-02, 4.9467e-08, 1.9189e-02, 3.2272e-02, 6.1691e-02, 1.0657e-02,
        2.3123e-08, 1.9403e-08, 4.4865e-02, 1.0660e-02, 1.8353e-02, 2.9395e-08,
        5.3732e-02, 4.3526e-02, 4.7178e-02, 1.0864e-01, 3.7639e-02, 5.1613e-02,
        7.6159e-03, 3.3128e-02, 2.9533e-03, 5.3164e-08, 2.5125e-02, 1.7193e-01,
        1.4447e-02, 4.3592e-08, 3.7111e-02, 1.4923e-02, 3.2607e-02, 1.0477e-02,
        5.5230e-08, 7.2517e-02, 3.3391e-08, 1.4015e-02, 5.0087e-08, 5.7118e-08,
        2.1288e-08, 8.2598e-02, 4.1219e-02, 4.2418e-02, 4.7512e-08, 8.7079e-02,
        1.5013e-02, 3.7531e-02, 2.0566e-08, 4.3925e-03, 1.5714e-01, 6.5060e-08,
        1.2371e-02, 8.0818e-02, 2.6932e-02, 1.8989e-02, 6.0604e-02, 3.7620e-02,
        1.4528e-02, 1.8105e-02, 1.2893e-02, 3.3207e-02, 4.1504e-02, 4.9696e-02,
        3.4274e-02, 2.8032e-08, 2.0840e-03, 4.9684e-08], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([5.0850e-02, 1.1839e-01, 4.3666e-07, 1.0790e-01, 3.1853e-07, 1.0949e-01,
        2.5482e-07, 7.9233e-03, 1.1464e-01, 1.0678e-01, 1.6924e-01, 2.7265e-02,
        3.7508e-02, 1.1672e-01, 2.6497e-02, 4.5718e-07, 4.8267e-02, 1.0782e-02,
        1.7062e-02, 1.6957e-01, 3.1455e-07, 9.7159e-03, 9.4408e-02, 8.2185e-03,
        4.0768e-02, 2.7182e-02, 1.1282e-01, 4.2833e-02, 8.8272e-03, 1.3251e-02,
        1.8891e-07, 2.5423e-07, 2.4083e-07, 9.1686e-03, 1.3901e-02, 5.1211e-02,
        4.8011e-07, 1.6460e-07, 1.2325e-01, 2.9606e-02, 1.2817e-01, 1.0012e-01,
        5.9243e-03, 3.1455e-07, 1.5647e-07, 2.3372e-07, 3.4761e-07, 4.8010e-07,
        1.0907e-01, 6.6456e-07, 1.0542e-01, 1.7554e-07, 1.8884e-02, 1.0461e-01,
        5.2759e-08, 1.4589e-02, 3.8894e-07, 1.9822e-07, 5.2974e-02, 4.9948e-03,
        6.3626e-07, 2.1131e-01, 1.1350e-01, 3.2807e-02], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([4.2428e-02, 9.8063e-02, 1.2093e-01, 9.0106e-02, 4.8922e-02, 6.1337e-07,
        1.0077e-01, 3.6145e-07, 7.2277e-02, 4.2091e-07, 7.7056e-03, 8.4571e-03,
        4.6910e-07, 6.3351e-07, 3.4141e-07, 3.3852e-07, 9.1964e-02, 5.2976e-07,
        4.7625e-02, 4.5532e-07, 6.3457e-07, 5.9240e-07, 9.4249e-07, 1.4509e-02,
        1.7090e-02, 1.1260e-06, 5.8104e-02, 1.0760e-01, 1.1751e-01, 8.5788e-03,
        1.5267e-06, 9.6679e-02, 5.9240e-07, 1.1406e-01, 4.5977e-02, 4.2028e-07,
        1.0008e-01, 8.3223e-03, 4.5158e-02, 9.4110e-02, 6.1003e-07, 1.0440e-01,
        3.9429e-07, 1.3825e-01, 4.8364e-02, 8.9583e-02, 1.0240e-01, 1.5267e-06,
        8.9455e-03, 6.3351e-07, 4.7362e-02, 9.5914e-02, 9.9899e-07, 1.0148e-06,
        5.2291e-03, 4.5024e-02, 4.8151e-02, 6.2218e-07, 9.3970e-02, 4.4092e-02,
        5.7526e-03, 1.1267e-01, 1.0403e-06, 9.5197e-02], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([2.4272e-02, 1.8548e-02, 9.4737e-03, 2.9746e-08, 5.4721e-02, 6.6093e-02,
        8.9006e-08, 8.0529e-03, 1.3798e-02, 1.8124e-02, 2.6343e-02, 4.2969e-08,
        1.0584e-01, 2.7674e-02, 1.8271e-02, 7.7617e-03, 8.1086e-02, 1.0052e-02,
        8.2179e-02, 1.5370e-01, 4.7241e-08, 2.1662e-02, 2.3701e-08, 1.0518e-02,
        2.9981e-02, 4.0265e-02, 1.0025e-02, 8.4110e-03, 4.0344e-02, 2.0382e-02,
        1.0768e-02, 1.4222e-02, 3.3715e-02, 7.8018e-03, 9.8975e-03, 8.2461e-02,
        6.3097e-08, 6.4655e-03, 7.9998e-03, 1.5396e-01, 9.8555e-03, 6.1267e-03,
        2.1832e-02, 6.7816e-02, 9.1790e-03, 3.0161e-03, 1.6680e-01, 4.4593e-02,
        2.9186e-02, 1.3866e-02, 1.2883e-02, 6.1108e-02, 6.9169e-03, 6.8340e-03,
        9.7721e-03, 1.2801e-02, 9.9591e-02, 1.7466e-02, 1.5230e-02, 2.7731e-02,
        3.9673e-08, 7.4695e-02, 6.3742e-08, 6.2502e-02, 9.2757e-03, 4.9532e-02,
        1.4572e-02, 1.8411e-02, 1.2735e-02, 1.5343e-02, 1.6052e-01, 1.5065e-02,
        5.2342e-08, 3.8985e-08, 3.9974e-06, 2.8940e-02, 4.4624e-08, 7.8911e-03,
        7.6791e-03, 1.8418e-02, 1.1835e-01, 1.5965e-02, 7.1962e-02, 4.9035e-08,
        5.9336e-03, 6.3901e-03, 6.2611e-03, 1.6785e-01, 1.0216e-02, 7.1152e-02,
        2.6050e-02, 1.3746e-01, 1.6690e-02, 5.8297e-02, 3.3862e-02, 1.4460e-02,
        1.8169e-02, 1.3940e-01, 1.3764e-07, 1.1092e-02, 3.7957e-02, 2.7769e-02,
        1.0595e-02, 1.2057e-02, 8.1152e-03, 1.0090e-02, 1.4467e-02, 2.3463e-02,
        8.2552e-03, 1.1472e-02, 5.7039e-03, 5.1173e-02, 1.1601e-02, 5.0464e-03,
        1.1547e-04, 7.2694e-08, 1.3740e-07, 3.9244e-02, 5.5797e-08, 3.6581e-03,
        4.7992e-02, 3.1465e-03, 2.1441e-01, 6.7631e-03, 4.7842e-02, 1.9636e-02,
        5.2596e-02, 4.7641e-02, 1.5050e-02, 6.4404e-02, 4.4159e-03, 1.3659e-02,
        2.0657e-01, 4.9744e-08, 5.8242e-03, 1.1768e-02, 8.8065e-02, 1.1083e-02,
        9.3226e-03, 7.8127e-02, 1.7687e-02, 3.9375e-08, 7.1406e-03, 1.1323e-02,
        7.0990e-03, 2.7424e-02, 3.2124e-02, 1.2489e-01, 6.0699e-02, 3.1950e-02,
        1.2337e-02, 1.2317e-02, 1.3196e-02, 6.4055e-03, 3.1664e-02, 7.9281e-03,
        7.9258e-03, 4.8555e-02, 4.3287e-08, 1.6155e-02, 1.9266e-02, 7.5707e-03,
        9.8306e-03, 6.8078e-02, 2.8246e-08, 6.6061e-08, 2.8560e-02, 3.2629e-02,
        1.1400e-01, 6.5181e-08, 2.5523e-02, 1.4348e-01, 7.2063e-02, 3.0304e-03,
        1.4646e-02, 7.8995e-02, 1.1375e-02, 3.4917e-08, 4.1475e-02, 1.7795e-02,
        5.3377e-02, 1.0698e-02, 1.2267e-01, 2.9277e-02, 2.6498e-02, 1.7782e-02,
        7.6799e-02, 4.7961e-02, 3.7110e-02, 4.2163e-08, 1.2987e-02, 1.1666e-01,
        4.2877e-08, 9.2804e-02, 1.1897e-02, 1.0007e-02, 8.6829e-08, 7.9791e-02,
        1.2721e-07, 1.3028e-01, 1.5210e-02, 7.1753e-03, 4.8602e-02, 2.4103e-08,
        7.8185e-03, 4.3633e-02, 3.7461e-02, 6.4741e-03, 6.5815e-02, 3.8893e-02,
        1.2974e-02, 1.2483e-01, 9.5867e-03, 4.6812e-03, 1.2999e-02, 1.2107e-02,
        2.1664e-02, 1.2832e-01, 4.9394e-02, 1.4883e-02, 3.6906e-02, 8.0929e-03,
        5.7261e-02, 1.0495e-02, 1.5155e-02, 1.3759e-02, 9.8549e-08, 3.7625e-02,
        1.2512e-07, 1.4679e-02, 3.8519e-02, 3.2618e-03, 1.3519e-01, 8.8862e-03,
        5.5613e-08, 1.2412e-01, 4.2311e-03, 1.0059e-02, 1.2085e-02, 8.6968e-08,
        1.2119e-02, 1.2703e-02, 2.5659e-02, 1.9610e-02, 5.2321e-02, 3.2818e-02,
        9.7451e-03, 1.7154e-02, 7.6765e-03, 6.5763e-03, 3.9154e-02, 3.7503e-02,
        1.5154e-02, 1.3105e-01, 8.3536e-02, 1.4811e-02], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([3.6801e-07, 5.4298e-02, 4.1643e-08, 5.0705e-02, 2.1213e-01, 6.7402e-04,
        1.5562e-01, 3.2886e-02, 6.0655e-02, 1.8258e-07, 1.8992e-07, 2.2654e-07,
        5.9774e-02, 1.4621e-07, 3.6850e-02, 5.9311e-02, 4.5515e-07, 7.4831e-02,
        1.5622e-07, 1.7110e-02, 7.9153e-02, 2.9198e-02, 1.4099e-01, 8.2207e-02,
        5.0502e-07, 2.9520e-07, 2.3726e-07, 1.8258e-07, 2.2654e-07, 2.2635e-01,
        6.0167e-02, 4.0011e-02, 7.5402e-02, 6.6426e-02, 2.4614e-07, 1.2801e-07,
        7.4778e-02, 1.4678e-01, 1.5098e-01, 5.8504e-08, 3.0514e-07, 1.7775e-01,
        3.2938e-07, 7.2677e-02, 9.8718e-03, 1.3090e-07, 7.5097e-08, 1.4614e-07,
        5.8504e-08, 1.8471e-07, 2.4945e-07, 9.7458e-08, 6.3981e-02, 7.9280e-03,
        1.8080e-07, 2.9811e-07, 1.9923e-02, 5.2801e-02, 2.1147e-07, 1.4614e-07,
        3.6086e-07, 3.4734e-07, 5.3990e-07, 4.6074e-02, 1.0372e-02, 1.1853e-01,
        2.6153e-02, 7.2811e-02, 1.6180e-01, 1.9394e-01, 8.2265e-02, 2.7194e-07,
        6.4584e-02, 2.4943e-07, 5.7651e-02, 2.4814e-02, 1.7110e-07, 4.0993e-02,
        4.5417e-02, 1.6421e-07, 3.4734e-07, 2.3726e-07, 1.8859e-02, 1.1681e-07,
        6.2526e-02, 6.1066e-02, 6.0952e-02, 1.3203e-01, 1.2080e-01, 7.2984e-02,
        5.3601e-02, 1.5123e-01, 3.1692e-02, 1.7536e-01, 1.3532e-07, 1.1013e-01,
        1.1455e-07, 5.9574e-02, 1.2543e-07, 3.3734e-02, 8.3771e-03, 5.3618e-02,
        3.0159e-07, 1.8610e-01, 4.0428e-02, 1.2093e-07, 5.0228e-02, 1.8471e-07,
        6.0057e-02, 3.3728e-07, 3.6801e-07, 2.1786e-01, 7.1609e-02, 4.2210e-02,
        3.6801e-07, 2.0928e-07, 1.8970e-02, 4.8145e-02, 1.2976e-01, 1.8471e-07,
        2.0895e-02, 4.3585e-02, 6.7561e-02, 1.8471e-07, 1.2110e-01, 1.1266e-07,
        3.4734e-07, 5.3990e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([8.5476e-02, 3.8752e-02, 9.1929e-07, 4.3424e-07, 1.0604e-06, 1.0187e-06,
        9.6009e-02, 3.3279e-07, 8.2119e-07, 2.1769e-07, 3.1147e-06, 3.0815e-02,
        6.4122e-07, 2.7744e-02, 4.1841e-02, 1.4471e-06, 1.0604e-06, 2.5473e-06,
        1.7026e-06, 3.3095e-02, 1.2617e-06, 1.1127e-06, 1.9653e-06, 1.8307e-06,
        3.6871e-02, 2.9603e-06, 1.2995e-06, 3.7540e-02, 7.7416e-07, 4.1099e-02,
        1.8307e-06, 2.2458e-06, 2.2109e-02, 2.6601e-02, 3.6838e-02, 1.1549e-06,
        2.5423e-06, 3.9865e-02, 2.9548e-02, 1.3059e-06, 1.0187e-06, 1.6900e-06,
        3.3058e-02, 6.1093e-07, 9.5317e-02, 4.3357e-02, 1.2796e-06, 3.8352e-02,
        1.0745e-06, 2.1842e-02, 1.1989e-06, 2.9374e-02, 3.4243e-02, 2.8551e-02,
        3.2841e-02, 8.0484e-07, 6.8718e-07, 9.2008e-07, 1.2369e-06, 2.4237e-06,
        9.1917e-02, 2.1102e-06, 3.0971e-06, 8.2119e-07, 1.6900e-06, 1.2576e-06,
        4.2224e-02, 3.8546e-02, 7.3255e-07, 1.2576e-06, 1.6900e-06, 9.0219e-07,
        4.1775e-02, 1.0427e-06, 1.2780e-06, 1.7026e-06, 2.0581e-06, 3.6490e-02,
        4.3497e-02, 1.2576e-06, 3.6648e-07, 2.9426e-02, 3.4126e-02, 4.0287e-02,
        2.0265e-06, 1.0743e-06, 1.4471e-06, 3.2077e-02, 3.5705e-02, 1.0337e-06,
        1.0187e-06, 4.2003e-02, 2.5164e-02, 2.5009e-06, 1.9525e-06, 1.0031e-01,
        1.1319e-01, 2.2610e-06, 1.8942e-06, 1.0187e-06, 2.4581e-02, 3.3279e-07,
        2.3940e-02, 8.0484e-07, 1.1789e-02, 1.0024e-06, 3.2916e-02, 4.2498e-02,
        9.1929e-07, 2.3701e-02, 6.8162e-07, 4.4009e-02, 4.5347e-02, 7.3480e-02,
        9.1820e-07, 3.3809e-02, 4.3994e-02, 8.0484e-07, 2.1102e-06, 1.0604e-06,
        3.8632e-02, 2.8552e-02, 1.4471e-06, 3.6765e-06, 2.5738e-02, 1.1296e-06,
        1.1127e-06, 3.3889e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([3.6812e-08, 3.8053e-02, 3.3126e-02, 1.6545e-01, 4.5685e-02, 4.5927e-02,
        6.1109e-02, 4.2049e-03, 1.5846e-02, 2.2888e-02, 3.6818e-02, 1.5475e-01,
        1.7402e-07, 6.3497e-02, 6.6931e-02, 1.5602e-02, 3.3980e-02, 6.9356e-08,
        4.4612e-02, 1.1543e-07, 5.9232e-02, 1.8049e-02, 4.0072e-02, 2.2787e-02,
        7.6510e-02, 5.6401e-02, 4.3920e-02, 7.9629e-02, 6.5638e-02, 1.9161e-07,
        4.1386e-02, 3.9613e-08, 3.9572e-02, 3.5131e-02, 1.5918e-07, 2.9097e-02,
        3.1122e-02, 3.1490e-02, 4.0302e-02, 1.0278e-07, 9.7792e-08, 3.6304e-02,
        2.9281e-02, 1.3709e-07, 7.9979e-02, 5.2473e-02, 9.7792e-08, 3.7797e-02,
        1.5377e-07, 2.3145e-02, 6.4813e-02, 5.1452e-02, 1.2661e-02, 7.7180e-03,
        4.7497e-02, 4.1036e-02, 5.4859e-02, 3.5543e-02, 5.9818e-08, 4.4995e-02,
        4.7722e-02, 5.5925e-02, 9.7055e-03, 3.3887e-02, 4.5723e-02, 3.2051e-02,
        5.1746e-02, 7.2244e-02, 6.2004e-02, 5.1229e-02, 1.1362e-07, 7.1699e-02,
        4.6054e-02, 5.0230e-02, 2.2842e-07, 2.9283e-02, 7.7724e-02, 6.0024e-03,
        9.7792e-08, 6.9356e-08, 5.1338e-02, 1.4822e-02, 4.5312e-08, 4.9031e-02,
        5.0426e-02, 9.4677e-08, 4.6877e-08, 4.9085e-02, 4.6649e-02, 5.3403e-02,
        2.2264e-02, 6.8535e-02, 5.1521e-02, 4.0033e-02, 2.2115e-07, 3.4556e-02,
        4.3810e-02, 2.6385e-02, 4.9057e-02, 5.6215e-02, 3.5673e-02, 8.4029e-02,
        4.6877e-08, 5.3125e-02, 3.0569e-02, 1.7485e-02, 6.3369e-02, 5.7868e-08,
        6.1055e-02, 9.7792e-08, 3.3443e-02, 3.7314e-02, 1.2397e-07, 5.5746e-08,
        5.0839e-02, 1.7177e-07, 4.1802e-02, 3.8680e-02, 3.6372e-02, 2.3215e-02,
        4.2539e-02, 4.1249e-02, 7.5470e-02, 4.3859e-02, 9.1056e-02, 1.1486e-07,
        6.2262e-02, 1.9775e-02, 5.5979e-02, 1.4323e-07, 8.1815e-02, 5.7574e-02,
        1.5377e-07, 1.0762e-07, 1.6477e-07, 4.7688e-08, 1.3822e-02, 2.8632e-02,
        1.3621e-07, 3.2219e-02, 9.0612e-02, 6.0410e-02, 3.5920e-02, 2.5057e-07,
        5.6086e-02, 5.0819e-02, 5.4476e-02, 1.1839e-07, 6.7170e-08, 1.0278e-07,
        5.3290e-02, 3.5077e-02, 4.3684e-03, 5.4670e-02, 6.6628e-02, 5.6629e-02,
        7.6322e-08, 4.1120e-02, 1.5918e-07, 5.3144e-02, 4.3652e-02, 8.2252e-08,
        1.6007e-07, 6.0696e-02, 4.2788e-02, 7.0331e-02, 1.8627e-01, 4.4614e-02,
        4.5329e-02, 2.1032e-02, 4.3017e-02, 7.1958e-02, 3.6488e-02, 2.7001e-02,
        1.1674e-07, 3.1711e-02, 1.1148e-07, 1.1279e-02, 5.4918e-02, 5.2212e-02,
        7.8778e-02, 4.5154e-08, 3.0820e-02, 6.2421e-02, 8.0646e-03, 3.2301e-02,
        2.1827e-07, 5.2014e-02, 5.8988e-02, 6.8645e-02, 2.3761e-02, 6.9647e-08,
        2.5445e-02, 2.0925e-02, 4.3742e-02, 2.7654e-02, 5.4326e-08, 2.1835e-02,
        8.6881e-02, 4.9422e-02, 1.1543e-07, 7.3639e-08, 9.7552e-08, 7.4502e-02,
        3.3632e-02, 4.4000e-02, 5.5877e-02, 4.7707e-02, 5.6086e-02, 2.1963e-02,
        8.4609e-08, 5.5748e-02, 1.3621e-07, 4.2156e-02, 3.6171e-02, 1.3943e-07,
        2.4430e-03, 3.7054e-02, 2.2870e-02, 6.7170e-08, 1.1927e-07, 6.0933e-08,
        3.2335e-02, 3.9613e-08, 7.1656e-02, 3.7597e-02, 5.2041e-02, 3.3588e-02,
        5.2033e-02, 5.8785e-02, 4.7490e-02, 5.9987e-02, 6.0117e-02, 9.7792e-08,
        5.0972e-02, 7.0019e-03, 3.2310e-02, 6.3021e-08, 1.7786e-08, 1.4844e-02,
        1.4124e-07, 4.2853e-02, 4.6547e-02, 5.7746e-02, 4.0713e-02, 3.9085e-02,
        3.2197e-08, 1.5918e-07, 5.2644e-08, 6.6962e-08, 1.8628e-02, 6.3132e-03,
        2.9647e-08, 3.6657e-02, 1.6387e-01, 1.4323e-07, 3.0247e-08, 7.8023e-02,
        4.7406e-02, 6.0095e-02, 1.1314e-07, 6.2934e-02, 1.0278e-07, 2.9648e-08,
        1.9345e-07, 1.2287e-02, 3.2005e-02, 4.7371e-02, 1.2990e-02, 1.7419e-02,
        1.1336e-01, 7.0866e-02, 1.7402e-07, 2.6294e-02, 3.2527e-02, 7.7840e-02,
        1.0289e-01, 1.5128e-01, 7.8262e-02, 1.4966e-01, 9.7852e-03, 2.0506e-03,
        2.8014e-08, 5.5884e-02, 3.7905e-02, 2.5110e-02, 1.1267e-02, 3.4294e-02,
        2.5700e-02, 1.5377e-07, 3.0438e-02, 5.2381e-03, 2.5057e-07, 9.5175e-03,
        1.3564e-07, 4.5781e-02, 6.1161e-02, 5.5986e-02, 2.9917e-02, 4.8901e-02,
        4.1066e-02, 7.6580e-02, 4.4530e-08, 4.7042e-02, 1.1927e-07, 4.5376e-08,
        3.5812e-02, 1.5533e-01, 3.7482e-02, 1.5377e-07, 4.2851e-02, 5.1185e-02,
        9.7792e-08, 4.6574e-02, 4.4723e-02, 4.7338e-02, 1.0483e-07, 2.1440e-02,
        7.1936e-02, 1.5415e-07, 3.6812e-08, 5.3011e-02, 8.1056e-02, 3.8970e-02,
        4.8238e-02, 6.4380e-02, 1.1971e-07, 3.9366e-02, 2.5485e-07, 7.7990e-02,
        3.0189e-02, 6.0767e-02, 2.5485e-07, 6.0251e-08, 8.4609e-08, 3.1920e-02,
        5.1323e-02, 1.1625e-02, 3.5306e-02, 1.1719e-07, 3.0725e-02, 5.2644e-08,
        2.8576e-02, 1.6893e-01, 1.1913e-07, 7.0848e-02, 1.0712e-07, 5.1409e-02,
        1.1971e-07, 6.9356e-08, 6.0125e-03, 1.1248e-07, 1.6357e-02, 4.7778e-02,
        3.2210e-02, 3.2113e-02, 7.6695e-08, 5.8322e-02, 1.0285e-07, 4.7662e-02,
        2.2424e-02, 1.0568e-02, 2.8624e-02, 4.4238e-02, 4.5144e-02, 3.9415e-02,
        4.9855e-02, 1.8148e-02, 2.7657e-02, 4.0648e-08, 5.0776e-02, 5.2955e-02,
        8.3376e-02, 1.5509e-02, 8.6158e-02, 6.9841e-02, 4.0401e-02, 5.9355e-02,
        4.7032e-02, 4.1835e-02, 3.1782e-02, 4.3854e-02, 2.4087e-02, 4.9631e-02,
        3.8652e-02, 6.0444e-02, 9.7792e-08, 5.4359e-02, 1.3621e-07, 2.8649e-07,
        3.6682e-02, 1.3621e-07, 4.1770e-02, 4.8048e-02, 3.5831e-02, 3.1993e-02,
        1.7969e-02, 8.2418e-03, 4.9865e-02, 2.4929e-02, 4.0686e-02, 6.5381e-03,
        9.1091e-03, 4.7910e-02, 2.2368e-02, 3.4716e-02, 4.4665e-02, 5.0016e-02,
        6.0106e-02, 1.9797e-02, 4.2860e-02, 1.2561e-07, 5.4875e-02, 5.1972e-02,
        1.1597e-01, 1.4763e-07, 8.0312e-02, 4.8763e-02, 7.6710e-02, 2.5548e-02,
        2.3463e-02, 2.3084e-02, 5.1713e-02, 4.4531e-08, 5.9938e-02, 3.6475e-02,
        7.6810e-02, 1.3621e-07, 8.9971e-02, 4.9826e-02, 3.9168e-02, 4.4702e-02,
        3.7375e-02, 9.4853e-08, 6.5441e-02, 4.7688e-08, 1.8180e-01, 1.2686e-02,
        3.1920e-02, 6.9356e-08, 4.8233e-02, 8.5797e-02, 5.1704e-02, 2.9961e-02,
        1.0676e-01, 1.4323e-07, 2.1827e-07, 3.9360e-02, 6.7170e-08, 5.3035e-02,
        1.4323e-07, 1.7318e-07, 1.5377e-07, 5.2644e-08, 6.9356e-08, 5.1495e-02,
        1.4821e-02, 7.1682e-02, 8.2961e-03, 9.8672e-03, 3.8812e-02, 4.6877e-08,
        2.3537e-02, 9.8632e-03, 6.1969e-02, 4.4029e-02, 6.0251e-02, 6.6962e-08,
        3.3287e-08, 1.0961e-01, 5.2350e-02, 6.7170e-08, 6.7982e-02, 4.2656e-08,
        6.3345e-08, 3.2490e-02, 6.4849e-02, 6.7170e-08, 3.1354e-02, 7.6322e-08,
        2.5057e-07, 2.4959e-02, 1.0788e-07, 3.1799e-08, 9.7792e-08, 5.6533e-02,
        4.1137e-02, 6.7170e-08, 2.5057e-07, 6.7130e-08, 4.4907e-02, 1.2658e-02,
        4.6043e-02, 2.7122e-02, 5.8702e-02, 4.9322e-02, 1.4763e-07, 9.8204e-08,
        2.9648e-08, 9.0886e-03, 5.7868e-08, 1.1927e-07, 1.1971e-07, 4.5358e-08,
        2.8459e-02, 5.6987e-02, 2.9648e-08, 2.7823e-02, 9.7792e-08, 1.4323e-07,
        1.5918e-07, 2.0320e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([5.9683e-08, 3.2341e-02, 4.2874e-02, 6.2155e-03, 5.5237e-02, 5.2265e-03,
        6.3203e-02, 3.6654e-02, 9.7550e-02, 5.8799e-02, 6.8714e-02, 4.8709e-02,
        9.0846e-08, 9.0550e-02, 5.0438e-02, 7.3792e-02, 1.0525e-01, 1.4128e-07,
        5.5387e-02, 4.3196e-07, 2.4976e-02, 2.7942e-02, 5.7768e-02, 3.9619e-02,
        4.1472e-02, 3.8371e-02, 1.8880e-07, 6.3626e-03, 5.3225e-02, 5.4572e-02,
        4.9897e-02, 1.5332e-07, 1.8536e-02, 5.0958e-02, 5.4307e-08, 9.1399e-03,
        4.7398e-02, 3.4218e-02, 3.9986e-02, 7.9457e-08, 1.2264e-07, 4.8361e-02,
        2.7999e-02, 4.2392e-07, 4.8140e-02, 1.6705e-02, 2.4088e-07, 5.7248e-02,
        3.2004e-07, 2.9706e-02, 4.9952e-02, 5.0763e-02, 4.2166e-08, 5.5719e-02,
        2.1640e-02, 7.1245e-02, 3.7066e-02, 8.5369e-02, 2.1982e-07, 4.3472e-02,
        1.8990e-02, 4.8005e-02, 1.8320e-02, 6.0959e-02, 2.7563e-02, 5.3115e-02,
        9.4621e-08, 3.2330e-02, 2.2128e-02, 4.5651e-02, 7.9457e-08, 3.3503e-02,
        4.5082e-02, 4.7062e-02, 4.1830e-02, 6.1235e-02, 4.9798e-02, 2.1869e-08,
        4.2240e-07, 1.7468e-07, 3.5079e-03, 3.4001e-02, 5.4307e-08, 1.1101e-07,
        1.1555e-01, 1.3258e-07, 3.2004e-07, 4.2059e-02, 6.0142e-03, 8.2678e-02,
        3.1228e-02, 5.9517e-03, 3.9023e-02, 4.6170e-02, 5.9683e-08, 5.5267e-02,
        7.9001e-02, 3.4684e-02, 5.2995e-02, 3.4620e-02, 3.1222e-02, 4.7123e-03,
        3.2004e-07, 3.5474e-02, 1.2707e-02, 2.3565e-02, 7.7199e-02, 3.3009e-07,
        6.5108e-02, 2.4088e-07, 4.5259e-02, 9.6131e-02, 3.3289e-07, 2.4088e-07,
        2.9776e-02, 3.2004e-07, 5.7844e-02, 3.5628e-02, 6.2747e-02, 2.9515e-02,
        7.1475e-02, 5.2270e-02, 3.1258e-02, 4.8721e-02, 3.2558e-03, 5.9683e-08,
        3.2554e-02, 4.1094e-02, 1.0259e-02, 2.2347e-07, 4.9093e-02, 5.4850e-02,
        6.8311e-08, 2.4219e-02, 1.4128e-07, 2.5246e-07, 9.6330e-02, 4.2212e-02,
        4.3196e-07, 5.7688e-02, 7.3639e-02, 5.3067e-02, 7.0228e-02, 4.5030e-08,
        5.2073e-02, 3.9539e-02, 9.4783e-02, 9.0185e-08, 7.9457e-08, 2.0298e-07,
        5.6935e-02, 4.6625e-02, 1.8605e-02, 6.7011e-02, 7.9156e-02, 7.7206e-02,
        1.6244e-07, 5.0562e-02, 1.3984e-07, 6.8149e-02, 4.2648e-02, 8.1662e-08,
        2.4088e-07, 4.5756e-02, 8.9305e-02, 4.5001e-02, 3.9070e-02, 6.2880e-02,
        2.4741e-02, 6.9349e-02, 6.6936e-02, 5.7470e-02, 7.6126e-02, 3.0746e-02,
        5.8447e-02, 5.9241e-02, 5.9683e-08, 6.1880e-02, 4.3860e-02, 6.4531e-02,
        8.7405e-03, 2.0298e-07, 3.0469e-02, 4.3804e-02, 5.9354e-08, 9.6719e-03,
        1.5921e-07, 6.9519e-02, 4.5282e-02, 3.2633e-02, 2.7189e-02, 4.5229e-08,
        1.2787e-07, 5.1025e-02, 5.8550e-02, 5.6351e-02, 1.6846e-07, 3.5858e-02,
        9.3226e-03, 8.6383e-02, 6.8083e-08, 2.3702e-07, 2.9593e-02, 1.3380e-02,
        8.9296e-02, 4.4603e-02, 5.8472e-02, 4.3736e-02, 6.9426e-02, 4.6833e-02,
        5.9683e-08, 5.1846e-02, 2.4088e-07, 4.6174e-02, 3.9641e-02, 5.9683e-08,
        2.0613e-02, 7.3400e-02, 3.5465e-02, 6.8311e-08, 2.1982e-07, 1.2928e-07,
        1.0380e-01, 2.4088e-07, 3.6770e-03, 6.9670e-02, 6.1546e-03, 3.8456e-02,
        3.0443e-02, 7.4505e-02, 3.1377e-02, 4.3473e-02, 4.9211e-02, 5.9683e-08,
        3.9151e-02, 5.9138e-02, 4.0209e-02, 3.2004e-07, 6.8311e-08, 7.5457e-02,
        8.9185e-08, 4.1483e-02, 1.6608e-02, 2.6394e-02, 5.9647e-02, 3.4514e-02,
        2.6441e-07, 2.0298e-07, 5.3723e-08, 5.9683e-08, 6.2285e-02, 4.5430e-02,
        6.8311e-08, 4.4308e-02, 5.1797e-03, 5.9683e-08, 5.4307e-08, 5.9251e-02,
        3.8675e-02, 4.6167e-02, 4.4986e-08, 3.6944e-02, 2.5246e-07, 7.9457e-08,
        3.1271e-02, 1.3620e-07, 9.3948e-02, 4.4351e-02, 5.6156e-02, 6.9400e-08,
        7.4900e-02, 7.2281e-02, 5.9683e-08, 4.4023e-02, 3.5817e-02, 3.8708e-02,
        1.5587e-02, 4.3356e-02, 5.4501e-02, 4.0649e-02, 4.5554e-02, 1.3614e-07,
        2.3702e-07, 1.0739e-01, 5.0611e-02, 3.3520e-02, 6.4295e-02, 1.1881e-07,
        3.2972e-02, 5.4307e-08, 4.9256e-02, 4.8324e-02, 2.3156e-07, 6.0644e-02,
        4.0110e-03, 3.9523e-02, 4.4277e-02, 6.5025e-02, 4.8968e-02, 3.8907e-02,
        2.6352e-07, 6.4261e-02, 5.4307e-08, 5.4505e-02, 1.2928e-07, 5.9683e-08,
        4.1592e-02, 4.7290e-02, 2.4030e-02, 3.3009e-07, 4.6639e-02, 4.7164e-02,
        5.9683e-08, 2.1720e-02, 6.3756e-02, 9.2407e-02, 1.2264e-07, 5.5672e-03,
        4.8722e-02, 7.0764e-02, 1.6845e-07, 3.0737e-02, 6.0842e-02, 4.6951e-02,
        4.1436e-02, 3.9813e-02, 5.9683e-08, 9.1059e-02, 3.6141e-02, 2.5247e-02,
        9.5661e-02, 2.0190e-02, 1.5921e-07, 3.8267e-02, 2.4088e-07, 9.0338e-02,
        4.2634e-02, 7.3733e-02, 4.4950e-02, 6.4951e-08, 5.8715e-02, 1.4128e-07,
        1.0242e-01, 5.4232e-02, 1.6244e-07, 3.3967e-02, 6.8311e-08, 4.5104e-03,
        1.3113e-07, 5.9683e-08, 4.0059e-02, 3.7713e-02, 2.8331e-02, 4.4397e-02,
        4.5285e-02, 1.0408e-01, 3.2694e-07, 4.1570e-02, 1.3984e-07, 2.7151e-02,
        5.1236e-02, 5.8781e-02, 4.5690e-02, 7.8162e-08, 3.0054e-02, 5.3284e-02,
        8.6190e-02, 5.7470e-02, 6.7440e-02, 1.3258e-07, 4.7779e-03, 6.1762e-02,
        1.3156e-02, 1.0838e-01, 4.0207e-02, 5.3058e-02, 4.1859e-02, 4.0576e-02,
        5.2704e-02, 4.7810e-02, 5.3786e-02, 5.7425e-02, 2.5276e-02, 3.1320e-02,
        2.8722e-02, 3.4587e-02, 4.5233e-08, 2.0851e-02, 5.9683e-08, 8.1664e-08,
        3.6250e-03, 1.3113e-07, 5.3292e-02, 5.3259e-02, 7.8800e-02, 1.8503e-02,
        7.6654e-02, 6.3960e-08, 1.3352e-02, 3.8218e-02, 6.2004e-02, 1.5410e-07,
        4.0224e-02, 7.6025e-02, 4.6855e-02, 4.7392e-08, 3.6628e-02, 4.8704e-02,
        4.0358e-02, 6.1702e-02, 5.0036e-02, 2.3702e-07, 3.2966e-02, 3.4365e-02,
        7.3070e-03, 1.3113e-07, 5.3653e-03, 6.6569e-02, 6.1315e-02, 1.2192e-07,
        2.7846e-02, 1.1507e-01, 5.9302e-02, 5.9683e-08, 8.6093e-02, 4.7992e-02,
        1.0603e-02, 4.2824e-07, 3.7846e-03, 5.8617e-02, 6.1172e-02, 6.0382e-02,
        3.1390e-02, 1.9418e-07, 5.3358e-02, 1.3984e-07, 3.8283e-02, 6.4932e-02,
        7.5019e-02, 5.9683e-08, 1.7042e-02, 5.7796e-02, 3.7789e-02, 4.3300e-02,
        5.3231e-02, 5.9683e-08, 4.7375e-08, 5.1058e-02, 2.1982e-07, 4.3404e-02,
        4.7375e-08, 2.1466e-07, 2.4088e-07, 1.6846e-07, 5.9683e-08, 4.4038e-02,
        7.1504e-02, 4.3335e-03, 2.1447e-02, 8.6828e-02, 2.6853e-02, 6.8311e-08,
        7.0459e-02, 6.3573e-02, 4.7944e-02, 3.3988e-02, 3.3028e-02, 2.0298e-07,
        2.4088e-07, 9.6674e-03, 4.3958e-02, 4.7375e-08, 8.2479e-03, 5.6338e-02,
        2.3702e-07, 6.2474e-02, 5.4670e-03, 7.2576e-08, 3.1368e-03, 2.3702e-07,
        3.2004e-07, 5.9055e-02, 5.6624e-02, 6.3344e-08, 5.9683e-08, 6.8924e-03,
        3.2297e-02, 2.8204e-07, 2.6441e-07, 1.8344e-02, 4.9678e-02, 4.1509e-02,
        3.4190e-03, 5.1257e-03, 1.4779e-02, 5.2957e-02, 5.9683e-08, 1.9418e-07,
        6.8311e-08, 5.7960e-02, 1.0188e-07, 1.3258e-07, 6.8311e-08, 5.9683e-08,
        1.0518e-07, 6.6274e-02, 6.8311e-08, 6.8974e-02, 1.7468e-07, 5.4307e-08,
        4.5227e-08, 9.1854e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([7.6594e-07, 3.3616e-07, 2.1053e-07, 5.4541e-02, 3.5695e-07, 5.5004e-02,
        6.3421e-02, 1.5106e-07, 4.7496e-02, 2.3628e-07, 3.7716e-02, 7.7428e-07,
        3.1186e-02, 1.3980e-07, 2.4253e-07, 2.3628e-07, 2.1695e-07, 2.1053e-07,
        7.3842e-02, 5.5765e-07, 1.8803e-07, 9.9746e-08, 5.5311e-02, 3.7916e-07,
        9.9228e-07, 1.5731e-07, 1.6883e-07, 4.0794e-02, 9.9746e-08, 2.9275e-07,
        6.1970e-02, 2.1053e-07, 1.1083e-07, 2.3628e-07, 2.6583e-02, 4.7450e-08,
        1.6883e-07, 6.2564e-07, 4.8510e-02, 2.3628e-07, 4.8274e-07, 4.3260e-07,
        3.5399e-07, 5.0754e-07, 8.4782e-02, 3.7916e-07, 3.4065e-07, 1.8803e-07,
        2.1053e-07, 4.7431e-07, 2.3403e-02, 4.7450e-08, 8.0418e-02, 2.3628e-07,
        4.7449e-08, 1.3963e-07, 1.8803e-07, 1.3980e-07, 6.2606e-02, 1.8803e-07,
        1.5106e-07, 8.6155e-07, 2.1695e-07, 4.3260e-07, 3.6497e-07, 3.3616e-07,
        1.9220e-02, 5.7883e-07, 5.5585e-02, 1.3980e-07, 2.7520e-07, 9.9746e-08,
        5.0092e-02, 1.1083e-07, 4.6680e-08, 7.7974e-08, 1.3980e-07, 1.9081e-07,
        4.8274e-07, 6.4797e-02, 7.7428e-07, 1.2410e-02, 2.7520e-07, 4.7841e-02,
        3.7916e-07, 1.5731e-07, 1.5731e-07, 3.0322e-02, 4.6481e-02, 7.7655e-02,
        9.8088e-08, 3.4280e-02, 9.9250e-07, 3.6497e-07, 1.8803e-07, 1.6883e-07,
        2.9275e-07, 1.6883e-07, 4.5617e-02, 2.7520e-07, 2.1695e-07, 6.5172e-02,
        1.3980e-07, 6.3042e-02, 7.7974e-08, 3.5203e-02, 1.6883e-07, 1.6883e-07,
        4.8274e-07, 1.6883e-07, 9.9171e-07, 7.7428e-07, 7.6565e-07, 4.3260e-07,
        7.6268e-02, 7.7428e-07, 4.1239e-02, 1.4451e-07, 4.6169e-02, 7.4750e-02,
        2.6308e-07, 4.5361e-02, 7.7973e-08, 4.1485e-02, 1.3980e-07, 4.6505e-02,
        4.8819e-07, 2.3628e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([2.3531e-07, 5.8519e-07, 1.4052e-06, 4.6442e-07, 1.2687e-01, 6.4724e-02,
        3.7430e-07, 4.3917e-07, 4.0940e-08, 2.3531e-07, 3.5697e-07, 5.0555e-07,
        1.2388e-06, 4.2875e-02, 9.8607e-07, 1.2995e-06, 2.5413e-07, 3.2086e-07,
        3.1774e-02, 3.5697e-07, 2.5391e-07, 3.3415e-07, 2.7340e-07, 6.2854e-07,
        6.5660e-07, 1.3647e-06, 3.5697e-07, 5.2022e-07, 9.0020e-02, 2.7340e-07,
        3.3255e-07, 2.3401e-07, 1.1029e-01, 7.1135e-07, 2.3401e-07, 5.8519e-07,
        2.3531e-07, 1.8705e-07, 1.8705e-07, 5.2022e-07, 7.9509e-07, 4.6442e-07,
        4.4059e-07, 2.3531e-07, 1.2978e-01, 3.5697e-07, 1.8705e-07, 7.4310e-02,
        9.3299e-02, 1.3012e-01, 7.9509e-07, 2.7341e-07, 9.3817e-02, 1.8705e-07,
        1.2995e-06, 3.3415e-07, 2.3531e-07, 1.8705e-07, 4.0687e-07, 8.6619e-02,
        5.8519e-07, 1.0136e-06, 5.7167e-02, 1.4116e-01, 1.1463e-01, 2.3531e-07,
        1.1730e-01, 7.9509e-07, 2.3775e-07, 7.1135e-07, 9.8904e-02, 1.0023e-01,
        7.7426e-02, 1.1275e-07, 6.8139e-07, 6.1339e-07, 4.6442e-07, 1.2995e-06,
        2.3334e-07, 2.3401e-07, 8.4330e-02, 6.3642e-07, 1.0223e-01, 7.9509e-07,
        3.7430e-07, 1.0064e-01, 5.9842e-07, 3.5697e-07, 7.9509e-07, 1.0997e-01,
        9.1590e-02, 7.9509e-07, 2.5413e-07, 2.3531e-07, 7.9629e-02, 2.3531e-07,
        5.9842e-07, 6.3046e-07, 5.2022e-07, 6.3642e-07, 2.3531e-07, 2.5413e-07,
        7.9509e-07, 5.9842e-07, 7.7185e-07, 3.3300e-02, 3.6856e-07, 1.0277e-06,
        7.9509e-07, 5.0556e-07, 3.5697e-07, 9.1050e-02, 3.3255e-07, 7.0009e-02,
        4.6442e-07, 7.7346e-02, 7.9509e-07, 9.8049e-02, 1.1451e-01, 3.3415e-07,
        1.2995e-06, 6.7677e-02, 6.2854e-07, 5.2022e-07, 2.3401e-07, 2.7340e-07,
        7.9509e-07, 1.2862e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.2828e-01, 7.2228e-08, 3.1989e-02, 8.7144e-02, 5.2812e-02, 6.8224e-08,
        1.0415e-07, 2.0719e-02, 1.7896e-02, 1.4281e-02, 6.7292e-02, 1.7363e-02,
        1.3980e-07, 9.5864e-02, 5.6088e-02, 4.3512e-02, 4.2570e-02, 4.1762e-08,
        6.1016e-02, 4.5045e-08, 1.3434e-02, 1.1178e-07, 2.2679e-02, 8.1060e-08,
        1.2101e-02, 7.2467e-02, 5.0164e-08, 4.8952e-08, 2.1183e-02, 1.1431e-07,
        3.3841e-02, 6.2054e-08, 2.2817e-08, 5.5862e-08, 1.6340e-01, 1.8954e-02,
        1.4259e-02, 3.1772e-02, 4.5344e-03, 1.1475e-07, 1.6471e-08, 3.5924e-02,
        5.4573e-08, 1.9679e-07, 3.9954e-02, 1.7121e-07, 3.4589e-08, 1.0985e-07,
        9.4322e-08, 4.5085e-02, 3.9791e-02, 2.6854e-02, 5.9601e-08, 4.5167e-08,
        1.3315e-01, 3.9185e-02, 2.1588e-03, 4.9542e-02, 6.7599e-08, 1.6250e-07,
        1.1264e-02, 3.5611e-02, 1.6283e-07, 2.3516e-02, 1.6137e-07, 5.0066e-03,
        5.0826e-08, 3.5624e-02, 1.7017e-07, 1.5200e-02, 7.6709e-02, 2.8691e-02,
        1.7131e-07, 2.6466e-02, 1.0250e-07, 5.2260e-02, 8.4218e-08, 2.7636e-07,
        9.7512e-08, 3.6452e-02, 5.1649e-08, 1.7568e-07, 9.3366e-08, 2.7146e-02,
        3.6963e-02, 1.9679e-07, 7.9302e-02, 3.4924e-02, 5.2451e-02, 1.2183e-02,
        1.1603e-07, 4.3674e-02, 1.4268e-07, 2.4406e-02, 1.5732e-07, 2.6236e-02,
        3.6053e-02, 5.2111e-08, 1.3986e-01, 6.3872e-02, 5.8685e-02, 7.4669e-02,
        3.8598e-02, 3.3636e-02, 1.4844e-02, 1.1587e-07, 3.1723e-02, 1.9787e-01,
        4.6556e-02, 1.5454e-07, 6.2239e-03, 7.2097e-03, 6.5087e-08, 1.3101e-07,
        3.3203e-02, 1.3924e-07, 3.0676e-02, 6.4856e-08, 7.7377e-08, 1.2031e-07,
        4.9547e-02, 1.0141e-02, 7.1462e-02, 5.1239e-02, 2.0928e-07, 7.0789e-02,
        2.0884e-02, 7.2373e-02, 6.1694e-02, 1.1562e-07, 2.8008e-02, 3.1723e-02,
        1.6987e-07, 6.6535e-08, 7.9659e-06, 1.3101e-07, 2.5041e-02, 2.7148e-02,
        2.1874e-01, 2.9682e-03, 1.8434e-02, 6.7804e-02, 3.8259e-02, 1.5454e-07,
        3.7296e-02, 3.4170e-08, 2.9245e-02, 2.4184e-07, 6.1078e-02, 1.5732e-07,
        2.4697e-02, 2.6675e-02, 1.7104e-07, 2.6184e-02, 2.6521e-02, 7.8464e-03,
        3.4790e-08, 2.1801e-02, 1.3980e-07, 2.9493e-02, 4.1652e-08, 8.4640e-08,
        4.1762e-08, 1.4651e-02, 2.2331e-02, 1.5516e-02, 1.8543e-02, 3.3284e-03,
        4.4941e-02, 5.9725e-02, 4.3019e-02, 8.7736e-03, 1.5672e-07, 2.0465e-02,
        1.2737e-07, 1.5073e-01, 7.0184e-08, 8.3784e-03, 5.6959e-03, 2.7411e-02,
        6.2200e-02, 3.9746e-02, 9.1070e-03, 3.6356e-02, 1.0367e-07, 1.1523e-07,
        3.4589e-08, 2.8303e-02, 1.5971e-07, 2.3027e-02, 1.6442e-07, 1.0734e-07,
        1.1193e-07, 5.8779e-02, 7.9862e-02, 3.8515e-02, 6.7599e-08, 8.5342e-08,
        1.6249e-01, 3.2570e-02, 9.2601e-08, 7.3748e-02, 2.3619e-08, 1.4250e-01,
        1.6128e-02, 2.2827e-07, 5.2976e-02, 2.1400e-02, 4.2095e-02, 3.8456e-02,
        5.4348e-02, 4.7387e-02, 1.3101e-07, 1.1741e-02, 1.3348e-07, 3.2143e-02,
        5.6438e-02, 1.8688e-02, 1.1583e-07, 2.4973e-07, 4.1762e-08, 1.5979e-07,
        3.4991e-02, 1.5991e-07, 5.9898e-08, 4.1327e-08, 1.4888e-01, 5.7656e-02,
        9.3611e-08, 3.2454e-02, 2.7920e-02, 9.4084e-03, 1.6963e-07, 3.4589e-08,
        2.0656e-02, 6.9033e-02, 6.4933e-02, 1.0260e-07, 9.3366e-08, 3.1804e-02,
        1.5979e-07, 4.8972e-02, 1.6354e-07, 2.5186e-02, 2.2973e-02, 4.9887e-02,
        1.3980e-07, 1.5454e-07, 1.5732e-07, 5.4236e-02, 7.2517e-02, 5.2537e-02,
        1.5732e-07, 5.7683e-02, 2.9158e-02, 1.8871e-01, 8.9492e-08, 2.0082e-02,
        7.3995e-03, 1.4413e-02, 1.5732e-07, 3.5734e-02, 5.7974e-08, 4.1762e-08,
        7.9117e-08, 8.6564e-08, 2.4184e-02, 3.5345e-02, 1.1924e-07, 1.1500e-07,
        2.1476e-02, 3.2986e-02, 1.0029e-01, 7.2751e-02, 5.9138e-03, 3.9192e-02,
        7.6872e-08, 3.9768e-02, 1.4948e-02, 1.4695e-01, 3.9012e-02, 1.2251e-07,
        1.6987e-07, 2.1234e-02, 2.1151e-07, 1.7240e-02, 7.5050e-03, 1.5922e-07,
        3.3896e-02, 1.1923e-07, 5.1838e-02, 1.5665e-07, 6.7599e-08, 6.5521e-02,
        1.5991e-07, 4.2365e-02, 1.5739e-02, 7.8658e-02, 2.5806e-07, 9.3230e-08,
        2.6707e-07, 3.3327e-02, 9.4322e-08, 1.6070e-07, 2.4184e-07, 9.4322e-08,
        3.1241e-02, 3.7803e-02, 1.5960e-07, 9.4322e-08, 5.2337e-02, 6.2270e-03,
        8.4638e-08, 4.3053e-02, 6.9352e-03, 3.7583e-02, 2.4184e-07, 1.2926e-07,
        9.1788e-02, 4.4610e-08, 6.3019e-02, 8.3226e-02, 1.7034e-02, 7.4450e-02,
        9.5764e-03, 4.6740e-02, 6.9255e-02, 4.1845e-02, 5.0231e-02, 6.4259e-02,
        3.6512e-02, 3.3349e-08, 6.2378e-02, 3.5923e-08, 6.2066e-08, 1.1219e-07,
        3.8182e-02, 5.0968e-02, 1.3943e-07, 6.2648e-08, 9.9608e-03, 6.7599e-08,
        1.5535e-02, 3.3520e-02, 1.1331e-02, 5.2348e-02, 5.1609e-02, 3.9321e-03,
        4.9962e-08, 2.4184e-07, 4.8027e-02, 8.8918e-03, 5.9292e-08, 1.5573e-07,
        4.1765e-02, 5.5771e-02, 5.5113e-08, 1.6276e-02, 1.2749e-07, 2.6609e-03,
        7.6070e-02, 4.0548e-02, 2.9476e-03, 7.9343e-08, 2.7257e-02, 4.5347e-02,
        3.8976e-02, 7.2552e-08, 3.3159e-02, 4.9962e-08, 6.4675e-03, 2.8052e-02,
        3.1533e-02, 2.9288e-02, 4.9235e-02, 2.9632e-02, 9.5810e-08, 9.6776e-04,
        5.4737e-02, 6.6047e-03, 8.8746e-02, 1.5007e-02, 1.6065e-07, 4.6668e-02,
        1.5001e-02, 8.5299e-03, 4.1762e-08, 3.4967e-02, 2.4198e-07, 5.3813e-08,
        5.6364e-08, 4.5045e-08, 1.1317e-02, 8.1043e-03, 2.6430e-02, 6.4860e-02,
        2.3093e-02, 5.4712e-08, 4.1867e-02, 3.1765e-02, 8.2150e-03, 1.2983e-07,
        1.8026e-02, 1.9512e-02, 5.4023e-02, 9.0665e-08, 2.6680e-02, 1.0472e-02,
        3.6612e-02, 4.3192e-02, 1.0522e-07, 6.7599e-08, 1.2108e-02, 6.1317e-02,
        1.8400e-01, 1.9679e-07, 6.1409e-02, 5.2611e-02, 2.2820e-02, 5.1032e-08,
        8.3151e-03, 7.1986e-02, 3.6507e-02, 4.5334e-02, 2.2173e-02, 5.6607e-08,
        7.1483e-08, 1.0947e-07, 4.4576e-08, 1.3892e-07, 1.0491e-02, 4.9846e-02,
        2.2543e-02, 1.1864e-07, 4.7244e-02, 6.4071e-02, 2.2855e-02, 1.8478e-02,
        5.1049e-02, 9.4476e-08, 9.6011e-08, 5.1946e-02, 4.3498e-02, 1.8197e-03,
        1.8463e-01, 1.5732e-07, 1.7979e-07, 4.3010e-02, 2.4441e-07, 7.0057e-02,
        2.2042e-02, 6.2054e-08, 1.2371e-07, 1.1475e-07, 7.0184e-08, 1.4991e-02,
        1.9921e-02, 3.0707e-02, 7.1524e-08, 1.4456e-02, 2.7471e-02, 1.5732e-07,
        4.4367e-02, 1.8798e-02, 9.9967e-03, 2.3422e-02, 4.3441e-02, 1.4679e-01,
        1.1923e-07, 5.5644e-02, 5.6963e-02, 9.4322e-08, 1.6230e-01, 7.7546e-03,
        6.2054e-08, 1.2910e-02, 1.0303e-07, 6.7599e-08, 4.9905e-02, 2.5562e-07,
        1.1475e-07, 1.3547e-02, 2.9506e-02, 5.9702e-08, 9.4322e-08, 2.8838e-02,
        3.0393e-02, 1.2578e-07, 6.5017e-02, 9.0131e-08, 4.1262e-02, 4.0800e-02,
        1.3187e-07, 3.1060e-02, 7.0111e-08, 4.9503e-02, 4.7057e-02, 9.5909e-08,
        1.1475e-07, 3.1104e-02, 3.1728e-07, 1.3980e-07, 1.6987e-07, 1.5979e-07,
        7.9043e-08, 5.0091e-02, 6.7599e-08, 9.2321e-03, 5.1364e-08, 6.7599e-08,
        4.5045e-08, 5.3887e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([4.6300e-02, 4.9197e-07, 4.9702e-02, 3.4066e-02, 3.9539e-02, 7.3486e-07,
        1.0385e-01, 6.6645e-07, 4.4866e-07, 7.7185e-07, 3.6705e-02, 4.4069e-02,
        8.8608e-07, 5.7339e-07, 1.0683e-06, 3.8981e-02, 4.8336e-07, 1.6091e-07,
        1.2283e-01, 4.5185e-02, 3.4794e-07, 3.8005e-02, 9.1832e-07, 4.3574e-02,
        4.6905e-02, 3.7357e-07, 2.5744e-07, 4.6626e-07, 5.7301e-02, 1.6091e-07,
        3.2853e-02, 1.6536e-01, 2.3843e-02, 9.0556e-07, 4.0318e-02, 3.7948e-02,
        1.2068e-06, 3.5710e-07, 1.2408e-01, 2.5510e-02, 2.9121e-04, 1.9448e-03,
        3.4691e-02, 4.2195e-02, 2.1313e-07, 3.3862e-02, 1.6870e-07, 7.7873e-07,
        5.6120e-02, 1.0811e-01, 3.1033e-02, 3.3854e-07, 3.8762e-02, 4.4677e-07,
        3.1501e-07, 5.3480e-07, 8.8607e-07, 4.4305e-07, 1.1461e-01, 3.7647e-02,
        2.3570e-02, 2.8887e-02, 4.8317e-02, 4.7050e-02, 3.3846e-02, 3.1623e-02,
        4.3198e-02, 9.8183e-07, 5.3714e-02, 3.9772e-07, 1.4133e-07, 4.8900e-02,
        9.7642e-02, 3.3111e-07, 2.9563e-07, 4.9197e-07, 3.8255e-02, 1.0623e-01,
        5.4538e-07, 4.4552e-07, 4.0887e-02, 5.8286e-02, 5.8228e-07, 7.5969e-07,
        4.0539e-02, 2.3848e-07, 3.5710e-07, 5.5322e-02, 5.7000e-03, 3.3116e-07,
        2.3234e-07, 1.1317e-06, 1.7267e-02, 6.9166e-07, 8.6091e-07, 8.2356e-07,
        1.3752e-01, 3.5247e-02, 3.1462e-07, 3.3841e-02, 9.0316e-07, 3.1843e-02,
        2.3488e-07, 4.9724e-02, 5.0575e-02, 4.3881e-02, 1.5146e-06, 3.3192e-02,
        2.9958e-02, 3.7281e-02, 3.4946e-02, 6.5639e-07, 9.7709e-07, 3.4951e-02,
        2.1880e-07, 3.4817e-07, 4.2115e-02, 1.1910e-01, 3.1955e-07, 6.7807e-08,
        2.9417e-02, 5.3608e-02, 3.5015e-03, 1.6091e-07, 1.1909e-01, 1.4773e-01,
        4.1578e-02, 9.7709e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.0436e-06, 2.2837e-06, 1.7873e-06, 5.0007e-07, 9.7278e-07, 5.2898e-07,
        9.2141e-02, 1.2948e-06, 1.9289e-06, 7.7105e-02, 1.9037e-06, 1.5191e-06,
        3.0146e-07, 5.8608e-07, 2.2918e-06, 1.7762e-06, 2.5823e-06, 8.7142e-02,
        2.9488e-06, 7.8462e-07, 1.4275e-06, 9.2401e-02, 1.1686e-06, 2.3097e-06,
        2.1520e-06, 9.8665e-02, 9.1161e-02, 1.6493e-06, 3.0280e-07, 7.7930e-02,
        1.8184e-06, 1.0482e-06, 1.1258e-01, 2.0688e-06, 1.3004e-06, 2.0029e-06,
        1.1877e-01, 9.7278e-07, 1.6690e-01, 1.8372e-06, 1.0537e-06, 9.5520e-02,
        7.9028e-02, 3.0585e-02, 1.0152e-01, 1.5413e-06, 2.0046e-06, 7.8426e-02,
        8.5748e-02, 7.3629e-07, 7.6422e-02, 3.0146e-07, 7.8946e-02, 1.0686e-01,
        7.7533e-07, 6.6519e-07, 5.0798e-06, 8.7873e-02, 2.7010e-06, 9.1598e-02,
        3.0146e-07, 1.1540e-06, 2.6427e-02, 9.1204e-02, 1.0540e-01, 6.6519e-07,
        3.7631e-06, 6.2946e-07, 2.5817e-06, 1.7385e-06, 4.8540e-06, 7.6360e-02,
        4.2188e-06, 1.7152e-06, 5.8608e-07, 1.0497e-01, 8.1817e-02, 2.5714e-06,
        7.4976e-07, 1.3004e-06, 3.0155e-06, 8.8705e-07, 3.5084e-02, 4.8260e-07,
        1.1217e-01, 1.4058e-06, 2.6113e-06, 1.2010e-01, 1.7228e-06, 3.5244e-06,
        1.0202e-06, 1.1116e-06, 1.2731e-06, 2.6216e-06, 3.9156e-06, 8.3746e-07,
        3.0876e-06, 8.8303e-02, 9.1115e-02, 9.7278e-07, 9.5448e-02, 1.2962e-01,
        8.7050e-02, 7.7533e-07, 1.4143e-01, 9.4116e-02, 8.8705e-07, 3.7364e-02,
        2.2682e-06, 2.3626e-06, 2.0304e-06, 1.0005e-01, 1.5632e-07, 6.6750e-07,
        1.0660e-01, 1.2453e-06, 6.1492e-07, 1.0476e-01, 2.9715e-02, 3.0146e-07,
        1.0786e-01, 1.0466e-06, 1.8626e-06, 3.5828e-02, 8.8414e-07, 2.4633e-06,
        3.5622e-06, 7.2494e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([6.0261e-02, 3.6449e-02, 6.0493e-02, 3.9885e-02, 4.9589e-02, 7.1230e-03,
        6.1428e-02, 3.5908e-02, 2.3948e-02, 7.4786e-02, 3.7090e-02, 4.2692e-02,
        3.8949e-02, 1.6490e-01, 3.8679e-02, 5.6638e-02, 2.9512e-02, 2.5927e-07,
        5.9116e-02, 1.4603e-07, 2.9611e-02, 4.2698e-02, 7.4132e-03, 7.1021e-03,
        5.0084e-02, 5.8301e-02, 1.5605e-07, 7.9810e-03, 7.2906e-02, 3.5502e-02,
        2.5752e-02, 6.7965e-02, 8.4899e-03, 3.0987e-02, 2.2426e-02, 1.4289e-02,
        9.1337e-02, 1.3280e-02, 2.8929e-02, 2.4824e-08, 7.8598e-02, 2.5176e-02,
        9.9566e-08, 4.2418e-02, 9.4044e-02, 8.0163e-08, 5.9350e-08, 2.5892e-02,
        2.6265e-08, 6.7461e-02, 4.9722e-02, 6.0290e-02, 1.0995e-07, 4.7503e-02,
        6.9359e-03, 3.0363e-02, 1.6840e-07, 1.2259e-02, 2.4918e-08, 3.7109e-02,
        1.1165e-02, 4.4475e-02, 1.2030e-07, 4.9764e-02, 2.8956e-02, 5.0271e-02,
        7.4228e-08, 6.8727e-02, 1.0518e-07, 1.0417e-02, 1.1958e-02, 1.8376e-02,
        1.4449e-01, 3.7584e-02, 1.2401e-07, 2.6498e-02, 4.7476e-02, 5.8360e-08,
        1.6499e-01, 9.4730e-08, 5.4973e-02, 8.0284e-08, 2.1958e-07, 3.3381e-02,
        5.3075e-02, 8.8508e-08, 1.8687e-02, 5.9780e-02, 1.0853e-02, 3.2977e-02,
        2.1129e-02, 2.4852e-02, 3.1330e-02, 2.7985e-02, 1.7704e-07, 1.6137e-02,
        1.9951e-02, 4.0328e-02, 6.4124e-02, 2.3294e-02, 3.4359e-02, 1.8987e-02,
        5.3302e-02, 7.6780e-02, 1.4444e-02, 1.5660e-02, 4.5639e-02, 4.1209e-03,
        3.8486e-02, 1.6694e-07, 4.8932e-02, 2.0340e-02, 8.6946e-02, 5.0961e-08,
        7.0522e-02, 1.5120e-07, 5.2739e-02, 2.0588e-02, 3.5765e-02, 6.2865e-08,
        5.5465e-02, 5.0955e-02, 5.4340e-02, 2.9015e-02, 3.5238e-02, 1.3069e-07,
        6.1404e-02, 1.5185e-02, 3.8329e-02, 2.4918e-08, 4.2826e-02, 2.9748e-02,
        2.1958e-07, 4.8605e-02, 4.1561e-08, 7.2800e-08, 3.1850e-02, 7.6998e-02,
        3.0103e-02, 3.7516e-02, 4.1550e-02, 3.8911e-02, 4.2106e-02, 2.5927e-07,
        1.4267e-01, 4.7168e-02, 5.0519e-02, 1.0621e-03, 5.8536e-02, 8.7789e-02,
        4.3196e-02, 5.5479e-02, 5.2747e-02, 3.7634e-02, 4.7081e-02, 5.4444e-02,
        5.2703e-08, 5.0057e-02, 1.4052e-07, 4.1966e-02, 6.9627e-08, 5.1371e-08,
        1.7736e-07, 1.4197e-01, 2.7829e-02, 1.5209e-02, 1.6474e-02, 3.7856e-02,
        5.9795e-02, 3.3360e-02, 3.7006e-02, 7.1593e-02, 3.7111e-02, 6.6732e-02,
        5.6535e-08, 4.0123e-02, 5.4549e-08, 1.1867e-02, 4.1307e-02, 4.1692e-02,
        3.2203e-02, 1.1421e-01, 7.5228e-03, 3.6893e-02, 9.7777e-08, 5.4817e-02,
        2.5927e-07, 4.3435e-02, 3.3609e-02, 3.0306e-07, 5.1082e-02, 1.2892e-07,
        8.8532e-08, 3.9683e-02, 4.3525e-02, 1.1952e-07, 8.9833e-06, 1.3573e-02,
        4.2944e-02, 5.1742e-02, 2.0483e-07, 1.3098e-02, 4.4107e-08, 5.8805e-02,
        2.0069e-02, 3.7223e-02, 6.4698e-02, 4.9509e-02, 4.6444e-02, 1.0602e-02,
        1.0675e-02, 6.3121e-02, 8.9144e-08, 1.1133e-02, 1.1941e-07, 1.7308e-07,
        1.0603e-02, 1.6948e-02, 5.3112e-08, 1.0962e-07, 1.3097e-07, 7.0182e-02,
        4.4396e-02, 6.0929e-08, 5.3213e-02, 2.3617e-02, 1.4500e-02, 3.6761e-02,
        2.4555e-02, 4.5446e-02, 1.0645e-02, 3.4396e-02, 1.0096e-07, 3.3226e-07,
        1.8267e-01, 2.8272e-02, 5.2670e-02, 1.4184e-01, 1.4870e-01, 2.8336e-02,
        8.8997e-08, 4.2869e-02, 2.4384e-02, 6.4137e-02, 5.8454e-02, 3.1514e-02,
        4.5704e-03, 1.2429e-07, 7.0900e-02, 1.2932e-01, 3.7718e-02, 6.5456e-03,
        1.2892e-07, 7.3170e-02, 5.5284e-02, 4.1560e-02, 1.6694e-07, 7.2689e-02,
        4.7013e-02, 6.2721e-02, 2.6526e-08, 3.5707e-02, 1.4938e-01, 1.3097e-07,
        7.0403e-08, 6.2533e-08, 2.0037e-02, 6.2027e-02, 1.9244e-02, 7.3368e-02,
        3.1753e-02, 2.7177e-02, 2.9006e-02, 3.0499e-02, 1.0465e-02, 2.0465e-01,
        3.4999e-02, 5.3059e-02, 1.8143e-02, 3.5004e-02, 4.1606e-02, 2.6620e-08,
        7.3418e-08, 2.8256e-02, 3.3885e-02, 5.3413e-08, 1.4530e-02, 3.0077e-07,
        1.8946e-07, 8.1260e-02, 2.3312e-02, 8.5999e-02, 1.3178e-01, 2.8792e-02,
        1.9487e-02, 1.4414e-02, 8.6654e-03, 4.0873e-02, 1.0191e-07, 6.5718e-02,
        9.0073e-08, 5.0373e-02, 8.9144e-08, 2.3855e-02, 1.6694e-07, 5.7291e-02,
        6.6206e-02, 1.2780e-01, 7.9858e-08, 9.2034e-02, 1.4768e-02, 6.6942e-02,
        1.6953e-02, 3.2116e-02, 1.7007e-02, 3.6693e-02, 5.4245e-02, 3.5318e-02,
        5.3739e-02, 6.1695e-08, 2.1049e-02, 5.9721e-02, 3.4909e-02, 9.6327e-02,
        1.3253e-02, 5.3399e-02, 4.4898e-02, 3.0814e-02, 1.0014e-07, 3.3358e-02,
        3.3025e-02, 1.1654e-07, 1.6151e-02, 2.9525e-02, 1.9587e-07, 4.1920e-02,
        1.4608e-01, 3.1001e-02, 2.6385e-02, 1.0187e-07, 5.6169e-02, 2.4601e-07,
        1.1685e-02, 1.5350e-02, 2.8862e-07, 6.1259e-02, 1.2477e-07, 1.4885e-02,
        1.7704e-07, 3.9370e-02, 2.9108e-08, 6.6938e-02, 2.6307e-08, 1.6870e-02,
        1.2164e-07, 3.1507e-02, 1.4052e-07, 5.0399e-08, 5.2001e-08, 1.6205e-07,
        2.4166e-02, 3.7519e-02, 4.1944e-02, 6.9759e-08, 3.4503e-02, 5.2159e-02,
        1.1914e-02, 3.7519e-02, 4.1584e-02, 1.8487e-07, 9.5003e-03, 4.5385e-02,
        8.0893e-02, 3.6646e-02, 3.9668e-02, 4.1506e-02, 1.2833e-07, 4.0817e-02,
        4.6614e-02, 1.3467e-02, 4.0870e-02, 1.7707e-02, 3.0624e-02, 4.7645e-02,
        3.8370e-02, 6.2900e-02, 2.1958e-07, 6.9153e-02, 4.8048e-02, 1.8293e-07,
        5.3799e-02, 1.4019e-01, 5.6508e-02, 8.0537e-02, 2.3155e-02, 2.1920e-02,
        1.5599e-02, 8.0460e-08, 5.7139e-02, 9.8485e-08, 3.0456e-02, 4.1166e-08,
        1.7820e-02, 2.1701e-02, 3.1784e-02, 2.7270e-07, 1.9886e-02, 4.3175e-02,
        2.2740e-02, 2.3946e-02, 9.8642e-08, 1.8794e-07, 4.0613e-02, 6.9381e-02,
        6.1203e-02, 1.4038e-01, 3.7326e-02, 6.2285e-02, 5.5235e-02, 6.2494e-08,
        7.7513e-02, 4.2714e-02, 5.4537e-02, 4.7523e-02, 1.9269e-02, 7.0145e-08,
        1.2136e-02, 4.6476e-02, 1.8275e-01, 1.8426e-02, 1.3881e-02, 5.2657e-02,
        8.2723e-02, 8.0515e-08, 5.0590e-02, 4.6448e-08, 2.3071e-02, 1.5120e-02,
        2.5120e-02, 3.7857e-08, 5.2999e-02, 7.6377e-02, 7.2196e-02, 5.5748e-02,
        3.4681e-02, 5.5865e-08, 5.4549e-08, 7.0710e-02, 2.4918e-08, 5.8634e-02,
        8.0019e-08, 1.7023e-01, 1.0096e-07, 7.0829e-02, 5.2313e-02, 4.9420e-02,
        1.6071e-02, 6.7623e-02, 7.6416e-03, 3.2368e-02, 8.3698e-02, 3.3430e-08,
        2.1522e-02, 1.4681e-02, 2.7707e-02, 1.8476e-01, 1.6938e-01, 3.2290e-02,
        1.2892e-07, 5.6163e-02, 4.6156e-02, 6.0183e-02, 2.0096e-01, 1.1498e-07,
        2.5209e-07, 3.2752e-02, 2.3981e-02, 9.3647e-08, 1.3928e-02, 2.6265e-08,
        1.4052e-07, 5.8570e-02, 2.6592e-02, 8.5720e-08, 1.7704e-07, 2.1665e-02,
        1.4987e-07, 4.1531e-08, 2.3018e-02, 5.5212e-02, 6.6643e-02, 6.2193e-02,
        4.2297e-02, 1.7601e-01, 2.2570e-02, 5.2207e-02, 5.9838e-02, 7.0889e-02,
        1.6814e-07, 3.9240e-02, 1.8987e-01, 8.2420e-08, 1.5893e-07, 1.2929e-07,
        9.2494e-08, 2.7838e-02, 6.6646e-02, 1.3175e-02, 6.1041e-02, 2.4601e-07,
        5.1432e-02, 3.9110e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([8.3545e-07, 5.1596e-02, 9.3917e-07, 4.7919e-07, 5.9781e-08, 1.0388e-01,
        1.7812e-02, 3.0653e-07, 3.9414e-02, 4.7271e-07, 4.9729e-02, 5.1503e-07,
        3.5433e-02, 3.6621e-07, 4.8375e-07, 1.0425e-06, 1.3813e-06, 4.5303e-07,
        4.6918e-07, 1.0424e-06, 2.3271e-07, 9.4802e-07, 3.0653e-07, 1.0745e-06,
        4.3854e-02, 5.5160e-07, 3.0433e-02, 3.9576e-02, 1.0425e-06, 7.5367e-07,
        5.3463e-07, 4.7271e-07, 4.8173e-02, 4.9622e-07, 1.2882e-01, 2.0577e-02,
        4.1802e-02, 3.0721e-02, 3.2331e-02, 1.1780e-01, 1.1029e-06, 1.3799e-02,
        4.7909e-07, 3.9234e-02, 5.7297e-07, 5.9781e-08, 4.6103e-07, 4.6918e-07,
        8.7009e-07, 4.6426e-02, 1.0077e-01, 4.8375e-07, 3.3387e-02, 1.2813e-01,
        9.9243e-07, 5.5160e-07, 3.6819e-07, 5.6083e-07, 2.0820e-07, 5.3960e-02,
        5.3009e-02, 4.4700e-07, 5.6083e-07, 4.1502e-02, 4.3505e-02, 1.3001e-01,
        4.5428e-07, 7.5367e-07, 5.1503e-07, 4.2218e-02, 1.0808e-06, 5.4752e-07,
        6.3465e-07, 7.1393e-07, 5.4752e-07, 7.4327e-07, 1.1152e-06, 1.4834e-07,
        3.7896e-07, 5.1503e-07, 5.0866e-07, 4.9991e-08, 3.4741e-02, 3.9187e-07,
        1.0331e-01, 5.0986e-07, 3.9348e-02, 2.9545e-07, 6.4528e-07, 2.5980e-02,
        5.6083e-07, 3.0716e-07, 1.2980e-06, 2.9541e-07, 4.2298e-02, 8.9924e-07,
        5.1503e-07, 9.4111e-07, 8.3894e-07, 3.5546e-07, 2.7249e-07, 2.7365e-07,
        5.2090e-02, 2.8228e-07, 4.7295e-02, 4.7271e-07, 5.1894e-07, 9.9243e-07,
        2.1642e-07, 4.0453e-07, 1.4834e-07, 1.0903e-01, 5.2152e-07, 4.6815e-02,
        7.2979e-07, 1.0876e-01, 5.5463e-07, 1.0077e-06, 9.3917e-07, 6.3020e-07,
        9.2628e-02, 4.9878e-02, 3.9428e-02, 5.1319e-02, 1.3447e-01, 4.4158e-07,
        4.8269e-02, 5.6477e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.6291e-06, 7.1283e-07, 5.4902e-07, 5.9278e-07, 1.7794e-06, 1.5007e-06,
        9.4541e-07, 4.5765e-07, 3.8710e-02, 5.9680e-04, 4.9587e-07, 1.0012e-06,
        5.7779e-07, 2.1065e-06, 2.7161e-03, 2.3745e-06, 4.6012e-06, 1.4027e-03,
        2.6288e-06, 5.9278e-07, 9.6642e-07, 1.2327e-03, 1.2654e-06, 6.5483e-07,
        6.9734e-07, 1.8823e-06, 3.2821e-06, 3.7357e-07, 5.5880e-03, 1.0369e-06,
        3.0543e-06, 1.8713e-06, 2.6881e-06, 3.2634e-06, 1.5212e-06, 1.2443e-06,
        1.2948e-02, 1.2101e-01, 1.9212e-06, 8.9939e-07, 8.7050e-07, 5.7779e-07,
        4.6681e-02, 1.4414e-06, 2.0580e-06, 5.4902e-07, 1.2054e-06, 4.1909e-02,
        1.0402e-01, 4.6556e-02, 7.5378e-07, 1.3197e-01, 1.4681e-03, 1.3544e-06,
        4.6568e-06, 1.6499e-06, 1.9951e-06, 1.3713e-06, 1.2054e-06, 1.5212e-06,
        1.9547e-07, 3.4227e-02, 2.2794e-06, 1.6092e-06, 6.6205e-07, 1.2536e-06,
        1.3277e-06, 1.2654e-06, 1.8086e-07, 4.8337e-02, 1.1714e-06, 1.5570e-06,
        1.1495e-06, 8.1730e-02, 7.3930e-07, 1.2159e-06, 1.9827e-07, 1.2283e-03,
        9.6642e-07, 1.1307e-06, 1.7453e-01, 1.1170e-06, 8.9939e-07, 7.5378e-07,
        1.1270e-06, 2.6881e-06, 1.8823e-06, 2.0880e-06, 1.5927e-06, 3.8943e-02,
        4.5765e-07, 8.2867e-02, 1.3244e-06, 1.0893e-06, 8.9899e-07, 1.3449e-01,
        1.5212e-06, 5.7779e-07, 5.0588e-07, 4.0741e-02, 1.2927e-06, 1.3013e-06,
        4.0526e-07, 1.2398e-06, 1.3013e-06, 1.0978e-01, 1.1794e-01, 9.9260e-02,
        1.2768e-06, 1.3932e-06, 3.0543e-06, 9.6642e-07, 1.8713e-06, 1.1307e-06,
        9.6642e-07, 3.2634e-06, 8.5654e-02, 2.0580e-06, 1.2654e-06, 8.4667e-07,
        1.1567e-01, 9.0006e-07, 2.7860e-02, 9.8541e-07, 5.9278e-07, 9.2137e-02,
        8.7125e-07, 1.0165e-01], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([5.3213e-08, 3.2064e-02, 2.0269e-02, 1.4623e-07, 7.7947e-04, 1.4124e-07,
        8.8154e-03, 1.4533e-01, 1.4193e-02, 1.2756e-07, 8.3797e-03, 3.6052e-04,
        2.3139e-07, 5.3032e-02, 8.9479e-03, 1.5546e-07, 1.0466e-02, 4.5381e-08,
        1.3011e-07, 5.7692e-08, 5.2493e-02, 3.7041e-02, 8.5796e-08, 1.0905e-07,
        4.2273e-02, 4.2043e-02, 1.2810e-07, 2.9201e-02, 3.4868e-03, 1.6802e-07,
        4.3768e-08, 1.7091e-07, 5.4658e-02, 6.3752e-02, 1.2680e-07, 1.1918e-07,
        1.5609e-07, 9.2745e-08, 1.4342e-02, 3.9558e-08, 5.2931e-02, 4.1406e-02,
        1.1025e-07, 1.2382e-07, 5.4140e-08, 7.8128e-08, 1.5093e-07, 8.6342e-03,
        4.2159e-08, 1.9927e-02, 3.4060e-02, 5.2324e-08, 1.6050e-07, 5.4076e-08,
        1.4131e-07, 1.0477e-02, 8.4896e-08, 5.3482e-02, 1.5686e-02, 7.1654e-02,
        5.3721e-08, 1.1465e-07, 4.8864e-02, 2.5742e-02, 8.5953e-08, 6.3019e-08,
        7.5507e-08, 7.4785e-02, 4.3927e-02, 7.3628e-03, 5.6195e-03, 5.0193e-08,
        4.3304e-03, 6.8228e-08, 1.6358e-07, 2.3137e-07, 1.9814e-07, 5.0415e-08,
        2.8821e-02, 1.5073e-07, 5.4502e-08, 1.1872e-07, 2.4927e-01, 4.4617e-08,
        2.2410e-02, 5.4445e-08, 5.0618e-08, 6.1379e-08, 7.6599e-02, 2.5406e-02,
        2.9003e-07, 6.8060e-02, 4.5641e-03, 4.0973e-02, 5.9228e-02, 1.3065e-02,
        5.1003e-02, 6.3678e-08, 2.0438e-02, 7.7377e-02, 1.8651e-02, 3.0149e-03,
        1.2333e-07, 2.1738e-07, 4.5646e-08, 3.6386e-02, 3.1255e-02, 4.4849e-08,
        5.5729e-08, 8.5272e-08, 5.1757e-02, 1.6625e-02, 7.6811e-02, 7.7357e-02,
        1.2881e-07, 6.7382e-02, 5.3564e-08, 2.6400e-02, 9.4562e-08, 1.5222e-07,
        1.4024e-02, 1.6254e-02, 4.3156e-02, 4.3272e-02, 1.9726e-07, 8.7526e-08,
        5.3257e-08, 1.9504e-02, 2.1158e-07, 1.7335e-07, 7.7701e-02, 7.2748e-03,
        1.3953e-07, 4.8783e-08, 2.4694e-07, 9.5025e-08, 1.1694e-07, 6.8797e-03,
        1.5093e-02, 7.3042e-02, 5.8348e-03, 1.3342e-01, 2.7212e-02, 1.3696e-07,
        3.0009e-02, 7.2092e-08, 1.9514e-02, 1.5999e-07, 6.4425e-03, 3.0923e-02,
        1.9838e-07, 6.1264e-08, 1.2122e-07, 1.8689e-02, 2.8013e-02, 1.3665e-07,
        4.2159e-08, 1.7000e-07, 1.0437e-07, 9.1617e-08, 3.4811e-02, 2.4365e-07,
        6.8097e-08, 8.6669e-03, 3.8969e-03, 1.3000e-02, 9.8629e-03, 1.5740e-02,
        4.9914e-03, 9.5686e-08, 5.2100e-02, 4.6641e-02, 4.1098e-02, 8.9434e-08,
        1.3960e-07, 2.2045e-07, 7.1225e-02, 5.2225e-02, 5.0279e-02, 4.4299e-02,
        1.4365e-07, 9.5762e-03, 1.1428e-07, 1.0352e-02, 1.2945e-07, 8.9915e-08,
        2.4365e-07, 1.4322e-01, 8.9431e-08, 1.1594e-07, 4.5821e-02, 1.4988e-07,
        4.0871e-08, 1.3930e-07, 1.2156e-07, 2.9799e-02, 1.4011e-07, 9.1491e-03,
        1.6205e-07, 3.1786e-02, 3.1952e-07, 1.9686e-02, 7.1651e-08, 1.8091e-07,
        5.7140e-03, 7.9130e-02, 5.8090e-08, 7.8120e-08, 2.2247e-02, 7.7514e-08,
        3.7072e-02, 2.4823e-02, 4.2159e-08, 6.3054e-08, 1.5470e-07, 7.7366e-08,
        7.6169e-08, 1.6445e-02, 4.5160e-08, 4.2159e-08, 2.1433e-07, 9.5814e-03,
        1.3495e-02, 4.9700e-02, 8.6801e-08, 1.0869e-03, 6.5835e-08, 8.6093e-02,
        4.4309e-02, 4.0491e-02, 6.9096e-08, 2.6559e-02, 8.8776e-08, 6.1445e-08,
        3.0123e-02, 1.6737e-07, 2.2695e-02, 1.1033e-02, 1.1455e-02, 5.1283e-02,
        8.3385e-08, 4.7653e-08, 1.3537e-07, 3.1333e-08, 2.3927e-02, 6.4741e-02,
        1.1520e-07, 4.5381e-08, 1.9323e-07, 5.5191e-03, 1.1356e-07, 1.6906e-07,
        4.5381e-08, 1.0583e-07, 1.4180e-01, 4.8798e-08, 2.1227e-01, 3.1359e-04,
        4.4004e-02, 7.1654e-08, 1.5416e-01, 1.5512e-01, 1.1858e-07, 3.9558e-08,
        4.9001e-08, 2.8070e-07, 9.5998e-03, 1.0127e-02, 3.7431e-02, 4.7559e-08,
        1.5098e-02, 1.1548e-07, 8.6055e-03, 2.5240e-02, 6.0515e-08, 1.3425e-07,
        1.2386e-02, 9.6625e-03, 1.2151e-07, 7.2489e-06, 4.4926e-02, 1.6098e-07,
        8.1904e-08, 9.4480e-03, 8.3456e-02, 6.1505e-08, 1.3557e-07, 1.1260e-07,
        8.9434e-08, 4.9165e-02, 1.8545e-02, 8.6705e-08, 1.2429e-07, 7.3949e-03,
        4.0485e-02, 1.0147e-02, 1.0903e-07, 2.9430e-02, 3.2068e-08, 6.0516e-08,
        1.3784e-07, 1.3896e-07, 9.4961e-02, 3.1305e-07, 5.4452e-08, 6.5303e-02,
        3.2234e-02, 7.0992e-02, 5.0661e-08, 1.1545e-02, 4.0527e-02, 3.9412e-02,
        1.7051e-07, 1.2459e-01, 1.6623e-07, 2.9804e-02, 9.1918e-03, 1.1775e-07,
        2.3212e-07, 4.6518e-08, 5.0257e-02, 1.6132e-07, 1.2651e-02, 8.9712e-08,
        3.9556e-08, 9.3581e-02, 1.9063e-02, 1.4417e-07, 1.1280e-07, 6.8427e-08,
        4.3556e-02, 3.2137e-08, 1.2718e-07, 5.1542e-08, 5.4452e-08, 2.7257e-02,
        3.1918e-02, 1.6900e-07, 1.7355e-07, 7.7783e-08, 1.2134e-07, 1.5551e-07,
        5.1135e-02, 1.0701e-02, 6.2875e-03, 2.5012e-02, 7.6924e-08, 1.1589e-07,
        4.2159e-08, 2.0115e-01, 4.1270e-08, 3.1727e-03, 3.9985e-02, 2.5846e-07,
        1.7637e-02, 6.4505e-08, 1.2548e-01, 2.8603e-02, 2.3140e-07, 1.9810e-07,
        2.6381e-02, 2.2134e-07, 4.6972e-08, 9.0497e-09, 9.0393e-08, 2.9245e-02,
        7.9799e-02, 4.5010e-02, 4.8226e-02, 5.0329e-08, 4.9162e-03, 2.4474e-02,
        9.9339e-08, 2.0138e-02, 2.5920e-02, 6.0277e-03, 1.4409e-02, 1.2255e-07,
        2.0286e-02, 7.7678e-08, 3.6161e-02, 7.7523e-08, 1.3901e-07, 1.4578e-07,
        5.0764e-08, 7.6379e-03, 1.4670e-01, 1.1277e-03, 5.7343e-02, 1.1751e-02,
        9.0846e-08, 1.9722e-02, 2.9333e-02, 7.5385e-03, 6.7267e-08, 1.3835e-07,
        5.1212e-08, 9.9040e-08, 1.1562e-07, 2.4199e-02, 5.4548e-02, 9.7391e-08,
        1.2739e-07, 6.4831e-02, 5.2938e-02, 1.5492e-07, 1.8030e-07, 5.1080e-08,
        2.5416e-02, 1.0865e-02, 1.4015e-07, 3.4865e-08, 1.0399e-07, 6.8959e-02,
        1.3691e-07, 2.3791e-02, 4.8056e-08, 1.7912e-07, 1.9986e-02, 4.5530e-08,
        2.4943e-02, 3.8792e-02, 8.5595e-08, 1.7472e-07, 3.4343e-02, 6.2968e-08,
        1.4802e-07, 6.2627e-02, 1.3391e-02, 2.2022e-02, 2.5947e-02, 1.8582e-01,
        2.2268e-03, 7.7739e-02, 1.5351e-07, 1.6372e-07, 1.2180e-02, 5.6084e-03,
        2.8540e-02, 9.0709e-08, 1.5939e-07, 6.9649e-08, 1.2476e-07, 4.9283e-02,
        1.2460e-02, 1.1374e-07, 5.2964e-02, 1.7809e-07, 6.8097e-08, 7.5358e-03,
        3.6327e-08, 3.8038e-02, 1.2046e-07, 7.0197e-08, 2.3374e-07, 1.8898e-07,
        6.9882e-03, 3.6295e-02, 1.1677e-07, 1.0349e-07, 2.0210e-07, 2.4365e-07,
        9.3861e-08, 2.0520e-02, 8.9561e-08, 9.7392e-08, 1.8809e-07, 4.7696e-03,
        4.5869e-03, 2.8859e-03, 1.2490e-02, 5.7179e-02, 1.4539e-03, 1.5039e-07,
        3.4865e-08, 4.8809e-02, 1.1599e-07, 8.4490e-08, 1.1512e-07, 6.8832e-02,
        9.0709e-08, 2.2478e-02, 1.2500e-07, 1.7335e-07, 6.1474e-08, 4.8884e-08,
        1.1411e-07, 2.1433e-07, 7.1255e-08, 4.5489e-02, 8.5504e-03, 1.1585e-07,
        1.5832e-07, 4.9965e-08, 1.7223e-07, 2.8980e-02, 1.8052e-07, 5.9575e-03,
        5.0685e-02, 3.3787e-02, 8.7041e-03, 2.1433e-07, 9.6630e-08, 3.1070e-08,
        9.3974e-08, 9.0862e-02, 1.2783e-07, 1.9071e-07, 6.3988e-02, 1.7335e-07,
        1.6331e-07, 5.1536e-08], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.5331e-07, 1.3666e-07, 6.5907e-07, 1.0505e-01, 4.4692e-07, 2.1245e-07,
        7.9991e-02, 6.6334e-07, 8.0337e-02, 1.1940e-07, 1.0734e-01, 1.3666e-07,
        1.0758e-01, 4.0608e-07, 1.7851e-07, 2.7975e-07, 3.6969e-07, 1.0182e-01,
        1.5897e-07, 4.8187e-07, 3.2728e-07, 6.4021e-07, 8.9436e-02, 4.7415e-07,
        1.1940e-07, 1.0864e-07, 1.1940e-07, 4.3970e-07, 3.4946e-07, 1.1940e-07,
        3.2497e-07, 2.6530e-07, 4.7415e-07, 3.1851e-07, 2.8265e-07, 2.2313e-07,
        4.0608e-07, 4.0608e-07, 3.2674e-07, 1.9851e-07, 3.4946e-07, 1.1940e-07,
        9.4776e-08, 2.2313e-07, 5.0492e-07, 1.3297e-07, 4.0608e-07, 1.1940e-07,
        3.4946e-07, 1.3297e-07, 4.8187e-07, 3.5861e-07, 2.8265e-07, 6.4021e-07,
        1.9851e-07, 1.1940e-07, 6.4021e-07, 4.8187e-07, 9.3929e-02, 4.7415e-07,
        2.8265e-07, 1.2055e-01, 4.3970e-07, 1.2120e-01, 1.1268e-01, 8.7944e-02,
        6.5311e-02, 2.6530e-07, 3.5861e-07, 9.9784e-02, 1.3666e-07, 4.8187e-07,
        4.0609e-07, 1.1940e-07, 2.5005e-07, 1.4042e-07, 8.4926e-02, 4.0608e-07,
        1.3664e-01, 1.3297e-07, 1.1940e-07, 1.0822e-01, 1.0379e-01, 8.7319e-02,
        7.7497e-02, 1.1940e-07, 1.3666e-07, 7.1136e-07, 9.4776e-08, 7.2034e-02,
        4.8187e-07, 1.6337e-07, 1.0232e-01, 1.6337e-07, 3.2497e-07, 1.3666e-07,
        3.1851e-07, 5.2899e-07, 8.8737e-02, 2.6530e-07, 1.0023e-01, 1.1940e-07,
        4.4692e-07, 1.1940e-07, 2.0320e-07, 4.8187e-07, 6.5906e-07, 2.8265e-07,
        1.5387e-07, 6.0687e-02, 4.7415e-07, 3.1851e-07, 7.1136e-07, 4.8187e-07,
        1.3666e-07, 2.6530e-07, 4.0608e-07, 6.4021e-07, 5.2899e-07, 1.0864e-07,
        1.9827e-07, 1.1763e-01, 1.1031e-01, 1.0864e-07, 3.2878e-07, 1.1940e-07,
        1.3666e-07, 1.1940e-07, 9.4776e-08, 2.8265e-07, 7.1136e-07, 4.8187e-07,
        1.1940e-07, 1.1940e-07, 1.5897e-07, 2.7975e-07, 1.1710e-01, 2.8265e-07,
        3.1851e-07, 3.6969e-07, 2.0320e-07, 1.0759e-01, 6.5424e-07, 9.6793e-02,
        6.4021e-07, 1.4519e-07, 4.8187e-07, 9.0179e-08, 2.6430e-02, 4.0608e-07,
        1.4519e-07, 3.1851e-07, 1.3666e-07, 4.7415e-07, 1.3666e-07, 1.8185e-07,
        1.1940e-07, 4.3970e-07, 1.9827e-07, 2.8524e-07, 1.1071e-01, 4.8187e-07,
        1.4519e-07, 2.8265e-07, 1.8185e-07, 6.4021e-07, 5.0492e-07, 8.1681e-02,
        1.0864e-07, 3.1851e-07, 1.4162e-07, 4.0608e-07, 9.4776e-08, 1.1525e-01,
        4.0608e-07, 9.0179e-08, 4.8187e-07, 4.8187e-07, 3.1851e-07, 1.6408e-01,
        1.3297e-07, 1.4162e-07, 7.7572e-02, 2.8265e-07, 1.4162e-07, 2.6530e-07,
        2.5465e-07, 1.1940e-07, 1.0654e-01, 9.7001e-02, 2.8265e-07, 1.3666e-07,
        4.8187e-07, 8.5196e-02, 4.8187e-07, 6.6334e-07, 1.6337e-07, 1.1450e-01,
        2.6530e-07, 3.2497e-07, 2.6530e-07, 2.8265e-07, 8.6416e-07, 8.6237e-02,
        1.3297e-07, 6.3741e-07, 4.8187e-07, 2.0320e-07, 4.8187e-07, 1.3297e-07,
        2.2313e-07, 9.4776e-08, 1.0864e-07, 4.8187e-07, 1.0475e-01, 6.4021e-07,
        1.0172e-01, 8.6416e-07, 2.4166e-07, 1.1940e-07, 1.1125e-01, 6.6333e-07,
        9.7784e-02, 1.3666e-07, 4.7415e-07, 4.7415e-07, 1.4162e-07, 1.1964e-01,
        1.0030e-01, 1.4519e-07, 1.4525e-01, 6.6334e-07, 1.3666e-07, 1.1940e-07,
        4.0608e-07, 1.1940e-07, 8.3795e-02, 9.1213e-02, 1.0878e-01, 1.1940e-07,
        7.0555e-02, 1.1940e-07, 1.1940e-07, 1.1137e-01, 4.8187e-07, 1.4162e-07,
        1.2800e-01, 3.8853e-07, 1.9851e-07, 9.2914e-02, 4.8187e-07, 2.6530e-07,
        8.6416e-07, 8.6416e-07, 1.9851e-07, 6.7387e-02], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([3.7050e-06, 7.1756e-02, 3.7802e-06, 5.8923e-07, 7.8905e-07, 6.7855e-07,
        5.5978e-02, 1.6230e-06, 2.3714e-06, 2.5688e-06, 3.7802e-06, 7.6729e-07,
        6.7855e-07, 2.3714e-06, 7.8905e-07, 1.4209e-06, 1.9939e-06, 6.7855e-07,
        8.6346e-07, 4.8391e-07, 4.4986e-06, 6.7855e-07, 2.4932e-06, 6.7855e-07,
        1.9976e-06, 9.1254e-07, 1.9976e-06, 5.8923e-07, 3.3534e-02, 2.4932e-06,
        7.6729e-07, 3.6635e-06, 1.5236e-07, 3.7802e-06, 1.9877e-06, 1.9976e-06,
        1.6230e-06, 1.6230e-06, 7.6626e-02, 2.2740e-06, 1.1530e-06, 1.2209e-06,
        6.2525e-02, 6.7855e-07, 1.0105e-06, 2.3714e-06, 1.1530e-06, 1.0206e-06,
        5.1230e-02, 6.7855e-07, 3.7029e-06, 7.6729e-07, 2.3714e-06, 2.4826e-06,
        2.5688e-06, 1.4977e-06, 5.4948e-02, 7.6729e-07, 1.0206e-06, 1.1966e-06,
        1.1530e-06, 1.7169e-06, 6.1928e-02, 1.0583e-06, 1.9877e-06, 1.7169e-06,
        1.6230e-06, 8.6345e-07, 4.1979e-02, 5.8923e-07, 2.5688e-06, 5.3080e-02,
        1.9976e-06, 6.7855e-07, 9.2639e-07, 6.7854e-07, 2.3870e-07, 7.6729e-07,
        1.9877e-06, 1.2108e-06, 3.7069e-06, 2.4826e-06, 1.1307e-06, 7.5952e-07,
        1.9877e-06, 2.3714e-06, 7.6729e-07, 1.1966e-06, 1.9877e-06, 1.7169e-06,
        2.3714e-06, 6.3922e-02, 6.7855e-07, 9.0761e-07, 1.1004e-06, 7.5952e-07,
        1.9976e-06, 9.2639e-07, 1.1004e-06, 1.7305e-06, 7.6729e-07, 1.7169e-06,
        2.2740e-06, 1.9976e-06, 6.7855e-07, 1.4796e-06, 2.9738e-06, 3.7017e-06,
        1.7169e-06, 2.3714e-06, 8.1222e-07, 2.9738e-06, 1.7169e-06, 7.5952e-07,
        9.2639e-07, 1.1966e-06, 6.7855e-07, 1.4209e-06, 1.9976e-06, 6.7096e-02,
        1.0539e-06, 9.1254e-07, 7.0465e-02, 1.8478e-06, 6.9041e-07, 2.4932e-06,
        5.9589e-07, 1.1530e-06, 3.7802e-06, 1.9976e-06, 1.9976e-06, 7.8905e-07,
        5.5740e-02, 1.7169e-06, 1.6230e-06, 4.6763e-02, 7.8023e-02, 2.4932e-06,
        2.5688e-06, 1.1530e-06, 9.2959e-07, 3.6646e-06, 2.4826e-06, 1.4796e-06,
        7.7498e-02, 1.9976e-06, 7.3218e-02, 1.7169e-06, 1.7169e-06, 1.2108e-06,
        2.3994e-06, 9.2639e-07, 1.1966e-06, 2.9738e-06, 1.9877e-06, 1.7169e-06,
        9.2639e-07, 5.8923e-07, 5.8923e-07, 1.6387e-06, 1.9976e-06, 1.2209e-06,
        4.8391e-07, 6.6784e-02, 5.7682e-08, 1.8478e-06, 6.1504e-02, 1.9976e-06,
        4.6144e-02, 2.5041e-02, 6.7855e-07, 1.1530e-06, 1.9877e-06, 5.9589e-07,
        1.1307e-06, 3.7256e-07, 1.2477e-06, 4.8391e-07, 1.9976e-06, 1.9976e-06,
        1.9939e-06, 9.2639e-07, 6.7855e-07, 6.7855e-07, 1.2209e-06, 3.5932e-07,
        6.7855e-07, 2.4932e-06, 5.9589e-07, 2.7303e-02, 1.9976e-06, 7.6397e-02,
        1.6230e-06, 7.4553e-02, 1.1575e-06, 1.9976e-06, 1.7169e-06, 6.9363e-02,
        1.9877e-06, 1.9877e-06, 8.6345e-07, 1.9976e-06, 4.8391e-07, 4.6303e-07,
        1.6718e-06, 6.6546e-02, 6.7855e-07, 8.6346e-07, 6.1776e-07, 1.9877e-06,
        3.8019e-07, 4.1824e-06, 1.7169e-06, 1.3732e-06, 5.9589e-07, 5.9589e-07,
        4.8391e-07, 1.4209e-06, 6.7726e-02, 1.2209e-06, 8.6345e-07, 2.2964e-08,
        4.8391e-07, 3.7802e-06, 1.0144e-06, 2.3714e-06, 1.2649e-06, 1.9976e-06,
        1.9877e-06, 1.1530e-06, 1.9578e-06, 5.9312e-07, 7.8076e-02, 1.9976e-06,
        9.2639e-07, 5.8923e-07, 3.6646e-06, 6.1540e-02, 4.9029e-02, 5.3405e-02,
        4.8391e-07, 7.8175e-02, 5.9589e-07, 1.4209e-06, 4.0647e-06, 2.4932e-06,
        6.7855e-07, 1.7169e-06, 1.0105e-06, 9.2639e-07, 7.6267e-07, 3.5854e-06,
        7.6729e-07, 1.0105e-06, 6.1184e-02, 8.6345e-07], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([2.6475e-07, 1.7501e-07, 2.5241e-07,  ..., 4.0350e-07, 1.7501e-07,
        3.8328e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([8.0093e-07, 2.7522e-07, 4.0379e-07,  ..., 1.3595e-07, 8.0552e-07,
        8.5022e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([2.8641e-07, 1.6957e-06, 2.2395e-07, 4.8535e-07, 1.4515e-06, 1.5587e-06,
        5.3229e-07, 5.1823e-07, 1.5587e-06, 3.9403e-07, 4.2849e-07, 7.5929e-07,
        4.7925e-07, 3.5408e-02, 8.4592e-07, 1.7838e-06, 2.1846e-06, 2.6788e-07,
        1.9756e-01, 6.0764e-07, 4.3297e-07, 3.0833e-07, 3.9968e-02, 9.9844e-07,
        3.9944e-07, 7.5929e-07, 4.8565e-07, 1.5587e-06, 1.3349e-06, 2.2941e-06,
        1.5587e-06, 3.0686e-06, 5.8560e-07, 1.1440e-06, 1.2568e-06, 1.1910e-06,
        4.3297e-07, 2.7722e-02, 1.5488e-06, 2.2924e-06, 8.4137e-07, 3.2950e-02,
        2.5594e-07, 1.5587e-06, 6.8655e-07, 4.1381e-02, 7.2471e-07, 1.5488e-06,
        1.5715e-06, 2.5594e-07, 1.5715e-06, 1.1028e-06, 1.5480e-01, 1.6397e-06,
        2.6633e-02, 1.5715e-06, 5.5248e-07, 2.6788e-07, 2.6788e-07, 9.8056e-07,
        2.5594e-07, 9.2289e-07, 3.0164e-02, 4.8565e-07, 3.1904e-02, 2.6788e-07,
        7.2724e-07, 3.7626e-02, 4.0610e-02, 1.0048e-06, 6.4791e-07, 9.5197e-07,
        5.7022e-07, 9.0657e-07, 5.5248e-07, 3.0309e-02, 4.8320e-07, 8.7391e-07,
        1.3349e-06, 8.4592e-07, 3.6057e-02, 1.5397e-06, 2.8336e-02, 2.1731e-06,
        9.0657e-07, 2.9776e-02, 2.3692e-06, 2.6414e-02, 1.7838e-06, 1.3349e-06,
        7.8503e-07, 4.1781e-02, 7.6897e-07, 3.0833e-07, 7.5929e-07, 5.5248e-07,
        2.4867e-02, 1.0414e-06, 2.6788e-07, 2.4011e-06, 1.7732e-07, 6.4872e-07,
        7.3497e-07, 5.8114e-07, 1.1508e-06, 1.3601e-06, 7.7575e-07, 1.0850e-06,
        5.8114e-07, 4.0257e-02, 1.2568e-06, 2.6788e-07, 2.6788e-07, 3.3118e-02,
        9.2289e-07, 4.6461e-07, 3.2004e-02, 1.1998e-06, 2.5594e-07, 1.6781e-06,
        4.0047e-02, 3.8854e-07, 5.8560e-07, 5.5248e-07, 1.5088e-06, 8.1427e-07,
        3.0833e-07, 7.2724e-07, 2.6446e-02, 8.4137e-07, 1.0673e-06, 1.2731e-06,
        7.6540e-07, 8.1427e-07, 7.3497e-07, 1.3410e-06, 6.4791e-07, 1.9915e-07,
        2.7813e-02, 6.4872e-07, 6.4791e-07, 2.8073e-07, 6.4872e-07, 9.5272e-07,
        5.0985e-02, 1.9063e-02, 1.6397e-06, 1.4054e-06, 1.1177e-02, 9.9844e-07,
        2.2941e-06, 5.0197e-07, 1.0340e-06, 3.6169e-02, 2.4018e-06, 2.9929e-02,
        1.3526e-06, 5.9216e-07, 8.9719e-07, 1.5397e-06, 5.7048e-07, 5.1348e-07,
        5.8560e-07, 1.1188e-06, 2.3734e-06, 2.7821e-07, 7.6897e-07, 3.4422e-02,
        6.4872e-07, 5.8628e-03, 1.3526e-06, 6.6938e-07, 7.8817e-07, 6.4791e-07,
        1.5587e-06, 9.8056e-07, 1.5488e-06, 4.8565e-07, 1.5488e-06, 1.7732e-07,
        2.6788e-07, 5.9992e-07, 3.9944e-07, 1.5587e-06, 1.0312e-06, 7.7575e-07,
        1.0850e-06, 5.1978e-07, 5.5248e-07, 3.5684e-02, 9.9844e-07, 1.5088e-06,
        5.5248e-07, 3.8854e-07, 3.0357e-02, 8.9719e-07, 5.9992e-07, 5.0962e-07,
        6.7892e-07, 7.9173e-07, 2.1681e-07, 4.6234e-07, 3.0833e-07, 1.4515e-06,
        1.5088e-06, 1.6957e-06, 2.8924e-02, 6.4011e-07, 2.9796e-02, 3.2097e-02,
        3.6048e-07, 2.5594e-07, 4.8320e-07, 6.4872e-07, 7.0650e-07, 4.0518e-02,
        1.6397e-06, 3.0833e-07, 3.2879e-02, 2.4869e-02, 3.2704e-02, 2.5594e-07,
        8.9719e-07, 1.8234e-01, 1.1417e-06, 1.3349e-06, 9.8760e-07, 5.8073e-07,
        6.4872e-07, 4.6234e-07, 1.6397e-06, 1.5587e-06, 3.3433e-02, 1.6957e-06,
        4.3297e-07, 2.8719e-02, 9.6608e-07, 4.7925e-07, 3.7878e-02, 1.4515e-06,
        2.6572e-07, 3.5588e-02, 9.8759e-07, 1.6397e-06, 1.6397e-06, 7.3497e-07,
        1.5587e-06, 8.7669e-07, 2.3107e-02, 1.1028e-06, 1.2568e-06, 2.8284e-02,
        1.4515e-06, 8.4137e-07, 2.6788e-07, 5.5560e-07], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([5.8048e-02, 5.5519e-02, 2.7287e-06, 1.0883e-06, 2.7287e-06, 1.4508e-06,
        4.2604e-02, 9.3436e-07, 2.9093e-06, 4.6103e-02, 2.7287e-06, 1.0908e-06,
        1.8715e-06, 2.9093e-06, 9.2564e-07, 2.9093e-06, 1.6064e-06, 1.1943e-06,
        1.3078e-06, 4.5112e-06, 9.6286e-07, 1.3189e-06, 1.0603e-06, 4.5166e-07,
        5.0024e-02, 5.4295e-06, 2.3347e-06, 5.4236e-06, 1.3971e-06, 4.2229e-06,
        2.0425e-06, 5.3511e-02, 2.9093e-06, 1.5299e-06, 8.4299e-07, 1.2003e-06,
        3.2229e-02, 2.3335e-06, 3.5636e-02, 2.3335e-06, 1.5790e-06, 9.2627e-07,
        9.6286e-07, 8.4045e-07, 1.7949e-06, 4.2396e-06, 2.8201e-06, 8.4045e-07,
        4.2165e-02, 1.3976e-06, 1.2593e-06, 1.2003e-06, 4.0666e-08, 2.3335e-06,
        5.9982e-02, 6.1066e-07, 5.7282e-02, 2.6158e-06, 5.4212e-06, 1.3189e-06,
        2.7287e-06, 5.8905e-07, 2.7287e-06, 4.1880e-06, 1.2003e-06, 2.1165e-06,
        2.0042e-07, 2.9093e-06, 5.8773e-02, 5.4959e-02, 1.7949e-06, 1.9492e-06,
        9.3436e-07, 1.8094e-06, 4.8898e-02, 2.9093e-06, 1.9492e-06, 7.7114e-07,
        9.6286e-07, 2.2830e-06, 4.1880e-06, 5.8905e-07, 1.4673e-01, 8.4045e-07,
        2.0323e-06, 2.7884e-02, 4.0436e-02, 3.4079e-07, 3.8706e-02, 3.6431e-06,
        4.5112e-06, 2.8432e-06, 2.9093e-06, 8.4045e-07, 1.5152e-01, 9.6286e-07,
        2.4121e-06, 3.9586e-02, 4.2244e-02, 2.8541e-02, 2.0425e-06, 5.9590e-02,
        2.0425e-06, 8.4045e-07, 2.3159e-06, 5.7566e-02, 5.6141e-02, 2.9093e-06,
        5.0811e-06, 2.0323e-06, 4.5037e-02, 2.9787e-06, 4.8048e-02, 1.0001e-06,
        1.1579e-06, 1.6064e-06, 2.9093e-06, 2.6158e-06, 1.9360e-06, 2.2444e-06,
        6.3788e-07, 5.4306e-06, 9.2627e-07, 4.7552e-02, 2.7287e-06, 2.3159e-06,
        1.2003e-06, 5.9157e-02, 2.7287e-06, 7.7114e-07, 2.9093e-06, 4.1816e-02,
        1.3976e-06, 6.3788e-07, 9.6286e-07, 2.7223e-06, 4.6722e-02, 9.2627e-07,
        3.4079e-07, 2.6158e-06, 2.3716e-06, 2.1411e-06, 9.0960e-07, 4.2396e-06,
        5.9245e-07, 4.2231e-06, 9.0960e-07, 1.2151e-06, 2.0425e-06, 4.1379e-06,
        1.2723e-02, 2.9093e-06, 9.2564e-07, 2.2444e-06, 1.0603e-06, 1.9360e-06,
        8.4045e-07, 5.0133e-02, 2.3159e-06, 8.4045e-07, 6.3587e-07, 1.1943e-06,
        1.3189e-06, 5.5277e-02, 2.8432e-06, 8.4045e-07, 4.2396e-06, 1.0883e-06,
        4.2372e-02, 5.8905e-07, 1.8033e-06, 6.3788e-07, 5.2119e-02, 6.8233e-07,
        1.2151e-06, 9.6286e-07, 4.1317e-06, 4.7231e-02, 2.3335e-06, 6.5712e-07,
        2.0425e-06, 3.7808e-02, 1.2003e-06, 2.9093e-06, 6.5712e-07, 2.3159e-06,
        2.0425e-06, 2.8345e-02, 2.9093e-06, 1.0848e-01, 6.1066e-07, 3.4648e-02,
        6.2622e-02, 6.5712e-07, 1.0908e-06, 2.1204e-06, 2.7287e-06, 1.2003e-06,
        8.5592e-07, 7.7114e-07, 9.0960e-07, 9.3436e-07, 2.1204e-06, 2.9093e-06,
        2.9093e-06, 2.1165e-06, 2.5930e-02, 1.6064e-06, 1.1842e-06, 5.0167e-02,
        2.3161e-02, 9.6286e-07, 2.2038e-02, 2.9093e-06, 5.1152e-02, 2.7843e-06,
        1.1943e-06, 4.5112e-06, 1.0883e-06, 2.9093e-06, 9.6286e-07, 3.6389e-07,
        3.9557e-06, 4.3954e-02, 2.1411e-06, 2.9093e-06, 6.3788e-07, 1.8094e-06,
        2.1165e-06, 5.3271e-02, 1.0603e-06, 6.3788e-07, 1.9648e-06, 2.7287e-06,
        2.3159e-06, 1.1943e-06, 2.3159e-06, 1.3189e-06, 8.1209e-02, 1.2003e-06,
        2.1411e-06, 2.1165e-06, 9.2627e-07, 1.3976e-06, 1.9648e-06, 4.1771e-02,
        6.0260e-02, 1.9836e-06, 1.0603e-06, 2.0920e-06, 2.6158e-06, 9.3217e-07,
        4.1879e-06, 1.4485e-06, 4.0657e-02, 4.2248e-06], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([3.8634e-07, 4.3481e-08, 2.5232e-07,  ..., 6.3558e-08, 1.6926e-07,
        1.0470e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.2034e-01, 1.4666e-06, 2.9585e-07, 8.6560e-07, 5.1449e-02, 3.0453e-07,
        1.5586e-07, 3.9940e-02, 4.7785e-02, 1.2654e-06, 2.5516e-07, 1.4104e-01,
        3.1528e-07, 4.8994e-02, 2.8217e-07, 5.4909e-07, 5.3016e-07, 5.0037e-02,
        5.6822e-02, 2.2462e-06, 1.4453e-06, 7.5741e-07, 4.9736e-02, 3.6125e-07,
        5.0241e-02, 4.6895e-07, 2.6478e-06, 1.1133e-06, 5.6137e-02, 5.4025e-02,
        1.9552e-06, 5.6531e-07, 4.4775e-02, 4.9936e-07, 7.5343e-07, 5.1359e-02,
        4.4501e-02, 3.7407e-02, 7.1057e-07, 1.0256e-06, 6.0699e-07, 1.0109e-06,
        2.5168e-07, 6.5708e-02, 5.1875e-02, 4.5175e-02, 5.4664e-02, 4.3087e-02,
        3.4580e-07, 1.4759e-01, 4.6930e-02, 1.4509e-06, 1.8280e-01, 5.5795e-02,
        5.0345e-02, 4.8349e-02, 4.8483e-02, 5.3025e-02, 4.0403e-07, 5.4935e-02,
        1.2414e-06, 5.3791e-02, 2.5168e-07, 2.1480e-06, 5.7013e-07, 7.7350e-07,
        2.8217e-07, 5.1404e-02, 7.4138e-07, 4.7421e-02, 4.7784e-02, 4.1019e-07,
        7.1057e-07, 3.9775e-02, 6.0287e-07, 4.8120e-02, 4.8767e-02, 5.0059e-02,
        5.7013e-07, 1.4509e-06, 5.3450e-07, 1.1966e-06, 7.1057e-07, 2.8217e-07,
        5.8154e-02, 5.0465e-02, 5.1304e-02, 5.1270e-02, 1.0256e-06, 2.2017e-06,
        4.9326e-02, 7.4053e-07, 2.8217e-07, 5.6254e-02, 6.3668e-07, 4.0491e-07,
        5.3767e-02, 4.9660e-02, 6.6861e-07, 4.2689e-07, 1.7123e-06, 4.7083e-02,
        5.5699e-02, 5.3526e-02, 9.4245e-07, 5.3029e-02, 5.6082e-02, 2.5217e-07,
        1.4453e-06, 1.5305e-06, 5.6191e-07, 4.2689e-07, 4.4288e-02, 4.3921e-02,
        5.3016e-07, 7.7350e-07, 5.5728e-02, 5.3205e-02, 1.3897e-06, 4.7076e-02,
        8.3513e-07, 5.3829e-02, 2.3120e-06, 5.6948e-02, 4.5650e-07, 4.2689e-07,
        2.2196e-06, 3.7098e-07, 3.0453e-07, 4.7704e-02, 1.2654e-06, 4.8753e-02,
        4.7239e-07, 5.3450e-07, 4.8505e-07, 4.0439e-02, 1.0469e-06, 5.0563e-02,
        4.6895e-07, 4.2141e-02, 5.7867e-02, 5.2318e-02, 4.2689e-07, 6.2960e-02,
        5.3600e-02, 4.2361e-02, 2.0381e-06, 2.2333e-06, 1.4666e-06, 5.3749e-02,
        3.1549e-02, 7.4053e-07, 1.6402e-06, 1.1133e-06, 4.7341e-02, 5.4783e-07,
        1.8877e-06, 1.2414e-06, 6.0699e-07, 2.6478e-06, 3.8122e-07, 4.4621e-02,
        4.6490e-07, 5.6007e-07, 1.3897e-06, 5.2263e-02, 4.7279e-02, 5.4359e-07,
        6.9629e-07, 5.2583e-02, 1.1570e-06, 6.3668e-07, 2.1557e-06, 1.4453e-06,
        5.3658e-02, 5.2086e-02, 5.6729e-02, 6.4112e-02, 4.8715e-02, 5.6531e-07,
        2.1557e-06, 7.1057e-07, 7.1057e-07, 7.3114e-07, 5.0669e-02, 5.0279e-02,
        5.0924e-02, 5.6191e-07, 9.4075e-07, 5.3913e-02, 1.4118e-06, 1.6547e-07,
        9.1924e-07, 1.9552e-06, 5.5232e-02, 1.4453e-06, 4.7097e-02, 5.3341e-02,
        4.7632e-02, 2.2835e-06, 3.0540e-02, 1.4509e-06, 5.4983e-02, 5.4526e-02,
        1.0256e-06, 6.2519e-02, 1.5305e-06, 5.4799e-02, 5.9666e-02, 5.3016e-07,
        6.9235e-07, 7.1057e-07, 1.5305e-06, 7.7350e-07, 6.0699e-07, 4.9322e-02,
        6.8065e-07, 1.4509e-06, 4.5650e-07, 5.4887e-02, 5.4909e-07, 4.6895e-07,
        5.4036e-02, 4.8505e-07, 2.1557e-06, 5.4887e-02, 5.5163e-02, 3.6125e-07,
        4.6701e-02, 1.0256e-06, 4.7347e-02, 7.2662e-07, 5.6648e-02, 5.7843e-02,
        4.5813e-02, 6.1871e-02, 3.5134e-02, 1.0256e-06, 5.8570e-02, 5.1753e-02,
        7.2662e-07, 1.3254e-01, 6.0321e-02, 6.4852e-07, 5.9469e-02, 6.3770e-07,
        4.9802e-02, 7.5343e-07, 5.4579e-02, 1.4453e-06, 2.8217e-07, 4.8876e-02,
        1.8877e-06, 5.7761e-02, 5.4336e-02, 3.6391e-02], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([1.0546e-01, 1.7498e-06, 7.5220e-06, 2.4581e-06, 3.2058e-06, 4.0662e-06,
        8.0415e-02, 1.4691e-07, 2.8895e-06, 3.6326e-06, 8.0406e-02, 8.4379e-02,
        2.3220e-06, 5.2913e-06, 1.1224e-05, 4.7348e-06, 2.3209e-06, 3.2347e-02,
        4.6048e-06, 1.9224e-06, 2.6048e-06, 3.4330e-06, 2.4053e-06, 2.7356e-06,
        4.7868e-02, 3.7071e-02, 3.8304e-06, 1.1989e-01, 4.9559e-06, 3.8300e-06,
        3.6529e-06, 5.7848e-06, 6.2573e-07, 1.6331e-06, 8.6102e-02, 1.8473e-06,
        9.9290e-02, 9.2617e-02, 4.6804e-06, 7.1610e-02, 9.0344e-02, 3.1864e-06,
        4.0578e-06, 1.6167e-06, 2.1661e-06, 2.7356e-06, 1.6331e-06, 2.0314e-06,
        4.3215e-06, 3.8644e-02, 1.1929e-06, 7.4866e-06, 7.6636e-02, 9.5606e-06,
        1.6883e-06, 3.9151e-06, 4.1357e-06, 1.0007e-06, 3.5833e-06, 3.4020e-02,
        3.1394e-06, 3.5686e-02, 6.8017e-02, 1.0553e-01, 3.7589e-06, 2.8161e-06,
        5.1430e-06, 8.8800e-02, 2.7070e-06, 1.0778e-01, 8.8481e-02, 7.9190e-02,
        6.5927e-06, 1.9224e-06, 9.8351e-02, 6.5664e-06, 3.7706e-02, 6.1562e-06,
        4.3910e-06, 5.8455e-02, 3.1710e-06, 4.9918e-06, 8.1752e-02, 3.0800e-06,
        3.2858e-06, 5.2341e-06, 1.8473e-06, 3.7325e-06, 7.3981e-02, 4.6415e-06,
        2.8209e-06, 7.6421e-02, 9.5606e-06, 3.4821e-06, 8.5548e-02, 6.1562e-06,
        4.7597e-02, 1.1224e-05, 5.7849e-06, 4.8311e-06, 4.8175e-06, 5.6933e-06,
        5.3971e-06, 7.6726e-02, 4.7429e-02, 8.4985e-02, 3.1394e-06, 2.8963e-06,
        5.4444e-06, 1.6331e-06, 5.9823e-06, 6.3443e-06, 2.9242e-06, 2.6909e-06,
        4.3657e-02, 7.6806e-02, 6.2949e-06, 5.8690e-06, 4.5898e-06, 4.9872e-06,
        3.9191e-06, 6.3052e-06, 3.2806e-07, 5.2910e-02, 4.7348e-06, 3.2784e-06,
        3.4008e-02, 2.4458e-06, 2.2214e-06, 1.9848e-06, 1.9580e-06, 1.5589e-06,
        1.4690e-07, 7.0921e-02, 3.1131e-06, 9.9674e-02, 3.5986e-06, 7.2758e-02,
        6.2949e-06, 1.0689e-01, 4.3215e-06, 5.3971e-06, 2.0314e-06, 1.2384e-01,
        1.2707e-06, 2.1661e-06, 5.2616e-06, 2.4093e-06, 3.4520e-02, 3.6494e-06,
        8.0696e-02, 3.2858e-06, 4.3108e-06, 2.3394e-06, 2.5540e-06, 8.9413e-02,
        3.5770e-02, 2.4985e-06, 3.8636e-06, 8.7359e-02, 3.2858e-06, 5.9385e-06,
        5.7848e-06, 6.2949e-06, 1.0564e-01, 2.3209e-06, 4.3215e-06, 2.9242e-06,
        3.6555e-02, 7.9158e-02, 5.2913e-06, 5.3821e-06, 3.2920e-02, 2.3220e-06,
        1.3934e-06, 6.9157e-06, 2.7178e-06, 3.5524e-02, 1.8528e-06, 8.7420e-02,
        4.3215e-06, 5.5978e-06, 3.2858e-06, 1.0433e-06, 7.9944e-02, 8.1038e-02,
        7.9428e-06, 3.4526e-02, 1.1362e-06, 2.2861e-06, 3.1491e-02, 3.2806e-07,
        3.4755e-02, 6.9110e-02, 4.6896e-06, 6.0035e-06, 1.4692e-07, 1.4691e-07,
        1.0758e-06, 4.2567e-06, 6.2949e-06, 2.1661e-06, 4.3562e-06, 2.7162e-06,
        3.0800e-06, 1.9696e-06, 1.6918e-06, 9.8997e-02, 1.0433e-06, 4.6804e-06,
        3.5225e-06, 8.6017e-06, 1.3900e-06, 9.2376e-02, 6.2949e-06, 3.5889e-02,
        2.3406e-06, 3.1131e-06, 6.7654e-02, 2.0722e-06, 2.1452e-06, 2.0314e-06,
        3.2947e-02, 3.7067e-06, 1.2849e-06, 4.2148e-06, 8.8452e-02, 2.9561e-06,
        4.7348e-06, 7.4408e-02, 6.6486e-06, 2.0472e-07, 1.6331e-06, 2.3262e-06,
        7.8481e-02, 2.0314e-06, 4.8661e-06, 1.1379e-06, 3.7492e-02, 4.3215e-06,
        8.6912e-02, 1.0007e-06, 3.7053e-06, 3.7640e-06, 4.0040e-06, 3.5986e-06,
        2.1492e-06, 7.9587e-02, 4.8311e-06, 1.7038e-06, 2.9645e-06, 7.7186e-02,
        4.6116e-06, 3.6529e-06, 1.1849e-06, 7.2774e-06], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([2.2958e-07, 6.0160e-07, 1.6091e-07,  ..., 1.6091e-07, 3.6000e-07,
        4.3587e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([2.8512e-06, 4.8106e-07, 9.3383e-07, 1.0842e-06, 1.8636e-06, 2.4494e-06,
        1.8608e-06, 8.9131e-07, 3.4103e-06, 8.9493e-07, 4.3735e-06, 5.1855e-07,
        2.3606e-06, 8.9261e-07, 2.2469e-06, 1.8004e-06, 1.4666e-06, 2.3166e-06,
        2.3714e-06, 1.0465e-06, 2.6558e-06, 1.6471e-06, 1.9348e-06, 1.6984e-06,
        2.0427e-06, 4.8949e-07, 6.6967e-07, 6.5270e-07, 9.7029e-02, 5.9494e-07,
        1.2045e-01, 1.6779e-06, 1.1900e-06, 5.2444e-07, 2.0182e-06, 1.7129e-06,
        2.5597e-06, 9.2462e-07, 7.3766e-02, 8.7620e-07, 7.0944e-07, 8.1613e-07,
        1.2352e-06, 1.2579e-06, 1.0008e-06, 3.0808e-07, 9.5399e-07, 1.6525e-06,
        9.5313e-07, 1.7370e-06, 6.7165e-07, 2.5597e-06, 8.7620e-07, 1.2669e-01,
        1.2542e-06, 1.3681e-06, 2.7101e-07, 1.0000e-01, 4.8408e-06, 4.6478e-07,
        1.1777e-01, 8.9546e-02, 1.3910e-06, 7.3486e-07, 4.9601e-07, 1.3752e-06,
        1.4062e-06, 1.4021e-06, 2.3266e-06, 8.7620e-07, 1.4807e-06, 1.4139e-06,
        1.0013e-06, 9.4974e-07, 7.9904e-07, 1.5718e-06, 1.8713e-06, 5.4297e-07,
        1.4021e-06, 2.0607e-06, 8.2947e-07, 1.4883e-06, 4.2109e-07, 1.5856e-01,
        1.1601e-06, 4.3414e-07, 2.2469e-06, 1.6510e-02, 1.2416e-06, 1.6142e-06,
        1.3309e-06, 1.1318e-06, 8.9493e-07, 1.6175e-06, 8.1613e-07, 1.8781e-06,
        1.9838e-02, 1.5777e-06, 1.6983e-06, 1.8067e-01, 2.3040e-06, 9.1322e-07,
        8.4502e-07, 2.0412e-02, 2.4494e-06, 1.4883e-06, 1.0953e-06, 1.1960e-06,
        1.1184e-06, 1.6643e-06, 3.8141e-07, 1.6175e-06, 2.7158e-06, 2.2726e-06,
        1.3836e-01, 6.6664e-07, 1.7631e-06, 2.7101e-07, 1.4807e-06, 9.2451e-07,
        1.5718e-06, 3.4273e-06, 1.5924e-06, 1.6749e-06, 9.2451e-07, 2.6881e-06,
        1.1947e-01, 1.3382e-06, 1.5519e-06, 2.3266e-06, 1.9725e-06, 2.4494e-06,
        1.4907e-03, 9.4818e-07, 1.8455e-06, 1.6779e-06, 3.3913e-06, 1.3012e-06,
        4.6478e-07, 2.8771e-06, 2.1656e-07, 1.7269e-06, 1.1714e-06, 9.5067e-07,
        9.1572e-07, 1.0014e-06, 1.3852e-01, 2.7158e-06, 2.8369e-06, 7.0327e-07,
        1.4556e-06, 8.0943e-07, 2.7158e-06, 7.3709e-07, 4.3101e-07, 9.4279e-07,
        3.1340e-06, 1.0492e-01, 1.9642e-06, 7.0481e-07, 4.4224e-07, 2.3266e-06,
        1.3681e-06, 1.5519e-06, 2.4333e-06, 1.0013e-06, 4.6478e-07, 4.6478e-07,
        8.7620e-07, 9.1375e-02, 1.9385e-06, 7.5150e-07, 1.0842e-06, 6.3397e-07,
        9.2064e-07, 1.4868e-06, 1.3910e-06, 3.5699e-02, 1.7870e-02, 3.2094e-06,
        9.3370e-07, 1.7890e-06, 1.4632e-06, 4.9872e-07, 1.2461e-06, 1.6643e-06,
        1.4864e-06, 2.4494e-06, 1.4807e-06, 3.5975e-08, 2.0640e-06, 1.6723e-06,
        1.2495e-06, 1.6989e-06, 9.3383e-07, 1.8505e-06, 2.0427e-06, 9.3383e-07,
        6.7165e-07, 1.6980e-06, 1.9316e-06, 1.5191e-06, 8.9131e-07, 8.9493e-07,
        8.1795e-07, 9.5399e-07, 9.3383e-07, 2.3528e-06, 8.7023e-07, 1.1758e-06,
        9.6482e-07, 4.5029e-07, 5.9494e-07, 9.3383e-07, 1.2029e-01, 2.1727e-06,
        1.6352e-06, 1.5474e-06, 1.5779e-02, 1.8218e-06, 9.2451e-07, 1.4868e-06,
        2.4134e-06, 9.1896e-07, 2.1334e-06, 1.1435e-01, 2.4494e-06, 1.3681e-06,
        1.2461e-06, 1.4807e-06, 1.4435e-06, 2.4494e-06, 1.4883e-06, 1.1116e-06,
        2.5597e-06, 1.4807e-06, 2.0769e-06, 2.0062e-06, 1.8004e-06, 1.2820e-06,
        1.3028e-06, 1.3681e-06, 1.3786e-06, 2.1727e-06, 1.1601e-06, 8.0477e-07,
        1.3662e-06, 1.2609e-06, 2.3266e-06, 1.0499e-06, 1.4021e-06, 9.4818e-07,
        1.6175e-06, 1.7726e-06, 2.4494e-06, 1.3662e-06], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([4.8087e-06, 4.4017e-06, 6.4924e-06, 3.9519e-06, 1.0199e-06, 1.5648e-06,
        6.4924e-06, 6.4924e-06, 1.3725e-05, 4.5329e-06, 5.6063e-06, 1.2087e-01,
        3.1497e-06, 5.9159e-06, 3.7378e-06, 7.5878e-06, 3.2184e-06, 1.3074e-06,
        3.9455e-06, 6.0974e-06, 5.3965e-06, 1.7951e-06, 4.6768e-06, 3.4805e-06,
        6.1078e-06, 6.2679e-06, 6.6959e-06, 3.9455e-06, 1.6711e-06, 5.3037e-06,
        2.4755e-06, 6.7942e-06, 5.4512e-06, 4.2972e-06, 5.2067e-06, 7.0424e-02,
        6.2933e-06, 1.9357e-06, 5.9444e-06, 9.7614e-06, 6.4924e-06, 6.4561e-06,
        3.7341e-06, 6.2986e-06, 7.8907e-06, 4.6176e-06, 1.0182e-02, 3.4242e-06,
        3.6137e-06, 6.6245e-06, 6.0107e-06, 5.7984e-06, 3.1148e-06, 2.2016e-06,
        3.0432e-06, 6.0055e-06, 6.4924e-06, 4.5557e-06, 4.8693e-06, 3.8357e-06,
        6.7876e-06, 6.8880e-06, 5.8193e-06, 6.0107e-06, 6.7198e-06, 2.8772e-06,
        6.2986e-06, 1.0995e-06, 6.2219e-06, 2.7022e-06, 5.4123e-06, 5.1317e-07,
        3.9156e-06, 1.9396e-06, 4.3796e-06, 8.3719e-06, 2.6041e-06, 6.8880e-06,
        3.9648e-06, 9.8194e-06, 6.4924e-06, 6.4924e-06, 5.6655e-06, 1.7304e-06,
        1.6840e-06, 4.6768e-06, 5.3965e-06, 5.3037e-06, 5.3644e-06, 1.8368e-06,
        8.3719e-06, 6.3868e-06, 1.2006e-06, 6.4924e-06, 1.0952e-05, 2.1481e-06,
        2.0686e-06, 7.7908e-06, 6.1361e-06, 2.8772e-06, 6.2829e-06, 6.6217e-06,
        1.0958e-01, 3.7341e-06, 4.1989e-06, 2.7299e-06, 4.0863e-06, 1.2770e-05,
        3.1798e-06, 5.4931e-06, 7.5007e-06, 6.6594e-06, 5.3891e-06, 4.1489e-06,
        6.6594e-06, 2.6818e-06, 1.8368e-06, 4.4381e-06, 6.9953e-06, 7.2632e-06,
        5.5439e-06, 5.0674e-06, 1.2645e-06, 2.6614e-06, 6.4924e-06, 1.0727e-05,
        3.4819e-06, 3.4201e-06, 2.9777e-06, 3.8117e-06, 5.6655e-06, 3.0493e-06,
        3.5225e-06, 6.2986e-06, 3.6261e-06, 3.6630e-06, 2.8772e-06, 3.9730e-06,
        3.4242e-06, 6.6826e-06, 2.7354e-06, 1.8339e-06, 6.0107e-06, 2.1567e-06,
        2.5311e-06, 9.8962e-02, 6.8826e-06, 5.1452e-06, 2.0485e-06, 3.4580e-06,
        6.0107e-06, 3.2028e-03, 8.5381e-02, 1.2956e-06, 3.2266e-06, 4.3606e-06,
        2.9720e-06, 6.9498e-06, 1.1204e-01, 1.5461e-06, 5.8958e-02, 7.2037e-06,
        2.9985e-06, 8.4668e-06, 1.1082e-01, 9.2558e-02, 1.9645e-06, 3.9156e-06,
        2.4468e-06, 7.0763e-03, 1.7443e-06, 6.2745e-06, 5.7984e-06, 2.2144e-06,
        6.4924e-06, 3.3733e-06, 7.5338e-02, 4.8087e-06, 3.7303e-06, 2.9351e-06,
        7.1836e-06, 4.2972e-06, 4.7063e-06, 4.9917e-06, 6.6594e-06, 1.7921e-06,
        3.0099e-06, 1.3074e-06, 1.5092e-06, 7.8454e-06, 7.8618e-06, 4.0377e-06,
        2.9777e-06, 3.0907e-06, 3.2832e-06, 2.0412e-06, 6.4439e-06, 6.4924e-06,
        3.8117e-06, 1.6788e-06, 5.3037e-06, 4.1351e-06, 4.6729e-06, 3.6261e-06,
        3.3626e-06, 1.0337e-05, 3.9070e-06, 4.5557e-06, 3.9156e-06, 8.6152e-06,
        1.1557e-05, 2.6868e-06, 7.5183e-06, 2.2922e-06, 5.9159e-06, 6.2742e-06,
        3.3626e-06, 3.9070e-06, 4.7120e-06, 1.9646e-06, 7.5878e-06, 4.1732e-06,
        4.5834e-06, 2.0422e-06, 4.7417e-06, 3.6346e-06, 1.6933e-06, 4.1105e-06,
        1.1810e-06, 3.9453e-06, 3.7236e-06, 3.5959e-06, 2.2016e-06, 4.7063e-06,
        3.8620e-06, 5.3037e-06, 6.0006e-06, 6.4924e-06, 2.5340e-06, 5.0837e-06,
        5.0291e-06, 2.6868e-06, 4.0735e-06, 4.8087e-06, 4.3604e-06, 8.0571e-06,
        1.5461e-06, 7.3522e-06, 4.2972e-06, 3.6230e-06, 7.7756e-06, 4.9302e-06,
        4.8142e-06, 6.6594e-06, 3.3445e-06, 1.9646e-06], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([2.4547e-07, 7.1517e-07, 2.1632e-07,  ..., 3.1206e-07, 1.4324e-07,
        3.0817e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.4461e-06, 1.1045e-06, 2.9133e-06, 1.2246e-06, 9.2052e-07, 1.9624e-06,
        1.0925e-06, 1.4461e-06, 1.3295e-06, 1.2246e-06, 1.0419e-06, 1.2762e-06,
        8.8872e-07, 1.0793e-06, 1.1786e-06, 6.6911e-07, 1.2006e-06, 1.4136e-06,
        3.0088e-06, 4.4906e-07, 6.1171e-07, 1.7114e-06, 6.8354e-07, 1.5790e-06,
        3.8780e-07, 1.0445e-06, 1.2246e-06, 1.4130e-07, 2.2281e-06, 3.5972e-07,
        2.5004e-06, 1.3503e-06, 1.5259e-06, 1.3468e-06, 1.0398e-06, 1.4183e-01,
        7.1023e-07, 1.0700e-06, 3.1555e-07, 7.1024e-07, 2.2511e-06, 1.4828e-06,
        1.7234e-01, 7.8850e-07, 2.7110e-06, 2.7007e-06, 6.8161e-07, 2.9133e-06,
        1.2173e-06, 7.1024e-07, 7.8943e-07, 6.1171e-07, 6.4356e-07, 1.1937e-06,
        2.3335e-06, 1.3821e-06, 1.2246e-06, 1.7054e-06, 2.7529e-06, 1.0036e-06,
        6.3018e-07, 6.8161e-07, 2.3914e-07, 2.6637e-06, 8.5784e-07, 6.8161e-07,
        1.4266e-01, 1.7710e-06, 1.6708e-06, 1.4461e-06, 5.1286e-07, 1.1475e-06,
        1.8367e-06, 1.0203e-06, 9.3974e-07, 1.7114e-06, 2.0808e-06, 1.1551e-06,
        2.2511e-06, 2.0808e-06, 2.3046e-06, 2.4344e-06, 9.4436e-07, 1.0095e-06,
        1.0036e-06, 7.7302e-07, 5.8899e-07, 2.8967e-06, 3.7513e-06, 1.8440e-06,
        6.8161e-07, 1.8239e-06, 4.4546e-07, 8.5784e-07, 2.8967e-06, 1.1937e-06,
        5.3283e-07, 4.1969e-07, 1.9734e-06, 1.4808e-06, 1.9734e-06, 4.1969e-07,
        4.1214e-07, 1.2010e-06, 4.1969e-07, 6.3018e-07, 1.3799e-06, 8.5784e-07,
        4.6331e-02, 2.2511e-06, 9.6171e-07, 1.0793e-06, 1.0611e-06, 6.3018e-07,
        1.0210e-06, 8.5784e-07, 1.0700e-06, 2.0233e-06, 1.5795e-06, 8.5784e-07,
        2.4343e-06, 1.1937e-06, 3.3172e-07, 1.0793e-06, 5.2614e-07, 2.7007e-06,
        7.4631e-07, 1.4609e-06, 1.1937e-06, 7.1024e-07, 1.1271e-06, 1.7276e-06,
        9.6689e-07, 1.6610e-06, 7.6706e-07, 1.7114e-06, 1.3799e-06, 1.2954e-06,
        1.9234e-06, 3.5972e-07, 1.6708e-06, 2.8967e-06, 3.8780e-07, 4.8734e-07,
        3.1432e-06, 7.6190e-07, 9.2052e-07, 1.0611e-06, 1.2173e-06, 4.1969e-07,
        2.9133e-06, 2.0779e-06, 8.5784e-07, 1.8129e-06, 4.9179e-07, 8.6380e-07,
        1.9734e-06, 2.8967e-06, 7.2794e-07, 5.9281e-07, 2.0233e-06, 8.5784e-07,
        1.2173e-06, 2.3335e-06, 1.7657e-06, 5.2614e-07, 2.3046e-06, 4.4906e-07,
        4.8734e-07, 1.2067e-06, 7.9581e-07, 7.7821e-07, 6.3063e-07, 1.6610e-06,
        1.9734e-06, 1.6853e-06, 1.7207e-06, 1.5795e-06, 4.1969e-07, 4.1969e-07,
        8.6160e-07, 7.2343e-07, 2.0096e-06, 1.3321e-06, 1.1475e-06, 1.5795e-06,
        1.1937e-06, 1.7654e-06, 2.8967e-06, 1.1045e-06, 1.1753e-06, 2.0233e-06,
        8.3696e-07, 6.8929e-07, 8.5784e-07, 2.8967e-06, 1.3295e-06, 6.4415e-07,
        7.1024e-07, 1.7054e-06, 1.2783e-06, 1.0203e-06, 2.7428e-06, 1.1753e-06,
        1.8699e-06, 2.7110e-06, 2.3335e-06, 1.0793e-06, 2.3335e-06, 1.1937e-06,
        6.1899e-07, 2.9133e-06, 2.1339e-06, 6.0324e-07, 9.6689e-07, 9.7298e-07,
        2.4343e-06, 3.3172e-07, 1.1353e-06, 2.0233e-06, 1.1045e-06, 1.1005e-06,
        8.5784e-07, 2.0233e-06, 1.0336e-06, 5.8899e-07, 3.0088e-06, 4.8734e-07,
        1.4990e-06, 3.0970e-06, 1.8699e-06, 4.4906e-07, 4.1969e-07, 1.0700e-06,
        2.9133e-06, 7.9896e-07, 1.1992e-06, 1.8699e-06, 6.2508e-07, 4.2606e-07,
        1.9987e-06, 1.4562e-06, 4.1969e-07, 2.3335e-06, 1.2006e-06, 2.0808e-06,
        2.8967e-06, 2.3859e-06, 2.0180e-06, 2.0096e-06, 1.1786e-06, 3.2412e-06,
        7.7821e-07, 2.0233e-06, 6.3403e-07, 7.8748e-07], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([2.4444e-06, 1.2632e-06, 2.0630e-06, 6.4373e-06, 1.5495e-06, 6.2258e-07,
        4.3505e-06, 2.5169e-06, 5.6601e-06, 4.0694e-06, 3.1647e-06, 2.6751e-06,
        1.5495e-06, 2.1949e-06, 5.7090e-06, 3.1527e-06, 2.1300e-06, 4.8020e-06,
        9.9947e-06, 3.0266e-06, 1.5496e-06, 1.6666e-06, 1.1319e-06, 2.2168e-06,
        3.7162e-06, 3.7791e-06, 1.0087e-05, 4.8888e-06, 2.1735e-06, 3.7162e-06,
        2.0196e-06, 5.9102e-06, 1.6654e-06, 3.7780e-06, 1.6666e-06, 2.3084e-06,
        1.3816e-06, 7.8190e-06, 3.1211e-06, 3.1211e-06, 1.7035e-06, 2.9812e-06,
        1.8364e-06, 1.8746e-06, 6.4252e-06, 3.6426e-06, 5.3677e-06, 2.3084e-06,
        5.4338e-06, 1.5495e-06, 5.5506e-07, 2.8269e-06, 6.6945e-06, 2.3084e-06,
        4.3900e-06, 1.5419e-06, 4.1179e-06, 2.1538e-06, 4.7888e-06, 2.8685e-06,
        2.1550e-06, 8.3768e-06, 1.6465e-06, 8.5526e-06, 5.3677e-06, 7.8198e-06,
        6.2258e-07, 4.0025e-06, 1.6585e-06, 5.7227e-06, 2.5183e-06, 1.1778e-06,
        5.1804e-06, 6.2258e-07, 5.3927e-06, 1.9976e-06, 4.4993e-06, 3.9998e-06,
        1.6581e-06, 1.5439e-06, 2.2619e-06, 3.4251e-06, 2.9341e-06, 5.5649e-06,
        2.4450e-06, 3.1527e-06, 6.2586e-06, 4.8020e-06, 3.0188e-06, 4.2550e-06,
        1.6585e-06, 7.2569e-06, 1.2632e-06, 1.6449e-06, 2.8004e-06, 2.8377e-06,
        1.5495e-06, 1.0087e-05, 6.2258e-07, 3.8922e-06, 2.9466e-06, 1.1117e-06,
        2.0559e-06, 4.4594e-06, 2.5897e-06, 3.6002e-06, 2.3267e-06, 2.3073e-06,
        6.1206e-06, 3.1527e-06, 3.4306e-06, 1.7497e-06, 3.5019e-06, 2.3084e-06,
        3.2326e-06, 2.0196e-06, 2.4444e-06, 1.2004e-06, 3.2261e-06, 1.7887e-06,
        5.4451e-06, 2.8269e-06, 1.9468e-06, 2.1431e-06, 1.6780e-06, 6.1206e-06,
        1.2071e-06, 8.3768e-06, 3.3437e-06, 1.7869e-06, 4.0694e-06, 1.6983e-06,
        1.0287e-05, 5.4338e-06, 5.3677e-06, 1.8807e-06, 4.0025e-06, 2.3267e-06,
        5.1361e-06, 2.4662e-06, 1.0526e-06, 4.7076e-06, 2.1735e-06, 3.1211e-06,
        1.5496e-06, 3.9998e-06, 1.8364e-06, 5.9871e-06, 5.0533e-06, 9.9947e-06,
        2.4444e-06, 3.6215e-06, 7.2313e-06, 2.9208e-06, 1.1778e-06, 1.0020e-06,
        1.8666e-06, 1.9112e-06, 1.8666e-06, 4.8371e-06, 5.3677e-06, 3.1292e-06,
        1.1117e-06, 5.1361e-06, 3.6967e-06, 1.6780e-06, 2.6102e-06, 1.5495e-06,
        2.0589e-06, 2.3511e-06, 1.6654e-06, 3.1292e-06, 2.6751e-06, 1.2632e-06,
        8.8231e-06, 2.0196e-06, 2.7004e-06, 7.0262e-06, 1.0452e-06, 1.6449e-06,
        7.6545e-06, 4.3325e-06, 4.9577e-06, 1.1117e-06, 2.9070e-06, 3.0087e-06,
        6.2586e-06, 8.5526e-06, 5.5649e-06, 3.0520e-06, 3.2326e-06, 2.5625e-06,
        5.8347e-06, 2.8685e-06, 2.1550e-06, 2.5183e-06, 3.2326e-06, 2.2516e-06,
        2.8619e-06, 4.6262e-06, 3.1527e-06, 2.0196e-06, 1.5495e-06, 2.7004e-06,
        5.8446e-06, 3.5911e-06, 8.3768e-06, 9.9465e-07, 4.0694e-06, 3.7283e-06,
        2.6330e-06, 9.9914e-06, 3.1527e-06, 3.5776e-06, 3.2326e-06, 4.7505e-06,
        5.1167e-06, 2.8377e-06, 6.5293e-06, 2.5266e-06, 5.8347e-06, 2.3084e-06,
        4.7169e-06, 2.0196e-06, 1.3457e-01, 2.3084e-06, 1.1312e-06, 7.2349e-06,
        3.9138e-06, 6.0292e-06, 3.2326e-06, 4.6818e-06, 5.6601e-06, 2.5897e-06,
        3.7239e-06, 2.9376e-06, 3.1657e-06, 3.1527e-06, 1.8327e-06, 2.0719e-07,
        1.5586e-06, 6.4086e-06, 1.6666e-06, 4.0419e-06, 6.5286e-06, 2.6102e-06,
        3.4544e-06, 1.5419e-06, 2.3163e-06, 7.6170e-06, 2.8729e-06, 1.6156e-06,
        3.1989e-06, 9.3184e-07, 4.0438e-06, 8.4071e-06], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([1.4174e-07, 8.3880e-08, 5.2053e-07,  ..., 2.6009e-07, 5.3153e-08,
        4.4342e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.6864e-06, 6.9237e-07, 3.3945e-07, 1.9232e-07, 1.0083e-06, 2.3642e-06,
        2.0375e-06, 9.2073e-07, 9.2702e-07, 2.0375e-06, 1.6525e-06, 7.9407e-07,
        1.3718e-06, 1.5074e-06, 4.2322e-07, 9.7090e-07, 1.7637e-06, 9.0888e-07,
        7.4881e-07, 7.4525e-07, 1.3679e-06, 6.1757e-07, 6.5455e-07, 9.3548e-07,
        3.2515e-07, 8.4303e-07, 9.2073e-07, 5.3593e-07, 1.7228e-06, 1.8037e-06,
        8.7089e-07, 9.7498e-07, 8.2966e-07, 7.9408e-07, 1.8942e-06, 5.3593e-07,
        1.2414e-06, 2.4391e-06, 9.0707e-07, 1.5302e-06, 7.4881e-07, 7.1263e-07,
        1.3679e-06, 2.5243e-06, 7.9407e-07, 1.0629e-06, 2.0375e-06, 5.9561e-07,
        7.7784e-07, 7.4881e-07, 7.4526e-07, 1.0629e-06, 9.2073e-07, 3.5339e-07,
        2.0846e-07, 1.0029e-06, 1.3882e-06, 1.8037e-06, 1.0781e-06, 6.9295e-07,
        1.1538e-06, 7.8927e-07, 7.4525e-07, 1.5842e-06, 4.4543e-07, 1.9232e-07,
        1.0063e-06, 1.0262e-06, 8.6430e-07, 6.9237e-07, 4.9829e-07, 1.0059e-06,
        9.3246e-07, 1.8625e-06, 1.6347e-06, 4.2322e-07, 1.3179e-06, 6.5455e-07,
        2.3569e-06, 6.6739e-07, 5.4869e-07, 9.3757e-07, 1.2693e-06, 8.2456e-07,
        4.4656e-07, 1.3718e-06, 7.9407e-07, 2.4391e-06, 1.7637e-06, 7.7784e-07,
        5.6117e-07, 4.9829e-07, 3.1125e-06, 1.7637e-06, 5.9561e-07, 1.0063e-06,
        4.4543e-07, 2.0578e-06, 1.6710e-06, 6.4070e-07, 2.6238e-06, 1.2693e-06,
        1.3011e-07, 1.5157e-06, 1.2491e-06, 5.0547e-07, 2.5103e-06, 1.0029e-06,
        2.0375e-06, 1.0029e-06, 2.4391e-06, 6.1757e-07, 1.0629e-06, 6.5455e-07,
        7.4595e-07, 1.7637e-06, 6.1757e-07, 9.7608e-07, 7.1263e-07, 7.7784e-07,
        2.0846e-07, 6.0759e-07, 9.3757e-07, 6.9295e-07, 9.2073e-07, 7.7784e-07,
        9.7498e-07, 7.4881e-07, 1.1538e-06, 2.5103e-06, 1.0629e-06, 2.5103e-06,
        1.0059e-06, 1.3679e-06, 1.9235e-06, 3.1516e-07, 2.0375e-06, 4.5357e-07,
        9.8976e-07, 1.0433e-06, 5.6117e-07, 2.5259e-06, 7.4881e-07, 3.2615e-07,
        6.9237e-07, 2.5103e-06, 5.3593e-07, 1.8942e-06, 1.5842e-06, 1.3718e-06,
        9.7498e-07, 2.0578e-06, 7.4595e-07, 1.1646e-06, 2.5103e-06, 1.3718e-06,
        1.0917e-06, 4.4543e-07, 4.9324e-07, 6.0759e-07, 9.7498e-07, 2.5243e-06,
        1.6054e-06, 1.9645e-06, 1.6347e-06, 5.2256e-07, 2.3777e-06, 1.5074e-06,
        1.1951e-07, 1.0059e-06, 5.3593e-07, 6.9461e-07, 1.0433e-06, 1.1951e-07,
        2.3569e-06, 1.8037e-06, 8.2456e-07, 4.2322e-07, 6.5455e-07, 1.1538e-06,
        3.5101e-07, 1.1538e-06, 1.3718e-06, 9.0354e-07, 5.7280e-07, 7.4595e-07,
        2.3353e-06, 1.2681e-06, 5.9182e-07, 6.3942e-07, 7.6954e-07, 1.0433e-06,
        2.0375e-06, 3.5101e-07, 2.6708e-06, 1.8449e-06, 9.8976e-07, 7.9407e-07,
        1.1111e-06, 1.8625e-06, 8.8093e-07, 1.0912e-06, 9.5018e-07, 7.7784e-07,
        6.1757e-07, 1.8037e-06, 1.1944e-06, 7.8927e-07, 6.5217e-07, 2.0375e-06,
        4.5357e-07, 3.3945e-07, 1.8007e-06, 1.8625e-06, 1.0063e-06, 7.9408e-07,
        1.8449e-06, 1.0029e-06, 6.9237e-07, 9.8896e-07, 9.2073e-07, 1.3718e-06,
        1.8037e-06, 3.3945e-07, 3.8221e-07, 2.0375e-06, 1.2443e-06, 1.8942e-06,
        1.1891e-06, 1.6347e-06, 9.2073e-07, 1.7637e-06, 3.1838e-07, 6.5455e-07,
        5.9901e-07, 4.4543e-07, 4.9829e-07, 4.5357e-07, 2.5243e-06, 1.3274e-06,
        2.0375e-06, 7.4595e-07, 7.4881e-07, 1.0433e-06, 5.3593e-07, 1.9444e-06,
        1.8625e-06, 8.1828e-07, 1.5351e-06, 1.1646e-06, 7.4525e-07, 2.0846e-07,
        4.9829e-07, 1.0262e-06, 9.3757e-07, 8.7089e-07], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([3.9338e-06, 5.4344e-06, 1.4495e-06, 3.0971e-06, 9.8698e-07, 1.9084e-06,
        2.6729e-06, 1.7692e-06, 3.3320e-06, 1.7270e-06, 2.1177e-06, 2.1635e-06,
        7.7622e-06, 3.4507e-06, 1.7475e-06, 3.6637e-06, 1.6211e-06, 8.2761e-06,
        7.5714e-06, 4.3192e-06, 4.5417e-06, 3.1089e-06, 3.8110e-06, 2.5112e-06,
        1.8333e-06, 7.7622e-06, 5.4344e-06, 2.5112e-06, 3.1471e-06, 2.5112e-06,
        3.1150e-06, 7.7495e-06, 4.1973e-06, 6.7037e-06, 1.8508e-06, 2.2507e-06,
        3.7329e-06, 3.0128e-06, 8.9415e-06, 6.1209e-06, 5.0441e-06, 4.1013e-06,
        9.2538e-06, 2.1177e-06, 4.9347e-06, 7.7934e-06, 4.1013e-06, 3.4031e-06,
        2.7148e-06, 4.2847e-06, 4.7215e-07, 2.4202e-06, 2.2597e-06, 5.2613e-06,
        2.4212e-06, 4.1013e-06, 1.7924e-06, 8.4484e-07, 2.3936e-06, 4.0278e-06,
        1.1869e-06, 2.6862e-06, 3.5823e-06, 4.0654e-06, 3.6027e-06, 2.7148e-06,
        1.5922e-06, 1.1948e-06, 2.2597e-06, 4.1013e-06, 4.6824e-06, 1.7475e-06,
        4.2681e-06, 1.8173e-06, 1.6211e-06, 1.2548e-06, 2.4411e-06, 3.3611e-06,
        4.4319e-07, 2.7599e-06, 4.1995e-06, 1.7762e-06, 2.6656e-06, 2.3062e-06,
        4.3192e-06, 4.0654e-06, 1.0232e-06, 7.3646e-07, 2.8180e-06, 2.2597e-06,
        3.0362e-06, 1.6040e-06, 1.0452e-06, 6.9439e-06, 2.7394e-06, 4.9864e-06,
        1.8508e-06, 2.8342e-06, 2.4212e-06, 6.5602e-06, 3.9435e-06, 3.3946e-06,
        2.8070e-06, 3.6908e-06, 4.0653e-06, 5.2046e-06, 6.5075e-06, 1.0697e-06,
        6.1960e-06, 4.5033e-06, 7.1445e-06, 3.9755e-06, 5.8798e-06, 4.3919e-06,
        2.4232e-06, 4.7774e-06, 2.4201e-06, 1.8508e-06, 2.2322e-06, 2.6729e-06,
        6.8429e-06, 3.3909e-06, 4.1270e-06, 1.9747e-06, 6.9439e-06, 1.8533e-06,
        2.1177e-06, 5.8868e-06, 4.1013e-06, 4.9347e-06, 3.7795e-06, 1.2594e-06,
        6.9439e-06, 1.3950e-07, 9.7897e-07, 2.8820e-06, 5.2613e-06, 2.1177e-06,
        4.4319e-07, 6.3544e-06, 6.0221e-06, 4.1973e-06, 3.7062e-06, 6.1347e-06,
        5.5140e-06, 2.1177e-06, 4.1528e-06, 7.9961e-06, 7.2839e-06, 4.5014e-06,
        4.8463e-06, 3.4961e-06, 1.6168e-06, 5.6793e-06, 4.5061e-06, 3.1979e-06,
        3.6637e-06, 3.0496e-06, 2.2597e-06, 6.9439e-06, 6.9775e-06, 2.8322e-06,
        3.8922e-06, 5.7735e-06, 2.8276e-06, 3.7974e-06, 1.0697e-06, 1.9590e-06,
        4.2847e-06, 1.9348e-06, 2.3075e-06, 6.0727e-06, 1.8787e-06, 9.8698e-07,
        1.8508e-06, 2.1568e-07, 4.2186e-06, 4.0378e-06, 4.7769e-06, 4.1013e-06,
        2.4421e-06, 7.7622e-06, 6.0432e-06, 5.3007e-06, 3.9055e-06, 5.1726e-06,
        5.3742e-06, 1.0867e-06, 2.6927e-07, 2.1177e-06, 3.7640e-06, 4.8883e-06,
        1.4988e-06, 2.0782e-06, 1.9319e-06, 5.3143e-06, 7.8065e-06, 9.7897e-07,
        1.6366e-06, 2.6058e-06, 3.8922e-06, 5.1072e-06, 4.1171e-06, 5.3143e-06,
        3.0496e-06, 4.8811e-06, 1.9424e-06, 7.1445e-06, 3.0061e-06, 1.0697e-06,
        4.1973e-06, 2.4212e-06, 3.3320e-06, 3.0088e-06, 4.5193e-06, 4.9864e-06,
        8.9619e-06, 4.7850e-06, 8.2761e-06, 5.3742e-06, 6.0336e-06, 3.3909e-06,
        6.1381e-06, 7.5284e-06, 4.1040e-06, 4.2018e-06, 4.7402e-06, 3.0132e-06,
        2.3936e-06, 4.9347e-06, 5.2701e-07, 5.2046e-06, 5.5690e-06, 2.7394e-06,
        3.1822e-06, 2.5112e-06, 6.7933e-06, 6.4896e-07, 3.8110e-06, 1.5256e-06,
        6.9439e-06, 1.3292e-06, 2.7148e-06, 3.1690e-06, 1.8517e-06, 7.9961e-06,
        3.3995e-06, 2.4090e-06, 3.3320e-06, 1.5186e-06, 4.4459e-06, 1.9084e-06,
        5.1452e-06, 3.8021e-06, 2.4411e-06, 3.0362e-06], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([1.2097e-07, 3.7124e-07, 3.4669e-07,  ..., 1.7364e-07, 1.8973e-07,
        1.9447e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.0655e-06, 1.3821e-06, 4.3960e-07, 2.8168e-07, 9.2317e-02, 1.3153e-06,
        5.5903e-07, 6.6107e-07, 1.7304e-06, 1.9646e-06, 6.2826e-07, 9.5258e-07,
        2.0273e-06, 9.6988e-07, 7.6727e-07, 1.3020e-06, 2.0273e-06, 9.5259e-07,
        1.4436e-06, 9.5259e-07, 4.1417e-07, 1.3020e-06, 1.6001e-06, 6.2826e-07,
        3.3594e-08, 1.9646e-06, 4.8111e-07, 1.3020e-06, 4.8534e-07, 4.8534e-07,
        5.7589e-07, 9.6988e-07, 2.0273e-06, 4.9259e-07, 1.3020e-06, 1.3153e-06,
        3.6643e-07, 3.2550e-07, 3.3146e-07, 9.5258e-07, 9.3992e-07, 7.6727e-07,
        1.3020e-06, 1.9394e-07, 4.1959e-07, 7.3325e-07, 5.7463e-07, 8.6121e-02,
        6.2547e-07, 1.9674e-06, 1.0065e-06, 5.7234e-07, 1.7304e-06, 4.0633e-07,
        4.8111e-07, 1.9674e-06, 6.6107e-07, 2.8833e-07, 5.7463e-07, 6.3217e-07,
        8.4065e-07, 5.4980e-07, 7.9585e-07, 1.7304e-06, 4.3993e-07, 3.8971e-07,
        6.6107e-07, 3.8429e-07, 3.6643e-07, 2.8833e-07, 4.1417e-07, 6.2826e-07,
        7.6727e-07, 4.5839e-07, 1.6001e-06, 1.2990e-01, 1.0065e-06, 7.7477e-07,
        4.3993e-07, 6.2826e-07, 5.7589e-07, 3.8429e-07, 1.5916e-06, 1.2029e-06,
        1.3153e-06, 6.2826e-07, 1.3020e-06, 4.4606e-07, 6.8880e-07, 1.3153e-06,
        3.0146e-07, 8.5226e-07, 1.9572e-06, 8.0072e-07, 5.4980e-07, 1.3821e-06,
        4.0633e-07, 4.0633e-07, 1.9394e-07, 4.0647e-07, 8.2965e-02, 1.9394e-07,
        1.3020e-06, 1.9646e-06, 1.9593e-06, 1.9646e-06, 6.8857e-07, 6.4384e-07,
        1.7304e-06, 8.5226e-07, 7.6727e-07, 1.9646e-06, 7.3325e-07, 5.4980e-07,
        7.3325e-07, 2.0699e-07, 5.8461e-02, 6.6107e-07, 8.4065e-07, 4.3960e-07,
        1.0065e-06, 1.0065e-06, 1.9394e-07, 5.4980e-07, 6.2826e-07, 5.6750e-07,
        8.1474e-02, 1.2479e-06, 3.6643e-07, 1.3821e-06, 4.1160e-07, 1.7675e-07,
        6.2826e-07, 3.4857e-07, 1.3153e-06, 3.8429e-07, 1.7304e-06, 2.3117e-07,
        4.0633e-07, 5.4980e-07, 5.4980e-07, 7.5241e-02, 1.2848e-01, 3.2550e-07,
        5.0023e-09, 4.4606e-07, 9.6973e-07, 3.8971e-07, 2.0273e-06, 1.4636e-06,
        5.4980e-07, 1.7304e-06, 7.3325e-07, 1.3821e-06, 2.0273e-06, 9.6988e-07,
        1.0109e-06, 3.4857e-07, 4.8534e-07, 5.4980e-07, 6.6107e-07, 1.3044e-06,
        4.0634e-07, 1.3153e-06, 1.3821e-06, 5.7912e-07, 1.4636e-06, 9.6988e-07,
        9.6988e-07, 4.0031e-07, 2.6451e-07, 4.8534e-07, 6.6107e-07, 1.9394e-07,
        6.6107e-07, 7.4175e-07, 4.0633e-07, 3.3146e-07, 1.9029e-06, 7.6727e-07,
        7.9585e-07, 7.6727e-07, 4.3712e-07, 5.4980e-07, 7.2625e-07, 1.1059e-06,
        4.8534e-07, 6.2826e-07, 1.3821e-06, 3.9559e-07, 3.8429e-07, 4.9259e-07,
        6.2826e-07, 1.7493e-07, 1.7304e-06, 1.7304e-06, 1.4636e-06, 9.6489e-07,
        9.6988e-07, 9.2167e-07, 3.2550e-07, 7.6875e-07, 4.0031e-07, 6.2826e-07,
        1.7304e-06, 3.2550e-07, 7.6727e-07, 1.6001e-06, 2.6108e-07, 4.4606e-07,
        6.8857e-07, 6.9386e-07, 1.3821e-06, 1.9029e-06, 4.4606e-07, 1.2280e-06,
        4.4606e-07, 9.5262e-07, 7.6727e-07, 5.4980e-07, 1.3688e-01, 1.3044e-06,
        7.9172e-07, 6.1099e-02, 5.7194e-07, 5.2014e-07, 2.3117e-07, 5.7463e-07,
        1.3821e-06, 1.9572e-06, 4.3993e-07, 7.9585e-07, 1.9029e-06, 4.4606e-07,
        1.3821e-06, 1.9394e-07, 1.3821e-06, 1.6001e-06, 3.0967e-07, 1.5551e-01,
        6.6107e-07, 9.2167e-07, 6.9905e-02, 1.7675e-07, 1.0751e-06, 6.6107e-07,
        6.6107e-07, 3.2550e-07, 1.9674e-06, 1.2280e-06, 2.7215e-07, 1.1457e-06,
        3.2550e-07, 1.6001e-06, 2.5258e-07, 6.8217e-07, 6.6107e-07, 4.3960e-07,
        3.6643e-07, 1.9394e-07, 1.3821e-06, 7.9585e-07, 2.6524e-07, 6.8857e-07,
        6.9386e-07, 1.9394e-07, 1.3114e-06, 9.6988e-07, 5.3172e-07, 2.0699e-07,
        4.3712e-07, 6.6259e-02, 1.9674e-06, 6.2826e-07, 4.3960e-07, 3.2550e-07,
        6.3217e-07, 6.4120e-07, 1.3821e-06, 4.3712e-07, 6.2547e-07, 4.1417e-07,
        1.9674e-06, 1.3153e-06, 1.9646e-06, 1.9674e-06, 7.9172e-07, 2.3041e-07,
        5.7194e-07, 2.3041e-07, 3.6643e-07, 5.7194e-07, 3.2550e-07, 6.8857e-07,
        7.9585e-07, 3.2550e-07, 7.5047e-02, 6.8217e-07, 1.3153e-06, 1.9591e-06,
        1.3020e-06, 7.6727e-07, 1.9674e-06, 5.6989e-07, 4.7040e-07, 4.3960e-07,
        9.5262e-07, 6.8857e-07, 3.0146e-07, 1.2280e-06, 1.3114e-06, 1.3821e-06,
        1.3821e-06, 4.3960e-07, 1.7304e-06, 2.0273e-06, 4.1448e-07, 2.3117e-07,
        4.8111e-07, 1.2029e-06, 5.4980e-07, 9.5258e-07, 5.4980e-07, 4.3712e-07,
        8.5226e-07, 4.3712e-07, 8.3909e-02, 3.2550e-07, 6.2826e-07, 2.0273e-06,
        3.4857e-07, 1.9646e-06, 4.3993e-07, 1.9394e-07, 6.6107e-07, 9.2578e-07,
        1.9029e-06, 4.8534e-07, 5.4980e-07, 8.5226e-07, 5.7912e-07, 1.1489e-06,
        1.9674e-06, 1.3821e-06, 1.7304e-06, 4.0633e-07, 1.9029e-06, 6.8857e-07,
        6.2547e-07, 2.0554e-06, 7.9585e-07, 5.0386e-07, 3.4857e-07, 5.7590e-07,
        1.3020e-06, 1.6061e-07, 6.2547e-07, 7.0161e-02, 9.4640e-07, 7.2625e-07,
        6.7162e-07, 1.3020e-06, 1.2539e-06, 4.3993e-07, 5.0520e-07, 1.3821e-06,
        9.2578e-07, 1.3020e-06, 4.0633e-07, 2.0273e-06, 1.0065e-06, 6.2547e-07,
        1.3544e-06, 7.9585e-07, 2.0554e-06, 3.6643e-07, 4.8111e-07, 4.0633e-07,
        8.2595e-07, 3.3146e-07, 1.3821e-06, 1.2029e-06, 1.7304e-06, 1.3153e-06,
        2.3117e-07, 1.0433e-06, 9.2167e-07, 9.5256e-07, 3.2550e-07, 5.0520e-07,
        4.1417e-07, 1.3020e-06, 2.0273e-06, 7.9585e-07, 4.4606e-07, 1.6001e-06,
        4.0633e-07, 1.9394e-07, 2.0143e-06, 1.2972e-06, 5.6052e-02, 4.0633e-07,
        1.4416e-06, 7.3325e-07, 2.0273e-06, 1.3821e-06, 1.3153e-06, 6.6107e-07,
        4.8534e-07, 1.7675e-07, 2.9009e-07, 2.0143e-06, 7.6727e-07, 8.5730e-07,
        6.2826e-07, 3.0967e-07, 9.3342e-07, 1.2500e-06, 1.5783e-07, 3.2550e-07,
        2.0699e-07, 7.9172e-07, 5.3172e-07, 3.7086e-07, 9.6973e-07, 3.2550e-07,
        4.8111e-07, 4.0633e-07, 4.1160e-07, 6.3217e-07, 3.4857e-07, 6.6107e-07,
        5.7912e-07, 7.6727e-07, 1.9394e-07, 1.6001e-06, 1.3020e-06, 9.6973e-07,
        1.7675e-07, 6.6107e-07, 2.0157e-06, 1.9646e-06, 4.8111e-07, 5.7463e-07,
        6.2826e-07, 1.0065e-06, 2.6055e-06, 4.8534e-07, 2.3117e-07, 1.0109e-06,
        1.0746e-06, 2.0157e-06, 7.2625e-07, 6.4384e-07, 1.3153e-06, 8.5226e-07,
        1.3963e-06, 7.6727e-07, 2.0554e-06, 7.6727e-07, 7.9585e-07, 4.0588e-07,
        2.8168e-07, 1.6028e-06, 8.2565e-02, 1.9592e-06, 7.6727e-07, 3.2550e-07,
        7.9585e-07, 4.8534e-07, 1.0304e-06, 3.6643e-07, 9.2578e-07, 4.8534e-07,
        4.3960e-07, 2.8168e-07, 2.0273e-06, 1.3821e-06, 4.0633e-07, 1.3821e-06,
        1.9674e-06, 6.2826e-07, 6.0728e-02, 1.2280e-06, 1.9029e-06, 4.0633e-07,
        1.3020e-06, 4.8534e-07, 1.7675e-07, 8.5226e-07, 5.3172e-07, 7.6727e-07,
        2.0273e-06, 1.9029e-06, 7.9585e-07, 4.3993e-07, 2.0273e-06, 7.6727e-07,
        6.0823e-02, 1.9674e-06, 1.9646e-06, 3.2550e-07, 4.9725e-07, 7.8028e-07,
        1.3020e-06, 2.0260e-06, 5.4980e-07, 1.3153e-06, 4.3960e-07, 1.3020e-06,
        1.2029e-06, 7.2625e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([9.3126e-06, 8.2526e-06, 5.2764e-06, 9.3126e-06, 3.1674e-06, 2.4516e-06,
        7.4115e-06, 1.1485e-05, 4.5992e-06, 3.6316e-06, 1.1485e-05, 4.5891e-06,
        3.6316e-06, 5.9898e-06, 2.2180e-06, 9.5206e-07, 3.6316e-06, 5.8731e-06,
        3.7734e-06, 9.8731e-07, 3.6316e-06, 4.3010e-06, 4.7716e-06, 6.2744e-06,
        2.3119e-06, 9.3126e-06, 1.1485e-05, 4.5969e-06, 3.1674e-06, 3.4101e-06,
        4.5891e-06, 2.0373e-06, 2.9927e-06, 9.3126e-06, 4.5891e-06, 4.4621e-06,
        2.9927e-06, 2.7237e-06, 9.3126e-06, 3.1674e-06, 1.6533e-06, 6.5025e-06,
        5.2764e-06, 6.6919e-07, 3.0518e-06, 4.2721e-06, 5.8731e-06, 9.7132e-06,
        1.0375e-05, 5.8731e-06, 2.0373e-06, 5.9033e-06, 8.6665e-06, 3.1674e-06,
        6.7417e-06, 4.5992e-06, 1.2577e-05, 5.4074e-06, 3.9724e-06, 1.9383e-06,
        5.9033e-06, 7.0202e-06, 1.7482e-06, 5.7061e-06, 2.9797e-06, 1.3149e-06,
        2.9797e-06, 7.1228e-06, 2.4516e-06, 1.1485e-05, 3.2583e-06, 2.9309e-06,
        6.2543e-06, 4.4597e-06, 4.5557e-06, 4.6905e-06, 2.4601e-06, 4.5557e-06,
        5.5837e-06, 2.4516e-06, 1.3264e-01, 8.2595e-06, 6.2744e-06, 5.0804e-06,
        7.5197e-06, 4.2312e-06, 4.2882e-06, 5.4074e-06, 4.5557e-06, 5.5837e-06,
        3.2583e-06, 9.5206e-07, 4.2630e-06, 3.0518e-06, 3.2583e-06, 9.2228e-07,
        2.2789e-06, 3.1674e-06, 1.6286e-06, 2.5677e-06, 2.8595e-07, 2.7977e-06,
        2.0373e-06, 9.3126e-06, 3.9361e-06, 9.3126e-06, 3.4101e-06, 2.4516e-06,
        8.6665e-06, 8.7936e-06, 6.8933e-06, 2.0373e-06, 2.5677e-06, 2.9710e-06,
        5.4571e-06, 5.7061e-06, 6.7975e-06, 3.7675e-06, 2.9927e-06, 9.3126e-06,
        2.1935e-06, 2.8593e-07, 4.2882e-06, 4.3452e-06, 2.4516e-06, 6.8903e-06,
        5.2764e-06, 5.5837e-06, 5.2764e-06, 1.1994e-05, 5.6765e-06, 3.1674e-06,
        7.5197e-06, 2.9927e-06, 9.3126e-06, 4.2312e-06, 4.4668e-06, 5.2764e-06,
        3.5559e-06, 3.0518e-06, 2.0373e-06, 4.2882e-06, 2.9309e-06, 2.5677e-06,
        4.3010e-06, 2.5677e-06, 4.2882e-06, 2.4516e-06, 4.1475e-06, 2.0373e-06,
        3.4113e-06, 4.5891e-06, 4.3010e-06, 4.8616e-06, 4.3452e-06, 5.6765e-06,
        3.2583e-06, 3.6316e-06, 3.9916e-06, 5.3644e-06, 7.0833e-06, 4.7716e-06,
        2.9927e-06, 5.5837e-06, 4.5992e-06, 2.8242e-06, 8.0630e-06, 8.6665e-06,
        3.9724e-06, 4.9739e-06, 9.3126e-06, 5.4074e-06, 8.6665e-06, 5.1242e-06,
        3.1684e-06, 4.8616e-06, 3.7734e-06, 9.3126e-06, 6.8903e-06, 5.9814e-06,
        2.9927e-06, 2.4516e-06, 6.2744e-06, 5.8919e-06, 7.5839e-06, 4.3010e-06,
        2.4516e-06, 8.7936e-06, 3.6316e-06, 3.7734e-06, 1.1908e-01, 2.3380e-06,
        9.2228e-07, 1.4583e-06, 4.3010e-06, 4.8616e-06, 1.9383e-06, 8.2526e-06,
        4.7716e-06, 1.4583e-06, 7.8822e-06, 6.3619e-03, 3.6316e-06, 7.6975e-06,
        4.4597e-06, 4.8797e-06, 1.1549e-05, 1.1162e-05, 3.2583e-06, 2.4516e-06,
        4.7717e-06, 9.3126e-06, 5.9033e-06, 2.5677e-06, 5.0804e-06, 5.2873e-06,
        7.2457e-06, 6.3484e-06, 8.2526e-06, 2.6417e-06, 9.8731e-07, 3.1280e-06,
        3.3253e-06, 5.8394e-06, 2.8590e-07, 5.2764e-06, 4.2723e-06, 7.0202e-06,
        5.3821e-06, 9.5206e-07, 6.0721e-06, 4.5557e-06, 3.9917e-06, 9.7132e-06,
        1.1485e-05, 3.2583e-06, 4.3901e-06, 1.0179e-05, 7.1650e-06, 6.1786e-06,
        4.5299e-06, 8.6665e-06, 4.2882e-06, 3.9916e-06, 9.7132e-06, 6.2744e-06,
        4.5891e-06, 5.7061e-06, 3.2583e-06, 2.7977e-06, 6.3512e-06, 6.2744e-06,
        2.9927e-06, 6.3484e-06, 2.2789e-06, 1.0812e-05, 2.5677e-06, 1.4583e-06,
        6.8933e-06, 9.5206e-07, 5.8731e-06, 3.9916e-06, 2.5677e-06, 4.8616e-06,
        6.6103e-06, 3.6316e-06, 2.9465e-06, 3.1674e-06, 3.5782e-06, 1.2441e-05,
        2.8242e-06, 2.8594e-07, 9.3126e-06, 3.4160e-06, 4.9739e-06, 3.9916e-06,
        8.2526e-06, 1.9817e-06, 3.2583e-06, 4.4621e-06, 2.0373e-06, 9.9368e-02,
        6.7074e-06, 1.6669e-05, 5.7061e-06, 2.2771e-06, 8.2526e-06, 6.8903e-06,
        1.0227e-05, 4.5891e-06, 2.4516e-06, 1.1162e-05, 4.5992e-06, 7.0202e-06,
        1.1162e-05, 2.0373e-06, 4.5891e-06, 6.3484e-06, 7.0202e-06, 6.2543e-06,
        6.3047e-06, 7.6426e-06, 2.0373e-06, 3.9724e-06, 4.5992e-06, 8.0630e-06,
        2.0373e-06, 1.5510e-06, 2.9927e-06, 7.8822e-06, 4.8616e-06, 1.5510e-06,
        5.8394e-06, 3.6387e-06, 1.1893e-01, 3.7734e-06, 6.0721e-06, 4.5557e-06,
        9.4211e-06, 5.4074e-06, 3.5559e-06, 2.8593e-07, 3.0518e-06, 3.6316e-06,
        7.2456e-06, 9.8731e-07, 6.3047e-06, 4.5992e-06, 6.7074e-06, 1.2219e-05,
        8.6665e-06, 4.2964e-06, 7.3423e-06, 8.2387e-06, 3.1684e-06, 4.5557e-06,
        2.9797e-06, 6.2744e-06, 6.2744e-06, 6.2744e-06, 3.2583e-06, 2.7237e-06,
        5.3821e-06, 6.8903e-06, 2.7545e-06, 3.1114e-06, 1.1485e-05, 4.3452e-06,
        7.1650e-06, 4.5992e-06, 3.7734e-06, 7.0202e-06, 4.7716e-06, 4.3010e-06,
        6.2744e-06, 5.9814e-06, 3.5559e-06, 1.9635e-06, 3.1674e-06, 8.6520e-06,
        2.3800e-06, 2.8593e-07, 8.0630e-06, 4.2200e-06, 4.5992e-06, 5.2764e-06,
        4.5891e-06, 2.8242e-06, 3.8343e-06, 4.4597e-06, 8.6665e-06, 4.5992e-06,
        8.2595e-06, 7.5197e-06, 3.5345e-06, 2.4319e-06, 3.9917e-06, 2.7237e-06,
        8.8291e-06, 8.2526e-06, 8.1814e-06, 2.4516e-06, 5.6812e-06, 3.9724e-06,
        8.9312e-06, 4.2882e-06, 6.6103e-06, 3.1674e-06, 1.1485e-05, 3.4083e-06,
        7.9662e-06, 5.5837e-06, 8.0630e-06, 6.5337e-06, 4.5992e-06, 4.8080e-06,
        4.4621e-06, 3.6316e-06, 6.0721e-06, 4.8616e-06, 1.2441e-05, 8.2526e-06,
        9.3126e-06, 6.2744e-06, 6.6103e-06, 4.5891e-06, 5.6771e-06, 2.7977e-06,
        4.5891e-06, 4.5891e-06, 5.2873e-06, 5.8919e-06, 3.4101e-06, 6.0721e-06,
        1.4583e-06, 1.2441e-05, 3.2562e-06, 4.2312e-06, 2.7237e-06, 1.0812e-05,
        8.1814e-06, 6.0721e-06, 7.0202e-06, 8.2293e-06, 2.9309e-06, 5.2764e-06,
        3.0518e-06, 3.1674e-06, 5.1268e-06, 3.5782e-06, 8.6520e-06, 6.7074e-06,
        3.5559e-06, 4.6905e-06, 6.0721e-06, 3.6316e-06, 3.9724e-06, 4.5557e-06,
        1.7482e-06, 3.4160e-06, 7.4115e-06, 1.4583e-06, 7.5839e-06, 9.3126e-06,
        4.5891e-06, 5.7493e-06, 1.0143e-05, 5.2764e-06, 2.7426e-06, 6.8933e-06,
        3.1674e-06, 4.5992e-06, 2.1060e-06, 9.8731e-07, 2.9797e-06, 4.4668e-06,
        2.4516e-06, 4.6236e-06, 2.3119e-06, 2.9927e-06, 2.4516e-06, 2.4516e-06,
        5.3644e-06, 7.4115e-06, 8.6665e-06, 2.5088e-06, 5.1756e-06, 3.9917e-06,
        4.2882e-06, 4.5992e-06, 1.6088e-06, 4.5992e-06, 3.5345e-06, 1.1485e-05,
        4.5891e-06, 3.2583e-06, 5.8053e-06, 6.2744e-06, 1.1994e-05, 6.6919e-07,
        6.6103e-06, 6.2543e-06, 1.6664e-06, 9.3126e-06, 8.0630e-06, 3.7734e-06,
        4.5891e-06, 2.1170e-06, 6.8903e-06, 9.3126e-06, 5.3821e-06, 9.3126e-06,
        3.1674e-06, 5.0804e-06, 3.5191e-06, 3.6083e-06, 4.5992e-06, 3.7734e-06,
        1.1007e-01, 2.9927e-06, 5.2764e-06, 3.1674e-06, 2.9927e-06, 2.9927e-06,
        5.8919e-06, 4.3010e-06, 4.1660e-06, 5.8053e-06, 2.5536e-06, 3.6316e-06,
        1.5209e-05, 6.2744e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([9.5644e-07, 6.3263e-07, 1.1464e-06,  ..., 5.7236e-08, 6.0738e-07,
        3.3816e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([3.9160e-07, 1.1976e-06, 4.5160e-07,  ..., 1.9145e-06, 1.2926e-06,
        9.0595e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([2.9352e-06, 1.3887e-06, 4.5763e-06, 4.6379e-06, 3.3032e-06, 3.0110e-06,
        5.3838e-06, 1.5778e-06, 1.3309e-06, 1.6753e-06, 5.1862e-06, 1.9838e-06,
        3.3328e-06, 6.7195e-06, 9.2197e-07, 3.3821e-06, 1.9143e-06, 5.3838e-06,
        8.0037e-07, 4.3974e-06, 1.3309e-06, 6.3606e-06, 1.3657e-06, 2.2169e-06,
        4.7209e-07, 3.1948e-06, 2.0051e-06, 5.0729e-06, 3.2969e-06, 2.7791e-06,
        2.2717e-06, 1.2562e-06, 1.0195e-06, 2.8580e-06, 5.3790e-07, 3.6109e-06,
        7.8869e-06, 2.2169e-06, 3.1039e-06, 3.3328e-06, 5.7595e-06, 1.1922e-06,
        2.5003e-06, 4.8228e-06, 3.8478e-06, 4.1245e-06, 4.7807e-06, 1.9848e-06,
        1.4566e-06, 3.2800e-06, 3.3993e-06, 1.3309e-06, 1.3309e-06, 2.4612e-06,
        5.0729e-06, 1.3389e-06, 2.9356e-06, 6.9471e-06, 1.8508e-06, 3.4405e-06,
        3.3867e-06, 1.8508e-06, 3.0759e-06, 3.3257e-06, 1.8713e-06, 1.4827e-06,
        1.4328e-06, 3.7273e-06, 3.2737e-07, 2.7973e-07, 3.0761e-06, 6.7587e-06,
        1.6753e-06, 8.0037e-07, 1.3843e-06, 3.3867e-06, 3.0005e-06, 2.8283e-06,
        3.2453e-06, 9.1480e-07, 5.9271e-06, 4.5664e-06, 6.7195e-06, 1.9508e-06,
        2.7772e-06, 4.1245e-06, 2.3710e-06, 7.1317e-06, 5.3838e-06, 7.1317e-06,
        1.8508e-06, 4.6103e-06, 2.9770e-07, 2.2431e-06, 2.1139e-06, 2.7878e-07,
        2.9356e-06, 7.9245e-06, 2.4717e-06, 2.6274e-06, 6.0863e-07, 2.7411e-06,
        1.5373e-06, 3.0758e-06, 2.2031e-06, 4.1629e-07, 3.4989e-06, 2.7214e-06,
        4.3458e-06, 1.4328e-06, 4.0845e-06, 3.5783e-06, 2.7869e-06, 2.8129e-07,
        1.0077e-06, 3.4405e-06, 1.9839e-06, 2.4856e-06, 2.1261e-06, 2.7878e-07,
        3.6578e-06, 1.7739e-06, 2.4069e-06, 2.7995e-06, 1.3309e-06, 1.8508e-06,
        1.6182e-06, 4.8550e-06, 3.0111e-06, 1.1652e-06, 1.8910e-06, 2.9531e-06,
        1.0465e-06, 6.7195e-06, 2.7122e-06, 3.4405e-06, 3.9771e-06, 5.3838e-06,
        2.9356e-06, 2.3710e-06, 7.1643e-07, 1.2562e-06, 1.6822e-06, 9.2164e-07,
        6.3994e-06, 8.6165e-07, 1.2532e-06, 1.2444e-06, 2.8580e-06, 1.7368e-06,
        3.5974e-06, 4.5396e-06, 3.5242e-06, 3.0760e-06, 3.3329e-06, 5.3838e-06,
        3.9771e-06, 4.3258e-06, 3.3328e-06, 6.4226e-06, 3.3607e-06, 3.3328e-06,
        1.7368e-06, 2.9356e-06, 3.4231e-06, 1.6753e-06, 2.9355e-06, 3.3657e-06,
        3.3328e-06, 1.7368e-06, 3.3350e-06, 1.8906e-01, 2.7217e-06, 2.7997e-06,
        4.3974e-06, 4.6110e-06, 4.1392e-06, 2.7122e-06, 1.1277e-06, 2.7214e-06,
        4.5084e-06, 5.3838e-06, 7.2929e-06, 2.2169e-06, 5.0167e-06, 1.7663e-06,
        2.3218e-06, 3.4401e-06, 3.3867e-06, 8.1029e-06, 4.1377e-06, 4.7975e-06,
        8.9275e-07, 5.2647e-06, 9.4472e-06, 4.6379e-06, 6.7587e-06, 2.2451e-06,
        3.2062e-06, 5.8054e-06, 2.7791e-06, 1.3273e-06, 1.5019e-06, 4.5515e-06,
        1.0677e-06, 3.7541e-06, 2.3218e-06, 1.1237e-06, 2.8463e-06, 7.4859e-06,
        2.8742e-06, 2.1535e-06, 2.8190e-07, 4.0495e-06, 9.1228e-06, 3.5783e-06,
        2.8345e-06, 3.3867e-06, 1.8629e-01, 1.3906e-06, 2.0805e-06, 4.8550e-06,
        5.6162e-06, 3.4405e-06, 3.9771e-06, 3.3143e-06, 8.3008e-07, 3.3328e-06,
        2.8061e-06, 1.8694e-06, 1.5373e-06, 4.6103e-06, 1.7441e-07, 1.5268e-07,
        1.3309e-06, 6.1335e-06, 3.4405e-06, 3.1203e-06, 7.4859e-06, 2.6522e-06,
        1.4328e-06, 3.3729e-06, 5.3808e-07, 1.7226e-06, 4.0001e-06, 4.8228e-06,
        1.2562e-06, 1.8900e-06, 7.5889e-06, 9.3346e-07, 3.7273e-06, 1.3308e-06,
        9.2164e-07, 4.2117e-06, 8.5381e-07, 6.7195e-06, 1.7663e-06, 1.3309e-06,
        2.4082e-06, 1.4328e-06, 7.3653e-07, 4.3868e-06, 3.9772e-06, 7.4858e-06,
        6.3994e-06, 3.8424e-06, 6.3606e-06, 5.3838e-06, 4.6635e-06, 2.2169e-06,
        1.3657e-06, 2.3084e-06, 6.1767e-07, 2.0844e-06, 7.5889e-06, 1.1877e-06,
        3.3258e-06, 1.7368e-06, 1.2902e-06, 1.9848e-06, 1.3309e-06, 4.6103e-06,
        5.0353e-06, 1.8546e-06, 2.4991e-06, 3.6767e-06, 3.3993e-06, 2.6071e-06,
        2.2992e-06, 2.2992e-06, 6.9471e-06, 2.8079e-07, 2.2163e-06, 4.5913e-06,
        4.4534e-06, 7.0496e-07, 1.3974e-06, 2.9501e-06, 2.3218e-06, 3.4264e-06,
        6.0840e-07, 3.0746e-06, 2.1314e-06, 3.9928e-06, 5.2347e-06, 4.7021e-06,
        2.7122e-06, 9.1480e-07, 3.2787e-06, 3.3257e-06, 4.4157e-06, 2.8039e-07,
        7.1317e-06, 2.2431e-06, 1.0939e-01, 3.0122e-06, 9.1228e-06, 2.1099e-06,
        1.7826e-06, 2.0805e-06, 1.4307e-06, 1.2637e-01, 2.3084e-06, 1.1652e-06,
        1.3657e-06, 1.4060e-06, 2.2946e-06, 2.6351e-06, 2.2324e-06, 1.6936e-06,
        2.6903e-06, 2.0413e-06, 1.4328e-06, 3.4739e-06, 5.1247e-06, 3.4726e-06,
        1.8261e-06, 1.9435e-06, 1.7368e-06, 2.4991e-06, 2.7791e-06, 1.7368e-06,
        2.2992e-06, 8.6165e-07, 6.3994e-06, 2.2992e-06, 1.9924e-06, 2.4698e-06,
        1.9143e-06, 2.2731e-06, 5.3790e-07, 1.3352e-06, 4.7833e-06, 3.3328e-06,
        2.2169e-06, 3.9771e-06, 1.4894e-07, 1.6058e-06, 2.3084e-06, 5.7595e-06,
        1.8900e-06, 6.3607e-06, 7.4859e-06, 4.5664e-06, 2.7243e-06, 1.6776e-06,
        3.1038e-06, 9.4468e-06, 2.4612e-06, 4.3386e-06, 3.1998e-06, 3.2716e-06,
        4.3458e-06, 5.1466e-06, 2.7996e-06, 4.3458e-06, 2.7878e-07, 3.3867e-06,
        2.8055e-06, 4.7834e-06, 1.7890e-06, 3.0110e-06, 2.9453e-06, 2.1535e-06,
        4.7021e-06, 1.8687e-06, 2.1535e-06, 2.9705e-06, 2.7878e-07, 2.9356e-06,
        3.8862e-06, 1.7368e-06, 2.0869e-06, 3.2485e-06, 1.9838e-06, 3.0746e-06,
        1.4823e-06, 1.7368e-06, 2.2276e-06, 2.7878e-07, 2.4717e-06, 1.2985e-07,
        4.8228e-06, 6.3606e-06, 7.4859e-06, 2.1057e-06, 2.7997e-06, 3.2800e-06,
        1.7368e-06, 5.3577e-06, 3.6981e-06, 1.2562e-06, 1.3887e-06, 4.3458e-06,
        4.0653e-06, 3.1998e-06, 2.4698e-06, 3.2800e-06, 2.8663e-06, 5.9057e-06,
        2.8582e-06, 2.8062e-01, 3.9771e-06, 1.0993e-06, 1.3657e-06, 3.1154e-06,
        9.1480e-07, 3.0746e-06, 3.5036e-06, 3.3867e-06, 4.1186e-06, 5.0729e-06,
        4.6635e-06, 4.2283e-06, 2.8580e-06, 1.7441e-07, 3.4405e-06, 6.7587e-06,
        2.2169e-06, 2.7878e-07, 1.3657e-06, 1.6058e-06, 4.6379e-06, 5.6162e-06,
        6.1767e-07, 8.3842e-07, 3.3258e-06, 1.3657e-06, 3.1940e-06, 3.1940e-06,
        1.4341e-06, 3.0746e-06, 3.9771e-06, 2.8245e-06, 2.4856e-06, 5.9059e-06,
        2.7667e-06, 5.7819e-06, 5.3790e-07, 2.7313e-06, 3.3993e-06, 2.7122e-06,
        3.4404e-06, 1.6333e-06, 2.4991e-06, 2.1037e-01, 2.0517e-01, 1.1948e-06,
        1.4328e-06, 3.6592e-06, 5.0729e-06, 4.8552e-06, 1.8694e-06, 6.0863e-07,
        9.2163e-07, 6.3605e-06, 2.3084e-06, 1.2461e-06, 4.0495e-06, 1.9089e-06,
        4.5913e-06, 4.7833e-06, 3.3867e-06, 5.1466e-06, 6.3605e-06, 2.2731e-06,
        1.5373e-06, 1.3689e-06, 5.1421e-06, 3.6047e-06, 2.4991e-06, 2.8076e-07,
        2.9355e-06, 6.7195e-06, 1.5267e-06, 1.1277e-06, 3.2647e-06, 2.6522e-06,
        1.3389e-06, 6.3606e-06, 1.7368e-06, 3.3328e-06, 1.3309e-06, 1.3309e-06,
        3.4231e-06, 3.0066e-06, 3.3867e-06, 3.3258e-06, 3.2729e-06, 1.8508e-06,
        6.2546e-06, 2.6695e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.9398e-05, 1.0137e-05, 7.5167e-06, 8.2674e-06, 3.0878e-06, 1.0027e-05,
        7.2228e-06, 5.4948e-06, 9.1031e-06, 2.8732e-06, 4.9879e-06, 1.3877e-05,
        1.1649e-05, 1.1216e-05, 2.6580e-06, 6.1258e-06, 1.5615e-05, 1.3504e-05,
        1.8364e-05, 7.0199e-06, 9.1038e-06, 7.6672e-06, 1.7609e-05, 1.0704e-05,
        2.1624e-05, 4.2143e-06, 1.6486e-05, 1.2635e-05, 7.5167e-06, 8.4232e-06,
        6.9745e-06, 2.1624e-05, 3.7719e-06, 1.3959e-05, 4.6756e-06, 7.0634e-06,
        2.5805e-05, 1.1194e-05, 1.1183e-05, 6.5728e-06, 8.8562e-06, 2.5569e-05,
        2.3008e-05, 8.7916e-06, 1.2320e-05, 4.9879e-06, 1.3192e-05, 7.1971e-06,
        4.7793e-06, 1.4177e-05, 4.4502e-06, 1.6325e-05, 8.7762e-06, 2.2085e-05,
        7.1778e-06, 1.0077e-05, 6.5074e-06, 7.7027e-06, 1.9313e-05, 1.1544e-05,
        1.8229e-05, 9.4644e-06, 9.7368e-06, 4.5486e-06, 1.5640e-05, 1.3727e-05,
        5.3018e-06, 9.7368e-06, 8.9877e-06, 7.0120e-06, 1.0516e-01, 2.5055e-05,
        1.9368e-05, 7.7038e-06, 9.4786e-06, 7.8867e-06, 6.7880e-06, 1.4505e-05,
        2.0882e-05, 3.3520e-06, 7.5154e-06, 6.9141e-06, 3.5783e-06, 4.2143e-06,
        1.7286e-05, 8.3512e-06, 2.5723e-05, 1.0241e-01, 1.6487e-05, 1.7482e-05,
        7.1971e-06, 5.9160e-06, 1.2608e-05, 1.0756e-05, 1.8778e-05, 6.4595e-06,
        1.4547e-05, 1.9381e-05, 1.5657e-05, 1.2234e-05, 4.4581e-06, 8.5655e-02,
        5.5074e-06, 1.8381e-05, 1.0367e-05, 2.3114e-05, 1.1145e-05, 6.4684e-06,
        1.3249e-05, 1.8033e-05, 1.1036e-05, 9.9608e-06, 2.5431e-05, 6.3825e-06,
        7.7256e-06, 1.5936e-05, 9.8762e-06, 5.1227e-02, 5.9956e-06, 1.0105e-05,
        4.0945e-06, 2.6801e-06, 1.0141e-01, 8.8972e-06, 6.4669e-06, 5.1268e-06,
        1.0586e-05, 4.9853e-06, 1.7546e-05, 6.5638e-06, 7.8671e-06, 6.3751e-06,
        7.6753e-06, 7.7256e-06, 2.6217e-05, 1.0047e-05, 5.4948e-06, 1.0841e-05,
        1.4918e-05, 1.6021e-05, 9.6856e-06, 1.0586e-05, 7.7756e-06, 9.4785e-06,
        1.6290e-05, 1.8863e-05, 6.5638e-06, 1.0140e-05, 8.8232e-06, 7.0349e-06,
        3.9744e-06, 7.0895e-06, 1.4739e-05, 9.4691e-06, 1.2193e-05, 9.6478e-02,
        9.4691e-06, 1.2784e-05, 8.5604e-06, 8.0025e-06, 3.2714e-06, 8.3806e-06,
        4.5026e-06, 2.0675e-05, 2.1441e-05, 8.5969e-06, 1.1036e-05, 6.6177e-06,
        9.2853e-06, 7.7756e-06, 1.4761e-05, 1.2692e-05, 8.4882e-06, 8.8562e-06,
        1.2666e-05, 2.5130e-05, 9.0103e-06, 9.2362e-06, 4.6166e-06, 1.3463e-05,
        2.6217e-05, 1.7798e-05, 1.6122e-05, 8.7916e-06, 8.8561e-06, 1.1200e-05,
        1.4057e-05, 2.5569e-05, 5.2146e-06, 1.5575e-05, 1.2628e-05, 5.4948e-06,
        1.8330e-05, 8.6780e-06, 7.5167e-06, 1.3892e-05, 1.3200e-05, 9.3594e-06,
        8.7916e-06, 1.4564e-05, 5.7252e-06, 1.5785e-05, 1.9782e-05, 1.5169e-05,
        3.1034e-05, 1.0535e-05, 1.4399e-05, 2.1678e-05, 1.4026e-05, 1.1292e-06,
        1.3650e-05, 1.0756e-05, 1.0363e-05, 7.4085e-06, 8.3379e-06, 2.0808e-05,
        1.4178e-05, 1.0697e-05, 2.4368e-05, 7.5167e-06, 5.4948e-06, 8.0472e-06,
        6.4433e-06, 7.9660e-06, 4.3224e-06, 8.3806e-06, 8.8972e-06, 1.2334e-05,
        7.5167e-06, 4.8152e-06, 4.4502e-06, 5.0396e-06, 3.6922e-06, 1.5438e-05,
        9.7368e-06, 8.5761e-06, 1.3686e-05, 9.3438e-06, 1.1579e-05, 1.2424e-05,
        7.7365e-06, 8.1704e-06, 1.3172e-05, 1.5966e-05, 1.0156e-05, 1.3485e-05,
        8.6780e-06, 6.5638e-06, 1.7034e-05, 1.4229e-05, 6.5638e-06, 1.5521e-05,
        6.6177e-06, 7.3036e-06, 7.5167e-06, 1.1389e-05, 1.6890e-05, 1.4399e-05,
        7.7971e-06, 8.3510e-02, 2.5805e-05, 9.3438e-06, 9.3594e-06, 5.4948e-06,
        2.1624e-05, 1.0536e-05, 8.5515e-06, 1.1640e-05, 5.4948e-06, 1.3425e-05,
        2.9650e-06, 2.2524e-05, 1.1169e-05, 1.1579e-05, 8.6886e-06, 8.5604e-06,
        3.6253e-06, 1.2234e-05, 1.1200e-05, 9.9166e-06, 9.4785e-06, 1.3583e-05,
        7.0635e-06, 7.6138e-06, 8.5924e-06, 1.0535e-05, 1.0921e-05, 1.3172e-05,
        1.4229e-05, 2.0790e-05, 1.0192e-05, 1.5438e-05, 8.8869e-06, 9.6856e-06,
        1.0679e-05, 1.7482e-05, 1.8672e-05, 1.7720e-05, 1.2315e-05, 1.9323e-05,
        2.4368e-05, 6.4565e-06, 1.1182e-05, 8.8972e-06, 9.7368e-06, 1.4192e-05,
        1.2704e-05, 1.1655e-05, 1.1649e-05, 1.1205e-05, 1.2379e-06, 5.8122e-06,
        6.2029e-06, 5.1636e-06, 2.8736e-05, 5.6049e-06, 2.5188e-05, 5.1635e-06,
        1.2193e-05, 5.8122e-06, 1.0140e-05, 1.3959e-05, 1.0756e-05, 6.9773e-06,
        7.6753e-06, 1.3172e-05, 1.2738e-05, 8.9390e-06, 8.1229e-06, 7.4883e-06,
        6.4336e-06, 1.2395e-05, 9.3594e-06, 1.2133e-05, 5.8170e-06, 1.1782e-05,
        6.8855e-06, 1.8599e-05, 2.4368e-05, 1.7054e-05, 8.7916e-06, 6.1451e-06,
        1.8235e-05, 6.5319e-06, 1.2334e-05, 1.0355e-05, 1.8359e-05, 7.0985e-06,
        1.5692e-05, 2.4368e-05, 9.6616e-06, 5.0905e-06, 1.2959e-05, 9.3594e-06,
        8.9415e-06, 4.1200e-06, 9.4691e-06, 1.0149e-05, 2.0139e-05, 8.7916e-06,
        4.8420e-06, 1.7434e-05, 7.1793e-06, 1.5102e-05, 8.8561e-06, 1.0400e-05,
        9.5046e-06, 1.8793e-05, 1.0547e-05, 2.1402e-05, 4.5026e-06, 9.3766e-06,
        8.6874e-06, 9.2127e-06, 6.9773e-06, 2.1624e-05, 1.1579e-05, 1.0400e-05,
        5.8781e-06, 1.3504e-05, 1.1961e-05, 7.0349e-06, 1.4472e-05, 9.5705e-06,
        2.0882e-05, 1.5381e-05, 1.1250e-05, 7.6180e-06, 1.9323e-05, 1.2441e-05,
        2.5805e-05, 7.7038e-06, 9.4725e-06, 6.7729e-02, 2.4188e-05, 1.2470e-05,
        2.3808e-05, 2.1624e-05, 1.7482e-05, 2.2746e-05, 9.7368e-06, 7.5167e-06,
        8.5604e-06, 1.0695e-05, 2.4236e-05, 6.4565e-06, 5.4948e-06, 1.0647e-05,
        1.2133e-05, 1.4469e-05, 1.2692e-05, 4.3940e-06, 4.7616e-06, 4.2602e-06,
        6.9956e-06, 8.8529e-06, 2.3651e-06, 9.4785e-06, 9.8147e-02, 5.6851e-06,
        9.4838e-06, 1.5534e-05, 9.6049e-06, 1.9510e-05, 2.5798e-05, 8.4253e-06,
        7.6441e-07, 1.0790e-05, 7.6231e-06, 2.2923e-05, 5.2759e-06, 1.7720e-05,
        6.5638e-06, 6.1435e-06, 1.0535e-05, 1.9050e-06, 2.9150e-05, 1.2331e-05,
        7.2869e-06, 7.0349e-06, 7.2869e-06, 8.0723e-06, 1.2118e-05, 6.5582e-02,
        3.6922e-06, 1.5242e-05, 1.3172e-05, 9.5046e-06, 3.3715e-06, 1.5692e-05,
        8.8561e-06, 1.0756e-05, 6.1833e-06, 2.0150e-05, 2.4909e-05, 8.3018e-06,
        1.3755e-05, 5.9160e-06, 6.3825e-06, 1.2441e-05, 1.0536e-05, 7.6753e-06,
        1.3877e-05, 2.4368e-05, 1.2329e-05, 3.9887e-06, 2.5805e-05, 1.3172e-05,
        1.0047e-05, 2.8736e-05, 9.7368e-06, 1.1461e-05, 9.4691e-06, 4.0272e-06,
        5.3018e-06, 7.6231e-06, 9.8708e-06, 4.2558e-06, 1.0355e-05, 3.9744e-06,
        4.6663e-06, 1.6568e-05, 2.6052e-06, 1.1867e-05, 8.3512e-06, 7.2961e-02,
        1.0323e-05, 1.8682e-05, 1.4948e-05, 8.3223e-02, 2.4188e-05, 8.3512e-06,
        2.5364e-06, 1.6510e-05, 2.2129e-05, 9.4691e-06, 7.5167e-06, 5.4971e-06,
        4.2274e-06, 1.7665e-05, 2.4188e-05, 1.0149e-05, 1.1183e-05, 7.0349e-06,
        1.2678e-05, 7.7027e-06, 7.5154e-06, 4.1021e-06, 7.7756e-06, 2.1122e-05,
        1.0027e-05, 1.1649e-05], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.4875e-06, 1.2772e-06, 2.5556e-06,  ..., 1.6157e-06, 1.3700e-06,
        2.4980e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([2.2368e-06, 6.8912e-08, 6.6268e-06, 3.7015e-06, 5.1604e-06, 2.0899e-06,
        7.4153e-06, 4.2848e-06, 4.7168e-06, 6.3861e-06, 3.4478e-06, 2.0992e-07,
        6.7850e-06, 3.6262e-06, 5.4008e-06, 7.0567e-06, 4.0783e-06, 2.2910e-06,
        5.6278e-06, 4.4038e-06, 6.0974e-06, 3.3798e-06, 4.6491e-06, 4.7280e-06,
        1.2187e-06, 9.2490e-06, 1.2818e-05, 1.8580e-06, 3.6444e-06, 2.6800e-06,
        3.5948e-06, 4.0910e-06, 5.6112e-06, 4.5946e-06, 4.4800e-06, 3.6439e-06,
        6.1968e-06, 5.5972e-06, 4.5223e-06, 6.1151e-06, 4.0910e-06, 9.6697e-07,
        5.1957e-06, 6.1847e-06, 6.8310e-06, 3.1056e-06, 6.0148e-06, 6.4030e-06,
        4.0910e-06, 6.3005e-06, 2.1055e-06, 2.0261e-06, 9.3003e-06, 1.4825e-06,
        1.9718e-06, 4.2081e-06, 6.0204e-06, 6.4238e-06, 2.8335e-06, 3.7728e-06,
        6.5567e-06, 6.7090e-06, 4.5433e-06, 1.4259e-06, 6.2890e-06, 5.6434e-06,
        4.0728e-06, 2.0666e-06, 1.0957e-05, 5.7205e-06, 7.9079e-06, 8.2951e-06,
        1.7447e-06, 4.7843e-06, 3.3579e-06, 5.6708e-06, 4.0910e-06, 5.3134e-06,
        5.3046e-06, 3.8711e-06, 5.6107e-06, 1.4122e-06, 3.1674e-06, 2.4094e-06,
        1.9444e-06, 4.4857e-06, 6.9064e-06, 8.7131e-06, 3.8095e-06, 5.5239e-06,
        5.6111e-06, 9.2490e-06, 1.8776e-06, 9.2018e-06, 3.8462e-06, 5.8032e-06,
        4.4384e-06, 2.8335e-06, 4.0382e-06, 8.2951e-06, 8.3895e-06, 6.7936e-06,
        5.4795e-06, 2.6049e-06, 4.4038e-06, 4.3121e-06, 5.3046e-06, 4.9793e-06,
        4.1495e-06, 7.1292e-06, 3.7795e-06, 1.8776e-06, 1.1564e-05, 3.8094e-06,
        2.5459e-06, 6.9550e-06, 5.8032e-06, 9.1573e-06, 3.6262e-06, 3.1780e-06,
        5.4873e-06, 4.5946e-06, 6.4226e-06, 3.7400e-06, 6.3720e-06, 4.4420e-06,
        2.3660e-06, 6.3378e-06, 5.5011e-06, 3.1674e-06, 7.7735e-06, 4.7988e-06,
        3.6705e-06, 6.0513e-06, 6.5567e-06, 3.1893e-06, 2.5852e-06, 3.8094e-06,
        5.1960e-06, 2.4721e-06, 2.9792e-06, 4.4442e-06, 7.9981e-06, 6.5198e-07,
        5.1635e-06, 4.7378e-06, 8.3895e-06, 1.4126e-06, 4.5098e-06, 2.3813e-06,
        8.5514e-06, 4.6827e-06, 7.9446e-06, 2.1844e-06, 7.0017e-06, 1.6569e-06,
        2.8558e-06, 5.5670e-06, 4.3393e-06, 4.0382e-06, 4.3568e-06, 3.5043e-06,
        4.0307e-06, 2.5688e-06, 1.1111e-05, 2.5176e-06, 2.2777e-06, 5.6492e-06,
        3.3400e-06, 6.5796e-06, 6.3471e-06, 5.3085e-06, 4.7168e-06, 2.8558e-06,
        4.0910e-06, 3.8892e-06, 9.7072e-06, 5.9081e-06, 2.6013e-06, 3.3710e-06,
        2.6456e-06, 1.3344e-06, 3.5713e-06, 8.0227e-06, 4.8649e-06, 8.3025e-06,
        1.3704e-05, 4.0910e-06, 5.8977e-06, 8.6487e-06, 1.4877e-06, 4.2501e-06,
        1.2469e-06, 2.8758e-06, 2.8736e-06, 4.0910e-06, 2.0158e-06, 1.9538e-06,
        5.7625e-06, 4.9722e-06, 4.4420e-06, 8.3895e-06, 4.3838e-06, 3.8094e-06,
        8.2951e-06, 3.1503e-06, 2.5514e-06, 5.4946e-06, 7.0333e-06, 1.2884e-06,
        3.3372e-06, 2.8603e-07, 4.7642e-06, 2.2910e-06, 6.1428e-06, 2.6331e-06,
        3.0556e-06, 3.7886e-06, 3.9184e-06, 1.8411e-06, 8.1663e-07, 2.8755e-06,
        5.8032e-06, 1.4781e-06, 4.2498e-06, 5.5011e-06, 1.1384e-06, 3.8711e-06,
        8.2119e-06, 6.1315e-06, 7.3366e-06, 6.8174e-06, 3.6627e-06, 4.9964e-06,
        2.8335e-06, 7.6192e-06, 5.0135e-06, 1.3745e-06, 4.8371e-06, 5.8032e-06,
        7.6850e-06, 4.8600e-06, 4.8841e-06, 5.3781e-06, 3.7795e-06, 5.9259e-06,
        2.2404e-06, 6.4238e-06, 4.7642e-06, 7.9760e-07, 7.7735e-06, 6.1824e-06,
        5.1604e-06, 6.5557e-07, 6.4291e-06, 9.0405e-06, 1.5388e-06, 1.1988e-05,
        4.1909e-06, 5.3158e-06, 7.2711e-06, 4.9618e-06, 8.1793e-06, 7.9483e-06,
        2.4835e-06, 2.3813e-06, 5.8032e-06, 2.3815e-06, 4.0910e-06, 2.8757e-06,
        2.4325e-06, 2.7596e-06, 7.8983e-06, 7.0333e-06, 4.3894e-06, 3.8600e-06,
        5.4008e-06, 8.2576e-06, 4.1858e-06, 9.1037e-06, 4.0440e-06, 3.7291e-06,
        2.9792e-06, 3.7527e-06, 5.9601e-06, 2.4094e-06, 9.0460e-06, 3.9490e-06,
        8.7886e-06, 3.7886e-06, 3.7728e-06, 1.0454e-06, 2.1698e-06, 5.4946e-06,
        5.1512e-06, 2.5585e-06, 3.9726e-06, 1.3723e-06, 5.1003e-06, 3.6262e-06,
        2.0158e-06, 4.2215e-06, 5.9822e-06, 4.0904e-06, 4.3828e-06, 2.3054e-06,
        8.2119e-06, 9.7760e-06, 5.1957e-06, 4.7642e-06, 6.5963e-06, 6.5198e-07,
        4.4038e-06, 4.5926e-06, 1.2469e-06, 8.8284e-06, 4.3838e-06, 2.6456e-06,
        5.9194e-06, 6.1293e-06, 1.8407e-06, 4.1751e-06, 1.4915e-06, 5.2782e-06,
        2.7188e-06, 2.2000e-06, 1.9251e-06, 8.4949e-06, 1.7447e-06, 1.7447e-06,
        6.5240e-06, 4.3370e-06, 7.5312e-06, 3.3414e-06, 3.4746e-06, 3.6444e-06,
        9.4627e-06, 4.0910e-06, 6.5933e-06, 4.0917e-06, 6.3359e-06, 7.9483e-06,
        7.3953e-06, 1.4172e-06, 2.3813e-06, 1.7447e-06, 6.0562e-06, 1.2655e-07,
        3.6816e-06, 7.2740e-06, 2.4111e-06, 2.4094e-06, 3.8095e-06, 8.3895e-06,
        5.5825e-06, 4.1240e-06, 5.1957e-06, 4.3291e-06, 4.9068e-06, 6.0068e-06,
        6.7288e-06, 6.5511e-06, 5.8977e-06, 6.0204e-06, 9.8341e-06, 4.9068e-06,
        2.4887e-06, 3.6262e-06, 4.1453e-06, 6.0885e-06, 5.5670e-06, 2.5449e-06,
        2.5139e-06, 3.7044e-06, 5.3085e-06, 3.8094e-06, 3.8709e-06, 4.8466e-07,
        1.4122e-06, 6.5198e-07, 3.3644e-06, 6.3720e-06, 4.6308e-06, 8.2951e-06,
        2.5128e-06, 9.3779e-06, 3.0860e-06, 1.3646e-05, 1.8776e-06, 2.4514e-06,
        1.9251e-06, 6.5495e-06, 1.5388e-06, 5.0593e-06, 2.4703e-06, 4.1394e-06,
        4.3023e-06, 1.4122e-06, 9.6690e-07, 2.5128e-06, 3.4985e-06, 6.1398e-06,
        6.0044e-06, 6.1629e-06, 3.1364e-06, 4.3838e-06, 4.0910e-06, 6.0404e-06,
        1.3783e-06, 5.0300e-06, 4.3629e-06, 5.3085e-06, 6.9277e-06, 3.9138e-06,
        1.1661e-05, 3.8094e-06, 3.4985e-06, 2.8957e-06, 2.2416e-06, 3.8133e-06,
        1.5852e-06, 5.5920e-06, 3.1893e-06, 3.2140e-06, 1.2422e-05, 1.0217e-05,
        1.6293e-06, 4.0307e-06, 4.0910e-06, 5.5920e-06, 2.9792e-06, 2.2000e-06,
        4.8907e-06, 2.5139e-06, 2.1698e-06, 4.1304e-06, 6.2690e-06, 9.2744e-06,
        6.4238e-06, 6.2890e-06, 8.2384e-06, 7.2851e-06, 1.5388e-06, 4.0910e-06,
        5.0331e-06, 1.1661e-05, 4.0910e-06, 6.0204e-06, 2.2910e-06, 2.8558e-06,
        4.6805e-06, 4.4038e-06, 2.6173e-06, 7.3920e-06, 9.1037e-06, 1.9071e-06,
        2.8750e-06, 2.9180e-06, 4.9225e-06, 2.8742e-06, 4.9979e-06, 2.9582e-06,
        4.7168e-06, 3.3454e-06, 3.7384e-06, 6.0974e-06, 1.0766e-06, 5.2089e-06,
        4.9011e-06, 6.0044e-06, 4.1152e-06, 3.2635e-06, 4.2501e-06, 5.0730e-06,
        5.3614e-06, 8.0155e-06, 2.7358e-06, 5.9822e-06, 5.9259e-06, 1.7453e-06,
        3.4847e-06, 4.1805e-06, 7.5311e-06, 9.2490e-06, 4.8876e-06, 1.3723e-06,
        5.1512e-06, 4.9964e-06, 3.8648e-06, 4.3838e-06, 5.0368e-06, 6.0204e-06,
        4.6396e-06, 1.0039e-05, 2.4674e-06, 2.0096e-06, 1.4122e-06, 2.4703e-06,
        2.2177e-06, 5.0135e-06, 2.2368e-06, 1.4289e-06, 5.8032e-06, 2.0710e-06,
        1.0766e-06, 3.6992e-06, 5.2368e-06, 1.7511e-06, 1.2469e-06, 3.8094e-06,
        3.7795e-06, 1.0475e-05], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.0836e-05, 1.6970e-05, 1.0182e-05, 1.0708e-05, 7.9257e-06, 7.9650e-06,
        1.3150e-05, 1.4108e-05, 1.0182e-05, 8.5849e-06, 5.3549e-06, 7.8519e-06,
        9.2171e-06, 1.2976e-05, 1.3207e-05, 1.1322e-05, 8.2323e-06, 2.3425e-05,
        1.3397e-05, 2.1888e-05, 8.8963e-06, 1.1589e-05, 2.4145e-05, 1.1403e-05,
        1.1270e-05, 5.5575e-06, 1.1055e-05, 9.4076e-06, 1.1452e-05, 8.4634e-06,
        1.4074e-05, 1.7224e-05, 1.8057e-05, 5.7614e-06, 1.0404e-05, 1.0458e-05,
        1.1123e-05, 5.6673e-06, 1.0315e-05, 7.0999e-06, 6.0791e-06, 9.6840e-06,
        6.7942e-06, 1.1224e-05, 1.2608e-05, 4.3310e-06, 1.1322e-05, 1.8138e-05,
        2.8697e-06, 4.1865e-06, 1.2346e-05, 1.5654e-05, 5.7165e-06, 8.6233e-06,
        1.3889e-05, 5.6673e-06, 9.7240e-06, 8.7613e-06, 8.9033e-06, 5.2485e-06,
        3.1220e-06, 1.3095e-05, 1.8392e-05, 1.1620e-05, 3.2372e-06, 1.6639e-05,
        7.9494e-06, 2.3425e-05, 6.7942e-06, 1.4705e-05, 1.0204e-05, 5.8987e-06,
        1.4327e-05, 8.4793e-06, 9.5453e-06, 3.0850e-06, 5.9561e-06, 1.4074e-05,
        9.6606e-06, 9.6034e-06, 1.4898e-05, 7.7996e-06, 7.0983e-06, 7.1515e-06,
        7.1204e-06, 8.2323e-06, 1.6342e-05, 1.0313e-05, 1.6168e-05, 7.2960e-06,
        1.4217e-05, 1.3468e-05, 1.2416e-05, 5.2936e-06, 2.0299e-05, 1.3415e-05,
        9.5453e-06, 9.4074e-06, 5.5575e-06, 8.5599e-06, 1.5303e-05, 1.0404e-05,
        8.7012e-06, 1.7250e-05, 2.3424e-05, 1.3545e-05, 7.6126e-06, 6.0791e-06,
        7.2370e-06, 1.1403e-05, 5.9168e-06, 1.1530e-05, 5.5575e-06, 8.1589e-06,
        9.0395e-06, 9.6058e-06, 1.4976e-05, 4.8010e-06, 9.4076e-06, 1.6457e-05,
        6.7131e-06, 7.1023e-06, 7.8599e-06, 1.4679e-05, 3.6974e-06, 5.4173e-06,
        1.3535e-05, 1.2558e-05, 1.3870e-05, 1.0182e-05, 9.0659e-06, 2.1645e-05,
        1.1686e-05, 5.5575e-06, 8.3085e-06, 6.1827e-06, 9.4318e-06, 2.1369e-05,
        6.2686e-06, 2.2821e-05, 9.2731e-06, 9.0659e-06, 2.0051e-05, 4.3883e-06,
        1.0424e-05, 1.7236e-05, 1.6310e-05, 1.7582e-05, 1.3692e-05, 2.4325e-05,
        6.2614e-06, 4.2994e-06, 1.0819e-05, 4.5402e-06, 9.0221e-06, 1.4289e-05,
        1.3862e-05, 6.9074e-06, 1.4959e-05, 2.5417e-06, 5.7681e-06, 7.7696e-06,
        5.9168e-06, 1.2328e-05, 1.6752e-05, 1.1686e-05, 1.2261e-05, 9.5453e-06,
        2.1645e-05, 8.4634e-06, 3.8827e-06, 1.5293e-05, 1.7724e-05, 8.2736e-06,
        1.2024e-05, 2.2569e-05, 4.0311e-06, 8.7012e-06, 1.8434e-05, 1.9247e-06,
        9.1675e-06, 1.0606e-05, 6.7887e-06, 7.0922e-06, 1.5082e-05, 1.1010e-05,
        2.3594e-05, 8.7200e-06, 8.7516e-06, 1.4959e-05, 1.2210e-05, 8.3402e-06,
        4.1865e-06, 8.4635e-06, 6.2246e-06, 9.2514e-06, 9.9891e-06, 9.6575e-06,
        1.0505e-05, 9.4195e-06, 3.9737e-06, 1.5491e-05, 1.1309e-05, 5.5350e-06,
        1.1397e-06, 5.1086e-06, 1.9386e-05, 1.2328e-05, 1.1686e-05, 1.4031e-05,
        1.2549e-05, 8.4635e-06, 1.3548e-05, 7.9257e-06, 1.2608e-05, 8.4263e-06,
        2.2579e-05, 8.6233e-06, 5.5350e-06, 8.7012e-06, 5.5575e-06, 1.8915e-05,
        3.4432e-06, 5.9778e-06, 1.4422e-05, 1.0404e-05, 1.2210e-05, 9.8022e-06,
        9.4765e-06, 4.8010e-06, 1.0708e-05, 1.7543e-05, 2.1369e-05, 2.4664e-06,
        9.1815e-06, 1.1443e-05, 1.9160e-05, 6.3303e-06, 1.3570e-05, 6.7155e-06,
        8.6467e-06, 2.8009e-05, 1.6074e-05, 1.2992e-05, 1.2842e-05, 8.4636e-06,
        4.4534e-06, 9.4765e-06, 1.2210e-05, 1.3332e-05, 1.4818e-05, 6.6800e-06,
        1.0643e-05, 3.1220e-06, 6.9530e-06, 1.9792e-05, 8.8697e-06, 5.7614e-06,
        1.0368e-05, 3.4897e-06, 6.3036e-06, 8.1589e-06, 6.1663e-06, 9.4042e-06,
        2.1590e-05, 7.8622e-06, 1.0184e-05, 7.0922e-06, 1.4053e-05, 1.6695e-05,
        7.9650e-06, 1.5617e-05, 6.1703e-06, 9.5453e-06, 4.0951e-06, 1.1291e-05,
        6.9476e-06, 3.8584e-06, 1.0703e-05, 1.1018e-05, 9.7240e-06, 5.7139e-06,
        1.0028e-05, 1.7523e-05, 1.3776e-05, 5.7654e-06, 1.7724e-05, 1.1552e-05,
        7.7696e-06, 1.2819e-05, 2.5959e-05, 1.0182e-05, 1.0836e-05, 2.3784e-05,
        9.6034e-06, 4.9197e-06, 1.0325e-05, 2.0751e-05, 1.1010e-05, 1.5916e-06,
        5.7514e-06, 1.0643e-05, 1.7139e-05, 1.9779e-05, 5.9505e-06, 1.0182e-05,
        1.9779e-05, 5.8638e-06, 4.5293e-06, 5.5350e-06, 8.8460e-06, 7.4430e-06,
        7.4928e-06, 1.0850e-05, 8.1296e-06, 1.0643e-05, 1.9160e-05, 1.1010e-05,
        9.6034e-06, 4.8010e-06, 5.0019e-06, 6.1745e-06, 9.6240e-06, 1.2064e-05,
        2.2958e-05, 2.0695e-05, 4.7295e-06, 5.8023e-06, 6.9476e-06, 5.6633e-06,
        4.8010e-06, 6.7155e-06, 1.3814e-05, 7.8275e-06, 2.1990e-05, 9.9647e-06,
        3.3459e-06, 5.3455e-06, 8.4190e-06, 4.8010e-06, 7.8700e-06, 1.1010e-05,
        3.5334e-06, 9.5125e-06, 1.2831e-05, 1.7224e-05, 1.1665e-05, 4.5934e-06,
        4.7127e-06, 1.3118e-05, 1.7582e-05, 2.4664e-06, 9.0221e-06, 2.4664e-06,
        1.2608e-05, 1.0643e-05, 1.7330e-05, 5.7696e-06, 7.4967e-06, 3.5873e-06,
        1.5491e-05, 1.6490e-06, 9.4076e-06, 1.3095e-05, 4.5402e-06, 1.0183e-05,
        5.5117e-06, 4.8373e-06, 8.6785e-06, 9.9452e-06, 1.6104e-05, 3.8185e-06,
        5.7696e-06, 1.3982e-05, 6.1745e-06, 8.1367e-06, 1.1112e-05, 1.1291e-05,
        6.6800e-06, 1.0483e-05, 1.3576e-05, 1.6639e-05, 2.5950e-05, 9.4195e-06,
        1.6752e-05, 6.3303e-06, 1.1686e-05, 1.4422e-05, 1.1620e-05, 8.4635e-06,
        1.1018e-05, 9.9029e-06, 6.1290e-06, 1.1665e-05, 1.1686e-05, 1.0500e-05,
        8.8352e-06, 1.5705e-05, 9.0591e-06, 6.0791e-06, 5.5156e-06, 1.1744e-05,
        8.4675e-06, 1.9061e-05, 1.9247e-06, 9.9120e-06, 1.9036e-05, 1.2608e-05,
        1.2842e-05, 1.3659e-05, 3.6602e-06, 4.5618e-06, 1.4083e-05, 1.4123e-05,
        7.7696e-06, 7.4430e-06, 1.8103e-05, 1.4139e-05, 4.8010e-06, 1.5379e-05,
        8.6467e-06, 2.4664e-06, 1.4608e-05, 5.7614e-06, 9.4073e-06, 1.0547e-05,
        8.4525e-06, 9.5453e-06, 1.5222e-05, 1.8138e-05, 7.9378e-06, 6.7942e-06,
        1.1403e-05, 7.7413e-06, 7.5002e-06, 1.4782e-05, 6.9188e-06, 1.1375e-05,
        3.3601e-06, 1.0597e-05, 1.3158e-05, 1.2307e-05, 9.2416e-06, 1.4780e-05,
        9.4076e-06, 9.4073e-06, 8.5176e-06, 1.4848e-05, 5.9793e-06, 1.0037e-05,
        4.5402e-06, 1.8434e-05, 9.4323e-06, 1.3124e-05, 8.8352e-06, 4.0702e-06,
        5.9779e-06, 1.1206e-05, 8.0402e-06, 1.1254e-05, 2.6908e-06, 5.9505e-06,
        5.5575e-06, 7.9949e-06, 1.6954e-05, 1.2913e-05, 9.8308e-06, 6.7372e-06,
        1.1322e-05, 1.1552e-05, 8.8460e-06, 5.2936e-06, 5.8742e-06, 1.7678e-05,
        7.9857e-06, 3.8692e-06, 2.4586e-06, 1.6362e-05, 8.3330e-06, 1.0332e-05,
        1.3415e-05, 7.5575e-06, 1.6457e-05, 3.6974e-06, 2.2261e-05, 5.5575e-06,
        1.0136e-05, 4.7700e-06, 2.4664e-06, 6.7131e-06, 4.0881e-06, 1.3095e-05,
        1.1578e-05, 8.4200e-06, 1.0490e-05, 1.2134e-05, 9.6034e-06, 8.4190e-06,
        1.2390e-05, 4.9833e-06, 1.1411e-05, 2.2261e-05, 4.8985e-06, 9.9029e-06,
        2.1369e-05, 1.8890e-05, 1.4658e-05, 1.0313e-05, 2.8754e-06, 9.4076e-06,
        8.8697e-06, 9.6034e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([5.7025e-07, 5.9074e-07, 1.2344e-06,  ..., 1.2161e-06, 1.2386e-06,
        5.5455e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.1844, 1.5226, 1.3760, 0.9125, 1.1625, 1.5041, 1.7238, 1.6247, 1.4539,
        1.7900, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223,
        0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223,
        0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223,
        0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223,
        0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223,
        0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223,
        0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223,
        0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223,
        0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223,
        0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223, 0.0223,
        0.0223], device='cuda:0', grad_fn=<NormBackward1>)

 sparsity of   [0.0, 0.0, 1.0, 0.0, 0.03703703731298447, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14814814925193787, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.1111111119389534, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.03703703731298447, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.03703703731298447, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [1.0, 1.0, 0.359375, 0.390625, 0.34375, 1.0, 1.0, 1.0, 0.359375, 0.359375, 1.0, 0.34375, 0.34375, 1.0, 0.34375, 0.34375, 0.34375, 0.34375, 0.359375, 1.0, 1.0, 1.0, 0.34375, 0.359375, 0.375, 0.359375, 0.34375, 0.359375, 0.34375, 0.359375, 0.34375, 0.359375, 0.359375, 0.34375, 0.375, 0.34375, 0.390625, 1.0, 0.34375, 0.34375, 0.359375, 0.375, 0.375, 1.0, 0.34375, 1.0, 1.0, 0.34375, 0.34375, 0.34375, 1.0, 0.34375, 0.34375, 1.0, 1.0, 0.359375, 0.34375, 0.34375, 0.34375, 1.0, 0.34375, 1.0, 0.359375, 0.34375]

 sparsity of   [0.3020833432674408, 1.0, 0.2986111044883728, 1.0, 1.0, 0.3038194477558136, 1.0, 1.0, 1.0, 1.0, 0.3107638955116272, 1.0, 1.0, 0.296875, 1.0, 1.0, 0.2986111044883728, 0.3072916567325592, 0.347222238779068, 1.0, 1.0, 0.3055555522441864, 0.2986111044883728, 1.0, 1.0, 1.0, 0.300347238779068, 1.0, 0.3072916567325592, 0.300347238779068, 1.0, 0.2986111044883728, 1.0, 1.0, 0.3020833432674408, 1.0, 1.0, 0.3020833432674408, 1.0, 0.2986111044883728, 0.2986111044883728, 1.0, 0.300347238779068, 0.300347238779068, 0.3020833432674408, 0.3055555522441864, 0.300347238779068, 1.0, 0.300347238779068, 1.0, 0.300347238779068, 1.0, 1.0, 1.0, 1.0, 0.3055555522441864, 0.2986111044883728, 1.0, 1.0, 0.2986111044883728, 1.0, 0.300347238779068, 0.296875, 1.0]

 sparsity of   [0.546875, 0.53125, 0.53125, 1.0, 0.53125, 1.0, 0.53125, 1.0, 0.546875, 0.515625, 0.53125, 1.0, 0.515625, 0.515625, 0.515625, 0.53125, 1.0, 0.53125, 0.515625, 1.0, 0.53125, 0.53125, 1.0, 0.515625, 0.53125, 0.53125, 0.53125, 0.53125, 0.53125, 0.53125, 0.53125, 0.53125, 0.53125, 1.0, 0.53125, 0.515625, 0.515625, 0.53125, 0.53125, 1.0, 0.53125, 0.53125, 0.515625, 1.0, 0.53125, 0.515625, 1.0, 0.53125, 0.515625, 0.546875, 0.515625, 0.546875, 0.53125, 0.546875, 0.53125, 0.5625, 1.0, 0.53125, 0.53125, 0.515625, 0.53125, 0.53125, 0.515625, 1.0, 0.53125, 0.53125, 0.515625, 0.53125, 0.53125, 0.53125, 1.0, 0.53125, 1.0, 0.53125, 0.53125, 0.53125, 0.53125, 0.515625, 0.515625, 0.53125, 1.0, 1.0, 0.53125, 0.53125, 0.53125, 0.515625, 0.546875, 1.0, 1.0, 1.0, 0.53125, 1.0, 0.53125, 0.515625, 1.0, 0.53125, 0.53125, 1.0, 0.53125, 0.53125, 0.515625, 0.515625, 0.515625, 0.53125, 0.53125, 0.515625, 0.53125, 0.515625, 0.53125, 0.53125, 0.515625, 0.53125, 0.53125, 0.53125, 1.0, 1.0, 1.0, 0.53125, 0.53125, 0.515625, 0.515625, 0.53125, 1.0, 1.0, 1.0, 0.53125, 1.0, 0.515625, 0.53125, 0.515625, 0.53125, 0.546875, 1.0, 1.0, 1.0, 0.515625, 1.0, 0.53125, 0.546875, 0.53125, 0.53125, 1.0, 0.53125, 0.515625, 0.53125, 1.0, 0.515625, 1.0, 0.515625, 0.53125, 0.53125, 0.515625, 0.515625, 1.0, 1.0, 0.546875, 0.53125, 0.515625, 0.546875, 0.53125, 0.515625, 0.53125, 0.515625, 0.53125, 0.53125, 1.0, 0.53125, 0.53125, 0.53125, 1.0, 0.53125, 1.0, 0.515625, 0.515625, 0.515625, 1.0, 0.53125, 1.0, 0.53125, 0.53125, 0.515625, 0.546875, 1.0, 0.53125, 0.53125, 0.53125, 1.0, 0.546875, 0.53125, 1.0, 0.515625, 0.515625, 0.53125, 1.0, 0.515625, 0.515625, 0.53125, 0.546875, 1.0, 1.0, 0.53125, 0.53125, 0.515625, 1.0, 0.53125, 0.53125, 0.53125, 0.515625, 0.53125, 0.53125, 1.0, 0.515625, 0.53125, 0.53125, 0.53125, 1.0, 0.515625, 1.0, 0.515625, 0.53125, 0.53125, 0.53125, 0.53125, 0.53125, 0.546875, 0.546875, 0.53125, 0.53125, 0.53125, 1.0, 0.53125, 0.53125, 1.0, 1.0, 0.53125, 0.53125, 0.53125, 0.515625, 1.0, 0.546875, 0.53125, 0.53125, 0.53125, 0.53125, 0.53125, 1.0, 0.53125, 0.53125, 0.53125, 0.515625, 0.53125, 0.53125, 0.53125, 1.0, 1.0, 0.53125]

 sparsity of   [0.359375, 0.34375, 0.34375, 0.46875, 0.34375, 1.0, 0.453125, 1.0, 0.34375, 0.34375, 0.34375, 1.0, 0.34375, 0.34375, 0.40625, 0.34375, 1.0, 0.34375, 0.390625, 1.0, 0.34375, 0.359375, 1.0, 0.359375, 0.359375, 0.34375, 0.4375, 0.359375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 1.0, 0.34375, 0.390625, 0.34375, 0.34375, 0.390625, 1.0, 0.34375, 0.34375, 0.34375, 1.0, 0.34375, 0.390625, 1.0, 0.34375, 0.359375, 0.34375, 0.34375, 0.34375, 0.359375, 0.359375, 0.359375, 0.34375, 1.0, 0.359375, 0.34375, 0.4375, 0.375, 0.34375, 0.375, 1.0, 0.34375, 0.34375, 0.34375, 0.34375, 0.359375, 0.34375, 1.0, 0.34375, 1.0, 1.0, 0.34375, 0.34375, 0.34375, 0.359375, 0.34375, 0.34375, 1.0, 1.0, 0.375, 1.0, 0.359375, 0.453125, 0.359375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.375, 0.359375, 1.0, 0.359375, 0.34375, 1.0, 0.359375, 0.359375, 0.34375, 0.390625, 0.34375, 0.359375, 0.359375, 0.34375, 0.375, 0.34375, 0.453125, 0.34375, 0.34375, 0.359375, 0.390625, 0.34375, 1.0, 1.0, 1.0, 0.359375, 0.375, 0.359375, 0.34375, 0.34375, 1.0, 1.0, 1.0, 0.34375, 1.0, 0.375, 0.34375, 0.359375, 0.34375, 0.34375, 1.0, 1.0, 1.0, 0.359375, 1.0, 0.34375, 0.34375, 0.359375, 0.34375, 1.0, 0.359375, 0.375, 0.359375, 1.0, 0.40625, 1.0, 0.4375, 0.34375, 0.390625, 0.34375, 0.390625, 0.34375, 1.0, 0.359375, 0.34375, 0.390625, 0.34375, 0.34375, 0.359375, 0.34375, 0.34375, 0.375, 1.0, 1.0, 0.34375, 0.359375, 0.34375, 1.0, 0.4375, 1.0, 0.375, 1.0, 0.375, 1.0, 0.34375, 1.0, 0.359375, 0.34375, 0.34375, 0.34375, 1.0, 0.34375, 0.359375, 0.359375, 1.0, 0.390625, 0.34375, 1.0, 0.34375, 0.375, 0.34375, 1.0, 0.34375, 0.359375, 0.34375, 0.390625, 1.0, 1.0, 0.40625, 0.34375, 0.34375, 1.0, 0.34375, 0.390625, 0.359375, 0.34375, 0.40625, 0.34375, 1.0, 0.390625, 0.359375, 0.34375, 0.34375, 1.0, 0.34375, 1.0, 0.375, 0.34375, 0.46875, 0.375, 0.375, 0.40625, 0.34375, 0.359375, 0.359375, 0.375, 0.359375, 1.0, 0.34375, 0.359375, 1.0, 1.0, 0.546875, 0.359375, 0.359375, 0.359375, 1.0, 0.421875, 0.359375, 0.375, 0.34375, 0.34375, 0.359375, 1.0, 0.375, 0.34375, 0.34375, 0.359375, 0.34375, 0.4375, 0.359375, 1.0, 1.0, 0.34375]

 sparsity of   [1.0, 1.0, 0.234375, 0.2265625, 1.0, 1.0, 1.0, 0.22265625, 0.2265625, 0.23046875, 1.0, 1.0, 0.2265625, 1.0, 1.0, 1.0, 1.0, 0.23046875, 0.234375, 1.0, 0.23828125, 1.0, 0.23046875, 0.2421875, 0.21875, 1.0, 0.22265625, 1.0, 0.21875, 1.0, 1.0, 1.0, 0.21484375, 0.22265625, 1.0, 1.0, 1.0, 1.0, 0.23046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.234375, 1.0, 0.2421875, 0.22265625, 1.0, 0.21875, 0.23828125, 0.23046875, 1.0, 0.234375, 1.0, 1.0, 0.24609375, 1.0, 1.0, 1.0, 0.21875, 0.22265625]

 sparsity of   [0.569444477558136, 0.5260416865348816, 0.522569477558136, 0.5434027910232544, 1.0, 1.0, 0.5486111044883728, 0.5555555820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5416666865348816, 1.0, 1.0, 0.5659722089767456, 1.0, 1.0, 0.5572916865348816, 1.0, 0.5677083134651184, 0.5520833134651184, 0.5347222089767456, 1.0, 0.5520833134651184, 1.0, 1.0, 1.0, 1.0, 0.5677083134651184, 1.0, 0.538194477558136, 0.5243055820465088, 1.0, 0.553819477558136, 0.553819477558136, 0.53125, 1.0, 1.0, 0.5364583134651184, 1.0, 0.546875, 1.0, 1.0, 1.0, 0.5711805820465088, 1.0, 0.5763888955116272, 0.5815972089767456, 1.0, 0.5659722089767456, 0.5590277910232544, 1.0, 1.0, 0.5625, 0.5329861044883728, 1.0, 1.0, 0.5746527910232544, 0.5503472089767456, 0.5520833134651184, 1.0]

 sparsity of   [0.515625, 0.515625, 0.53125, 0.53125, 0.5, 0.53125, 0.53125, 0.5, 0.515625, 0.5, 0.515625, 0.5, 0.515625, 0.515625, 0.53125, 0.515625, 1.0, 0.515625, 0.5, 1.0, 0.53125, 0.515625, 0.515625, 0.515625, 0.53125, 0.5, 1.0, 0.515625, 0.515625, 0.5625, 0.515625, 0.53125, 0.515625, 0.515625, 1.0, 0.515625, 0.515625, 0.515625, 1.0, 0.5, 1.0, 0.5625, 0.515625, 0.515625, 0.53125, 1.0, 1.0, 0.515625, 0.5, 0.515625, 0.515625, 0.53125, 0.515625, 0.515625, 0.5, 0.515625, 1.0, 0.515625, 1.0, 0.515625, 1.0, 0.515625, 0.515625, 1.0, 0.546875, 0.515625, 0.5, 0.53125, 0.53125, 0.515625, 0.515625, 0.515625, 1.0, 1.0, 0.515625, 0.515625, 1.0, 1.0, 1.0, 0.515625, 0.515625, 1.0, 0.515625, 1.0, 1.0, 0.515625, 0.53125, 0.5, 0.515625, 1.0, 1.0, 0.5, 0.515625, 0.515625, 0.484375, 0.515625, 0.515625, 0.546875, 1.0, 0.515625, 1.0, 0.515625, 0.5625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.5, 0.515625, 0.515625, 1.0, 1.0, 1.0, 0.515625, 0.515625, 0.515625, 0.515625, 1.0, 0.53125, 0.5, 1.0, 0.515625, 1.0, 0.515625, 0.515625, 0.515625, 0.53125, 0.515625, 1.0, 0.515625, 0.53125, 0.515625, 1.0, 0.53125, 0.515625, 0.515625, 0.5, 0.5625, 0.53125, 0.515625, 0.515625, 0.515625, 0.53125, 0.5, 0.515625, 0.515625, 0.53125, 0.515625, 0.53125, 0.515625, 0.53125, 0.515625, 0.515625, 0.515625, 0.53125, 0.515625, 0.515625, 1.0, 0.53125, 0.515625, 1.0, 1.0, 0.515625, 1.0, 0.515625, 0.515625, 1.0, 1.0, 0.515625, 0.515625, 0.53125, 1.0, 0.546875, 1.0, 0.515625, 0.5, 0.5, 0.515625, 0.515625, 0.515625, 0.515625, 1.0, 1.0, 0.5, 0.5, 1.0, 0.515625, 0.5, 0.515625, 1.0, 0.515625, 0.5, 0.515625, 0.53125, 1.0, 1.0, 0.515625, 0.53125, 0.515625, 1.0, 0.5, 0.5, 0.515625, 0.515625, 0.515625, 0.5, 0.515625, 0.53125, 0.515625, 1.0, 0.515625, 0.515625, 0.515625, 1.0, 0.53125, 0.515625, 0.53125, 0.515625, 1.0, 0.5, 1.0, 0.515625, 1.0, 1.0, 1.0, 0.515625, 0.515625, 0.515625, 1.0, 0.53125, 0.53125, 0.53125, 1.0, 0.515625, 0.515625, 1.0, 0.53125, 0.5, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 1.0, 0.53125, 1.0]

 sparsity of   [0.1015625, 0.1015625, 1.0, 0.1015625, 1.0, 0.09375, 1.0, 0.1328125, 0.09765625, 0.1015625, 0.09375, 0.109375, 0.10546875, 0.10546875, 0.125, 1.0, 0.1015625, 0.12109375, 0.1328125, 0.09765625, 1.0, 0.12890625, 0.109375, 0.1328125, 0.11328125, 0.11328125, 0.10546875, 0.12109375, 0.12109375, 0.1171875, 1.0, 1.0, 1.0, 0.125, 0.125, 0.1015625, 1.0, 1.0, 0.1015625, 0.109375, 0.08984375, 0.10546875, 0.1328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 0.1015625, 1.0, 0.12890625, 0.10546875, 1.0, 0.12890625, 1.0, 1.0, 0.1015625, 0.14453125, 1.0, 0.09765625, 0.1015625, 0.109375]

 sparsity of   [0.3229166567325592, 0.3211805522441864, 0.3125, 0.3211805522441864, 0.3142361044883728, 1.0, 0.3142361044883728, 1.0, 0.3263888955116272, 1.0, 0.3229166567325592, 0.3263888955116272, 1.0, 1.0, 1.0, 1.0, 0.315972238779068, 1.0, 0.3229166567325592, 1.0, 1.0, 1.0, 1.0, 0.3211805522441864, 0.3177083432674408, 1.0, 0.3194444477558136, 0.3194444477558136, 0.3177083432674408, 0.34375, 1.0, 0.3194444477558136, 1.0, 0.3125, 0.3177083432674408, 1.0, 0.3177083432674408, 0.331597238779068, 0.3211805522441864, 0.3177083432674408, 1.0, 0.3211805522441864, 1.0, 0.3090277910232544, 0.3194444477558136, 0.3263888955116272, 0.3125, 1.0, 0.3246527910232544, 1.0, 0.3211805522441864, 0.3211805522441864, 1.0, 1.0, 0.3385416567325592, 0.3142361044883728, 0.3194444477558136, 1.0, 0.3211805522441864, 0.3142361044883728, 0.3368055522441864, 0.3142361044883728, 1.0, 0.3194444477558136]

 sparsity of   [0.359375, 0.359375, 0.375, 1.0, 0.375, 0.359375, 1.0, 0.359375, 0.359375, 0.359375, 0.375, 1.0, 0.375, 0.359375, 0.359375, 0.375, 0.375, 0.359375, 0.359375, 0.359375, 1.0, 0.359375, 1.0, 0.375, 0.40625, 0.375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.375, 0.359375, 1.0, 0.375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.375, 0.359375, 0.359375, 0.359375, 0.375, 0.375, 0.359375, 0.375, 0.375, 0.359375, 0.359375, 1.0, 0.359375, 1.0, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 1.0, 1.0, 1.0, 0.375, 1.0, 0.359375, 0.375, 0.359375, 0.359375, 0.375, 0.375, 1.0, 0.359375, 0.390625, 0.375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.375, 0.375, 1.0, 0.359375, 0.359375, 0.359375, 0.390625, 0.359375, 0.375, 0.390625, 0.375, 0.359375, 0.375, 0.359375, 0.375, 0.359375, 0.359375, 0.359375, 0.46875, 1.0, 1.0, 0.40625, 1.0, 0.375, 0.359375, 0.390625, 0.359375, 0.390625, 0.359375, 0.359375, 0.390625, 0.375, 0.359375, 0.359375, 0.390625, 0.359375, 0.359375, 1.0, 0.375, 0.359375, 0.375, 0.375, 0.359375, 0.359375, 0.359375, 1.0, 0.375, 0.375, 0.359375, 0.359375, 0.359375, 0.359375, 0.375, 0.359375, 0.359375, 0.359375, 0.359375, 0.375, 0.359375, 0.375, 0.359375, 0.359375, 1.0, 0.359375, 0.359375, 0.359375, 0.40625, 0.359375, 1.0, 1.0, 0.359375, 0.359375, 0.359375, 1.0, 0.359375, 0.375, 0.359375, 0.375, 0.359375, 0.359375, 0.390625, 1.0, 0.375, 0.375, 0.375, 0.390625, 0.359375, 0.359375, 0.359375, 0.375, 0.375, 0.359375, 0.390625, 1.0, 0.359375, 0.359375, 1.0, 0.359375, 0.359375, 0.359375, 1.0, 0.359375, 1.0, 0.359375, 0.359375, 0.375, 0.359375, 1.0, 0.375, 0.375, 0.359375, 0.359375, 0.359375, 0.375, 0.359375, 0.359375, 0.359375, 0.375, 0.40625, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.375, 0.359375, 0.375, 0.375, 0.359375, 1.0, 0.359375, 1.0, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 1.0, 0.359375, 0.390625, 0.375, 0.359375, 1.0, 0.375, 0.359375, 0.359375, 0.359375, 0.359375, 0.375, 0.359375, 0.375, 0.359375, 0.359375, 0.359375, 0.359375, 0.375, 0.359375, 0.359375, 0.359375]

 sparsity of   [1.0, 0.0234375, 1.0, 0.0234375, 0.02734375, 0.24609375, 0.0234375, 0.02734375, 0.03515625, 1.0, 1.0, 1.0, 0.0234375, 1.0, 0.03125, 0.02734375, 1.0, 0.03125, 1.0, 0.04296875, 0.02734375, 0.02734375, 0.0234375, 0.0390625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.01953125, 0.02734375, 0.0390625, 0.02734375, 0.03515625, 1.0, 1.0, 0.03125, 0.0234375, 0.02734375, 1.0, 1.0, 0.02734375, 1.0, 0.03515625, 0.0625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.02734375, 0.046875, 1.0, 1.0, 0.03125, 0.03125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.03515625, 0.05859375, 0.03125, 0.046875, 0.0234375, 0.0234375, 0.03125, 0.0234375, 1.0, 0.0234375, 1.0, 0.03515625, 0.0390625, 1.0, 0.046875, 0.03515625, 1.0, 1.0, 1.0, 0.046875, 1.0, 0.03125, 0.03125, 0.03125, 0.0390625, 0.02734375, 0.0234375, 0.02734375, 0.02734375, 0.0234375, 0.02734375, 1.0, 0.02734375, 1.0, 0.03125, 1.0, 0.03515625, 0.046875, 0.02734375, 1.0, 0.03515625, 0.02734375, 1.0, 0.03515625, 1.0, 0.01953125, 1.0, 1.0, 0.0390625, 0.0234375, 0.02734375, 1.0, 1.0, 0.03515625, 0.03125, 0.03125, 1.0, 0.0390625, 0.03515625, 0.02734375, 1.0, 0.0234375, 1.0, 1.0, 1.0]

 sparsity of   [0.409722238779068, 0.4149305522441864, 1.0, 1.0, 1.0, 1.0, 0.4088541567325592, 1.0, 1.0, 1.0, 1.0, 0.4140625, 1.0, 0.421875, 0.40625, 1.0, 1.0, 1.0, 1.0, 0.4131944477558136, 1.0, 1.0, 1.0, 1.0, 0.409722238779068, 1.0, 1.0, 0.4157986044883728, 1.0, 0.4079861044883728, 1.0, 1.0, 0.4244791567325592, 0.4166666567325592, 0.4184027910232544, 1.0, 1.0, 0.4071180522441864, 0.4157986044883728, 1.0, 1.0, 1.0, 0.4157986044883728, 1.0, 0.40625, 0.4123263955116272, 1.0, 0.417534738779068, 1.0, 0.4140625, 1.0, 0.4184027910232544, 0.4131944477558136, 0.4201388955116272, 0.4184027910232544, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4053819477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4131944477558136, 0.4149305522441864, 1.0, 1.0, 1.0, 1.0, 0.4123263955116272, 1.0, 1.0, 1.0, 1.0, 0.4105902910232544, 0.409722238779068, 1.0, 1.0, 0.4140625, 0.4140625, 0.4131944477558136, 1.0, 1.0, 1.0, 0.4192708432674408, 0.4123263955116272, 1.0, 1.0, 0.4088541567325592, 0.4192708432674408, 1.0, 1.0, 0.4053819477558136, 0.4105902910232544, 1.0, 1.0, 1.0, 0.417534738779068, 1.0, 0.4201388955116272, 1.0, 0.4270833432674408, 1.0, 0.4114583432674408, 0.4045138955116272, 1.0, 0.4201388955116272, 1.0, 0.4149305522441864, 0.4123263955116272, 0.4071180522441864, 1.0, 0.4123263955116272, 0.4105902910232544, 1.0, 1.0, 1.0, 0.4053819477558136, 0.4166666567325592, 1.0, 1.0, 0.4184027910232544, 1.0, 1.0, 0.4140625]

 sparsity of   [1.0, 0.5703125, 0.5703125, 0.5625, 0.578125, 0.5703125, 0.5703125, 0.59375, 0.5703125, 0.578125, 0.5703125, 0.5546875, 1.0, 0.5859375, 0.5625, 0.578125, 0.578125, 1.0, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.578125, 0.5703125, 0.578125, 0.5625, 0.578125, 0.5703125, 0.5625, 1.0, 0.5703125, 1.0, 0.5703125, 0.578125, 1.0, 0.5703125, 0.5703125, 0.578125, 0.5703125, 1.0, 1.0, 0.5703125, 0.5859375, 1.0, 0.5703125, 0.5703125, 1.0, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.5625, 0.5859375, 0.578125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 1.0, 0.5703125, 0.578125, 0.5703125, 0.578125, 0.578125, 0.5703125, 0.5703125, 0.578125, 0.5625, 0.5859375, 0.5625, 1.0, 0.5703125, 0.5703125, 0.5703125, 1.0, 0.59375, 0.578125, 0.578125, 1.0, 1.0, 0.578125, 0.5859375, 1.0, 0.578125, 0.578125, 1.0, 1.0, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125, 0.5625, 0.578125, 1.0, 0.5703125, 0.578125, 0.578125, 0.5703125, 0.5703125, 0.5703125, 0.5625, 1.0, 0.578125, 0.5859375, 0.578125, 0.5703125, 1.0, 0.578125, 1.0, 0.5703125, 0.5703125, 1.0, 1.0, 0.5546875, 1.0, 0.5703125, 0.5703125, 0.578125, 0.578125, 0.578125, 0.578125, 0.5625, 0.578125, 0.5703125, 1.0, 0.578125, 0.578125, 0.5625, 1.0, 0.578125, 0.5703125, 1.0, 1.0, 1.0, 1.0, 0.578125, 0.5703125, 1.0, 0.5703125, 0.5625, 0.5703125, 0.5703125, 1.0, 0.578125, 0.5859375, 0.578125, 1.0, 1.0, 1.0, 0.578125, 0.578125, 0.578125, 0.578125, 0.5703125, 0.5703125, 1.0, 0.5859375, 1.0, 0.5859375, 0.5703125, 1.0, 1.0, 0.5546875, 0.5703125, 0.5703125, 0.5703125, 0.5625, 0.5703125, 0.5703125, 0.578125, 0.5703125, 0.5703125, 0.5703125, 1.0, 0.5703125, 1.0, 0.5859375, 0.5703125, 0.578125, 0.5703125, 1.0, 0.578125, 0.578125, 0.5859375, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 1.0, 0.578125, 0.5703125, 0.5703125, 0.578125, 1.0, 0.5703125, 0.5546875, 0.5625, 1.0, 1.0, 1.0, 0.5703125, 0.578125, 0.5703125, 0.5703125, 0.578125, 0.5703125, 0.5859375, 1.0, 0.5703125, 1.0, 0.5703125, 0.5859375, 1.0, 0.59375, 0.5703125, 0.5703125, 1.0, 1.0, 1.0, 0.578125, 1.0, 0.578125, 0.578125, 0.5703125, 0.578125, 0.5703125, 0.578125, 0.5703125, 0.5703125, 0.578125, 1.0, 0.5703125, 0.5859375, 0.5859375, 1.0, 1.0, 0.578125, 1.0, 0.578125, 0.5703125, 0.5703125, 0.578125, 0.5703125, 1.0, 1.0, 1.0, 1.0, 0.5703125, 0.578125, 1.0, 0.578125, 0.5625, 1.0, 1.0, 0.5625, 0.5703125, 0.578125, 1.0, 0.5625, 1.0, 1.0, 1.0, 0.578125, 0.578125, 0.578125, 0.5703125, 0.578125, 0.5703125, 0.5625, 1.0, 0.578125, 0.578125, 0.5546875, 0.5546875, 0.578125, 0.5625, 0.5859375, 0.5859375, 0.59375, 1.0, 0.5859375, 0.5703125, 0.578125, 0.59375, 0.578125, 0.578125, 1.0, 0.5859375, 0.6015625, 1.0, 0.578125, 1.0, 0.578125, 0.5703125, 0.5703125, 0.578125, 0.5703125, 0.5703125, 0.5703125, 1.0, 0.5703125, 1.0, 1.0, 0.578125, 0.5703125, 0.5703125, 1.0, 0.5859375, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.5625, 1.0, 0.578125, 0.578125, 1.0, 1.0, 0.5703125, 0.5625, 0.578125, 0.578125, 0.5625, 1.0, 0.578125, 1.0, 0.5625, 0.5703125, 0.5703125, 1.0, 1.0, 1.0, 0.5703125, 0.5546875, 0.578125, 0.5703125, 1.0, 0.5703125, 1.0, 0.5703125, 0.5546875, 1.0, 0.5625, 1.0, 0.578125, 1.0, 1.0, 0.59375, 1.0, 0.578125, 0.578125, 0.578125, 0.5703125, 1.0, 0.5703125, 1.0, 0.578125, 0.5703125, 0.578125, 0.578125, 0.5703125, 0.578125, 0.5703125, 0.5703125, 0.578125, 0.578125, 1.0, 0.5703125, 0.5625, 0.5703125, 0.5859375, 0.5625, 0.5625, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5859375, 0.5859375, 0.578125, 0.578125, 0.5625, 0.5703125, 1.0, 0.5625, 1.0, 1.0, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.5703125, 0.578125, 0.578125, 0.578125, 0.5703125, 0.5703125, 0.5703125, 0.578125, 0.59375, 0.578125, 0.59375, 0.578125, 0.5703125, 0.5703125, 0.5703125, 0.578125, 0.578125, 1.0, 0.5703125, 0.5703125, 0.5625, 1.0, 0.5703125, 0.5703125, 0.5703125, 0.578125, 0.5703125, 0.5703125, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.5625, 1.0, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125, 1.0, 0.5703125, 1.0, 0.5703125, 0.578125, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5625, 1.0, 1.0, 0.578125, 1.0, 0.5703125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5625, 0.578125, 0.5625, 0.578125, 0.578125, 0.5703125, 1.0, 0.5859375, 0.59375, 0.5703125, 0.5625, 0.578125, 1.0, 1.0, 0.5546875, 0.578125, 1.0, 0.5703125, 1.0, 1.0, 0.5703125, 0.5703125, 1.0, 0.5703125, 1.0, 1.0, 0.578125, 1.0, 1.0, 1.0, 0.5703125, 0.5625, 1.0, 1.0, 1.0, 0.578125, 0.578125, 0.5703125, 0.578125, 0.5625, 0.5703125, 1.0, 1.0, 1.0, 0.5859375, 1.0, 1.0, 1.0, 1.0, 0.5703125, 0.5703125, 1.0, 0.5859375, 1.0, 1.0, 1.0, 0.5703125]

 sparsity of   [1.0, 0.03515625, 0.0390625, 0.11328125, 0.02734375, 0.1015625, 0.04296875, 0.03515625, 0.02734375, 0.0390625, 0.02734375, 0.02734375, 1.0, 0.03125, 0.03125, 0.02734375, 0.03515625, 1.0, 0.02734375, 1.0, 0.03515625, 0.04296875, 0.03515625, 0.03125, 0.03515625, 0.02734375, 1.0, 0.0859375, 0.0390625, 0.0390625, 0.03515625, 1.0, 0.05078125, 0.04296875, 1.0, 0.0546875, 0.0390625, 0.04296875, 0.05859375, 1.0, 1.0, 0.03515625, 0.03515625, 1.0, 0.03515625, 0.04296875, 1.0, 0.0390625, 1.0, 0.04296875, 0.03515625, 0.02734375, 1.0, 0.02734375, 0.0390625, 0.0234375, 0.03515625, 0.02734375, 1.0, 0.03125, 0.05078125, 0.03515625, 0.05078125, 0.02734375, 0.05078125, 0.03515625, 1.0, 0.04296875, 0.046875, 0.03125, 1.0, 0.03125, 0.03125, 0.03515625, 0.02734375, 0.03515625, 0.03515625, 1.0, 1.0, 1.0, 0.109375, 0.046875, 1.0, 1.0, 0.02734375, 1.0, 1.0, 0.03515625, 0.078125, 0.02734375, 0.046875, 0.07421875, 0.046875, 0.03125, 1.0, 0.02734375, 0.0234375, 0.04296875, 0.03125, 0.03515625, 0.04296875, 0.08984375, 1.0, 0.02734375, 0.04296875, 0.04296875, 0.0234375, 1.0, 0.0234375, 1.0, 0.0234375, 0.02734375, 1.0, 1.0, 0.05859375, 1.0, 0.03515625, 0.0390625, 0.03125, 0.04296875, 0.02734375, 0.05078125, 0.0390625, 0.0234375, 0.1328125, 1.0, 0.03125, 0.0390625, 0.0546875, 1.0, 0.0390625, 0.02734375, 1.0, 0.03515625, 1.0, 1.0, 0.0234375, 0.03125, 1.0, 0.03515625, 0.02734375, 0.02734375, 0.04296875, 1.0, 0.03125, 0.02734375, 0.0234375, 1.0, 1.0, 1.0, 0.03515625, 0.03515625, 0.046875, 0.03515625, 0.03125, 0.02734375, 1.0, 0.03515625, 1.0, 0.03125, 0.03125, 1.0, 1.0, 0.03125, 0.02734375, 0.0390625, 0.0390625, 0.02734375, 0.05078125, 0.03125, 0.03125, 0.03125, 0.03125, 0.05078125, 0.0390625, 0.03125, 1.0, 0.01953125, 0.0390625, 0.02734375, 0.08984375, 1.0, 0.03515625, 0.02734375, 1.0, 0.0625, 1.0, 0.0234375, 0.02734375, 0.02734375, 0.03515625, 1.0, 1.0, 0.03515625, 0.01953125, 0.03125, 1.0, 0.04296875, 0.06640625, 0.03125, 1.0, 1.0, 0.03515625, 0.05859375, 0.03125, 0.03515625, 0.0234375, 0.02734375, 0.01953125, 0.046875, 1.0, 0.0234375, 1.0, 0.0234375, 0.02734375, 1.0, 0.0546875, 0.03515625, 0.03515625, 1.0, 1.0, 1.0, 0.03515625, 1.0, 0.1171875, 0.03515625, 0.08984375, 0.04296875, 0.0390625, 0.03125, 0.046875, 0.03125, 0.03515625, 1.0, 0.046875, 0.02734375, 0.04296875, 1.0, 1.0, 0.0390625, 1.0, 0.03515625, 0.05078125, 0.03515625, 0.0234375, 0.03125, 1.0, 1.0, 1.0, 1.0, 0.0234375, 0.03125, 1.0, 0.03125, 0.08203125, 1.0, 1.0, 0.03515625, 0.0546875, 0.02734375, 1.0, 0.046875, 1.0, 1.0, 0.03515625, 1.0, 0.02734375, 0.046875, 0.03515625, 1.0, 0.03515625, 0.03515625, 1.0, 0.03125, 0.0390625, 0.03515625, 0.046875, 0.03125, 0.03125, 0.0390625, 0.02734375, 1.0, 1.0, 0.03125, 0.03515625, 0.046875, 0.03125, 1.0, 0.05078125, 1.0, 0.03125, 0.03125, 1.0, 0.0390625, 0.0859375, 0.04296875, 0.02734375, 0.02734375, 0.02734375, 0.02734375, 1.0, 0.02734375, 1.0, 0.0234375, 1.0, 1.0, 0.0390625, 0.0390625, 0.05078125, 1.0, 0.02734375, 0.03515625, 1.0, 0.03515625, 0.0234375, 0.02734375, 1.0, 0.08984375, 0.03125, 0.02734375, 1.0, 0.046875, 0.03515625, 0.04296875, 0.03125, 0.02734375, 1.0, 0.03125, 0.0390625, 0.03515625, 0.0390625, 0.0390625, 1.0, 0.03125, 1.0, 0.0234375, 0.0390625, 0.04296875, 0.03515625, 1.0, 0.03125, 1.0, 0.0234375, 0.03125, 1.0, 0.03515625, 1.0, 0.10546875, 1.0, 1.0, 0.0390625, 0.02734375, 0.03515625, 0.03125, 0.03125, 0.02734375, 1.0, 0.0390625, 1.0, 0.0390625, 0.03125, 0.0390625, 0.02734375, 1.0, 0.03515625, 0.03125, 0.03125, 0.02734375, 0.02734375, 1.0, 0.0859375, 0.02734375, 0.0625, 0.0234375, 0.03125, 0.03515625, 0.03515625, 0.0234375, 0.03125, 0.02734375, 0.02734375, 0.02734375, 0.03515625, 0.04296875, 0.03125, 0.03515625, 1.0, 0.0546875, 1.0, 1.0, 0.1015625, 1.0, 0.02734375, 0.03515625, 0.04296875, 0.046875, 0.03515625, 1.0, 0.0625, 0.03515625, 0.03125, 1.0, 0.0390625, 0.02734375, 0.03125, 1.0, 0.03125, 0.03515625, 0.03125, 0.03125, 0.03125, 1.0, 0.04296875, 0.03125, 0.09375, 1.0, 0.109375, 0.0234375, 0.03125, 1.0, 0.03125, 0.0390625, 0.03515625, 1.0, 0.03125, 0.03125, 0.05859375, 1.0, 0.09375, 0.03515625, 0.0234375, 0.01953125, 0.046875, 1.0, 0.02734375, 1.0, 0.03515625, 0.03125, 0.03125, 1.0, 0.046875, 0.03125, 0.03125, 0.03125, 0.04296875, 1.0, 1.0, 0.03125, 1.0, 0.0390625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.02734375, 0.03125, 0.109375, 0.04296875, 0.03125, 0.0390625, 1.0, 0.02734375, 0.046875, 0.03515625, 0.03515625, 0.02734375, 1.0, 1.0, 0.06640625, 0.02734375, 1.0, 0.06640625, 0.03125, 1.0, 0.03125, 0.07421875, 1.0, 0.15234375, 1.0, 1.0, 0.02734375, 0.03125, 1.0, 1.0, 0.08203125, 0.03515625, 1.0, 1.0, 0.05859375, 0.046875, 0.0234375, 0.1328125, 0.1015625, 0.05859375, 0.02734375, 1.0, 1.0, 1.0, 0.02734375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.03125, 1.0, 0.0390625, 1.0, 1.0, 1.0, 0.02734375]

 sparsity of   [1.0, 1.0, 1.0, 0.2578125, 1.0, 0.263671875, 0.25390625, 1.0, 0.259765625, 1.0, 0.25390625, 1.0, 0.265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.259765625, 1.0, 1.0, 1.0, 0.2578125, 1.0, 1.0, 1.0, 1.0, 0.26171875, 1.0, 1.0, 0.2578125, 1.0, 1.0, 1.0, 0.28125, 1.0, 1.0, 1.0, 0.263671875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.259765625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28125, 1.0, 0.25390625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.255859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.279296875, 1.0, 0.263671875, 1.0, 1.0, 1.0, 0.26171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.259765625, 1.0, 0.27734375, 1.0, 0.259765625, 1.0, 1.0, 1.0, 0.263671875, 0.26171875, 0.2578125, 1.0, 0.26171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.259765625, 1.0, 1.0, 0.255859375, 1.0, 0.251953125, 1.0, 0.259765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.255859375, 1.0, 0.265625, 1.0, 0.267578125, 0.25, 1.0, 0.263671875, 1.0, 0.265625, 1.0, 0.263671875, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 0.7039930820465088, 0.7065972089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 1.0, 1.0, 0.7144097089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7039930820465088, 1.0, 1.0, 1.0, 0.703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6987847089767456, 1.0, 1.0, 0.7048611044883728, 0.7039930820465088, 0.6970486044883728, 1.0, 1.0, 0.7013888955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7057291865348816, 1.0, 1.0, 0.7118055820465088, 0.7013888955116272, 0.703125, 1.0, 0.7005208134651184, 1.0, 1.0, 1.0, 0.7048611044883728, 0.7048611044883728, 0.7065972089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7048611044883728, 1.0, 0.7048611044883728, 1.0, 1.0, 0.703125, 1.0, 1.0, 1.0, 0.703125, 0.7005208134651184, 1.0, 1.0, 1.0, 0.7092013955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7048611044883728, 1.0, 0.7092013955116272, 1.0, 0.7074652910232544, 1.0, 0.7048611044883728, 0.6996527910232544, 1.0, 1.0, 0.7065972089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.75, 1.0, 0.75, 0.7578125, 0.75, 1.0, 1.0, 0.75, 0.75, 0.75, 0.75, 0.765625, 1.0, 0.75, 0.75, 0.75, 0.75, 1.0, 0.75, 1.0, 0.7578125, 1.0, 0.75, 1.0, 0.765625, 0.75, 1.0, 1.0, 0.75, 1.0, 0.75, 1.0, 1.0, 1.0, 0.75, 0.765625, 0.75, 0.75, 0.7578125, 1.0, 1.0, 0.75, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 0.75, 0.75, 0.75, 1.0, 1.0, 0.7578125, 0.75, 0.7578125, 0.75, 1.0, 1.0, 0.75, 0.75, 1.0, 0.75, 1.0, 0.75, 1.0, 0.75, 1.0, 0.75, 0.75, 0.75, 1.0, 0.75, 1.0, 0.75, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.75, 0.7578125, 1.0, 0.75, 0.75, 0.75, 0.765625, 1.0, 0.75, 1.0, 0.7578125, 1.0, 0.7578125, 0.75, 1.0, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.7734375, 1.0, 0.75, 0.75, 0.75, 1.0, 0.75, 0.75, 1.0, 1.0, 0.75, 1.0, 0.75, 1.0, 1.0, 1.0, 0.75, 0.75, 0.75, 0.75, 1.0, 0.75, 0.75, 0.75, 0.75, 1.0, 0.75, 0.75, 1.0, 1.0, 1.0, 1.0, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 1.0, 0.75, 1.0, 0.7578125, 1.0, 0.75, 1.0, 0.75, 0.75, 1.0, 0.75, 0.75, 0.75, 1.0, 0.75, 1.0, 0.75, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 0.75, 0.75, 0.7578125, 0.7578125, 0.75, 0.7578125, 0.75, 1.0, 0.75, 1.0, 0.75, 1.0, 0.75, 0.75, 0.75, 0.75, 0.75, 0.7578125, 0.75, 1.0, 1.0, 1.0, 0.75, 1.0, 0.75, 1.0, 1.0, 1.0, 0.75, 0.75, 0.75, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 0.75, 1.0, 0.75, 0.75, 1.0, 0.75, 0.75, 0.7578125, 0.75, 0.75, 0.75, 1.0, 0.7578125, 1.0, 0.75, 0.75, 0.75, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.75, 0.75, 1.0, 0.75, 0.75, 0.75, 1.0, 1.0, 0.75, 0.75, 0.75, 1.0, 1.0, 0.75, 1.0, 0.75, 1.0, 0.75, 0.75, 0.7578125, 1.0, 1.0, 1.0, 0.75, 0.75, 0.75, 1.0, 0.75, 0.75, 0.75, 1.0, 0.75, 0.75, 0.7578125, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.75, 1.0, 1.0, 0.7578125, 0.75, 0.75, 0.75, 0.75, 0.75, 1.0, 0.75, 0.75, 0.75, 0.7578125, 1.0, 1.0, 0.7578125, 1.0, 0.75, 0.75, 1.0, 0.75, 1.0, 0.75, 1.0, 1.0, 0.75, 1.0, 0.75, 0.75, 0.75, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 0.75, 0.75, 1.0, 1.0, 0.75, 0.75, 1.0, 0.75, 0.75, 0.75, 1.0, 1.0, 0.75, 1.0, 0.75, 0.75, 0.7578125, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 1.0, 0.7578125, 1.0, 1.0, 1.0, 0.75, 0.75, 1.0, 1.0, 0.7578125, 1.0, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 1.0, 1.0, 0.75, 0.75, 1.0, 1.0, 0.75, 0.75, 1.0, 0.75, 1.0, 0.7578125, 0.75, 0.75, 0.7578125, 1.0, 0.75, 0.75, 0.7578125, 1.0, 0.75, 1.0, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 1.0, 0.7578125, 0.75, 0.75, 0.75, 0.7578125, 1.0, 0.75, 0.75, 0.7734375, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.75, 0.75, 0.75, 0.75, 1.0, 0.75, 0.75, 0.75, 1.0, 0.75, 0.765625, 0.75, 1.0, 0.75, 0.75, 0.75, 0.75, 1.0, 1.0, 0.7578125, 0.75, 0.75, 1.0, 0.7578125, 0.75, 0.765625, 1.0, 0.75, 0.75, 0.75, 0.75, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 0.75, 0.75, 1.0, 0.75, 0.75, 0.7578125, 0.75, 0.75, 1.0, 1.0, 0.75, 0.75, 0.75, 0.75, 1.0, 1.0, 0.75, 1.0, 0.75, 0.75, 1.0, 1.0, 1.0, 1.0, 0.75, 0.75, 0.75, 1.0, 0.7578125, 0.75, 1.0, 0.75, 0.7578125, 0.75, 0.7578125, 0.75, 0.75, 1.0, 0.75, 0.75, 1.0, 0.75, 0.75, 1.0, 0.75, 1.0, 1.0, 0.75, 1.0, 1.0, 0.75, 0.75, 1.0, 1.0, 0.75, 0.75, 1.0, 0.75, 1.0, 0.75, 0.75, 1.0, 0.75, 1.0, 0.75, 0.75, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 0.7578125, 1.0, 1.0, 1.0, 0.75]

 sparsity of   [0.205078125, 1.0, 0.208984375, 0.208984375, 0.19921875, 1.0, 0.19921875, 1.0, 1.0, 1.0, 0.203125, 0.205078125, 1.0, 1.0, 1.0, 0.201171875, 1.0, 1.0, 0.19921875, 0.201171875, 1.0, 0.203125, 1.0, 0.205078125, 0.208984375, 1.0, 1.0, 1.0, 0.19921875, 1.0, 0.2109375, 0.201171875, 0.208984375, 1.0, 0.212890625, 0.203125, 1.0, 1.0, 0.19921875, 0.212890625, 0.587890625, 0.291015625, 0.201171875, 0.197265625, 1.0, 0.205078125, 1.0, 1.0, 0.19140625, 0.193359375, 0.205078125, 1.0, 0.1953125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19921875, 0.203125, 0.20703125, 0.208984375, 0.197265625, 0.19140625, 0.20703125, 0.208984375, 0.203125, 1.0, 0.2109375, 1.0, 1.0, 0.201171875, 0.197265625, 1.0, 1.0, 1.0, 0.2109375, 0.203125, 1.0, 1.0, 0.203125, 0.19921875, 1.0, 1.0, 0.203125, 1.0, 1.0, 0.205078125, 0.220703125, 1.0, 1.0, 1.0, 0.208984375, 1.0, 1.0, 1.0, 0.205078125, 0.205078125, 1.0, 0.203125, 1.0, 0.208984375, 1.0, 0.19921875, 0.203125, 0.201171875, 1.0, 0.2109375, 0.203125, 0.201171875, 0.19921875, 1.0, 1.0, 0.203125, 1.0, 1.0, 0.201171875, 0.1953125, 1.0, 1.0, 0.205078125, 0.193359375, 0.25, 1.0, 0.201171875, 0.20703125, 0.19921875, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444477558136, 1.0, 1.0, 0.448784738779068, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4435763955116272, 1.0, 1.0, 1.0, 0.4470486044883728, 1.0, 1.0, 1.0, 0.4392361044883728, 0.4392361044883728, 1.0, 1.0, 0.4444444477558136, 1.0, 1.0, 0.4418402910232544, 1.0, 1.0, 1.0, 0.4418402910232544, 1.0, 0.4418402910232544, 1.0, 1.0, 0.440972238779068, 0.4366319477558136, 0.453125, 0.440972238779068, 1.0, 1.0, 0.4418402910232544, 0.4427083432674408, 1.0, 0.4427083432674408, 1.0, 0.4435763955116272, 0.4427083432674408, 1.0, 1.0, 1.0, 0.4435763955116272, 1.0, 0.440972238779068, 1.0, 1.0, 0.4505208432674408, 0.4479166567325592, 0.4444444477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4479166567325592, 1.0, 1.0, 1.0, 0.4401041567325592, 0.4435763955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4392361044883728, 1.0, 0.4418402910232544, 1.0, 1.0, 0.4418402910232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4427083432674408, 0.4453125, 1.0, 0.4461805522441864, 0.4427083432674408, 0.4496527910232544, 1.0, 0.4479166567325592, 0.4418402910232544, 1.0, 0.4444444477558136, 1.0, 1.0, 1.0, 0.4392361044883728, 1.0, 1.0, 0.4435763955116272, 1.0, 1.0, 0.4444444477558136, 0.4479166567325592, 1.0, 0.4427083432674408, 1.0, 1.0, 0.4435763955116272, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.671875, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 0.6640625, 0.65625, 0.65625, 0.6640625, 0.6640625, 1.0, 0.671875, 0.65625, 0.6640625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.6640625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 1.0, 1.0, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.6640625, 1.0, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 1.0, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.6640625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.6640625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.6640625, 0.65625, 0.6640625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.6640625, 1.0, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 1.0, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 1.0, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 0.671875, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 1.0, 0.65625, 1.0, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 1.0, 0.6640625, 0.65625, 1.0, 1.0, 1.0, 0.65625, 0.65625, 1.0, 0.6640625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.6640625, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.6640625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.6640625, 0.65625, 1.0, 0.65625, 0.65625, 1.0, 1.0, 1.0, 0.6640625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 1.0, 0.65625, 0.6640625, 1.0, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 0.671875, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 1.0, 0.6640625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.671875, 0.65625, 1.0, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.6640625, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 0.65625, 1.0, 0.6640625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 1.0, 1.0, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.6640625, 0.671875, 0.65625, 0.6640625, 0.6640625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.6640625, 0.65625, 0.6640625, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.6640625, 0.6640625, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 1.0, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 0.6640625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 1.0, 1.0, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.6640625, 0.65625, 1.0, 1.0, 1.0, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.6640625]

 sparsity of   [1.0, 0.134765625, 1.0, 1.0, 1.0, 0.134765625, 0.1484375, 1.0, 0.1328125, 1.0, 0.125, 1.0, 0.140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12890625, 1.0, 0.130859375, 0.12890625, 1.0, 1.0, 1.0, 1.0, 0.130859375, 1.0, 0.130859375, 0.138671875, 0.123046875, 0.13671875, 0.12890625, 0.126953125, 1.0, 0.140625, 1.0, 0.140625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1328125, 0.123046875, 1.0, 0.138671875, 0.12109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.134765625, 0.130859375, 1.0, 1.0, 0.1328125, 0.12890625, 0.1328125, 1.0, 1.0, 1.0, 0.12890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1328125, 1.0, 0.125, 1.0, 0.130859375, 1.0, 1.0, 0.138671875, 1.0, 1.0, 1.0, 1.0, 0.12890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.134765625, 1.0, 0.130859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.126953125, 1.0, 0.12890625, 1.0, 0.12109375, 1.0, 1.0, 1.0, 1.0, 0.125, 0.130859375, 0.130859375, 0.123046875, 0.123046875, 1.0, 0.1328125, 0.123046875]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6354166865348816, 0.7404513955116272, 1.0, 1.0, 1.0, 1.0, 0.6614583134651184, 1.0, 1.0, 0.694444477558136, 1.0, 1.0, 1.0, 0.694444477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6545138955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6432291865348816, 0.6284722089767456, 1.0, 1.0, 1.0, 1.0, 0.6362847089767456, 1.0, 1.0, 1.0, 1.0, 0.6258680820465088, 0.6267361044883728, 0.6223958134651184, 1.0, 0.6293402910232544, 0.678819477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.631944477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6293402910232544, 1.0, 1.0, 1.0, 0.616319477558136, 1.0, 1.0, 1.0, 0.6927083134651184, 1.0, 1.0, 0.6302083134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6328125, 1.0, 0.624131977558136, 1.0, 1.0, 1.0, 0.6362847089767456, 1.0, 1.0, 1.0, 0.6328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6232638955116272, 0.625, 0.6232638955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6276041865348816, 1.0, 1.0, 1.0, 0.6293402910232544, 1.0, 0.6371527910232544, 1.0, 1.0, 0.6310763955116272, 1.0, 0.6258680820465088]

 sparsity of   [1.0, 0.7578125, 0.7578125, 1.0, 0.765625, 1.0, 0.7578125, 0.7578125, 0.765625, 1.0, 0.7578125, 0.765625, 1.0, 0.765625, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.7578125, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7578125, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.765625, 1.0, 0.7578125, 0.7578125, 0.7421875, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 0.765625, 0.7578125, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7578125, 1.0, 1.0, 1.0, 0.7421875, 1.0, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 0.7421875, 0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.7578125, 1.0, 0.7578125, 0.7578125, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 0.7421875, 0.7578125, 1.0, 0.75, 1.0, 0.7578125, 1.0, 1.0, 0.7578125, 0.7578125, 0.7578125, 0.765625, 1.0, 1.0, 1.0, 0.7578125, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.7421875, 0.765625, 1.0, 0.7578125, 1.0, 0.7578125, 1.0, 0.7578125, 0.75, 1.0, 1.0, 1.0, 0.7578125, 0.765625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.765625, 1.0, 1.0, 0.7578125, 0.765625, 0.7578125, 0.7578125, 0.7578125, 0.7578125, 1.0, 0.7421875, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 0.765625, 0.75, 0.765625, 0.75, 1.0, 0.7578125, 1.0, 0.765625, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.7578125, 1.0, 0.765625, 1.0, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 0.765625, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7578125, 1.0, 1.0, 1.0, 0.765625, 0.7578125, 0.75, 1.0, 0.7734375, 1.0, 0.7578125, 0.7578125, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 0.7578125, 1.0, 0.7578125, 0.7578125, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.75, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 0.75, 0.7578125, 0.7578125, 1.0, 0.7734375, 0.75, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 0.75, 1.0, 0.7578125, 1.0, 0.765625, 0.7578125, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 0.7578125, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 0.7578125, 0.78125, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.7578125, 1.0, 1.0, 0.765625, 0.7578125, 0.7578125, 1.0, 0.7578125, 0.7578125, 0.7578125, 1.0, 0.75, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 0.75, 0.765625, 1.0, 1.0, 1.0, 0.765625, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 0.765625, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 1.0, 0.7578125, 0.7578125, 1.0, 0.7734375, 1.0, 0.7578125, 0.7734375, 1.0, 1.0, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 0.75, 0.7578125, 1.0, 0.7578125, 0.7578125, 1.0, 0.7578125, 0.7578125, 0.7578125, 0.765625, 1.0, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 0.765625, 0.765625, 0.7578125, 1.0, 0.7578125, 0.7578125, 0.765625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 0.765625, 0.75, 1.0, 1.0, 1.0, 0.7578125, 0.765625, 1.0, 1.0, 1.0, 0.7578125, 1.0, 0.765625, 1.0, 1.0, 0.765625, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 0.7578125, 1.0, 1.0, 0.75, 0.7578125, 0.7578125, 0.7578125, 0.75, 0.765625, 0.7578125, 1.0, 1.0, 0.7578125, 0.78125, 0.765625, 1.0, 1.0, 1.0, 1.0, 0.765625, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 0.765625, 1.0, 1.0, 1.0, 0.765625, 0.7578125, 0.765625, 0.7578125, 0.7578125, 0.765625, 1.0, 1.0, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.765625, 1.0, 1.0, 1.0, 1.0, 0.7578125, 1.0, 0.7578125, 0.7578125, 0.75, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.7578125, 1.0, 1.0, 0.7578125, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 0.0859375, 1.0, 1.0, 0.099609375, 1.0, 0.099609375, 1.0, 0.087890625, 1.0, 0.091796875, 1.0, 1.0, 1.0, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.095703125, 1.0, 1.0, 0.091796875, 1.0, 0.09375, 0.091796875, 0.0859375, 0.1015625, 1.0, 1.0, 0.09375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.091796875, 1.0, 0.091796875, 1.0, 1.0, 0.08984375, 0.095703125, 0.09375, 0.095703125, 1.0, 1.0, 1.0, 1.0, 0.091796875, 1.0, 1.0, 0.091796875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.107421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.091796875, 0.09375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 0.08984375, 1.0, 0.091796875, 1.0, 1.0, 1.0, 1.0, 0.1171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.083984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.103515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.087890625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09375, 1.0, 1.0, 0.1015625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08984375, 0.091796875, 1.0, 1.0, 1.0, 0.095703125, 1.0, 1.0, 1.0, 0.08984375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.103515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09375, 1.0, 0.09375, 1.0, 1.0, 1.0, 0.095703125, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 0.0859375, 0.08984375, 1.0, 0.1015625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.091796875, 0.095703125, 0.09375, 1.0, 0.09765625, 1.0, 1.0, 0.091796875, 1.0, 1.0, 0.09765625, 1.0, 1.0, 0.099609375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.103515625]

 sparsity of   [1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 0.7825520634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7825520634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7821180820465088, 1.0, 1.0, 1.0, 0.7829861044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7825520634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7825520634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7825520634651184, 1.0, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7821180820465088, 1.0, 1.0, 0.7825520634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7834201455116272, 1.0, 1.0, 0.7834201455116272, 0.7829861044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7821180820465088, 1.0, 0.78125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7816840410232544, 1.0, 1.0, 0.7821180820465088, 1.0, 0.7834201455116272, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.7821180820465088, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7825520634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 0.7821180820465088, 0.7829861044883728, 0.7829861044883728, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7834201455116272, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 0.87109375, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 0.87109375, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.87109375, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.87109375, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.87109375, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.87109375, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.87109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.875, 0.8671875, 1.0, 0.87109375, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 0.87109375, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.87109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 0.87109375, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.87109375, 1.0, 1.0, 0.87109375, 1.0, 0.8671875, 1.0, 0.87109375, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.875, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.87109375, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.87109375, 0.87109375, 1.0, 0.8671875, 0.8671875, 1.0, 0.8671875, 1.0, 0.875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.87109375, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 0.8671875, 1.0, 0.87109375, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.87109375, 1.0, 1.0, 1.0, 1.0, 0.87109375, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 0.8671875, 0.87109375, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 0.87109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 0.87109375, 0.8671875, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.87109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.87109375, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 0.87109375, 0.8671875, 1.0, 1.0, 0.87109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.87109375, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8828125, 1.0, 1.0, 1.0, 0.87109375, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 0.87109375, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.87109375, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.87109375, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.87109375, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.87109375, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875]

 sparsity of   [1.0, 1.0, 1.0, 0.18359375, 1.0, 0.095703125, 0.099609375, 0.21875, 1.0, 0.107421875, 0.10546875, 1.0, 0.1171875, 1.0, 0.099609375, 1.0, 1.0, 0.09765625, 0.103515625, 0.095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.095703125, 0.11328125, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 0.095703125, 1.0, 0.1015625, 1.0, 0.107421875, 1.0, 1.0, 1.0, 0.10546875, 0.1015625, 1.0, 1.0, 1.0, 0.095703125, 0.09375, 1.0, 0.109375, 0.1015625, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 0.185546875, 1.0, 1.0, 1.0, 0.103515625, 1.0, 1.0, 1.0, 0.099609375, 1.0, 0.11328125, 1.0, 0.09765625, 0.09765625, 1.0, 0.10546875, 0.099609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09375, 0.09765625, 1.0, 1.0, 0.087890625, 1.0, 1.0, 1.0, 0.10546875, 0.091796875, 1.0, 0.193359375, 1.0, 0.099609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09375, 1.0, 0.09375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09765625, 0.119140625, 0.08984375, 1.0, 1.0, 0.095703125, 1.0, 1.0, 1.0, 0.08984375, 0.09765625, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 0.087890625, 1.0, 1.0, 1.0, 0.099609375, 1.0, 1.0, 0.099609375, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.107421875, 0.107421875, 1.0, 0.08984375, 0.08984375, 1.0, 1.0, 1.0, 0.08984375, 1.0, 0.09375, 0.09765625, 0.130859375, 0.09765625, 1.0, 1.0, 0.087890625, 1.0, 1.0, 0.103515625, 0.099609375, 1.0, 0.09765625, 0.109375, 1.0, 0.09765625, 0.095703125, 1.0, 1.0, 0.107421875, 1.0, 0.109375, 1.0, 1.0, 1.0, 0.09765625, 1.0, 0.12890625, 0.095703125, 1.0, 0.099609375, 1.0, 1.0, 1.0, 0.09765625, 0.091796875, 1.0, 1.0, 1.0, 0.1640625, 1.0, 1.0, 0.1015625, 1.0, 1.0, 1.0, 0.091796875, 1.0, 1.0, 0.107421875, 0.095703125, 0.091796875, 0.10546875, 1.0, 0.091796875, 0.09765625, 1.0, 1.0, 0.095703125, 0.091796875, 1.0, 1.0, 1.0, 0.1015625, 1.0, 0.1015625, 1.0, 1.0, 1.0, 0.1015625, 1.0, 1.0, 1.0, 0.099609375, 0.107421875, 1.0, 0.107421875, 0.10546875, 0.091796875, 1.0, 1.0, 1.0, 1.0, 0.1015625, 1.0, 1.0, 1.0, 0.12109375, 1.0, 1.0, 0.1171875, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 0.09765625, 0.09765625, 0.107421875, 1.0, 1.0, 0.091796875, 0.091796875, 0.091796875, 1.0, 0.099609375, 0.103515625, 1.0, 0.099609375, 1.0, 1.0, 0.095703125, 1.0, 0.099609375, 1.0, 1.0, 0.09375, 1.0, 0.099609375, 0.10546875, 0.095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.134765625, 1.0, 1.0, 0.09765625, 1.0, 0.10546875, 0.095703125, 1.0, 1.0, 1.0, 1.0, 0.091796875, 0.1015625, 1.0, 1.0, 0.09375, 1.0, 1.0, 1.0, 1.0, 0.091796875, 1.0, 0.10546875, 1.0, 1.0, 0.1640625, 1.0, 0.099609375, 0.095703125, 1.0, 0.10546875, 0.103515625, 1.0, 0.109375, 1.0, 0.09375, 1.0, 1.0, 1.0, 1.0, 0.103515625, 1.0, 1.0, 1.0, 1.0, 0.08984375, 1.0, 1.0, 0.095703125, 0.09375, 1.0, 1.0, 1.0, 0.1171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 0.099609375, 1.0, 0.10546875, 0.095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09375, 0.1015625, 0.095703125, 1.0, 0.1015625, 1.0, 0.09765625, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 0.08984375, 1.0, 0.08984375, 1.0, 1.0, 1.0, 1.0, 0.099609375, 1.0, 0.099609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 0.08984375, 0.09765625, 0.107421875, 1.0, 1.0, 0.1015625, 0.1015625, 0.099609375, 1.0, 1.0, 1.0, 1.0, 0.09765625, 0.095703125, 1.0, 1.0, 0.09765625, 1.0, 0.0859375, 1.0, 1.0, 0.16015625, 0.10546875, 0.103515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.099609375, 0.095703125, 0.115234375, 0.099609375, 0.107421875, 0.103515625, 1.0, 0.103515625, 1.0, 0.09765625, 1.0, 1.0, 0.091796875, 1.0, 1.0, 0.103515625, 0.09765625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.087890625, 0.107421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11328125, 1.0, 0.09765625, 1.0, 1.0, 0.103515625, 0.103515625, 1.0, 1.0, 0.1015625, 1.0, 0.103515625, 1.0, 0.09765625, 1.0, 1.0, 0.09375, 1.0, 1.0, 1.0, 0.09765625, 1.0, 0.1015625, 1.0, 1.0, 0.107421875, 1.0, 0.1015625, 1.0, 0.10546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.087890625, 1.0, 1.0, 1.0, 0.1015625, 1.0, 0.087890625, 1.0, 1.0, 0.09765625, 0.107421875, 1.0, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.091796875, 0.09765625, 0.091796875, 0.091796875, 1.0, 0.1015625, 0.115234375, 0.0859375, 1.0, 1.0, 1.0, 0.1015625, 0.103515625, 0.1015625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 0.103515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.107421875, 1.0, 1.0, 1.0, 1.0, 0.09375, 0.103515625, 0.099609375, 0.091796875, 1.0, 1.0, 1.0, 0.09765625, 1.0, 0.109375, 1.0, 0.1015625, 0.107421875, 0.09765625, 0.095703125, 1.0, 0.095703125, 1.0, 0.107421875, 1.0, 1.0, 1.0, 0.111328125, 1.0, 1.0, 0.125, 1.0, 0.09375, 1.0, 1.0, 0.095703125, 0.099609375, 0.099609375, 0.091796875, 1.0, 1.0, 1.0, 0.109375, 0.10546875, 0.09375, 0.09765625, 1.0, 1.0, 1.0, 0.109375, 1.0, 1.0, 0.09375, 0.09765625, 0.103515625, 0.10546875, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.107421875, 0.099609375, 1.0, 1.0, 0.099609375, 1.0, 1.0, 0.095703125, 0.12109375, 1.0, 0.09765625, 0.1015625, 1.0, 0.1171875, 1.0, 1.0, 0.09765625, 0.1015625, 0.09375, 0.126953125, 1.0, 0.107421875, 0.11328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 0.11328125, 1.0, 0.1015625, 1.0, 0.115234375, 1.0, 0.107421875, 1.0, 1.0, 1.0, 1.0, 0.1015625, 0.1015625, 1.0, 0.099609375, 1.0, 0.115234375, 0.107421875, 1.0, 1.0, 0.099609375, 0.10546875, 0.095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11328125, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09375, 1.0, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 0.1015625, 1.0, 1.0, 0.103515625, 0.177734375, 0.109375, 0.091796875, 1.0, 0.115234375, 0.09375, 1.0, 1.0, 0.10546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.099609375, 0.09765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.103515625, 0.10546875, 1.0, 1.0, 1.0, 0.09375, 0.09765625, 1.0, 1.0, 1.0, 1.0, 0.087890625, 1.0, 0.10546875, 1.0, 1.0, 0.099609375, 1.0, 0.09765625, 0.09375, 1.0, 1.0, 1.0, 1.0, 0.10546875, 1.0, 1.0, 0.10546875, 0.103515625, 0.107421875, 0.099609375, 1.0, 0.09765625, 1.0, 1.0, 1.0, 0.759765625, 1.0, 1.0, 1.0, 0.15625, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 0.09375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.091796875, 0.12109375, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 0.1015625, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 0.095703125, 1.0, 0.095703125, 0.09765625, 1.0, 0.09375, 0.111328125, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 0.150390625, 0.095703125, 1.0, 1.0, 0.1015625, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 0.1015625, 1.0, 0.09765625, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.103515625, 1.0, 0.1015625, 0.099609375, 1.0, 1.0, 0.1015625, 0.1875, 1.0, 1.0, 0.09765625, 1.0, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1328125, 1.0, 1.0, 0.103515625, 1.0, 1.0, 0.095703125, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 0.13671875, 1.0, 0.1015625, 1.0, 0.087890625, 0.09375, 0.1015625, 1.0, 1.0, 0.10546875, 1.0, 1.0, 0.095703125, 1.0, 1.0, 0.095703125, 1.0, 0.095703125, 0.08984375, 1.0, 1.0, 0.09765625, 0.154296875, 1.0, 1.0, 1.0, 0.099609375, 0.09375, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09375, 0.09765625, 0.11328125, 0.09375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.10546875, 1.0, 1.0, 1.0, 0.1015625, 0.10546875, 1.0, 1.0, 1.0, 0.099609375, 0.1015625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.099609375, 1.0, 0.109375, 1.0, 1.0, 0.099609375, 1.0, 0.15234375, 0.095703125, 1.0, 0.1796875, 1.0, 1.0, 1.0, 1.0, 0.09765625, 0.1015625, 1.0, 0.1015625, 1.0, 1.0, 0.09375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1015625, 0.09765625, 1.0, 0.111328125, 0.216796875, 1.0, 1.0, 0.087890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.607421875, 1.0, 1.0, 1.0, 1.0, 0.603515625, 1.0, 1.0, 1.0, 0.60546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6142578125, 1.0, 1.0, 1.0, 0.6123046875, 1.0, 1.0, 1.0, 0.609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.603515625, 1.0, 0.61328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.607421875, 1.0, 0.60546875, 1.0, 1.0, 0.607421875, 0.609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.609375, 1.0, 1.0, 1.0, 1.0, 0.6103515625, 1.0, 0.6123046875, 1.0, 1.0, 0.6083984375, 1.0, 0.6123046875, 1.0, 1.0, 1.0, 0.6083984375, 1.0, 1.0, 1.0, 1.0, 0.61328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6103515625, 1.0, 1.0, 1.0, 0.6162109375, 1.0, 1.0, 0.6103515625, 1.0, 1.0, 1.0, 0.6103515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6142578125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.611328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6044921875, 0.6142578125, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 0.6103515625, 1.0, 0.609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.611328125, 1.0, 0.626953125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.611328125, 1.0, 1.0, 1.0, 1.0, 0.611328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.609375, 1.0, 0.607421875, 0.6123046875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.609375, 1.0, 1.0, 0.609375, 0.6142578125, 0.6123046875, 1.0, 1.0, 0.6044921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6123046875, 1.0, 1.0, 0.61328125, 1.0, 1.0, 0.609375, 1.0, 1.0, 0.60546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6142578125, 1.0, 1.0, 0.6083984375, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.8133680820465088, 0.8138020634651184, 1.0, 1.0, 1.0, 1.0, 0.8142361044883728, 1.0, 1.0, 0.8129340410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8129340410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8129340410232544, 1.0, 1.0, 1.0, 1.0, 0.8133680820465088, 1.0, 0.8142361044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8142361044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8129340410232544, 1.0, 0.8129340410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8129340410232544, 0.8129340410232544, 1.0, 1.0, 1.0, 1.0, 0.8133680820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8111979365348816, 1.0, 1.0, 0.81640625, 0.8138020634651184, 1.0, 0.8133680820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8107638955116272, 1.0, 1.0, 0.8133680820465088, 0.8142361044883728, 0.8151041865348816, 1.0, 0.8133680820465088, 1.0, 1.0, 1.0, 0.8129340410232544, 0.8129340410232544, 1.0, 1.0, 1.0, 0.8146701455116272, 1.0, 0.8129340410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8138020634651184, 1.0, 1.0, 1.0, 0.8129340410232544, 1.0, 1.0, 1.0, 0.8151041865348816, 1.0, 1.0, 1.0, 1.0, 0.8129340410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8142361044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8138020634651184, 1.0, 1.0, 1.0, 1.0, 0.8142361044883728, 1.0, 1.0, 1.0, 0.8133680820465088, 1.0, 1.0, 1.0, 1.0, 0.8133680820465088, 1.0, 1.0, 1.0, 0.8133680820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8138020634651184, 1.0, 0.8125, 1.0, 0.8138020634651184, 0.8138020634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8133680820465088, 1.0, 1.0, 0.8125, 0.8151041865348816, 1.0, 0.8138020634651184, 1.0, 0.8142361044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8133680820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8129340410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8120659589767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8146701455116272, 0.8138020634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8129340410232544, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.796875, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.796875, 0.80078125, 0.796875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.796875, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.796875, 1.0, 1.0, 1.0, 0.796875, 0.79296875, 1.0, 1.0, 0.79296875, 0.796875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.80078125, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.796875, 0.7890625, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 0.796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.796875, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.796875, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.796875, 1.0, 0.80078125, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.796875, 0.79296875, 1.0, 1.0, 0.796875, 0.79296875, 0.796875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.796875, 1.0, 1.0, 1.0, 0.796875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 0.796875, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.796875, 0.79296875, 0.79296875, 1.0, 1.0, 0.7890625, 1.0, 0.796875, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.796875, 1.0, 0.796875, 1.0, 1.0, 0.79296875, 1.0, 0.796875, 0.796875, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.796875, 0.796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 0.796875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.796875, 0.79296875, 0.796875, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.796875, 1.0, 0.796875, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.796875, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 0.796875, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 0.796875, 1.0, 1.0, 0.796875, 1.0, 0.796875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.796875, 1.0, 0.80078125, 1.0, 0.796875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.796875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.80078125, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 0.796875, 1.0, 1.0, 1.0, 0.796875, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.796875, 1.0, 1.0, 0.79296875, 0.796875, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.796875, 0.79296875, 1.0, 1.0, 1.0, 0.796875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.8046875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.80078125, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.796875, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.796875, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.80078125, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 0.796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.796875, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.796875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.796875, 1.0, 1.0, 0.79296875, 0.79296875, 0.80078125, 0.79296875, 0.796875, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.796875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.796875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.796875, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.796875, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.84765625, 1.0, 0.796875, 0.79296875, 1.0, 1.0, 1.0, 0.796875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.796875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.796875, 1.0, 0.79296875, 0.796875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.796875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.5244140625, 1.0, 1.0, 1.0, 0.5263671875, 1.0, 1.0, 0.529296875, 0.529296875, 1.0, 1.0, 0.51953125, 1.0, 0.533203125, 1.0, 1.0, 1.0, 0.529296875, 0.5263671875, 1.0, 1.0, 1.0, 0.5283203125, 1.0, 0.5283203125, 1.0, 1.0, 1.0, 0.5283203125, 0.52734375, 1.0, 1.0, 0.529296875, 1.0, 1.0, 0.5322265625, 0.529296875, 0.533203125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5224609375, 0.52734375, 0.533203125, 0.53125, 0.53515625, 1.0, 0.517578125, 0.5341796875, 1.0, 0.5263671875, 0.5244140625, 0.5322265625, 0.5341796875, 0.53125, 0.525390625, 1.0, 0.5302734375, 1.0, 0.52734375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.52734375, 1.0, 0.5244140625, 0.53125, 1.0, 1.0, 0.5322265625, 1.0, 0.533203125, 0.5263671875, 0.5234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5244140625, 0.53125, 0.5283203125, 0.5263671875, 1.0, 1.0, 0.52734375, 1.0, 1.0, 0.5224609375, 1.0, 1.0, 0.5302734375, 0.5341796875, 1.0, 1.0, 1.0, 0.53125, 0.5234375, 0.5263671875, 1.0, 0.525390625, 0.5263671875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.53125, 0.5283203125, 1.0, 1.0, 0.5283203125, 0.5263671875, 1.0, 0.5263671875, 1.0, 0.5263671875, 1.0, 0.5302734375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.529296875, 1.0, 0.53125, 1.0, 1.0, 1.0, 0.5341796875, 1.0, 0.5302734375, 1.0, 0.5322265625, 0.525390625, 0.525390625, 1.0, 0.5166015625, 0.5263671875, 0.5302734375, 1.0, 1.0, 1.0, 0.5234375, 0.53515625, 1.0, 1.0, 1.0, 0.5302734375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.533203125, 1.0, 1.0, 1.0, 0.5263671875, 0.53125, 1.0, 1.0, 0.5263671875, 1.0, 1.0, 1.0, 1.0, 0.5283203125, 0.5302734375, 0.53125, 0.5234375, 0.529296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5322265625, 0.52734375, 0.5263671875, 1.0, 1.0, 0.5283203125, 1.0, 1.0, 1.0, 1.0, 0.5234375, 1.0, 0.5263671875, 0.5224609375, 0.52734375, 1.0, 0.5439453125, 1.0, 0.5283203125, 0.525390625, 1.0, 0.521484375, 1.0, 0.53125, 0.5234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5283203125, 1.0, 1.0, 1.0, 0.5224609375, 1.0, 1.0, 0.5224609375, 1.0, 1.0, 0.5263671875, 0.5283203125, 1.0, 0.5283203125, 1.0, 0.5302734375, 1.0, 0.5283203125, 0.52734375, 0.529296875, 0.5234375, 0.5341796875, 1.0, 0.521484375, 0.5205078125, 1.0, 0.517578125, 0.5185546875, 1.0, 0.5263671875, 1.0, 0.53125, 1.0, 0.5244140625, 1.0, 1.0, 0.525390625, 1.0, 0.52734375, 0.5322265625, 0.533203125]

 sparsity of   [0.5451388955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 0.54296875, 1.0, 1.0, 1.0, 0.5464409589767456, 0.5447048544883728, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5442708134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5447048544883728, 0.5451388955116272, 1.0, 0.5455729365348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5451388955116272, 1.0, 0.5447048544883728, 0.5438368320465088, 1.0, 0.5455729365348816, 0.5442708134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5447048544883728, 1.0, 1.0, 0.5442708134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5455729365348816, 1.0, 0.5442708134651184, 0.546006977558136, 0.5451388955116272, 1.0, 1.0, 1.0, 0.5455729365348816, 1.0, 0.5451388955116272, 0.5438368320465088, 0.5451388955116272, 1.0, 1.0, 0.5451388955116272, 1.0, 0.5438368320465088, 1.0, 1.0, 0.5455729365348816, 1.0, 1.0, 0.5438368320465088, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5447048544883728, 1.0, 1.0, 0.5438368320465088, 1.0, 1.0, 0.5438368320465088, 1.0, 0.5442708134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5447048544883728, 0.546875, 0.5442708134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5438368320465088, 0.5447048544883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5451388955116272, 1.0, 1.0, 0.546006977558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5455729365348816, 1.0, 0.5438368320465088, 1.0, 0.546875, 1.0, 0.5451388955116272, 1.0, 1.0, 1.0, 0.5438368320465088, 1.0, 1.0, 1.0, 1.0, 0.5442708134651184, 1.0, 0.5438368320465088, 1.0, 1.0, 1.0, 1.0, 0.5451388955116272, 0.5451388955116272, 1.0, 1.0, 0.5451388955116272, 1.0, 1.0, 1.0, 1.0, 0.5447048544883728, 1.0, 1.0, 1.0, 0.5451388955116272, 0.5464409589767456, 1.0, 1.0, 0.5451388955116272, 1.0, 1.0, 1.0, 1.0, 0.5447048544883728, 1.0, 0.5455729365348816, 1.0, 1.0, 1.0, 1.0, 0.5434027910232544, 0.54296875, 1.0, 0.5442708134651184, 1.0, 1.0, 0.546006977558136, 1.0, 0.5438368320465088, 0.5451388955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5447048544883728, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5451388955116272, 1.0, 0.5447048544883728, 1.0, 1.0, 0.5447048544883728, 1.0, 1.0, 1.0, 0.5442708134651184, 1.0, 1.0, 1.0, 0.5442708134651184, 1.0, 1.0, 0.546006977558136, 1.0, 1.0, 1.0, 1.0, 0.5442708134651184, 1.0, 1.0, 1.0, 0.5442708134651184, 1.0, 0.5451388955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.546006977558136, 1.0, 1.0, 1.0, 0.5447048544883728, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.7265625, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.72265625, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 0.72265625, 0.71875, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.72265625, 0.72265625, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.7265625, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.7265625, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.7265625, 0.71875, 0.7265625, 1.0, 1.0, 0.71875, 0.73046875, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 0.7265625, 1.0, 1.0, 0.71875, 1.0, 0.71875, 0.71875, 0.7265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 0.7265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.71875, 1.0, 0.72265625, 0.71875, 1.0, 0.72265625, 1.0, 0.71875, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.72265625, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.72265625, 0.71875, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 0.73046875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 0.72265625, 0.72265625, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.72265625, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 0.71875, 0.71875, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 0.7265625, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.7265625, 0.71875, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.72265625, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.72265625, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.71875, 1.0, 0.72265625, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 0.72265625, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.71875, 0.72265625, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 0.71875, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.71875, 1.0, 0.71875, 0.71875, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.72265625, 1.0, 1.0, 0.73046875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 0.72265625, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.72265625, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.51953125, 1.0, 0.5224609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5205078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.513671875, 1.0, 1.0, 1.0, 0.5146484375, 1.0, 1.0, 0.513671875, 0.5185546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.51171875, 1.0, 1.0, 1.0, 0.5341796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5322265625, 1.0, 1.0, 0.521484375, 1.0, 1.0, 1.0, 0.5302734375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.51171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.572265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.513671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5126953125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5146484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.525390625, 0.5322265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5146484375, 1.0, 1.0, 1.0, 0.53515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.517578125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.897569477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9006076455116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.90234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.897569477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8984375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9079861044883728, 0.9001736044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8971354365348816, 1.0, 0.8997395634651184, 1.0, 1.0, 1.0, 0.8993055820465088, 0.9001736044883728, 1.0, 1.0, 1.0, 0.905381977558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8993055820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 0.94140625, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5107421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.50390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.509765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9800347089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 0.5068359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5087890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.509765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5146484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5166015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5068359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5107421875, 0.505859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5107421875, 1.0, 1.0, 0.5078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5078125, 1.0, 1.0, 0.51171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.513671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.51171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5048828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.51171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5166015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5068359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5166015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9618055820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.990234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5068359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5048828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5166015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.51171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.50390625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.501953125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.51953125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.54296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.517578125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5146484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.50390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.517578125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5224609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.517578125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.513671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5498046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5185546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5166015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.51171875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5087890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.517578125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5146484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5078125, 1.0, 1.0, 1.0, 1.0, 0.521484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5107421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5146484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5048828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5126953125, 1.0, 1.0, 0.5087890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.509765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.509765625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5087890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5166015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9814453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9814453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9814453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9814453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9814453125, 0.98193359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9817708134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9802517294883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9832899570465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.983506977558136, 1.0, 1.0, 1.0, 1.0, 0.982421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9774305820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9780815839767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.978515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9819878339767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9809027910232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9822048544883728, 1.0, 1.0, 1.0, 0.982421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.970703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.970703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.970703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.81005859375, 0.80126953125, 0.79345703125, 0.798828125, 0.7978515625, 0.7978515625, 0.8017578125, 0.7998046875, 0.81640625, 0.81494140625, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125]

Total parameter pruned: 22750820.00354965 (unstructured) 21489810 (structured)

Test: [0/79]	Time 0.154 (0.154)	Loss 0.3500 (0.3500) ([0.229]+[0.121])	Prec@1 93.750 (93.750)
 * Prec@1 93.800

 Total elapsed time  3:52:30.785687 
 FINETUNING


 sparsity of   [0.0, 0.0, 1.0, 0.0, 0.03703703731298447, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14814814925193787, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.1111111119389534, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.03703703731298447, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.03703703731298447, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [1.0, 1.0, 0.359375, 0.390625, 0.34375, 1.0, 1.0, 1.0, 0.359375, 0.359375, 1.0, 0.34375, 0.34375, 1.0, 0.34375, 0.34375, 0.34375, 0.34375, 0.359375, 1.0, 1.0, 1.0, 0.34375, 0.359375, 0.375, 0.359375, 0.34375, 0.359375, 0.34375, 0.359375, 0.34375, 0.359375, 0.359375, 0.34375, 0.375, 0.34375, 0.390625, 1.0, 0.34375, 0.34375, 0.359375, 0.375, 0.375, 1.0, 0.34375, 1.0, 1.0, 0.34375, 0.34375, 0.34375, 1.0, 0.34375, 0.34375, 1.0, 1.0, 0.359375, 0.34375, 0.34375, 0.34375, 1.0, 0.34375, 1.0, 0.359375, 0.34375]

 sparsity of   [0.3020833432674408, 1.0, 0.2986111044883728, 1.0, 1.0, 0.3038194477558136, 1.0, 1.0, 1.0, 1.0, 0.3107638955116272, 1.0, 1.0, 0.296875, 1.0, 1.0, 0.2986111044883728, 0.3072916567325592, 0.347222238779068, 1.0, 1.0, 0.3055555522441864, 0.2986111044883728, 1.0, 1.0, 1.0, 0.300347238779068, 1.0, 0.3072916567325592, 0.300347238779068, 1.0, 0.2986111044883728, 1.0, 1.0, 0.3020833432674408, 1.0, 1.0, 0.3020833432674408, 1.0, 0.2986111044883728, 0.2986111044883728, 1.0, 0.300347238779068, 0.300347238779068, 0.3020833432674408, 0.3055555522441864, 0.300347238779068, 1.0, 0.300347238779068, 1.0, 0.300347238779068, 1.0, 1.0, 1.0, 1.0, 0.3055555522441864, 0.2986111044883728, 1.0, 1.0, 0.2986111044883728, 1.0, 0.300347238779068, 0.296875, 1.0]

 sparsity of   [0.546875, 0.53125, 0.53125, 1.0, 0.53125, 1.0, 0.53125, 1.0, 0.546875, 0.515625, 0.53125, 1.0, 0.515625, 0.515625, 0.515625, 0.53125, 1.0, 0.53125, 0.515625, 1.0, 0.53125, 0.53125, 1.0, 0.515625, 0.53125, 0.53125, 0.53125, 0.53125, 0.53125, 0.53125, 0.53125, 0.53125, 0.53125, 1.0, 0.53125, 0.515625, 0.515625, 0.53125, 0.53125, 1.0, 0.53125, 0.53125, 0.515625, 1.0, 0.53125, 0.515625, 1.0, 0.53125, 0.515625, 0.546875, 0.515625, 0.546875, 0.53125, 0.546875, 0.53125, 0.5625, 1.0, 0.53125, 0.53125, 0.515625, 0.53125, 0.53125, 0.515625, 1.0, 0.53125, 0.53125, 0.515625, 0.53125, 0.53125, 0.53125, 1.0, 0.53125, 1.0, 0.53125, 0.53125, 0.53125, 0.53125, 0.515625, 0.515625, 0.53125, 1.0, 1.0, 0.53125, 0.53125, 0.53125, 0.515625, 0.546875, 1.0, 1.0, 1.0, 0.53125, 1.0, 0.53125, 0.515625, 1.0, 0.53125, 0.53125, 1.0, 0.53125, 0.53125, 0.515625, 0.515625, 0.515625, 0.53125, 0.53125, 0.515625, 0.53125, 0.515625, 0.53125, 0.53125, 0.515625, 0.53125, 0.53125, 0.53125, 1.0, 1.0, 1.0, 0.53125, 0.53125, 0.515625, 0.515625, 0.53125, 1.0, 1.0, 1.0, 0.53125, 1.0, 0.515625, 0.53125, 0.515625, 0.53125, 0.546875, 1.0, 1.0, 1.0, 0.515625, 1.0, 0.53125, 0.546875, 0.53125, 0.53125, 1.0, 0.53125, 0.515625, 0.53125, 1.0, 0.515625, 1.0, 0.515625, 0.53125, 0.53125, 0.515625, 0.515625, 1.0, 1.0, 0.546875, 0.53125, 0.515625, 0.546875, 0.53125, 0.515625, 0.53125, 0.515625, 0.53125, 0.53125, 1.0, 0.53125, 0.53125, 0.53125, 1.0, 0.53125, 1.0, 0.515625, 0.515625, 0.515625, 1.0, 0.53125, 1.0, 0.53125, 0.53125, 0.515625, 0.546875, 1.0, 0.53125, 0.53125, 0.53125, 1.0, 0.546875, 0.53125, 1.0, 0.515625, 0.515625, 0.53125, 1.0, 0.515625, 0.515625, 0.53125, 0.546875, 1.0, 1.0, 0.53125, 0.53125, 0.515625, 1.0, 0.53125, 0.53125, 0.53125, 0.515625, 0.53125, 0.53125, 1.0, 0.515625, 0.53125, 0.53125, 0.53125, 1.0, 0.515625, 1.0, 0.515625, 0.53125, 0.53125, 0.53125, 0.53125, 0.53125, 0.546875, 0.546875, 0.53125, 0.53125, 0.53125, 1.0, 0.53125, 0.53125, 1.0, 1.0, 0.53125, 0.53125, 0.53125, 0.515625, 1.0, 0.546875, 0.53125, 0.53125, 0.53125, 0.53125, 0.53125, 1.0, 0.53125, 0.53125, 0.53125, 0.515625, 0.53125, 0.53125, 0.53125, 1.0, 1.0, 0.53125]

 sparsity of   [0.359375, 0.34375, 0.34375, 0.46875, 0.34375, 1.0, 0.453125, 1.0, 0.34375, 0.34375, 0.34375, 1.0, 0.34375, 0.34375, 0.40625, 0.34375, 1.0, 0.34375, 0.390625, 1.0, 0.34375, 0.359375, 1.0, 0.359375, 0.359375, 0.34375, 0.4375, 0.359375, 0.34375, 0.34375, 0.34375, 0.34375, 0.34375, 1.0, 0.34375, 0.390625, 0.34375, 0.34375, 0.390625, 1.0, 0.34375, 0.34375, 0.34375, 1.0, 0.34375, 0.390625, 1.0, 0.34375, 0.359375, 0.34375, 0.34375, 0.34375, 0.359375, 0.359375, 0.359375, 0.34375, 1.0, 0.359375, 0.34375, 0.4375, 0.375, 0.34375, 0.375, 1.0, 0.34375, 0.34375, 0.34375, 0.34375, 0.359375, 0.34375, 1.0, 0.34375, 1.0, 1.0, 0.34375, 0.34375, 0.34375, 0.359375, 0.34375, 0.34375, 1.0, 1.0, 0.375, 1.0, 0.359375, 0.453125, 0.359375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.375, 0.359375, 1.0, 0.359375, 0.34375, 1.0, 0.359375, 0.359375, 0.34375, 0.390625, 0.34375, 0.359375, 0.359375, 0.34375, 0.375, 0.34375, 0.453125, 0.34375, 0.34375, 0.359375, 0.390625, 0.34375, 1.0, 1.0, 1.0, 0.359375, 0.375, 0.359375, 0.34375, 0.34375, 1.0, 1.0, 1.0, 0.34375, 1.0, 0.375, 0.34375, 0.359375, 0.34375, 0.34375, 1.0, 1.0, 1.0, 0.359375, 1.0, 0.34375, 0.34375, 0.359375, 0.34375, 1.0, 0.359375, 0.375, 0.359375, 1.0, 0.40625, 1.0, 0.4375, 0.34375, 0.390625, 0.34375, 0.390625, 0.34375, 1.0, 0.359375, 0.34375, 0.390625, 0.34375, 0.34375, 0.359375, 0.34375, 0.34375, 0.375, 1.0, 1.0, 0.34375, 0.359375, 0.34375, 1.0, 0.4375, 1.0, 0.375, 1.0, 0.375, 1.0, 0.34375, 1.0, 0.359375, 0.34375, 0.34375, 0.34375, 1.0, 0.34375, 0.359375, 0.359375, 1.0, 0.390625, 0.34375, 1.0, 0.34375, 0.375, 0.34375, 1.0, 0.34375, 0.359375, 0.34375, 0.390625, 1.0, 1.0, 0.40625, 0.34375, 0.34375, 1.0, 0.34375, 0.390625, 0.359375, 0.34375, 0.40625, 0.34375, 1.0, 0.390625, 0.359375, 0.34375, 0.34375, 1.0, 0.34375, 1.0, 0.375, 0.34375, 0.46875, 0.375, 0.375, 0.40625, 0.34375, 0.359375, 0.359375, 0.375, 0.359375, 1.0, 0.34375, 0.359375, 1.0, 1.0, 0.546875, 0.359375, 0.359375, 0.359375, 1.0, 0.421875, 0.359375, 0.375, 0.34375, 0.34375, 0.359375, 1.0, 0.375, 0.34375, 0.34375, 0.359375, 0.34375, 0.4375, 0.359375, 1.0, 1.0, 0.34375]

 sparsity of   [1.0, 1.0, 0.234375, 0.2265625, 1.0, 1.0, 1.0, 0.22265625, 0.2265625, 0.23046875, 1.0, 1.0, 0.2265625, 1.0, 1.0, 1.0, 1.0, 0.23046875, 0.234375, 1.0, 0.23828125, 1.0, 0.23046875, 0.2421875, 0.21875, 1.0, 0.22265625, 1.0, 0.21875, 1.0, 1.0, 1.0, 0.21484375, 0.22265625, 1.0, 1.0, 1.0, 1.0, 0.23046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.234375, 1.0, 0.2421875, 0.22265625, 1.0, 0.21875, 0.23828125, 0.23046875, 1.0, 0.234375, 1.0, 1.0, 0.24609375, 1.0, 1.0, 1.0, 0.21875, 0.22265625]

 sparsity of   [0.569444477558136, 0.5260416865348816, 0.522569477558136, 0.5434027910232544, 1.0, 1.0, 0.5486111044883728, 0.5555555820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5416666865348816, 1.0, 1.0, 0.5659722089767456, 1.0, 1.0, 0.5572916865348816, 1.0, 0.5677083134651184, 0.5520833134651184, 0.5347222089767456, 1.0, 0.5520833134651184, 1.0, 1.0, 1.0, 1.0, 0.5677083134651184, 1.0, 0.538194477558136, 0.5243055820465088, 1.0, 0.553819477558136, 0.553819477558136, 0.53125, 1.0, 1.0, 0.5364583134651184, 1.0, 0.546875, 1.0, 1.0, 1.0, 0.5711805820465088, 1.0, 0.5763888955116272, 0.5815972089767456, 1.0, 0.5659722089767456, 0.5590277910232544, 1.0, 1.0, 0.5625, 0.5329861044883728, 1.0, 1.0, 0.5746527910232544, 0.5503472089767456, 0.5520833134651184, 1.0]

 sparsity of   [0.515625, 0.515625, 0.53125, 0.53125, 0.5, 0.53125, 0.53125, 0.5, 0.515625, 0.5, 0.515625, 0.5, 0.515625, 0.515625, 0.53125, 0.515625, 1.0, 0.515625, 0.5, 1.0, 0.53125, 0.515625, 0.515625, 0.515625, 0.53125, 0.5, 1.0, 0.515625, 0.515625, 0.5625, 0.515625, 0.53125, 0.515625, 0.515625, 1.0, 0.515625, 0.515625, 0.515625, 1.0, 0.5, 1.0, 0.5625, 0.515625, 0.515625, 0.53125, 1.0, 1.0, 0.515625, 0.5, 0.515625, 0.515625, 0.53125, 0.515625, 0.515625, 0.5, 0.515625, 1.0, 0.515625, 1.0, 0.515625, 1.0, 0.515625, 0.515625, 1.0, 0.546875, 0.515625, 0.5, 0.53125, 0.53125, 0.515625, 0.515625, 0.515625, 1.0, 1.0, 0.515625, 0.515625, 1.0, 1.0, 1.0, 0.515625, 0.515625, 1.0, 0.515625, 1.0, 1.0, 0.515625, 0.53125, 0.5, 0.515625, 1.0, 1.0, 0.5, 0.515625, 0.515625, 0.484375, 0.515625, 0.515625, 0.546875, 1.0, 0.515625, 1.0, 0.515625, 0.5625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.5, 0.515625, 0.515625, 1.0, 1.0, 1.0, 0.515625, 0.515625, 0.515625, 0.515625, 1.0, 0.53125, 0.5, 1.0, 0.515625, 1.0, 0.515625, 0.515625, 0.515625, 0.53125, 0.515625, 1.0, 0.515625, 0.53125, 0.515625, 1.0, 0.53125, 0.515625, 0.515625, 0.5, 0.5625, 0.53125, 0.515625, 0.515625, 0.515625, 0.53125, 0.5, 0.515625, 0.515625, 0.53125, 0.515625, 0.53125, 0.515625, 0.53125, 0.515625, 0.515625, 0.515625, 0.53125, 0.515625, 0.515625, 1.0, 0.53125, 0.515625, 1.0, 1.0, 0.515625, 1.0, 0.515625, 0.515625, 1.0, 1.0, 0.515625, 0.515625, 0.53125, 1.0, 0.546875, 1.0, 0.515625, 0.5, 0.5, 0.515625, 0.515625, 0.515625, 0.515625, 1.0, 1.0, 0.5, 0.5, 1.0, 0.515625, 0.5, 0.515625, 1.0, 0.515625, 0.5, 0.515625, 0.53125, 1.0, 1.0, 0.515625, 0.53125, 0.515625, 1.0, 0.5, 0.5, 0.515625, 0.515625, 0.515625, 0.5, 0.515625, 0.53125, 0.515625, 1.0, 0.515625, 0.515625, 0.515625, 1.0, 0.53125, 0.515625, 0.53125, 0.515625, 1.0, 0.5, 1.0, 0.515625, 1.0, 1.0, 1.0, 0.515625, 0.515625, 0.515625, 1.0, 0.53125, 0.53125, 0.53125, 1.0, 0.515625, 0.515625, 1.0, 0.53125, 0.5, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 0.515625, 1.0, 0.53125, 1.0]

 sparsity of   [0.1015625, 0.1015625, 1.0, 0.1015625, 1.0, 0.09375, 1.0, 0.1328125, 0.09765625, 0.1015625, 0.09375, 0.109375, 0.10546875, 0.10546875, 0.125, 1.0, 0.1015625, 0.12109375, 0.1328125, 0.09765625, 1.0, 0.12890625, 0.109375, 0.1328125, 0.11328125, 0.11328125, 0.10546875, 0.12109375, 0.12109375, 0.1171875, 1.0, 1.0, 1.0, 0.125, 0.125, 0.1015625, 1.0, 1.0, 0.1015625, 0.109375, 0.08984375, 0.10546875, 0.1328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 0.1015625, 1.0, 0.12890625, 0.10546875, 1.0, 0.12890625, 1.0, 1.0, 0.1015625, 0.14453125, 1.0, 0.09765625, 0.1015625, 0.109375]

 sparsity of   [0.3229166567325592, 0.3211805522441864, 0.3125, 0.3211805522441864, 0.3142361044883728, 1.0, 0.3142361044883728, 1.0, 0.3263888955116272, 1.0, 0.3229166567325592, 0.3263888955116272, 1.0, 1.0, 1.0, 1.0, 0.315972238779068, 1.0, 0.3229166567325592, 1.0, 1.0, 1.0, 1.0, 0.3211805522441864, 0.3177083432674408, 1.0, 0.3194444477558136, 0.3194444477558136, 0.3177083432674408, 0.34375, 1.0, 0.3194444477558136, 1.0, 0.3125, 0.3177083432674408, 1.0, 0.3177083432674408, 0.331597238779068, 0.3211805522441864, 0.3177083432674408, 1.0, 0.3211805522441864, 1.0, 0.3090277910232544, 0.3194444477558136, 0.3263888955116272, 0.3125, 1.0, 0.3246527910232544, 1.0, 0.3211805522441864, 0.3211805522441864, 1.0, 1.0, 0.3385416567325592, 0.3142361044883728, 0.3194444477558136, 1.0, 0.3211805522441864, 0.3142361044883728, 0.3368055522441864, 0.3142361044883728, 1.0, 0.3194444477558136]

 sparsity of   [0.359375, 0.359375, 0.375, 1.0, 0.375, 0.359375, 1.0, 0.359375, 0.359375, 0.359375, 0.375, 1.0, 0.375, 0.359375, 0.359375, 0.375, 0.375, 0.359375, 0.359375, 0.359375, 1.0, 0.359375, 1.0, 0.375, 0.40625, 0.375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.375, 0.359375, 1.0, 0.375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.375, 0.359375, 0.359375, 0.359375, 0.375, 0.375, 0.359375, 0.375, 0.375, 0.359375, 0.359375, 1.0, 0.359375, 1.0, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 1.0, 1.0, 1.0, 0.375, 1.0, 0.359375, 0.375, 0.359375, 0.359375, 0.375, 0.375, 1.0, 0.359375, 0.390625, 0.375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.375, 0.375, 1.0, 0.359375, 0.359375, 0.359375, 0.390625, 0.359375, 0.375, 0.390625, 0.375, 0.359375, 0.375, 0.359375, 0.375, 0.359375, 0.359375, 0.359375, 0.46875, 1.0, 1.0, 0.40625, 1.0, 0.375, 0.359375, 0.390625, 0.359375, 0.390625, 0.359375, 0.359375, 0.390625, 0.375, 0.359375, 0.359375, 0.390625, 0.359375, 0.359375, 1.0, 0.375, 0.359375, 0.375, 0.375, 0.359375, 0.359375, 0.359375, 1.0, 0.375, 0.375, 0.359375, 0.359375, 0.359375, 0.359375, 0.375, 0.359375, 0.359375, 0.359375, 0.359375, 0.375, 0.359375, 0.375, 0.359375, 0.359375, 1.0, 0.359375, 0.359375, 0.359375, 0.40625, 0.359375, 1.0, 1.0, 0.359375, 0.359375, 0.359375, 1.0, 0.359375, 0.375, 0.359375, 0.375, 0.359375, 0.359375, 0.390625, 1.0, 0.375, 0.375, 0.375, 0.390625, 0.359375, 0.359375, 0.359375, 0.375, 0.375, 0.359375, 0.390625, 1.0, 0.359375, 0.359375, 1.0, 0.359375, 0.359375, 0.359375, 1.0, 0.359375, 1.0, 0.359375, 0.359375, 0.375, 0.359375, 1.0, 0.375, 0.375, 0.359375, 0.359375, 0.359375, 0.375, 0.359375, 0.359375, 0.359375, 0.375, 0.40625, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 0.375, 0.359375, 0.375, 0.375, 0.359375, 1.0, 0.359375, 1.0, 0.359375, 0.359375, 0.359375, 0.359375, 0.359375, 1.0, 0.359375, 0.390625, 0.375, 0.359375, 1.0, 0.375, 0.359375, 0.359375, 0.359375, 0.359375, 0.375, 0.359375, 0.375, 0.359375, 0.359375, 0.359375, 0.359375, 0.375, 0.359375, 0.359375, 0.359375]

 sparsity of   [1.0, 0.0234375, 1.0, 0.0234375, 0.02734375, 0.24609375, 0.0234375, 0.02734375, 0.03515625, 1.0, 1.0, 1.0, 0.0234375, 1.0, 0.03125, 0.02734375, 1.0, 0.03125, 1.0, 0.04296875, 0.02734375, 0.02734375, 0.0234375, 0.0390625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.01953125, 0.02734375, 0.0390625, 0.02734375, 0.03515625, 1.0, 1.0, 0.03125, 0.0234375, 0.02734375, 1.0, 1.0, 0.02734375, 1.0, 0.03515625, 0.0625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.02734375, 0.046875, 1.0, 1.0, 0.03125, 0.03125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.03515625, 0.05859375, 0.03125, 0.046875, 0.0234375, 0.0234375, 0.03125, 0.0234375, 1.0, 0.0234375, 1.0, 0.03515625, 0.0390625, 1.0, 0.046875, 0.03515625, 1.0, 1.0, 1.0, 0.046875, 1.0, 0.03125, 0.03125, 0.03125, 0.0390625, 0.02734375, 0.0234375, 0.02734375, 0.02734375, 0.0234375, 0.02734375, 1.0, 0.02734375, 1.0, 0.03125, 1.0, 0.03515625, 0.046875, 0.02734375, 1.0, 0.03515625, 0.02734375, 1.0, 0.03515625, 1.0, 0.01953125, 1.0, 1.0, 0.0390625, 0.0234375, 0.02734375, 1.0, 1.0, 0.03515625, 0.03125, 0.03125, 1.0, 0.0390625, 0.03515625, 0.02734375, 1.0, 0.0234375, 1.0, 1.0, 1.0]

 sparsity of   [0.409722238779068, 0.4149305522441864, 1.0, 1.0, 1.0, 1.0, 0.4088541567325592, 1.0, 1.0, 1.0, 1.0, 0.4140625, 1.0, 0.421875, 0.40625, 1.0, 1.0, 1.0, 1.0, 0.4131944477558136, 1.0, 1.0, 1.0, 1.0, 0.409722238779068, 1.0, 1.0, 0.4157986044883728, 1.0, 0.4079861044883728, 1.0, 1.0, 0.4244791567325592, 0.4166666567325592, 0.4184027910232544, 1.0, 1.0, 0.4071180522441864, 0.4157986044883728, 1.0, 1.0, 1.0, 0.4157986044883728, 1.0, 0.40625, 0.4123263955116272, 1.0, 0.417534738779068, 1.0, 0.4140625, 1.0, 0.4184027910232544, 0.4131944477558136, 0.4201388955116272, 0.4184027910232544, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4053819477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4131944477558136, 0.4149305522441864, 1.0, 1.0, 1.0, 1.0, 0.4123263955116272, 1.0, 1.0, 1.0, 1.0, 0.4105902910232544, 0.409722238779068, 1.0, 1.0, 0.4140625, 0.4140625, 0.4131944477558136, 1.0, 1.0, 1.0, 0.4192708432674408, 0.4123263955116272, 1.0, 1.0, 0.4088541567325592, 0.4192708432674408, 1.0, 1.0, 0.4053819477558136, 0.4105902910232544, 1.0, 1.0, 1.0, 0.417534738779068, 1.0, 0.4201388955116272, 1.0, 0.4270833432674408, 1.0, 0.4114583432674408, 0.4045138955116272, 1.0, 0.4201388955116272, 1.0, 0.4149305522441864, 0.4123263955116272, 0.4071180522441864, 1.0, 0.4123263955116272, 0.4105902910232544, 1.0, 1.0, 1.0, 0.4053819477558136, 0.4166666567325592, 1.0, 1.0, 0.4184027910232544, 1.0, 1.0, 0.4140625]

 sparsity of   [1.0, 0.5703125, 0.5703125, 0.5625, 0.578125, 0.5703125, 0.5703125, 0.59375, 0.5703125, 0.578125, 0.5703125, 0.5546875, 1.0, 0.5859375, 0.5625, 0.578125, 0.578125, 1.0, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.578125, 0.5703125, 0.578125, 0.5625, 0.578125, 0.5703125, 0.5625, 1.0, 0.5703125, 1.0, 0.5703125, 0.578125, 1.0, 0.5703125, 0.5703125, 0.578125, 0.5703125, 1.0, 1.0, 0.5703125, 0.5859375, 1.0, 0.5703125, 0.5703125, 1.0, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.5625, 0.5859375, 0.578125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 1.0, 0.5703125, 0.578125, 0.5703125, 0.578125, 0.578125, 0.5703125, 0.5703125, 0.578125, 0.5625, 0.5859375, 0.5625, 1.0, 0.5703125, 0.5703125, 0.5703125, 1.0, 0.59375, 0.578125, 0.578125, 1.0, 1.0, 0.578125, 0.5859375, 1.0, 0.578125, 0.578125, 1.0, 1.0, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125, 0.5625, 0.578125, 1.0, 0.5703125, 0.578125, 0.578125, 0.5703125, 0.5703125, 0.5703125, 0.5625, 1.0, 0.578125, 0.5859375, 0.578125, 0.5703125, 1.0, 0.578125, 1.0, 0.5703125, 0.5703125, 1.0, 1.0, 0.5546875, 1.0, 0.5703125, 0.5703125, 0.578125, 0.578125, 0.578125, 0.578125, 0.5625, 0.578125, 0.5703125, 1.0, 0.578125, 0.578125, 0.5625, 1.0, 0.578125, 0.5703125, 1.0, 1.0, 1.0, 1.0, 0.578125, 0.5703125, 1.0, 0.5703125, 0.5625, 0.5703125, 0.5703125, 1.0, 0.578125, 0.5859375, 0.578125, 1.0, 1.0, 1.0, 0.578125, 0.578125, 0.578125, 0.578125, 0.5703125, 0.5703125, 1.0, 0.5859375, 1.0, 0.5859375, 0.5703125, 1.0, 1.0, 0.5546875, 0.5703125, 0.5703125, 0.5703125, 0.5625, 0.5703125, 0.5703125, 0.578125, 0.5703125, 0.5703125, 0.5703125, 1.0, 0.5703125, 1.0, 0.5859375, 0.5703125, 0.578125, 0.5703125, 1.0, 0.578125, 0.578125, 0.5859375, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 1.0, 0.578125, 0.5703125, 0.5703125, 0.578125, 1.0, 0.5703125, 0.5546875, 0.5625, 1.0, 1.0, 1.0, 0.5703125, 0.578125, 0.5703125, 0.5703125, 0.578125, 0.5703125, 0.5859375, 1.0, 0.5703125, 1.0, 0.5703125, 0.5859375, 1.0, 0.59375, 0.5703125, 0.5703125, 1.0, 1.0, 1.0, 0.578125, 1.0, 0.578125, 0.578125, 0.5703125, 0.578125, 0.5703125, 0.578125, 0.5703125, 0.5703125, 0.578125, 1.0, 0.5703125, 0.5859375, 0.5859375, 1.0, 1.0, 0.578125, 1.0, 0.578125, 0.5703125, 0.5703125, 0.578125, 0.5703125, 1.0, 1.0, 1.0, 1.0, 0.5703125, 0.578125, 1.0, 0.578125, 0.5625, 1.0, 1.0, 0.5625, 0.5703125, 0.578125, 1.0, 0.5625, 1.0, 1.0, 1.0, 0.578125, 0.578125, 0.578125, 0.5703125, 0.578125, 0.5703125, 0.5625, 1.0, 0.578125, 0.578125, 0.5546875, 0.5546875, 0.578125, 0.5625, 0.5859375, 0.5859375, 0.59375, 1.0, 0.5859375, 0.5703125, 0.578125, 0.59375, 0.578125, 0.578125, 1.0, 0.5859375, 0.6015625, 1.0, 0.578125, 1.0, 0.578125, 0.5703125, 0.5703125, 0.578125, 0.5703125, 0.5703125, 0.5703125, 1.0, 0.5703125, 1.0, 1.0, 0.578125, 0.5703125, 0.5703125, 1.0, 0.5859375, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.5625, 1.0, 0.578125, 0.578125, 1.0, 1.0, 0.5703125, 0.5625, 0.578125, 0.578125, 0.5625, 1.0, 0.578125, 1.0, 0.5625, 0.5703125, 0.5703125, 1.0, 1.0, 1.0, 0.5703125, 0.5546875, 0.578125, 0.5703125, 1.0, 0.5703125, 1.0, 0.5703125, 0.5546875, 1.0, 0.5625, 1.0, 0.578125, 1.0, 1.0, 0.59375, 1.0, 0.578125, 0.578125, 0.578125, 0.5703125, 1.0, 0.5703125, 1.0, 0.578125, 0.5703125, 0.578125, 0.578125, 0.5703125, 0.578125, 0.5703125, 0.5703125, 0.578125, 0.578125, 1.0, 0.5703125, 0.5625, 0.5703125, 0.5859375, 0.5625, 0.5625, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5859375, 0.5859375, 0.578125, 0.578125, 0.5625, 0.5703125, 1.0, 0.5625, 1.0, 1.0, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.5703125, 0.578125, 0.578125, 0.578125, 0.5703125, 0.5703125, 0.5703125, 0.578125, 0.59375, 0.578125, 0.59375, 0.578125, 0.5703125, 0.5703125, 0.5703125, 0.578125, 0.578125, 1.0, 0.5703125, 0.5703125, 0.5625, 1.0, 0.5703125, 0.5703125, 0.5703125, 0.578125, 0.5703125, 0.5703125, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.5625, 1.0, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125, 1.0, 0.5703125, 1.0, 0.5703125, 0.578125, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5625, 1.0, 1.0, 0.578125, 1.0, 0.5703125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5625, 0.578125, 0.5625, 0.578125, 0.578125, 0.5703125, 1.0, 0.5859375, 0.59375, 0.5703125, 0.5625, 0.578125, 1.0, 1.0, 0.5546875, 0.578125, 1.0, 0.5703125, 1.0, 1.0, 0.5703125, 0.5703125, 1.0, 0.5703125, 1.0, 1.0, 0.578125, 1.0, 1.0, 1.0, 0.5703125, 0.5625, 1.0, 1.0, 1.0, 0.578125, 0.578125, 0.5703125, 0.578125, 0.5625, 0.5703125, 1.0, 1.0, 1.0, 0.5859375, 1.0, 1.0, 1.0, 1.0, 0.5703125, 0.5703125, 1.0, 0.5859375, 1.0, 1.0, 1.0, 0.5703125]

 sparsity of   [1.0, 0.03515625, 0.0390625, 0.11328125, 0.02734375, 0.1015625, 0.04296875, 0.03515625, 0.02734375, 0.0390625, 0.02734375, 0.02734375, 1.0, 0.03125, 0.03125, 0.02734375, 0.03515625, 1.0, 0.02734375, 1.0, 0.03515625, 0.04296875, 0.03515625, 0.03125, 0.03515625, 0.02734375, 1.0, 0.0859375, 0.0390625, 0.0390625, 0.03515625, 1.0, 0.05078125, 0.04296875, 1.0, 0.0546875, 0.0390625, 0.04296875, 0.05859375, 1.0, 1.0, 0.03515625, 0.03515625, 1.0, 0.03515625, 0.04296875, 1.0, 0.0390625, 1.0, 0.04296875, 0.03515625, 0.02734375, 1.0, 0.02734375, 0.0390625, 0.0234375, 0.03515625, 0.02734375, 1.0, 0.03125, 0.05078125, 0.03515625, 0.05078125, 0.02734375, 0.05078125, 0.03515625, 1.0, 0.04296875, 0.046875, 0.03125, 1.0, 0.03125, 0.03125, 0.03515625, 0.02734375, 0.03515625, 0.03515625, 1.0, 1.0, 1.0, 0.109375, 0.046875, 1.0, 1.0, 0.02734375, 1.0, 1.0, 0.03515625, 0.078125, 0.02734375, 0.046875, 0.07421875, 0.046875, 0.03125, 1.0, 0.02734375, 0.0234375, 0.04296875, 0.03125, 0.03515625, 0.04296875, 0.08984375, 1.0, 0.02734375, 0.04296875, 0.04296875, 0.0234375, 1.0, 0.0234375, 1.0, 0.0234375, 0.02734375, 1.0, 1.0, 0.05859375, 1.0, 0.03515625, 0.0390625, 0.03125, 0.04296875, 0.02734375, 0.05078125, 0.0390625, 0.0234375, 0.1328125, 1.0, 0.03125, 0.0390625, 0.0546875, 1.0, 0.0390625, 0.02734375, 1.0, 0.03515625, 1.0, 1.0, 0.0234375, 0.03125, 1.0, 0.03515625, 0.02734375, 0.02734375, 0.04296875, 1.0, 0.03125, 0.02734375, 0.0234375, 1.0, 1.0, 1.0, 0.03515625, 0.03515625, 0.046875, 0.03515625, 0.03125, 0.02734375, 1.0, 0.03515625, 1.0, 0.03125, 0.03125, 1.0, 1.0, 0.03125, 0.02734375, 0.0390625, 0.0390625, 0.02734375, 0.05078125, 0.03125, 0.03125, 0.03125, 0.03125, 0.05078125, 0.0390625, 0.03125, 1.0, 0.01953125, 0.0390625, 0.02734375, 0.08984375, 1.0, 0.03515625, 0.02734375, 1.0, 0.0625, 1.0, 0.0234375, 0.02734375, 0.02734375, 0.03515625, 1.0, 1.0, 0.03515625, 0.01953125, 0.03125, 1.0, 0.04296875, 0.06640625, 0.03125, 1.0, 1.0, 0.03515625, 0.05859375, 0.03125, 0.03515625, 0.0234375, 0.02734375, 0.01953125, 0.046875, 1.0, 0.0234375, 1.0, 0.0234375, 0.02734375, 1.0, 0.0546875, 0.03515625, 0.03515625, 1.0, 1.0, 1.0, 0.03515625, 1.0, 0.1171875, 0.03515625, 0.08984375, 0.04296875, 0.0390625, 0.03125, 0.046875, 0.03125, 0.03515625, 1.0, 0.046875, 0.02734375, 0.04296875, 1.0, 1.0, 0.0390625, 1.0, 0.03515625, 0.05078125, 0.03515625, 0.0234375, 0.03125, 1.0, 1.0, 1.0, 1.0, 0.0234375, 0.03125, 1.0, 0.03125, 0.08203125, 1.0, 1.0, 0.03515625, 0.0546875, 0.02734375, 1.0, 0.046875, 1.0, 1.0, 0.03515625, 1.0, 0.02734375, 0.046875, 0.03515625, 1.0, 0.03515625, 0.03515625, 1.0, 0.03125, 0.0390625, 0.03515625, 0.046875, 0.03125, 0.03125, 0.0390625, 0.02734375, 1.0, 1.0, 0.03125, 0.03515625, 0.046875, 0.03125, 1.0, 0.05078125, 1.0, 0.03125, 0.03125, 1.0, 0.0390625, 0.0859375, 0.04296875, 0.02734375, 0.02734375, 0.02734375, 0.02734375, 1.0, 0.02734375, 1.0, 0.0234375, 1.0, 1.0, 0.0390625, 0.0390625, 0.05078125, 1.0, 0.02734375, 0.03515625, 1.0, 0.03515625, 0.0234375, 0.02734375, 1.0, 0.08984375, 0.03125, 0.02734375, 1.0, 0.046875, 0.03515625, 0.04296875, 0.03125, 0.02734375, 1.0, 0.03125, 0.0390625, 0.03515625, 0.0390625, 0.0390625, 1.0, 0.03125, 1.0, 0.0234375, 0.0390625, 0.04296875, 0.03515625, 1.0, 0.03125, 1.0, 0.0234375, 0.03125, 1.0, 0.03515625, 1.0, 0.10546875, 1.0, 1.0, 0.0390625, 0.02734375, 0.03515625, 0.03125, 0.03125, 0.02734375, 1.0, 0.0390625, 1.0, 0.0390625, 0.03125, 0.0390625, 0.02734375, 1.0, 0.03515625, 0.03125, 0.03125, 0.02734375, 0.02734375, 1.0, 0.0859375, 0.02734375, 0.0625, 0.0234375, 0.03125, 0.03515625, 0.03515625, 0.0234375, 0.03125, 0.02734375, 0.02734375, 0.02734375, 0.03515625, 0.04296875, 0.03125, 0.03515625, 1.0, 0.0546875, 1.0, 1.0, 0.1015625, 1.0, 0.02734375, 0.03515625, 0.04296875, 0.046875, 0.03515625, 1.0, 0.0625, 0.03515625, 0.03125, 1.0, 0.0390625, 0.02734375, 0.03125, 1.0, 0.03125, 0.03515625, 0.03125, 0.03125, 0.03125, 1.0, 0.04296875, 0.03125, 0.09375, 1.0, 0.109375, 0.0234375, 0.03125, 1.0, 0.03125, 0.0390625, 0.03515625, 1.0, 0.03125, 0.03125, 0.05859375, 1.0, 0.09375, 0.03515625, 0.0234375, 0.01953125, 0.046875, 1.0, 0.02734375, 1.0, 0.03515625, 0.03125, 0.03125, 1.0, 0.046875, 0.03125, 0.03125, 0.03125, 0.04296875, 1.0, 1.0, 0.03125, 1.0, 0.0390625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.02734375, 0.03125, 0.109375, 0.04296875, 0.03125, 0.0390625, 1.0, 0.02734375, 0.046875, 0.03515625, 0.03515625, 0.02734375, 1.0, 1.0, 0.06640625, 0.02734375, 1.0, 0.06640625, 0.03125, 1.0, 0.03125, 0.07421875, 1.0, 0.15234375, 1.0, 1.0, 0.02734375, 0.03125, 1.0, 1.0, 0.08203125, 0.03515625, 1.0, 1.0, 0.05859375, 0.046875, 0.0234375, 0.1328125, 0.1015625, 0.05859375, 0.02734375, 1.0, 1.0, 1.0, 0.02734375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.03125, 1.0, 0.0390625, 1.0, 1.0, 1.0, 0.02734375]

 sparsity of   [1.0, 1.0, 1.0, 0.2578125, 1.0, 0.263671875, 0.25390625, 1.0, 0.259765625, 1.0, 0.25390625, 1.0, 0.265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.259765625, 1.0, 1.0, 1.0, 0.2578125, 1.0, 1.0, 1.0, 1.0, 0.26171875, 1.0, 1.0, 0.2578125, 1.0, 1.0, 1.0, 0.28125, 1.0, 1.0, 1.0, 0.263671875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.259765625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28125, 1.0, 0.25390625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.255859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.279296875, 1.0, 0.263671875, 1.0, 1.0, 1.0, 0.26171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.259765625, 1.0, 0.27734375, 1.0, 0.259765625, 1.0, 1.0, 1.0, 0.263671875, 0.26171875, 0.2578125, 1.0, 0.26171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.259765625, 1.0, 1.0, 0.255859375, 1.0, 0.251953125, 1.0, 0.259765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.255859375, 1.0, 0.265625, 1.0, 0.267578125, 0.25, 1.0, 0.263671875, 1.0, 0.265625, 1.0, 0.263671875, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 0.7039930820465088, 0.7065972089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 1.0, 1.0, 0.7144097089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7039930820465088, 1.0, 1.0, 1.0, 0.703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6987847089767456, 1.0, 1.0, 0.7048611044883728, 0.7039930820465088, 0.6970486044883728, 1.0, 1.0, 0.7013888955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7057291865348816, 1.0, 1.0, 0.7118055820465088, 0.7013888955116272, 0.703125, 1.0, 0.7005208134651184, 1.0, 1.0, 1.0, 0.7048611044883728, 0.7048611044883728, 0.7065972089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7048611044883728, 1.0, 0.7048611044883728, 1.0, 1.0, 0.703125, 1.0, 1.0, 1.0, 0.703125, 0.7005208134651184, 1.0, 1.0, 1.0, 0.7092013955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7048611044883728, 1.0, 0.7092013955116272, 1.0, 0.7074652910232544, 1.0, 0.7048611044883728, 0.6996527910232544, 1.0, 1.0, 0.7065972089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.75, 1.0, 0.75, 0.7578125, 0.75, 1.0, 1.0, 0.75, 0.75, 0.75, 0.75, 0.765625, 1.0, 0.75, 0.75, 0.75, 0.75, 1.0, 0.75, 1.0, 0.7578125, 1.0, 0.75, 1.0, 0.765625, 0.75, 1.0, 1.0, 0.75, 1.0, 0.75, 1.0, 1.0, 1.0, 0.75, 0.765625, 0.75, 0.75, 0.7578125, 1.0, 1.0, 0.75, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 0.75, 0.75, 0.75, 1.0, 1.0, 0.7578125, 0.75, 0.7578125, 0.75, 1.0, 1.0, 0.75, 0.75, 1.0, 0.75, 1.0, 0.75, 1.0, 0.75, 1.0, 0.75, 0.75, 0.75, 1.0, 0.75, 1.0, 0.75, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.75, 0.7578125, 1.0, 0.75, 0.75, 0.75, 0.765625, 1.0, 0.75, 1.0, 0.7578125, 1.0, 0.7578125, 0.75, 1.0, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.7734375, 1.0, 0.75, 0.75, 0.75, 1.0, 0.75, 0.75, 1.0, 1.0, 0.75, 1.0, 0.75, 1.0, 1.0, 1.0, 0.75, 0.75, 0.75, 0.75, 1.0, 0.75, 0.75, 0.75, 0.75, 1.0, 0.75, 0.75, 1.0, 1.0, 1.0, 1.0, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 1.0, 0.75, 1.0, 0.7578125, 1.0, 0.75, 1.0, 0.75, 0.75, 1.0, 0.75, 0.75, 0.75, 1.0, 0.75, 1.0, 0.75, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 0.75, 0.75, 0.7578125, 0.7578125, 0.75, 0.7578125, 0.75, 1.0, 0.75, 1.0, 0.75, 1.0, 0.75, 0.75, 0.75, 0.75, 0.75, 0.7578125, 0.75, 1.0, 1.0, 1.0, 0.75, 1.0, 0.75, 1.0, 1.0, 1.0, 0.75, 0.75, 0.75, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 0.75, 1.0, 0.75, 0.75, 1.0, 0.75, 0.75, 0.7578125, 0.75, 0.75, 0.75, 1.0, 0.7578125, 1.0, 0.75, 0.75, 0.75, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.75, 0.75, 1.0, 0.75, 0.75, 0.75, 1.0, 1.0, 0.75, 0.75, 0.75, 1.0, 1.0, 0.75, 1.0, 0.75, 1.0, 0.75, 0.75, 0.7578125, 1.0, 1.0, 1.0, 0.75, 0.75, 0.75, 1.0, 0.75, 0.75, 0.75, 1.0, 0.75, 0.75, 0.7578125, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.75, 1.0, 1.0, 0.7578125, 0.75, 0.75, 0.75, 0.75, 0.75, 1.0, 0.75, 0.75, 0.75, 0.7578125, 1.0, 1.0, 0.7578125, 1.0, 0.75, 0.75, 1.0, 0.75, 1.0, 0.75, 1.0, 1.0, 0.75, 1.0, 0.75, 0.75, 0.75, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 0.75, 0.75, 1.0, 1.0, 0.75, 0.75, 1.0, 0.75, 0.75, 0.75, 1.0, 1.0, 0.75, 1.0, 0.75, 0.75, 0.7578125, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 1.0, 0.7578125, 1.0, 1.0, 1.0, 0.75, 0.75, 1.0, 1.0, 0.7578125, 1.0, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 1.0, 1.0, 0.75, 0.75, 1.0, 1.0, 0.75, 0.75, 1.0, 0.75, 1.0, 0.7578125, 0.75, 0.75, 0.7578125, 1.0, 0.75, 0.75, 0.7578125, 1.0, 0.75, 1.0, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 1.0, 0.7578125, 0.75, 0.75, 0.75, 0.7578125, 1.0, 0.75, 0.75, 0.7734375, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.75, 0.75, 0.75, 0.75, 1.0, 0.75, 0.75, 0.75, 1.0, 0.75, 0.765625, 0.75, 1.0, 0.75, 0.75, 0.75, 0.75, 1.0, 1.0, 0.7578125, 0.75, 0.75, 1.0, 0.7578125, 0.75, 0.765625, 1.0, 0.75, 0.75, 0.75, 0.75, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 0.75, 0.75, 1.0, 0.75, 0.75, 0.7578125, 0.75, 0.75, 1.0, 1.0, 0.75, 0.75, 0.75, 0.75, 1.0, 1.0, 0.75, 1.0, 0.75, 0.75, 1.0, 1.0, 1.0, 1.0, 0.75, 0.75, 0.75, 1.0, 0.7578125, 0.75, 1.0, 0.75, 0.7578125, 0.75, 0.7578125, 0.75, 0.75, 1.0, 0.75, 0.75, 1.0, 0.75, 0.75, 1.0, 0.75, 1.0, 1.0, 0.75, 1.0, 1.0, 0.75, 0.75, 1.0, 1.0, 0.75, 0.75, 1.0, 0.75, 1.0, 0.75, 0.75, 1.0, 0.75, 1.0, 0.75, 0.75, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 0.7578125, 1.0, 1.0, 1.0, 0.75]

 sparsity of   [0.205078125, 1.0, 0.208984375, 0.208984375, 0.19921875, 1.0, 0.19921875, 1.0, 1.0, 1.0, 0.203125, 0.205078125, 1.0, 1.0, 1.0, 0.201171875, 1.0, 1.0, 0.19921875, 0.201171875, 1.0, 0.203125, 1.0, 0.205078125, 0.208984375, 1.0, 1.0, 1.0, 0.19921875, 1.0, 0.2109375, 0.201171875, 0.208984375, 1.0, 0.212890625, 0.203125, 1.0, 1.0, 0.19921875, 0.212890625, 0.587890625, 0.291015625, 0.201171875, 0.197265625, 1.0, 0.205078125, 1.0, 1.0, 0.19140625, 0.193359375, 0.205078125, 1.0, 0.1953125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19921875, 0.203125, 0.20703125, 0.208984375, 0.197265625, 0.19140625, 0.20703125, 0.208984375, 0.203125, 1.0, 0.2109375, 1.0, 1.0, 0.201171875, 0.197265625, 1.0, 1.0, 1.0, 0.2109375, 0.203125, 1.0, 1.0, 0.203125, 0.19921875, 1.0, 1.0, 0.203125, 1.0, 1.0, 0.205078125, 0.220703125, 1.0, 1.0, 1.0, 0.208984375, 1.0, 1.0, 1.0, 0.205078125, 0.205078125, 1.0, 0.203125, 1.0, 0.208984375, 1.0, 0.19921875, 0.203125, 0.201171875, 1.0, 0.2109375, 0.203125, 0.201171875, 0.19921875, 1.0, 1.0, 0.203125, 1.0, 1.0, 0.201171875, 0.1953125, 1.0, 1.0, 0.205078125, 0.193359375, 0.25, 1.0, 0.201171875, 0.20703125, 0.19921875, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444477558136, 1.0, 1.0, 0.448784738779068, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4435763955116272, 1.0, 1.0, 1.0, 0.4470486044883728, 1.0, 1.0, 1.0, 0.4392361044883728, 0.4392361044883728, 1.0, 1.0, 0.4444444477558136, 1.0, 1.0, 0.4418402910232544, 1.0, 1.0, 1.0, 0.4418402910232544, 1.0, 0.4418402910232544, 1.0, 1.0, 0.440972238779068, 0.4366319477558136, 0.453125, 0.440972238779068, 1.0, 1.0, 0.4418402910232544, 0.4427083432674408, 1.0, 0.4427083432674408, 1.0, 0.4435763955116272, 0.4427083432674408, 1.0, 1.0, 1.0, 0.4435763955116272, 1.0, 0.440972238779068, 1.0, 1.0, 0.4505208432674408, 0.4479166567325592, 0.4444444477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4479166567325592, 1.0, 1.0, 1.0, 0.4401041567325592, 0.4435763955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4392361044883728, 1.0, 0.4418402910232544, 1.0, 1.0, 0.4418402910232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4427083432674408, 0.4453125, 1.0, 0.4461805522441864, 0.4427083432674408, 0.4496527910232544, 1.0, 0.4479166567325592, 0.4418402910232544, 1.0, 0.4444444477558136, 1.0, 1.0, 1.0, 0.4392361044883728, 1.0, 1.0, 0.4435763955116272, 1.0, 1.0, 0.4444444477558136, 0.4479166567325592, 1.0, 0.4427083432674408, 1.0, 1.0, 0.4435763955116272, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.671875, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 0.6640625, 0.65625, 0.65625, 0.6640625, 0.6640625, 1.0, 0.671875, 0.65625, 0.6640625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.6640625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 1.0, 1.0, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.6640625, 1.0, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 1.0, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.6640625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.6640625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.6640625, 0.65625, 0.6640625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.6640625, 1.0, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 1.0, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 1.0, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 0.671875, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 1.0, 0.65625, 1.0, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 1.0, 0.6640625, 0.65625, 1.0, 1.0, 1.0, 0.65625, 0.65625, 1.0, 0.6640625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.6640625, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.6640625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.6640625, 0.65625, 1.0, 0.65625, 0.65625, 1.0, 1.0, 1.0, 0.6640625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 1.0, 0.65625, 0.6640625, 1.0, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 0.671875, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 1.0, 0.6640625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.671875, 0.65625, 1.0, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.6640625, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 0.65625, 1.0, 0.6640625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 1.0, 1.0, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.6640625, 0.671875, 0.65625, 0.6640625, 0.6640625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.6640625, 0.65625, 0.6640625, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.6640625, 0.6640625, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 1.0, 0.65625, 1.0, 0.65625, 1.0, 0.65625, 1.0, 0.6640625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 1.0, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 1.0, 1.0, 0.65625, 1.0, 1.0, 0.65625, 0.65625, 0.6640625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.6640625, 0.65625, 1.0, 1.0, 1.0, 1.0, 0.65625, 0.65625, 0.65625, 0.65625, 1.0, 0.65625, 0.6640625]

 sparsity of   [1.0, 0.134765625, 1.0, 1.0, 1.0, 0.134765625, 0.1484375, 1.0, 0.1328125, 1.0, 0.125, 1.0, 0.140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12890625, 1.0, 0.130859375, 0.12890625, 1.0, 1.0, 1.0, 1.0, 0.130859375, 1.0, 0.130859375, 0.138671875, 0.123046875, 0.13671875, 0.12890625, 0.126953125, 1.0, 0.140625, 1.0, 0.140625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1328125, 0.123046875, 1.0, 0.138671875, 0.12109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.134765625, 0.130859375, 1.0, 1.0, 0.1328125, 0.12890625, 0.1328125, 1.0, 1.0, 1.0, 0.12890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1328125, 1.0, 0.125, 1.0, 0.130859375, 1.0, 1.0, 0.138671875, 1.0, 1.0, 1.0, 1.0, 0.12890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.134765625, 1.0, 0.130859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.126953125, 1.0, 0.12890625, 1.0, 0.12109375, 1.0, 1.0, 1.0, 1.0, 0.125, 0.130859375, 0.130859375, 0.123046875, 0.123046875, 1.0, 0.1328125, 0.123046875]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6354166865348816, 0.7404513955116272, 1.0, 1.0, 1.0, 1.0, 0.6614583134651184, 1.0, 1.0, 0.694444477558136, 1.0, 1.0, 1.0, 0.694444477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6545138955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6432291865348816, 0.6284722089767456, 1.0, 1.0, 1.0, 1.0, 0.6362847089767456, 1.0, 1.0, 1.0, 1.0, 0.6258680820465088, 0.6267361044883728, 0.6223958134651184, 1.0, 0.6293402910232544, 0.678819477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.631944477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6293402910232544, 1.0, 1.0, 1.0, 0.616319477558136, 1.0, 1.0, 1.0, 0.6927083134651184, 1.0, 1.0, 0.6302083134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6328125, 1.0, 0.624131977558136, 1.0, 1.0, 1.0, 0.6362847089767456, 1.0, 1.0, 1.0, 0.6328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6232638955116272, 0.625, 0.6232638955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6276041865348816, 1.0, 1.0, 1.0, 0.6293402910232544, 1.0, 0.6371527910232544, 1.0, 1.0, 0.6310763955116272, 1.0, 0.6258680820465088]

 sparsity of   [1.0, 0.7578125, 0.7578125, 1.0, 0.765625, 1.0, 0.7578125, 0.7578125, 0.765625, 1.0, 0.7578125, 0.765625, 1.0, 0.765625, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.7578125, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7578125, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.765625, 1.0, 0.7578125, 0.7578125, 0.7421875, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 0.765625, 0.7578125, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7578125, 1.0, 1.0, 1.0, 0.7421875, 1.0, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 0.7421875, 0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.7578125, 1.0, 0.7578125, 0.7578125, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 0.7421875, 0.7578125, 1.0, 0.75, 1.0, 0.7578125, 1.0, 1.0, 0.7578125, 0.7578125, 0.7578125, 0.765625, 1.0, 1.0, 1.0, 0.7578125, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.7421875, 0.765625, 1.0, 0.7578125, 1.0, 0.7578125, 1.0, 0.7578125, 0.75, 1.0, 1.0, 1.0, 0.7578125, 0.765625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.765625, 1.0, 1.0, 0.7578125, 0.765625, 0.7578125, 0.7578125, 0.7578125, 0.7578125, 1.0, 0.7421875, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 0.765625, 0.75, 0.765625, 0.75, 1.0, 0.7578125, 1.0, 0.765625, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.7578125, 1.0, 0.765625, 1.0, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 0.765625, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7578125, 1.0, 1.0, 1.0, 0.765625, 0.7578125, 0.75, 1.0, 0.7734375, 1.0, 0.7578125, 0.7578125, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 0.7578125, 1.0, 0.7578125, 0.7578125, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.75, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 0.75, 0.7578125, 0.7578125, 1.0, 0.7734375, 0.75, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 0.75, 1.0, 0.7578125, 1.0, 0.765625, 0.7578125, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 0.7578125, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 0.7578125, 0.78125, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.7578125, 1.0, 1.0, 0.765625, 0.7578125, 0.7578125, 1.0, 0.7578125, 0.7578125, 0.7578125, 1.0, 0.75, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 0.75, 0.765625, 1.0, 1.0, 1.0, 0.765625, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 0.765625, 0.7578125, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 1.0, 0.7578125, 0.7578125, 1.0, 0.7734375, 1.0, 0.7578125, 0.7734375, 1.0, 1.0, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 0.75, 0.7578125, 1.0, 0.7578125, 0.7578125, 1.0, 0.7578125, 0.7578125, 0.7578125, 0.765625, 1.0, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 0.765625, 0.765625, 0.7578125, 1.0, 0.7578125, 0.7578125, 0.765625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 0.765625, 0.75, 1.0, 1.0, 1.0, 0.7578125, 0.765625, 1.0, 1.0, 1.0, 0.7578125, 1.0, 0.765625, 1.0, 1.0, 0.765625, 1.0, 0.7578125, 0.7578125, 1.0, 1.0, 0.7578125, 1.0, 1.0, 0.75, 0.7578125, 0.7578125, 0.7578125, 0.75, 0.765625, 0.7578125, 1.0, 1.0, 0.7578125, 0.78125, 0.765625, 1.0, 1.0, 1.0, 1.0, 0.765625, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 0.765625, 1.0, 1.0, 1.0, 0.765625, 0.7578125, 0.765625, 0.7578125, 0.7578125, 0.765625, 1.0, 1.0, 0.7578125, 1.0, 1.0, 1.0, 0.7578125, 1.0, 0.7578125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7578125, 0.765625, 1.0, 1.0, 1.0, 1.0, 0.7578125, 1.0, 0.7578125, 0.7578125, 0.75, 0.7578125, 1.0, 1.0, 1.0, 1.0, 0.7578125, 1.0, 1.0, 0.7578125, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 0.0859375, 1.0, 1.0, 0.099609375, 1.0, 0.099609375, 1.0, 0.087890625, 1.0, 0.091796875, 1.0, 1.0, 1.0, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.095703125, 1.0, 1.0, 0.091796875, 1.0, 0.09375, 0.091796875, 0.0859375, 0.1015625, 1.0, 1.0, 0.09375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.091796875, 1.0, 0.091796875, 1.0, 1.0, 0.08984375, 0.095703125, 0.09375, 0.095703125, 1.0, 1.0, 1.0, 1.0, 0.091796875, 1.0, 1.0, 0.091796875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.107421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.091796875, 0.09375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 0.08984375, 1.0, 0.091796875, 1.0, 1.0, 1.0, 1.0, 0.1171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.083984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.103515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.087890625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09375, 1.0, 1.0, 0.1015625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08984375, 0.091796875, 1.0, 1.0, 1.0, 0.095703125, 1.0, 1.0, 1.0, 0.08984375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.103515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09375, 1.0, 0.09375, 1.0, 1.0, 1.0, 0.095703125, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 0.0859375, 0.08984375, 1.0, 0.1015625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.091796875, 0.095703125, 0.09375, 1.0, 0.09765625, 1.0, 1.0, 0.091796875, 1.0, 1.0, 0.09765625, 1.0, 1.0, 0.099609375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.103515625]

 sparsity of   [1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 0.7825520634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7825520634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7821180820465088, 1.0, 1.0, 1.0, 0.7829861044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7825520634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7825520634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7825520634651184, 1.0, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7821180820465088, 1.0, 1.0, 0.7825520634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7834201455116272, 1.0, 1.0, 0.7834201455116272, 0.7829861044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7821180820465088, 1.0, 0.78125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7816840410232544, 1.0, 1.0, 0.7821180820465088, 1.0, 0.7834201455116272, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.7821180820465088, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7825520634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 0.7821180820465088, 0.7829861044883728, 0.7829861044883728, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7834201455116272, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 0.87109375, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 0.87109375, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.87109375, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.87109375, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.87109375, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.87109375, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.87109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.875, 0.8671875, 1.0, 0.87109375, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 0.87109375, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.87109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 0.87109375, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.87109375, 1.0, 1.0, 0.87109375, 1.0, 0.8671875, 1.0, 0.87109375, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.875, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.87109375, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.87109375, 0.87109375, 1.0, 0.8671875, 0.8671875, 1.0, 0.8671875, 1.0, 0.875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.87109375, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 0.8671875, 1.0, 0.87109375, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.87109375, 1.0, 1.0, 1.0, 1.0, 0.87109375, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 0.8671875, 0.87109375, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 0.87109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 0.87109375, 0.8671875, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.87109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.87109375, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 0.87109375, 0.8671875, 1.0, 1.0, 0.87109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.87109375, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8828125, 1.0, 1.0, 1.0, 0.87109375, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 0.8671875, 0.8671875, 0.87109375, 1.0, 1.0, 0.8671875, 1.0, 1.0, 0.87109375, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.87109375, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 1.0, 0.87109375, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 0.87109375, 1.0, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875, 0.8671875, 1.0, 0.8671875, 0.8671875, 1.0, 1.0, 0.8671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8671875]

 sparsity of   [1.0, 1.0, 1.0, 0.18359375, 1.0, 0.095703125, 0.099609375, 0.21875, 1.0, 0.107421875, 0.10546875, 1.0, 0.1171875, 1.0, 0.099609375, 1.0, 1.0, 0.09765625, 0.103515625, 0.095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.095703125, 0.11328125, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 0.095703125, 1.0, 0.1015625, 1.0, 0.107421875, 1.0, 1.0, 1.0, 0.10546875, 0.1015625, 1.0, 1.0, 1.0, 0.095703125, 0.09375, 1.0, 0.109375, 0.1015625, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 0.185546875, 1.0, 1.0, 1.0, 0.103515625, 1.0, 1.0, 1.0, 0.099609375, 1.0, 0.11328125, 1.0, 0.09765625, 0.09765625, 1.0, 0.10546875, 0.099609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09375, 0.09765625, 1.0, 1.0, 0.087890625, 1.0, 1.0, 1.0, 0.10546875, 0.091796875, 1.0, 0.193359375, 1.0, 0.099609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09375, 1.0, 0.09375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09765625, 0.119140625, 0.08984375, 1.0, 1.0, 0.095703125, 1.0, 1.0, 1.0, 0.08984375, 0.09765625, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 0.087890625, 1.0, 1.0, 1.0, 0.099609375, 1.0, 1.0, 0.099609375, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.107421875, 0.107421875, 1.0, 0.08984375, 0.08984375, 1.0, 1.0, 1.0, 0.08984375, 1.0, 0.09375, 0.09765625, 0.130859375, 0.09765625, 1.0, 1.0, 0.087890625, 1.0, 1.0, 0.103515625, 0.099609375, 1.0, 0.09765625, 0.109375, 1.0, 0.09765625, 0.095703125, 1.0, 1.0, 0.107421875, 1.0, 0.109375, 1.0, 1.0, 1.0, 0.09765625, 1.0, 0.12890625, 0.095703125, 1.0, 0.099609375, 1.0, 1.0, 1.0, 0.09765625, 0.091796875, 1.0, 1.0, 1.0, 0.1640625, 1.0, 1.0, 0.1015625, 1.0, 1.0, 1.0, 0.091796875, 1.0, 1.0, 0.107421875, 0.095703125, 0.091796875, 0.10546875, 1.0, 0.091796875, 0.09765625, 1.0, 1.0, 0.095703125, 0.091796875, 1.0, 1.0, 1.0, 0.1015625, 1.0, 0.1015625, 1.0, 1.0, 1.0, 0.1015625, 1.0, 1.0, 1.0, 0.099609375, 0.107421875, 1.0, 0.107421875, 0.10546875, 0.091796875, 1.0, 1.0, 1.0, 1.0, 0.1015625, 1.0, 1.0, 1.0, 0.12109375, 1.0, 1.0, 0.1171875, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 0.09765625, 0.09765625, 0.107421875, 1.0, 1.0, 0.091796875, 0.091796875, 0.091796875, 1.0, 0.099609375, 0.103515625, 1.0, 0.099609375, 1.0, 1.0, 0.095703125, 1.0, 0.099609375, 1.0, 1.0, 0.09375, 1.0, 0.099609375, 0.10546875, 0.095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.134765625, 1.0, 1.0, 0.09765625, 1.0, 0.10546875, 0.095703125, 1.0, 1.0, 1.0, 1.0, 0.091796875, 0.1015625, 1.0, 1.0, 0.09375, 1.0, 1.0, 1.0, 1.0, 0.091796875, 1.0, 0.10546875, 1.0, 1.0, 0.1640625, 1.0, 0.099609375, 0.095703125, 1.0, 0.10546875, 0.103515625, 1.0, 0.109375, 1.0, 0.09375, 1.0, 1.0, 1.0, 1.0, 0.103515625, 1.0, 1.0, 1.0, 1.0, 0.08984375, 1.0, 1.0, 0.095703125, 0.09375, 1.0, 1.0, 1.0, 0.1171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 0.099609375, 1.0, 0.10546875, 0.095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09375, 0.1015625, 0.095703125, 1.0, 0.1015625, 1.0, 0.09765625, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 0.08984375, 1.0, 0.08984375, 1.0, 1.0, 1.0, 1.0, 0.099609375, 1.0, 0.099609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 0.08984375, 0.09765625, 0.107421875, 1.0, 1.0, 0.1015625, 0.1015625, 0.099609375, 1.0, 1.0, 1.0, 1.0, 0.09765625, 0.095703125, 1.0, 1.0, 0.09765625, 1.0, 0.0859375, 1.0, 1.0, 0.16015625, 0.10546875, 0.103515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.099609375, 0.095703125, 0.115234375, 0.099609375, 0.107421875, 0.103515625, 1.0, 0.103515625, 1.0, 0.09765625, 1.0, 1.0, 0.091796875, 1.0, 1.0, 0.103515625, 0.09765625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.087890625, 0.107421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11328125, 1.0, 0.09765625, 1.0, 1.0, 0.103515625, 0.103515625, 1.0, 1.0, 0.1015625, 1.0, 0.103515625, 1.0, 0.09765625, 1.0, 1.0, 0.09375, 1.0, 1.0, 1.0, 0.09765625, 1.0, 0.1015625, 1.0, 1.0, 0.107421875, 1.0, 0.1015625, 1.0, 0.10546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.087890625, 1.0, 1.0, 1.0, 0.1015625, 1.0, 0.087890625, 1.0, 1.0, 0.09765625, 0.107421875, 1.0, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.091796875, 0.09765625, 0.091796875, 0.091796875, 1.0, 0.1015625, 0.115234375, 0.0859375, 1.0, 1.0, 1.0, 0.1015625, 0.103515625, 0.1015625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 0.103515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.107421875, 1.0, 1.0, 1.0, 1.0, 0.09375, 0.103515625, 0.099609375, 0.091796875, 1.0, 1.0, 1.0, 0.09765625, 1.0, 0.109375, 1.0, 0.1015625, 0.107421875, 0.09765625, 0.095703125, 1.0, 0.095703125, 1.0, 0.107421875, 1.0, 1.0, 1.0, 0.111328125, 1.0, 1.0, 0.125, 1.0, 0.09375, 1.0, 1.0, 0.095703125, 0.099609375, 0.099609375, 0.091796875, 1.0, 1.0, 1.0, 0.109375, 0.10546875, 0.09375, 0.09765625, 1.0, 1.0, 1.0, 0.109375, 1.0, 1.0, 0.09375, 0.09765625, 0.103515625, 0.10546875, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.107421875, 0.099609375, 1.0, 1.0, 0.099609375, 1.0, 1.0, 0.095703125, 0.12109375, 1.0, 0.09765625, 0.1015625, 1.0, 0.1171875, 1.0, 1.0, 0.09765625, 0.1015625, 0.09375, 0.126953125, 1.0, 0.107421875, 0.11328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 0.11328125, 1.0, 0.1015625, 1.0, 0.115234375, 1.0, 0.107421875, 1.0, 1.0, 1.0, 1.0, 0.1015625, 0.1015625, 1.0, 0.099609375, 1.0, 0.115234375, 0.107421875, 1.0, 1.0, 0.099609375, 0.10546875, 0.095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11328125, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09375, 1.0, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 0.1015625, 1.0, 1.0, 0.103515625, 0.177734375, 0.109375, 0.091796875, 1.0, 0.115234375, 0.09375, 1.0, 1.0, 0.10546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.099609375, 0.09765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.103515625, 0.10546875, 1.0, 1.0, 1.0, 0.09375, 0.09765625, 1.0, 1.0, 1.0, 1.0, 0.087890625, 1.0, 0.10546875, 1.0, 1.0, 0.099609375, 1.0, 0.09765625, 0.09375, 1.0, 1.0, 1.0, 1.0, 0.10546875, 1.0, 1.0, 0.10546875, 0.103515625, 0.107421875, 0.099609375, 1.0, 0.09765625, 1.0, 1.0, 1.0, 0.759765625, 1.0, 1.0, 1.0, 0.15625, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 0.09375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.091796875, 0.12109375, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 0.1015625, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 0.095703125, 1.0, 0.095703125, 0.09765625, 1.0, 0.09375, 0.111328125, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 0.150390625, 0.095703125, 1.0, 1.0, 0.1015625, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 0.1015625, 1.0, 0.09765625, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.103515625, 1.0, 0.1015625, 0.099609375, 1.0, 1.0, 0.1015625, 0.1875, 1.0, 1.0, 0.09765625, 1.0, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1328125, 1.0, 1.0, 0.103515625, 1.0, 1.0, 0.095703125, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 0.13671875, 1.0, 0.1015625, 1.0, 0.087890625, 0.09375, 0.1015625, 1.0, 1.0, 0.10546875, 1.0, 1.0, 0.095703125, 1.0, 1.0, 0.095703125, 1.0, 0.095703125, 0.08984375, 1.0, 1.0, 0.09765625, 0.154296875, 1.0, 1.0, 1.0, 0.099609375, 0.09375, 1.0, 0.095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09375, 0.09765625, 0.11328125, 0.09375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.10546875, 1.0, 1.0, 1.0, 0.1015625, 0.10546875, 1.0, 1.0, 1.0, 0.099609375, 0.1015625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.099609375, 1.0, 0.109375, 1.0, 1.0, 0.099609375, 1.0, 0.15234375, 0.095703125, 1.0, 0.1796875, 1.0, 1.0, 1.0, 1.0, 0.09765625, 0.1015625, 1.0, 0.1015625, 1.0, 1.0, 0.09375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1015625, 0.09765625, 1.0, 0.111328125, 0.216796875, 1.0, 1.0, 0.087890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.607421875, 1.0, 1.0, 1.0, 1.0, 0.603515625, 1.0, 1.0, 1.0, 0.60546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6142578125, 1.0, 1.0, 1.0, 0.6123046875, 1.0, 1.0, 1.0, 0.609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.603515625, 1.0, 0.61328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.607421875, 1.0, 0.60546875, 1.0, 1.0, 0.607421875, 0.609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.609375, 1.0, 1.0, 1.0, 1.0, 0.6103515625, 1.0, 0.6123046875, 1.0, 1.0, 0.6083984375, 1.0, 0.6123046875, 1.0, 1.0, 1.0, 0.6083984375, 1.0, 1.0, 1.0, 1.0, 0.61328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6103515625, 1.0, 1.0, 1.0, 0.6162109375, 1.0, 1.0, 0.6103515625, 1.0, 1.0, 1.0, 0.6103515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6142578125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.611328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6044921875, 0.6142578125, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 0.6103515625, 1.0, 0.609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.611328125, 1.0, 0.626953125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.611328125, 1.0, 1.0, 1.0, 1.0, 0.611328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.609375, 1.0, 0.607421875, 0.6123046875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.609375, 1.0, 1.0, 0.609375, 0.6142578125, 0.6123046875, 1.0, 1.0, 0.6044921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6123046875, 1.0, 1.0, 0.61328125, 1.0, 1.0, 0.609375, 1.0, 1.0, 0.60546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6142578125, 1.0, 1.0, 0.6083984375, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.8133680820465088, 0.8138020634651184, 1.0, 1.0, 1.0, 1.0, 0.8142361044883728, 1.0, 1.0, 0.8129340410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8129340410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8129340410232544, 1.0, 1.0, 1.0, 1.0, 0.8133680820465088, 1.0, 0.8142361044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8142361044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8129340410232544, 1.0, 0.8129340410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8129340410232544, 0.8129340410232544, 1.0, 1.0, 1.0, 1.0, 0.8133680820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8111979365348816, 1.0, 1.0, 0.81640625, 0.8138020634651184, 1.0, 0.8133680820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8107638955116272, 1.0, 1.0, 0.8133680820465088, 0.8142361044883728, 0.8151041865348816, 1.0, 0.8133680820465088, 1.0, 1.0, 1.0, 0.8129340410232544, 0.8129340410232544, 1.0, 1.0, 1.0, 0.8146701455116272, 1.0, 0.8129340410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8138020634651184, 1.0, 1.0, 1.0, 0.8129340410232544, 1.0, 1.0, 1.0, 0.8151041865348816, 1.0, 1.0, 1.0, 1.0, 0.8129340410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8142361044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8138020634651184, 1.0, 1.0, 1.0, 1.0, 0.8142361044883728, 1.0, 1.0, 1.0, 0.8133680820465088, 1.0, 1.0, 1.0, 1.0, 0.8133680820465088, 1.0, 1.0, 1.0, 0.8133680820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8138020634651184, 1.0, 0.8125, 1.0, 0.8138020634651184, 0.8138020634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8133680820465088, 1.0, 1.0, 0.8125, 0.8151041865348816, 1.0, 0.8138020634651184, 1.0, 0.8142361044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8133680820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8129340410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8120659589767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8146701455116272, 0.8138020634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8129340410232544, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.796875, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.796875, 0.80078125, 0.796875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.796875, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.796875, 1.0, 1.0, 1.0, 0.796875, 0.79296875, 1.0, 1.0, 0.79296875, 0.796875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.80078125, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.796875, 0.7890625, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 0.796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.796875, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.796875, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.796875, 1.0, 0.80078125, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.796875, 0.79296875, 1.0, 1.0, 0.796875, 0.79296875, 0.796875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.796875, 1.0, 1.0, 1.0, 0.796875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 0.796875, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.796875, 0.79296875, 0.79296875, 1.0, 1.0, 0.7890625, 1.0, 0.796875, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.796875, 1.0, 0.796875, 1.0, 1.0, 0.79296875, 1.0, 0.796875, 0.796875, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.796875, 0.796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 0.796875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.796875, 0.79296875, 0.796875, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.796875, 1.0, 0.796875, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.796875, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 0.796875, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 0.796875, 1.0, 1.0, 0.796875, 1.0, 0.796875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.796875, 1.0, 0.80078125, 1.0, 0.796875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.796875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.80078125, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 0.796875, 1.0, 1.0, 1.0, 0.796875, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.796875, 1.0, 1.0, 0.79296875, 0.796875, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.796875, 0.79296875, 1.0, 1.0, 1.0, 0.796875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.8046875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.80078125, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.796875, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.796875, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.80078125, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 0.796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.796875, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.796875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.796875, 1.0, 1.0, 0.79296875, 0.79296875, 0.80078125, 0.79296875, 0.796875, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.796875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.796875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.796875, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.796875, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.84765625, 1.0, 0.796875, 0.79296875, 1.0, 1.0, 1.0, 0.796875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.796875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.796875, 1.0, 0.79296875, 0.796875, 1.0, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.796875, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.79296875, 0.79296875, 1.0, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.5244140625, 1.0, 1.0, 1.0, 0.5263671875, 1.0, 1.0, 0.529296875, 0.529296875, 1.0, 1.0, 0.51953125, 1.0, 0.533203125, 1.0, 1.0, 1.0, 0.529296875, 0.5263671875, 1.0, 1.0, 1.0, 0.5283203125, 1.0, 0.5283203125, 1.0, 1.0, 1.0, 0.5283203125, 0.52734375, 1.0, 1.0, 0.529296875, 1.0, 1.0, 0.5322265625, 0.529296875, 0.533203125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5224609375, 0.52734375, 0.533203125, 0.53125, 0.53515625, 1.0, 0.517578125, 0.5341796875, 1.0, 0.5263671875, 0.5244140625, 0.5322265625, 0.5341796875, 0.53125, 0.525390625, 1.0, 0.5302734375, 1.0, 0.52734375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.52734375, 1.0, 0.5244140625, 0.53125, 1.0, 1.0, 0.5322265625, 1.0, 0.533203125, 0.5263671875, 0.5234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5244140625, 0.53125, 0.5283203125, 0.5263671875, 1.0, 1.0, 0.52734375, 1.0, 1.0, 0.5224609375, 1.0, 1.0, 0.5302734375, 0.5341796875, 1.0, 1.0, 1.0, 0.53125, 0.5234375, 0.5263671875, 1.0, 0.525390625, 0.5263671875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.53125, 0.5283203125, 1.0, 1.0, 0.5283203125, 0.5263671875, 1.0, 0.5263671875, 1.0, 0.5263671875, 1.0, 0.5302734375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.529296875, 1.0, 0.53125, 1.0, 1.0, 1.0, 0.5341796875, 1.0, 0.5302734375, 1.0, 0.5322265625, 0.525390625, 0.525390625, 1.0, 0.5166015625, 0.5263671875, 0.5302734375, 1.0, 1.0, 1.0, 0.5234375, 0.53515625, 1.0, 1.0, 1.0, 0.5302734375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.533203125, 1.0, 1.0, 1.0, 0.5263671875, 0.53125, 1.0, 1.0, 0.5263671875, 1.0, 1.0, 1.0, 1.0, 0.5283203125, 0.5302734375, 0.53125, 0.5234375, 0.529296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5322265625, 0.52734375, 0.5263671875, 1.0, 1.0, 0.5283203125, 1.0, 1.0, 1.0, 1.0, 0.5234375, 1.0, 0.5263671875, 0.5224609375, 0.52734375, 1.0, 0.5439453125, 1.0, 0.5283203125, 0.525390625, 1.0, 0.521484375, 1.0, 0.53125, 0.5234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5283203125, 1.0, 1.0, 1.0, 0.5224609375, 1.0, 1.0, 0.5224609375, 1.0, 1.0, 0.5263671875, 0.5283203125, 1.0, 0.5283203125, 1.0, 0.5302734375, 1.0, 0.5283203125, 0.52734375, 0.529296875, 0.5234375, 0.5341796875, 1.0, 0.521484375, 0.5205078125, 1.0, 0.517578125, 0.5185546875, 1.0, 0.5263671875, 1.0, 0.53125, 1.0, 0.5244140625, 1.0, 1.0, 0.525390625, 1.0, 0.52734375, 0.5322265625, 0.533203125]

 sparsity of   [0.5451388955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 0.54296875, 1.0, 1.0, 1.0, 0.5464409589767456, 0.5447048544883728, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5442708134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5447048544883728, 0.5451388955116272, 1.0, 0.5455729365348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5451388955116272, 1.0, 0.5447048544883728, 0.5438368320465088, 1.0, 0.5455729365348816, 0.5442708134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5447048544883728, 1.0, 1.0, 0.5442708134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5455729365348816, 1.0, 0.5442708134651184, 0.546006977558136, 0.5451388955116272, 1.0, 1.0, 1.0, 0.5455729365348816, 1.0, 0.5451388955116272, 0.5438368320465088, 0.5451388955116272, 1.0, 1.0, 0.5451388955116272, 1.0, 0.5438368320465088, 1.0, 1.0, 0.5455729365348816, 1.0, 1.0, 0.5438368320465088, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5447048544883728, 1.0, 1.0, 0.5438368320465088, 1.0, 1.0, 0.5438368320465088, 1.0, 0.5442708134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5447048544883728, 0.546875, 0.5442708134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5438368320465088, 0.5447048544883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5451388955116272, 1.0, 1.0, 0.546006977558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5455729365348816, 1.0, 0.5438368320465088, 1.0, 0.546875, 1.0, 0.5451388955116272, 1.0, 1.0, 1.0, 0.5438368320465088, 1.0, 1.0, 1.0, 1.0, 0.5442708134651184, 1.0, 0.5438368320465088, 1.0, 1.0, 1.0, 1.0, 0.5451388955116272, 0.5451388955116272, 1.0, 1.0, 0.5451388955116272, 1.0, 1.0, 1.0, 1.0, 0.5447048544883728, 1.0, 1.0, 1.0, 0.5451388955116272, 0.5464409589767456, 1.0, 1.0, 0.5451388955116272, 1.0, 1.0, 1.0, 1.0, 0.5447048544883728, 1.0, 0.5455729365348816, 1.0, 1.0, 1.0, 1.0, 0.5434027910232544, 0.54296875, 1.0, 0.5442708134651184, 1.0, 1.0, 0.546006977558136, 1.0, 0.5438368320465088, 0.5451388955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5447048544883728, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5451388955116272, 1.0, 0.5447048544883728, 1.0, 1.0, 0.5447048544883728, 1.0, 1.0, 1.0, 0.5442708134651184, 1.0, 1.0, 1.0, 0.5442708134651184, 1.0, 1.0, 0.546006977558136, 1.0, 1.0, 1.0, 1.0, 0.5442708134651184, 1.0, 1.0, 1.0, 0.5442708134651184, 1.0, 0.5451388955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.546006977558136, 1.0, 1.0, 1.0, 0.5447048544883728, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.7265625, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.72265625, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 0.72265625, 0.71875, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.72265625, 0.72265625, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.7265625, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.7265625, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.7265625, 0.71875, 0.7265625, 1.0, 1.0, 0.71875, 0.73046875, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 0.7265625, 1.0, 1.0, 0.71875, 1.0, 0.71875, 0.71875, 0.7265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 0.7265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.71875, 1.0, 0.72265625, 0.71875, 1.0, 0.72265625, 1.0, 0.71875, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.72265625, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.72265625, 0.71875, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 0.73046875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 0.72265625, 0.72265625, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.72265625, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 0.71875, 0.71875, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 0.7265625, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.7265625, 0.71875, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.72265625, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.72265625, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.71875, 1.0, 0.72265625, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 0.72265625, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.71875, 0.72265625, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 0.71875, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.71875, 1.0, 0.71875, 0.71875, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.72265625, 1.0, 1.0, 0.73046875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 0.72265625, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.72265625, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.51953125, 1.0, 0.5224609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5205078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.513671875, 1.0, 1.0, 1.0, 0.5146484375, 1.0, 1.0, 0.513671875, 0.5185546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.51171875, 1.0, 1.0, 1.0, 0.5341796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5322265625, 1.0, 1.0, 0.521484375, 1.0, 1.0, 1.0, 0.5302734375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.51171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.572265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.513671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5126953125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5146484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.525390625, 0.5322265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5146484375, 1.0, 1.0, 1.0, 0.53515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.517578125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.897569477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9006076455116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.90234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.897569477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8984375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9079861044883728, 0.9001736044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8971354365348816, 1.0, 0.8997395634651184, 1.0, 1.0, 1.0, 0.8993055820465088, 0.9001736044883728, 1.0, 1.0, 1.0, 0.905381977558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8993055820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 0.94140625, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 0.94140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5107421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.50390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.509765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9800347089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 0.5068359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5087890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.509765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5146484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5166015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5068359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5107421875, 0.505859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5107421875, 1.0, 1.0, 0.5078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5078125, 1.0, 1.0, 0.51171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.513671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.51171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5048828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.51171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5166015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5068359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5166015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9618055820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.990234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5068359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5048828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5166015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.51171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.50390625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.501953125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.51953125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.54296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.517578125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5146484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.50390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.517578125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5224609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.517578125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.513671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5498046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5185546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5166015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.51171875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5087890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.517578125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5146484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5078125, 1.0, 1.0, 1.0, 1.0, 0.521484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5107421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5146484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5048828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5126953125, 1.0, 1.0, 0.5087890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.509765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.509765625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5087890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5166015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98095703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9814453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9814453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9814453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9814453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9814453125, 0.98193359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9817708134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9802517294883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9832899570465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.983506977558136, 1.0, 1.0, 1.0, 1.0, 0.982421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9774305820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9780815839767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.978515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9819878339767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9809027910232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9822048544883728, 1.0, 1.0, 1.0, 0.982421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.970703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.970703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.970703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.81005859375, 0.80126953125, 0.79345703125, 0.798828125, 0.7978515625, 0.7978515625, 0.8017578125, 0.7998046875, 0.81640625, 0.81494140625, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125]

Total parameter pruned: 22750820.00354965 (unstructured) 21489810 (structured)

Test: [0/79]	Time 0.157 (0.157)	Loss 0.3500 (0.3500) ([0.229]+[0.121])	Prec@1 93.750 (93.750)
 * Prec@1 93.800

 Elapsed time for training  3:52:37.892868

 sparsity of   [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]

 sparsity of   [0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]

 sparsity of   [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.515625, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]

 sparsity of   [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]

 sparsity of   [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]

 sparsity of   [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]

 sparsity of   [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]

 sparsity of   [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]

 sparsity of   [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]

 sparsity of   [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5703125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]

 sparsity of   [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]

 sparsity of   [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6328125, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5546875, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5703125, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5859375, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6328125, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]

 sparsity of   [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.85546875, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]

 sparsity of   [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6796875, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.66796875, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.68359375, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.67578125, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.67578125, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.59375, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6640625, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.53125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.04296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.04296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.58203125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0234375, 1.0, 0.56640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5390625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.56640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.54296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.54296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.421875, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.05078125, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.00390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.81005859375, 0.80126953125, 0.79345703125, 0.798828125, 0.7978515625, 0.7978515625, 0.8017578125, 0.7998046875, 0.81640625, 0.81494140625, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125, 0.9453125]
Total parameter pruned: 21684063.0 (unstructured) 21489810 (structured)
Test: [0/79]	Time 0.133 (0.133)	Loss 0.2289 (0.2289) ([0.229]+[0.000])	Prec@1 93.750 (93.750)
 * Prec@1 93.800
Best accuracy:  0
