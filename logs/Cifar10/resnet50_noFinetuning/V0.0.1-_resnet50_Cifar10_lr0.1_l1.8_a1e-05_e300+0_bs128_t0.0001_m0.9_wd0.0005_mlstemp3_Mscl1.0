V0.0.1-_resnet50_Cifar10_lr0.1_l1.8_a1e-05_e300+0_bs128_t0.0001_m0.9_wd0.0005_mlstemp3_Mscl1.0
Files already downloaded and verified
M values:
 {Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.5254763960838318, Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.24196940660476685, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.15759095549583435, Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.13501641154289246, Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.3461485505104065, Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.17473100125789642, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.21617008745670319, Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.14946585893630981, Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.09060623496770859, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.08498729020357132, Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.11497705429792404, Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.11804789304733276, Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False): 0.08379501849412918, Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.1424030363559723, Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False): 0.19753389060497284, Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.16684924066066742, Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.22829987108707428, Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.12801074981689453, Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.09603530913591385, Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.06901206821203232, Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.12272872775793076, Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.0835055485367775, Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.07954221963882446, Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.12703275680541992, Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.19747452437877655, Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False): 0.15407174825668335, Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.1602816879749298, Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False): 0.10645194351673126, Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.10600411146879196, Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.13483507931232452, Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.21709460020065308, Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.11353497207164764, Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.0660422295331955, Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.10686782747507095, Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.06808818876743317, Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.05323619768023491, Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.08759226649999619, Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.07965513318777084, Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.06643471866846085, Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.12164679169654846, Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.09185265004634857, Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.06330689787864685, Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.1110600158572197, Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.12582343816757202, Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False): 0.09035182744264603, Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.07410024106502533, Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False): 0.07018566876649857, Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.0687103122472763, Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.04065759852528572, Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.03755198046565056, Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.04725675657391548, Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.045549724251031876, Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.06192586570978165, Linear(in_features=2048, out_features=100, bias=True): 0.44340774416923523}
current lr 1.00000e-01
Grad=  tensor(7117.2544, device='cuda:0')
Epoch: [0][0/391]	Time 0.253 (0.253)	Data 0.133 (0.133)	Loss 6.8251 (6.8251) ([4.663]+[2.162])	Prec@1 3.906 (3.906)
Epoch: [0][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 5.3137 (7.7489) ([2.378]+[2.935])	Prec@1 8.594 (10.326)
Epoch: [0][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 4.9095 (6.4524) ([2.283]+[2.627])	Prec@1 13.281 (10.304)
Epoch: [0][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 4.4186 (5.8768) ([2.077]+[2.341])	Prec@1 21.094 (11.890)
Test: [0/79]	Time 0.164 (0.164)	Loss 5.2762 (5.2762) ([3.170]+[2.106])	Prec@1 13.281 (13.281)
 * Prec@1 11.560
current lr 1.00000e-01
Grad=  tensor(0.3691, device='cuda:0')
Epoch: [1][0/391]	Time 0.258 (0.258)	Data 0.132 (0.132)	Loss 4.2471 (4.2471) ([2.141]+[2.106])	Prec@1 14.062 (14.062)
Epoch: [1][100/391]	Time 0.114 (0.114)	Data 0.000 (0.001)	Loss 3.9017 (4.0343) ([2.038]+[1.864])	Prec@1 18.750 (22.030)
Epoch: [1][200/391]	Time 0.113 (0.114)	Data 0.000 (0.001)	Loss 3.5304 (3.8715) ([1.889]+[1.641])	Prec@1 30.469 (23.884)
Epoch: [1][300/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 3.2725 (3.7159) ([1.830]+[1.442])	Prec@1 32.812 (26.012)
Test: [0/79]	Time 0.168 (0.168)	Loss 3.0204 (3.0204) ([1.713]+[1.307])	Prec@1 39.844 (39.844)
 * Prec@1 34.790
current lr 1.00000e-01
Grad=  tensor(0.4526, device='cuda:0')
Epoch: [2][0/391]	Time 0.254 (0.254)	Data 0.133 (0.133)	Loss 3.1416 (3.1416) ([1.834]+[1.307])	Prec@1 28.125 (28.125)
Epoch: [2][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 2.9554 (3.0191) ([1.794]+[1.161])	Prec@1 35.938 (33.687)
Epoch: [2][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 2.9081 (2.9627) ([1.754]+[1.154])	Prec@1 37.500 (34.255)
Epoch: [2][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 2.6566 (2.9042) ([1.643]+[1.014])	Prec@1 37.500 (35.120)
Test: [0/79]	Time 0.158 (0.158)	Loss 2.6533 (2.6533) ([1.750]+[0.903])	Prec@1 32.812 (32.812)
 * Prec@1 35.940
current lr 1.00000e-01
Grad=  tensor(0.5300, device='cuda:0')
Epoch: [3][0/391]	Time 0.252 (0.252)	Data 0.132 (0.132)	Loss 2.5588 (2.5588) ([1.655]+[0.903])	Prec@1 40.625 (40.625)
Epoch: [3][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 2.5671 (2.5410) ([1.692]+[0.875])	Prec@1 32.812 (38.614)
Epoch: [3][200/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 2.3232 (2.4789) ([1.559]+[0.765])	Prec@1 41.406 (39.377)
Epoch: [3][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 2.2586 (2.4100) ([1.563]+[0.696])	Prec@1 46.875 (40.609)
Test: [0/79]	Time 0.155 (0.155)	Loss 2.2209 (2.2209) ([1.584]+[0.637])	Prec@1 37.500 (37.500)
 * Prec@1 42.540
current lr 1.00000e-01
Grad=  tensor(0.8301, device='cuda:0')
Epoch: [4][0/391]	Time 0.253 (0.253)	Data 0.133 (0.133)	Loss 2.2435 (2.2435) ([1.607]+[0.637])	Prec@1 42.188 (42.188)
Epoch: [4][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 2.1320 (2.0537) ([1.533]+[0.599])	Prec@1 45.312 (47.486)
Epoch: [4][200/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 1.8963 (2.0144) ([1.347]+[0.549])	Prec@1 53.906 (47.862)
Epoch: [4][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 1.9123 (1.9862) ([1.368]+[0.544])	Prec@1 49.219 (48.308)
Test: [0/79]	Time 0.157 (0.157)	Loss 1.8714 (1.8714) ([1.370]+[0.502])	Prec@1 50.000 (50.000)
 * Prec@1 49.420
current lr 1.00000e-01
Grad=  tensor(1.3511, device='cuda:0')
Epoch: [5][0/391]	Time 0.251 (0.251)	Data 0.133 (0.133)	Loss 1.9250 (1.9250) ([1.423]+[0.502])	Prec@1 45.312 (45.312)
Epoch: [5][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 1.7900 (1.7830) ([1.319]+[0.471])	Prec@1 52.344 (53.403)
Epoch: [5][200/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 1.6975 (1.7473) ([1.252]+[0.445])	Prec@1 53.125 (54.042)
Epoch: [5][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 1.5851 (1.7111) ([1.165]+[0.420])	Prec@1 56.250 (54.745)
Test: [0/79]	Time 0.158 (0.158)	Loss 1.4991 (1.4991) ([1.089]+[0.410])	Prec@1 62.500 (62.500)
 * Prec@1 60.060
current lr 1.00000e-01
Grad=  tensor(1.3183, device='cuda:0')
Epoch: [6][0/391]	Time 0.249 (0.249)	Data 0.129 (0.129)	Loss 1.5502 (1.5502) ([1.140]+[0.410])	Prec@1 57.031 (57.031)
Epoch: [6][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 1.4404 (1.5515) ([1.038]+[0.402])	Prec@1 60.156 (58.478)
Epoch: [6][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 1.5217 (1.5417) ([1.137]+[0.385])	Prec@1 58.594 (58.629)
Epoch: [6][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 1.6890 (1.5171) ([1.308]+[0.381])	Prec@1 56.250 (59.481)
Test: [0/79]	Time 0.157 (0.157)	Loss 1.5469 (1.5469) ([1.172]+[0.375])	Prec@1 55.469 (55.469)
 * Prec@1 55.330
current lr 1.00000e-01
Grad=  tensor(2.5763, device='cuda:0')
Epoch: [7][0/391]	Time 0.248 (0.248)	Data 0.129 (0.129)	Loss 1.4826 (1.4826) ([1.107]+[0.375])	Prec@1 57.812 (57.812)
Epoch: [7][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 1.2697 (1.4182) ([0.909]+[0.361])	Prec@1 65.625 (62.314)
Epoch: [7][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 1.3759 (1.3815) ([1.026]+[0.350])	Prec@1 61.719 (63.262)
Epoch: [7][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 1.3000 (1.3696) ([0.951]+[0.348])	Prec@1 64.062 (63.663)
Test: [0/79]	Time 0.160 (0.160)	Loss 1.5555 (1.5555) ([1.206]+[0.350])	Prec@1 55.469 (55.469)
 * Prec@1 59.970
current lr 1.00000e-01
Grad=  tensor(1.3455, device='cuda:0')
Epoch: [8][0/391]	Time 0.249 (0.249)	Data 0.129 (0.129)	Loss 1.2509 (1.2509) ([0.901]+[0.350])	Prec@1 68.750 (68.750)
Epoch: [8][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 1.3244 (1.2898) ([0.985]+[0.340])	Prec@1 61.719 (66.762)
Epoch: [8][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 1.2636 (1.2688) ([0.930]+[0.333])	Prec@1 66.406 (67.215)
Epoch: [8][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 1.2924 (1.2582) ([0.968]+[0.324])	Prec@1 64.844 (67.481)
Test: [0/79]	Time 0.160 (0.160)	Loss 1.3401 (1.3401) ([1.012]+[0.328])	Prec@1 60.938 (60.938)
 * Prec@1 62.300
current lr 1.00000e-01
Grad=  tensor(1.5987, device='cuda:0')
Epoch: [9][0/391]	Time 0.252 (0.252)	Data 0.132 (0.132)	Loss 1.2331 (1.2331) ([0.905]+[0.328])	Prec@1 71.875 (71.875)
Epoch: [9][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 1.1834 (1.2028) ([0.862]+[0.322])	Prec@1 71.875 (69.276)
Epoch: [9][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 1.1634 (1.1898) ([0.851]+[0.313])	Prec@1 69.531 (69.446)
Epoch: [9][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.9385 (1.1790) ([0.629]+[0.309])	Prec@1 77.344 (69.653)
Test: [0/79]	Time 0.158 (0.158)	Loss 1.6184 (1.6184) ([1.308]+[0.311])	Prec@1 60.938 (60.938)
 * Prec@1 55.260
current lr 1.00000e-01
Grad=  tensor(1.8739, device='cuda:0')
Epoch: [10][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 1.3430 (1.3430) ([1.032]+[0.311])	Prec@1 64.062 (64.062)
Epoch: [10][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 1.0737 (1.1095) ([0.770]+[0.304])	Prec@1 69.531 (71.759)
Epoch: [10][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 1.2667 (1.1226) ([0.964]+[0.303])	Prec@1 67.188 (71.296)
Epoch: [10][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 1.1703 (1.1223) ([0.867]+[0.304])	Prec@1 71.094 (71.307)
Test: [0/79]	Time 0.164 (0.164)	Loss 1.3744 (1.3744) ([1.074]+[0.300])	Prec@1 62.500 (62.500)
 * Prec@1 61.480
current lr 1.00000e-01
Grad=  tensor(1.6429, device='cuda:0')
Epoch: [11][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.9972 (0.9972) ([0.697]+[0.300])	Prec@1 76.562 (76.562)
Epoch: [11][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.9520 (1.0788) ([0.653]+[0.299])	Prec@1 77.344 (72.587)
Epoch: [11][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 1.0118 (1.0848) ([0.715]+[0.296])	Prec@1 75.000 (72.625)
Epoch: [11][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 1.0264 (1.0799) ([0.729]+[0.297])	Prec@1 73.438 (72.807)
Test: [0/79]	Time 0.162 (0.162)	Loss 1.1941 (1.1941) ([0.903]+[0.291])	Prec@1 72.656 (72.656)
 * Prec@1 66.500
current lr 1.00000e-01
Grad=  tensor(2.7269, device='cuda:0')
Epoch: [12][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 1.1177 (1.1177) ([0.826]+[0.291])	Prec@1 71.094 (71.094)
Epoch: [12][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 1.1773 (1.0297) ([0.890]+[0.288])	Prec@1 69.531 (74.714)
Epoch: [12][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 1.1743 (1.0273) ([0.886]+[0.288])	Prec@1 67.969 (74.541)
Epoch: [12][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 1.0958 (1.0269) ([0.813]+[0.282])	Prec@1 69.531 (74.541)
Test: [0/79]	Time 0.161 (0.161)	Loss 1.2121 (1.2121) ([0.929]+[0.283])	Prec@1 64.844 (64.844)
 * Prec@1 67.920
current lr 1.00000e-01
Grad=  tensor(2.1190, device='cuda:0')
Epoch: [13][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 1.0869 (1.0869) ([0.804]+[0.283])	Prec@1 71.875 (71.875)
Epoch: [13][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 1.0130 (0.9937) ([0.735]+[0.278])	Prec@1 71.094 (75.735)
Epoch: [13][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 1.0087 (1.0083) ([0.733]+[0.276])	Prec@1 73.438 (75.058)
Epoch: [13][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8781 (1.0001) ([0.605]+[0.273])	Prec@1 77.344 (75.151)
Test: [0/79]	Time 0.156 (0.156)	Loss 0.9462 (0.9462) ([0.674]+[0.272])	Prec@1 77.344 (77.344)
 * Prec@1 72.940
current lr 1.00000e-01
Grad=  tensor(1.3787, device='cuda:0')
Epoch: [14][0/391]	Time 0.253 (0.253)	Data 0.132 (0.132)	Loss 0.9188 (0.9188) ([0.647]+[0.272])	Prec@1 78.906 (78.906)
Epoch: [14][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.9276 (0.9625) ([0.653]+[0.275])	Prec@1 78.125 (76.114)
Epoch: [14][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.9780 (0.9666) ([0.710]+[0.268])	Prec@1 76.562 (76.189)
Epoch: [14][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.9526 (0.9663) ([0.686]+[0.266])	Prec@1 78.125 (76.085)
Test: [0/79]	Time 0.158 (0.158)	Loss 1.2201 (1.2201) ([0.958]+[0.262])	Prec@1 64.844 (64.844)
 * Prec@1 69.800
current lr 1.00000e-01
Grad=  tensor(2.0813, device='cuda:0')
Epoch: [15][0/391]	Time 0.244 (0.244)	Data 0.123 (0.123)	Loss 0.9468 (0.9468) ([0.685]+[0.262])	Prec@1 72.656 (72.656)
Epoch: [15][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8833 (0.9451) ([0.617]+[0.266])	Prec@1 76.562 (76.547)
Epoch: [15][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.9984 (0.9508) ([0.736]+[0.262])	Prec@1 78.906 (76.224)
Epoch: [15][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7863 (0.9485) ([0.528]+[0.258])	Prec@1 81.250 (76.329)
Test: [0/79]	Time 0.152 (0.152)	Loss 1.1871 (1.1871) ([0.933]+[0.254])	Prec@1 64.844 (64.844)
 * Prec@1 67.460
current lr 1.00000e-01
Grad=  tensor(1.5004, device='cuda:0')
Epoch: [16][0/391]	Time 0.249 (0.249)	Data 0.129 (0.129)	Loss 0.8759 (0.8759) ([0.622]+[0.254])	Prec@1 76.562 (76.562)
Epoch: [16][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7625 (0.9101) ([0.510]+[0.252])	Prec@1 78.125 (77.119)
Epoch: [16][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8206 (0.9203) ([0.570]+[0.250])	Prec@1 81.250 (76.854)
Epoch: [16][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 1.0623 (0.9110) ([0.814]+[0.248])	Prec@1 74.219 (77.224)
Test: [0/79]	Time 0.160 (0.160)	Loss 1.0600 (1.0600) ([0.812]+[0.248])	Prec@1 72.656 (72.656)
 * Prec@1 73.280
current lr 1.00000e-01
Grad=  tensor(1.6523, device='cuda:0')
Epoch: [17][0/391]	Time 0.250 (0.250)	Data 0.130 (0.130)	Loss 0.8261 (0.8261) ([0.578]+[0.248])	Prec@1 81.250 (81.250)
Epoch: [17][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8590 (0.8941) ([0.610]+[0.249])	Prec@1 80.469 (77.669)
Epoch: [17][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 1.0009 (0.8954) ([0.753]+[0.248])	Prec@1 78.906 (77.752)
Epoch: [17][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.9644 (0.8997) ([0.717]+[0.247])	Prec@1 75.000 (77.606)
Test: [0/79]	Time 0.158 (0.158)	Loss 0.9513 (0.9513) ([0.706]+[0.245])	Prec@1 73.438 (73.438)
 * Prec@1 73.690
current lr 1.00000e-01
Grad=  tensor(1.6365, device='cuda:0')
Epoch: [18][0/391]	Time 0.252 (0.252)	Data 0.132 (0.132)	Loss 0.8073 (0.8073) ([0.562]+[0.245])	Prec@1 81.250 (81.250)
Epoch: [18][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 1.1292 (0.8863) ([0.884]+[0.245])	Prec@1 75.000 (77.893)
Epoch: [18][200/391]	Time 0.114 (0.111)	Data 0.000 (0.001)	Loss 0.8709 (0.8852) ([0.627]+[0.244])	Prec@1 78.125 (77.872)
Epoch: [18][300/391]	Time 0.113 (0.112)	Data 0.000 (0.001)	Loss 0.8300 (0.8776) ([0.586]+[0.244])	Prec@1 80.469 (78.068)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.8468 (0.8468) ([0.604]+[0.243])	Prec@1 80.469 (80.469)
 * Prec@1 74.380
current lr 1.00000e-01
Grad=  tensor(1.3604, device='cuda:0')
Epoch: [19][0/391]	Time 0.261 (0.261)	Data 0.138 (0.138)	Loss 0.8106 (0.8106) ([0.568]+[0.243])	Prec@1 85.156 (85.156)
Epoch: [19][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.8159 (0.8637) ([0.572]+[0.244])	Prec@1 78.906 (78.311)
Epoch: [19][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.9730 (0.8833) ([0.729]+[0.244])	Prec@1 73.438 (77.748)
Epoch: [19][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8850 (0.8781) ([0.642]+[0.243])	Prec@1 72.656 (78.006)
Test: [0/79]	Time 0.161 (0.161)	Loss 1.6177 (1.6177) ([1.376]+[0.242])	Prec@1 60.938 (60.938)
 * Prec@1 62.040
current lr 1.00000e-01
Grad=  tensor(1.4594, device='cuda:0')
Epoch: [20][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.7909 (0.7909) ([0.549]+[0.242])	Prec@1 78.906 (78.906)
Epoch: [20][100/391]	Time 0.113 (0.113)	Data 0.000 (0.001)	Loss 0.8063 (0.8505) ([0.565]+[0.242])	Prec@1 80.469 (78.798)
Epoch: [20][200/391]	Time 0.113 (0.113)	Data 0.000 (0.001)	Loss 0.7897 (0.8635) ([0.548]+[0.242])	Prec@1 84.375 (78.762)
Epoch: [20][300/391]	Time 0.115 (0.113)	Data 0.000 (0.001)	Loss 0.7767 (0.8640) ([0.535]+[0.242])	Prec@1 82.812 (78.704)
Test: [0/79]	Time 0.171 (0.171)	Loss 0.8053 (0.8053) ([0.565]+[0.240])	Prec@1 75.781 (75.781)
 * Prec@1 76.400
current lr 1.00000e-01
Grad=  tensor(1.5993, device='cuda:0')
Epoch: [21][0/391]	Time 0.263 (0.263)	Data 0.139 (0.139)	Loss 0.8072 (0.8072) ([0.567]+[0.240])	Prec@1 77.344 (77.344)
Epoch: [21][100/391]	Time 0.112 (0.113)	Data 0.000 (0.001)	Loss 0.8438 (0.8491) ([0.604]+[0.240])	Prec@1 75.781 (78.953)
Epoch: [21][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 1.0037 (0.8579) ([0.764]+[0.240])	Prec@1 75.000 (78.774)
Epoch: [21][300/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.8212 (0.8609) ([0.581]+[0.240])	Prec@1 79.688 (78.745)
Test: [0/79]	Time 0.165 (0.165)	Loss 1.1609 (1.1609) ([0.922]+[0.239])	Prec@1 72.656 (72.656)
 * Prec@1 68.710
current lr 1.00000e-01
Grad=  tensor(1.9863, device='cuda:0')
Epoch: [22][0/391]	Time 0.279 (0.279)	Data 0.154 (0.154)	Loss 0.8198 (0.8198) ([0.581]+[0.239])	Prec@1 78.906 (78.906)
Epoch: [22][100/391]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.8774 (0.8536) ([0.638]+[0.239])	Prec@1 78.125 (78.968)
Epoch: [22][200/391]	Time 0.113 (0.114)	Data 0.000 (0.001)	Loss 0.8605 (0.8555) ([0.621]+[0.240])	Prec@1 82.031 (78.863)
Epoch: [22][300/391]	Time 0.114 (0.114)	Data 0.000 (0.001)	Loss 0.8261 (0.8546) ([0.587]+[0.240])	Prec@1 78.125 (78.950)
Test: [0/79]	Time 0.181 (0.181)	Loss 1.2082 (1.2082) ([0.969]+[0.239])	Prec@1 71.875 (71.875)
 * Prec@1 69.530
current lr 1.00000e-01
Grad=  tensor(2.0545, device='cuda:0')
Epoch: [23][0/391]	Time 0.270 (0.270)	Data 0.148 (0.148)	Loss 0.9376 (0.9376) ([0.699]+[0.239])	Prec@1 77.344 (77.344)
Epoch: [23][100/391]	Time 0.111 (0.113)	Data 0.000 (0.002)	Loss 0.7889 (0.8335) ([0.550]+[0.239])	Prec@1 79.688 (79.285)
Epoch: [23][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8384 (0.8415) ([0.601]+[0.237])	Prec@1 78.906 (79.194)
Epoch: [23][300/391]	Time 0.114 (0.113)	Data 0.000 (0.001)	Loss 0.8045 (0.8397) ([0.568]+[0.237])	Prec@1 85.156 (79.368)
Test: [0/79]	Time 0.185 (0.185)	Loss 1.1363 (1.1363) ([0.899]+[0.237])	Prec@1 74.219 (74.219)
 * Prec@1 70.280
current lr 1.00000e-01
Grad=  tensor(2.2069, device='cuda:0')
Epoch: [24][0/391]	Time 0.261 (0.261)	Data 0.138 (0.138)	Loss 0.9659 (0.9659) ([0.729]+[0.237])	Prec@1 75.000 (75.000)
Epoch: [24][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.7871 (0.8062) ([0.550]+[0.237])	Prec@1 78.125 (80.438)
Epoch: [24][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.8049 (0.8219) ([0.568]+[0.237])	Prec@1 80.469 (79.742)
Epoch: [24][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7934 (0.8320) ([0.556]+[0.237])	Prec@1 83.594 (79.524)
Test: [0/79]	Time 0.165 (0.165)	Loss 1.1752 (1.1752) ([0.939]+[0.236])	Prec@1 67.969 (67.969)
 * Prec@1 70.660
current lr 1.00000e-01
Grad=  tensor(2.4650, device='cuda:0')
Epoch: [25][0/391]	Time 0.253 (0.253)	Data 0.131 (0.131)	Loss 0.8580 (0.8580) ([0.622]+[0.236])	Prec@1 73.438 (73.438)
Epoch: [25][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7350 (0.8213) ([0.499]+[0.236])	Prec@1 84.375 (79.811)
Epoch: [25][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6796 (0.8219) ([0.444]+[0.236])	Prec@1 84.375 (79.847)
Epoch: [25][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7714 (0.8214) ([0.535]+[0.236])	Prec@1 82.812 (79.739)
Test: [0/79]	Time 0.183 (0.183)	Loss 0.9365 (0.9365) ([0.701]+[0.236])	Prec@1 73.438 (73.438)
 * Prec@1 75.450
current lr 1.00000e-01
Grad=  tensor(2.2581, device='cuda:0')
Epoch: [26][0/391]	Time 0.275 (0.275)	Data 0.152 (0.152)	Loss 0.7903 (0.7903) ([0.555]+[0.236])	Prec@1 80.469 (80.469)
Epoch: [26][100/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.8013 (0.8100) ([0.566]+[0.235])	Prec@1 83.594 (80.067)
Epoch: [26][200/391]	Time 0.114 (0.115)	Data 0.000 (0.001)	Loss 0.7761 (0.8086) ([0.541]+[0.236])	Prec@1 82.031 (80.313)
Epoch: [26][300/391]	Time 0.114 (0.114)	Data 0.000 (0.001)	Loss 0.7193 (0.8156) ([0.483]+[0.236])	Prec@1 84.375 (80.274)
Test: [0/79]	Time 0.177 (0.177)	Loss 1.1300 (1.1300) ([0.894]+[0.236])	Prec@1 70.312 (70.312)
 * Prec@1 71.510
current lr 1.00000e-01
Grad=  tensor(1.9979, device='cuda:0')
Epoch: [27][0/391]	Time 0.272 (0.272)	Data 0.149 (0.149)	Loss 0.8288 (0.8288) ([0.593]+[0.236])	Prec@1 76.562 (76.562)
Epoch: [27][100/391]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.8381 (0.8133) ([0.603]+[0.236])	Prec@1 76.562 (80.028)
Epoch: [27][200/391]	Time 0.114 (0.115)	Data 0.000 (0.001)	Loss 1.0008 (0.8064) ([0.765]+[0.236])	Prec@1 75.781 (80.189)
Epoch: [27][300/391]	Time 0.114 (0.114)	Data 0.000 (0.001)	Loss 0.7836 (0.8145) ([0.548]+[0.236])	Prec@1 78.125 (80.147)
Test: [0/79]	Time 0.176 (0.176)	Loss 1.0282 (1.0282) ([0.793]+[0.235])	Prec@1 72.656 (72.656)
 * Prec@1 68.930
current lr 1.00000e-01
Grad=  tensor(1.5751, device='cuda:0')
Epoch: [28][0/391]	Time 0.257 (0.257)	Data 0.134 (0.134)	Loss 0.7468 (0.7468) ([0.511]+[0.235])	Prec@1 82.812 (82.812)
Epoch: [28][100/391]	Time 0.112 (0.113)	Data 0.000 (0.001)	Loss 0.8380 (0.7879) ([0.603]+[0.235])	Prec@1 78.125 (81.049)
Epoch: [28][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7764 (0.8045) ([0.541]+[0.236])	Prec@1 82.812 (80.430)
Epoch: [28][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7662 (0.8106) ([0.531]+[0.235])	Prec@1 83.594 (80.310)
Test: [0/79]	Time 0.153 (0.153)	Loss 1.0703 (1.0703) ([0.836]+[0.235])	Prec@1 74.219 (74.219)
 * Prec@1 72.280
current lr 1.00000e-01
Grad=  tensor(2.5488, device='cuda:0')
Epoch: [29][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.8982 (0.8982) ([0.664]+[0.235])	Prec@1 76.562 (76.562)
Epoch: [29][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.9182 (0.7961) ([0.684]+[0.234])	Prec@1 73.438 (80.476)
Epoch: [29][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6822 (0.8027) ([0.447]+[0.235])	Prec@1 82.812 (80.461)
Epoch: [29][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7396 (0.8046) ([0.505]+[0.235])	Prec@1 82.812 (80.440)
Test: [0/79]	Time 0.182 (0.182)	Loss 0.9516 (0.9516) ([0.717]+[0.234])	Prec@1 72.656 (72.656)
 * Prec@1 76.080
current lr 1.00000e-01
Grad=  tensor(1.9662, device='cuda:0')
Epoch: [30][0/391]	Time 0.279 (0.279)	Data 0.154 (0.154)	Loss 0.9152 (0.9152) ([0.681]+[0.234])	Prec@1 76.562 (76.562)
Epoch: [30][100/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.8566 (0.7842) ([0.622]+[0.235])	Prec@1 78.125 (81.482)
Epoch: [30][200/391]	Time 0.113 (0.115)	Data 0.000 (0.001)	Loss 0.8694 (0.8009) ([0.635]+[0.235])	Prec@1 79.688 (80.718)
Epoch: [30][300/391]	Time 0.113 (0.114)	Data 0.000 (0.001)	Loss 0.8668 (0.8029) ([0.633]+[0.234])	Prec@1 78.906 (80.736)
Test: [0/79]	Time 0.183 (0.183)	Loss 0.8856 (0.8856) ([0.652]+[0.233])	Prec@1 80.469 (80.469)
 * Prec@1 71.890
current lr 1.00000e-01
Grad=  tensor(1.7587, device='cuda:0')
Epoch: [31][0/391]	Time 0.279 (0.279)	Data 0.156 (0.156)	Loss 0.7704 (0.7704) ([0.537]+[0.233])	Prec@1 82.031 (82.031)
Epoch: [31][100/391]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.8751 (0.7838) ([0.642]+[0.233])	Prec@1 81.250 (80.886)
Epoch: [31][200/391]	Time 0.113 (0.115)	Data 0.000 (0.001)	Loss 0.8654 (0.7818) ([0.633]+[0.233])	Prec@1 77.344 (81.133)
Epoch: [31][300/391]	Time 0.112 (0.114)	Data 0.000 (0.001)	Loss 0.7464 (0.7867) ([0.513]+[0.233])	Prec@1 82.812 (80.993)
Test: [0/79]	Time 0.173 (0.173)	Loss 1.1381 (1.1381) ([0.905]+[0.233])	Prec@1 70.312 (70.312)
 * Prec@1 73.080
current lr 1.00000e-01
Grad=  tensor(1.8208, device='cuda:0')
Epoch: [32][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.7871 (0.7871) ([0.554]+[0.233])	Prec@1 79.688 (79.688)
Epoch: [32][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.6854 (0.7987) ([0.453]+[0.233])	Prec@1 82.031 (80.268)
Epoch: [32][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.6812 (0.7989) ([0.448]+[0.233])	Prec@1 84.375 (80.574)
Epoch: [32][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8445 (0.7965) ([0.612]+[0.232])	Prec@1 76.562 (80.669)
Test: [0/79]	Time 0.163 (0.163)	Loss 1.3872 (1.3872) ([1.156]+[0.231])	Prec@1 67.188 (67.188)
 * Prec@1 65.520
current lr 1.00000e-01
Grad=  tensor(2.6089, device='cuda:0')
Epoch: [33][0/391]	Time 0.248 (0.248)	Data 0.126 (0.126)	Loss 1.0232 (1.0232) ([0.792]+[0.231])	Prec@1 70.312 (70.312)
Epoch: [33][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8285 (0.7789) ([0.597]+[0.231])	Prec@1 78.125 (81.250)
Epoch: [33][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7802 (0.7761) ([0.549]+[0.231])	Prec@1 83.594 (81.231)
Epoch: [33][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8149 (0.7811) ([0.584]+[0.231])	Prec@1 80.469 (81.151)
Test: [0/79]	Time 0.160 (0.160)	Loss 1.0443 (1.0443) ([0.813]+[0.231])	Prec@1 70.312 (70.312)
 * Prec@1 74.350
current lr 1.00000e-01
Grad=  tensor(1.7496, device='cuda:0')
Epoch: [34][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.7083 (0.7083) ([0.477]+[0.231])	Prec@1 82.031 (82.031)
Epoch: [34][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7160 (0.7709) ([0.485]+[0.231])	Prec@1 88.281 (81.327)
Epoch: [34][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8012 (0.7786) ([0.570]+[0.231])	Prec@1 81.250 (81.149)
Epoch: [34][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7997 (0.7755) ([0.569]+[0.231])	Prec@1 78.906 (81.258)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.9290 (0.9290) ([0.698]+[0.231])	Prec@1 76.562 (76.562)
 * Prec@1 76.500
current lr 1.00000e-01
Grad=  tensor(1.8412, device='cuda:0')
Epoch: [35][0/391]	Time 0.254 (0.254)	Data 0.133 (0.133)	Loss 0.7136 (0.7136) ([0.483]+[0.231])	Prec@1 83.594 (83.594)
Epoch: [35][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.9480 (0.7828) ([0.717]+[0.231])	Prec@1 77.344 (81.312)
Epoch: [35][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.9809 (0.7782) ([0.750]+[0.231])	Prec@1 75.781 (81.460)
Epoch: [35][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7729 (0.7844) ([0.542]+[0.231])	Prec@1 81.250 (81.081)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.9377 (0.9377) ([0.707]+[0.231])	Prec@1 77.344 (77.344)
 * Prec@1 72.780
current lr 1.00000e-01
Grad=  tensor(2.0882, device='cuda:0')
Epoch: [36][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.7425 (0.7425) ([0.512]+[0.231])	Prec@1 81.250 (81.250)
Epoch: [36][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.6378 (0.7807) ([0.407]+[0.231])	Prec@1 85.156 (80.848)
Epoch: [36][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.7366 (0.7675) ([0.507]+[0.230])	Prec@1 82.031 (81.464)
Epoch: [36][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.6516 (0.7710) ([0.422]+[0.230])	Prec@1 85.156 (81.452)
Test: [0/79]	Time 0.155 (0.155)	Loss 0.8807 (0.8807) ([0.651]+[0.230])	Prec@1 79.688 (79.688)
 * Prec@1 74.910
current lr 1.00000e-01
Grad=  tensor(2.1672, device='cuda:0')
Epoch: [37][0/391]	Time 0.248 (0.248)	Data 0.128 (0.128)	Loss 0.8505 (0.8505) ([0.621]+[0.230])	Prec@1 83.594 (83.594)
Epoch: [37][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8694 (0.7819) ([0.639]+[0.230])	Prec@1 82.031 (81.358)
Epoch: [37][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.6935 (0.7821) ([0.463]+[0.230])	Prec@1 82.031 (81.394)
Epoch: [37][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.9163 (0.7827) ([0.687]+[0.230])	Prec@1 77.344 (81.320)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.8549 (0.8549) ([0.626]+[0.229])	Prec@1 80.469 (80.469)
 * Prec@1 73.910
current lr 1.00000e-01
Grad=  tensor(2.2542, device='cuda:0')
Epoch: [38][0/391]	Time 0.251 (0.251)	Data 0.131 (0.131)	Loss 0.7833 (0.7833) ([0.555]+[0.229])	Prec@1 79.688 (79.688)
Epoch: [38][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.9081 (0.7734) ([0.678]+[0.230])	Prec@1 79.688 (81.436)
Epoch: [38][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8074 (0.7723) ([0.578]+[0.229])	Prec@1 81.250 (81.573)
Epoch: [38][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.8387 (0.7768) ([0.608]+[0.230])	Prec@1 82.812 (81.421)
Test: [0/79]	Time 0.162 (0.162)	Loss 1.1376 (1.1376) ([0.908]+[0.230])	Prec@1 70.312 (70.312)
 * Prec@1 74.960
current lr 1.00000e-01
Grad=  tensor(1.8334, device='cuda:0')
Epoch: [39][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 0.7360 (0.7360) ([0.506]+[0.230])	Prec@1 83.594 (83.594)
Epoch: [39][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6938 (0.7730) ([0.465]+[0.229])	Prec@1 89.062 (81.397)
Epoch: [39][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.7943 (0.7659) ([0.566]+[0.229])	Prec@1 85.156 (81.600)
Epoch: [39][300/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.8817 (0.7667) ([0.653]+[0.228])	Prec@1 79.688 (81.629)
Test: [0/79]	Time 0.163 (0.163)	Loss 1.2321 (1.2321) ([1.004]+[0.228])	Prec@1 71.094 (71.094)
 * Prec@1 68.200
current lr 1.00000e-01
Grad=  tensor(1.8608, device='cuda:0')
Epoch: [40][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.7913 (0.7913) ([0.563]+[0.228])	Prec@1 80.469 (80.469)
Epoch: [40][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7159 (0.7566) ([0.488]+[0.228])	Prec@1 82.812 (81.706)
Epoch: [40][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7429 (0.7667) ([0.514]+[0.229])	Prec@1 79.688 (81.479)
Epoch: [40][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6797 (0.7637) ([0.452]+[0.228])	Prec@1 85.156 (81.520)
Test: [0/79]	Time 0.162 (0.162)	Loss 1.0444 (1.0444) ([0.817]+[0.228])	Prec@1 74.219 (74.219)
 * Prec@1 74.900
current lr 1.00000e-01
Grad=  tensor(2.4639, device='cuda:0')
Epoch: [41][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.8600 (0.8600) ([0.632]+[0.228])	Prec@1 75.000 (75.000)
Epoch: [41][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7443 (0.7627) ([0.517]+[0.228])	Prec@1 82.812 (81.381)
Epoch: [41][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8614 (0.7683) ([0.633]+[0.228])	Prec@1 79.688 (81.409)
Epoch: [41][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.8189 (0.7688) ([0.591]+[0.228])	Prec@1 78.906 (81.359)
Test: [0/79]	Time 0.158 (0.158)	Loss 0.8158 (0.8158) ([0.588]+[0.227])	Prec@1 79.688 (79.688)
 * Prec@1 74.630
current lr 1.00000e-01
Grad=  tensor(2.0373, device='cuda:0')
Epoch: [42][0/391]	Time 0.249 (0.249)	Data 0.129 (0.129)	Loss 0.6738 (0.6738) ([0.446]+[0.227])	Prec@1 85.938 (85.938)
Epoch: [42][100/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.6953 (0.7513) ([0.468]+[0.227])	Prec@1 83.594 (82.054)
Epoch: [42][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6480 (0.7630) ([0.421]+[0.227])	Prec@1 85.156 (81.588)
Epoch: [42][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6754 (0.7605) ([0.449]+[0.227])	Prec@1 88.281 (81.728)
Test: [0/79]	Time 0.160 (0.160)	Loss 1.0111 (1.0111) ([0.785]+[0.227])	Prec@1 74.219 (74.219)
 * Prec@1 72.940
current lr 1.00000e-01
Grad=  tensor(1.5211, device='cuda:0')
Epoch: [43][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 0.6031 (0.6031) ([0.377]+[0.227])	Prec@1 86.719 (86.719)
Epoch: [43][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7099 (0.7583) ([0.483]+[0.227])	Prec@1 85.156 (81.861)
Epoch: [43][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7548 (0.7618) ([0.528]+[0.227])	Prec@1 85.156 (81.693)
Epoch: [43][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.8382 (0.7583) ([0.611]+[0.227])	Prec@1 78.906 (81.774)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.9783 (0.9783) ([0.751]+[0.227])	Prec@1 77.344 (77.344)
 * Prec@1 74.100
current lr 1.00000e-01
Grad=  tensor(2.2641, device='cuda:0')
Epoch: [44][0/391]	Time 0.248 (0.248)	Data 0.127 (0.127)	Loss 0.7896 (0.7896) ([0.562]+[0.227])	Prec@1 82.031 (82.031)
Epoch: [44][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.7923 (0.7490) ([0.566]+[0.227])	Prec@1 82.031 (82.310)
Epoch: [44][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7624 (0.7506) ([0.536]+[0.227])	Prec@1 79.688 (82.175)
Epoch: [44][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7584 (0.7531) ([0.532]+[0.227])	Prec@1 81.250 (82.052)
Test: [0/79]	Time 0.158 (0.158)	Loss 0.9461 (0.9461) ([0.720]+[0.226])	Prec@1 77.344 (77.344)
 * Prec@1 75.280
current lr 1.00000e-01
Grad=  tensor(1.8521, device='cuda:0')
Epoch: [45][0/391]	Time 0.255 (0.255)	Data 0.130 (0.130)	Loss 0.6800 (0.6800) ([0.454]+[0.226])	Prec@1 81.250 (81.250)
Epoch: [45][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7047 (0.7687) ([0.478]+[0.227])	Prec@1 82.031 (81.614)
Epoch: [45][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.8138 (0.7567) ([0.588]+[0.226])	Prec@1 78.906 (81.895)
Epoch: [45][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.8282 (0.7530) ([0.603]+[0.225])	Prec@1 77.344 (82.052)
Test: [0/79]	Time 0.159 (0.159)	Loss 1.2085 (1.2085) ([0.984]+[0.225])	Prec@1 70.312 (70.312)
 * Prec@1 67.100
current lr 1.00000e-01
Grad=  tensor(2.1776, device='cuda:0')
Epoch: [46][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.7525 (0.7525) ([0.528]+[0.225])	Prec@1 79.688 (79.688)
Epoch: [46][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7330 (0.7369) ([0.508]+[0.225])	Prec@1 78.906 (82.588)
Epoch: [46][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.7833 (0.7349) ([0.558]+[0.225])	Prec@1 78.906 (82.463)
Epoch: [46][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8839 (0.7472) ([0.658]+[0.226])	Prec@1 78.125 (82.021)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.7793 (0.7793) ([0.554]+[0.225])	Prec@1 80.469 (80.469)
 * Prec@1 78.550
current lr 1.00000e-01
Grad=  tensor(1.4059, device='cuda:0')
Epoch: [47][0/391]	Time 0.255 (0.255)	Data 0.134 (0.134)	Loss 0.6233 (0.6233) ([0.398]+[0.225])	Prec@1 86.719 (86.719)
Epoch: [47][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.7866 (0.7528) ([0.561]+[0.225])	Prec@1 78.906 (81.784)
Epoch: [47][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7822 (0.7529) ([0.557]+[0.225])	Prec@1 83.594 (81.806)
Epoch: [47][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7218 (0.7521) ([0.497]+[0.225])	Prec@1 82.812 (81.805)
Test: [0/79]	Time 0.162 (0.162)	Loss 1.0654 (1.0654) ([0.839]+[0.226])	Prec@1 72.656 (72.656)
 * Prec@1 72.470
current lr 1.00000e-01
Grad=  tensor(1.6005, device='cuda:0')
Epoch: [48][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.6731 (0.6731) ([0.447]+[0.226])	Prec@1 78.906 (78.906)
Epoch: [48][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.5984 (0.7470) ([0.373]+[0.226])	Prec@1 87.500 (82.140)
Epoch: [48][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8266 (0.7455) ([0.602]+[0.225])	Prec@1 78.906 (82.136)
Epoch: [48][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6915 (0.7450) ([0.467]+[0.225])	Prec@1 84.375 (82.132)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.8593 (0.8593) ([0.634]+[0.225])	Prec@1 78.125 (78.125)
 * Prec@1 75.250
current lr 1.00000e-01
Grad=  tensor(1.6144, device='cuda:0')
Epoch: [49][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.6494 (0.6494) ([0.424]+[0.225])	Prec@1 86.719 (86.719)
Epoch: [49][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6677 (0.7581) ([0.442]+[0.225])	Prec@1 86.719 (81.428)
Epoch: [49][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7498 (0.7503) ([0.525]+[0.225])	Prec@1 78.906 (81.623)
Epoch: [49][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8239 (0.7511) ([0.599]+[0.225])	Prec@1 80.469 (81.629)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.8686 (0.8686) ([0.644]+[0.224])	Prec@1 77.344 (77.344)
 * Prec@1 75.720
current lr 1.00000e-01
Grad=  tensor(2.1379, device='cuda:0')
Epoch: [50][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 0.7310 (0.7310) ([0.507]+[0.224])	Prec@1 82.031 (82.031)
Epoch: [50][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7255 (0.7347) ([0.501]+[0.224])	Prec@1 85.156 (82.472)
Epoch: [50][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7751 (0.7341) ([0.551]+[0.224])	Prec@1 85.156 (82.711)
Epoch: [50][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8166 (0.7388) ([0.592]+[0.225])	Prec@1 81.250 (82.480)
Test: [0/79]	Time 0.207 (0.207)	Loss 0.8985 (0.8985) ([0.675]+[0.224])	Prec@1 80.469 (80.469)
 * Prec@1 77.490
current lr 1.00000e-01
Grad=  tensor(2.1421, device='cuda:0')
Epoch: [51][0/391]	Time 0.336 (0.336)	Data 0.177 (0.177)	Loss 0.7775 (0.7775) ([0.554]+[0.224])	Prec@1 82.031 (82.031)
Epoch: [51][100/391]	Time 0.111 (0.113)	Data 0.000 (0.002)	Loss 0.7172 (0.7441) ([0.493]+[0.224])	Prec@1 83.594 (82.287)
Epoch: [51][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6848 (0.7427) ([0.461]+[0.224])	Prec@1 86.719 (82.233)
Epoch: [51][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8320 (0.7489) ([0.609]+[0.223])	Prec@1 79.688 (82.104)
Test: [0/79]	Time 0.162 (0.162)	Loss 1.4942 (1.4942) ([1.271]+[0.223])	Prec@1 69.531 (69.531)
 * Prec@1 68.780
current lr 1.00000e-01
Grad=  tensor(1.8662, device='cuda:0')
Epoch: [52][0/391]	Time 0.247 (0.247)	Data 0.127 (0.127)	Loss 0.6955 (0.6955) ([0.473]+[0.223])	Prec@1 87.500 (87.500)
Epoch: [52][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.5919 (0.7335) ([0.368]+[0.223])	Prec@1 85.156 (82.464)
Epoch: [52][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.6886 (0.7397) ([0.465]+[0.223])	Prec@1 85.156 (82.331)
Epoch: [52][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.8752 (0.7517) ([0.652]+[0.224])	Prec@1 75.000 (81.878)
Test: [0/79]	Time 0.164 (0.164)	Loss 1.0139 (1.0139) ([0.790]+[0.224])	Prec@1 70.312 (70.312)
 * Prec@1 74.010
current lr 1.00000e-01
Grad=  tensor(1.4682, device='cuda:0')
Epoch: [53][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.6806 (0.6806) ([0.457]+[0.224])	Prec@1 87.500 (87.500)
Epoch: [53][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.7557 (0.7274) ([0.533]+[0.223])	Prec@1 80.469 (82.898)
Epoch: [53][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.5629 (0.7335) ([0.340]+[0.223])	Prec@1 89.844 (82.754)
Epoch: [53][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7248 (0.7380) ([0.502]+[0.223])	Prec@1 81.250 (82.543)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.9348 (0.9348) ([0.712]+[0.223])	Prec@1 76.562 (76.562)
 * Prec@1 76.540
current lr 1.00000e-01
Grad=  tensor(2.5776, device='cuda:0')
Epoch: [54][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 0.6604 (0.6604) ([0.438]+[0.223])	Prec@1 85.938 (85.938)
Epoch: [54][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7960 (0.7401) ([0.573]+[0.223])	Prec@1 83.594 (82.186)
Epoch: [54][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.9269 (0.7473) ([0.704]+[0.223])	Prec@1 75.781 (82.023)
Epoch: [54][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6450 (0.7430) ([0.422]+[0.223])	Prec@1 85.938 (82.241)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.9181 (0.9181) ([0.696]+[0.222])	Prec@1 78.125 (78.125)
 * Prec@1 75.990
current lr 1.00000e-01
Grad=  tensor(1.5604, device='cuda:0')
Epoch: [55][0/391]	Time 0.251 (0.251)	Data 0.131 (0.131)	Loss 0.5809 (0.5809) ([0.359]+[0.222])	Prec@1 88.281 (88.281)
Epoch: [55][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.9081 (0.7536) ([0.686]+[0.223])	Prec@1 80.469 (81.730)
Epoch: [55][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6808 (0.7441) ([0.459]+[0.222])	Prec@1 81.250 (82.214)
Epoch: [55][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7456 (0.7399) ([0.524]+[0.222])	Prec@1 78.906 (82.447)
Test: [0/79]	Time 0.163 (0.163)	Loss 1.2615 (1.2615) ([1.040]+[0.222])	Prec@1 67.969 (67.969)
 * Prec@1 68.080
current lr 1.00000e-01
Grad=  tensor(1.6499, device='cuda:0')
Epoch: [56][0/391]	Time 0.253 (0.253)	Data 0.132 (0.132)	Loss 0.7313 (0.7313) ([0.510]+[0.222])	Prec@1 82.812 (82.812)
Epoch: [56][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.6275 (0.7376) ([0.406]+[0.222])	Prec@1 89.062 (82.635)
Epoch: [56][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6646 (0.7431) ([0.443]+[0.222])	Prec@1 83.594 (82.521)
Epoch: [56][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7124 (0.7418) ([0.491]+[0.222])	Prec@1 83.594 (82.540)
Test: [0/79]	Time 0.164 (0.164)	Loss 1.3594 (1.3594) ([1.137]+[0.222])	Prec@1 68.750 (68.750)
 * Prec@1 67.940
current lr 1.00000e-01
Grad=  tensor(2.0577, device='cuda:0')
Epoch: [57][0/391]	Time 0.254 (0.254)	Data 0.133 (0.133)	Loss 0.6761 (0.6761) ([0.454]+[0.222])	Prec@1 81.250 (81.250)
Epoch: [57][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6724 (0.7236) ([0.451]+[0.222])	Prec@1 87.500 (83.045)
Epoch: [57][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6113 (0.7303) ([0.389]+[0.222])	Prec@1 88.281 (82.820)
Epoch: [57][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7593 (0.7382) ([0.537]+[0.222])	Prec@1 81.250 (82.361)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.8962 (0.8962) ([0.675]+[0.221])	Prec@1 76.562 (76.562)
 * Prec@1 75.480
current lr 1.00000e-01
Grad=  tensor(2.0347, device='cuda:0')
Epoch: [58][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.7236 (0.7236) ([0.502]+[0.221])	Prec@1 82.031 (82.031)
Epoch: [58][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.9461 (0.7319) ([0.724]+[0.222])	Prec@1 79.688 (82.565)
Epoch: [58][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6989 (0.7329) ([0.478]+[0.221])	Prec@1 81.250 (82.575)
Epoch: [58][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8042 (0.7314) ([0.583]+[0.221])	Prec@1 82.031 (82.657)
Test: [0/79]	Time 0.161 (0.161)	Loss 1.0015 (1.0015) ([0.781]+[0.220])	Prec@1 73.438 (73.438)
 * Prec@1 75.670
current lr 1.00000e-01
Grad=  tensor(1.6840, device='cuda:0')
Epoch: [59][0/391]	Time 0.253 (0.253)	Data 0.131 (0.131)	Loss 0.6691 (0.6691) ([0.449]+[0.220])	Prec@1 86.719 (86.719)
Epoch: [59][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.6969 (0.7261) ([0.477]+[0.220])	Prec@1 82.031 (82.789)
Epoch: [59][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8338 (0.7299) ([0.613]+[0.220])	Prec@1 75.781 (82.606)
Epoch: [59][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6676 (0.7345) ([0.447]+[0.220])	Prec@1 85.156 (82.376)
Test: [0/79]	Time 0.163 (0.163)	Loss 1.0931 (1.0931) ([0.873]+[0.220])	Prec@1 72.656 (72.656)
 * Prec@1 75.640
current lr 1.00000e-01
Grad=  tensor(1.4894, device='cuda:0')
Epoch: [60][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.6732 (0.6732) ([0.453]+[0.220])	Prec@1 85.156 (85.156)
Epoch: [60][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8149 (0.7273) ([0.595]+[0.220])	Prec@1 78.906 (82.635)
Epoch: [60][200/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.6955 (0.7300) ([0.476]+[0.219])	Prec@1 82.812 (82.556)
Epoch: [60][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7981 (0.7330) ([0.578]+[0.220])	Prec@1 81.250 (82.402)
Test: [0/79]	Time 0.161 (0.161)	Loss 1.0251 (1.0251) ([0.805]+[0.220])	Prec@1 73.438 (73.438)
 * Prec@1 75.470
current lr 1.00000e-01
Grad=  tensor(1.8673, device='cuda:0')
Epoch: [61][0/391]	Time 0.249 (0.249)	Data 0.130 (0.130)	Loss 0.6396 (0.6396) ([0.420]+[0.220])	Prec@1 85.938 (85.938)
Epoch: [61][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.7527 (0.7398) ([0.532]+[0.220])	Prec@1 81.250 (82.201)
Epoch: [61][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7188 (0.7405) ([0.498]+[0.221])	Prec@1 84.375 (82.097)
Epoch: [61][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7280 (0.7332) ([0.508]+[0.220])	Prec@1 82.031 (82.358)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.9814 (0.9814) ([0.761]+[0.220])	Prec@1 75.000 (75.000)
 * Prec@1 70.290
current lr 1.00000e-01
Grad=  tensor(1.8193, device='cuda:0')
Epoch: [62][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.6476 (0.6476) ([0.427]+[0.220])	Prec@1 82.812 (82.812)
Epoch: [62][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.8669 (0.7345) ([0.646]+[0.221])	Prec@1 78.125 (82.588)
Epoch: [62][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.7466 (0.7339) ([0.526]+[0.220])	Prec@1 79.688 (82.408)
Epoch: [62][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.6737 (0.7324) ([0.453]+[0.221])	Prec@1 83.594 (82.483)
Test: [0/79]	Time 0.162 (0.162)	Loss 1.6355 (1.6355) ([1.414]+[0.221])	Prec@1 60.938 (60.938)
 * Prec@1 63.820
current lr 1.00000e-01
Grad=  tensor(1.6501, device='cuda:0')
Epoch: [63][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.7070 (0.7070) ([0.486]+[0.221])	Prec@1 86.719 (86.719)
Epoch: [63][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7624 (0.7168) ([0.542]+[0.221])	Prec@1 78.906 (82.774)
Epoch: [63][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6782 (0.7219) ([0.458]+[0.220])	Prec@1 82.031 (82.824)
Epoch: [63][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6934 (0.7290) ([0.474]+[0.220])	Prec@1 81.250 (82.519)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.7505 (0.7505) ([0.532]+[0.219])	Prec@1 82.812 (82.812)
 * Prec@1 78.710
current lr 1.00000e-01
Grad=  tensor(2.0871, device='cuda:0')
Epoch: [64][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.7003 (0.7003) ([0.482]+[0.219])	Prec@1 83.594 (83.594)
Epoch: [64][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.8587 (0.7213) ([0.640]+[0.219])	Prec@1 78.125 (82.681)
Epoch: [64][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7766 (0.7316) ([0.558]+[0.219])	Prec@1 82.812 (82.311)
Epoch: [64][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.6666 (0.7348) ([0.448]+[0.219])	Prec@1 85.938 (82.249)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.9539 (0.9539) ([0.735]+[0.219])	Prec@1 74.219 (74.219)
 * Prec@1 72.310
current lr 1.00000e-01
Grad=  tensor(1.0604, device='cuda:0')
Epoch: [65][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.5220 (0.5220) ([0.303]+[0.219])	Prec@1 89.844 (89.844)
Epoch: [65][100/391]	Time 0.113 (0.113)	Data 0.000 (0.001)	Loss 0.7289 (0.7166) ([0.509]+[0.219])	Prec@1 82.812 (82.929)
Epoch: [65][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.8189 (0.7319) ([0.599]+[0.220])	Prec@1 83.594 (82.443)
Epoch: [65][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7175 (0.7352) ([0.497]+[0.220])	Prec@1 81.250 (82.314)
Test: [0/79]	Time 0.161 (0.161)	Loss 1.0995 (1.0995) ([0.879]+[0.220])	Prec@1 67.969 (67.969)
 * Prec@1 70.800
current lr 1.00000e-01
Grad=  tensor(1.8477, device='cuda:0')
Epoch: [66][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.7879 (0.7879) ([0.568]+[0.220])	Prec@1 79.688 (79.688)
Epoch: [66][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8573 (0.7118) ([0.638]+[0.220])	Prec@1 79.688 (83.099)
Epoch: [66][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7362 (0.7255) ([0.517]+[0.220])	Prec@1 84.375 (82.626)
Epoch: [66][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6550 (0.7306) ([0.436]+[0.219])	Prec@1 85.156 (82.501)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.8662 (0.8662) ([0.647]+[0.219])	Prec@1 80.469 (80.469)
 * Prec@1 74.460
current lr 1.00000e-01
Grad=  tensor(1.2273, device='cuda:0')
Epoch: [67][0/391]	Time 0.252 (0.252)	Data 0.129 (0.129)	Loss 0.5862 (0.5862) ([0.367]+[0.219])	Prec@1 86.719 (86.719)
Epoch: [67][100/391]	Time 0.112 (0.113)	Data 0.000 (0.001)	Loss 0.7053 (0.7267) ([0.486]+[0.219])	Prec@1 82.031 (82.774)
Epoch: [67][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.6440 (0.7280) ([0.425]+[0.219])	Prec@1 83.594 (82.805)
Epoch: [67][300/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.6710 (0.7320) ([0.452]+[0.219])	Prec@1 83.594 (82.561)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.8615 (0.8615) ([0.643]+[0.219])	Prec@1 78.125 (78.125)
 * Prec@1 77.920
current lr 1.00000e-01
Grad=  tensor(1.8926, device='cuda:0')
Epoch: [68][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.7155 (0.7155) ([0.497]+[0.219])	Prec@1 82.812 (82.812)
Epoch: [68][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8936 (0.7303) ([0.675]+[0.219])	Prec@1 78.125 (82.782)
Epoch: [68][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.7044 (0.7305) ([0.486]+[0.218])	Prec@1 79.688 (82.688)
Epoch: [68][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7895 (0.7315) ([0.571]+[0.218])	Prec@1 82.812 (82.678)
Test: [0/79]	Time 0.162 (0.162)	Loss 1.2505 (1.2505) ([1.032]+[0.218])	Prec@1 64.844 (64.844)
 * Prec@1 69.160
current lr 1.00000e-01
Grad=  tensor(1.4839, device='cuda:0')
Epoch: [69][0/391]	Time 0.251 (0.251)	Data 0.129 (0.129)	Loss 0.6410 (0.6410) ([0.423]+[0.218])	Prec@1 82.812 (82.812)
Epoch: [69][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.7373 (0.7163) ([0.519]+[0.218])	Prec@1 82.812 (82.820)
Epoch: [69][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6417 (0.7189) ([0.424]+[0.218])	Prec@1 85.938 (82.832)
Epoch: [69][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.5238 (0.7236) ([0.306]+[0.218])	Prec@1 92.188 (82.691)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.9567 (0.9567) ([0.739]+[0.218])	Prec@1 75.781 (75.781)
 * Prec@1 76.750
current lr 1.00000e-01
Grad=  tensor(2.4117, device='cuda:0')
Epoch: [70][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.8246 (0.8246) ([0.607]+[0.218])	Prec@1 77.344 (77.344)
Epoch: [70][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8864 (0.7212) ([0.669]+[0.218])	Prec@1 74.219 (82.936)
Epoch: [70][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8180 (0.7235) ([0.600]+[0.218])	Prec@1 79.688 (82.785)
Epoch: [70][300/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.7823 (0.7249) ([0.564]+[0.218])	Prec@1 80.469 (82.626)
Test: [0/79]	Time 0.162 (0.162)	Loss 1.0003 (1.0003) ([0.782]+[0.218])	Prec@1 73.438 (73.438)
 * Prec@1 73.400
current lr 1.00000e-01
Grad=  tensor(1.8365, device='cuda:0')
Epoch: [71][0/391]	Time 0.253 (0.253)	Data 0.131 (0.131)	Loss 0.7291 (0.7291) ([0.511]+[0.218])	Prec@1 84.375 (84.375)
Epoch: [71][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.5663 (0.7337) ([0.348]+[0.218])	Prec@1 89.062 (82.147)
Epoch: [71][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6242 (0.7345) ([0.406]+[0.219])	Prec@1 84.375 (82.296)
Epoch: [71][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6314 (0.7289) ([0.413]+[0.218])	Prec@1 87.500 (82.672)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.8303 (0.8303) ([0.613]+[0.218])	Prec@1 78.125 (78.125)
 * Prec@1 76.550
current lr 1.00000e-01
Grad=  tensor(1.7103, device='cuda:0')
Epoch: [72][0/391]	Time 0.255 (0.255)	Data 0.128 (0.128)	Loss 0.7632 (0.7632) ([0.546]+[0.218])	Prec@1 80.469 (80.469)
Epoch: [72][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.5856 (0.7287) ([0.368]+[0.218])	Prec@1 84.375 (82.464)
Epoch: [72][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6017 (0.7274) ([0.385]+[0.217])	Prec@1 87.500 (82.583)
Epoch: [72][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6952 (0.7282) ([0.478]+[0.217])	Prec@1 82.812 (82.527)
Test: [0/79]	Time 0.159 (0.159)	Loss 1.0376 (1.0376) ([0.820]+[0.217])	Prec@1 75.781 (75.781)
 * Prec@1 73.860
current lr 1.00000e-01
Grad=  tensor(2.6983, device='cuda:0')
Epoch: [73][0/391]	Time 0.253 (0.253)	Data 0.131 (0.131)	Loss 0.8391 (0.8391) ([0.622]+[0.217])	Prec@1 78.906 (78.906)
Epoch: [73][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7457 (0.7113) ([0.529]+[0.217])	Prec@1 82.812 (83.230)
Epoch: [73][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7137 (0.7233) ([0.497]+[0.217])	Prec@1 82.812 (82.778)
Epoch: [73][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8783 (0.7193) ([0.662]+[0.216])	Prec@1 81.250 (82.914)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.7751 (0.7751) ([0.559]+[0.216])	Prec@1 81.250 (81.250)
 * Prec@1 77.200
current lr 1.00000e-01
Grad=  tensor(2.0857, device='cuda:0')
Epoch: [74][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.6996 (0.6996) ([0.483]+[0.216])	Prec@1 84.375 (84.375)
Epoch: [74][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7747 (0.7127) ([0.558]+[0.216])	Prec@1 78.125 (82.720)
Epoch: [74][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6343 (0.7151) ([0.418]+[0.216])	Prec@1 83.594 (82.867)
Epoch: [74][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.6988 (0.7223) ([0.482]+[0.217])	Prec@1 85.156 (82.667)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.6922 (0.6922) ([0.476]+[0.216])	Prec@1 85.156 (85.156)
 * Prec@1 79.580
current lr 1.00000e-01
Grad=  tensor(1.4861, device='cuda:0')
Epoch: [75][0/391]	Time 0.254 (0.254)	Data 0.133 (0.133)	Loss 0.5975 (0.5975) ([0.381]+[0.216])	Prec@1 85.156 (85.156)
Epoch: [75][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.6238 (0.7138) ([0.408]+[0.216])	Prec@1 87.500 (83.106)
Epoch: [75][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8001 (0.7190) ([0.584]+[0.216])	Prec@1 80.469 (82.879)
Epoch: [75][300/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.7156 (0.7247) ([0.499]+[0.216])	Prec@1 81.250 (82.818)
Test: [0/79]	Time 0.163 (0.163)	Loss 1.1804 (1.1804) ([0.964]+[0.216])	Prec@1 72.656 (72.656)
 * Prec@1 66.470
current lr 1.00000e-01
Grad=  tensor(1.8174, device='cuda:0')
Epoch: [76][0/391]	Time 0.253 (0.253)	Data 0.132 (0.132)	Loss 0.6888 (0.6888) ([0.473]+[0.216])	Prec@1 85.156 (85.156)
Epoch: [76][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7565 (0.6986) ([0.541]+[0.216])	Prec@1 82.812 (83.601)
Epoch: [76][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6876 (0.7118) ([0.472]+[0.216])	Prec@1 85.156 (83.135)
Epoch: [76][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7963 (0.7191) ([0.581]+[0.216])	Prec@1 78.906 (82.937)
Test: [0/79]	Time 0.162 (0.162)	Loss 1.0077 (1.0077) ([0.792]+[0.216])	Prec@1 71.094 (71.094)
 * Prec@1 74.040
current lr 1.00000e-01
Grad=  tensor(1.8091, device='cuda:0')
Epoch: [77][0/391]	Time 0.251 (0.251)	Data 0.129 (0.129)	Loss 0.5848 (0.5848) ([0.369]+[0.216])	Prec@1 83.594 (83.594)
Epoch: [77][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7048 (0.7246) ([0.489]+[0.216])	Prec@1 83.594 (82.666)
Epoch: [77][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8443 (0.7216) ([0.629]+[0.216])	Prec@1 74.219 (82.882)
Epoch: [77][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8594 (0.7257) ([0.643]+[0.216])	Prec@1 78.125 (82.618)
Test: [0/79]	Time 0.160 (0.160)	Loss 1.3527 (1.3527) ([1.137]+[0.216])	Prec@1 66.406 (66.406)
 * Prec@1 66.530
current lr 1.00000e-01
Grad=  tensor(1.8656, device='cuda:0')
Epoch: [78][0/391]	Time 0.255 (0.255)	Data 0.129 (0.129)	Loss 0.7043 (0.7043) ([0.489]+[0.216])	Prec@1 84.375 (84.375)
Epoch: [78][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.7636 (0.7113) ([0.548]+[0.216])	Prec@1 78.906 (83.501)
Epoch: [78][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7673 (0.7142) ([0.551]+[0.216])	Prec@1 82.812 (83.174)
Epoch: [78][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7936 (0.7164) ([0.578]+[0.215])	Prec@1 80.469 (83.085)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.8612 (0.8612) ([0.646]+[0.215])	Prec@1 79.688 (79.688)
 * Prec@1 72.490
current lr 1.00000e-01
Grad=  tensor(1.6428, device='cuda:0')
Epoch: [79][0/391]	Time 0.249 (0.249)	Data 0.130 (0.130)	Loss 0.6896 (0.6896) ([0.475]+[0.215])	Prec@1 82.812 (82.812)
Epoch: [79][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.5918 (0.7314) ([0.375]+[0.216])	Prec@1 85.938 (82.232)
Epoch: [79][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.8409 (0.7304) ([0.625]+[0.216])	Prec@1 76.562 (82.319)
Epoch: [79][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.7180 (0.7258) ([0.502]+[0.216])	Prec@1 82.812 (82.413)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.9164 (0.9164) ([0.701]+[0.216])	Prec@1 76.562 (76.562)
 * Prec@1 75.760
current lr 1.00000e-01
Grad=  tensor(1.6172, device='cuda:0')
Epoch: [80][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.6477 (0.6477) ([0.432]+[0.216])	Prec@1 85.156 (85.156)
Epoch: [80][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.7328 (0.7150) ([0.517]+[0.216])	Prec@1 79.688 (82.990)
Epoch: [80][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.5932 (0.7075) ([0.378]+[0.215])	Prec@1 91.406 (83.279)
Epoch: [80][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7763 (0.7102) ([0.561]+[0.216])	Prec@1 81.250 (83.243)
Test: [0/79]	Time 0.161 (0.161)	Loss 1.0556 (1.0556) ([0.840]+[0.215])	Prec@1 75.000 (75.000)
 * Prec@1 73.330
current lr 1.00000e-01
Grad=  tensor(1.8434, device='cuda:0')
Epoch: [81][0/391]	Time 0.252 (0.252)	Data 0.132 (0.132)	Loss 0.6663 (0.6663) ([0.451]+[0.215])	Prec@1 85.156 (85.156)
Epoch: [81][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.6134 (0.7157) ([0.399]+[0.215])	Prec@1 85.156 (82.766)
Epoch: [81][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7819 (0.7201) ([0.567]+[0.215])	Prec@1 81.250 (82.735)
Epoch: [81][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7226 (0.7158) ([0.508]+[0.214])	Prec@1 84.375 (82.896)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.8780 (0.8780) ([0.664]+[0.214])	Prec@1 77.344 (77.344)
 * Prec@1 76.020
current lr 1.00000e-01
Grad=  tensor(1.4563, device='cuda:0')
Epoch: [82][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.6110 (0.6110) ([0.397]+[0.214])	Prec@1 85.156 (85.156)
Epoch: [82][100/391]	Time 0.110 (0.113)	Data 0.000 (0.001)	Loss 0.6331 (0.7076) ([0.418]+[0.215])	Prec@1 87.500 (82.975)
Epoch: [82][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6580 (0.7133) ([0.444]+[0.214])	Prec@1 83.594 (82.727)
Epoch: [82][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6243 (0.7187) ([0.409]+[0.215])	Prec@1 90.625 (82.680)
Test: [0/79]	Time 0.161 (0.161)	Loss 1.1418 (1.1418) ([0.926]+[0.216])	Prec@1 73.438 (73.438)
 * Prec@1 71.420
current lr 1.00000e-01
Grad=  tensor(1.5835, device='cuda:0')
Epoch: [83][0/391]	Time 0.253 (0.253)	Data 0.131 (0.131)	Loss 0.6840 (0.6840) ([0.468]+[0.216])	Prec@1 85.938 (85.938)
Epoch: [83][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.9439 (0.7125) ([0.729]+[0.215])	Prec@1 76.562 (83.130)
Epoch: [83][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6910 (0.7196) ([0.476]+[0.215])	Prec@1 84.375 (82.727)
Epoch: [83][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.4536 (0.7178) ([0.239]+[0.214])	Prec@1 93.750 (82.877)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.7673 (0.7673) ([0.553]+[0.214])	Prec@1 81.250 (81.250)
 * Prec@1 77.290
current lr 1.00000e-01
Grad=  tensor(2.3096, device='cuda:0')
Epoch: [84][0/391]	Time 0.249 (0.249)	Data 0.127 (0.127)	Loss 0.6964 (0.6964) ([0.482]+[0.214])	Prec@1 80.469 (80.469)
Epoch: [84][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.5204 (0.7013) ([0.306]+[0.214])	Prec@1 89.844 (83.230)
Epoch: [84][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.7343 (0.7019) ([0.520]+[0.214])	Prec@1 79.688 (83.186)
Epoch: [84][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6747 (0.7097) ([0.461]+[0.214])	Prec@1 84.375 (82.929)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.9740 (0.9740) ([0.760]+[0.214])	Prec@1 72.656 (72.656)
 * Prec@1 73.560
current lr 1.00000e-01
Grad=  tensor(2.0859, device='cuda:0')
Epoch: [85][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.7492 (0.7492) ([0.535]+[0.214])	Prec@1 80.469 (80.469)
Epoch: [85][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.7806 (0.6947) ([0.567]+[0.214])	Prec@1 84.375 (83.756)
Epoch: [85][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.7174 (0.7118) ([0.504]+[0.214])	Prec@1 80.469 (82.871)
Epoch: [85][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7935 (0.7214) ([0.580]+[0.214])	Prec@1 77.344 (82.527)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.8980 (0.8980) ([0.684]+[0.214])	Prec@1 76.562 (76.562)
 * Prec@1 74.570
current lr 1.00000e-01
Grad=  tensor(2.1945, device='cuda:0')
Epoch: [86][0/391]	Time 0.255 (0.255)	Data 0.129 (0.129)	Loss 0.7520 (0.7520) ([0.538]+[0.214])	Prec@1 87.500 (87.500)
Epoch: [86][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7139 (0.7274) ([0.500]+[0.214])	Prec@1 82.812 (82.557)
Epoch: [86][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7478 (0.7124) ([0.534]+[0.213])	Prec@1 82.031 (82.937)
Epoch: [86][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.6380 (0.7204) ([0.424]+[0.214])	Prec@1 85.156 (82.719)
Test: [0/79]	Time 0.165 (0.165)	Loss 1.0122 (1.0122) ([0.799]+[0.213])	Prec@1 74.219 (74.219)
 * Prec@1 70.900
current lr 1.00000e-01
Grad=  tensor(2.2095, device='cuda:0')
Epoch: [87][0/391]	Time 0.252 (0.252)	Data 0.132 (0.132)	Loss 0.7901 (0.7901) ([0.577]+[0.213])	Prec@1 83.594 (83.594)
Epoch: [87][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.8072 (0.7073) ([0.594]+[0.213])	Prec@1 78.906 (83.099)
Epoch: [87][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.6450 (0.7084) ([0.432]+[0.213])	Prec@1 84.375 (83.057)
Epoch: [87][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.7018 (0.7090) ([0.489]+[0.213])	Prec@1 83.594 (82.994)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.7001 (0.7001) ([0.486]+[0.214])	Prec@1 82.812 (82.812)
 * Prec@1 79.090
current lr 1.00000e-01
Grad=  tensor(2.6626, device='cuda:0')
Epoch: [88][0/391]	Time 0.249 (0.249)	Data 0.130 (0.130)	Loss 0.8669 (0.8669) ([0.653]+[0.214])	Prec@1 78.906 (78.906)
Epoch: [88][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7865 (0.7107) ([0.573]+[0.214])	Prec@1 77.344 (83.137)
Epoch: [88][200/391]	Time 0.112 (0.110)	Data 0.000 (0.001)	Loss 0.6973 (0.7181) ([0.484]+[0.213])	Prec@1 83.594 (82.719)
Epoch: [88][300/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.5457 (0.7146) ([0.333]+[0.213])	Prec@1 89.844 (82.823)
Test: [0/79]	Time 0.171 (0.171)	Loss 0.7379 (0.7379) ([0.525]+[0.212])	Prec@1 82.812 (82.812)
 * Prec@1 78.840
current lr 1.00000e-01
Grad=  tensor(2.4328, device='cuda:0')
Epoch: [89][0/391]	Time 0.254 (0.254)	Data 0.133 (0.133)	Loss 0.8144 (0.8144) ([0.602]+[0.212])	Prec@1 75.781 (75.781)
Epoch: [89][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.9185 (0.7061) ([0.706]+[0.212])	Prec@1 76.562 (83.277)
Epoch: [89][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8490 (0.7071) ([0.637]+[0.212])	Prec@1 77.344 (83.147)
Epoch: [89][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6520 (0.7102) ([0.440]+[0.212])	Prec@1 85.156 (83.051)
Test: [0/79]	Time 0.164 (0.164)	Loss 1.0143 (1.0143) ([0.802]+[0.212])	Prec@1 78.125 (78.125)
 * Prec@1 74.540
current lr 1.00000e-01
Grad=  tensor(1.7601, device='cuda:0')
Epoch: [90][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 0.6449 (0.6449) ([0.433]+[0.212])	Prec@1 85.156 (85.156)
Epoch: [90][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.7016 (0.7165) ([0.489]+[0.213])	Prec@1 81.250 (82.758)
Epoch: [90][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8249 (0.7180) ([0.612]+[0.212])	Prec@1 80.469 (82.894)
Epoch: [90][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6500 (0.7126) ([0.438]+[0.212])	Prec@1 84.375 (82.955)
Test: [0/79]	Time 0.158 (0.158)	Loss 1.2941 (1.2941) ([1.083]+[0.212])	Prec@1 70.312 (70.312)
 * Prec@1 69.690
current lr 1.00000e-01
Grad=  tensor(2.0582, device='cuda:0')
Epoch: [91][0/391]	Time 0.250 (0.250)	Data 0.130 (0.130)	Loss 0.6479 (0.6479) ([0.436]+[0.212])	Prec@1 84.375 (84.375)
Epoch: [91][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.6858 (0.6990) ([0.474]+[0.212])	Prec@1 83.594 (83.315)
Epoch: [91][200/391]	Time 0.113 (0.112)	Data 0.000 (0.001)	Loss 0.7941 (0.7064) ([0.583]+[0.212])	Prec@1 80.469 (83.225)
Epoch: [91][300/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.6380 (0.7101) ([0.426]+[0.212])	Prec@1 84.375 (83.085)
Test: [0/79]	Time 0.165 (0.165)	Loss 1.0008 (1.0008) ([0.789]+[0.211])	Prec@1 74.219 (74.219)
 * Prec@1 73.040
current lr 1.00000e-01
Grad=  tensor(2.0034, device='cuda:0')
Epoch: [92][0/391]	Time 0.255 (0.255)	Data 0.133 (0.133)	Loss 0.7068 (0.7068) ([0.495]+[0.211])	Prec@1 79.688 (79.688)
Epoch: [92][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.7138 (0.7035) ([0.502]+[0.212])	Prec@1 83.594 (82.952)
Epoch: [92][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7694 (0.7175) ([0.558]+[0.212])	Prec@1 78.906 (82.552)
Epoch: [92][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.6075 (0.7136) ([0.396]+[0.212])	Prec@1 87.500 (82.916)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.8790 (0.8790) ([0.668]+[0.211])	Prec@1 77.344 (77.344)
 * Prec@1 74.200
current lr 1.00000e-01
Grad=  tensor(1.9045, device='cuda:0')
Epoch: [93][0/391]	Time 0.259 (0.259)	Data 0.133 (0.133)	Loss 0.6083 (0.6083) ([0.397]+[0.211])	Prec@1 83.594 (83.594)
Epoch: [93][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8532 (0.7074) ([0.641]+[0.212])	Prec@1 80.469 (82.859)
Epoch: [93][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6312 (0.7202) ([0.419]+[0.212])	Prec@1 87.500 (82.591)
Epoch: [93][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6211 (0.7161) ([0.409]+[0.212])	Prec@1 85.938 (82.667)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.9365 (0.9365) ([0.724]+[0.213])	Prec@1 79.688 (79.688)
 * Prec@1 74.680
current lr 1.00000e-01
Grad=  tensor(1.9980, device='cuda:0')
Epoch: [94][0/391]	Time 0.259 (0.259)	Data 0.136 (0.136)	Loss 0.7380 (0.7380) ([0.525]+[0.213])	Prec@1 85.156 (85.156)
Epoch: [94][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.6977 (0.6744) ([0.486]+[0.211])	Prec@1 80.469 (84.158)
Epoch: [94][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6956 (0.7049) ([0.483]+[0.212])	Prec@1 83.594 (83.057)
Epoch: [94][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6177 (0.7120) ([0.405]+[0.212])	Prec@1 86.719 (82.787)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.8539 (0.8539) ([0.642]+[0.212])	Prec@1 82.812 (82.812)
 * Prec@1 78.050
current lr 1.00000e-01
Grad=  tensor(1.8807, device='cuda:0')
Epoch: [95][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.6565 (0.6565) ([0.445]+[0.212])	Prec@1 84.375 (84.375)
Epoch: [95][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.5777 (0.7094) ([0.366]+[0.212])	Prec@1 92.188 (82.944)
Epoch: [95][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.5675 (0.7208) ([0.355]+[0.212])	Prec@1 85.938 (82.478)
Epoch: [95][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7298 (0.7126) ([0.518]+[0.212])	Prec@1 82.812 (82.716)
Test: [0/79]	Time 0.159 (0.159)	Loss 0.9144 (0.9144) ([0.702]+[0.212])	Prec@1 75.781 (75.781)
 * Prec@1 73.480
current lr 1.00000e-01
Grad=  tensor(1.2982, device='cuda:0')
Epoch: [96][0/391]	Time 0.249 (0.249)	Data 0.128 (0.128)	Loss 0.6424 (0.6424) ([0.430]+[0.212])	Prec@1 86.719 (86.719)
Epoch: [96][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7670 (0.7038) ([0.555]+[0.212])	Prec@1 78.906 (83.300)
Epoch: [96][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8367 (0.7059) ([0.625]+[0.212])	Prec@1 80.469 (83.263)
Epoch: [96][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.6382 (0.7082) ([0.427]+[0.211])	Prec@1 83.594 (83.090)
Test: [0/79]	Time 0.162 (0.162)	Loss 1.9539 (1.9539) ([1.742]+[0.212])	Prec@1 63.281 (63.281)
 * Prec@1 61.080
current lr 1.00000e-01
Grad=  tensor(2.6120, device='cuda:0')
Epoch: [97][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.7557 (0.7557) ([0.544]+[0.212])	Prec@1 78.906 (78.906)
Epoch: [97][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.7941 (0.6945) ([0.582]+[0.212])	Prec@1 74.219 (83.246)
Epoch: [97][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.6403 (0.7008) ([0.429]+[0.211])	Prec@1 85.938 (83.170)
Epoch: [97][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6357 (0.7067) ([0.424]+[0.211])	Prec@1 82.031 (82.929)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.8087 (0.8087) ([0.598]+[0.211])	Prec@1 80.469 (80.469)
 * Prec@1 77.720
current lr 1.00000e-01
Grad=  tensor(1.4238, device='cuda:0')
Epoch: [98][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 0.5659 (0.5659) ([0.355]+[0.211])	Prec@1 87.500 (87.500)
Epoch: [98][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.7580 (0.7073) ([0.547]+[0.211])	Prec@1 81.250 (82.952)
Epoch: [98][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7752 (0.7123) ([0.564]+[0.211])	Prec@1 84.375 (82.968)
Epoch: [98][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7088 (0.7136) ([0.498]+[0.211])	Prec@1 84.375 (82.950)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.8466 (0.8466) ([0.636]+[0.211])	Prec@1 80.469 (80.469)
 * Prec@1 75.700
current lr 1.00000e-01
Grad=  tensor(1.6838, device='cuda:0')
Epoch: [99][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.6753 (0.6753) ([0.465]+[0.211])	Prec@1 82.812 (82.812)
Epoch: [99][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8235 (0.7168) ([0.612]+[0.211])	Prec@1 78.906 (82.689)
Epoch: [99][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7881 (0.7151) ([0.577]+[0.211])	Prec@1 80.469 (82.770)
Epoch: [99][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7922 (0.7071) ([0.582]+[0.211])	Prec@1 80.469 (83.098)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.7693 (0.7693) ([0.559]+[0.210])	Prec@1 82.812 (82.812)
 * Prec@1 78.600
current lr 1.00000e-02
Grad=  tensor(1.8788, device='cuda:0')
Epoch: [100][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.6696 (0.6696) ([0.459]+[0.210])	Prec@1 84.375 (84.375)
Epoch: [100][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.4522 (0.5735) ([0.256]+[0.196])	Prec@1 89.062 (87.028)
Epoch: [100][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.4957 (0.5338) ([0.301]+[0.194])	Prec@1 89.062 (88.386)
Epoch: [100][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.5552 (0.5161) ([0.362]+[0.193])	Prec@1 89.062 (88.928)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.3912 (0.3912) ([0.200]+[0.192])	Prec@1 92.188 (92.188)
 * Prec@1 89.730
current lr 1.00000e-02
Grad=  tensor(1.2252, device='cuda:0')
Epoch: [101][0/391]	Time 0.259 (0.259)	Data 0.133 (0.133)	Loss 0.4907 (0.4907) ([0.299]+[0.192])	Prec@1 89.844 (89.844)
Epoch: [101][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.5825 (0.4408) ([0.392]+[0.190])	Prec@1 88.281 (91.530)
Epoch: [101][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.5693 (0.4441) ([0.380]+[0.189])	Prec@1 89.844 (91.367)
Epoch: [101][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3513 (0.4411) ([0.164]+[0.188])	Prec@1 94.531 (91.440)
Test: [0/79]	Time 0.159 (0.159)	Loss 0.3844 (0.3844) ([0.198]+[0.187])	Prec@1 92.969 (92.969)
 * Prec@1 90.310
current lr 1.00000e-02
Grad=  tensor(1.5541, device='cuda:0')
Epoch: [102][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.4294 (0.4294) ([0.243]+[0.187])	Prec@1 93.750 (93.750)
Epoch: [102][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3763 (0.4202) ([0.191]+[0.185])	Prec@1 92.969 (92.010)
Epoch: [102][200/391]	Time 0.108 (0.111)	Data 0.000 (0.001)	Loss 0.4662 (0.4182) ([0.282]+[0.184])	Prec@1 92.188 (91.943)
Epoch: [102][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.4403 (0.4194) ([0.257]+[0.183])	Prec@1 92.188 (91.951)
Test: [0/79]	Time 0.158 (0.158)	Loss 0.3924 (0.3924) ([0.211]+[0.182])	Prec@1 94.531 (94.531)
 * Prec@1 90.540
current lr 1.00000e-02
Grad=  tensor(1.9964, device='cuda:0')
Epoch: [103][0/391]	Time 0.252 (0.252)	Data 0.133 (0.133)	Loss 0.3699 (0.3699) ([0.188]+[0.182])	Prec@1 93.750 (93.750)
Epoch: [103][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.3909 (0.3839) ([0.210]+[0.181])	Prec@1 92.188 (93.154)
Epoch: [103][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3345 (0.3865) ([0.155]+[0.179])	Prec@1 96.875 (93.012)
Epoch: [103][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3560 (0.3896) ([0.178]+[0.178])	Prec@1 92.188 (92.823)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.3576 (0.3576) ([0.180]+[0.177])	Prec@1 93.750 (93.750)
 * Prec@1 90.330
current lr 1.00000e-02
Grad=  tensor(2.4095, device='cuda:0')
Epoch: [104][0/391]	Time 0.247 (0.247)	Data 0.128 (0.128)	Loss 0.4728 (0.4728) ([0.295]+[0.177])	Prec@1 89.844 (89.844)
Epoch: [104][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3620 (0.3713) ([0.186]+[0.176])	Prec@1 96.094 (93.371)
Epoch: [104][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.4068 (0.3777) ([0.232]+[0.175])	Prec@1 92.188 (93.070)
Epoch: [104][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3927 (0.3801) ([0.219]+[0.174])	Prec@1 92.969 (92.956)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.3599 (0.3599) ([0.187]+[0.173])	Prec@1 94.531 (94.531)
 * Prec@1 90.880
current lr 1.00000e-02
Grad=  tensor(2.4872, device='cuda:0')
Epoch: [105][0/391]	Time 0.254 (0.254)	Data 0.134 (0.134)	Loss 0.3800 (0.3800) ([0.207]+[0.173])	Prec@1 94.531 (94.531)
Epoch: [105][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.3227 (0.3668) ([0.150]+[0.172])	Prec@1 94.531 (93.348)
Epoch: [105][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3612 (0.3652) ([0.190]+[0.171])	Prec@1 92.969 (93.334)
Epoch: [105][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3124 (0.3632) ([0.142]+[0.170])	Prec@1 96.094 (93.452)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.4191 (0.4191) ([0.250]+[0.169])	Prec@1 94.531 (94.531)
 * Prec@1 90.450
current lr 1.00000e-02
Grad=  tensor(2.2813, device='cuda:0')
Epoch: [106][0/391]	Time 0.248 (0.248)	Data 0.127 (0.127)	Loss 0.3572 (0.3572) ([0.188]+[0.169])	Prec@1 93.750 (93.750)
Epoch: [106][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.4223 (0.3418) ([0.254]+[0.168])	Prec@1 92.188 (94.052)
Epoch: [106][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.3104 (0.3481) ([0.143]+[0.167])	Prec@1 94.531 (93.855)
Epoch: [106][300/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.3409 (0.3537) ([0.174]+[0.167])	Prec@1 95.312 (93.636)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.3554 (0.3554) ([0.190]+[0.166])	Prec@1 93.750 (93.750)
 * Prec@1 90.820
current lr 1.00000e-02
Grad=  tensor(2.7496, device='cuda:0')
Epoch: [107][0/391]	Time 0.251 (0.251)	Data 0.131 (0.131)	Loss 0.3554 (0.3554) ([0.190]+[0.166])	Prec@1 94.531 (94.531)
Epoch: [107][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3004 (0.3402) ([0.136]+[0.165])	Prec@1 96.094 (93.874)
Epoch: [107][200/391]	Time 0.112 (0.110)	Data 0.000 (0.001)	Loss 0.3316 (0.3388) ([0.168]+[0.164])	Prec@1 94.531 (93.921)
Epoch: [107][300/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.3447 (0.3414) ([0.182]+[0.163])	Prec@1 91.406 (93.901)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.3678 (0.3678) ([0.205]+[0.162])	Prec@1 95.312 (95.312)
 * Prec@1 90.550
current lr 1.00000e-02
Grad=  tensor(2.7798, device='cuda:0')
Epoch: [108][0/391]	Time 0.253 (0.253)	Data 0.131 (0.131)	Loss 0.3218 (0.3218) ([0.159]+[0.162])	Prec@1 94.531 (94.531)
Epoch: [108][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3164 (0.3326) ([0.155]+[0.162])	Prec@1 93.750 (94.230)
Epoch: [108][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2550 (0.3316) ([0.094]+[0.161])	Prec@1 97.656 (94.290)
Epoch: [108][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3797 (0.3338) ([0.220]+[0.160])	Prec@1 92.188 (94.155)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.3851 (0.3851) ([0.226]+[0.159])	Prec@1 95.312 (95.312)
 * Prec@1 90.900
current lr 1.00000e-02
Grad=  tensor(4.4838, device='cuda:0')
Epoch: [109][0/391]	Time 0.255 (0.255)	Data 0.134 (0.134)	Loss 0.4630 (0.4630) ([0.304]+[0.159])	Prec@1 91.406 (91.406)
Epoch: [109][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3054 (0.3230) ([0.147]+[0.158])	Prec@1 92.969 (94.531)
Epoch: [109][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2517 (0.3196) ([0.094]+[0.158])	Prec@1 97.656 (94.477)
Epoch: [109][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2552 (0.3202) ([0.098]+[0.157])	Prec@1 96.875 (94.443)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.3971 (0.3971) ([0.241]+[0.156])	Prec@1 91.406 (91.406)
 * Prec@1 90.590
current lr 1.00000e-02
Grad=  tensor(4.6386, device='cuda:0')
Epoch: [110][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 0.3521 (0.3521) ([0.196]+[0.156])	Prec@1 92.188 (92.188)
Epoch: [110][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3118 (0.3088) ([0.156]+[0.156])	Prec@1 93.750 (94.972)
Epoch: [110][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3864 (0.3179) ([0.231]+[0.155])	Prec@1 91.406 (94.446)
Epoch: [110][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.4371 (0.3186) ([0.283]+[0.154])	Prec@1 89.844 (94.357)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.3218 (0.3218) ([0.168]+[0.154])	Prec@1 95.312 (95.312)
 * Prec@1 90.930
current lr 1.00000e-02
Grad=  tensor(3.5554, device='cuda:0')
Epoch: [111][0/391]	Time 0.257 (0.257)	Data 0.135 (0.135)	Loss 0.3208 (0.3208) ([0.167]+[0.154])	Prec@1 94.531 (94.531)
Epoch: [111][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.3519 (0.3128) ([0.199]+[0.153])	Prec@1 94.531 (94.353)
Epoch: [111][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2951 (0.3110) ([0.143]+[0.152])	Prec@1 92.188 (94.341)
Epoch: [111][300/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.4439 (0.3140) ([0.292]+[0.152])	Prec@1 89.844 (94.235)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.4196 (0.4196) ([0.268]+[0.151])	Prec@1 92.188 (92.188)
 * Prec@1 90.330
current lr 1.00000e-02
Grad=  tensor(4.5858, device='cuda:0')
Epoch: [112][0/391]	Time 0.248 (0.248)	Data 0.129 (0.129)	Loss 0.3079 (0.3079) ([0.157]+[0.151])	Prec@1 94.531 (94.531)
Epoch: [112][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3163 (0.3099) ([0.166]+[0.151])	Prec@1 95.312 (94.609)
Epoch: [112][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2787 (0.3102) ([0.129]+[0.150])	Prec@1 95.312 (94.527)
Epoch: [112][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2777 (0.3096) ([0.128]+[0.150])	Prec@1 96.094 (94.500)
Test: [0/79]	Time 0.157 (0.157)	Loss 0.4510 (0.4510) ([0.302]+[0.149])	Prec@1 91.406 (91.406)
 * Prec@1 90.750
current lr 1.00000e-02
Grad=  tensor(3.4271, device='cuda:0')
Epoch: [113][0/391]	Time 0.253 (0.253)	Data 0.132 (0.132)	Loss 0.2815 (0.2815) ([0.132]+[0.149])	Prec@1 95.312 (95.312)
Epoch: [113][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3247 (0.3010) ([0.176]+[0.148])	Prec@1 92.969 (94.810)
Epoch: [113][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3263 (0.3007) ([0.178]+[0.148])	Prec@1 93.750 (94.741)
Epoch: [113][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3978 (0.3044) ([0.250]+[0.147])	Prec@1 90.625 (94.557)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.4049 (0.4049) ([0.258]+[0.147])	Prec@1 92.969 (92.969)
 * Prec@1 90.790
current lr 1.00000e-02
Grad=  tensor(4.9915, device='cuda:0')
Epoch: [114][0/391]	Time 0.253 (0.253)	Data 0.133 (0.133)	Loss 0.2998 (0.2998) ([0.153]+[0.147])	Prec@1 94.531 (94.531)
Epoch: [114][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2796 (0.2831) ([0.133]+[0.146])	Prec@1 95.312 (95.282)
Epoch: [114][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3132 (0.2919) ([0.167]+[0.146])	Prec@1 93.750 (94.990)
Epoch: [114][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3916 (0.2963) ([0.246]+[0.146])	Prec@1 90.625 (94.801)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.3470 (0.3470) ([0.202]+[0.145])	Prec@1 92.969 (92.969)
 * Prec@1 89.770
current lr 1.00000e-02
Grad=  tensor(5.1481, device='cuda:0')
Epoch: [115][0/391]	Time 0.253 (0.253)	Data 0.133 (0.133)	Loss 0.3252 (0.3252) ([0.180]+[0.145])	Prec@1 91.406 (91.406)
Epoch: [115][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2417 (0.2955) ([0.097]+[0.145])	Prec@1 97.656 (94.794)
Epoch: [115][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3027 (0.2932) ([0.158]+[0.144])	Prec@1 96.094 (94.908)
Epoch: [115][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2814 (0.2950) ([0.138]+[0.144])	Prec@1 95.312 (94.895)
Test: [0/79]	Time 0.171 (0.171)	Loss 0.3865 (0.3865) ([0.243]+[0.143])	Prec@1 92.969 (92.969)
 * Prec@1 90.560
current lr 1.00000e-02
Grad=  tensor(5.7861, device='cuda:0')
Epoch: [116][0/391]	Time 0.256 (0.256)	Data 0.136 (0.136)	Loss 0.3095 (0.3095) ([0.166]+[0.143])	Prec@1 93.750 (93.750)
Epoch: [116][100/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2828 (0.2902) ([0.140]+[0.143])	Prec@1 96.094 (95.019)
Epoch: [116][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3065 (0.2940) ([0.164]+[0.143])	Prec@1 93.750 (94.757)
Epoch: [116][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3052 (0.2987) ([0.163]+[0.142])	Prec@1 92.188 (94.570)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.3869 (0.3869) ([0.245]+[0.142])	Prec@1 93.750 (93.750)
 * Prec@1 90.310
current lr 1.00000e-02
Grad=  tensor(4.5157, device='cuda:0')
Epoch: [117][0/391]	Time 0.255 (0.255)	Data 0.133 (0.133)	Loss 0.2648 (0.2648) ([0.123]+[0.142])	Prec@1 96.094 (96.094)
Epoch: [117][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1835 (0.2856) ([0.042]+[0.141])	Prec@1 99.219 (95.088)
Epoch: [117][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2661 (0.2909) ([0.125]+[0.141])	Prec@1 96.094 (94.877)
Epoch: [117][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2740 (0.2947) ([0.133]+[0.141])	Prec@1 95.312 (94.788)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.3630 (0.3630) ([0.222]+[0.140])	Prec@1 92.969 (92.969)
 * Prec@1 90.280
current lr 1.00000e-02
Grad=  tensor(5.9686, device='cuda:0')
Epoch: [118][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.2853 (0.2853) ([0.145]+[0.140])	Prec@1 94.531 (94.531)
Epoch: [118][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3230 (0.2749) ([0.183]+[0.140])	Prec@1 92.188 (95.390)
Epoch: [118][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3532 (0.2870) ([0.213]+[0.140])	Prec@1 92.969 (94.819)
Epoch: [118][300/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.2174 (0.2888) ([0.078]+[0.140])	Prec@1 96.875 (94.773)
Test: [0/79]	Time 0.156 (0.156)	Loss 0.3751 (0.3751) ([0.236]+[0.139])	Prec@1 92.188 (92.188)
 * Prec@1 90.330
current lr 1.00000e-02
Grad=  tensor(4.3252, device='cuda:0')
Epoch: [119][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.2714 (0.2714) ([0.132]+[0.139])	Prec@1 96.094 (96.094)
Epoch: [119][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.3170 (0.2785) ([0.178]+[0.139])	Prec@1 96.094 (95.374)
Epoch: [119][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2225 (0.2818) ([0.084]+[0.139])	Prec@1 96.875 (95.122)
Epoch: [119][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2409 (0.2827) ([0.103]+[0.138])	Prec@1 96.875 (95.022)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.2974 (0.2974) ([0.159]+[0.138])	Prec@1 92.188 (92.188)
 * Prec@1 89.710
current lr 1.00000e-02
Grad=  tensor(5.0186, device='cuda:0')
Epoch: [120][0/391]	Time 0.255 (0.255)	Data 0.135 (0.135)	Loss 0.2596 (0.2596) ([0.122]+[0.138])	Prec@1 94.531 (94.531)
Epoch: [120][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3078 (0.2789) ([0.170]+[0.138])	Prec@1 94.531 (95.080)
Epoch: [120][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2949 (0.2811) ([0.157]+[0.138])	Prec@1 95.312 (95.040)
Epoch: [120][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3202 (0.2834) ([0.183]+[0.137])	Prec@1 92.969 (94.915)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.3541 (0.3541) ([0.217]+[0.137])	Prec@1 93.750 (93.750)
 * Prec@1 90.790
current lr 1.00000e-02
Grad=  tensor(2.0222, device='cuda:0')
Epoch: [121][0/391]	Time 0.251 (0.251)	Data 0.131 (0.131)	Loss 0.1929 (0.1929) ([0.056]+[0.137])	Prec@1 98.438 (98.438)
Epoch: [121][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3008 (0.2735) ([0.164]+[0.137])	Prec@1 93.750 (95.328)
Epoch: [121][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3061 (0.2882) ([0.169]+[0.137])	Prec@1 96.094 (94.827)
Epoch: [121][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3370 (0.2869) ([0.200]+[0.136])	Prec@1 93.750 (94.887)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.4298 (0.4298) ([0.293]+[0.136])	Prec@1 92.188 (92.188)
 * Prec@1 90.090
current lr 1.00000e-02
Grad=  tensor(3.5599, device='cuda:0')
Epoch: [122][0/391]	Time 0.255 (0.255)	Data 0.135 (0.135)	Loss 0.2391 (0.2391) ([0.103]+[0.136])	Prec@1 96.875 (96.875)
Epoch: [122][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2522 (0.2789) ([0.116]+[0.136])	Prec@1 96.094 (95.243)
Epoch: [122][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3098 (0.2863) ([0.174]+[0.136])	Prec@1 92.969 (94.900)
Epoch: [122][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3244 (0.2884) ([0.189]+[0.136])	Prec@1 91.406 (94.762)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.4746 (0.4746) ([0.339]+[0.136])	Prec@1 92.188 (92.188)
 * Prec@1 89.710
current lr 1.00000e-02
Grad=  tensor(3.6770, device='cuda:0')
Epoch: [123][0/391]	Time 0.255 (0.255)	Data 0.135 (0.135)	Loss 0.2244 (0.2244) ([0.089]+[0.136])	Prec@1 98.438 (98.438)
Epoch: [123][100/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.2176 (0.2777) ([0.082]+[0.135])	Prec@1 96.875 (95.111)
Epoch: [123][200/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.2671 (0.2805) ([0.132]+[0.135])	Prec@1 94.531 (94.970)
Epoch: [123][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.3913 (0.2858) ([0.256]+[0.135])	Prec@1 90.625 (94.801)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.3331 (0.3331) ([0.198]+[0.135])	Prec@1 92.969 (92.969)
 * Prec@1 89.090
current lr 1.00000e-02
Grad=  tensor(2.4890, device='cuda:0')
Epoch: [124][0/391]	Time 0.255 (0.255)	Data 0.135 (0.135)	Loss 0.2056 (0.2056) ([0.071]+[0.135])	Prec@1 99.219 (99.219)
Epoch: [124][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2675 (0.2687) ([0.133]+[0.135])	Prec@1 95.312 (95.490)
Epoch: [124][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3071 (0.2749) ([0.173]+[0.135])	Prec@1 94.531 (95.200)
Epoch: [124][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2891 (0.2796) ([0.155]+[0.134])	Prec@1 95.312 (95.019)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.3638 (0.3638) ([0.229]+[0.134])	Prec@1 92.188 (92.188)
 * Prec@1 88.900
current lr 1.00000e-02
Grad=  tensor(4.0924, device='cuda:0')
Epoch: [125][0/391]	Time 0.252 (0.252)	Data 0.132 (0.132)	Loss 0.2496 (0.2496) ([0.115]+[0.134])	Prec@1 97.656 (97.656)
Epoch: [125][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2791 (0.2706) ([0.145]+[0.134])	Prec@1 96.094 (95.150)
Epoch: [125][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2845 (0.2804) ([0.150]+[0.134])	Prec@1 93.750 (94.811)
Epoch: [125][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.3476 (0.2835) ([0.214]+[0.134])	Prec@1 94.531 (94.850)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.2833 (0.2833) ([0.149]+[0.134])	Prec@1 95.312 (95.312)
 * Prec@1 89.680
current lr 1.00000e-02
Grad=  tensor(7.0078, device='cuda:0')
Epoch: [126][0/391]	Time 0.255 (0.255)	Data 0.132 (0.132)	Loss 0.2832 (0.2832) ([0.149]+[0.134])	Prec@1 96.094 (96.094)
Epoch: [126][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2550 (0.2802) ([0.121]+[0.134])	Prec@1 95.312 (95.026)
Epoch: [126][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2943 (0.2793) ([0.161]+[0.134])	Prec@1 95.312 (95.040)
Epoch: [126][300/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.3301 (0.2887) ([0.196]+[0.134])	Prec@1 92.969 (94.684)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3772 (0.3772) ([0.244]+[0.134])	Prec@1 92.969 (92.969)
 * Prec@1 89.540
current lr 1.00000e-02
Grad=  tensor(9.4942, device='cuda:0')
Epoch: [127][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 0.3129 (0.3129) ([0.179]+[0.134])	Prec@1 95.312 (95.312)
Epoch: [127][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2793 (0.2761) ([0.146]+[0.133])	Prec@1 95.312 (95.096)
Epoch: [127][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2519 (0.2764) ([0.119]+[0.133])	Prec@1 96.875 (95.138)
Epoch: [127][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3236 (0.2800) ([0.190]+[0.133])	Prec@1 91.406 (94.988)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3216 (0.3216) ([0.188]+[0.133])	Prec@1 92.969 (92.969)
 * Prec@1 89.870
current lr 1.00000e-02
Grad=  tensor(6.0513, device='cuda:0')
Epoch: [128][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.2823 (0.2823) ([0.149]+[0.133])	Prec@1 92.969 (92.969)
Epoch: [128][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2563 (0.2814) ([0.123]+[0.133])	Prec@1 95.312 (94.732)
Epoch: [128][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2925 (0.2859) ([0.159]+[0.133])	Prec@1 92.969 (94.531)
Epoch: [128][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2716 (0.2865) ([0.139]+[0.133])	Prec@1 92.969 (94.599)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.3698 (0.3698) ([0.237]+[0.133])	Prec@1 90.625 (90.625)
 * Prec@1 90.590
current lr 1.00000e-02
Grad=  tensor(5.2861, device='cuda:0')
Epoch: [129][0/391]	Time 0.253 (0.253)	Data 0.132 (0.132)	Loss 0.3074 (0.3074) ([0.174]+[0.133])	Prec@1 92.969 (92.969)
Epoch: [129][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3113 (0.2753) ([0.179]+[0.133])	Prec@1 94.531 (95.204)
Epoch: [129][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2729 (0.2751) ([0.140]+[0.133])	Prec@1 94.531 (95.270)
Epoch: [129][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3478 (0.2833) ([0.215]+[0.133])	Prec@1 92.969 (94.856)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.4574 (0.4574) ([0.325]+[0.133])	Prec@1 91.406 (91.406)
 * Prec@1 89.340
current lr 1.00000e-02
Grad=  tensor(2.7511, device='cuda:0')
Epoch: [130][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.2155 (0.2155) ([0.083]+[0.133])	Prec@1 97.656 (97.656)
Epoch: [130][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2097 (0.2680) ([0.077]+[0.132])	Prec@1 97.656 (95.467)
Epoch: [130][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3175 (0.2755) ([0.185]+[0.132])	Prec@1 93.750 (95.005)
Epoch: [130][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.4179 (0.2803) ([0.286]+[0.132])	Prec@1 89.844 (94.819)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.4524 (0.4524) ([0.320]+[0.132])	Prec@1 90.625 (90.625)
 * Prec@1 89.940
current lr 1.00000e-02
Grad=  tensor(6.9042, device='cuda:0')
Epoch: [131][0/391]	Time 0.250 (0.250)	Data 0.131 (0.131)	Loss 0.2437 (0.2437) ([0.111]+[0.132])	Prec@1 95.312 (95.312)
Epoch: [131][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.2051 (0.2711) ([0.073]+[0.132])	Prec@1 97.656 (95.312)
Epoch: [131][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2908 (0.2749) ([0.159]+[0.132])	Prec@1 93.750 (95.176)
Epoch: [131][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2609 (0.2749) ([0.129]+[0.132])	Prec@1 95.312 (95.131)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.4086 (0.4086) ([0.277]+[0.132])	Prec@1 90.625 (90.625)
 * Prec@1 89.590
current lr 1.00000e-02
Grad=  tensor(6.6313, device='cuda:0')
Epoch: [132][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.2984 (0.2984) ([0.166]+[0.132])	Prec@1 93.750 (93.750)
Epoch: [132][100/391]	Time 0.112 (0.113)	Data 0.000 (0.001)	Loss 0.3733 (0.2693) ([0.241]+[0.132])	Prec@1 92.188 (95.398)
Epoch: [132][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2956 (0.2735) ([0.164]+[0.132])	Prec@1 94.531 (95.254)
Epoch: [132][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2560 (0.2763) ([0.124]+[0.132])	Prec@1 96.094 (95.084)
Test: [0/79]	Time 0.159 (0.159)	Loss 0.3732 (0.3732) ([0.241]+[0.132])	Prec@1 92.969 (92.969)
 * Prec@1 90.010
current lr 1.00000e-02
Grad=  tensor(5.0323, device='cuda:0')
Epoch: [133][0/391]	Time 0.257 (0.257)	Data 0.134 (0.134)	Loss 0.2374 (0.2374) ([0.106]+[0.132])	Prec@1 96.094 (96.094)
Epoch: [133][100/391]	Time 0.110 (0.113)	Data 0.000 (0.001)	Loss 0.2825 (0.2763) ([0.151]+[0.132])	Prec@1 96.875 (95.057)
Epoch: [133][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2919 (0.2775) ([0.160]+[0.132])	Prec@1 94.531 (95.072)
Epoch: [133][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3083 (0.2820) ([0.177]+[0.132])	Prec@1 94.531 (94.874)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.3697 (0.3697) ([0.238]+[0.132])	Prec@1 92.188 (92.188)
 * Prec@1 89.490
current lr 1.00000e-02
Grad=  tensor(5.0357, device='cuda:0')
Epoch: [134][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.2436 (0.2436) ([0.112]+[0.132])	Prec@1 97.656 (97.656)
Epoch: [134][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2387 (0.2696) ([0.107]+[0.132])	Prec@1 96.094 (95.374)
Epoch: [134][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2215 (0.2742) ([0.090]+[0.132])	Prec@1 98.438 (95.134)
Epoch: [134][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2665 (0.2785) ([0.135]+[0.132])	Prec@1 94.531 (94.949)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3859 (0.3859) ([0.254]+[0.132])	Prec@1 94.531 (94.531)
 * Prec@1 89.380
current lr 1.00000e-02
Grad=  tensor(4.3185, device='cuda:0')
Epoch: [135][0/391]	Time 0.253 (0.253)	Data 0.131 (0.131)	Loss 0.2402 (0.2402) ([0.109]+[0.132])	Prec@1 95.312 (95.312)
Epoch: [135][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3223 (0.2760) ([0.191]+[0.132])	Prec@1 94.531 (94.933)
Epoch: [135][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2791 (0.2786) ([0.148]+[0.132])	Prec@1 96.094 (94.807)
Epoch: [135][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2259 (0.2783) ([0.094]+[0.131])	Prec@1 96.875 (94.850)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.3527 (0.3527) ([0.221]+[0.132])	Prec@1 92.969 (92.969)
 * Prec@1 89.870
current lr 1.00000e-02
Grad=  tensor(6.1400, device='cuda:0')
Epoch: [136][0/391]	Time 0.246 (0.246)	Data 0.125 (0.125)	Loss 0.2744 (0.2744) ([0.143]+[0.132])	Prec@1 94.531 (94.531)
Epoch: [136][100/391]	Time 0.113 (0.113)	Data 0.000 (0.001)	Loss 0.2655 (0.2756) ([0.134]+[0.132])	Prec@1 96.875 (94.972)
Epoch: [136][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2904 (0.2795) ([0.159]+[0.132])	Prec@1 92.188 (94.834)
Epoch: [136][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3981 (0.2785) ([0.267]+[0.132])	Prec@1 90.625 (94.884)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3576 (0.3576) ([0.226]+[0.132])	Prec@1 92.188 (92.188)
 * Prec@1 89.880
current lr 1.00000e-02
Grad=  tensor(7.1545, device='cuda:0')
Epoch: [137][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.2775 (0.2775) ([0.146]+[0.132])	Prec@1 96.875 (96.875)
Epoch: [137][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2594 (0.2747) ([0.128]+[0.132])	Prec@1 96.875 (95.119)
Epoch: [137][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2773 (0.2730) ([0.146]+[0.132])	Prec@1 94.531 (95.208)
Epoch: [137][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2600 (0.2806) ([0.128]+[0.132])	Prec@1 94.531 (94.900)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.3382 (0.3382) ([0.207]+[0.132])	Prec@1 92.188 (92.188)
 * Prec@1 90.370
current lr 1.00000e-02
Grad=  tensor(5.0100, device='cuda:0')
Epoch: [138][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.2245 (0.2245) ([0.093]+[0.132])	Prec@1 96.094 (96.094)
Epoch: [138][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2674 (0.2767) ([0.136]+[0.132])	Prec@1 96.875 (95.065)
Epoch: [138][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3056 (0.2734) ([0.174]+[0.131])	Prec@1 95.312 (95.134)
Epoch: [138][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2865 (0.2770) ([0.155]+[0.132])	Prec@1 94.531 (95.027)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.4270 (0.4270) ([0.295]+[0.132])	Prec@1 91.406 (91.406)
 * Prec@1 87.920
current lr 1.00000e-02
Grad=  tensor(5.0539, device='cuda:0')
Epoch: [139][0/391]	Time 0.253 (0.253)	Data 0.131 (0.131)	Loss 0.2619 (0.2619) ([0.130]+[0.132])	Prec@1 96.094 (96.094)
Epoch: [139][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.2591 (0.2759) ([0.127]+[0.132])	Prec@1 95.312 (95.080)
Epoch: [139][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3705 (0.2785) ([0.239]+[0.132])	Prec@1 89.844 (94.893)
Epoch: [139][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3123 (0.2824) ([0.181]+[0.132])	Prec@1 92.969 (94.783)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.4353 (0.4353) ([0.304]+[0.132])	Prec@1 89.062 (89.062)
 * Prec@1 89.190
current lr 1.00000e-02
Grad=  tensor(6.2297, device='cuda:0')
Epoch: [140][0/391]	Time 0.253 (0.253)	Data 0.131 (0.131)	Loss 0.2341 (0.2341) ([0.102]+[0.132])	Prec@1 96.094 (96.094)
Epoch: [140][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2592 (0.2642) ([0.128]+[0.131])	Prec@1 94.531 (95.359)
Epoch: [140][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2977 (0.2716) ([0.166]+[0.132])	Prec@1 96.094 (95.204)
Epoch: [140][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3920 (0.2773) ([0.260]+[0.132])	Prec@1 92.188 (94.941)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.4448 (0.4448) ([0.313]+[0.132])	Prec@1 90.625 (90.625)
 * Prec@1 89.500
current lr 1.00000e-02
Grad=  tensor(11.2058, device='cuda:0')
Epoch: [141][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 0.3894 (0.3894) ([0.258]+[0.132])	Prec@1 93.750 (93.750)
Epoch: [141][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.2519 (0.2744) ([0.120]+[0.132])	Prec@1 96.875 (94.887)
Epoch: [141][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2441 (0.2734) ([0.112]+[0.132])	Prec@1 97.656 (94.974)
Epoch: [141][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3174 (0.2803) ([0.186]+[0.132])	Prec@1 96.094 (94.848)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.5611 (0.5611) ([0.429]+[0.132])	Prec@1 85.156 (85.156)
 * Prec@1 89.420
current lr 1.00000e-02
Grad=  tensor(9.1047, device='cuda:0')
Epoch: [142][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.4157 (0.4157) ([0.284]+[0.132])	Prec@1 92.969 (92.969)
Epoch: [142][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2590 (0.2784) ([0.127]+[0.132])	Prec@1 96.094 (94.941)
Epoch: [142][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3568 (0.2765) ([0.225]+[0.132])	Prec@1 92.969 (95.068)
Epoch: [142][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3086 (0.2817) ([0.177]+[0.132])	Prec@1 92.969 (94.939)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.3791 (0.3791) ([0.247]+[0.132])	Prec@1 93.750 (93.750)
 * Prec@1 89.540
current lr 1.00000e-02
Grad=  tensor(8.4410, device='cuda:0')
Epoch: [143][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.2695 (0.2695) ([0.138]+[0.132])	Prec@1 93.750 (93.750)
Epoch: [143][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2515 (0.2679) ([0.120]+[0.132])	Prec@1 95.312 (95.297)
Epoch: [143][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.3181 (0.2730) ([0.186]+[0.132])	Prec@1 91.406 (95.134)
Epoch: [143][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3400 (0.2798) ([0.208]+[0.132])	Prec@1 92.969 (94.892)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.4708 (0.4708) ([0.339]+[0.132])	Prec@1 89.844 (89.844)
 * Prec@1 87.810
current lr 1.00000e-02
Grad=  tensor(7.8358, device='cuda:0')
Epoch: [144][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.2735 (0.2735) ([0.141]+[0.132])	Prec@1 96.094 (96.094)
Epoch: [144][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2649 (0.2673) ([0.133]+[0.132])	Prec@1 96.094 (95.514)
Epoch: [144][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3329 (0.2689) ([0.201]+[0.132])	Prec@1 91.406 (95.367)
Epoch: [144][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2472 (0.2735) ([0.115]+[0.132])	Prec@1 95.312 (95.162)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.4347 (0.4347) ([0.303]+[0.132])	Prec@1 90.625 (90.625)
 * Prec@1 88.160
current lr 1.00000e-02
Grad=  tensor(7.4045, device='cuda:0')
Epoch: [145][0/391]	Time 0.255 (0.255)	Data 0.133 (0.133)	Loss 0.2605 (0.2605) ([0.128]+[0.132])	Prec@1 94.531 (94.531)
Epoch: [145][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.2386 (0.2719) ([0.107]+[0.132])	Prec@1 95.312 (94.817)
Epoch: [145][200/391]	Time 0.109 (0.112)	Data 0.000 (0.001)	Loss 0.2873 (0.2732) ([0.155]+[0.132])	Prec@1 93.750 (94.935)
Epoch: [145][300/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.2495 (0.2792) ([0.117]+[0.132])	Prec@1 94.531 (94.767)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.3379 (0.3379) ([0.206]+[0.132])	Prec@1 92.188 (92.188)
 * Prec@1 88.860
current lr 1.00000e-02
Grad=  tensor(4.6582, device='cuda:0')
Epoch: [146][0/391]	Time 0.256 (0.256)	Data 0.132 (0.132)	Loss 0.2165 (0.2165) ([0.084]+[0.132])	Prec@1 97.656 (97.656)
Epoch: [146][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.3024 (0.2666) ([0.170]+[0.132])	Prec@1 93.750 (95.606)
Epoch: [146][200/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.3652 (0.2758) ([0.233]+[0.132])	Prec@1 93.750 (95.250)
Epoch: [146][300/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.3413 (0.2786) ([0.209]+[0.132])	Prec@1 92.188 (95.053)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.3485 (0.3485) ([0.216]+[0.132])	Prec@1 92.188 (92.188)
 * Prec@1 89.950
current lr 1.00000e-02
Grad=  tensor(11.3286, device='cuda:0')
Epoch: [147][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.2827 (0.2827) ([0.150]+[0.132])	Prec@1 94.531 (94.531)
Epoch: [147][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.2358 (0.2667) ([0.104]+[0.132])	Prec@1 96.875 (95.351)
Epoch: [147][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2696 (0.2732) ([0.137]+[0.132])	Prec@1 96.094 (95.114)
Epoch: [147][300/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.2650 (0.2767) ([0.133]+[0.132])	Prec@1 95.312 (95.032)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.4232 (0.4232) ([0.291]+[0.132])	Prec@1 90.625 (90.625)
 * Prec@1 89.440
current lr 1.00000e-02
Grad=  tensor(5.5351, device='cuda:0')
Epoch: [148][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.2968 (0.2968) ([0.164]+[0.132])	Prec@1 96.875 (96.875)
Epoch: [148][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2659 (0.2820) ([0.134]+[0.132])	Prec@1 95.312 (94.903)
Epoch: [148][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2689 (0.2826) ([0.136]+[0.132])	Prec@1 95.312 (94.776)
Epoch: [148][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2793 (0.2821) ([0.147]+[0.132])	Prec@1 95.312 (94.858)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.3224 (0.3224) ([0.190]+[0.132])	Prec@1 96.875 (96.875)
 * Prec@1 89.280
current lr 1.00000e-02
Grad=  tensor(5.0235, device='cuda:0')
Epoch: [149][0/391]	Time 0.255 (0.255)	Data 0.132 (0.132)	Loss 0.2224 (0.2224) ([0.090]+[0.132])	Prec@1 96.094 (96.094)
Epoch: [149][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.2740 (0.2695) ([0.142]+[0.132])	Prec@1 96.094 (95.312)
Epoch: [149][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.3055 (0.2690) ([0.173]+[0.132])	Prec@1 93.750 (95.382)
Epoch: [149][300/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2827 (0.2721) ([0.150]+[0.132])	Prec@1 94.531 (95.242)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3767 (0.3767) ([0.244]+[0.132])	Prec@1 92.188 (92.188)
 * Prec@1 89.120
current lr 1.00000e-02
Grad=  tensor(9.8112, device='cuda:0')
Epoch: [150][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 0.3062 (0.3062) ([0.174]+[0.132])	Prec@1 94.531 (94.531)
Epoch: [150][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2560 (0.2728) ([0.124]+[0.132])	Prec@1 93.750 (95.204)
Epoch: [150][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1973 (0.2774) ([0.065]+[0.133])	Prec@1 98.438 (95.037)
Epoch: [150][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2294 (0.2745) ([0.097]+[0.132])	Prec@1 97.656 (95.196)
Test: [0/79]	Time 0.157 (0.157)	Loss 0.5248 (0.5248) ([0.392]+[0.132])	Prec@1 90.625 (90.625)
 * Prec@1 88.620
current lr 1.00000e-02
Grad=  tensor(7.6324, device='cuda:0')
Epoch: [151][0/391]	Time 0.256 (0.256)	Data 0.135 (0.135)	Loss 0.2646 (0.2646) ([0.132]+[0.132])	Prec@1 96.094 (96.094)
Epoch: [151][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2460 (0.2541) ([0.114]+[0.132])	Prec@1 97.656 (95.900)
Epoch: [151][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2421 (0.2688) ([0.110]+[0.132])	Prec@1 96.875 (95.417)
Epoch: [151][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2369 (0.2728) ([0.104]+[0.133])	Prec@1 97.656 (95.219)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.4307 (0.4307) ([0.298]+[0.133])	Prec@1 89.844 (89.844)
 * Prec@1 89.240
current lr 1.00000e-02
Grad=  tensor(7.5271, device='cuda:0')
Epoch: [152][0/391]	Time 0.249 (0.249)	Data 0.128 (0.128)	Loss 0.2693 (0.2693) ([0.137]+[0.133])	Prec@1 94.531 (94.531)
Epoch: [152][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3181 (0.2785) ([0.185]+[0.133])	Prec@1 93.750 (95.050)
Epoch: [152][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2903 (0.2734) ([0.158]+[0.133])	Prec@1 94.531 (95.141)
Epoch: [152][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2357 (0.2770) ([0.103]+[0.133])	Prec@1 96.875 (94.972)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.4140 (0.4140) ([0.281]+[0.133])	Prec@1 91.406 (91.406)
 * Prec@1 89.810
current lr 1.00000e-02
Grad=  tensor(5.1762, device='cuda:0')
Epoch: [153][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.2441 (0.2441) ([0.111]+[0.133])	Prec@1 96.094 (96.094)
Epoch: [153][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2479 (0.2659) ([0.115]+[0.133])	Prec@1 96.094 (95.444)
Epoch: [153][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2674 (0.2662) ([0.135]+[0.133])	Prec@1 94.531 (95.491)
Epoch: [153][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3747 (0.2734) ([0.242]+[0.133])	Prec@1 91.406 (95.224)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3595 (0.3595) ([0.226]+[0.133])	Prec@1 94.531 (94.531)
 * Prec@1 90.030
current lr 1.00000e-02
Grad=  tensor(9.6729, device='cuda:0')
Epoch: [154][0/391]	Time 0.253 (0.253)	Data 0.131 (0.131)	Loss 0.2935 (0.2935) ([0.160]+[0.133])	Prec@1 94.531 (94.531)
Epoch: [154][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2426 (0.2574) ([0.110]+[0.133])	Prec@1 96.094 (95.715)
Epoch: [154][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3023 (0.2600) ([0.169]+[0.133])	Prec@1 94.531 (95.592)
Epoch: [154][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2601 (0.2689) ([0.127]+[0.133])	Prec@1 95.312 (95.351)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.4913 (0.4913) ([0.358]+[0.133])	Prec@1 88.281 (88.281)
 * Prec@1 88.640
current lr 1.00000e-02
Grad=  tensor(9.3688, device='cuda:0')
Epoch: [155][0/391]	Time 0.252 (0.252)	Data 0.129 (0.129)	Loss 0.3076 (0.3076) ([0.174]+[0.133])	Prec@1 94.531 (94.531)
Epoch: [155][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2362 (0.2807) ([0.103]+[0.133])	Prec@1 96.875 (94.825)
Epoch: [155][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2473 (0.2777) ([0.114]+[0.133])	Prec@1 96.875 (94.978)
Epoch: [155][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2715 (0.2751) ([0.138]+[0.133])	Prec@1 96.094 (95.074)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.2742 (0.2742) ([0.141]+[0.133])	Prec@1 96.094 (96.094)
 * Prec@1 89.410
current lr 1.00000e-02
Grad=  tensor(4.2078, device='cuda:0')
Epoch: [156][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.2218 (0.2218) ([0.088]+[0.133])	Prec@1 96.875 (96.875)
Epoch: [156][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2250 (0.2596) ([0.092]+[0.133])	Prec@1 97.656 (95.761)
Epoch: [156][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2358 (0.2639) ([0.103]+[0.133])	Prec@1 99.219 (95.515)
Epoch: [156][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2359 (0.2702) ([0.103]+[0.133])	Prec@1 94.531 (95.346)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3645 (0.3645) ([0.231]+[0.133])	Prec@1 93.750 (93.750)
 * Prec@1 89.980
current lr 1.00000e-02
Grad=  tensor(10.0014, device='cuda:0')
Epoch: [157][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.2902 (0.2902) ([0.157]+[0.133])	Prec@1 94.531 (94.531)
Epoch: [157][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3605 (0.2595) ([0.227]+[0.133])	Prec@1 89.062 (95.668)
Epoch: [157][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2441 (0.2642) ([0.111]+[0.133])	Prec@1 96.094 (95.561)
Epoch: [157][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2459 (0.2699) ([0.113]+[0.133])	Prec@1 96.094 (95.362)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.4234 (0.4234) ([0.290]+[0.134])	Prec@1 91.406 (91.406)
 * Prec@1 88.970
current lr 1.00000e-02
Grad=  tensor(6.7891, device='cuda:0')
Epoch: [158][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 0.2638 (0.2638) ([0.130]+[0.134])	Prec@1 93.750 (93.750)
Epoch: [158][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2703 (0.2604) ([0.137]+[0.133])	Prec@1 95.312 (95.676)
Epoch: [158][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1990 (0.2639) ([0.066]+[0.133])	Prec@1 97.656 (95.670)
Epoch: [158][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3040 (0.2672) ([0.171]+[0.133])	Prec@1 94.531 (95.556)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.3810 (0.3810) ([0.248]+[0.133])	Prec@1 93.750 (93.750)
 * Prec@1 89.110
current lr 1.00000e-02
Grad=  tensor(3.2435, device='cuda:0')
Epoch: [159][0/391]	Time 0.256 (0.256)	Data 0.130 (0.130)	Loss 0.2106 (0.2106) ([0.077]+[0.133])	Prec@1 98.438 (98.438)
Epoch: [159][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2413 (0.2616) ([0.108]+[0.133])	Prec@1 96.094 (95.653)
Epoch: [159][200/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.2763 (0.2657) ([0.143]+[0.133])	Prec@1 94.531 (95.522)
Epoch: [159][300/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.2595 (0.2684) ([0.126]+[0.134])	Prec@1 94.531 (95.416)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.5346 (0.5346) ([0.401]+[0.134])	Prec@1 89.062 (89.062)
 * Prec@1 87.960
current lr 1.00000e-02
Grad=  tensor(10.2071, device='cuda:0')
Epoch: [160][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.2751 (0.2751) ([0.141]+[0.134])	Prec@1 93.750 (93.750)
Epoch: [160][100/391]	Time 0.115 (0.112)	Data 0.000 (0.001)	Loss 0.2814 (0.2643) ([0.148]+[0.134])	Prec@1 95.312 (95.506)
Epoch: [160][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2337 (0.2626) ([0.100]+[0.134])	Prec@1 97.656 (95.441)
Epoch: [160][300/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2719 (0.2703) ([0.138]+[0.134])	Prec@1 96.094 (95.206)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.3209 (0.3209) ([0.187]+[0.134])	Prec@1 93.750 (93.750)
 * Prec@1 89.800
current lr 1.00000e-02
Grad=  tensor(6.8479, device='cuda:0')
Epoch: [161][0/391]	Time 0.253 (0.253)	Data 0.132 (0.132)	Loss 0.2453 (0.2453) ([0.112]+[0.134])	Prec@1 96.875 (96.875)
Epoch: [161][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2343 (0.2664) ([0.101]+[0.134])	Prec@1 97.656 (95.529)
Epoch: [161][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2779 (0.2726) ([0.144]+[0.134])	Prec@1 96.094 (95.180)
Epoch: [161][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2880 (0.2738) ([0.154]+[0.134])	Prec@1 95.312 (95.123)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.4342 (0.4342) ([0.300]+[0.134])	Prec@1 90.625 (90.625)
 * Prec@1 88.140
current lr 1.00000e-02
Grad=  tensor(7.4901, device='cuda:0')
Epoch: [162][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.2500 (0.2500) ([0.116]+[0.134])	Prec@1 96.875 (96.875)
Epoch: [162][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.2854 (0.2749) ([0.152]+[0.134])	Prec@1 93.750 (95.127)
Epoch: [162][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3206 (0.2711) ([0.187]+[0.134])	Prec@1 93.750 (95.200)
Epoch: [162][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2944 (0.2730) ([0.160]+[0.134])	Prec@1 96.094 (95.141)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.3164 (0.3164) ([0.182]+[0.134])	Prec@1 93.750 (93.750)
 * Prec@1 90.660
current lr 1.00000e-02
Grad=  tensor(8.0949, device='cuda:0')
Epoch: [163][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.3332 (0.3332) ([0.199]+[0.134])	Prec@1 95.312 (95.312)
Epoch: [163][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2902 (0.2680) ([0.156]+[0.134])	Prec@1 93.750 (95.390)
Epoch: [163][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2461 (0.2676) ([0.112]+[0.134])	Prec@1 96.094 (95.309)
Epoch: [163][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2833 (0.2675) ([0.149]+[0.134])	Prec@1 94.531 (95.323)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.4207 (0.4207) ([0.287]+[0.134])	Prec@1 89.062 (89.062)
 * Prec@1 88.810
current lr 1.00000e-02
Grad=  tensor(6.7637, device='cuda:0')
Epoch: [164][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.2706 (0.2706) ([0.136]+[0.134])	Prec@1 95.312 (95.312)
Epoch: [164][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2021 (0.2541) ([0.068]+[0.134])	Prec@1 97.656 (95.939)
Epoch: [164][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2592 (0.2643) ([0.125]+[0.134])	Prec@1 95.312 (95.503)
Epoch: [164][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2510 (0.2681) ([0.117]+[0.134])	Prec@1 95.312 (95.398)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.4262 (0.4262) ([0.292]+[0.134])	Prec@1 92.188 (92.188)
 * Prec@1 90.150
current lr 1.00000e-02
Grad=  tensor(4.9502, device='cuda:0')
Epoch: [165][0/391]	Time 0.253 (0.253)	Data 0.132 (0.132)	Loss 0.2281 (0.2281) ([0.094]+[0.134])	Prec@1 97.656 (97.656)
Epoch: [165][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2309 (0.2612) ([0.097]+[0.134])	Prec@1 96.094 (95.746)
Epoch: [165][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2900 (0.2627) ([0.156]+[0.134])	Prec@1 95.312 (95.658)
Epoch: [165][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2200 (0.2656) ([0.086]+[0.134])	Prec@1 96.875 (95.481)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.4012 (0.4012) ([0.267]+[0.134])	Prec@1 90.625 (90.625)
 * Prec@1 89.560
current lr 1.00000e-02
Grad=  tensor(7.0943, device='cuda:0')
Epoch: [166][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.2248 (0.2248) ([0.091]+[0.134])	Prec@1 96.875 (96.875)
Epoch: [166][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3037 (0.2536) ([0.170]+[0.134])	Prec@1 94.531 (95.831)
Epoch: [166][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1999 (0.2578) ([0.066]+[0.134])	Prec@1 99.219 (95.697)
Epoch: [166][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2288 (0.2618) ([0.095]+[0.134])	Prec@1 97.656 (95.569)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3339 (0.3339) ([0.200]+[0.134])	Prec@1 92.188 (92.188)
 * Prec@1 89.660
current lr 1.00000e-02
Grad=  tensor(4.8403, device='cuda:0')
Epoch: [167][0/391]	Time 0.255 (0.255)	Data 0.131 (0.131)	Loss 0.2416 (0.2416) ([0.107]+[0.134])	Prec@1 97.656 (97.656)
Epoch: [167][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3454 (0.2636) ([0.211]+[0.134])	Prec@1 92.188 (95.707)
Epoch: [167][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3875 (0.2683) ([0.253]+[0.134])	Prec@1 90.625 (95.449)
Epoch: [167][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2266 (0.2698) ([0.092]+[0.134])	Prec@1 96.094 (95.370)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.4690 (0.4690) ([0.335]+[0.134])	Prec@1 89.844 (89.844)
 * Prec@1 89.600
current lr 1.00000e-02
Grad=  tensor(8.6916, device='cuda:0')
Epoch: [168][0/391]	Time 0.249 (0.249)	Data 0.126 (0.126)	Loss 0.2837 (0.2837) ([0.149]+[0.134])	Prec@1 95.312 (95.312)
Epoch: [168][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2576 (0.2645) ([0.123]+[0.134])	Prec@1 95.312 (95.661)
Epoch: [168][200/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.2943 (0.2685) ([0.160]+[0.134])	Prec@1 95.312 (95.484)
Epoch: [168][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2133 (0.2688) ([0.079]+[0.134])	Prec@1 97.656 (95.486)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.4087 (0.4087) ([0.274]+[0.134])	Prec@1 92.969 (92.969)
 * Prec@1 89.650
current lr 1.00000e-02
Grad=  tensor(7.8963, device='cuda:0')
Epoch: [169][0/391]	Time 0.253 (0.253)	Data 0.131 (0.131)	Loss 0.2848 (0.2848) ([0.150]+[0.134])	Prec@1 95.312 (95.312)
Epoch: [169][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2013 (0.2559) ([0.067]+[0.134])	Prec@1 97.656 (95.916)
Epoch: [169][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2519 (0.2587) ([0.118]+[0.134])	Prec@1 97.656 (95.728)
Epoch: [169][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3641 (0.2626) ([0.230]+[0.134])	Prec@1 92.969 (95.577)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.4466 (0.4466) ([0.312]+[0.134])	Prec@1 92.188 (92.188)
 * Prec@1 89.840
current lr 1.00000e-02
Grad=  tensor(5.7389, device='cuda:0')
Epoch: [170][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.2478 (0.2478) ([0.113]+[0.134])	Prec@1 95.312 (95.312)
Epoch: [170][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3095 (0.2619) ([0.175]+[0.134])	Prec@1 93.750 (95.552)
Epoch: [170][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2869 (0.2627) ([0.153]+[0.134])	Prec@1 95.312 (95.627)
Epoch: [170][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2871 (0.2617) ([0.153]+[0.134])	Prec@1 95.312 (95.676)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3792 (0.3792) ([0.245]+[0.134])	Prec@1 93.750 (93.750)
 * Prec@1 89.460
current lr 1.00000e-02
Grad=  tensor(4.5654, device='cuda:0')
Epoch: [171][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.2023 (0.2023) ([0.068]+[0.134])	Prec@1 99.219 (99.219)
Epoch: [171][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2148 (0.2619) ([0.081]+[0.134])	Prec@1 98.438 (95.692)
Epoch: [171][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2428 (0.2686) ([0.108]+[0.134])	Prec@1 96.875 (95.398)
Epoch: [171][300/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2376 (0.2685) ([0.103]+[0.134])	Prec@1 95.312 (95.380)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.4375 (0.4375) ([0.303]+[0.135])	Prec@1 91.406 (91.406)
 * Prec@1 89.710
current lr 1.00000e-02
Grad=  tensor(3.8543, device='cuda:0')
Epoch: [172][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 0.2187 (0.2187) ([0.084]+[0.135])	Prec@1 98.438 (98.438)
Epoch: [172][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2018 (0.2633) ([0.067]+[0.134])	Prec@1 97.656 (95.545)
Epoch: [172][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2811 (0.2642) ([0.147]+[0.135])	Prec@1 96.094 (95.526)
Epoch: [172][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2501 (0.2674) ([0.115]+[0.135])	Prec@1 96.094 (95.403)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.4647 (0.4647) ([0.330]+[0.135])	Prec@1 92.188 (92.188)
 * Prec@1 87.850
current lr 1.00000e-02
Grad=  tensor(3.1456, device='cuda:0')
Epoch: [173][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.1959 (0.1959) ([0.061]+[0.135])	Prec@1 99.219 (99.219)
Epoch: [173][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3640 (0.2642) ([0.229]+[0.135])	Prec@1 90.625 (95.599)
Epoch: [173][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2941 (0.2647) ([0.159]+[0.135])	Prec@1 95.312 (95.550)
Epoch: [173][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2737 (0.2711) ([0.139]+[0.135])	Prec@1 96.875 (95.258)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.4211 (0.4211) ([0.286]+[0.135])	Prec@1 93.750 (93.750)
 * Prec@1 89.900
current lr 1.00000e-02
Grad=  tensor(9.7162, device='cuda:0')
Epoch: [174][0/391]	Time 0.253 (0.253)	Data 0.132 (0.132)	Loss 0.3000 (0.3000) ([0.165]+[0.135])	Prec@1 94.531 (94.531)
Epoch: [174][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2340 (0.2643) ([0.099]+[0.135])	Prec@1 96.094 (95.429)
Epoch: [174][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2459 (0.2657) ([0.111]+[0.135])	Prec@1 96.094 (95.456)
Epoch: [174][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2716 (0.2694) ([0.137]+[0.135])	Prec@1 95.312 (95.338)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.2884 (0.2884) ([0.153]+[0.135])	Prec@1 95.312 (95.312)
 * Prec@1 89.640
current lr 1.00000e-02
Grad=  tensor(3.8498, device='cuda:0')
Epoch: [175][0/391]	Time 0.255 (0.255)	Data 0.133 (0.133)	Loss 0.2218 (0.2218) ([0.087]+[0.135])	Prec@1 97.656 (97.656)
Epoch: [175][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2703 (0.2603) ([0.135]+[0.135])	Prec@1 94.531 (95.730)
Epoch: [175][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3128 (0.2616) ([0.178]+[0.135])	Prec@1 94.531 (95.588)
Epoch: [175][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2001 (0.2624) ([0.065]+[0.135])	Prec@1 99.219 (95.580)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.3105 (0.3105) ([0.175]+[0.135])	Prec@1 91.406 (91.406)
 * Prec@1 89.390
current lr 1.00000e-02
Grad=  tensor(6.0181, device='cuda:0')
Epoch: [176][0/391]	Time 0.255 (0.255)	Data 0.134 (0.134)	Loss 0.2161 (0.2161) ([0.081]+[0.135])	Prec@1 96.875 (96.875)
Epoch: [176][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2907 (0.2641) ([0.156]+[0.135])	Prec@1 94.531 (95.545)
Epoch: [176][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2658 (0.2582) ([0.131]+[0.135])	Prec@1 96.094 (95.732)
Epoch: [176][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2590 (0.2651) ([0.124]+[0.135])	Prec@1 94.531 (95.499)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3846 (0.3846) ([0.250]+[0.135])	Prec@1 89.062 (89.062)
 * Prec@1 90.090
current lr 1.00000e-02
Grad=  tensor(4.0349, device='cuda:0')
Epoch: [177][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.2231 (0.2231) ([0.088]+[0.135])	Prec@1 97.656 (97.656)
Epoch: [177][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2106 (0.2555) ([0.076]+[0.135])	Prec@1 99.219 (95.738)
Epoch: [177][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2833 (0.2592) ([0.148]+[0.135])	Prec@1 95.312 (95.662)
Epoch: [177][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3184 (0.2612) ([0.183]+[0.135])	Prec@1 92.969 (95.598)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.4494 (0.4494) ([0.314]+[0.135])	Prec@1 92.969 (92.969)
 * Prec@1 89.770
current lr 1.00000e-02
Grad=  tensor(8.9636, device='cuda:0')
Epoch: [178][0/391]	Time 0.252 (0.252)	Data 0.129 (0.129)	Loss 0.2647 (0.2647) ([0.130]+[0.135])	Prec@1 93.750 (93.750)
Epoch: [178][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2268 (0.2475) ([0.092]+[0.135])	Prec@1 97.656 (96.194)
Epoch: [178][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3205 (0.2575) ([0.186]+[0.135])	Prec@1 93.750 (95.818)
Epoch: [178][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2775 (0.2605) ([0.143]+[0.135])	Prec@1 94.531 (95.710)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.3276 (0.3276) ([0.193]+[0.135])	Prec@1 94.531 (94.531)
 * Prec@1 89.270
current lr 1.00000e-02
Grad=  tensor(6.6035, device='cuda:0')
Epoch: [179][0/391]	Time 0.253 (0.253)	Data 0.130 (0.130)	Loss 0.2421 (0.2421) ([0.107]+[0.135])	Prec@1 96.875 (96.875)
Epoch: [179][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2048 (0.2601) ([0.070]+[0.135])	Prec@1 97.656 (95.753)
Epoch: [179][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2638 (0.2610) ([0.129]+[0.135])	Prec@1 96.875 (95.635)
Epoch: [179][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2594 (0.2616) ([0.124]+[0.135])	Prec@1 95.312 (95.608)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.3827 (0.3827) ([0.248]+[0.135])	Prec@1 91.406 (91.406)
 * Prec@1 89.800
current lr 1.00000e-02
Grad=  tensor(4.7694, device='cuda:0')
Epoch: [180][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 0.2165 (0.2165) ([0.081]+[0.135])	Prec@1 96.875 (96.875)
Epoch: [180][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.2807 (0.2547) ([0.146]+[0.135])	Prec@1 93.750 (95.823)
Epoch: [180][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3904 (0.2634) ([0.255]+[0.135])	Prec@1 93.750 (95.503)
Epoch: [180][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3264 (0.2659) ([0.191]+[0.135])	Prec@1 94.531 (95.427)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.3510 (0.3510) ([0.216]+[0.135])	Prec@1 90.625 (90.625)
 * Prec@1 89.350
current lr 1.00000e-02
Grad=  tensor(6.5806, device='cuda:0')
Epoch: [181][0/391]	Time 0.248 (0.248)	Data 0.129 (0.129)	Loss 0.2353 (0.2353) ([0.100]+[0.135])	Prec@1 95.312 (95.312)
Epoch: [181][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3167 (0.2584) ([0.182]+[0.135])	Prec@1 92.969 (95.815)
Epoch: [181][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3469 (0.2658) ([0.212]+[0.135])	Prec@1 92.188 (95.522)
Epoch: [181][300/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.2297 (0.2640) ([0.094]+[0.135])	Prec@1 96.094 (95.564)
Test: [0/79]	Time 0.181 (0.181)	Loss 0.4385 (0.4385) ([0.303]+[0.135])	Prec@1 91.406 (91.406)
 * Prec@1 90.200
current lr 1.00000e-02
Grad=  tensor(3.9450, device='cuda:0')
Epoch: [182][0/391]	Time 0.281 (0.281)	Data 0.156 (0.156)	Loss 0.2161 (0.2161) ([0.081]+[0.135])	Prec@1 96.875 (96.875)
Epoch: [182][100/391]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.2150 (0.2549) ([0.080]+[0.135])	Prec@1 95.312 (96.101)
Epoch: [182][200/391]	Time 0.114 (0.114)	Data 0.000 (0.001)	Loss 0.2167 (0.2554) ([0.082]+[0.135])	Prec@1 97.656 (96.043)
Epoch: [182][300/391]	Time 0.113 (0.114)	Data 0.000 (0.001)	Loss 0.2302 (0.2600) ([0.095]+[0.135])	Prec@1 96.875 (95.832)
Test: [0/79]	Time 0.178 (0.178)	Loss 0.3435 (0.3435) ([0.208]+[0.135])	Prec@1 93.750 (93.750)
 * Prec@1 89.120
current lr 1.00000e-02
Grad=  tensor(3.8148, device='cuda:0')
Epoch: [183][0/391]	Time 0.274 (0.274)	Data 0.151 (0.151)	Loss 0.2054 (0.2054) ([0.070]+[0.135])	Prec@1 97.656 (97.656)
Epoch: [183][100/391]	Time 0.111 (0.113)	Data 0.000 (0.002)	Loss 0.2013 (0.2479) ([0.066]+[0.135])	Prec@1 98.438 (96.179)
Epoch: [183][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2563 (0.2551) ([0.121]+[0.135])	Prec@1 95.312 (95.861)
Epoch: [183][300/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3151 (0.2626) ([0.180]+[0.135])	Prec@1 93.750 (95.541)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.4871 (0.4871) ([0.352]+[0.135])	Prec@1 89.062 (89.062)
 * Prec@1 89.280
current lr 1.00000e-02
Grad=  tensor(6.1419, device='cuda:0')
Epoch: [184][0/391]	Time 0.244 (0.244)	Data 0.123 (0.123)	Loss 0.2275 (0.2275) ([0.092]+[0.135])	Prec@1 96.875 (96.875)
Epoch: [184][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3531 (0.2651) ([0.218]+[0.135])	Prec@1 92.188 (95.483)
Epoch: [184][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2504 (0.2616) ([0.115]+[0.135])	Prec@1 96.875 (95.651)
Epoch: [184][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2678 (0.2624) ([0.133]+[0.135])	Prec@1 93.750 (95.645)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.3809 (0.3809) ([0.246]+[0.135])	Prec@1 91.406 (91.406)
 * Prec@1 89.090
current lr 1.00000e-02
Grad=  tensor(8.7128, device='cuda:0')
Epoch: [185][0/391]	Time 0.248 (0.248)	Data 0.126 (0.126)	Loss 0.2534 (0.2534) ([0.118]+[0.135])	Prec@1 95.312 (95.312)
Epoch: [185][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2371 (0.2439) ([0.102]+[0.135])	Prec@1 96.094 (96.218)
Epoch: [185][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2886 (0.2565) ([0.153]+[0.135])	Prec@1 92.969 (95.771)
Epoch: [185][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2734 (0.2574) ([0.138]+[0.135])	Prec@1 95.312 (95.689)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.4846 (0.4846) ([0.349]+[0.135])	Prec@1 92.188 (92.188)
 * Prec@1 88.510
current lr 1.00000e-02
Grad=  tensor(9.5791, device='cuda:0')
Epoch: [186][0/391]	Time 0.253 (0.253)	Data 0.132 (0.132)	Loss 0.2918 (0.2918) ([0.156]+[0.135])	Prec@1 94.531 (94.531)
Epoch: [186][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1718 (0.2603) ([0.036]+[0.135])	Prec@1 100.000 (95.815)
Epoch: [186][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2689 (0.2595) ([0.134]+[0.135])	Prec@1 96.094 (95.748)
Epoch: [186][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3034 (0.2628) ([0.168]+[0.135])	Prec@1 94.531 (95.640)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.4180 (0.4180) ([0.283]+[0.135])	Prec@1 92.188 (92.188)
 * Prec@1 89.770
current lr 1.00000e-02
Grad=  tensor(5.7729, device='cuda:0')
Epoch: [187][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.2157 (0.2157) ([0.080]+[0.135])	Prec@1 97.656 (97.656)
Epoch: [187][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2168 (0.2578) ([0.081]+[0.135])	Prec@1 98.438 (95.753)
Epoch: [187][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2969 (0.2590) ([0.161]+[0.135])	Prec@1 92.969 (95.787)
Epoch: [187][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3339 (0.2608) ([0.199]+[0.135])	Prec@1 93.750 (95.741)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.3940 (0.3940) ([0.259]+[0.135])	Prec@1 90.625 (90.625)
 * Prec@1 89.250
current lr 1.00000e-02
Grad=  tensor(10.3242, device='cuda:0')
Epoch: [188][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.2877 (0.2877) ([0.152]+[0.135])	Prec@1 96.094 (96.094)
Epoch: [188][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2735 (0.2462) ([0.138]+[0.135])	Prec@1 94.531 (96.187)
Epoch: [188][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2793 (0.2520) ([0.144]+[0.135])	Prec@1 94.531 (96.012)
Epoch: [188][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2898 (0.2563) ([0.154]+[0.135])	Prec@1 95.312 (95.863)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.5807 (0.5807) ([0.445]+[0.136])	Prec@1 89.062 (89.062)
 * Prec@1 87.730
current lr 1.00000e-02
Grad=  tensor(4.5008, device='cuda:0')
Epoch: [189][0/391]	Time 0.253 (0.253)	Data 0.132 (0.132)	Loss 0.2100 (0.2100) ([0.074]+[0.136])	Prec@1 98.438 (98.438)
Epoch: [189][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2199 (0.2486) ([0.085]+[0.135])	Prec@1 97.656 (96.179)
Epoch: [189][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2222 (0.2497) ([0.087]+[0.135])	Prec@1 99.219 (96.133)
Epoch: [189][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2903 (0.2537) ([0.155]+[0.135])	Prec@1 95.312 (95.985)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3268 (0.3268) ([0.191]+[0.135])	Prec@1 94.531 (94.531)
 * Prec@1 89.990
current lr 1.00000e-02
Grad=  tensor(7.0130, device='cuda:0')
Epoch: [190][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.2283 (0.2283) ([0.093]+[0.135])	Prec@1 96.094 (96.094)
Epoch: [190][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3007 (0.2545) ([0.165]+[0.135])	Prec@1 94.531 (95.939)
Epoch: [190][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2001 (0.2506) ([0.065]+[0.135])	Prec@1 98.438 (96.171)
Epoch: [190][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2492 (0.2559) ([0.114]+[0.135])	Prec@1 96.875 (95.896)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.3163 (0.3163) ([0.181]+[0.136])	Prec@1 92.969 (92.969)
 * Prec@1 89.260
current lr 1.00000e-02
Grad=  tensor(10.0672, device='cuda:0')
Epoch: [191][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.2750 (0.2750) ([0.139]+[0.136])	Prec@1 95.312 (95.312)
Epoch: [191][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2629 (0.2559) ([0.127]+[0.136])	Prec@1 95.312 (95.838)
Epoch: [191][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2791 (0.2595) ([0.143]+[0.136])	Prec@1 95.312 (95.759)
Epoch: [191][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2578 (0.2630) ([0.122]+[0.136])	Prec@1 95.312 (95.577)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.3904 (0.3904) ([0.254]+[0.136])	Prec@1 92.969 (92.969)
 * Prec@1 88.630
current lr 1.00000e-02
Grad=  tensor(5.0529, device='cuda:0')
Epoch: [192][0/391]	Time 0.249 (0.249)	Data 0.127 (0.127)	Loss 0.2406 (0.2406) ([0.105]+[0.136])	Prec@1 97.656 (97.656)
Epoch: [192][100/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2288 (0.2427) ([0.093]+[0.136])	Prec@1 96.875 (96.403)
Epoch: [192][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2295 (0.2471) ([0.094]+[0.136])	Prec@1 96.094 (96.249)
Epoch: [192][300/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.2496 (0.2510) ([0.114]+[0.136])	Prec@1 95.312 (96.029)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.5060 (0.5060) ([0.370]+[0.136])	Prec@1 89.062 (89.062)
 * Prec@1 88.020
current lr 1.00000e-02
Grad=  tensor(7.7115, device='cuda:0')
Epoch: [193][0/391]	Time 0.256 (0.256)	Data 0.135 (0.135)	Loss 0.2368 (0.2368) ([0.101]+[0.136])	Prec@1 95.312 (95.312)
Epoch: [193][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3100 (0.2461) ([0.174]+[0.136])	Prec@1 92.188 (96.295)
Epoch: [193][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2772 (0.2528) ([0.142]+[0.136])	Prec@1 94.531 (96.020)
Epoch: [193][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3124 (0.2587) ([0.177]+[0.136])	Prec@1 93.750 (95.793)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.3778 (0.3778) ([0.242]+[0.136])	Prec@1 93.750 (93.750)
 * Prec@1 89.610
current lr 1.00000e-02
Grad=  tensor(17.1967, device='cuda:0')
Epoch: [194][0/391]	Time 0.256 (0.256)	Data 0.134 (0.134)	Loss 0.3210 (0.3210) ([0.185]+[0.136])	Prec@1 92.969 (92.969)
Epoch: [194][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2449 (0.2629) ([0.109]+[0.136])	Prec@1 96.094 (95.653)
Epoch: [194][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2783 (0.2603) ([0.143]+[0.136])	Prec@1 94.531 (95.759)
Epoch: [194][300/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2710 (0.2592) ([0.135]+[0.136])	Prec@1 94.531 (95.775)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.3889 (0.3889) ([0.253]+[0.136])	Prec@1 90.625 (90.625)
 * Prec@1 90.850
current lr 1.00000e-02
Grad=  tensor(5.2010, device='cuda:0')
Epoch: [195][0/391]	Time 0.255 (0.255)	Data 0.133 (0.133)	Loss 0.2385 (0.2385) ([0.103]+[0.136])	Prec@1 96.094 (96.094)
Epoch: [195][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.2287 (0.2453) ([0.093]+[0.136])	Prec@1 98.438 (96.450)
Epoch: [195][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2221 (0.2482) ([0.086]+[0.136])	Prec@1 97.656 (96.288)
Epoch: [195][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2753 (0.2553) ([0.140]+[0.136])	Prec@1 96.094 (96.018)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.4412 (0.4412) ([0.305]+[0.136])	Prec@1 89.844 (89.844)
 * Prec@1 88.780
current lr 1.00000e-02
Grad=  tensor(10.4349, device='cuda:0')
Epoch: [196][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.2765 (0.2765) ([0.141]+[0.136])	Prec@1 96.094 (96.094)
Epoch: [196][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2209 (0.2562) ([0.085]+[0.136])	Prec@1 96.875 (95.947)
Epoch: [196][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2540 (0.2636) ([0.118]+[0.136])	Prec@1 96.875 (95.651)
Epoch: [196][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2679 (0.2644) ([0.132]+[0.136])	Prec@1 95.312 (95.616)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.2992 (0.2992) ([0.163]+[0.136])	Prec@1 92.969 (92.969)
 * Prec@1 90.190
current lr 1.00000e-02
Grad=  tensor(10.3511, device='cuda:0')
Epoch: [197][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 0.2854 (0.2854) ([0.149]+[0.136])	Prec@1 95.312 (95.312)
Epoch: [197][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2436 (0.2469) ([0.108]+[0.136])	Prec@1 97.656 (96.349)
Epoch: [197][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2574 (0.2497) ([0.122]+[0.136])	Prec@1 95.312 (96.156)
Epoch: [197][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2736 (0.2544) ([0.138]+[0.136])	Prec@1 94.531 (95.961)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3803 (0.3803) ([0.245]+[0.136])	Prec@1 91.406 (91.406)
 * Prec@1 90.090
current lr 1.00000e-02
Grad=  tensor(8.5776, device='cuda:0')
Epoch: [198][0/391]	Time 0.251 (0.251)	Data 0.131 (0.131)	Loss 0.2520 (0.2520) ([0.116]+[0.136])	Prec@1 96.094 (96.094)
Epoch: [198][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2434 (0.2474) ([0.108]+[0.136])	Prec@1 96.875 (96.187)
Epoch: [198][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3161 (0.2513) ([0.180]+[0.136])	Prec@1 92.188 (96.024)
Epoch: [198][300/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.2378 (0.2570) ([0.102]+[0.136])	Prec@1 96.875 (95.829)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.3934 (0.3934) ([0.257]+[0.136])	Prec@1 91.406 (91.406)
 * Prec@1 90.060
current lr 1.00000e-02
Grad=  tensor(3.8004, device='cuda:0')
Epoch: [199][0/391]	Time 0.253 (0.253)	Data 0.132 (0.132)	Loss 0.1967 (0.1967) ([0.061]+[0.136])	Prec@1 96.875 (96.875)
Epoch: [199][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2492 (0.2494) ([0.113]+[0.136])	Prec@1 96.094 (96.094)
Epoch: [199][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2233 (0.2536) ([0.087]+[0.136])	Prec@1 97.656 (95.981)
Epoch: [199][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2832 (0.2569) ([0.147]+[0.136])	Prec@1 96.094 (95.884)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.4091 (0.4091) ([0.273]+[0.136])	Prec@1 91.406 (91.406)
 * Prec@1 89.170
current lr 1.00000e-02
Grad=  tensor(8.0489, device='cuda:0')
Epoch: [200][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.2559 (0.2559) ([0.120]+[0.136])	Prec@1 96.094 (96.094)
Epoch: [200][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2744 (0.2487) ([0.138]+[0.136])	Prec@1 93.750 (96.225)
Epoch: [200][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2826 (0.2511) ([0.147]+[0.136])	Prec@1 96.094 (96.140)
Epoch: [200][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2142 (0.2575) ([0.078]+[0.136])	Prec@1 96.875 (95.873)
Test: [0/79]	Time 0.159 (0.159)	Loss 0.4045 (0.4045) ([0.269]+[0.136])	Prec@1 92.188 (92.188)
 * Prec@1 88.430
current lr 1.00000e-02
Grad=  tensor(10.5416, device='cuda:0')
Epoch: [201][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.2807 (0.2807) ([0.145]+[0.136])	Prec@1 95.312 (95.312)
Epoch: [201][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2858 (0.2555) ([0.150]+[0.136])	Prec@1 96.094 (95.993)
Epoch: [201][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1844 (0.2540) ([0.049]+[0.136])	Prec@1 99.219 (96.008)
Epoch: [201][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2795 (0.2565) ([0.144]+[0.136])	Prec@1 92.969 (95.884)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.3612 (0.3612) ([0.225]+[0.136])	Prec@1 92.188 (92.188)
 * Prec@1 89.850
current lr 1.00000e-02
Grad=  tensor(9.2872, device='cuda:0')
Epoch: [202][0/391]	Time 0.253 (0.253)	Data 0.131 (0.131)	Loss 0.2372 (0.2372) ([0.101]+[0.136])	Prec@1 96.094 (96.094)
Epoch: [202][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.1905 (0.2425) ([0.055]+[0.136])	Prec@1 99.219 (96.341)
Epoch: [202][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2932 (0.2492) ([0.157]+[0.136])	Prec@1 95.312 (96.000)
Epoch: [202][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2598 (0.2506) ([0.124]+[0.136])	Prec@1 96.094 (95.969)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.4525 (0.4525) ([0.317]+[0.136])	Prec@1 89.844 (89.844)
 * Prec@1 88.200
current lr 1.00000e-02
Grad=  tensor(11.7747, device='cuda:0')
Epoch: [203][0/391]	Time 0.249 (0.249)	Data 0.127 (0.127)	Loss 0.3023 (0.3023) ([0.166]+[0.136])	Prec@1 93.750 (93.750)
Epoch: [203][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2565 (0.2411) ([0.121]+[0.136])	Prec@1 96.094 (96.388)
Epoch: [203][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3146 (0.2510) ([0.179]+[0.136])	Prec@1 93.750 (95.969)
Epoch: [203][300/391]	Time 0.114 (0.112)	Data 0.000 (0.001)	Loss 0.2756 (0.2552) ([0.140]+[0.136])	Prec@1 96.875 (95.873)
Test: [0/79]	Time 0.177 (0.177)	Loss 0.3808 (0.3808) ([0.245]+[0.136])	Prec@1 90.625 (90.625)
 * Prec@1 89.840
current lr 1.00000e-02
Grad=  tensor(7.0289, device='cuda:0')
Epoch: [204][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.2354 (0.2354) ([0.099]+[0.136])	Prec@1 96.875 (96.875)
Epoch: [204][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.2351 (0.2438) ([0.099]+[0.136])	Prec@1 96.875 (96.372)
Epoch: [204][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2739 (0.2496) ([0.138]+[0.136])	Prec@1 93.750 (96.121)
Epoch: [204][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2538 (0.2575) ([0.118]+[0.136])	Prec@1 95.312 (95.821)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3550 (0.3550) ([0.219]+[0.136])	Prec@1 92.969 (92.969)
 * Prec@1 90.300
current lr 1.00000e-02
Grad=  tensor(4.3358, device='cuda:0')
Epoch: [205][0/391]	Time 0.253 (0.253)	Data 0.132 (0.132)	Loss 0.2239 (0.2239) ([0.088]+[0.136])	Prec@1 96.875 (96.875)
Epoch: [205][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2187 (0.2422) ([0.083]+[0.136])	Prec@1 96.875 (96.218)
Epoch: [205][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2773 (0.2504) ([0.141]+[0.136])	Prec@1 96.094 (96.051)
Epoch: [205][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2374 (0.2541) ([0.101]+[0.136])	Prec@1 93.750 (95.899)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.4407 (0.4407) ([0.304]+[0.136])	Prec@1 92.188 (92.188)
 * Prec@1 90.110
current lr 1.00000e-02
Grad=  tensor(5.4375, device='cuda:0')
Epoch: [206][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.2186 (0.2186) ([0.082]+[0.136])	Prec@1 96.875 (96.875)
Epoch: [206][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2260 (0.2501) ([0.090]+[0.136])	Prec@1 97.656 (96.140)
Epoch: [206][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3006 (0.2486) ([0.165]+[0.136])	Prec@1 92.969 (96.245)
Epoch: [206][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2237 (0.2549) ([0.087]+[0.136])	Prec@1 96.875 (96.021)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.4057 (0.4057) ([0.269]+[0.136])	Prec@1 91.406 (91.406)
 * Prec@1 89.310
current lr 1.00000e-02
Grad=  tensor(9.7870, device='cuda:0')
Epoch: [207][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.2884 (0.2884) ([0.152]+[0.136])	Prec@1 92.969 (92.969)
Epoch: [207][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1865 (0.2529) ([0.050]+[0.136])	Prec@1 97.656 (96.009)
Epoch: [207][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2574 (0.2539) ([0.121]+[0.136])	Prec@1 93.750 (95.958)
Epoch: [207][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2776 (0.2540) ([0.141]+[0.136])	Prec@1 94.531 (95.902)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3433 (0.3433) ([0.207]+[0.136])	Prec@1 91.406 (91.406)
 * Prec@1 89.400
current lr 1.00000e-02
Grad=  tensor(8.7798, device='cuda:0')
Epoch: [208][0/391]	Time 0.259 (0.259)	Data 0.136 (0.136)	Loss 0.2543 (0.2543) ([0.118]+[0.136])	Prec@1 96.094 (96.094)
Epoch: [208][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.3636 (0.2472) ([0.227]+[0.136])	Prec@1 92.969 (96.341)
Epoch: [208][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3380 (0.2490) ([0.202]+[0.136])	Prec@1 92.188 (96.152)
Epoch: [208][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2373 (0.2550) ([0.101]+[0.136])	Prec@1 96.094 (95.920)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.3352 (0.3352) ([0.199]+[0.136])	Prec@1 92.188 (92.188)
 * Prec@1 90.220
current lr 1.00000e-02
Grad=  tensor(12.1194, device='cuda:0')
Epoch: [209][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.2758 (0.2758) ([0.139]+[0.136])	Prec@1 92.969 (92.969)
Epoch: [209][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2796 (0.2652) ([0.143]+[0.137])	Prec@1 94.531 (95.606)
Epoch: [209][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2177 (0.2623) ([0.081]+[0.137])	Prec@1 97.656 (95.725)
Epoch: [209][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2697 (0.2614) ([0.133]+[0.136])	Prec@1 95.312 (95.673)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.3091 (0.3091) ([0.172]+[0.137])	Prec@1 93.750 (93.750)
 * Prec@1 89.430
current lr 1.00000e-02
Grad=  tensor(12.3336, device='cuda:0')
Epoch: [210][0/391]	Time 0.260 (0.260)	Data 0.138 (0.138)	Loss 0.2816 (0.2816) ([0.145]+[0.137])	Prec@1 92.969 (92.969)
Epoch: [210][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1904 (0.2498) ([0.054]+[0.137])	Prec@1 99.219 (96.171)
Epoch: [210][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2112 (0.2480) ([0.075]+[0.137])	Prec@1 96.875 (96.179)
Epoch: [210][300/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.2964 (0.2544) ([0.160]+[0.137])	Prec@1 96.094 (95.959)
Test: [0/79]	Time 0.175 (0.175)	Loss 0.4704 (0.4704) ([0.334]+[0.137])	Prec@1 90.625 (90.625)
 * Prec@1 88.870
current lr 1.00000e-02
Grad=  tensor(10.5600, device='cuda:0')
Epoch: [211][0/391]	Time 0.273 (0.273)	Data 0.148 (0.148)	Loss 0.2875 (0.2875) ([0.151]+[0.137])	Prec@1 95.312 (95.312)
Epoch: [211][100/391]	Time 0.111 (0.113)	Data 0.000 (0.002)	Loss 0.2630 (0.2457) ([0.126]+[0.137])	Prec@1 94.531 (96.094)
Epoch: [211][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2068 (0.2452) ([0.070]+[0.136])	Prec@1 98.438 (96.191)
Epoch: [211][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2267 (0.2502) ([0.090]+[0.137])	Prec@1 96.875 (95.993)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.3939 (0.3939) ([0.257]+[0.137])	Prec@1 91.406 (91.406)
 * Prec@1 89.070
current lr 1.00000e-02
Grad=  tensor(7.2973, device='cuda:0')
Epoch: [212][0/391]	Time 0.255 (0.255)	Data 0.131 (0.131)	Loss 0.2179 (0.2179) ([0.081]+[0.137])	Prec@1 96.875 (96.875)
Epoch: [212][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2309 (0.2625) ([0.094]+[0.137])	Prec@1 96.094 (95.630)
Epoch: [212][200/391]	Time 0.114 (0.113)	Data 0.000 (0.001)	Loss 0.2947 (0.2611) ([0.158]+[0.137])	Prec@1 92.188 (95.682)
Epoch: [212][300/391]	Time 0.112 (0.113)	Data 0.000 (0.001)	Loss 0.2776 (0.2622) ([0.141]+[0.137])	Prec@1 94.531 (95.665)
Test: [0/79]	Time 0.185 (0.185)	Loss 0.3804 (0.3804) ([0.244]+[0.137])	Prec@1 92.188 (92.188)
 * Prec@1 89.040
current lr 1.00000e-02
Grad=  tensor(6.9396, device='cuda:0')
Epoch: [213][0/391]	Time 0.272 (0.272)	Data 0.149 (0.149)	Loss 0.2122 (0.2122) ([0.076]+[0.137])	Prec@1 98.438 (98.438)
Epoch: [213][100/391]	Time 0.115 (0.115)	Data 0.000 (0.002)	Loss 0.2299 (0.2485) ([0.093]+[0.137])	Prec@1 97.656 (96.040)
Epoch: [213][200/391]	Time 0.114 (0.114)	Data 0.000 (0.001)	Loss 0.2399 (0.2515) ([0.103]+[0.137])	Prec@1 96.875 (95.973)
Epoch: [213][300/391]	Time 0.115 (0.114)	Data 0.000 (0.001)	Loss 0.2652 (0.2529) ([0.129]+[0.137])	Prec@1 96.094 (95.972)
Test: [0/79]	Time 0.180 (0.180)	Loss 0.4294 (0.4294) ([0.293]+[0.137])	Prec@1 90.625 (90.625)
 * Prec@1 89.720
current lr 1.00000e-02
Grad=  tensor(5.0291, device='cuda:0')
Epoch: [214][0/391]	Time 0.273 (0.273)	Data 0.149 (0.149)	Loss 0.2214 (0.2214) ([0.085]+[0.137])	Prec@1 96.875 (96.875)
Epoch: [214][100/391]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.2075 (0.2371) ([0.071]+[0.137])	Prec@1 96.094 (96.566)
Epoch: [214][200/391]	Time 0.116 (0.114)	Data 0.000 (0.001)	Loss 0.3249 (0.2418) ([0.188]+[0.136])	Prec@1 92.188 (96.432)
Epoch: [214][300/391]	Time 0.118 (0.114)	Data 0.000 (0.001)	Loss 0.1988 (0.2455) ([0.062]+[0.136])	Prec@1 98.438 (96.314)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.3734 (0.3734) ([0.237]+[0.136])	Prec@1 90.625 (90.625)
 * Prec@1 89.940
current lr 1.00000e-02
Grad=  tensor(9.0496, device='cuda:0')
Epoch: [215][0/391]	Time 0.260 (0.260)	Data 0.136 (0.136)	Loss 0.2505 (0.2505) ([0.114]+[0.136])	Prec@1 95.312 (95.312)
Epoch: [215][100/391]	Time 0.114 (0.115)	Data 0.000 (0.001)	Loss 0.2462 (0.2329) ([0.110]+[0.136])	Prec@1 96.094 (96.744)
Epoch: [215][200/391]	Time 0.114 (0.114)	Data 0.000 (0.001)	Loss 0.2094 (0.2419) ([0.073]+[0.136])	Prec@1 97.656 (96.358)
Epoch: [215][300/391]	Time 0.114 (0.114)	Data 0.000 (0.001)	Loss 0.2174 (0.2456) ([0.081]+[0.136])	Prec@1 96.875 (96.247)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.3553 (0.3553) ([0.219]+[0.136])	Prec@1 92.969 (92.969)
 * Prec@1 86.630
current lr 1.00000e-02
Grad=  tensor(13.1554, device='cuda:0')
Epoch: [216][0/391]	Time 0.257 (0.257)	Data 0.135 (0.135)	Loss 0.2806 (0.2806) ([0.144]+[0.136])	Prec@1 93.750 (93.750)
Epoch: [216][100/391]	Time 0.113 (0.114)	Data 0.000 (0.001)	Loss 0.2484 (0.2530) ([0.112]+[0.136])	Prec@1 97.656 (96.094)
Epoch: [216][200/391]	Time 0.115 (0.113)	Data 0.000 (0.001)	Loss 0.2186 (0.2515) ([0.082]+[0.136])	Prec@1 96.875 (96.090)
Epoch: [216][300/391]	Time 0.114 (0.114)	Data 0.000 (0.001)	Loss 0.2751 (0.2549) ([0.139]+[0.136])	Prec@1 94.531 (95.964)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.3474 (0.3474) ([0.211]+[0.137])	Prec@1 93.750 (93.750)
 * Prec@1 90.250
current lr 1.00000e-02
Grad=  tensor(7.4853, device='cuda:0')
Epoch: [217][0/391]	Time 0.258 (0.258)	Data 0.134 (0.134)	Loss 0.2371 (0.2371) ([0.101]+[0.137])	Prec@1 95.312 (95.312)
Epoch: [217][100/391]	Time 0.111 (0.114)	Data 0.000 (0.001)	Loss 0.2814 (0.2454) ([0.145]+[0.136])	Prec@1 94.531 (96.318)
Epoch: [217][200/391]	Time 0.115 (0.113)	Data 0.000 (0.001)	Loss 0.3091 (0.2511) ([0.173]+[0.136])	Prec@1 93.750 (96.109)
Epoch: [217][300/391]	Time 0.114 (0.114)	Data 0.000 (0.001)	Loss 0.2453 (0.2527) ([0.109]+[0.136])	Prec@1 96.094 (96.060)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.3774 (0.3774) ([0.241]+[0.136])	Prec@1 92.969 (92.969)
 * Prec@1 90.190
current lr 1.00000e-02
Grad=  tensor(9.8711, device='cuda:0')
Epoch: [218][0/391]	Time 0.258 (0.258)	Data 0.136 (0.136)	Loss 0.2796 (0.2796) ([0.143]+[0.136])	Prec@1 95.312 (95.312)
Epoch: [218][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2623 (0.2452) ([0.126]+[0.136])	Prec@1 97.656 (96.372)
Epoch: [218][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2341 (0.2441) ([0.098]+[0.136])	Prec@1 95.312 (96.397)
Epoch: [218][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2807 (0.2454) ([0.144]+[0.136])	Prec@1 95.312 (96.366)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.4365 (0.4365) ([0.300]+[0.136])	Prec@1 92.969 (92.969)
 * Prec@1 90.140
current lr 1.00000e-02
Grad=  tensor(7.0911, device='cuda:0')
Epoch: [219][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.2215 (0.2215) ([0.085]+[0.136])	Prec@1 96.875 (96.875)
Epoch: [219][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2244 (0.2447) ([0.088]+[0.136])	Prec@1 96.094 (96.380)
Epoch: [219][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2252 (0.2496) ([0.089]+[0.136])	Prec@1 96.875 (96.117)
Epoch: [219][300/391]	Time 0.108 (0.111)	Data 0.000 (0.001)	Loss 0.1928 (0.2537) ([0.056]+[0.136])	Prec@1 98.438 (95.980)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.3993 (0.3993) ([0.263]+[0.137])	Prec@1 89.844 (89.844)
 * Prec@1 88.530
current lr 1.00000e-02
Grad=  tensor(6.2092, device='cuda:0')
Epoch: [220][0/391]	Time 0.249 (0.249)	Data 0.129 (0.129)	Loss 0.2239 (0.2239) ([0.087]+[0.137])	Prec@1 96.875 (96.875)
Epoch: [220][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2478 (0.2470) ([0.111]+[0.136])	Prec@1 96.094 (96.411)
Epoch: [220][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3883 (0.2533) ([0.252]+[0.136])	Prec@1 92.969 (96.109)
Epoch: [220][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2803 (0.2570) ([0.144]+[0.137])	Prec@1 92.969 (95.993)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3439 (0.3439) ([0.207]+[0.136])	Prec@1 94.531 (94.531)
 * Prec@1 90.640
current lr 1.00000e-02
Grad=  tensor(9.4699, device='cuda:0')
Epoch: [221][0/391]	Time 0.250 (0.250)	Data 0.131 (0.131)	Loss 0.2384 (0.2384) ([0.102]+[0.136])	Prec@1 94.531 (94.531)
Epoch: [221][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.1970 (0.2390) ([0.061]+[0.136])	Prec@1 96.875 (96.279)
Epoch: [221][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2588 (0.2429) ([0.122]+[0.136])	Prec@1 96.094 (96.253)
Epoch: [221][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2981 (0.2491) ([0.162]+[0.136])	Prec@1 96.094 (96.037)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.3078 (0.3078) ([0.172]+[0.136])	Prec@1 94.531 (94.531)
 * Prec@1 89.480
current lr 1.00000e-02
Grad=  tensor(5.1945, device='cuda:0')
Epoch: [222][0/391]	Time 0.250 (0.250)	Data 0.130 (0.130)	Loss 0.2314 (0.2314) ([0.095]+[0.136])	Prec@1 97.656 (97.656)
Epoch: [222][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2143 (0.2407) ([0.078]+[0.136])	Prec@1 97.656 (96.372)
Epoch: [222][200/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.2217 (0.2433) ([0.086]+[0.136])	Prec@1 97.656 (96.350)
Epoch: [222][300/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.2741 (0.2524) ([0.138]+[0.136])	Prec@1 95.312 (96.024)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.3072 (0.3072) ([0.171]+[0.136])	Prec@1 94.531 (94.531)
 * Prec@1 90.790
current lr 1.00000e-02
Grad=  tensor(8.3047, device='cuda:0')
Epoch: [223][0/391]	Time 0.258 (0.258)	Data 0.131 (0.131)	Loss 0.2392 (0.2392) ([0.103]+[0.136])	Prec@1 95.312 (95.312)
Epoch: [223][100/391]	Time 0.112 (0.113)	Data 0.000 (0.001)	Loss 0.1990 (0.2462) ([0.063]+[0.136])	Prec@1 98.438 (96.171)
Epoch: [223][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2747 (0.2503) ([0.138]+[0.136])	Prec@1 95.312 (96.051)
Epoch: [223][300/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.2179 (0.2535) ([0.081]+[0.136])	Prec@1 96.875 (95.969)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.4996 (0.4996) ([0.363]+[0.136])	Prec@1 88.281 (88.281)
 * Prec@1 90.060
current lr 1.00000e-02
Grad=  tensor(12.1857, device='cuda:0')
Epoch: [224][0/391]	Time 0.253 (0.253)	Data 0.132 (0.132)	Loss 0.2890 (0.2890) ([0.153]+[0.136])	Prec@1 94.531 (94.531)
Epoch: [224][100/391]	Time 0.112 (0.113)	Data 0.000 (0.001)	Loss 0.2220 (0.2570) ([0.085]+[0.137])	Prec@1 98.438 (95.877)
Epoch: [224][200/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.3528 (0.2564) ([0.216]+[0.137])	Prec@1 95.312 (95.915)
Epoch: [224][300/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2792 (0.2564) ([0.143]+[0.137])	Prec@1 94.531 (95.933)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3723 (0.3723) ([0.236]+[0.137])	Prec@1 92.969 (92.969)
 * Prec@1 90.320
current lr 1.00000e-02
Grad=  tensor(6.9631, device='cuda:0')
Epoch: [225][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.2406 (0.2406) ([0.104]+[0.137])	Prec@1 96.875 (96.875)
Epoch: [225][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2513 (0.2455) ([0.115]+[0.137])	Prec@1 93.750 (96.279)
Epoch: [225][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2815 (0.2485) ([0.145]+[0.137])	Prec@1 94.531 (96.148)
Epoch: [225][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2488 (0.2511) ([0.112]+[0.137])	Prec@1 96.094 (96.099)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3866 (0.3866) ([0.250]+[0.137])	Prec@1 89.062 (89.062)
 * Prec@1 89.650
current lr 1.00000e-02
Grad=  tensor(5.5973, device='cuda:0')
Epoch: [226][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.2372 (0.2372) ([0.100]+[0.137])	Prec@1 97.656 (97.656)
Epoch: [226][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2452 (0.2492) ([0.108]+[0.137])	Prec@1 96.094 (96.202)
Epoch: [226][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2286 (0.2473) ([0.092]+[0.137])	Prec@1 97.656 (96.319)
Epoch: [226][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2272 (0.2487) ([0.091]+[0.137])	Prec@1 97.656 (96.211)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.3446 (0.3446) ([0.208]+[0.137])	Prec@1 92.969 (92.969)
 * Prec@1 88.980
current lr 1.00000e-02
Grad=  tensor(13.8583, device='cuda:0')
Epoch: [227][0/391]	Time 0.253 (0.253)	Data 0.131 (0.131)	Loss 0.3083 (0.3083) ([0.171]+[0.137])	Prec@1 93.750 (93.750)
Epoch: [227][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2522 (0.2411) ([0.116]+[0.137])	Prec@1 96.875 (96.450)
Epoch: [227][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2554 (0.2431) ([0.119]+[0.136])	Prec@1 95.312 (96.273)
Epoch: [227][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2387 (0.2457) ([0.102]+[0.136])	Prec@1 95.312 (96.159)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.4042 (0.4042) ([0.268]+[0.137])	Prec@1 90.625 (90.625)
 * Prec@1 89.880
current lr 1.00000e-02
Grad=  tensor(10.6736, device='cuda:0')
Epoch: [228][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.2505 (0.2505) ([0.114]+[0.137])	Prec@1 95.312 (95.312)
Epoch: [228][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.2033 (0.2397) ([0.067]+[0.137])	Prec@1 97.656 (96.465)
Epoch: [228][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1819 (0.2392) ([0.046]+[0.136])	Prec@1 99.219 (96.510)
Epoch: [228][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2491 (0.2437) ([0.113]+[0.136])	Prec@1 96.094 (96.314)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.3713 (0.3713) ([0.235]+[0.136])	Prec@1 88.281 (88.281)
 * Prec@1 87.070
current lr 1.00000e-02
Grad=  tensor(14.4453, device='cuda:0')
Epoch: [229][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.3079 (0.3079) ([0.171]+[0.136])	Prec@1 93.750 (93.750)
Epoch: [229][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2463 (0.2515) ([0.110]+[0.136])	Prec@1 97.656 (96.334)
Epoch: [229][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3027 (0.2508) ([0.166]+[0.136])	Prec@1 92.969 (96.284)
Epoch: [229][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2647 (0.2530) ([0.128]+[0.137])	Prec@1 97.656 (96.169)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3306 (0.3306) ([0.194]+[0.137])	Prec@1 93.750 (93.750)
 * Prec@1 89.180
current lr 1.00000e-02
Grad=  tensor(6.3320, device='cuda:0')
Epoch: [230][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.2235 (0.2235) ([0.087]+[0.137])	Prec@1 96.875 (96.875)
Epoch: [230][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.2369 (0.2527) ([0.100]+[0.137])	Prec@1 96.094 (96.187)
Epoch: [230][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2899 (0.2496) ([0.153]+[0.137])	Prec@1 92.969 (96.206)
Epoch: [230][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1963 (0.2485) ([0.060]+[0.136])	Prec@1 98.438 (96.185)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3672 (0.3672) ([0.231]+[0.137])	Prec@1 93.750 (93.750)
 * Prec@1 89.660
current lr 1.00000e-02
Grad=  tensor(10.8230, device='cuda:0')
Epoch: [231][0/391]	Time 0.255 (0.255)	Data 0.133 (0.133)	Loss 0.2830 (0.2830) ([0.146]+[0.137])	Prec@1 96.875 (96.875)
Epoch: [231][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2937 (0.2442) ([0.157]+[0.137])	Prec@1 95.312 (96.334)
Epoch: [231][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2712 (0.2512) ([0.134]+[0.137])	Prec@1 94.531 (96.090)
Epoch: [231][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2782 (0.2544) ([0.141]+[0.137])	Prec@1 95.312 (95.969)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.5421 (0.5421) ([0.405]+[0.137])	Prec@1 88.281 (88.281)
 * Prec@1 88.040
current lr 1.00000e-02
Grad=  tensor(7.6702, device='cuda:0')
Epoch: [232][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.2455 (0.2455) ([0.109]+[0.137])	Prec@1 96.875 (96.875)
Epoch: [232][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2207 (0.2480) ([0.084]+[0.137])	Prec@1 95.312 (96.187)
Epoch: [232][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2412 (0.2489) ([0.104]+[0.137])	Prec@1 95.312 (96.183)
Epoch: [232][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2860 (0.2538) ([0.149]+[0.137])	Prec@1 93.750 (96.013)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.4309 (0.4309) ([0.294]+[0.137])	Prec@1 93.750 (93.750)
 * Prec@1 89.960
current lr 1.00000e-02
Grad=  tensor(3.3176, device='cuda:0')
Epoch: [233][0/391]	Time 0.253 (0.253)	Data 0.131 (0.131)	Loss 0.1980 (0.1980) ([0.061]+[0.137])	Prec@1 97.656 (97.656)
Epoch: [233][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2185 (0.2306) ([0.082]+[0.137])	Prec@1 96.094 (96.906)
Epoch: [233][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2776 (0.2358) ([0.141]+[0.137])	Prec@1 92.969 (96.653)
Epoch: [233][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2786 (0.2444) ([0.142]+[0.137])	Prec@1 96.094 (96.358)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.3726 (0.3726) ([0.236]+[0.137])	Prec@1 92.188 (92.188)
 * Prec@1 88.910
current lr 1.00000e-02
Grad=  tensor(6.6298, device='cuda:0')
Epoch: [234][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.2208 (0.2208) ([0.084]+[0.137])	Prec@1 96.875 (96.875)
Epoch: [234][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2304 (0.2489) ([0.094]+[0.137])	Prec@1 96.094 (96.326)
Epoch: [234][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3081 (0.2488) ([0.171]+[0.137])	Prec@1 92.969 (96.323)
Epoch: [234][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1821 (0.2496) ([0.045]+[0.137])	Prec@1 99.219 (96.260)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.3922 (0.3922) ([0.255]+[0.137])	Prec@1 88.281 (88.281)
 * Prec@1 90.060
current lr 1.00000e-02
Grad=  tensor(2.2640, device='cuda:0')
Epoch: [235][0/391]	Time 0.252 (0.252)	Data 0.132 (0.132)	Loss 0.1779 (0.1779) ([0.041]+[0.137])	Prec@1 99.219 (99.219)
Epoch: [235][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2120 (0.2439) ([0.075]+[0.137])	Prec@1 98.438 (96.372)
Epoch: [235][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2404 (0.2488) ([0.104]+[0.137])	Prec@1 97.656 (96.210)
Epoch: [235][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1828 (0.2552) ([0.046]+[0.137])	Prec@1 99.219 (95.964)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.3994 (0.3994) ([0.262]+[0.137])	Prec@1 89.062 (89.062)
 * Prec@1 89.740
current lr 1.00000e-02
Grad=  tensor(13.1478, device='cuda:0')
Epoch: [236][0/391]	Time 0.253 (0.253)	Data 0.132 (0.132)	Loss 0.2889 (0.2889) ([0.152]+[0.137])	Prec@1 95.312 (95.312)
Epoch: [236][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.2216 (0.2416) ([0.085]+[0.137])	Prec@1 96.875 (96.419)
Epoch: [236][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2824 (0.2494) ([0.145]+[0.137])	Prec@1 95.312 (96.129)
Epoch: [236][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2798 (0.2508) ([0.143]+[0.137])	Prec@1 94.531 (96.065)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.4402 (0.4402) ([0.303]+[0.137])	Prec@1 92.188 (92.188)
 * Prec@1 89.740
current lr 1.00000e-02
Grad=  tensor(3.7057, device='cuda:0')
Epoch: [237][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.2091 (0.2091) ([0.072]+[0.137])	Prec@1 99.219 (99.219)
Epoch: [237][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2219 (0.2446) ([0.085]+[0.137])	Prec@1 96.875 (96.326)
Epoch: [237][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2228 (0.2483) ([0.086]+[0.137])	Prec@1 97.656 (96.214)
Epoch: [237][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2707 (0.2483) ([0.134]+[0.137])	Prec@1 95.312 (96.226)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.4093 (0.4093) ([0.272]+[0.137])	Prec@1 89.844 (89.844)
 * Prec@1 89.620
current lr 1.00000e-02
Grad=  tensor(5.0674, device='cuda:0')
Epoch: [238][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.2189 (0.2189) ([0.082]+[0.137])	Prec@1 97.656 (97.656)
Epoch: [238][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2005 (0.2563) ([0.063]+[0.137])	Prec@1 96.875 (96.016)
Epoch: [238][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1832 (0.2501) ([0.046]+[0.137])	Prec@1 99.219 (96.191)
Epoch: [238][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2735 (0.2554) ([0.136]+[0.137])	Prec@1 96.094 (95.954)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.5115 (0.5115) ([0.374]+[0.137])	Prec@1 90.625 (90.625)
 * Prec@1 88.860
current lr 1.00000e-02
Grad=  tensor(3.7806, device='cuda:0')
Epoch: [239][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.2206 (0.2206) ([0.083]+[0.137])	Prec@1 98.438 (98.438)
Epoch: [239][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2237 (0.2495) ([0.087]+[0.137])	Prec@1 98.438 (96.310)
Epoch: [239][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2735 (0.2475) ([0.137]+[0.137])	Prec@1 94.531 (96.343)
Epoch: [239][300/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.2625 (0.2468) ([0.126]+[0.137])	Prec@1 96.094 (96.348)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.4496 (0.4496) ([0.313]+[0.137])	Prec@1 90.625 (90.625)
 * Prec@1 89.170
current lr 1.00000e-02
Grad=  tensor(5.8163, device='cuda:0')
Epoch: [240][0/391]	Time 0.255 (0.255)	Data 0.132 (0.132)	Loss 0.2166 (0.2166) ([0.080]+[0.137])	Prec@1 97.656 (97.656)
Epoch: [240][100/391]	Time 0.109 (0.112)	Data 0.000 (0.001)	Loss 0.2560 (0.2416) ([0.119]+[0.137])	Prec@1 94.531 (96.450)
Epoch: [240][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2527 (0.2492) ([0.116]+[0.137])	Prec@1 94.531 (96.195)
Epoch: [240][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2286 (0.2497) ([0.092]+[0.137])	Prec@1 96.094 (96.166)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.4454 (0.4454) ([0.308]+[0.137])	Prec@1 90.625 (90.625)
 * Prec@1 90.100
current lr 1.00000e-02
Grad=  tensor(8.7886, device='cuda:0')
Epoch: [241][0/391]	Time 0.255 (0.255)	Data 0.132 (0.132)	Loss 0.2494 (0.2494) ([0.112]+[0.137])	Prec@1 96.094 (96.094)
Epoch: [241][100/391]	Time 0.112 (0.113)	Data 0.000 (0.001)	Loss 0.2795 (0.2417) ([0.143]+[0.137])	Prec@1 95.312 (96.303)
Epoch: [241][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2765 (0.2397) ([0.140]+[0.137])	Prec@1 93.750 (96.467)
Epoch: [241][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2476 (0.2432) ([0.111]+[0.137])	Prec@1 94.531 (96.346)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3101 (0.3101) ([0.173]+[0.137])	Prec@1 92.969 (92.969)
 * Prec@1 90.680
current lr 1.00000e-02
Grad=  tensor(6.3628, device='cuda:0')
Epoch: [242][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.2254 (0.2254) ([0.089]+[0.137])	Prec@1 96.875 (96.875)
Epoch: [242][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2613 (0.2388) ([0.125]+[0.137])	Prec@1 95.312 (96.558)
Epoch: [242][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2108 (0.2377) ([0.074]+[0.137])	Prec@1 99.219 (96.630)
Epoch: [242][300/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.2069 (0.2487) ([0.070]+[0.137])	Prec@1 97.656 (96.203)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.4620 (0.4620) ([0.325]+[0.137])	Prec@1 91.406 (91.406)
 * Prec@1 89.750
current lr 1.00000e-02
Grad=  tensor(4.6020, device='cuda:0')
Epoch: [243][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.1978 (0.1978) ([0.061]+[0.137])	Prec@1 97.656 (97.656)
Epoch: [243][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2707 (0.2388) ([0.134]+[0.137])	Prec@1 96.094 (96.511)
Epoch: [243][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3501 (0.2454) ([0.213]+[0.137])	Prec@1 93.750 (96.327)
Epoch: [243][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2939 (0.2490) ([0.157]+[0.137])	Prec@1 94.531 (96.169)
Test: [0/79]	Time 0.167 (0.167)	Loss 0.4494 (0.4494) ([0.313]+[0.137])	Prec@1 90.625 (90.625)
 * Prec@1 89.810
current lr 1.00000e-02
Grad=  tensor(14.0049, device='cuda:0')
Epoch: [244][0/391]	Time 0.254 (0.254)	Data 0.133 (0.133)	Loss 0.2959 (0.2959) ([0.159]+[0.137])	Prec@1 95.312 (95.312)
Epoch: [244][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2652 (0.2480) ([0.128]+[0.137])	Prec@1 96.094 (96.256)
Epoch: [244][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3489 (0.2478) ([0.212]+[0.137])	Prec@1 95.312 (96.269)
Epoch: [244][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2355 (0.2486) ([0.099]+[0.137])	Prec@1 96.094 (96.224)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.4289 (0.4289) ([0.292]+[0.137])	Prec@1 91.406 (91.406)
 * Prec@1 88.510
current lr 1.00000e-02
Grad=  tensor(11.6096, device='cuda:0')
Epoch: [245][0/391]	Time 0.256 (0.256)	Data 0.135 (0.135)	Loss 0.2690 (0.2690) ([0.132]+[0.137])	Prec@1 94.531 (94.531)
Epoch: [245][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1981 (0.2375) ([0.061]+[0.137])	Prec@1 96.875 (96.620)
Epoch: [245][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1845 (0.2383) ([0.048]+[0.137])	Prec@1 99.219 (96.564)
Epoch: [245][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2925 (0.2438) ([0.156]+[0.137])	Prec@1 95.312 (96.384)
Test: [0/79]	Time 0.176 (0.176)	Loss 0.4261 (0.4261) ([0.289]+[0.137])	Prec@1 91.406 (91.406)
 * Prec@1 90.430
current lr 1.00000e-02
Grad=  tensor(6.7568, device='cuda:0')
Epoch: [246][0/391]	Time 0.274 (0.274)	Data 0.151 (0.151)	Loss 0.2197 (0.2197) ([0.083]+[0.137])	Prec@1 97.656 (97.656)
Epoch: [246][100/391]	Time 0.112 (0.114)	Data 0.000 (0.002)	Loss 0.2849 (0.2393) ([0.148]+[0.137])	Prec@1 96.094 (96.581)
Epoch: [246][200/391]	Time 0.112 (0.113)	Data 0.000 (0.001)	Loss 0.2367 (0.2459) ([0.100]+[0.137])	Prec@1 96.875 (96.374)
Epoch: [246][300/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.2024 (0.2445) ([0.066]+[0.137])	Prec@1 97.656 (96.452)
Test: [0/79]	Time 0.158 (0.158)	Loss 0.4208 (0.4208) ([0.284]+[0.137])	Prec@1 92.188 (92.188)
 * Prec@1 88.620
current lr 1.00000e-02
Grad=  tensor(6.4506, device='cuda:0')
Epoch: [247][0/391]	Time 0.250 (0.250)	Data 0.128 (0.128)	Loss 0.2405 (0.2405) ([0.104]+[0.137])	Prec@1 97.656 (97.656)
Epoch: [247][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2088 (0.2482) ([0.072]+[0.137])	Prec@1 97.656 (96.279)
Epoch: [247][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2093 (0.2452) ([0.073]+[0.137])	Prec@1 97.656 (96.304)
Epoch: [247][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2784 (0.2513) ([0.142]+[0.137])	Prec@1 95.312 (96.081)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.4417 (0.4417) ([0.305]+[0.137])	Prec@1 91.406 (91.406)
 * Prec@1 89.670
current lr 1.00000e-02
Grad=  tensor(5.7329, device='cuda:0')
Epoch: [248][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.2084 (0.2084) ([0.072]+[0.137])	Prec@1 97.656 (97.656)
Epoch: [248][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3184 (0.2299) ([0.182]+[0.137])	Prec@1 94.531 (96.968)
Epoch: [248][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2547 (0.2387) ([0.118]+[0.137])	Prec@1 96.094 (96.564)
Epoch: [248][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2640 (0.2428) ([0.127]+[0.137])	Prec@1 96.094 (96.452)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.4199 (0.4199) ([0.283]+[0.137])	Prec@1 92.188 (92.188)
 * Prec@1 89.570
current lr 1.00000e-02
Grad=  tensor(6.0856, device='cuda:0')
Epoch: [249][0/391]	Time 0.259 (0.259)	Data 0.138 (0.138)	Loss 0.1981 (0.1981) ([0.062]+[0.137])	Prec@1 96.094 (96.094)
Epoch: [249][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1784 (0.2431) ([0.042]+[0.137])	Prec@1 99.219 (96.380)
Epoch: [249][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2602 (0.2507) ([0.124]+[0.137])	Prec@1 95.312 (96.067)
Epoch: [249][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2588 (0.2519) ([0.122]+[0.137])	Prec@1 96.094 (96.112)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.3853 (0.3853) ([0.249]+[0.137])	Prec@1 94.531 (94.531)
 * Prec@1 90.900
current lr 1.00000e-03
Grad=  tensor(3.0517, device='cuda:0')
Epoch: [250][0/391]	Time 0.254 (0.254)	Data 0.133 (0.133)	Loss 0.1949 (0.1949) ([0.058]+[0.137])	Prec@1 97.656 (97.656)
Epoch: [250][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1655 (0.2068) ([0.030]+[0.135])	Prec@1 99.219 (97.741)
Epoch: [250][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2052 (0.1996) ([0.070]+[0.135])	Prec@1 97.656 (97.991)
Epoch: [250][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1695 (0.1950) ([0.034]+[0.135])	Prec@1 99.219 (98.212)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.2721 (0.2721) ([0.137]+[0.135])	Prec@1 94.531 (94.531)
 * Prec@1 93.370
current lr 1.00000e-03
Grad=  tensor(5.2445, device='cuda:0')
Epoch: [251][0/391]	Time 0.254 (0.254)	Data 0.133 (0.133)	Loss 0.1997 (0.1997) ([0.065]+[0.135])	Prec@1 97.656 (97.656)
Epoch: [251][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1581 (0.1777) ([0.023]+[0.135])	Prec@1 99.219 (98.840)
Epoch: [251][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1453 (0.1749) ([0.011]+[0.135])	Prec@1 100.000 (98.927)
Epoch: [251][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1867 (0.1732) ([0.052]+[0.135])	Prec@1 99.219 (99.009)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.2832 (0.2832) ([0.149]+[0.134])	Prec@1 92.969 (92.969)
 * Prec@1 93.460
current lr 1.00000e-03
Grad=  tensor(0.4194, device='cuda:0')
Epoch: [252][0/391]	Time 0.255 (0.255)	Data 0.133 (0.133)	Loss 0.1469 (0.1469) ([0.013]+[0.134])	Prec@1 100.000 (100.000)
Epoch: [252][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1965 (0.1668) ([0.062]+[0.134])	Prec@1 97.656 (99.196)
Epoch: [252][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1495 (0.1659) ([0.015]+[0.134])	Prec@1 100.000 (99.168)
Epoch: [252][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1781 (0.1651) ([0.044]+[0.134])	Prec@1 99.219 (99.219)
Test: [0/79]	Time 0.159 (0.159)	Loss 0.3021 (0.3021) ([0.168]+[0.134])	Prec@1 95.312 (95.312)
 * Prec@1 93.570
current lr 1.00000e-03
Grad=  tensor(3.0550, device='cuda:0')
Epoch: [253][0/391]	Time 0.251 (0.251)	Data 0.131 (0.131)	Loss 0.1649 (0.1649) ([0.031]+[0.134])	Prec@1 98.438 (98.438)
Epoch: [253][100/391]	Time 0.112 (0.110)	Data 0.000 (0.001)	Loss 0.1482 (0.1617) ([0.014]+[0.134])	Prec@1 100.000 (99.428)
Epoch: [253][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1720 (0.1616) ([0.038]+[0.134])	Prec@1 99.219 (99.347)
Epoch: [253][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1532 (0.1609) ([0.020]+[0.133])	Prec@1 100.000 (99.377)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.2894 (0.2894) ([0.156]+[0.133])	Prec@1 94.531 (94.531)
 * Prec@1 93.510
current lr 1.00000e-03
Grad=  tensor(5.8529, device='cuda:0')
Epoch: [254][0/391]	Time 0.255 (0.255)	Data 0.133 (0.133)	Loss 0.1876 (0.1876) ([0.054]+[0.133])	Prec@1 97.656 (97.656)
Epoch: [254][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1627 (0.1570) ([0.029]+[0.133])	Prec@1 99.219 (99.489)
Epoch: [254][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1618 (0.1577) ([0.029]+[0.133])	Prec@1 98.438 (99.440)
Epoch: [254][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1450 (0.1574) ([0.012]+[0.133])	Prec@1 100.000 (99.455)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.2862 (0.2862) ([0.153]+[0.133])	Prec@1 95.312 (95.312)
 * Prec@1 93.560
current lr 1.00000e-03
Grad=  tensor(1.7312, device='cuda:0')
Epoch: [255][0/391]	Time 0.253 (0.253)	Data 0.132 (0.132)	Loss 0.1565 (0.1565) ([0.024]+[0.133])	Prec@1 99.219 (99.219)
Epoch: [255][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1654 (0.1547) ([0.033]+[0.133])	Prec@1 99.219 (99.520)
Epoch: [255][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1592 (0.1547) ([0.026]+[0.133])	Prec@1 99.219 (99.534)
Epoch: [255][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1387 (0.1554) ([0.006]+[0.133])	Prec@1 100.000 (99.483)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3005 (0.3005) ([0.168]+[0.132])	Prec@1 95.312 (95.312)
 * Prec@1 93.570
current lr 1.00000e-03
Grad=  tensor(0.1555, device='cuda:0')
Epoch: [256][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.1375 (0.1375) ([0.005]+[0.132])	Prec@1 100.000 (100.000)
Epoch: [256][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1498 (0.1519) ([0.017]+[0.132])	Prec@1 99.219 (99.544)
Epoch: [256][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1506 (0.1524) ([0.018]+[0.132])	Prec@1 100.000 (99.557)
Epoch: [256][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1615 (0.1523) ([0.029]+[0.132])	Prec@1 98.438 (99.556)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.3118 (0.3118) ([0.180]+[0.132])	Prec@1 95.312 (95.312)
 * Prec@1 93.680
current lr 1.00000e-03
Grad=  tensor(0.3375, device='cuda:0')
Epoch: [257][0/391]	Time 0.249 (0.249)	Data 0.128 (0.128)	Loss 0.1381 (0.1381) ([0.006]+[0.132])	Prec@1 100.000 (100.000)
Epoch: [257][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1524 (0.1523) ([0.020]+[0.132])	Prec@1 99.219 (99.629)
Epoch: [257][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1508 (0.1513) ([0.019]+[0.132])	Prec@1 100.000 (99.642)
Epoch: [257][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1683 (0.1512) ([0.037]+[0.132])	Prec@1 98.438 (99.634)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.3030 (0.3030) ([0.172]+[0.132])	Prec@1 95.312 (95.312)
 * Prec@1 93.620
current lr 1.00000e-03
Grad=  tensor(0.2296, device='cuda:0')
Epoch: [258][0/391]	Time 0.251 (0.251)	Data 0.129 (0.129)	Loss 0.1378 (0.1378) ([0.006]+[0.132])	Prec@1 100.000 (100.000)
Epoch: [258][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1455 (0.1488) ([0.014]+[0.131])	Prec@1 100.000 (99.652)
Epoch: [258][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1508 (0.1493) ([0.020]+[0.131])	Prec@1 99.219 (99.615)
Epoch: [258][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1466 (0.1493) ([0.015]+[0.131])	Prec@1 100.000 (99.608)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.2852 (0.2852) ([0.154]+[0.131])	Prec@1 95.312 (95.312)
 * Prec@1 93.660
current lr 1.00000e-03
Grad=  tensor(2.8143, device='cuda:0')
Epoch: [259][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 0.1480 (0.1480) ([0.017]+[0.131])	Prec@1 99.219 (99.219)
Epoch: [259][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1515 (0.1486) ([0.021]+[0.131])	Prec@1 99.219 (99.652)
Epoch: [259][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1397 (0.1484) ([0.009]+[0.131])	Prec@1 100.000 (99.639)
Epoch: [259][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1597 (0.1484) ([0.029]+[0.131])	Prec@1 99.219 (99.639)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.2923 (0.2923) ([0.162]+[0.131])	Prec@1 95.312 (95.312)
 * Prec@1 93.700
current lr 1.00000e-03
Grad=  tensor(0.5952, device='cuda:0')
Epoch: [260][0/391]	Time 0.257 (0.257)	Data 0.135 (0.135)	Loss 0.1384 (0.1384) ([0.008]+[0.131])	Prec@1 100.000 (100.000)
Epoch: [260][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1504 (0.1468) ([0.020]+[0.131])	Prec@1 99.219 (99.652)
Epoch: [260][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1471 (0.1461) ([0.017]+[0.130])	Prec@1 100.000 (99.693)
Epoch: [260][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1482 (0.1461) ([0.018]+[0.130])	Prec@1 99.219 (99.694)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.3028 (0.3028) ([0.173]+[0.130])	Prec@1 95.312 (95.312)
 * Prec@1 93.590
current lr 1.00000e-03
Grad=  tensor(0.7127, device='cuda:0')
Epoch: [261][0/391]	Time 0.253 (0.253)	Data 0.131 (0.131)	Loss 0.1417 (0.1417) ([0.011]+[0.130])	Prec@1 100.000 (100.000)
Epoch: [261][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1394 (0.1454) ([0.009]+[0.130])	Prec@1 100.000 (99.714)
Epoch: [261][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1412 (0.1457) ([0.011]+[0.130])	Prec@1 100.000 (99.689)
Epoch: [261][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1400 (0.1458) ([0.010]+[0.130])	Prec@1 100.000 (99.676)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.2989 (0.2989) ([0.169]+[0.130])	Prec@1 95.312 (95.312)
 * Prec@1 93.690
current lr 1.00000e-03
Grad=  tensor(0.4086, device='cuda:0')
Epoch: [262][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.1386 (0.1386) ([0.009]+[0.130])	Prec@1 100.000 (100.000)
Epoch: [262][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.1412 (0.1456) ([0.012]+[0.130])	Prec@1 100.000 (99.667)
Epoch: [262][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1455 (0.1453) ([0.016]+[0.130])	Prec@1 99.219 (99.662)
Epoch: [262][300/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1368 (0.1451) ([0.007]+[0.129])	Prec@1 100.000 (99.673)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.2977 (0.2977) ([0.168]+[0.129])	Prec@1 95.312 (95.312)
 * Prec@1 93.640
current lr 1.00000e-03
Grad=  tensor(1.8074, device='cuda:0')
Epoch: [263][0/391]	Time 0.251 (0.251)	Data 0.131 (0.131)	Loss 0.1499 (0.1499) ([0.021]+[0.129])	Prec@1 99.219 (99.219)
Epoch: [263][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.1534 (0.1435) ([0.024]+[0.129])	Prec@1 99.219 (99.691)
Epoch: [263][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1399 (0.1433) ([0.011]+[0.129])	Prec@1 100.000 (99.724)
Epoch: [263][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.1425 (0.1430) ([0.013]+[0.129])	Prec@1 99.219 (99.735)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.3092 (0.3092) ([0.180]+[0.129])	Prec@1 95.312 (95.312)
 * Prec@1 93.790
current lr 1.00000e-03
Grad=  tensor(2.8973, device='cuda:0')
Epoch: [264][0/391]	Time 0.248 (0.248)	Data 0.128 (0.128)	Loss 0.1611 (0.1611) ([0.032]+[0.129])	Prec@1 99.219 (99.219)
Epoch: [264][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.1504 (0.1437) ([0.022]+[0.129])	Prec@1 99.219 (99.706)
Epoch: [264][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.1481 (0.1434) ([0.019]+[0.129])	Prec@1 99.219 (99.697)
Epoch: [264][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1426 (0.1431) ([0.014]+[0.129])	Prec@1 100.000 (99.707)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.2918 (0.2918) ([0.163]+[0.129])	Prec@1 95.312 (95.312)
 * Prec@1 93.740
current lr 1.00000e-03
Grad=  tensor(0.8247, device='cuda:0')
Epoch: [265][0/391]	Time 0.252 (0.252)	Data 0.132 (0.132)	Loss 0.1417 (0.1417) ([0.013]+[0.129])	Prec@1 100.000 (100.000)
Epoch: [265][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.1336 (0.1406) ([0.005]+[0.128])	Prec@1 100.000 (99.768)
Epoch: [265][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.1419 (0.1412) ([0.014]+[0.128])	Prec@1 100.000 (99.751)
Epoch: [265][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1446 (0.1410) ([0.016]+[0.128])	Prec@1 99.219 (99.769)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.2930 (0.2930) ([0.165]+[0.128])	Prec@1 95.312 (95.312)
 * Prec@1 93.730
current lr 1.00000e-03
Grad=  tensor(4.5842, device='cuda:0')
Epoch: [266][0/391]	Time 0.253 (0.253)	Data 0.133 (0.133)	Loss 0.1641 (0.1641) ([0.036]+[0.128])	Prec@1 98.438 (98.438)
Epoch: [266][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.1368 (0.1415) ([0.009]+[0.128])	Prec@1 100.000 (99.737)
Epoch: [266][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.1381 (0.1414) ([0.010]+[0.128])	Prec@1 100.000 (99.743)
Epoch: [266][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.1440 (0.1408) ([0.016]+[0.128])	Prec@1 100.000 (99.761)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.3069 (0.3069) ([0.179]+[0.128])	Prec@1 95.312 (95.312)
 * Prec@1 93.670
current lr 1.00000e-03
Grad=  tensor(0.1672, device='cuda:0')
Epoch: [267][0/391]	Time 0.254 (0.254)	Data 0.134 (0.134)	Loss 0.1320 (0.1320) ([0.004]+[0.128])	Prec@1 100.000 (100.000)
Epoch: [267][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1388 (0.1413) ([0.011]+[0.128])	Prec@1 100.000 (99.722)
Epoch: [267][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1537 (0.1409) ([0.026]+[0.127])	Prec@1 99.219 (99.732)
Epoch: [267][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.1355 (0.1402) ([0.008]+[0.127])	Prec@1 100.000 (99.761)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3156 (0.3156) ([0.188]+[0.127])	Prec@1 94.531 (94.531)
 * Prec@1 93.640
current lr 1.00000e-03
Grad=  tensor(0.3624, device='cuda:0')
Epoch: [268][0/391]	Time 0.253 (0.253)	Data 0.134 (0.134)	Loss 0.1345 (0.1345) ([0.007]+[0.127])	Prec@1 100.000 (100.000)
Epoch: [268][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1363 (0.1395) ([0.009]+[0.127])	Prec@1 100.000 (99.752)
Epoch: [268][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1321 (0.1395) ([0.005]+[0.127])	Prec@1 100.000 (99.759)
Epoch: [268][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1325 (0.1395) ([0.006]+[0.127])	Prec@1 100.000 (99.772)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.3028 (0.3028) ([0.176]+[0.127])	Prec@1 95.312 (95.312)
 * Prec@1 93.910
current lr 1.00000e-03
Grad=  tensor(0.1624, device='cuda:0')
Epoch: [269][0/391]	Time 0.252 (0.252)	Data 0.133 (0.133)	Loss 0.1306 (0.1306) ([0.004]+[0.127])	Prec@1 100.000 (100.000)
Epoch: [269][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1303 (0.1380) ([0.004]+[0.127])	Prec@1 100.000 (99.814)
Epoch: [269][200/391]	Time 0.112 (0.110)	Data 0.000 (0.001)	Loss 0.1386 (0.1385) ([0.012]+[0.127])	Prec@1 99.219 (99.813)
Epoch: [269][300/391]	Time 0.112 (0.110)	Data 0.000 (0.001)	Loss 0.1368 (0.1381) ([0.010]+[0.127])	Prec@1 100.000 (99.831)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.3061 (0.3061) ([0.180]+[0.126])	Prec@1 95.312 (95.312)
 * Prec@1 93.870
current lr 1.00000e-03
Grad=  tensor(1.5387, device='cuda:0')
Epoch: [270][0/391]	Time 0.251 (0.251)	Data 0.131 (0.131)	Loss 0.1360 (0.1360) ([0.010]+[0.126])	Prec@1 100.000 (100.000)
Epoch: [270][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.1322 (0.1384) ([0.006]+[0.126])	Prec@1 100.000 (99.783)
Epoch: [270][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.1329 (0.1375) ([0.007]+[0.126])	Prec@1 100.000 (99.802)
Epoch: [270][300/391]	Time 0.111 (0.109)	Data 0.000 (0.001)	Loss 0.1310 (0.1373) ([0.005]+[0.126])	Prec@1 100.000 (99.808)
Test: [0/79]	Time 0.159 (0.159)	Loss 0.3096 (0.3096) ([0.184]+[0.126])	Prec@1 94.531 (94.531)
 * Prec@1 93.760
current lr 1.00000e-03
Grad=  tensor(0.7233, device='cuda:0')
Epoch: [271][0/391]	Time 0.249 (0.249)	Data 0.127 (0.127)	Loss 0.1344 (0.1344) ([0.008]+[0.126])	Prec@1 100.000 (100.000)
Epoch: [271][100/391]	Time 0.114 (0.113)	Data 0.000 (0.001)	Loss 0.1355 (0.1369) ([0.010]+[0.126])	Prec@1 100.000 (99.869)
Epoch: [271][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1426 (0.1372) ([0.017]+[0.126])	Prec@1 100.000 (99.825)
Epoch: [271][300/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1272 (0.1373) ([0.001]+[0.126])	Prec@1 100.000 (99.808)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.2922 (0.2922) ([0.167]+[0.126])	Prec@1 95.312 (95.312)
 * Prec@1 93.750
current lr 1.00000e-03
Grad=  tensor(0.9599, device='cuda:0')
Epoch: [272][0/391]	Time 0.247 (0.247)	Data 0.127 (0.127)	Loss 0.1395 (0.1395) ([0.014]+[0.126])	Prec@1 100.000 (100.000)
Epoch: [272][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1382 (0.1363) ([0.013]+[0.125])	Prec@1 100.000 (99.845)
Epoch: [272][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1322 (0.1358) ([0.007]+[0.125])	Prec@1 100.000 (99.848)
Epoch: [272][300/391]	Time 0.110 (0.109)	Data 0.000 (0.001)	Loss 0.1436 (0.1362) ([0.018]+[0.125])	Prec@1 100.000 (99.836)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.3010 (0.3010) ([0.176]+[0.125])	Prec@1 95.312 (95.312)
 * Prec@1 93.820
current lr 1.00000e-03
Grad=  tensor(0.1971, device='cuda:0')
Epoch: [273][0/391]	Time 0.255 (0.255)	Data 0.133 (0.133)	Loss 0.1290 (0.1290) ([0.004]+[0.125])	Prec@1 100.000 (100.000)
Epoch: [273][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1327 (0.1356) ([0.008]+[0.125])	Prec@1 100.000 (99.845)
Epoch: [273][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1317 (0.1357) ([0.007]+[0.125])	Prec@1 100.000 (99.821)
Epoch: [273][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1456 (0.1355) ([0.021]+[0.125])	Prec@1 99.219 (99.816)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.3011 (0.3011) ([0.176]+[0.125])	Prec@1 95.312 (95.312)
 * Prec@1 93.650
current lr 1.00000e-03
Grad=  tensor(0.2679, device='cuda:0')
Epoch: [274][0/391]	Time 0.253 (0.253)	Data 0.131 (0.131)	Loss 0.1301 (0.1301) ([0.005]+[0.125])	Prec@1 100.000 (100.000)
Epoch: [274][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1303 (0.1339) ([0.006]+[0.125])	Prec@1 100.000 (99.915)
Epoch: [274][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1287 (0.1350) ([0.004]+[0.125])	Prec@1 100.000 (99.860)
Epoch: [274][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1352 (0.1350) ([0.011]+[0.124])	Prec@1 100.000 (99.844)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.2670 (0.2670) ([0.143]+[0.124])	Prec@1 95.312 (95.312)
 * Prec@1 93.790
current lr 1.00000e-03
Grad=  tensor(0.3504, device='cuda:0')
Epoch: [275][0/391]	Time 0.252 (0.252)	Data 0.130 (0.130)	Loss 0.1308 (0.1308) ([0.006]+[0.124])	Prec@1 100.000 (100.000)
Epoch: [275][100/391]	Time 0.112 (0.113)	Data 0.000 (0.001)	Loss 0.1322 (0.1358) ([0.008]+[0.124])	Prec@1 100.000 (99.776)
Epoch: [275][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1400 (0.1350) ([0.016]+[0.124])	Prec@1 100.000 (99.813)
Epoch: [275][300/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1275 (0.1346) ([0.003]+[0.124])	Prec@1 100.000 (99.818)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.2884 (0.2884) ([0.164]+[0.124])	Prec@1 95.312 (95.312)
 * Prec@1 93.800
current lr 1.00000e-03
Grad=  tensor(0.7038, device='cuda:0')
Epoch: [276][0/391]	Time 0.249 (0.249)	Data 0.128 (0.128)	Loss 0.1346 (0.1346) ([0.011]+[0.124])	Prec@1 100.000 (100.000)
Epoch: [276][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1320 (0.1335) ([0.008]+[0.124])	Prec@1 100.000 (99.845)
Epoch: [276][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1471 (0.1339) ([0.023]+[0.124])	Prec@1 99.219 (99.848)
Epoch: [276][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.1307 (0.1339) ([0.007]+[0.124])	Prec@1 100.000 (99.844)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.2811 (0.2811) ([0.158]+[0.124])	Prec@1 95.312 (95.312)
 * Prec@1 93.880
current lr 1.00000e-03
Grad=  tensor(0.5381, device='cuda:0')
Epoch: [277][0/391]	Time 0.252 (0.252)	Data 0.132 (0.132)	Loss 0.1301 (0.1301) ([0.007]+[0.124])	Prec@1 100.000 (100.000)
Epoch: [277][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.1386 (0.1326) ([0.015]+[0.123])	Prec@1 100.000 (99.884)
Epoch: [277][200/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.1410 (0.1323) ([0.018]+[0.123])	Prec@1 100.000 (99.899)
Epoch: [277][300/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.1352 (0.1325) ([0.012]+[0.123])	Prec@1 100.000 (99.888)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.2947 (0.2947) ([0.172]+[0.123])	Prec@1 96.094 (96.094)
 * Prec@1 93.730
current lr 1.00000e-03
Grad=  tensor(0.3501, device='cuda:0')
Epoch: [278][0/391]	Time 0.251 (0.251)	Data 0.131 (0.131)	Loss 0.1284 (0.1284) ([0.005]+[0.123])	Prec@1 100.000 (100.000)
Epoch: [278][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1361 (0.1326) ([0.013]+[0.123])	Prec@1 99.219 (99.838)
Epoch: [278][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1353 (0.1325) ([0.012]+[0.123])	Prec@1 100.000 (99.837)
Epoch: [278][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1299 (0.1324) ([0.007]+[0.123])	Prec@1 100.000 (99.844)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.2792 (0.2792) ([0.156]+[0.123])	Prec@1 95.312 (95.312)
 * Prec@1 93.800
current lr 1.00000e-03
Grad=  tensor(0.2631, device='cuda:0')
Epoch: [279][0/391]	Time 0.250 (0.250)	Data 0.128 (0.128)	Loss 0.1266 (0.1266) ([0.004]+[0.123])	Prec@1 100.000 (100.000)
Epoch: [279][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.1264 (0.1316) ([0.004]+[0.123])	Prec@1 100.000 (99.884)
Epoch: [279][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1357 (0.1314) ([0.013]+[0.123])	Prec@1 100.000 (99.868)
Epoch: [279][300/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1333 (0.1315) ([0.011]+[0.122])	Prec@1 100.000 (99.865)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.3120 (0.3120) ([0.190]+[0.122])	Prec@1 94.531 (94.531)
 * Prec@1 93.720
current lr 1.00000e-03
Grad=  tensor(0.2041, device='cuda:0')
Epoch: [280][0/391]	Time 0.251 (0.251)	Data 0.129 (0.129)	Loss 0.1274 (0.1274) ([0.005]+[0.122])	Prec@1 100.000 (100.000)
Epoch: [280][100/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1263 (0.1310) ([0.004]+[0.122])	Prec@1 100.000 (99.884)
Epoch: [280][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1342 (0.1311) ([0.012]+[0.122])	Prec@1 100.000 (99.895)
Epoch: [280][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1280 (0.1308) ([0.006]+[0.122])	Prec@1 100.000 (99.894)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.3006 (0.3006) ([0.179]+[0.122])	Prec@1 95.312 (95.312)
 * Prec@1 93.960
current lr 1.00000e-03
Grad=  tensor(0.1312, device='cuda:0')
Epoch: [281][0/391]	Time 0.261 (0.261)	Data 0.138 (0.138)	Loss 0.1252 (0.1252) ([0.003]+[0.122])	Prec@1 100.000 (100.000)
Epoch: [281][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1266 (0.1302) ([0.005]+[0.122])	Prec@1 100.000 (99.899)
Epoch: [281][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1340 (0.1310) ([0.012]+[0.122])	Prec@1 99.219 (99.864)
Epoch: [281][300/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.1265 (0.1307) ([0.005]+[0.122])	Prec@1 100.000 (99.875)
Test: [0/79]	Time 0.161 (0.161)	Loss 0.2959 (0.2959) ([0.174]+[0.122])	Prec@1 96.094 (96.094)
 * Prec@1 93.740
current lr 1.00000e-03
Grad=  tensor(0.9560, device='cuda:0')
Epoch: [282][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 0.1299 (0.1299) ([0.008]+[0.122])	Prec@1 100.000 (100.000)
Epoch: [282][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1281 (0.1296) ([0.007]+[0.121])	Prec@1 100.000 (99.930)
Epoch: [282][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1299 (0.1296) ([0.009]+[0.121])	Prec@1 100.000 (99.914)
Epoch: [282][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1272 (0.1298) ([0.006]+[0.121])	Prec@1 100.000 (99.909)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.2658 (0.2658) ([0.145]+[0.121])	Prec@1 95.312 (95.312)
 * Prec@1 93.820
current lr 1.00000e-03
Grad=  tensor(0.2354, device='cuda:0')
Epoch: [283][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.1253 (0.1253) ([0.004]+[0.121])	Prec@1 100.000 (100.000)
Epoch: [283][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1269 (0.1288) ([0.006]+[0.121])	Prec@1 100.000 (99.946)
Epoch: [283][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1295 (0.1296) ([0.008]+[0.121])	Prec@1 99.219 (99.903)
Epoch: [283][300/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1301 (0.1294) ([0.009]+[0.121])	Prec@1 100.000 (99.888)
Test: [0/79]	Time 0.160 (0.160)	Loss 0.2935 (0.2935) ([0.173]+[0.121])	Prec@1 95.312 (95.312)
 * Prec@1 93.990
current lr 1.00000e-03
Grad=  tensor(0.1740, device='cuda:0')
Epoch: [284][0/391]	Time 0.252 (0.252)	Data 0.132 (0.132)	Loss 0.1241 (0.1241) ([0.003]+[0.121])	Prec@1 100.000 (100.000)
Epoch: [284][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1244 (0.1283) ([0.004]+[0.121])	Prec@1 100.000 (99.923)
Epoch: [284][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.1278 (0.1290) ([0.007]+[0.121])	Prec@1 100.000 (99.880)
Epoch: [284][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1345 (0.1291) ([0.014]+[0.120])	Prec@1 99.219 (99.881)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.2943 (0.2943) ([0.174]+[0.120])	Prec@1 94.531 (94.531)
 * Prec@1 93.950
current lr 1.00000e-03
Grad=  tensor(0.1225, device='cuda:0')
Epoch: [285][0/391]	Time 0.250 (0.250)	Data 0.130 (0.130)	Loss 0.1223 (0.1223) ([0.002]+[0.120])	Prec@1 100.000 (100.000)
Epoch: [285][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.1275 (0.1286) ([0.007]+[0.120])	Prec@1 100.000 (99.915)
Epoch: [285][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1296 (0.1293) ([0.009]+[0.120])	Prec@1 100.000 (99.876)
Epoch: [285][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1287 (0.1290) ([0.009]+[0.120])	Prec@1 100.000 (99.868)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.2765 (0.2765) ([0.157]+[0.120])	Prec@1 96.094 (96.094)
 * Prec@1 93.890
current lr 1.00000e-03
Grad=  tensor(7.3673, device='cuda:0')
Epoch: [286][0/391]	Time 0.249 (0.249)	Data 0.129 (0.129)	Loss 0.1613 (0.1613) ([0.041]+[0.120])	Prec@1 98.438 (98.438)
Epoch: [286][100/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1255 (0.1282) ([0.006]+[0.120])	Prec@1 100.000 (99.869)
Epoch: [286][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1298 (0.1281) ([0.010]+[0.120])	Prec@1 100.000 (99.880)
Epoch: [286][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.1292 (0.1277) ([0.010]+[0.120])	Prec@1 100.000 (99.883)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.2825 (0.2825) ([0.163]+[0.120])	Prec@1 96.094 (96.094)
 * Prec@1 93.930
current lr 1.00000e-03
Grad=  tensor(8.8012, device='cuda:0')
Epoch: [287][0/391]	Time 0.252 (0.252)	Data 0.131 (0.131)	Loss 0.1596 (0.1596) ([0.040]+[0.120])	Prec@1 99.219 (99.219)
Epoch: [287][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1381 (0.1271) ([0.019]+[0.119])	Prec@1 100.000 (99.915)
Epoch: [287][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.1228 (0.1268) ([0.003]+[0.119])	Prec@1 100.000 (99.918)
Epoch: [287][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1489 (0.1270) ([0.030]+[0.119])	Prec@1 99.219 (99.912)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.2838 (0.2838) ([0.165]+[0.119])	Prec@1 96.094 (96.094)
 * Prec@1 93.870
current lr 1.00000e-03
Grad=  tensor(1.7969, device='cuda:0')
Epoch: [288][0/391]	Time 0.251 (0.251)	Data 0.129 (0.129)	Loss 0.1297 (0.1297) ([0.011]+[0.119])	Prec@1 100.000 (100.000)
Epoch: [288][100/391]	Time 0.112 (0.113)	Data 0.000 (0.001)	Loss 0.1257 (0.1268) ([0.007]+[0.119])	Prec@1 100.000 (99.907)
Epoch: [288][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1255 (0.1273) ([0.006]+[0.119])	Prec@1 100.000 (99.887)
Epoch: [288][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1245 (0.1273) ([0.006]+[0.119])	Prec@1 100.000 (99.891)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.2864 (0.2864) ([0.168]+[0.119])	Prec@1 96.094 (96.094)
 * Prec@1 93.920
current lr 1.00000e-03
Grad=  tensor(0.2521, device='cuda:0')
Epoch: [289][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.1229 (0.1229) ([0.004]+[0.119])	Prec@1 100.000 (100.000)
Epoch: [289][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1356 (0.1261) ([0.017]+[0.119])	Prec@1 100.000 (99.915)
Epoch: [289][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1284 (0.1261) ([0.010]+[0.119])	Prec@1 100.000 (99.922)
Epoch: [289][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1235 (0.1262) ([0.005]+[0.119])	Prec@1 100.000 (99.917)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.3018 (0.3018) ([0.183]+[0.118])	Prec@1 95.312 (95.312)
 * Prec@1 93.950
current lr 1.00000e-03
Grad=  tensor(1.3400, device='cuda:0')
Epoch: [290][0/391]	Time 0.251 (0.251)	Data 0.130 (0.130)	Loss 0.1299 (0.1299) ([0.012]+[0.118])	Prec@1 100.000 (100.000)
Epoch: [290][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1235 (0.1252) ([0.005]+[0.118])	Prec@1 100.000 (99.930)
Epoch: [290][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1289 (0.1258) ([0.011]+[0.118])	Prec@1 100.000 (99.895)
Epoch: [290][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1224 (0.1256) ([0.004]+[0.118])	Prec@1 100.000 (99.896)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.3064 (0.3064) ([0.188]+[0.118])	Prec@1 96.094 (96.094)
 * Prec@1 93.750
current lr 1.00000e-03
Grad=  tensor(0.8120, device='cuda:0')
Epoch: [291][0/391]	Time 0.250 (0.250)	Data 0.131 (0.131)	Loss 0.1256 (0.1256) ([0.008]+[0.118])	Prec@1 100.000 (100.000)
Epoch: [291][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1236 (0.1251) ([0.006]+[0.118])	Prec@1 100.000 (99.923)
Epoch: [291][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1319 (0.1253) ([0.014]+[0.118])	Prec@1 99.219 (99.911)
Epoch: [291][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1320 (0.1249) ([0.014]+[0.118])	Prec@1 99.219 (99.920)
Test: [0/79]	Time 0.166 (0.166)	Loss 0.2925 (0.2925) ([0.175]+[0.118])	Prec@1 95.312 (95.312)
 * Prec@1 93.870
current lr 1.00000e-03
Grad=  tensor(1.3402, device='cuda:0')
Epoch: [292][0/391]	Time 0.250 (0.250)	Data 0.130 (0.130)	Loss 0.1248 (0.1248) ([0.007]+[0.118])	Prec@1 100.000 (100.000)
Epoch: [292][100/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.1231 (0.1247) ([0.006]+[0.118])	Prec@1 100.000 (99.930)
Epoch: [292][200/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.1202 (0.1250) ([0.003]+[0.117])	Prec@1 100.000 (99.911)
Epoch: [292][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1239 (0.1248) ([0.007]+[0.117])	Prec@1 100.000 (99.909)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.2941 (0.2941) ([0.177]+[0.117])	Prec@1 96.094 (96.094)
 * Prec@1 94.020
current lr 1.00000e-03
Grad=  tensor(0.5444, device='cuda:0')
Epoch: [293][0/391]	Time 0.258 (0.258)	Data 0.136 (0.136)	Loss 0.1230 (0.1230) ([0.006]+[0.117])	Prec@1 100.000 (100.000)
Epoch: [293][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1234 (0.1245) ([0.006]+[0.117])	Prec@1 100.000 (99.915)
Epoch: [293][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1204 (0.1249) ([0.003]+[0.117])	Prec@1 100.000 (99.895)
Epoch: [293][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1207 (0.1245) ([0.004]+[0.117])	Prec@1 100.000 (99.907)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.2979 (0.2979) ([0.181]+[0.117])	Prec@1 96.094 (96.094)
 * Prec@1 93.940
current lr 1.00000e-03
Grad=  tensor(0.3469, device='cuda:0')
Epoch: [294][0/391]	Time 0.259 (0.259)	Data 0.137 (0.137)	Loss 0.1228 (0.1228) ([0.006]+[0.117])	Prec@1 100.000 (100.000)
Epoch: [294][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1191 (0.1243) ([0.002]+[0.117])	Prec@1 100.000 (99.923)
Epoch: [294][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1208 (0.1244) ([0.004]+[0.117])	Prec@1 100.000 (99.926)
Epoch: [294][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1472 (0.1244) ([0.031]+[0.117])	Prec@1 99.219 (99.925)
Test: [0/79]	Time 0.163 (0.163)	Loss 0.2943 (0.2943) ([0.178]+[0.116])	Prec@1 95.312 (95.312)
 * Prec@1 93.850
current lr 1.00000e-03
Grad=  tensor(4.2658, device='cuda:0')
Epoch: [295][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.1475 (0.1475) ([0.031]+[0.116])	Prec@1 99.219 (99.219)
Epoch: [295][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1246 (0.1240) ([0.008]+[0.116])	Prec@1 100.000 (99.892)
Epoch: [295][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1306 (0.1234) ([0.014]+[0.116])	Prec@1 99.219 (99.907)
Epoch: [295][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1200 (0.1234) ([0.004]+[0.116])	Prec@1 100.000 (99.907)
Test: [0/79]	Time 0.164 (0.164)	Loss 0.3139 (0.3139) ([0.198]+[0.116])	Prec@1 94.531 (94.531)
 * Prec@1 93.970
current lr 1.00000e-03
Grad=  tensor(1.1500, device='cuda:0')
Epoch: [296][0/391]	Time 0.256 (0.256)	Data 0.135 (0.135)	Loss 0.1260 (0.1260) ([0.010]+[0.116])	Prec@1 100.000 (100.000)
Epoch: [296][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1195 (0.1232) ([0.003]+[0.116])	Prec@1 100.000 (99.892)
Epoch: [296][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1186 (0.1232) ([0.003]+[0.116])	Prec@1 100.000 (99.903)
Epoch: [296][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1222 (0.1234) ([0.006]+[0.116])	Prec@1 100.000 (99.904)
Test: [0/79]	Time 0.162 (0.162)	Loss 0.3104 (0.3104) ([0.195]+[0.116])	Prec@1 94.531 (94.531)
 * Prec@1 93.980
current lr 1.00000e-03
Grad=  tensor(0.6673, device='cuda:0')
Epoch: [297][0/391]	Time 0.250 (0.250)	Data 0.129 (0.129)	Loss 0.1223 (0.1223) ([0.007]+[0.116])	Prec@1 100.000 (100.000)
Epoch: [297][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1201 (0.1230) ([0.004]+[0.116])	Prec@1 100.000 (99.884)
Epoch: [297][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1204 (0.1228) ([0.005]+[0.116])	Prec@1 100.000 (99.907)
Epoch: [297][300/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1235 (0.1228) ([0.008]+[0.115])	Prec@1 100.000 (99.901)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.3054 (0.3054) ([0.190]+[0.115])	Prec@1 94.531 (94.531)
 * Prec@1 93.970
current lr 1.00000e-03
Grad=  tensor(0.1260, device='cuda:0')
Epoch: [298][0/391]	Time 0.253 (0.253)	Data 0.131 (0.131)	Loss 0.1182 (0.1182) ([0.003]+[0.115])	Prec@1 100.000 (100.000)
Epoch: [298][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1193 (0.1219) ([0.004]+[0.115])	Prec@1 100.000 (99.930)
Epoch: [298][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1177 (0.1218) ([0.003]+[0.115])	Prec@1 100.000 (99.938)
Epoch: [298][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1191 (0.1223) ([0.004]+[0.115])	Prec@1 100.000 (99.909)
Test: [0/79]	Time 0.168 (0.168)	Loss 0.2842 (0.2842) ([0.169]+[0.115])	Prec@1 95.312 (95.312)
 * Prec@1 93.940
current lr 1.00000e-03
Grad=  tensor(1.2678, device='cuda:0')
Epoch: [299][0/391]	Time 0.254 (0.254)	Data 0.132 (0.132)	Loss 0.1243 (0.1243) ([0.009]+[0.115])	Prec@1 100.000 (100.000)
Epoch: [299][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1245 (0.1217) ([0.010]+[0.115])	Prec@1 100.000 (99.946)
Epoch: [299][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1202 (0.1215) ([0.005]+[0.115])	Prec@1 100.000 (99.922)
Epoch: [299][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1177 (0.1214) ([0.003]+[0.115])	Prec@1 100.000 (99.927)
Test: [0/79]	Time 0.165 (0.165)	Loss 0.2976 (0.2976) ([0.183]+[0.115])	Prec@1 95.312 (95.312)
 * Prec@1 93.870

 Elapsed time for training  3:53:48.767276

 sparsity of   [0.48148149251937866, 0.0, 0.7037037014961243, 0.9259259104728699, 0.0, 0.9629629850387573, 0.6666666865348816, 0.0, 0.9629629850387573, 0.0, 0.9629629850387573, 0.0, 0.9629629850387573, 0.0, 0.9259259104728699, 0.7037037014961243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8148148059844971, 0.9629629850387573, 0.9259259104728699, 0.9629629850387573, 0.0, 0.8518518805503845, 0.9629629850387573, 0.0, 0.0, 0.9629629850387573, 0.9259259104728699, 0.9629629850387573, 0.0, 0.0, 0.0, 0.9629629850387573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9259259104728699, 0.0, 0.9629629850387573, 0.0, 0.0, 0.0, 0.5185185074806213, 0.0, 0.0, 0.9259259104728699, 0.9629629850387573, 0.9629629850387573, 0.9629629850387573, 0.0, 0.0, 0.0, 0.0, 0.9629629850387573, 0.0, 0.0]

 sparsity of   [0.96875, 0.0, 0.96875, 0.4375, 0.0, 0.0, 0.96875, 0.96875, 0.984375, 0.984375, 0.0, 0.96875, 0.0, 0.96875, 0.96875, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.96875, 0.96875, 0.0, 0.96875, 0.96875, 0.0, 0.4375, 0.96875, 0.0, 0.984375, 0.96875, 0.984375, 0.96875, 0.96875, 0.96875, 0.984375, 0.984375, 0.0, 0.96875, 0.984375, 0.984375, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.984375, 0.0, 0.96875, 0.0, 0.984375, 0.96875, 0.0, 0.0, 0.96875, 0.96875]

 sparsity of   [0.9965277910232544, 0.9965277910232544, 0.5625, 0.0, 0.9965277910232544, 0.5625, 0.9965277910232544, 0.0, 0.9982638955116272, 0.9965277910232544, 0.0, 0.5625, 0.9965277910232544, 0.5625, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.0, 0.9965277910232544, 0.0, 0.9965277910232544, 0.9947916865348816, 0.0, 0.0, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.0, 0.9965277910232544, 0.9965277910232544, 0.0, 0.5625, 0.9965277910232544, 0.9965277910232544, 0.0, 0.9982638955116272, 0.9965277910232544, 0.5625, 0.0, 0.0, 0.9965277910232544, 0.0, 0.5625, 0.9965277910232544, 0.0, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.0, 0.0, 0.9982638955116272, 0.9982638955116272, 0.0, 0.5625, 0.9965277910232544, 0.0, 0.0, 0.9965277910232544, 0.0, 0.9965277910232544, 0.9965277910232544, 0.5625]

 sparsity of   [0.0, 0.96875, 0.984375, 0.546875, 0.984375, 0.96875, 0.0, 0.0, 0.0, 0.546875, 0.546875, 0.0, 0.546875, 0.0, 0.0, 0.546875, 0.546875, 0.0, 0.0, 0.953125, 0.0, 0.0, 0.96875, 0.984375, 0.0, 0.0, 0.96875, 0.953125, 0.546875, 0.375, 0.0, 0.0, 0.984375, 0.0, 0.546875, 0.0, 0.4375, 0.546875, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.984375, 0.546875, 0.0, 0.546875, 0.0, 0.96875, 0.546875, 0.96875, 0.0, 0.96875, 0.0, 0.546875, 0.0, 0.0, 0.546875, 0.53125, 0.0, 0.546875, 0.0, 0.046875, 0.71875, 0.0, 0.0, 0.0, 0.546875, 0.0, 0.0625, 0.0, 0.265625, 0.546875, 0.0, 0.0, 0.953125, 0.546875, 0.46875, 0.953125, 0.96875, 0.0, 0.96875, 0.0, 0.546875, 0.0, 0.0, 0.546875, 0.0, 0.0, 0.96875, 0.96875, 0.984375, 0.0, 0.0, 0.96875, 0.96875, 0.546875, 0.0, 0.0, 0.546875, 0.0, 0.546875, 0.96875, 0.546875, 0.546875, 0.578125, 0.546875, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.546875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.953125, 0.015625, 0.546875, 0.96875, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.96875, 0.0, 0.546875, 0.0, 0.0, 0.546875, 0.0, 0.96875, 0.0, 0.984375, 0.0, 0.546875, 0.0, 0.546875, 0.0, 0.0, 0.546875, 0.0, 0.0, 0.0, 0.546875, 0.984375, 0.0, 0.546875, 0.0, 0.546875, 0.0, 0.546875, 0.96875, 0.96875, 0.546875, 0.0, 0.96875, 0.0, 0.96875, 0.0, 0.0, 0.546875, 0.0, 0.0, 0.546875, 0.0, 0.546875, 0.984375, 0.546875, 0.546875, 0.546875, 0.96875, 0.96875, 0.109375, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.546875, 0.0, 0.546875, 0.0, 0.96875, 0.546875, 0.96875, 0.546875, 0.96875, 0.546875, 0.984375, 0.0, 0.0, 0.984375, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.96875, 0.0, 0.96875, 0.0, 0.0, 0.984375, 0.96875, 0.0, 0.96875, 0.546875, 0.96875, 0.546875, 0.0, 0.0, 0.0, 0.546875, 0.0, 0.984375, 0.0, 0.0, 0.96875, 0.96875, 0.546875, 0.0, 0.546875, 0.0, 0.0, 0.546875, 0.0, 0.0, 0.0, 0.0, 0.546875, 0.96875, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.546875, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 0.984375, 0.96875, 0.0, 0.96875, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.984375, 0.96875, 0.0, 0.0, 0.96875, 0.96875, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4375, 0.0, 0.96875, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.984375, 0.96875, 0.0, 0.96875, 0.4375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.96875, 0.96875, 0.0, 0.0, 0.984375, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.953125, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.96875, 0.0, 0.0, 0.96875, 0.0, 0.96875, 0.0, 0.0, 0.4375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.984375, 0.96875, 0.96875, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.96875, 0.0, 0.96875, 0.0, 0.96875, 0.0, 0.0, 0.96875, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.96875, 0.0, 0.0, 0.96875, 0.96875, 0.0, 0.84375, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4375, 0.984375, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.265625, 0.265625, 0.0, 0.49609375, 0.9921875, 0.9921875, 0.0, 0.265625, 0.265625, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.265625, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0]

 sparsity of   [0.9965277910232544, 0.0, 0.9965277910232544, 0.9965277910232544, 0.5, 0.5, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.0, 0.0, 0.0, 0.0, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.0, 0.9965277910232544, 0.5, 0.5, 0.9965277910232544, 0.9982638955116272, 0.9965277910232544, 0.9965277910232544, 0.0, 0.5, 0.0, 0.0, 0.9965277910232544, 0.9965277910232544, 0.5, 0.5, 0.0, 0.5, 0.9965277910232544, 0.0, 0.9965277910232544, 0.0, 0.9965277910232544, 0.9965277910232544, 0.0, 0.5, 0.9982638955116272, 0.9965277910232544, 0.0, 0.5, 0.9965277910232544, 0.9965277910232544, 0.0, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.0, 0.0, 0.0, 0.0, 0.9982638955116272, 0.9965277910232544, 0.9965277910232544, 0.5, 0.5, 0.9965277910232544]

 sparsity of   [0.0, 0.96875, 0.0, 0.0, 0.96875, 0.515625, 0.515625, 0.0, 0.0, 0.0, 0.515625, 0.0, 0.0, 0.0, 0.515625, 0.515625, 0.515625, 0.0, 0.515625, 0.984375, 0.515625, 0.515625, 0.0, 0.984375, 0.0, 0.0, 0.515625, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.515625, 0.0, 0.0, 0.515625, 0.0, 0.0, 0.515625, 0.515625, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.515625, 0.0, 0.515625, 0.96875, 0.0, 0.0, 0.515625, 0.515625, 0.0, 0.0, 0.515625, 0.0, 0.0, 0.515625, 0.0, 0.953125, 0.0, 0.0, 0.0, 0.515625, 0.0, 0.0, 0.515625, 0.0, 0.0, 0.515625, 0.0, 0.0, 0.0, 0.515625, 0.515625, 0.515625, 0.515625, 0.0, 0.0, 0.515625, 0.34375, 0.0, 0.0, 0.0, 0.0, 0.515625, 0.0, 0.96875, 0.96875, 0.0, 0.0, 0.96875, 0.96875, 0.0, 0.0, 0.0, 0.515625, 0.0, 0.0, 0.96875, 0.515625, 0.0, 0.96875, 0.515625, 0.515625, 0.0, 0.0, 0.515625, 0.0, 0.96875, 0.515625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.515625, 0.0, 0.0, 0.515625, 0.0, 0.96875, 0.0, 0.0, 0.953125, 0.515625, 0.0, 0.0, 0.515625, 0.0, 0.0, 0.515625, 0.515625, 0.96875, 0.0, 0.515625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0625, 0.0, 0.0, 0.0, 0.515625, 0.0, 0.0, 0.0, 0.515625, 0.0, 0.515625, 0.0, 0.0, 0.515625, 0.0, 0.0, 0.0, 0.515625, 0.515625, 0.0, 0.015625, 0.0, 0.515625, 0.515625, 0.0, 0.515625, 0.0, 0.0, 0.515625, 0.0, 0.0, 0.515625, 0.96875, 0.0, 0.984375, 0.0, 0.0, 0.515625, 0.515625, 0.0, 0.0, 0.0, 0.96875, 0.515625, 0.0, 0.515625, 0.984375, 0.515625, 0.0, 0.0, 0.0, 0.0, 0.421875, 0.0625, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.03125, 0.96875, 0.0, 0.515625, 0.515625, 0.515625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.515625, 0.0, 0.515625, 0.0, 0.0, 0.515625, 0.0, 0.0, 0.96875, 0.515625, 0.0, 0.515625, 0.0, 0.0, 0.515625, 0.515625, 0.0, 0.0, 0.0, 0.515625, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.515625, 0.0]

 sparsity of   [0.0, 0.9921875, 0.0, 0.203125, 0.0, 0.0390625, 0.953125, 0.109375, 0.0859375, 0.12890625, 0.98828125, 0.0, 0.01953125, 0.99609375, 0.9921875, 0.02734375, 0.0, 0.8125, 0.9921875, 0.9921875, 0.0, 0.0, 0.26953125, 0.015625, 0.02734375, 0.0, 0.9921875, 0.01171875, 0.1328125, 0.0, 0.9921875, 0.01171875, 0.0, 0.98828125, 0.0, 0.9921875, 0.07421875, 0.0, 0.0, 0.1953125, 0.01171875, 0.078125, 0.98828125, 0.37109375, 0.01171875, 0.0, 0.0, 0.05859375, 0.9921875, 0.046875, 0.98828125, 0.01953125, 0.01953125, 0.94140625, 0.9921875, 0.2578125, 0.0, 0.4296875, 0.02734375, 0.05859375, 0.99609375, 0.0, 0.9921875, 0.0]

 sparsity of   [0.8055555820465088, 0.0381944440305233, 0.6822916865348816, 0.0, 0.9982638955116272, 0.0625, 0.0, 0.881944477558136, 0.0399305559694767, 0.0, 0.1111111119389534, 0.01909722201526165, 0.0, 0.0, 0.0520833320915699, 0.1701388955116272, 0.8836805820465088, 0.9982638955116272, 0.0, 0.0, 0.0694444477558136, 0.0, 0.9947916865348816, 0.09375, 0.0607638880610466, 0.0, 0.9965277910232544, 0.02083333395421505, 0.8732638955116272, 0.0, 0.0225694440305233, 0.8454861044883728, 0.0329861119389534, 0.1961805522441864, 0.9982638955116272, 0.0607638880610466, 0.9965277910232544, 0.0, 0.1909722238779068, 0.4149305522441864, 0.02083333395421505, 0.0, 0.0173611119389534, 0.2135416716337204, 0.0069444444961845875, 0.9982638955116272, 0.2170138955116272, 0.0, 0.0381944440305233, 0.9965277910232544, 0.859375, 0.0347222238779068, 0.0920138880610466, 0.0659722238779068, 0.881944477558136, 0.078125, 0.0538194440305233, 0.0, 0.9965277910232544, 0.0, 0.0, 0.0677083358168602, 0.9965277910232544, 0.0798611119389534]

 sparsity of   [0.0, 0.0, 0.703125, 0.015625, 0.0, 0.53125, 0.03125, 0.0, 0.0, 0.703125, 0.6875, 0.0, 0.0, 0.0, 0.703125, 0.703125, 0.0, 0.0, 0.703125, 0.0, 0.6875, 0.703125, 0.0, 0.0, 0.703125, 0.03125, 0.703125, 0.0, 0.703125, 0.65625, 0.703125, 0.703125, 0.703125, 0.703125, 0.640625, 0.703125, 0.703125, 0.0, 0.65625, 0.015625, 0.703125, 0.703125, 0.984375, 0.703125, 0.703125, 0.0, 0.0, 0.0, 0.703125, 0.703125, 0.65625, 0.0, 0.0, 0.703125, 0.078125, 0.703125, 0.6875, 0.703125, 0.03125, 0.703125, 0.0, 0.65625, 0.0625, 0.0, 0.703125, 0.0, 0.703125, 0.0, 0.6875, 0.0, 0.0, 0.0, 0.703125, 0.703125, 0.6875, 0.03125, 0.0, 0.703125, 0.6875, 0.703125, 0.6875, 0.6875, 0.0, 0.703125, 0.703125, 0.0, 0.703125, 0.703125, 0.0, 0.09375, 0.078125, 0.0, 0.0, 0.0, 0.703125, 0.0, 0.0, 0.703125, 0.265625, 0.0, 0.6875, 0.0, 0.703125, 0.0, 0.703125, 0.703125, 0.640625, 0.25, 0.078125, 0.703125, 0.0, 0.703125, 0.25, 0.640625, 0.703125, 0.0, 0.140625, 0.703125, 0.0, 0.703125, 0.0, 0.703125, 0.703125, 0.09375, 0.703125, 0.0, 0.703125, 0.59375, 0.0, 0.0, 0.0, 0.703125, 0.0625, 0.0, 0.0, 0.0, 0.703125, 0.6875, 0.625, 0.0, 0.6875, 0.703125, 0.703125, 0.703125, 0.0, 0.09375, 0.703125, 0.703125, 0.703125, 0.421875, 0.0, 0.625, 0.0625, 0.0625, 0.0, 0.703125, 0.0, 0.703125, 0.0, 0.0, 0.703125, 0.0, 0.703125, 0.0, 0.703125, 0.0, 0.703125, 0.65625, 0.703125, 0.703125, 0.703125, 0.0, 0.703125, 0.703125, 0.703125, 0.6875, 0.0, 0.703125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.703125, 0.703125, 0.0625, 0.703125, 0.0, 0.703125, 0.703125, 0.640625, 0.015625, 0.0, 0.703125, 0.703125, 0.0, 0.703125, 0.703125, 0.0, 0.6875, 0.0, 0.703125, 0.703125, 0.703125, 0.0, 0.609375, 0.6875, 0.0, 0.0, 0.6875, 0.96875, 0.6875, 0.703125, 0.703125, 0.0, 0.0, 0.0, 0.0, 0.65625, 0.703125, 0.703125, 0.0, 0.703125, 0.0, 0.0, 0.0, 0.0, 0.6875, 0.0, 0.125, 0.671875, 0.0, 0.703125, 0.703125, 0.703125, 0.0, 0.296875, 0.703125, 0.0, 0.0, 0.0, 0.703125, 0.0, 0.0, 0.703125, 0.703125, 0.0, 0.0, 0.125, 0.0, 0.703125, 0.0, 0.703125, 0.6875, 0.6875]

 sparsity of   [0.99609375, 0.98828125, 0.0, 0.30078125, 0.00390625, 0.109375, 0.0, 0.3515625, 0.9921875, 0.0, 0.08203125, 0.0, 0.0, 0.9921875, 0.9921875, 0.98828125, 0.99609375, 0.99609375, 0.99609375, 0.9921875, 0.0, 0.0078125, 0.0, 0.40234375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.3671875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.99609375, 0.99609375, 0.46484375, 0.0078125, 0.9921875, 0.0, 0.2265625, 0.9921875, 0.9921875, 0.99609375, 0.05078125, 0.984375, 0.0078125, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.98828125, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.36328125, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.98828125, 0.0, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.0, 0.328125, 0.9921875, 0.99609375, 0.00390625, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.98828125, 0.0, 0.9921875, 0.9921875, 0.68359375, 0.1171875, 0.9921875, 0.3203125, 0.0, 0.9921875, 0.50390625, 0.0, 0.9921875, 0.99609375, 0.0, 0.0078125, 0.09765625, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.0]

 sparsity of   [0.0173611119389534, 0.0, 0.0, 0.0581597238779068, 0.0, 0.9322916865348816, 0.1336805522441864, 0.0078125, 0.9375, 0.078125, 0.0329861119389534, 0.0, 0.0, 0.625, 0.0, 0.9973958134651184, 0.9982638955116272, 0.0434027798473835, 0.0, 0.0, 0.0434027798473835, 0.0, 0.0, 0.9982638955116272, 0.0, 0.0, 0.0, 0.0642361119389534, 0.0, 0.0, 0.0, 0.110243059694767, 0.0, 0.0399305559694767, 0.01909722201526165, 0.9982638955116272, 0.0, 0.1336805522441864, 0.0, 0.999131977558136, 0.269097238779068, 0.0, 0.9982638955116272, 0.0329861119389534, 0.0, 0.0, 0.8758680820465088, 0.5494791865348816, 0.0, 0.0494791679084301, 0.0, 0.0078125, 0.9982638955116272, 0.0, 0.01909722201526165, 0.0, 0.01996527798473835, 0.0, 0.0, 0.0529513880610466, 0.1328125, 0.1015625, 0.01996527798473835, 0.9383680820465088, 0.0, 0.0486111119389534, 0.01128472201526165, 0.0, 0.8810763955116272, 0.0451388880610466, 0.0, 0.0451388880610466, 0.0, 0.0, 0.0164930559694767, 0.063368059694767, 0.0460069440305233, 0.0, 0.0833333358168602, 0.1128472238779068, 0.9973958134651184, 0.0, 0.0355902798473835, 0.0416666679084301, 0.9513888955116272, 0.071180559694767, 0.999131977558136, 0.1258680522441864, 0.5798611044883728, 0.0, 0.0, 0.0668402761220932, 0.0, 0.9973958134651184, 0.8255208134651184, 0.0668402761220932, 0.8246527910232544, 0.1163194477558136, 0.0, 0.0164930559694767, 0.0, 0.0173611119389534, 0.8654513955116272, 0.8932291865348816, 0.0225694440305233, 0.0, 0.01215277798473835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8480902910232544, 0.0442708320915699, 0.0407986119389534, 0.0, 0.1744791716337204, 0.0, 0.0, 0.0364583320915699, 0.9973958134651184, 0.0251736119389534, 0.0381944440305233, 0.0755208358168602, 0.0303819440305233, 0.0]

 sparsity of   [0.96875, 0.0, 0.984375, 0.984375, 0.984375, 0.984375, 0.9765625, 0.9921875, 0.9921875, 0.9921875, 0.40625, 0.0, 0.9921875, 0.0, 0.5390625, 0.0, 0.984375, 0.984375, 0.0, 0.984375, 0.9921875, 0.984375, 0.984375, 0.0, 0.0, 0.984375, 0.0, 0.984375, 0.984375, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.9765625, 0.9765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.0234375, 0.0, 0.984375, 0.9921875, 0.0, 0.0, 0.984375, 0.0, 0.1328125, 0.984375, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.9921875, 0.984375, 0.046875, 0.0, 0.0, 0.5390625, 0.9921875, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.9765625, 0.9921875, 0.03125, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.984375, 0.0, 0.0, 0.8203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5390625, 0.0, 0.984375, 0.9765625, 0.0, 0.0, 0.0, 0.0, 0.78125, 0.984375, 0.0, 0.0, 0.9921875, 0.3203125, 0.0, 0.984375, 0.0, 0.0, 0.9921875, 0.9765625, 0.5390625, 0.9921875, 0.984375, 0.0, 0.0, 0.984375, 0.0, 0.984375, 0.0, 0.984375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0390625, 0.0, 0.984375, 0.296875, 0.0, 0.0, 0.9921875, 0.5390625, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.9921875, 0.0, 0.0, 0.0, 0.0546875, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.984375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.78125, 0.9765625, 0.0, 0.0, 0.5390625, 0.0625, 0.0, 0.984375, 0.5390625, 0.984375, 0.984375, 0.0, 0.0, 0.9921875, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.984375, 0.984375, 0.984375, 0.984375, 0.4609375, 0.0, 0.984375, 0.984375, 0.0, 0.484375, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.9921875, 0.0, 0.5390625, 0.0, 0.0, 0.9765625, 0.9765625, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.984375, 0.984375, 0.9921875, 0.9765625, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.984375, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.96875, 0.984375, 0.0, 0.0, 0.984375, 0.0, 0.9921875, 0.0, 0.0859375, 0.0, 0.984375, 0.9921875, 0.53125, 0.984375, 0.984375, 0.0, 0.046875, 0.984375, 0.0, 0.984375, 0.0, 0.5078125, 0.984375, 0.9921875, 0.984375, 0.984375, 0.5390625, 0.9921875, 0.984375, 0.0, 0.0, 0.0, 0.03125, 0.9921875, 0.984375, 0.984375, 0.0, 0.0, 0.4609375, 0.0, 0.4296875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.53125, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9765625, 0.703125, 0.9765625, 0.0, 0.984375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.390625, 0.984375, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.9765625, 0.984375, 0.1328125, 0.0, 0.984375, 0.984375, 0.5390625, 0.9921875, 0.0, 0.9453125, 0.46875, 0.0, 0.0, 0.0, 0.9921875, 0.5390625, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.984375, 0.984375, 0.9921875, 0.0, 0.984375, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.5390625, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.984375, 0.984375, 0.0, 0.9921875, 0.9765625, 0.9921875, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.5390625, 0.953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.984375, 0.0, 0.984375, 0.0, 0.984375, 0.984375, 0.984375, 0.4296875, 0.9921875, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.984375, 0.984375, 0.9921875, 0.0, 0.984375, 0.0, 0.0, 0.4140625, 0.0, 0.9765625, 0.0, 0.0, 0.984375, 0.9765625, 0.984375, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.984375, 0.0, 0.984375, 0.5390625, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.046875, 0.984375, 0.0, 0.0]

 sparsity of   [0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0078125, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.99609375, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0078125, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.98828125, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0078125, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.0078125, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0078125, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.98828125, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0078125, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0078125, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0]

 sparsity of   [0.439453125, 0.0, 0.99609375, 0.0, 0.439453125, 0.994140625, 0.41796875, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.998046875, 0.99609375, 0.99609375, 0.998046875, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.994140625, 0.99609375, 0.0, 0.998046875, 0.439453125, 0.99609375, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.4375, 0.99609375, 0.439453125, 0.99609375, 0.99609375, 0.4375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.998046875, 0.99609375, 0.439453125, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.994140625, 0.0, 0.99609375, 0.994140625, 0.99609375, 0.99609375, 0.0, 0.439453125, 0.0, 0.99609375, 0.0, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.99609375, 0.439453125, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.439453125, 0.439453125, 0.998046875, 0.0, 0.0, 0.0, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.439453125, 0.99609375, 0.99609375, 0.99609375, 0.4375, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.4375, 0.99609375, 0.0, 0.998046875, 0.0, 0.439453125, 0.0, 0.994140625, 0.99609375, 0.994140625, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.439453125, 0.0, 0.998046875, 0.439453125, 0.0, 0.998046875, 0.998046875, 0.439453125, 0.0]

 sparsity of   [0.0, 0.999131977558136, 0.0, 0.0, 0.9982638955116272, 0.9982638955116272, 0.999131977558136, 0.9982638955116272, 0.9982638955116272, 0.0, 0.0, 0.9982638955116272, 0.553819477558136, 0.9982638955116272, 0.999131977558136, 0.0, 0.0, 0.0, 0.0, 0.9982638955116272, 0.9982638955116272, 0.0, 0.999131977558136, 0.0, 0.9982638955116272, 0.9982638955116272, 0.0, 0.0, 0.9982638955116272, 0.999131977558136, 0.9982638955116272, 0.999131977558136, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.0, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.999131977558136, 0.9982638955116272, 0.9982638955116272, 0.0, 0.9982638955116272, 0.0, 0.0, 0.0, 0.999131977558136, 0.5625, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.0, 0.0, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.0, 0.9982638955116272, 0.999131977558136, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.999131977558136, 0.0, 0.0, 0.9982638955116272, 0.0, 0.0, 0.9982638955116272, 0.0, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.0, 0.0, 0.999131977558136, 0.9982638955116272, 0.0, 0.9982638955116272, 0.0, 0.9982638955116272, 0.0, 0.999131977558136, 0.9982638955116272, 0.9982638955116272, 0.0, 0.9982638955116272, 0.0, 0.9982638955116272, 0.0, 0.0, 0.999131977558136, 0.9982638955116272, 0.0, 0.999131977558136, 0.0, 0.9982638955116272, 0.0, 0.0, 0.9982638955116272, 0.9982638955116272, 0.0, 0.9982638955116272, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9982638955116272, 0.0, 0.0, 0.9982638955116272, 0.0, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.999131977558136, 0.9982638955116272, 0.999131977558136]

 sparsity of   [0.984375, 0.0, 0.9921875, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.9765625, 0.984375, 0.984375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.984375, 0.6953125, 0.640625, 0.9921875, 0.609375, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1796875, 0.0, 0.6484375, 0.6484375, 0.0, 0.640625, 0.9921875, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.6484375, 0.0, 0.0, 0.984375, 0.640625, 0.984375, 0.6328125, 0.0, 0.0, 0.640625, 0.9921875, 0.984375, 0.0, 0.0, 0.640625, 0.1796875, 0.0, 0.0703125, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.6484375, 0.0, 0.6328125, 0.0, 0.9765625, 0.640625, 0.0, 0.984375, 0.0, 0.0, 0.984375, 0.6484375, 0.0, 0.0, 0.0, 0.0, 0.6484375, 0.640625, 0.0703125, 0.9765625, 0.0, 0.6328125, 0.0, 0.0, 0.984375, 0.9921875, 0.0, 0.9921875, 0.515625, 0.9765625, 0.0, 0.984375, 0.0, 0.0, 0.984375, 0.984375, 0.90625, 0.9921875, 0.9921875, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.984375, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.078125, 0.0, 0.9921875, 0.9765625, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.0, 0.0, 0.640625, 0.984375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.984375, 0.6328125, 0.984375, 0.0, 0.46875, 0.0, 0.0, 0.0, 0.0, 0.6484375, 0.0, 0.0, 0.640625, 0.0, 0.0625, 0.0, 0.0, 0.640625, 0.9921875, 0.9921875, 0.0, 0.0, 0.640625, 0.984375, 0.0, 0.9765625, 0.6328125, 0.984375, 0.984375, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.9921875, 0.640625, 0.9921875, 0.703125, 0.0, 0.984375, 0.984375, 0.0, 0.984375, 0.0, 0.984375, 0.0, 0.6484375, 0.0, 0.9921875, 0.640625, 0.0, 0.6328125, 0.0, 0.0, 0.0, 0.6328125, 0.6328125, 0.0, 0.0, 0.0, 0.0, 0.6484375, 0.9921875, 0.296875, 0.0, 0.6484375, 0.0, 0.0, 0.9921875, 0.984375, 0.9921875, 0.0, 0.6484375, 0.0, 0.0, 0.6484375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9765625, 0.0, 0.96875, 0.984375, 0.28125, 0.0, 0.640625, 0.0, 0.6328125, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.1015625, 0.0, 0.9921875, 0.4375, 0.0, 0.0, 0.0, 0.4140625, 0.984375, 0.0, 0.0, 0.984375, 0.6328125, 0.0, 0.6484375, 0.0, 0.0, 0.984375, 0.984375, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.8046875, 0.6328125, 0.0, 0.0, 0.9921875, 0.09375, 0.9765625, 0.984375, 0.9921875, 0.0, 0.984375, 0.640625, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.984375, 0.0, 0.6328125, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.09375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7890625, 0.90625, 0.6328125, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.6484375, 0.984375, 0.640625, 0.9921875, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6328125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.984375, 0.0, 0.9765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9296875, 0.0, 0.0, 0.9921875, 0.640625, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.9921875, 0.984375, 0.0, 0.984375, 0.0, 0.984375, 0.7890625, 0.0, 0.0, 0.0, 0.9921875, 0.640625, 0.9921875, 0.0, 0.0, 0.0, 0.640625, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.984375, 0.9921875, 0.984375, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.9921875, 0.078125, 0.0, 0.0, 0.0, 0.625, 0.9765625, 0.6484375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.984375, 0.9921875, 0.0, 0.0, 0.8046875, 0.6484375, 0.0, 0.0, 0.203125, 0.0, 0.0, 0.0, 0.9921875, 0.6484375, 0.0, 0.984375, 0.0, 0.6484375, 0.9765625, 0.0, 0.0, 0.0, 0.0, 0.6328125, 0.984375, 0.0, 0.0, 0.9765625, 0.0, 0.9921875, 0.9921875, 0.9765625, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.6484375, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.984375, 0.140625, 0.984375, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.6328125, 0.0, 0.0, 0.6328125, 0.984375, 0.6328125, 0.0, 0.0, 0.0, 0.296875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.9765625, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.859375, 0.0, 0.0, 0.072265625, 0.0, 0.3125, 0.0, 0.09765625, 0.0, 0.0, 0.0, 0.875, 0.0, 0.994140625, 0.330078125, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.326171875, 0.015625, 0.0, 0.0, 0.99609375, 0.12109375, 0.0, 0.0, 0.14453125, 0.0, 0.0703125, 0.58203125, 0.14453125, 0.05078125, 0.0, 0.0, 0.076171875, 0.037109375, 0.041015625, 0.0, 0.02734375, 0.0, 0.0, 0.0, 0.0, 0.9140625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037109375, 0.0, 0.30859375, 0.0, 0.99609375, 0.1015625, 0.0, 0.998046875, 0.0, 0.044921875, 0.0, 0.515625, 0.0, 0.0, 0.0, 0.025390625, 0.052734375, 0.0, 0.861328125, 0.0, 0.0, 0.15234375, 0.0, 0.134765625, 0.0, 0.0, 0.04296875, 0.0, 0.021484375, 0.080078125, 0.0, 0.0, 0.0, 0.0, 0.05078125, 0.0, 0.0, 0.0, 0.068359375, 0.0, 0.123046875, 0.0, 0.0, 0.0, 0.0, 0.033203125, 0.330078125, 0.994140625, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.060546875, 0.0, 0.02734375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37109375, 0.0, 0.0, 0.0, 0.07421875, 0.99609375, 0.0]

 sparsity of   [0.009548611007630825, 0.0, 0.0, 0.300347238779068, 0.0251736119389534, 0.1944444477558136, 0.0, 0.0, 0.0, 0.9435763955116272, 0.0303819440305233, 0.010416666977107525, 0.0, 0.7925347089767456, 0.0381944440305233, 0.015625, 0.046875, 0.1649305522441864, 0.3914930522441864, 0.0, 0.0, 0.140625, 0.8845486044883728, 0.0, 0.0989583358168602, 0.9973958134651184, 0.0, 0.0, 0.0598958320915699, 0.0390625, 0.0243055559694767, 0.03125, 0.0, 0.0, 0.0564236119389534, 0.0017361111240461469, 0.0451388880610466, 0.0407986119389534, 0.0, 0.0, 0.0737847238779068, 0.1076388880610466, 0.0, 0.015625, 0.7977430820465088, 0.1762152761220932, 0.009548611007630825, 0.0321180559694767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02864583395421505, 0.0, 0.086805559694767, 0.0, 0.7361111044883728, 0.0, 0.0, 0.0355902798473835, 0.0, 0.0, 0.8420138955116272, 0.0677083358168602, 0.1067708358168602, 0.0251736119389534, 0.0321180559694767, 0.0, 0.0763888880610466, 0.0876736119389534, 0.0876736119389534, 0.0434027798473835, 0.0529513880610466, 0.0416666679084301, 0.0920138880610466, 0.0, 0.0243055559694767, 0.1067708358168602, 0.0, 0.0303819440305233, 0.0, 0.0, 0.1215277761220932, 0.0, 0.0, 0.0390625, 0.0668402761220932, 0.0, 0.2491319477558136, 0.8402777910232544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2447916716337204, 0.02690972201526165, 0.0, 0.0685763880610466, 0.0, 0.0, 0.0425347238779068, 0.0, 0.0598958320915699, 0.0598958320915699, 0.84375, 0.0, 0.0, 0.0651041641831398, 0.0, 0.7065972089767456, 0.0572916679084301, 0.009548611007630825, 0.0503472238779068, 0.0, 0.0347222238779068, 0.0, 0.0677083358168602, 0.9973958134651184, 0.0, 0.02170138992369175, 0.0, 0.671006977558136, 0.0]

 sparsity of   [0.0, 0.0, 0.9921875, 0.0, 0.0, 0.078125, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.984375, 0.1171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.609375, 0.984375, 0.0, 0.5625, 0.0, 0.0, 0.5546875, 0.5625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5546875, 0.0, 0.0, 0.5625, 0.0, 0.0, 0.0, 0.5625, 0.0, 0.0, 0.0625, 0.0, 0.140625, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.9765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5625, 0.5625, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.546875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.078125, 0.0, 0.5625, 0.0, 0.0, 0.5625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.546875, 0.5625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9765625, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.5625, 0.5625, 0.0, 0.0, 0.0, 0.9765625, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.9921875, 0.0, 0.9921875, 0.984375, 0.0, 0.0, 0.5625, 0.546875, 0.0, 0.0, 0.0, 0.5546875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.5625, 0.0, 0.6484375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.5625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5625, 0.984375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.578125, 0.0, 0.0, 0.0, 0.4921875, 0.9921875, 0.0, 0.0, 0.0, 0.0703125, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.5625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.5625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.140625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0625, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.984375, 0.9921875, 0.515625, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.5625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7734375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.7734375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.421875, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.34375, 0.0, 0.0, 0.5625, 0.453125, 0.0, 0.0, 0.0, 0.0, 0.5625, 0.0, 0.0, 0.9921875, 0.78125, 0.0, 0.0, 0.0, 0.0, 0.0390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5625, 0.0, 0.984375, 0.1484375, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.9921875, 0.984375, 0.0, 0.0, 0.984375, 0.1953125, 0.0, 0.0, 0.984375, 0.5625, 0.0, 0.0, 0.0, 0.5625, 0.0, 0.984375, 0.0, 0.5625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5625, 0.5625, 0.0, 0.0, 0.984375, 0.078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2109375, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0]

 sparsity of   [0.146484375, 0.0, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.765625, 0.0, 0.0, 0.0, 0.427734375, 0.0, 0.0, 0.189453125, 0.341796875, 0.0, 0.0, 0.15625, 0.021484375, 0.041015625, 0.0, 0.0, 0.017578125, 0.0, 0.02734375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.99609375, 0.0, 0.0625, 0.99609375, 0.0, 0.0, 0.99609375, 0.994140625, 0.0, 0.921875, 0.10546875, 0.0, 0.0, 0.0, 0.095703125, 0.0, 0.99609375, 0.06640625, 0.0, 0.0, 0.0, 0.029296875, 0.845703125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.064453125, 0.0, 0.025390625, 0.0, 0.0, 0.0, 0.931640625, 0.0, 0.0, 0.0625, 0.01171875, 0.0, 0.119140625, 0.0, 0.927734375, 0.00390625, 0.0, 0.0, 0.1640625, 0.7578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.03125, 0.02734375, 0.0, 0.0, 0.0, 0.0, 0.103515625, 0.0, 0.017578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2265625, 0.126953125, 0.0, 0.0, 0.0, 0.0, 0.353515625, 0.0, 0.955078125, 0.69921875, 0.0, 0.0, 0.955078125, 0.88671875, 0.0, 0.01171875, 0.77734375, 0.01171875, 0.048828125, 0.046875]

 sparsity of   [0.0355902798473835, 0.02170138992369175, 0.8758680820465088, 0.0, 0.01996527798473835, 0.1145833358168602, 0.0234375, 0.0, 0.0, 0.0164930559694767, 0.0416666679084301, 0.0164930559694767, 0.2065972238779068, 0.8715277910232544, 0.013020833022892475, 0.0, 0.0, 0.0642361119389534, 0.0251736119389534, 0.0, 0.0512152798473835, 0.0520833320915699, 0.0954861119389534, 0.0, 0.0, 0.0, 0.0, 0.0321180559694767, 0.0729166641831398, 0.0, 0.9019097089767456, 0.0, 0.0, 0.0564236119389534, 0.0, 0.0, 0.0, 0.094618059694767, 0.0373263880610466, 0.0355902798473835, 0.0, 0.0763888880610466, 0.0, 0.0, 0.0, 0.0225694440305233, 0.0225694440305233, 0.0329861119389534, 0.0, 0.0, 0.02083333395421505, 0.010416666977107525, 0.0, 0.0, 0.0, 0.078125, 0.0, 0.0, 0.0, 0.9956597089767456, 0.0, 0.0355902798473835, 0.0, 0.0, 0.0, 0.999131977558136, 0.071180559694767, 0.0, 0.00434027798473835, 0.0, 0.0, 0.0442708320915699, 0.0, 0.006076388992369175, 0.02170138992369175, 0.1137152761220932, 0.999131977558136, 0.0, 0.0, 0.0, 0.0425347238779068, 0.0225694440305233, 0.0, 0.0, 0.0, 0.819444477558136, 0.0, 0.1545138955116272, 0.0, 0.8385416865348816, 0.0520833320915699, 0.02083333395421505, 0.0, 0.9418402910232544, 0.0, 0.0, 0.01996527798473835, 0.0763888880610466, 0.0, 0.015625, 0.0, 0.0, 0.59375, 0.02690972201526165, 0.0, 0.0, 0.0, 0.999131977558136, 0.0, 0.0, 0.0225694440305233, 0.0, 0.1145833358168602, 0.01215277798473835, 0.0, 0.0, 0.0842013880610466, 0.953125, 0.0, 0.0616319440305233, 0.0225694440305233, 0.0, 0.0, 0.0, 0.0, 0.00434027798473835, 0.09375, 0.0703125]

 sparsity of   [0.0, 0.5078125, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.5078125, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5078125, 0.984375, 0.0390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.484375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.0, 0.78125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4296875, 0.0, 0.0, 0.0, 0.4765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.109375, 0.0, 0.0, 0.0, 0.71875, 0.4921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.5078125, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.984375, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0703125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.0, 0.0, 0.5234375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4921875, 0.0, 0.4921875, 0.0, 0.0, 0.0, 0.5, 0.203125, 0.0, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.5078125, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8046875, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 0.998046875, 0.03125, 0.99609375, 0.0, 0.998046875, 0.99609375, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.029296875, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.03515625, 0.0, 0.998046875, 0.99609375, 0.99609375, 0.03515625, 0.99609375, 0.0, 0.998046875, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.99609375, 0.03515625, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.99609375, 0.03515625, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.03515625, 0.0, 0.0, 0.0, 0.998046875, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03515625, 0.99609375, 0.0, 0.0, 0.0, 0.99609375, 0.03515625, 0.0, 0.99609375, 0.99609375, 0.998046875, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.03125, 0.99609375, 0.0, 0.998046875, 0.03515625, 0.0, 0.0, 0.99609375, 0.99609375, 0.998046875, 0.0, 0.0, 0.03515625, 0.99609375, 0.99609375, 0.99609375, 0.03515625, 0.0, 0.0, 0.0, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.03515625, 0.0, 0.0, 0.03515625, 0.03515625, 0.03515625, 0.0, 0.0, 0.0, 0.03515625, 0.0, 0.0, 0.99609375, 0.998046875, 0.99609375, 0.99609375, 0.033203125, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.0, 0.998046875, 0.0, 0.0, 0.03515625, 0.0, 0.998046875, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.03515625, 0.0, 0.03125, 0.0, 0.0, 0.99609375, 0.029296875, 0.0, 0.03515625, 0.03515625, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.03515625, 0.0, 0.0, 0.03515625, 0.99609375, 0.0, 0.0, 0.03515625, 0.998046875, 0.03515625, 0.0, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.0, 0.998046875, 0.03515625, 0.998046875, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.99609375]

 sparsity of   [0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.0, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.0, 0.0, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.3515625, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.3515625, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.0, 0.999131977558136, 0.999131977558136, 0.0967881977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.9995659589767456, 0.0, 0.9995659589767456, 0.9986979365348816, 0.999131977558136, 0.0, 0.9982638955116272, 0.9995659589767456, 0.999131977558136, 0.1119791641831398, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.3515625, 0.999131977558136, 0.9995659589767456, 0.0, 0.3515625, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.999131977558136, 0.0, 0.9995659589767456, 0.999131977558136, 0.0, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.3515625, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.3515625, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.0425347238779068, 0.0, 0.999131977558136, 0.999131977558136, 0.0, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.0, 0.0, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.3515625, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.9995659589767456, 0.0, 0.999131977558136, 0.3515625, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.0, 0.3450520932674408, 0.0, 0.999131977558136, 0.0, 0.3515625, 0.3463541567325592, 0.0, 0.999131977558136, 0.0, 0.9995659589767456]

 sparsity of   [0.0, 0.48828125, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.671875, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.671875, 0.0, 0.98828125, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.98828125, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.671875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.99609375, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.671875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.671875, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.99609375, 0.0, 0.671875, 0.671875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.671875, 0.671875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.671875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.671875, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.81640625, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.83984375, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.98828125, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.671875, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.98828125, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.98828125, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.84375, 0.9921875, 0.671875, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.98828125, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.83203125, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.671875, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.671875, 0.32421875, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.671875, 0.9921875, 0.9921875, 0.98828125, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.99609375, 0.99609375, 0.671875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.99609375, 0.0, 0.98828125, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.8671875, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.671875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.4765625, 0.0, 0.9921875, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.671875, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.671875, 0.9921875, 0.671875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.671875, 0.0, 0.9921875, 0.0, 0.2421875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.671875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.671875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.671875, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.99609375, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.0, 0.671875, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.671875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.671875, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375]

 sparsity of   [0.0, 0.173828125, 0.0, 0.99609375, 0.0, 0.548828125, 0.0, 0.0, 0.99609375, 0.0, 0.02734375, 0.998046875, 0.998046875, 0.998046875, 0.0, 0.0, 0.0, 0.080078125, 0.0, 0.099609375, 0.0, 0.162109375, 0.99609375, 0.431640625, 0.505859375, 0.0, 0.99609375, 0.169921875, 0.0, 0.068359375, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.18359375, 0.998046875, 0.994140625, 0.095703125, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.046875, 0.0, 0.896484375, 0.0, 0.16015625, 0.0, 0.0, 0.177734375, 0.078125, 0.0, 0.0, 0.017578125, 0.0, 0.994140625, 0.99609375, 0.0, 0.072265625, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13671875, 0.0, 0.998046875, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.013671875, 0.0625, 0.087890625, 0.99609375, 0.0, 0.0, 0.99609375, 0.296875, 0.0, 0.0, 0.015625, 0.0, 0.99609375, 0.0, 0.072265625, 0.0, 0.0, 0.03515625, 0.998046875, 0.99609375, 0.041015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017578125, 0.1875, 0.515625, 0.0, 0.072265625, 0.0, 0.99609375, 0.0, 0.0, 0.001953125, 0.0, 0.99609375, 0.0, 0.03125, 0.31640625, 0.353515625, 0.998046875, 0.05859375, 0.0, 0.0, 0.0078125, 0.99609375, 0.224609375, 0.0, 0.048828125, 0.0, 0.998046875, 0.0, 0.02734375, 0.001953125, 0.99609375, 0.01171875, 0.33203125, 0.10546875, 0.0, 0.99609375, 0.99609375, 0.212890625, 0.0, 0.998046875, 0.99609375, 0.0, 0.0, 0.0, 0.845703125, 0.0, 0.998046875, 0.375, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.80859375, 0.99609375, 0.0, 0.123046875, 0.0, 0.99609375, 0.0, 0.994140625, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.0, 0.033203125, 0.0, 0.0, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0859375, 0.0, 0.99609375, 0.11328125, 0.0, 0.99609375, 0.890625, 0.99609375, 0.998046875, 0.0, 0.994140625, 0.0, 0.017578125, 0.99609375, 0.0, 0.07421875, 0.078125, 0.0, 0.0, 0.9921875, 0.0625, 0.99609375, 0.05859375, 0.818359375, 0.119140625, 0.99609375, 0.0, 0.03515625, 0.265625, 0.103515625, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.06640625, 0.99609375, 0.0, 0.998046875, 0.998046875, 0.0, 0.0, 0.03515625, 0.99609375, 0.07421875, 0.796875, 0.298828125, 0.0, 0.0, 0.998046875, 0.01953125, 0.04296875, 0.2109375, 0.99609375, 0.0625, 0.0, 0.0, 0.046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.181640625, 0.056640625, 0.642578125, 0.0, 0.99609375, 0.998046875, 0.56640625, 0.0, 0.0625, 0.0, 0.109375, 0.0, 0.994140625, 0.1875, 0.060546875, 0.0, 0.994140625, 0.99609375, 0.0, 0.99609375, 0.060546875, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.017578125, 0.0, 0.13671875, 0.072265625, 0.99609375, 0.244140625, 0.0, 0.0, 0.0, 0.064453125, 0.99609375, 0.0, 0.99609375, 0.001953125, 0.0, 0.0, 0.033203125, 0.0, 0.0, 0.99609375, 0.0, 0.173828125, 0.0, 0.99609375, 0.03515625, 0.0, 0.0, 0.0, 0.013671875, 0.0, 0.99609375, 0.03515625, 0.998046875, 0.0, 0.0, 0.5703125, 0.001953125, 0.0, 0.0, 0.998046875, 0.0, 0.06640625, 0.78125, 0.0, 0.998046875, 0.0, 0.998046875, 0.06640625, 0.0, 0.111328125, 0.0, 0.0, 0.99609375, 0.16015625, 0.146484375, 0.99609375, 0.99609375, 0.0703125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.994140625, 0.287109375, 0.0859375, 0.0, 0.99609375, 0.0, 0.109375, 0.03515625, 0.998046875, 0.998046875, 0.0, 0.326171875, 0.99609375, 0.1328125, 0.0, 0.0, 0.0, 0.125, 0.998046875, 0.091796875, 0.0, 0.99609375, 0.091796875, 0.087890625, 0.0, 0.99609375, 0.99609375, 0.0, 0.763671875, 0.0, 0.99609375, 0.0, 0.154296875, 0.109375, 0.669921875, 0.0, 0.0, 0.0, 0.0, 0.052734375, 0.0, 0.0, 0.99609375, 0.013671875, 0.0, 0.109375, 0.0, 0.99609375, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.07421875, 0.01171875, 0.673828125, 0.99609375, 0.041015625, 0.0, 0.029296875, 0.0, 0.99609375, 0.998046875, 0.0546875, 0.0, 0.998046875, 0.998046875, 0.99609375, 0.005859375, 0.578125, 0.158203125, 0.0, 0.0, 0.0, 0.0, 0.994140625, 0.998046875, 0.0, 0.109375, 0.26171875, 0.0, 0.248046875, 0.99609375, 0.166015625, 0.0, 0.998046875, 0.0, 0.998046875, 0.0, 0.1796875, 0.087890625, 0.0, 0.998046875, 0.017578125, 0.99609375, 0.181640625, 0.0, 0.0, 0.0, 0.029296875, 0.8984375, 0.0, 0.0, 0.998046875, 0.001953125, 0.0, 0.0, 0.0078125, 0.537109375, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.033203125, 0.0, 0.998046875, 0.169921875, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.138671875, 0.0, 0.037109375, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.1328125, 0.0, 0.99609375, 0.08984375, 0.998046875, 0.185546875, 0.99609375, 0.0, 0.0, 0.03515625, 0.0, 0.99609375, 0.0, 0.005859375, 0.0, 0.0, 0.009765625, 0.431640625, 0.0078125, 0.064453125, 0.84765625, 0.0, 0.0, 0.0, 0.99609375, 0.171875, 0.99609375, 0.0, 0.03515625, 0.0, 0.99609375, 0.0, 0.873046875, 0.99609375, 0.0, 0.263671875, 0.0, 0.08984375, 0.15234375, 0.0, 0.99609375, 0.056640625, 0.0, 0.998046875, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.0, 0.998046875, 0.111328125, 0.0, 0.0, 0.23828125, 0.185546875, 0.994140625, 0.0, 0.390625, 0.99609375, 0.998046875, 0.078125, 0.169921875, 0.0, 0.19140625, 0.99609375, 0.0, 0.0, 0.1875, 0.021484375, 0.693359375, 0.0, 0.0, 0.0703125, 0.0, 0.0, 0.24609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.998046875, 0.998046875, 0.20703125, 0.02734375, 0.0, 0.99609375, 0.19140625, 0.994140625, 0.158203125, 0.99609375, 0.99609375, 0.181640625, 0.99609375, 0.0, 0.033203125, 0.0, 0.0, 0.001953125, 0.310546875, 0.0, 0.0, 0.0, 0.0, 0.0234375, 0.333984375, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.99609375, 0.0, 0.998046875, 0.0, 0.890625, 0.998046875, 0.99609375, 0.998046875, 0.99609375, 0.552734375, 0.177734375, 0.998046875, 0.0, 0.99609375, 0.0, 0.998046875, 0.107421875, 0.01171875, 0.0, 0.892578125, 0.0, 0.0, 0.0, 0.994140625, 0.0, 0.03125, 0.0, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.18359375, 0.107421875, 0.005859375, 0.99609375, 0.005859375, 0.2734375, 0.0625, 0.0, 0.1171875, 0.99609375, 0.03125, 0.51171875, 0.99609375, 0.099609375, 0.0, 0.0, 0.162109375, 0.01953125, 0.0, 0.0, 0.99609375, 0.0546875, 0.099609375, 0.0, 0.03515625, 0.119140625, 0.029296875, 0.99609375, 0.0, 0.904296875, 0.0, 0.126953125, 0.99609375, 0.029296875, 0.0, 0.0, 0.0, 0.123046875, 0.0, 0.0, 0.99609375, 0.0, 0.994140625, 0.998046875, 0.056640625, 0.0078125, 0.0, 0.140625, 0.994140625, 0.173828125, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.02734375, 0.23046875, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.994140625, 0.0, 0.15625, 0.0, 0.0, 0.0, 0.095703125, 0.990234375, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.998046875, 0.0, 0.0, 0.0, 0.021484375, 0.99609375, 0.0, 0.05859375, 0.994140625, 0.07421875, 0.0, 0.998046875, 0.99609375, 0.1875, 0.0, 0.99609375, 0.0078125, 0.3515625, 0.998046875, 0.115234375, 0.005859375, 0.0, 0.861328125, 0.07421875, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.14453125, 0.0, 0.1640625, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.998046875, 0.03515625, 0.005859375, 0.99609375, 0.0, 0.998046875, 0.99609375, 0.00390625, 0.0, 0.998046875, 0.1328125, 0.0, 0.033203125, 0.99609375, 0.0546875, 0.0, 0.99609375, 0.03515625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021484375, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.064453125, 0.0, 0.1484375, 0.998046875, 0.142578125, 0.125, 0.0, 0.0, 0.998046875, 0.0, 0.99609375, 0.0, 0.0, 0.1640625, 0.99609375, 0.24609375, 0.0, 0.017578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.0, 0.0, 0.095703125, 0.033203125, 0.99609375, 0.0, 0.865234375, 0.033203125, 0.99609375, 0.0703125, 0.326171875, 0.0, 0.0, 0.0, 0.0, 0.146484375, 0.0, 0.998046875, 0.03515625, 0.0078125, 0.0, 0.068359375, 0.033203125, 0.99609375, 0.0, 0.0, 0.99609375, 0.0, 0.998046875, 0.166015625, 0.099609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.138671875, 0.248046875, 0.033203125, 0.01953125, 0.26171875, 0.0, 0.080078125, 0.99609375, 0.0, 0.095703125, 0.99609375, 0.033203125, 0.0, 0.0, 0.169921875, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.0, 0.013671875, 0.0, 0.99609375, 0.015625, 0.0, 0.0, 0.0, 0.55078125, 0.1328125, 0.0, 0.0234375, 0.107421875, 0.994140625, 0.029296875, 0.869140625, 0.0, 0.0625, 0.99609375, 0.05078125, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.0, 0.068359375, 0.29296875, 0.0, 0.1015625, 0.0, 0.166015625, 0.0, 0.0, 0.1640625, 0.052734375, 0.994140625, 0.0, 0.51953125, 0.146484375, 0.0, 0.0, 0.037109375, 0.87109375, 0.0, 0.005859375, 0.328125, 0.087890625, 0.0, 0.998046875, 0.99609375, 0.0, 0.203125, 0.99609375, 0.99609375, 0.0, 0.0, 0.998046875, 0.048828125, 0.0, 0.0, 0.0, 0.99609375, 0.08203125, 0.142578125, 0.025390625, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.01171875, 0.01953125, 0.07421875, 0.0, 0.998046875, 0.0, 0.998046875, 0.0, 0.0, 0.998046875, 0.244140625, 0.0, 0.998046875, 0.076171875, 0.138671875, 0.0, 0.0703125, 0.18359375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.994140625, 0.99609375, 0.998046875, 0.99609375, 0.0, 0.0, 0.0, 0.994140625, 0.994140625, 0.0, 0.0, 0.99609375, 0.1640625, 0.0, 0.99609375, 0.060546875, 0.0, 0.80078125, 0.0, 0.03515625, 0.0, 0.994140625, 0.501953125, 0.99609375, 0.056640625, 0.146484375, 0.09375, 0.0, 0.546875, 0.017578125, 0.0, 0.0, 0.0, 0.400390625, 0.224609375, 0.0, 0.0078125, 0.099609375, 0.048828125, 0.0, 0.99609375, 0.0, 0.0, 0.05078125, 0.0, 0.99609375, 0.0, 0.072265625, 0.0, 0.0, 0.99609375, 0.013671875, 0.0, 0.99609375, 0.0, 0.763671875, 0.998046875, 0.998046875, 0.0, 0.99609375, 0.998046875, 0.0, 0.99609375, 0.998046875, 0.0, 0.99609375, 0.0, 0.0, 0.99609375, 0.998046875, 0.99609375, 0.99609375, 0.173828125, 0.1796875]

 sparsity of   [0.0, 0.0, 0.0, 0.0615234375, 0.998046875, 0.0, 0.998046875, 0.0, 0.486328125, 0.9990234375, 0.4658203125, 0.9970703125, 0.998046875, 0.9990234375, 0.0, 0.072265625, 0.05859375, 0.0, 0.0, 0.998046875, 0.400390625, 0.0, 0.0, 0.0, 0.998046875, 0.076171875, 0.4609375, 0.87890625, 0.0, 0.0, 0.0390625, 0.998046875, 0.0, 0.998046875, 0.052734375, 0.998046875, 0.0, 0.0, 0.9990234375, 0.0, 0.0, 0.9990234375, 0.146484375, 0.4873046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45703125, 0.1728515625, 0.0537109375, 0.0, 0.0830078125, 0.34375, 0.802734375, 0.0322265625, 0.181640625, 0.0, 0.3359375, 0.486328125, 0.224609375, 0.4658203125, 0.0849609375, 0.9990234375, 0.0, 0.1044921875, 0.0390625, 0.0, 0.0, 0.0, 0.0, 0.052734375, 0.3623046875, 0.0, 0.9990234375, 0.232421875, 0.0, 0.0, 0.0, 0.9970703125, 0.48828125, 0.0576171875, 0.9970703125, 0.806640625, 0.0, 0.0, 0.2294921875, 0.0673828125, 0.078125, 0.0, 0.029296875, 0.48828125, 0.0458984375, 0.0, 0.998046875, 0.48828125, 0.3544921875, 0.998046875, 0.0, 0.9970703125, 0.0, 0.0, 0.0, 0.212890625, 0.998046875, 0.05078125, 0.056640625, 0.48828125, 0.998046875, 0.0791015625, 0.1884765625, 0.271484375, 0.1435546875, 0.140625, 0.0, 0.373046875, 0.20703125, 0.0, 0.2392578125, 0.103515625, 0.916015625, 0.0263671875, 0.0, 0.998046875, 0.1171875, 0.0, 0.244140625, 0.1435546875, 0.3251953125, 0.0, 0.0, 0.767578125, 0.0, 0.4248046875, 0.029296875, 0.0888671875, 0.0654296875, 0.2939453125, 0.0224609375, 0.0, 0.072265625, 0.0, 0.1171875, 0.7607421875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.998046875, 0.0, 0.0, 0.421875, 0.0, 0.8349609375, 0.0498046875, 0.9990234375, 0.9990234375, 0.0, 0.0, 0.0517578125, 0.9970703125, 0.0, 0.0, 0.423828125, 0.0, 0.0, 0.0, 0.0, 0.7822265625, 0.03515625, 0.0, 0.0, 0.48828125, 0.0, 0.0, 0.201171875, 0.9990234375, 0.0, 0.0, 0.1220703125, 0.998046875, 0.0, 0.0, 0.4609375, 0.998046875, 0.0, 0.0, 0.9990234375, 0.998046875, 0.998046875, 0.0, 0.1650390625, 0.5625, 0.04296875, 0.0, 0.998046875, 0.998046875, 0.0478515625, 0.0, 0.9990234375, 0.03515625, 0.998046875, 0.0, 0.828125, 0.0888671875, 0.2958984375, 0.0, 0.078125, 0.0, 0.435546875, 0.4873046875, 0.1376953125, 0.0, 0.0, 0.064453125, 0.0947265625, 0.0732421875, 0.216796875, 0.8486328125, 0.998046875, 0.072265625, 0.423828125, 0.0, 0.0, 0.0, 0.0, 0.03125, 0.998046875, 0.041015625, 0.48828125, 0.0, 0.0, 0.166015625, 0.08984375, 0.2119140625, 0.0, 0.068359375, 0.99609375, 0.998046875, 0.0712890625, 0.0654296875, 0.0, 0.998046875, 0.0, 0.0, 0.0341796875, 0.998046875, 0.998046875, 0.2119140625, 0.998046875, 0.0, 0.998046875]

 sparsity of   [0.0, 0.0, 0.9995659589767456, 0.9995659589767456, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.0, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.0872395858168602, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.0, 0.0, 0.0, 0.999131977558136, 0.999131977558136, 0.0, 0.0, 0.999131977558136, 0.9986979365348816, 0.999131977558136, 0.0, 0.0, 0.9995659589767456, 0.999131977558136, 0.0, 0.0, 0.999131977558136, 0.0, 0.0, 0.9995659589767456, 0.8385416865348816, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.0, 0.9995659589767456, 0.999131977558136, 0.0, 0.9995659589767456, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.0, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.9995659589767456, 0.0, 0.0, 0.999131977558136, 0.0, 0.9995659589767456, 0.0, 0.999131977558136, 0.9995659589767456, 0.0, 0.0, 0.999131977558136, 0.999131977558136, 0.0, 0.0, 0.9995659589767456, 0.8229166865348816, 0.999131977558136, 0.0, 0.999131977558136, 0.32421875, 0.0, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.130642369389534, 0.0, 0.999131977558136, 0.9986979365348816, 0.0, 0.999131977558136, 0.0, 0.3389756977558136, 0.999131977558136, 0.0, 0.9995659589767456, 0.999131977558136, 0.0, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.9986979365348816, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.3072916567325592, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.0, 0.0, 0.9995659589767456, 0.999131977558136, 0.9986979365348816, 0.999131977558136, 0.0, 0.999131977558136, 0.0846354141831398, 0.9986979365348816, 0.999131977558136, 0.9995659589767456, 0.0, 0.0, 0.999131977558136, 0.0, 0.9986979365348816, 0.0, 0.1080729141831398, 0.0, 0.999131977558136, 0.0, 0.0, 0.0, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.9986979365348816, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.0, 0.0, 0.3441840410232544, 0.999131977558136, 0.9995659589767456, 0.9986979365348816, 0.0, 0.999131977558136, 0.9986979365348816, 0.999131977558136, 0.9986979365348816, 0.9995659589767456, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.0729166641831398, 0.999131977558136, 0.3289930522441864, 0.0, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.0972222238779068, 0.999131977558136, 0.9986979365348816, 0.999131977558136, 0.999131977558136, 0.0, 0.0768229141831398, 0.0, 0.999131977558136, 0.0, 0.9986979365348816, 0.0, 0.999131977558136, 0.9995659589767456, 0.0, 0.0, 0.999131977558136, 0.9986979365348816, 0.0, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.0, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.999131977558136, 0.0889756977558136, 0.3467881977558136, 0.0, 0.9995659589767456, 0.999131977558136]

 sparsity of   [0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.65234375, 0.65234375, 0.0, 0.0, 0.9921875, 0.6484375, 0.9921875, 0.0, 0.0, 0.65234375, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.65234375, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.65234375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.65234375, 0.65234375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.65234375, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.65234375, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.65234375, 0.9921875, 0.0, 0.9921875, 0.0, 0.65234375, 0.0, 0.9921875, 0.0, 0.0, 0.65234375, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.65234375, 0.9921875, 0.0, 0.65234375, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.65234375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.65234375, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.65234375, 0.65234375, 0.65234375, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.65234375, 0.9921875, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.65234375, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.65234375, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.65234375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.65234375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.65234375, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.65234375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.65234375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.65234375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6484375, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.65234375, 0.65234375, 0.65234375, 0.0, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.99609375, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.65234375, 0.0, 0.9921875, 0.0, 0.65234375, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.65234375, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.65234375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.65234375, 0.0, 0.99609375, 0.9921875, 0.99609375, 0.0, 0.65234375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.65234375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.65234375, 0.65234375, 0.0, 0.0, 0.0, 0.65234375, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.65234375, 0.0, 0.0, 0.0, 0.9921875, 0.65234375, 0.0, 0.65234375, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.65234375, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.65234375, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.65234375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.65234375, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.65234375, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.65234375, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.984375, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.65234375, 0.65234375, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.99609375, 0.65234375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.65234375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.65234375, 0.65234375, 0.0, 0.0, 0.65234375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.65234375, 0.0, 0.0, 0.0, 0.65234375, 0.0, 0.0, 0.65234375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.65234375, 0.0, 0.65234375, 0.9921875, 0.99609375, 0.65234375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.99609375, 0.99609375, 0.65234375, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.65234375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.65234375, 0.9921875, 0.65234375, 0.9921875, 0.9921875, 0.65234375, 0.99609375, 0.65234375, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.65234375, 0.9921875, 0.65234375, 0.9921875, 0.0, 0.9921875, 0.0, 0.65234375, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.65234375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.65234375, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.65234375, 0.65234375, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.65234375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.98828125, 0.9921875, 0.9921875, 0.0, 0.0, 0.65234375, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.65234375, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.65234375, 0.0, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.65234375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.65234375, 0.65234375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.65234375, 0.65234375, 0.0, 0.9921875, 0.65234375, 0.9921875, 0.0, 0.65234375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.65234375, 0.65234375, 0.9921875, 0.9921875, 0.9921875, 0.65234375, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.65234375, 0.99609375, 0.0, 0.9921875, 0.65234375, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.65234375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.65234375, 0.0, 0.99609375, 0.9921875, 0.0, 0.65234375, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.98828125, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.65234375, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.99609375, 0.65234375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.65234375, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.65234375, 0.9921875, 0.65234375, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.65234375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.65234375, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.65234375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.65234375, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.65234375, 0.0, 0.9921875, 0.0, 0.65234375, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.65234375, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375]

 sparsity of   [0.0, 0.0, 0.333984375, 0.998046875, 0.388671875, 0.4091796875, 0.0, 0.1650390625, 0.0, 0.998046875, 0.998046875, 0.0, 0.0, 0.0, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.6064453125, 0.3037109375, 0.9990234375, 0.1103515625, 0.998046875, 0.998046875, 0.849609375, 0.998046875, 0.0, 0.0, 0.998046875, 0.998046875, 0.998046875, 0.4091796875, 0.0, 0.998046875, 0.1806640625, 0.0, 0.1064453125, 0.0, 0.998046875, 0.0, 0.998046875, 0.0, 0.3193359375, 0.044921875, 0.0, 0.998046875, 0.0, 0.0, 0.9990234375, 0.0, 0.0, 0.05859375, 0.0322265625, 0.0, 0.0, 0.0986328125, 0.0, 0.998046875, 0.0, 0.3974609375, 0.0, 0.05859375, 0.0, 0.3896484375, 0.0693359375, 0.0, 0.0390625, 0.998046875, 0.4091796875, 0.0, 0.998046875, 0.9990234375, 0.0, 0.0, 0.998046875, 0.998046875, 0.068359375, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.9990234375, 0.052734375, 0.0, 0.4091796875, 0.0, 0.998046875, 0.998046875, 0.048828125, 0.998046875, 0.998046875, 0.0, 0.1240234375, 0.998046875, 0.9970703125, 0.0, 0.0, 0.103515625, 0.0, 0.0, 0.998046875, 0.0, 0.0, 0.998046875, 0.240234375, 0.0732421875, 0.396484375, 0.998046875, 0.0, 0.1005859375, 0.0, 0.998046875, 0.095703125, 0.9990234375, 0.998046875, 0.0, 0.0, 0.0, 0.0791015625, 0.0, 0.0, 0.998046875, 0.068359375, 0.0, 0.0, 0.998046875, 0.998046875, 0.03125, 0.998046875, 0.568359375, 0.0, 0.0, 0.0625, 0.0, 0.0, 0.998046875, 0.9990234375, 0.9970703125, 0.0, 0.1083984375, 0.0, 0.1923828125, 0.044921875, 0.998046875, 0.0, 0.40625, 0.9990234375, 0.0, 0.07421875, 0.9990234375, 0.9990234375, 0.9990234375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1171875, 0.998046875, 0.0, 0.9990234375, 0.052734375, 0.4072265625, 0.0, 0.0, 0.998046875, 0.0, 0.0556640625, 0.294921875, 0.998046875, 0.0, 0.9970703125, 0.0, 0.0712890625, 0.3798828125, 0.0, 0.998046875, 0.0, 0.9990234375, 0.998046875, 0.9990234375, 0.9990234375, 0.0, 0.0, 0.998046875, 0.0, 0.8681640625, 0.998046875, 0.1220703125, 0.9990234375, 0.0, 0.4052734375, 0.40625, 0.29296875, 0.998046875, 0.4072265625, 0.1083984375, 0.064453125, 0.0, 0.9970703125, 0.998046875, 0.9990234375, 0.40625, 0.9990234375, 0.998046875, 0.998046875, 0.99609375, 0.998046875, 0.9990234375, 0.9990234375, 0.0, 0.0, 0.1416015625, 0.998046875, 0.0947265625, 0.0, 0.9990234375, 0.830078125, 0.0, 0.0, 0.998046875, 0.0, 0.0859375, 0.998046875, 0.0, 0.998046875, 0.998046875, 0.0, 0.0, 0.998046875, 0.3759765625, 0.0703125, 0.0625, 0.0, 0.998046875, 0.380859375, 0.0, 0.078125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.0, 0.998046875, 0.0, 0.0400390625, 0.0, 0.9990234375, 0.0, 0.998046875, 0.998046875, 0.998046875, 0.998046875]

 sparsity of   [0.0, 0.999131977558136, 0.01822916604578495, 0.0086805559694767, 0.0451388880610466, 0.0, 0.0768229141831398, 0.0607638880610466, 0.0381944440305233, 0.9201388955116272, 0.02083333395421505, 0.8012152910232544, 0.125, 0.0, 0.0203993059694767, 0.0, 0.0, 0.0069444444961845875, 0.4457465410232544, 0.1788194477558136, 0.0, 0.5277777910232544, 0.0, 0.9995659589767456, 0.0030381944961845875, 0.0434027798473835, 0.02777777798473835, 0.0598958320915699, 0.9986979365348816, 0.1671006977558136, 0.0798611119389534, 0.1154513880610466, 0.0, 0.0, 0.02604166604578495, 0.0225694440305233, 0.1519097238779068, 0.0164930559694767, 0.0004340277810115367, 0.1258680522441864, 0.0, 0.0, 0.17578125, 0.01692708395421505, 0.01909722201526165, 0.1440972238779068, 0.9379340410232544, 0.1688368022441864, 0.8046875, 0.9986979365348816, 0.0368923619389534, 0.0746527761220932, 0.0, 0.0, 0.9448784589767456, 0.0004340277810115367, 0.013454861007630825, 0.0, 0.02170138992369175, 0.0, 0.0, 0.0251736119389534, 0.0490451380610466, 0.0, 0.8615451455116272, 0.08984375, 0.9995659589767456, 0.1605902761220932, 0.0364583320915699, 0.0, 0.0225694440305233, 0.0, 0.01779513992369175, 0.0164930559694767, 0.4609375, 0.0, 0.1818576455116272, 0.7378472089767456, 0.010850694961845875, 0.9995659589767456, 0.0438368059694767, 0.0, 0.01953125, 0.0755208358168602, 0.0438368059694767, 0.0, 0.9144965410232544, 0.0, 0.0525173619389534, 0.1801215261220932, 0.0499131940305233, 0.03081597201526165, 0.0, 0.0737847238779068, 0.02604166604578495, 0.0, 0.1488715261220932, 0.944444477558136, 0.0, 0.8177083134651184, 0.0772569477558136, 0.0, 0.0, 0.1323784738779068, 0.0, 0.00390625, 0.9253472089767456, 0.0, 0.2760416567325592, 0.0, 0.0052083334885537624, 0.138454869389534, 0.046875, 0.02213541604578495, 0.114149309694767, 0.6427951455116272, 0.014322916977107525, 0.9995659589767456, 0.1206597238779068, 0.1714409738779068, 0.02213541604578495, 0.0394965298473835, 0.015625, 0.0403645820915699, 0.0, 0.01953125, 0.009114583022892475, 0.0186631940305233, 0.0442708320915699, 0.0030381944961845875, 0.02213541604578495, 0.0, 0.02300347201526165, 0.0394965298473835, 0.7174479365348816, 0.1206597238779068, 0.9986979365348816, 0.2413194477558136, 0.0360243059694767, 0.0, 0.999131977558136, 0.02387152798473835, 0.1380208283662796, 0.01128472201526165, 0.0590277798473835, 0.0, 0.02170138992369175, 0.01822916604578495, 0.01822916604578495, 0.0442708320915699, 0.1228298619389534, 0.0338541679084301, 0.02473958395421505, 0.5980902910232544, 0.0, 0.014756944961845875, 0.0264756940305233, 0.1788194477558136, 0.09765625, 0.0360243059694767, 0.1796875, 0.0, 0.1644965261220932, 0.014756944961845875, 0.02213541604578495, 0.009548611007630825, 0.9079861044883728, 0.0460069440305233, 0.125, 0.8324652910232544, 0.0, 0.9995659589767456, 0.0655381977558136, 0.01519097201526165, 0.0, 0.0373263880610466, 0.0, 0.0329861119389534, 0.05078125, 0.009982638992369175, 0.0, 0.0455729179084301, 0.02951388992369175, 0.0438368059694767, 0.0590277798473835, 0.0616319440305233, 0.9995659589767456, 0.1870659738779068, 0.01519097201526165, 0.9986979365348816, 0.901475727558136, 0.3064236044883728, 0.1818576455116272, 0.0724826380610466, 0.0, 0.1414930522441864, 0.6019965410232544, 0.0364583320915699, 0.1119791641831398, 0.2113715261220932, 0.015625, 0.0390625, 0.05078125, 0.0125868059694767, 0.7465277910232544, 0.02170138992369175, 0.0, 0.01996527798473835, 0.01605902798473835, 0.1284722238779068, 0.1293402761220932, 0.9175347089767456, 0.0, 0.0993923619389534, 0.01215277798473835, 0.8932291865348816, 0.0546875, 0.1106770858168602, 0.0, 0.0026041667442768812, 0.02473958395421505, 0.0, 0.1553819477558136, 0.0173611119389534, 0.014756944961845875, 0.0, 0.0303819440305233, 0.0373263880610466, 0.07421875, 0.0, 0.6597222089767456, 0.0, 0.0, 0.0, 0.8763020634651184, 0.02387152798473835, 0.0225694440305233, 0.0321180559694767, 0.0, 0.02951388992369175, 0.6072048544883728, 0.9986979365348816, 0.0720486119389534, 0.2230902761220932, 0.0876736119389534, 0.02213541604578495, 0.83984375, 0.2000868022441864, 0.0, 0.9027777910232544, 0.0, 0.01692708395421505, 0.0, 0.6310763955116272, 0.03081597201526165, 0.0]

 sparsity of   [0.7421875, 0.7265625, 0.77734375, 0.04296875, 0.75, 0.77734375, 0.77734375, 0.6953125, 0.75390625, 0.75, 0.74609375, 0.73046875, 0.6875, 0.9921875, 0.74609375, 0.77734375, 0.77734375, 0.75390625, 0.77734375, 0.0, 0.0, 0.78515625, 0.99609375, 0.75, 0.77734375, 0.0, 0.9921875, 0.0390625, 0.77734375, 0.76171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.9921875, 0.9921875, 0.7265625, 0.0, 0.77734375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.77734375, 0.0, 0.765625, 0.0, 0.7421875, 0.75390625, 0.74609375, 0.0, 0.9921875, 0.0546875, 0.0, 0.1796875, 0.0, 0.9921875, 0.08984375, 0.0, 0.99609375, 0.77734375, 0.7265625, 0.77734375, 0.7421875, 0.0, 0.77734375, 0.0, 0.0, 0.71484375, 0.734375, 0.76171875, 0.0, 0.6875, 0.0, 0.69140625, 0.0, 0.77734375, 0.9921875, 0.77734375, 0.734375, 0.0, 0.54296875, 0.77734375, 0.7109375, 0.03515625, 0.0, 0.77734375, 0.0, 0.23828125, 0.7109375, 0.16796875, 0.0, 0.0, 0.05859375, 0.03125, 0.0625, 0.99609375, 0.77734375, 0.24609375, 0.0, 0.0, 0.72265625, 0.0, 0.76171875, 0.76953125, 0.0, 0.77734375, 0.41796875, 0.0, 0.6875, 0.0, 0.0, 0.7734375, 0.7265625, 0.0, 0.359375, 0.75, 0.99609375, 0.77734375, 0.74609375, 0.14453125, 0.77734375, 0.0, 0.20703125, 0.99609375, 0.77734375, 0.0, 0.7421875, 0.765625, 0.9921875, 0.0, 0.77734375, 0.00390625, 0.78515625, 0.77734375, 0.9921875, 0.9921875, 0.77734375, 0.98828125, 0.28515625, 0.9921875, 0.0, 0.046875, 0.71875, 0.77734375, 0.0, 0.77734375, 0.0546875, 0.734375, 0.75390625, 0.77734375, 0.77734375, 0.72265625, 0.01171875, 0.0, 0.0, 0.0, 0.953125, 0.7578125, 0.72265625, 0.2421875, 0.0, 0.9921875, 0.0, 0.98828125, 0.0, 0.77734375, 0.77734375, 0.0, 0.7109375, 0.72265625, 0.0, 0.73046875, 0.0, 0.77734375, 0.765625, 0.73828125, 0.015625, 0.0, 0.0, 0.68359375, 0.05078125, 0.765625, 0.99609375, 0.7265625, 0.73828125, 0.77734375, 0.7890625, 0.0859375, 0.1015625, 0.0, 0.765625, 0.08203125, 0.0625, 0.0, 0.0, 0.98828125, 0.16796875, 0.05078125, 0.0, 0.015625, 0.0, 0.9921875, 0.77734375, 0.9921875, 0.65625, 0.76171875, 0.74609375, 0.03515625, 0.09765625, 0.77734375, 0.7421875, 0.9921875, 0.77734375, 0.77734375, 0.77734375, 0.0, 0.71875, 0.0, 0.7734375, 0.77734375, 0.0, 0.0, 0.13671875, 0.06640625, 0.7578125, 0.9921875, 0.7421875, 0.67578125, 0.0, 0.125, 0.74609375, 0.12890625, 0.77734375, 0.0, 0.7109375, 0.0, 0.77734375, 0.9921875, 0.0, 0.77734375, 0.77734375, 0.77734375, 0.75390625, 0.77734375, 0.0, 0.6484375, 0.08203125, 0.74609375, 0.7265625, 0.7734375, 0.75390625, 0.765625, 0.75, 0.1875, 0.0, 0.75, 0.0, 0.05078125, 0.7109375, 0.77734375, 0.71875, 0.99609375, 0.05859375, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.734375, 0.71484375, 0.75, 0.0, 0.765625, 0.77734375, 0.9921875, 0.0546875, 0.0, 0.18359375, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.04296875, 0.0, 0.77734375, 0.00390625, 0.0, 0.765625, 0.7734375, 0.0, 0.7265625, 0.0, 0.9921875, 0.734375, 0.7421875, 0.0, 0.01171875, 0.71484375, 0.0, 0.77734375, 0.76953125, 0.69921875, 0.04296875, 0.75, 0.99609375, 0.77734375, 0.05078125, 0.0, 0.98828125, 0.0, 0.70703125, 0.7734375, 0.0, 0.69921875, 0.77734375, 0.0, 0.69921875, 0.0, 0.7734375, 0.77734375, 0.0, 0.08984375, 0.734375, 0.82421875, 0.7109375, 0.6640625, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6640625, 0.75, 0.0, 0.69140625, 0.0, 0.9921875, 0.73828125, 0.76953125, 0.9921875, 0.9921875, 0.0, 0.0, 0.734375, 0.77734375, 0.1953125, 0.0, 0.0, 0.05078125, 0.9921875, 0.71875, 0.0, 0.0, 0.99609375, 0.99609375, 0.76953125, 0.72265625, 0.77734375, 0.77734375, 0.0, 0.77734375, 0.0, 0.7265625, 0.0, 0.9921875, 0.69921875, 0.75390625, 0.75390625, 0.0, 0.0, 0.77734375, 0.71484375, 0.77734375, 0.0, 0.0, 0.7734375, 0.0, 0.765625, 0.0, 0.9921875, 0.77734375, 0.7421875, 0.0, 0.7578125, 0.0, 0.0, 0.77734375, 0.36328125, 0.67578125, 0.54296875, 0.0, 0.75, 0.0, 0.9921875, 0.75, 0.71484375, 0.0, 0.0, 0.99609375, 0.7734375, 0.77734375, 0.7265625, 0.04296875, 0.0, 0.0, 0.13671875, 0.0, 0.77734375, 0.0078125, 0.77734375, 0.9921875, 0.0, 0.0, 0.72265625, 0.09375, 0.9921875, 0.77734375, 0.20703125, 0.0, 0.75390625, 0.77734375, 0.73828125, 0.9921875, 0.0, 0.9921875, 0.734375, 0.77734375, 0.73828125, 0.0, 0.76171875, 0.0, 0.0, 0.703125, 0.0, 0.6953125, 0.0, 0.76953125, 0.0, 0.77734375, 0.77734375, 0.77734375, 0.74609375, 0.078125, 0.08984375, 0.74609375, 0.0, 0.0, 0.13671875, 0.734375, 0.71875, 0.73828125, 0.99609375, 0.77734375, 0.77734375, 0.0, 0.27734375, 0.0859375, 0.0, 0.77734375, 0.0, 0.77734375, 0.77734375, 0.0, 0.7265625, 0.87890625, 0.86328125, 0.77734375, 0.68359375, 0.77734375, 0.7265625, 0.99609375, 0.05859375, 0.0, 0.77734375, 0.9921875, 0.0, 0.0, 0.09375, 0.76953125, 0.71484375, 0.0, 0.77734375, 0.74609375, 0.77734375, 0.75390625, 0.9921875, 0.0, 0.62890625, 0.0, 0.7421875, 0.76953125, 0.765625, 0.0, 0.76171875, 0.75, 0.98828125, 0.0, 0.04296875, 0.9921875, 0.71484375, 0.71484375, 0.0, 0.05859375, 0.6328125, 0.0, 0.77734375, 0.9921875, 0.0, 0.76171875, 0.43359375, 0.69921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.73828125, 0.0, 0.77734375, 0.82421875, 0.75, 0.9921875, 0.0, 0.0, 0.75, 0.00390625, 0.01953125, 0.7578125, 0.0, 0.0546875, 0.234375, 0.0, 0.0, 0.62890625, 0.7578125, 0.77734375, 0.0, 0.77734375, 0.77734375, 0.0078125, 0.77734375, 0.18359375, 0.77734375, 0.77734375, 0.765625, 0.015625, 0.0, 0.77734375, 0.0, 0.77734375, 0.7734375, 0.98828125, 0.9921875, 0.04296875, 0.0, 0.9921875, 0.17578125, 0.76953125, 0.75390625, 0.0703125, 0.06640625, 0.77734375, 0.9921875, 0.0625, 0.74609375, 0.0, 0.3046875, 0.75390625, 0.0, 0.7578125, 0.0, 0.046875, 0.0, 0.0, 0.74609375, 0.77734375, 0.75, 0.7734375, 0.7734375, 0.0, 0.0, 0.77734375, 0.0, 0.77734375, 0.73828125, 0.80859375, 0.77734375, 0.0, 0.171875, 0.0, 0.15625, 0.70703125, 0.046875, 0.77734375, 0.77734375, 0.75, 0.69140625, 0.77734375, 0.0, 0.671875, 0.77734375, 0.01953125, 0.765625, 0.73828125, 0.77734375, 0.9921875, 0.77734375, 0.74609375, 0.77734375, 0.19921875, 0.0, 0.9921875, 0.0, 0.76953125, 0.0, 0.0, 0.75, 0.09765625, 0.7421875, 0.74609375, 0.0, 0.98828125, 0.05859375, 0.1640625, 0.9921875, 0.7421875, 0.796875, 0.99609375, 0.1015625, 0.77734375, 0.734375, 0.70703125, 0.0, 0.7578125, 0.765625, 0.0, 0.77734375, 0.0, 0.6953125, 0.67578125, 0.6640625, 0.0, 0.7421875, 0.3515625, 0.74609375, 0.77734375, 0.0, 0.7890625, 0.0, 0.77734375, 0.13671875, 0.9921875, 0.08984375, 0.0, 0.77734375, 0.73828125, 0.77734375, 0.77734375, 0.0625, 0.0, 0.77734375, 0.9921875, 0.9921875, 0.73828125, 0.0, 0.109375, 0.76953125, 0.7578125, 0.0, 0.7109375, 0.75, 0.0, 0.77734375, 0.7109375, 0.76953125, 0.9921875, 0.77734375, 0.70703125, 0.04296875, 0.70703125, 0.0, 0.71484375, 0.75, 0.0, 0.0, 0.015625, 0.77734375, 0.0, 0.77734375, 0.0, 0.0, 0.07421875, 0.0, 0.7890625, 0.0, 0.0, 0.77734375, 0.1796875, 0.99609375, 0.76953125, 0.05859375, 0.75, 0.76171875, 0.77734375, 0.76953125, 0.76953125, 0.9921875, 0.0, 0.05078125, 0.7265625, 0.77734375, 0.98828125, 0.75390625, 0.72265625, 0.0, 0.05078125, 0.2421875, 0.69140625, 0.0, 0.6875, 0.73828125, 0.0, 0.8203125, 0.16015625, 0.76171875, 0.0, 0.0, 0.23046875, 0.77734375, 0.0, 0.75390625, 0.77734375, 0.0, 0.10546875, 0.0, 0.13671875, 0.9921875, 0.734375, 0.0, 0.77734375, 0.09765625, 0.0, 0.9921875, 0.7578125, 0.72265625, 0.75390625, 0.98828125, 0.77734375, 0.0, 0.3046875, 0.0, 0.0, 0.0, 0.7578125, 0.0, 0.0, 0.7421875, 0.015625, 0.7421875, 0.76171875, 0.0, 0.75390625, 0.0625, 0.65234375, 0.55859375, 0.0, 0.0, 0.76171875, 0.75390625, 0.265625, 0.77734375, 0.0, 0.98828125, 0.77734375, 0.05078125, 0.77734375, 0.74609375, 0.0, 0.0, 0.0, 0.0, 0.77734375, 0.77734375, 0.10546875, 0.0, 0.75, 0.76953125, 0.71875, 0.0, 0.08203125, 0.73828125, 0.7578125, 0.77734375, 0.82421875, 0.7421875, 0.0, 0.0, 0.77734375, 0.76171875, 0.0, 0.72265625, 0.75, 0.75390625, 0.0, 0.77734375, 0.75390625, 0.9921875, 0.0, 0.0, 0.99609375, 0.06640625, 0.99609375, 0.0, 0.77734375, 0.0, 0.77734375, 0.77734375, 0.77734375, 0.75, 0.734375, 0.0, 0.72265625, 0.99609375, 0.078125, 0.203125, 0.765625, 0.77734375, 0.734375, 0.77734375, 0.73828125, 0.01953125, 0.10546875, 0.99609375, 0.77734375, 0.74609375, 0.0, 0.98828125, 0.77734375, 0.0, 0.7265625, 0.9921875, 0.0, 0.77734375, 0.09375, 0.0, 0.21875, 0.0, 0.75390625, 0.640625, 0.77734375, 0.05859375, 0.25390625, 0.0, 0.7109375, 0.73828125, 0.7421875, 0.77734375, 0.9921875, 0.0, 0.09375, 0.03515625, 0.7265625, 0.8515625, 0.0, 0.0, 0.0, 0.77734375, 0.98828125, 0.77734375, 0.734375, 0.0, 0.0, 0.11328125, 0.0, 0.67578125, 0.7109375, 0.77734375, 0.3046875, 0.73828125, 0.7578125, 0.0, 0.21484375, 0.7734375, 0.0, 0.0, 0.07421875, 0.77734375, 0.77734375, 0.77734375, 0.98828125, 0.73828125, 0.77734375, 0.9921875, 0.77734375, 0.0, 0.80078125, 0.9921875, 0.9921875, 0.0, 0.0, 0.8671875, 0.7578125, 0.0, 0.05859375, 0.0, 0.171875, 0.9921875, 0.9921875, 0.77734375, 0.0, 0.77734375, 0.77734375, 0.0078125, 0.453125, 0.77734375, 0.0, 0.9375, 0.0, 0.015625, 0.77734375, 0.73046875, 0.75, 0.0, 0.75, 0.0, 0.03515625, 0.75390625, 0.0, 0.07421875, 0.7421875, 0.72265625, 0.7421875, 0.0859375, 0.98828125, 0.77734375, 0.6796875, 0.671875, 0.16796875, 0.72265625, 0.36328125, 0.734375, 0.0, 0.7109375, 0.765625, 0.7421875, 0.734375, 0.76171875, 0.0, 0.0, 0.9921875, 0.08984375, 0.77734375, 0.0, 0.77734375, 0.77734375, 0.0, 0.9921875, 0.078125, 0.734375, 0.99609375, 0.0, 0.23828125, 0.77734375, 0.9921875, 0.046875, 0.6953125, 0.9921875, 0.76171875, 0.0, 0.0, 0.76171875, 0.30859375, 0.37890625, 0.0, 0.0, 0.77734375, 0.9921875, 0.0, 0.0, 0.93359375, 0.77734375, 0.0, 0.9921875, 0.77734375, 0.0, 0.6328125, 0.0, 0.77734375, 0.0, 0.9921875, 0.0, 0.0, 0.73046875, 0.52734375, 0.77734375, 0.984375, 0.77734375, 0.98828125, 0.75390625, 0.0, 0.0, 0.7578125, 0.70703125, 0.0, 0.05859375, 0.67578125, 0.0, 0.83203125, 0.0, 0.0, 0.99609375, 0.0703125, 0.9921875, 0.8984375, 0.01953125, 0.09765625]

 sparsity of   [0.2861328125, 0.015625, 0.8544921875, 0.876953125, 0.2568359375, 0.7548828125, 0.015625, 0.2763671875, 0.0048828125, 0.0888671875, 0.00390625, 0.1328125, 0.0185546875, 0.1240234375, 0.20703125, 0.033203125, 0.0068359375, 0.005859375, 0.0341796875, 0.10546875, 0.0361328125, 0.0302734375, 0.115234375, 0.013671875, 0.0166015625, 0.123046875, 0.044921875, 0.0087890625, 0.0302734375, 0.0087890625, 0.087890625, 0.0419921875, 0.0234375, 0.1025390625, 0.908203125, 0.0341796875, 0.03515625, 0.0029296875, 0.9990234375, 0.0126953125, 0.8564453125, 0.1005859375, 0.0634765625, 0.0849609375, 0.017578125, 0.0302734375, 0.0107421875, 0.0068359375, 0.0205078125, 0.0107421875, 0.00390625, 0.01953125, 0.0087890625, 0.0185546875, 0.025390625, 0.0146484375, 0.59765625, 0.6494140625, 0.0, 0.01953125, 0.9677734375, 0.056640625, 0.1435546875, 0.796875, 0.0234375, 0.0419921875, 0.189453125, 0.009765625, 0.013671875, 0.0068359375, 0.0224609375, 0.0087890625, 0.0517578125, 0.0029296875, 0.0703125, 0.998046875, 0.263671875, 0.876953125, 0.09765625, 0.05859375, 0.0, 0.0380859375, 0.017578125, 0.1865234375, 0.0625, 0.9990234375, 0.0673828125, 0.150390625, 0.0341796875, 0.01171875, 0.150390625, 0.0322265625, 0.8955078125, 0.86328125, 0.287109375, 0.0205078125, 0.01953125, 0.046875, 0.0166015625, 0.06640625, 0.0087890625, 0.03125, 0.314453125, 0.07421875, 0.68359375, 0.0888671875, 0.001953125, 0.142578125, 0.1708984375, 0.01171875, 0.0400390625, 0.0107421875, 0.998046875, 0.0654296875, 0.033203125, 0.0283203125, 0.001953125, 0.0068359375, 0.015625, 0.013671875, 0.09765625, 0.1513671875, 0.0185546875, 0.0166015625, 0.001953125, 0.0166015625, 0.0732421875, 0.0302734375, 0.046875, 0.2353515625, 0.013671875, 0.01171875, 0.09375, 0.017578125, 0.3828125, 0.0166015625, 0.00390625, 0.013671875, 0.0185546875, 0.0966796875, 0.8076171875, 0.998046875, 0.0185546875, 0.021484375, 0.0458984375, 0.033203125, 0.0361328125, 0.8701171875, 0.998046875, 0.83984375, 0.0986328125, 0.05859375, 0.0322265625, 0.9990234375, 0.154296875, 0.0537109375, 0.02734375, 0.013671875, 0.0361328125, 0.0595703125, 0.1005859375, 0.0283203125, 0.0126953125, 0.021484375, 0.3642578125, 0.62890625, 0.0419921875, 0.833984375, 0.0283203125, 0.0, 0.1494140625, 0.0107421875, 0.1123046875, 0.8388671875, 0.712890625, 0.099609375, 0.0341796875, 0.140625, 0.01953125, 0.0263671875, 0.18359375, 0.9970703125, 0.0263671875, 0.021484375, 0.0390625, 0.0146484375, 0.0458984375, 0.150390625, 0.0068359375, 0.9208984375, 0.0107421875, 0.01171875, 0.7333984375, 0.2060546875, 0.005859375, 0.1513671875, 0.029296875, 0.041015625, 0.04296875, 0.0263671875, 0.9228515625, 0.0029296875, 0.072265625, 0.0263671875, 0.0224609375, 0.03125, 0.9326171875, 0.0068359375, 0.009765625, 0.005859375, 0.025390625, 0.7734375, 0.0068359375, 0.021484375, 0.7607421875, 0.01171875, 0.1572265625, 0.05859375, 0.009765625, 0.0830078125, 0.0556640625, 0.0078125, 0.82421875, 0.046875, 0.0244140625, 0.0205078125, 0.52734375, 0.0498046875, 0.15234375, 0.0419921875, 0.0244140625, 0.017578125, 0.021484375, 0.1416015625, 0.8232421875, 0.0126953125, 0.41796875, 0.5439453125, 0.078125, 0.0849609375, 0.0107421875, 0.07421875, 0.2939453125, 0.009765625, 0.1689453125, 0.0712890625, 0.03125, 0.0859375, 0.095703125, 0.021484375, 0.076171875, 0.005859375, 0.9990234375, 0.0126953125, 0.875, 0.0732421875]

 sparsity of   [0.02387152798473835, 0.0559895820915699, 0.0078125, 0.0008680555620230734, 0.0078125, 0.02864583395421505, 0.0004340277810115367, 0.01909722201526165, 0.0993923619389534, 0.02387152798473835, 0.0616319440305233, 0.0234375, 0.02083333395421505, 0.9079861044883728, 0.2743055522441864, 0.9027777910232544, 0.1380208283662796, 0.02387152798473835, 0.2217881977558136, 0.5789930820465088, 0.0004340277810115367, 0.02300347201526165, 0.0390625, 0.0902777761220932, 0.0503472238779068, 0.776475727558136, 0.4162326455116272, 0.4405381977558136, 0.0004340277810115367, 0.02560763992369175, 0.1310763955116272, 0.01519097201526165, 0.014756944961845875, 0.0494791679084301, 0.01953125, 0.0282118059694767, 0.03081597201526165, 0.02994791604578495, 0.0677083358168602, 0.0802951380610466, 0.0316840298473835, 0.0646701380610466, 0.7282986044883728, 0.1263020783662796, 0.0551215298473835, 0.1341145783662796, 0.0815972238779068, 0.118055559694767, 0.6931423544883728, 0.0685763880610466, 0.177517369389534, 0.0078125, 0.1032986119389534, 0.02473958395421505, 0.0004340277810115367, 0.0004340277810115367, 0.0859375, 0.0842013880610466, 0.0069444444961845875, 0.0264756940305233, 0.0499131940305233, 0.009548611007630825, 0.086805559694767, 0.2903645932674408, 0.01519097201526165, 0.9956597089767456, 0.0421006940305233, 0.0520833320915699, 0.01822916604578495, 0.1176215261220932, 0.0815972238779068, 0.1215277761220932, 0.121961809694767, 0.1137152761220932, 0.12109375, 0.0368923619389534, 0.02300347201526165, 0.0564236119389534, 0.6519097089767456, 0.02604166604578495, 0.1731770783662796, 0.0416666679084301, 0.2495659738779068, 0.29296875, 0.9995659589767456, 0.0889756977558136, 0.0438368059694767, 0.0694444477558136, 0.0078125, 0.0998263880610466, 0.0065104165114462376, 0.6019965410232544, 0.0, 0.3411458432674408, 0.02170138992369175, 0.1046006977558136, 0.082899309694767, 0.1571180522441864, 0.7677951455116272, 0.010850694961845875, 0.0390625, 0.0442708320915699, 0.0889756977558136, 0.1979166716337204, 0.0377604179084301, 0.8845486044883728, 0.2413194477558136, 0.01996527798473835, 0.1302083283662796, 0.0377604179084301, 0.1944444477558136, 0.0008680555620230734, 0.296440988779068, 0.0755208358168602, 0.01909722201526165, 0.1414930522441864, 0.01909722201526165, 0.0542534738779068, 0.02777777798473835, 0.0564236119389534, 0.0416666679084301, 0.5104166865348816, 0.1532118022441864, 0.0915798619389534, 0.7439236044883728, 0.03081597201526165, 0.0368923619389534, 0.0, 0.0004340277810115367, 0.082899309694767, 0.05078125, 0.01953125, 0.0963541641831398, 0.0004340277810115367, 0.0251736119389534, 0.0581597238779068, 0.075086809694767, 0.0659722238779068, 0.0, 0.078125, 0.02213541604578495, 0.01128472201526165, 0.0125868059694767, 0.234375, 0.03081597201526165, 0.0572916679084301, 0.02300347201526165, 0.0329861119389534, 0.2326388955116272, 0.0251736119389534, 0.0455729179084301, 0.0290798619389534, 0.0902777761220932, 0.0386284738779068, 0.02473958395421505, 0.0173611119389534, 0.0047743055038154125, 0.08984375, 0.0555555559694767, 0.0203993059694767, 0.0399305559694767, 0.0399305559694767, 0.02473958395421505, 0.2261284738779068, 0.0360243059694767, 0.005642361007630825, 0.1163194477558136, 0.01822916604578495, 0.0451388880610466, 0.0911458358168602, 0.9995659589767456, 0.0243055559694767, 0.0993923619389534, 0.9309895634651184, 0.02387152798473835, 0.0885416641831398, 0.0677083358168602, 0.0607638880610466, 0.0008680555620230734, 0.0412326380610466, 0.0759548619389534, 0.00390625, 0.01953125, 0.015625, 0.0017361111240461469, 0.05078125, 0.03081597201526165, 0.0078125, 0.02951388992369175, 0.0412326380610466, 0.0954861119389534, 0.0325520820915699, 0.1115451380610466, 0.1106770858168602, 0.00390625, 0.1080729141831398, 0.0455729179084301, 0.41796875, 0.0486111119389534, 0.0533854179084301, 0.0325520820915699, 0.0013020833721384406, 0.0464409738779068, 0.0590277798473835, 0.9995659589767456, 0.0538194440305233, 0.01953125, 0.02734375, 0.02777777798473835, 0.4835069477558136, 0.0538194440305233, 0.4704861044883728, 0.0577256940305233, 0.00824652798473835, 0.0399305559694767, 0.0078125, 0.0, 0.01519097201526165, 0.02560763992369175, 0.0989583358168602, 0.0846354141831398, 0.01605902798473835, 0.1215277761220932, 0.999131977558136, 0.0047743055038154125, 0.0, 0.2829861044883728, 0.0551215298473835, 0.0203993059694767, 0.03081597201526165, 0.0017361111240461469, 0.0008680555620230734, 0.0993923619389534, 0.8446180820465088, 0.0889756977558136, 0.0173611119389534, 0.53515625, 0.0034722222480922937, 0.0203993059694767, 0.0538194440305233, 0.0486111119389534, 0.0325520820915699, 0.0594618059694767, 0.075086809694767, 0.0347222238779068, 0.01779513992369175, 0.015625, 0.01996527798473835, 0.1184895858168602, 0.013454861007630825, 0.014322916977107525, 0.0321180559694767, 0.02951388992369175, 0.9995659589767456, 0.0659722238779068, 0.0677083358168602]

 sparsity of   [0.94921875, 0.98046875, 0.984375, 0.97265625, 0.984375, 0.94140625, 0.984375, 0.96484375, 0.94921875, 0.984375, 0.265625, 0.984375, 0.9453125, 0.98828125, 0.94140625, 0.984375, 0.984375, 0.953125, 0.96484375, 0.984375, 0.984375, 0.984375, 0.96875, 0.96484375, 0.94140625, 0.984375, 0.96484375, 0.9765625, 0.984375, 0.953125, 0.984375, 0.984375, 0.984375, 0.95703125, 0.984375, 0.984375, 0.953125, 0.95703125, 0.984375, 0.94140625, 0.94921875, 0.984375, 0.984375, 0.984375, 0.9453125, 0.984375, 0.94921875, 0.984375, 0.96875, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.96484375, 0.98046875, 0.984375, 0.9453125, 0.984375, 0.94921875, 0.9453125, 0.96484375, 0.98046875, 0.96484375, 0.953125, 0.984375, 0.98046875, 0.00390625, 0.984375, 0.984375, 0.984375, 0.94921875, 0.984375, 0.95703125, 0.984375, 0.984375, 0.984375, 0.95703125, 0.953125, 0.953125, 0.94921875, 0.984375, 0.9609375, 0.984375, 0.984375, 0.9453125, 0.9453125, 0.984375, 0.984375, 0.9609375, 0.984375, 0.94140625, 0.984375, 0.9609375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.9609375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.96484375, 0.96484375, 0.9609375, 0.984375, 0.97265625, 0.984375, 0.9453125, 0.984375, 0.984375, 0.953125, 0.015625, 0.984375, 0.984375, 0.96484375, 0.984375, 0.94140625, 0.9921875, 0.94140625, 0.21484375, 0.984375, 0.984375, 0.984375, 0.9453125, 0.984375, 0.96875, 0.95703125, 0.97265625, 0.984375, 0.953125, 0.984375, 0.9765625, 0.953125, 0.94921875, 0.97265625, 0.984375, 0.94921875, 0.953125, 0.94140625, 0.984375, 0.94921875, 0.94921875, 0.984375, 0.984375, 0.984375, 0.9921875, 0.984375, 0.94921875, 0.984375, 0.95703125, 0.9609375, 0.953125, 0.984375, 0.984375, 0.9453125, 0.96875, 0.96875, 0.984375, 0.9609375, 0.984375, 0.95703125, 0.984375, 0.9453125, 0.984375, 0.95703125, 0.984375, 0.984375, 0.984375, 0.953125, 0.984375, 0.95703125, 0.984375, 0.953125, 0.95703125, 0.9609375, 0.984375, 0.984375, 0.984375, 0.9453125, 0.953125, 0.953125, 0.953125, 0.9453125, 0.94921875, 0.9765625, 0.98828125, 0.96875, 0.94921875, 0.984375, 0.94140625, 0.8984375, 0.97265625, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.96875, 0.984375, 0.98046875, 0.9765625, 0.984375, 0.984375, 0.9609375, 0.984375, 0.9921875, 0.9609375, 0.9453125, 0.9453125, 0.9453125, 0.97265625, 0.984375, 0.984375, 0.984375, 0.9453125, 0.984375, 0.98046875, 0.9453125, 0.984375, 0.984375, 0.953125, 0.94140625, 0.984375, 0.9921875, 0.984375, 0.984375, 0.984375, 0.94140625, 0.9765625, 0.984375, 0.94921875, 0.984375, 0.94921875, 0.984375, 0.984375, 0.984375, 0.984375, 0.95703125, 0.953125, 0.96484375, 0.95703125, 0.984375, 0.984375, 0.9453125, 0.97265625, 0.984375, 0.984375, 0.9453125, 0.94921875, 0.984375, 0.9453125, 0.9453125, 0.984375, 0.9453125, 0.984375, 0.953125, 0.94921875, 0.94921875, 0.96875, 0.9765625, 0.94140625, 0.984375, 0.9921875, 0.9609375, 0.02734375, 0.984375, 0.953125, 0.94921875, 0.0234375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.97265625, 0.984375, 0.95703125, 0.984375, 0.984375, 0.0078125, 0.9921875, 0.984375, 0.984375, 0.984375, 0.96875, 0.984375, 0.984375, 0.9609375, 0.984375, 0.984375, 0.9609375, 0.984375, 0.9921875, 0.984375, 0.9453125, 0.953125, 0.984375, 0.98046875, 0.95703125, 0.97265625, 0.953125, 0.96875, 0.94921875, 0.984375, 0.984375, 0.984375, 0.43359375, 0.98046875, 0.96484375, 0.95703125, 0.94921875, 0.984375, 0.94140625, 0.9453125, 0.984375, 0.94921875, 0.984375, 0.984375, 0.9453125, 0.984375, 0.9453125, 0.984375, 0.984375, 0.98046875, 0.953125, 0.9765625, 0.9453125, 0.984375, 0.98046875, 0.984375, 0.984375, 0.984375, 0.96484375, 0.984375, 0.984375, 0.94140625, 0.984375, 0.953125, 0.984375, 0.9453125, 0.984375, 0.96875, 0.97265625, 0.95703125, 0.984375, 0.984375, 0.9453125, 0.953125, 0.95703125, 0.984375, 0.94140625, 0.06640625, 0.98046875, 0.984375, 0.984375, 0.984375, 0.9453125, 0.94140625, 0.95703125, 0.984375, 0.984375, 0.96484375, 0.984375, 0.96875, 0.96484375, 0.9453125, 0.984375, 0.98046875, 0.9765625, 0.0078125, 0.953125, 0.984375, 0.984375, 0.984375, 0.953125, 0.94921875, 0.984375, 0.984375, 0.984375, 0.984375, 0.953125, 0.984375, 0.96875, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.953125, 0.9609375, 0.984375, 0.984375, 0.9609375, 0.984375, 0.98046875, 0.94921875, 0.94921875, 0.984375, 0.98046875, 0.984375, 0.984375, 0.96875, 0.96484375, 0.98046875, 0.984375, 0.984375, 0.984375, 0.0390625, 0.015625, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.9453125, 0.95703125, 0.99609375, 0.94140625, 0.94140625, 0.984375, 0.953125, 0.984375, 0.95703125, 0.98046875, 0.984375, 0.90625, 0.984375, 0.96875, 0.984375, 0.9453125, 0.984375, 0.984375, 0.984375, 0.96875, 0.984375, 0.984375, 0.984375, 0.953125, 0.984375, 0.984375, 0.953125, 0.953125, 0.984375, 0.9765625, 0.984375, 0.96484375, 0.984375, 0.984375, 0.94140625, 0.96875, 0.984375, 0.94921875, 0.96875, 0.9453125, 0.984375, 0.984375, 0.96875, 0.94140625, 0.984375, 0.984375, 0.984375, 0.984375, 0.953125, 0.984375, 0.984375, 0.98828125, 0.9921875, 0.984375, 0.97265625, 0.9765625, 0.96484375, 0.96484375, 0.9765625, 0.01171875, 0.984375, 0.9765625, 0.984375, 0.984375, 0.984375, 0.9765625, 0.984375, 0.984375, 0.953125, 0.02734375, 0.984375, 0.953125, 0.94921875, 0.984375, 0.984375, 0.984375, 0.984375, 0.9609375, 0.984375, 0.984375, 0.94140625, 0.96484375, 0.984375, 0.984375, 0.9453125, 0.99609375, 0.984375, 0.984375, 0.984375, 0.95703125, 0.98046875, 0.984375, 0.9609375, 0.96875, 0.984375, 0.97265625, 0.984375, 0.984375, 0.984375, 0.94140625, 0.984375, 0.984375, 0.9609375, 0.984375, 0.984375, 0.9609375, 0.94921875, 0.984375, 0.984375, 0.984375, 0.96875, 0.984375, 0.97265625, 0.9453125, 0.95703125, 0.94921875, 0.9453125, 0.984375, 0.984375, 0.97265625, 0.984375, 0.03515625, 0.984375, 0.9453125, 0.953125, 0.984375, 0.953125, 0.97265625, 0.9453125, 0.94921875, 0.94140625, 0.953125, 0.9921875, 0.984375, 0.02734375, 0.9453125, 0.95703125, 0.97265625, 0.953125, 0.984375, 0.984375, 0.96484375, 0.95703125, 0.9453125, 0.95703125, 0.953125, 0.953125, 0.9453125, 0.98828125, 0.9453125, 0.953125, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.9453125, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.9453125, 0.94921875, 0.984375, 0.984375, 0.96875, 0.984375, 0.984375, 0.984375, 0.96875, 0.984375, 0.984375, 0.9453125, 0.984375, 0.98046875, 0.96875, 0.94140625, 0.96484375, 0.984375, 0.94921875, 0.953125, 0.9609375, 0.125, 0.98046875, 0.984375, 0.984375, 0.97265625, 0.953125, 0.984375, 0.984375, 0.984375, 0.95703125, 0.984375, 0.96875, 0.984375, 0.96875, 0.984375, 0.95703125, 0.984375, 0.984375, 0.984375, 0.94140625, 0.984375, 0.984375, 0.984375, 0.984375, 0.98046875, 0.9453125, 0.96875, 0.984375, 0.94921875, 0.97265625, 0.9453125, 0.94921875, 0.94921875, 0.9765625, 0.984375, 0.984375, 0.9765625, 0.9609375, 0.94140625, 0.984375, 0.96484375, 0.953125, 0.97265625, 0.94140625, 0.94921875, 0.96484375, 0.94140625, 0.953125, 0.984375, 0.98046875, 0.984375, 0.94921875, 0.94921875, 0.96875, 0.984375, 0.984375, 0.984375, 0.99609375, 0.984375, 0.984375, 0.95703125, 0.9453125, 0.94921875, 0.97265625, 0.9453125, 0.95703125, 0.984375, 0.94140625, 0.94140625, 0.984375, 0.984375, 0.984375, 0.9609375, 0.984375, 0.984375, 0.94921875, 0.9765625, 0.96875, 0.984375, 0.94921875, 0.98046875, 0.984375, 0.94140625, 0.984375, 0.96484375, 0.16015625, 0.984375, 0.94140625, 0.953125, 0.984375, 0.984375, 0.984375, 0.984375, 0.94140625, 0.984375, 0.9921875, 0.0703125, 0.984375, 0.98046875, 0.953125, 0.984375, 0.984375, 0.96875, 0.98828125, 0.9453125, 0.984375, 0.9765625, 0.9453125, 0.96875, 0.984375, 0.9453125, 0.95703125, 0.9921875, 0.94140625, 0.984375, 0.984375, 0.984375, 0.94140625, 0.96875, 0.95703125, 0.984375, 0.984375, 0.94921875, 0.984375, 0.9921875, 0.984375, 0.96875, 0.00390625, 0.984375, 0.94921875, 0.95703125, 0.984375, 0.9765625, 0.94921875, 0.984375, 0.9921875, 0.984375, 0.9453125, 0.95703125, 0.984375, 0.984375, 0.984375, 0.94140625, 0.984375, 0.984375, 0.97265625, 0.9453125, 0.984375, 0.95703125, 0.984375, 0.984375, 0.9765625, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.94921875, 0.96875, 0.94921875, 0.9765625, 0.96875, 0.984375, 0.984375, 0.984375, 0.94921875, 0.984375, 0.98046875, 0.984375, 0.1015625, 0.97265625, 0.94140625, 0.97265625, 0.984375, 0.94921875, 0.984375, 0.984375, 0.96875, 0.984375, 0.94140625, 0.94921875, 0.953125, 0.984375, 0.9453125, 0.9453125, 0.953125, 0.984375, 0.9453125, 0.95703125, 0.9453125, 0.94140625, 0.98828125, 0.984375, 0.94921875, 0.984375, 0.984375, 0.97265625, 0.984375, 0.9453125, 0.984375, 0.94921875, 0.984375, 0.97265625, 0.078125, 0.97265625, 0.94921875, 0.984375, 0.99609375, 0.984375, 0.9453125, 0.984375, 0.94921875, 0.984375, 0.94921875, 0.984375, 0.9453125, 0.984375, 0.984375, 0.984375, 0.96484375, 0.9921875, 0.97265625, 0.9453125, 0.98828125, 0.94140625, 0.984375, 0.9453125, 0.9765625, 0.984375, 0.9453125, 0.94921875, 0.984375, 0.984375, 0.984375, 0.9453125, 0.078125, 0.984375, 0.95703125, 0.98046875, 0.984375, 0.984375, 0.94921875, 0.984375, 0.98046875, 0.9453125, 0.984375, 0.984375, 0.984375, 0.94921875, 0.96875, 0.953125, 0.94140625, 0.9921875, 0.98828125, 0.984375, 0.94140625, 0.984375, 0.94921875, 0.984375, 0.97265625, 0.94921875, 0.984375, 0.95703125, 0.984375, 0.984375, 0.953125, 0.984375, 0.984375, 0.984375, 0.984375, 0.94140625, 0.95703125, 0.94921875, 0.984375, 0.953125, 0.94921875, 0.953125, 0.984375, 0.984375, 0.07421875, 0.99609375, 0.984375, 0.2421875, 0.984375, 0.9609375, 0.984375, 0.984375, 0.984375, 0.98046875, 0.984375, 0.95703125, 0.953125, 0.984375, 0.953125, 0.9921875, 0.95703125, 0.984375, 0.984375, 0.9921875, 0.9453125, 0.984375, 0.95703125, 0.984375, 0.984375, 0.95703125, 0.953125, 0.984375, 0.984375, 0.984375, 0.98046875, 0.984375, 0.984375, 0.984375, 0.984375, 0.98046875, 0.94921875, 0.984375, 0.984375, 0.9453125, 0.94140625, 0.984375, 0.97265625, 0.96875, 0.0, 0.984375, 0.984375, 0.984375, 0.94140625, 0.984375, 0.9453125, 0.96875, 0.984375, 0.984375, 0.97265625, 0.984375, 0.984375, 0.24609375, 0.01953125, 0.94140625, 0.984375, 0.9453125, 0.9609375, 0.9453125, 0.94921875, 0.984375, 0.984375, 0.984375, 0.9921875, 0.98828125, 0.984375, 0.984375, 0.86328125, 0.94921875, 0.984375, 0.97265625, 0.94140625, 0.953125, 0.9921875, 0.984375, 0.96875, 0.984375, 0.96484375, 0.9609375, 0.94140625, 0.96875, 0.984375, 0.984375, 0.984375, 0.95703125, 0.984375, 0.9609375, 0.01171875, 0.296875, 0.05859375, 0.95703125, 0.984375, 0.984375, 0.96484375, 0.984375, 0.984375, 0.9765625, 0.94921875, 0.984375, 0.984375, 0.984375, 0.96875, 0.984375, 0.94140625, 0.984375, 0.984375, 0.953125, 0.984375, 0.94921875, 0.9453125, 0.984375, 0.984375, 0.95703125, 0.984375, 0.984375, 0.9453125, 0.85546875, 0.984375, 0.94140625, 0.9765625, 0.984375, 0.97265625, 0.984375, 0.984375, 0.984375, 0.953125, 0.984375, 0.9921875, 0.9765625, 0.94921875]

 sparsity of   [0.080078125, 0.998046875, 0.05078125, 0.9970703125, 0.9462890625, 0.0791015625, 0.1064453125, 0.01953125, 0.0673828125, 0.0390625, 0.0107421875, 0.0390625, 0.7939453125, 0.0400390625, 0.033203125, 0.1787109375, 0.9970703125, 0.0263671875, 0.9990234375, 0.8955078125, 0.9990234375, 0.0849609375, 0.9990234375, 0.0390625, 0.9482421875, 0.623046875, 0.095703125, 0.04296875, 0.0625, 0.0927734375, 0.43359375, 0.0166015625, 0.0, 0.05859375, 0.845703125, 0.9306640625, 0.845703125, 0.0498046875, 0.8505859375, 0.0498046875, 0.0537109375, 0.0908203125, 0.0810546875, 0.078125, 0.9287109375, 0.119140625, 0.0224609375, 0.07421875, 0.01171875, 0.0947265625, 0.0078125, 0.833984375, 0.998046875, 0.0244140625, 0.9990234375, 0.0234375, 0.05859375, 0.1630859375, 0.921875, 0.998046875, 0.01171875, 0.1025390625, 0.0107421875, 0.0400390625, 0.9208984375, 0.130859375, 0.8994140625, 0.0791015625, 0.087890625, 0.0576171875, 0.060546875, 0.6455078125, 0.998046875, 0.060546875, 0.0419921875, 0.0830078125, 0.9296875, 0.9970703125, 0.0107421875, 0.146484375, 0.046875, 0.8349609375, 0.0146484375, 0.9970703125, 0.072265625, 0.1806640625, 0.1083984375, 0.943359375, 0.0498046875, 0.0263671875, 0.0380859375, 0.1181640625, 0.0625, 0.04296875, 0.0224609375, 0.0576171875, 0.0224609375, 0.94921875, 0.0146484375, 0.0419921875, 0.0322265625, 0.0693359375, 0.83984375, 0.8984375, 0.9970703125, 0.0625, 0.0732421875, 0.1103515625, 0.8251953125, 0.01953125, 0.087890625, 0.458984375, 0.103515625, 0.8544921875, 0.947265625, 0.109375, 0.111328125, 0.0361328125, 0.9853515625, 0.142578125, 0.0703125, 0.0107421875, 0.998046875, 0.53125, 0.9609375, 0.0439453125, 0.998046875, 0.9990234375, 0.0439453125, 0.0625, 0.919921875, 0.9287109375, 0.939453125, 0.0, 0.78125, 0.0234375, 0.009765625, 0.087890625, 0.0712890625, 0.87890625, 0.0732421875, 0.8388671875, 0.890625, 0.03125, 0.033203125, 0.107421875, 0.064453125, 0.1337890625, 0.998046875, 0.1279296875, 0.0087890625, 0.029296875, 0.0751953125, 0.0625, 0.03125, 0.9326171875, 0.9013671875, 0.12890625, 0.8720703125, 0.2138671875, 0.0322265625, 0.1767578125, 0.0146484375, 0.998046875, 0.7744140625, 0.998046875, 0.0712890625, 0.0283203125, 0.0302734375, 0.0224609375, 0.9970703125, 0.02734375, 0.0224609375, 0.96484375, 0.0283203125, 0.0625, 0.1240234375, 0.998046875, 0.02734375, 0.998046875, 0.087890625, 0.822265625, 0.822265625, 0.9970703125, 0.02734375, 0.041015625, 0.998046875, 0.998046875, 0.005859375, 0.0771484375, 0.03515625, 0.056640625, 0.998046875, 0.1279296875, 0.033203125, 0.017578125, 0.998046875, 0.9326171875, 0.0693359375, 0.5, 0.005859375, 0.017578125, 0.0751953125, 0.021484375, 0.2177734375, 0.0380859375, 0.0341796875, 0.037109375, 0.0302734375, 0.8212890625, 0.111328125, 0.125, 0.0732421875, 0.0400390625, 0.00390625, 0.041015625, 0.0234375, 0.056640625, 0.9990234375, 0.9990234375, 0.9970703125, 0.0234375, 0.91796875, 0.818359375, 0.05859375, 0.119140625, 0.0751953125, 0.19140625, 0.0234375, 0.15625, 0.1064453125, 0.998046875, 0.7919921875, 0.0390625, 0.109375, 0.8212890625, 0.0126953125, 0.029296875, 0.0322265625, 0.8701171875, 0.7783203125, 0.078125, 0.0146484375, 0.0595703125, 0.068359375, 0.9990234375, 0.03515625, 0.0224609375, 0.998046875, 0.0009765625, 0.998046875, 0.046875, 0.935546875, 0.052734375, 0.13671875, 0.9306640625]

 sparsity of   [0.6805555820465088, 0.0442708320915699, 0.8051215410232544, 0.0729166641831398, 0.1206597238779068, 0.02690972201526165, 0.01128472201526165, 0.0390625, 0.16015625, 0.006076388992369175, 0.0203993059694767, 0.0004340277810115367, 0.8237847089767456, 0.0008680555620230734, 0.999131977558136, 0.181423619389534, 0.0212673619389534, 0.014756944961845875, 0.013888888992369175, 0.03081597201526165, 0.01215277798473835, 0.0559895820915699, 0.1263020783662796, 0.010416666977107525, 0.0047743055038154125, 0.999131977558136, 0.0959201380610466, 0.02387152798473835, 0.014756944961845875, 0.0707465261220932, 0.9201388955116272, 0.0125868059694767, 0.0421006940305233, 0.0086805559694767, 0.138454869389534, 0.02473958395421505, 0.075086809694767, 0.5711805820465088, 0.0438368059694767, 0.0611979179084301, 0.953125, 0.0334201380610466, 0.02473958395421505, 0.0794270858168602, 0.1254340261220932, 0.0303819440305233, 0.0646701380610466, 0.9652777910232544, 0.0490451380610466, 0.0959201380610466, 0.013454861007630825, 0.0520833320915699, 0.9314236044883728, 0.01605902798473835, 0.071180559694767, 0.03125, 0.01692708395421505, 0.247829869389534, 0.02213541604578495, 0.02690972201526165, 0.8185763955116272, 0.01171875, 0.013020833022892475, 0.0173611119389534, 0.013454861007630825, 0.0173611119389534, 0.0447048619389534, 0.01171875, 0.1011284738779068, 0.1605902761220932, 0.04296875, 0.010850694961845875, 0.0768229141831398, 0.1154513880610466, 0.9995659589767456, 0.015625, 0.9995659589767456, 0.01822916604578495, 0.0516493059694767, 0.0451388880610466, 0.01605902798473835, 0.999131977558136, 0.1232638880610466, 0.9986979365348816, 0.0316840298473835, 0.8871527910232544, 0.0386284738779068, 0.9995659589767456, 0.7769097089767456, 0.0069444444961845875, 0.02473958395421505, 0.0768229141831398, 0.0243055559694767, 0.0203993059694767, 0.02170138992369175, 0.09375, 0.0490451380610466, 0.0329861119389534, 0.0386284738779068, 0.02690972201526165, 0.999131977558136, 0.8289930820465088, 0.02387152798473835, 0.0407986119389534, 0.5872395634651184, 0.00390625, 0.4869791567325592, 0.9010416865348816, 0.0972222238779068, 0.7890625, 0.0703125, 0.999131977558136, 0.075086809694767, 0.0, 0.0086805559694767, 0.780381977558136, 0.0360243059694767, 0.02170138992369175, 0.0368923619389534, 0.0598958320915699, 0.0078125, 0.01171875, 0.0746527761220932, 0.0069444444961845875, 0.009982638992369175, 0.0967881977558136, 0.007378472480922937, 0.01215277798473835, 0.9986979365348816, 0.0677083358168602, 0.2109375, 0.0807291641831398, 0.11328125, 0.0568576380610466, 0.0234375, 0.02560763992369175, 0.005642361007630825, 0.0403645820915699, 0.02083333395421505, 0.0486111119389534, 0.01822916604578495, 0.009548611007630825, 0.0373263880610466, 0.0455729179084301, 0.0438368059694767, 0.01519097201526165, 0.0442708320915699, 0.02690972201526165, 0.01605902798473835, 0.9552951455116272, 0.9995659589767456, 0.0282118059694767, 0.01996527798473835, 0.03515625, 0.9995659589767456, 0.0334201380610466, 0.1037326380610466, 0.0716145858168602, 0.01171875, 0.0529513880610466, 0.90625, 0.02387152798473835, 0.0225694440305233, 0.0225694440305233, 0.0282118059694767, 0.0303819440305233, 0.02213541604578495, 0.8120659589767456, 0.0807291641831398, 0.917100727558136, 0.1705729216337204, 0.0768229141831398, 0.0212673619389534, 0.014756944961845875, 0.0850694477558136, 0.625, 0.4674479067325592, 0.086805559694767, 0.0203993059694767, 0.9318576455116272, 0.1215277761220932, 0.7717013955116272, 0.002170138992369175, 0.9986979365348816, 0.02213541604578495, 0.0677083358168602, 0.9995659589767456, 0.0, 0.8055555820465088, 0.9995659589767456, 0.106336809694767, 0.01215277798473835, 0.0542534738779068, 0.0212673619389534, 0.03125, 0.0733506977558136, 0.169704869389534, 0.009548611007630825, 0.6315104365348816, 0.02213541604578495, 0.7721354365348816, 0.01605902798473835, 0.9995659589767456, 0.014322916977107525, 0.009548611007630825, 0.9995659589767456, 0.0729166641831398, 0.0338541679084301, 0.0603298619389534, 0.01822916604578495, 0.00824652798473835, 0.010850694961845875, 0.01519097201526165, 0.9995659589767456, 0.0321180559694767, 0.013020833022892475, 0.0490451380610466, 0.0334201380610466, 0.02734375, 0.9487847089767456, 0.1922743022441864, 0.02560763992369175, 0.0047743055038154125, 0.01692708395421505, 0.0776909738779068, 0.9314236044883728, 0.0203993059694767, 0.9348958134651184, 0.0338541679084301, 0.0815972238779068, 0.0451388880610466, 0.913194477558136, 0.9097222089767456, 0.02951388992369175, 0.009548611007630825, 0.02604166604578495, 0.9995659589767456, 0.9986979365348816, 0.0416666679084301, 0.999131977558136, 0.02734375, 0.01128472201526165, 0.1106770858168602, 0.02300347201526165, 0.02300347201526165, 0.007378472480922937, 0.0598958320915699, 0.0078125, 0.0842013880610466, 0.0625, 0.02170138992369175, 0.0772569477558136, 0.109375, 0.1067708358168602, 0.999131977558136, 0.6041666865348816]

 sparsity of   [0.0390625, 0.99609375, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.17578125, 0.078125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.109375, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.09375, 0.09375, 0.9921875, 0.9921875, 0.99609375, 0.125, 0.9921875, 0.9921875, 0.9921875, 0.0703125, 0.9921875, 0.109375, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.19921875, 0.9921875, 0.9921875, 0.9921875, 0.16796875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.98046875, 0.14453125, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.07421875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.02734375, 0.9921875, 0.99609375, 0.9921875, 0.42578125, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.05078125, 0.98828125, 0.2578125, 0.99609375, 0.9921875, 0.125, 0.99609375, 0.0546875, 0.9921875, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.48046875, 0.9921875, 0.1015625, 0.015625, 0.9921875, 0.03125, 0.13671875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.98828125, 0.03515625, 0.9921875, 0.9921875, 0.9921875, 0.328125, 0.99609375, 0.15625, 0.98828125, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.1171875, 0.9921875, 0.06640625, 0.9921875, 0.98828125, 0.9921875, 0.0859375, 0.06640625, 0.06640625, 0.9921875, 0.99609375, 0.98828125, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.125, 0.1484375, 0.99609375, 0.99609375, 0.3046875, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.57421875, 0.99609375, 0.9921875, 0.28515625, 0.9921875, 0.9921875, 0.9921875, 0.16015625, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.98828125, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.09765625, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.1640625, 0.40625, 0.125, 0.99609375, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.08984375, 0.9921875, 0.44921875, 0.40625, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.08984375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.07421875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.48828125, 0.08984375, 0.9921875, 0.0234375, 0.9921875, 0.078125, 0.9921875, 0.109375, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.18359375, 0.1640625, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.06640625, 0.9921875, 0.08203125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.08203125, 0.9921875, 0.9921875, 0.16796875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.13671875, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.09765625, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.10546875, 0.9921875, 0.9921875, 0.99609375, 0.98828125, 0.4921875, 0.07421875, 0.99609375, 0.9921875, 0.9921875, 0.1640625, 0.9921875, 0.9921875, 0.1171875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.1484375, 0.125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.4375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.99609375, 0.46875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.21484375, 0.9921875, 0.99609375, 0.99609375, 0.05859375, 0.9921875, 0.0234375, 0.9921875, 0.0859375, 0.9921875, 0.9921875, 0.99609375, 0.98828125, 0.99609375, 0.484375, 0.375, 0.98828125, 0.06640625, 0.98828125, 0.99609375, 0.98828125, 0.9921875, 0.99609375, 0.98828125, 0.99609375, 0.11328125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.40625, 0.9921875, 0.9921875, 0.29296875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.16015625, 0.08203125, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.24609375, 0.9921875, 0.99609375, 0.0703125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.08984375, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.125, 0.9921875, 0.98828125, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.12109375, 0.21484375, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.0625, 0.9921875, 0.37109375, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.1640625, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.0625, 0.99609375, 0.99609375, 0.03125, 0.9921875, 0.98828125, 0.05859375, 0.99609375, 0.05859375, 0.99609375, 0.3125, 0.9921875, 0.9921875, 0.9921875, 0.30859375, 0.9921875, 0.40625, 0.9921875, 0.1171875, 0.99609375, 0.9921875, 0.18359375, 0.99609375, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.25, 0.9921875, 0.07421875, 0.9921875, 0.98828125, 0.99609375, 0.9921875, 0.98828125, 0.12890625, 0.98828125, 0.9921875, 0.9921875, 0.09765625, 0.9921875, 0.9921875, 0.99609375, 0.13671875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.1171875, 0.9921875, 0.9921875, 0.99609375, 0.90234375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.171875, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.04296875, 0.9921875, 0.1015625, 0.99609375, 0.98828125, 0.9921875, 0.1328125, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.06640625, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.02734375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.31640625, 0.9921875, 0.20703125, 0.99609375, 0.0625, 0.9921875, 0.9921875, 0.078125, 0.9921875, 0.9921875, 0.0546875, 0.99609375, 0.9921875, 0.9921875, 0.4921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.2109375, 0.9921875, 0.09765625, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.3203125, 0.07421875, 0.98828125, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.14453125, 0.9921875, 0.875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.07421875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.16796875, 0.9921875, 0.9921875, 0.99609375, 0.12890625, 0.9921875, 0.9921875, 0.98828125, 0.1484375, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.12109375, 0.41015625, 0.9921875, 0.9921875, 0.9921875, 0.44140625, 0.9921875, 0.10546875, 0.99609375, 0.99609375, 0.9921875, 0.1640625, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.05859375, 0.9921875, 0.98828125, 0.33984375, 0.10546875, 0.484375, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.16015625, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.1484375, 0.14453125, 0.44921875, 0.9921875, 0.9921875, 0.2265625, 0.9921875, 0.99609375, 0.9921875, 0.015625, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.0625, 0.99609375, 0.9921875, 0.98828125, 0.99609375, 0.9921875, 0.75, 0.9921875, 0.01171875, 0.484375, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.1953125, 0.171875, 0.99609375, 0.0703125, 0.9921875, 0.1796875, 0.9921875, 0.03515625, 0.9921875, 0.11328125, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.41015625, 0.9921875, 0.09765625, 0.99609375, 0.9921875, 0.1875, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.98828125, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.0390625, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.08203125, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.12890625, 0.98828125, 0.9921875, 0.98828125, 0.48828125, 0.9921875, 0.0703125, 0.98828125, 0.1484375, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.109375, 0.13671875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.2734375, 0.08203125, 0.9921875, 0.3984375, 0.99609375, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.078125, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.10546875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.1953125, 0.99609375, 0.9921875, 0.9921875, 0.09375, 0.9921875, 0.0390625, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.1796875, 0.9921875, 0.06640625, 0.9921875, 0.32421875, 0.99609375, 0.99609375, 0.0625, 0.4296875, 0.9921875, 0.98828125, 0.98828125, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.09375, 0.19140625, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.1015625, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.0703125, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.08203125, 0.9921875, 0.9921875, 0.015625, 0.99609375, 0.9921875, 0.9921875, 0.98828125, 0.99609375, 0.09765625, 0.15234375, 0.9921875, 0.9921875, 0.04296875, 0.03515625, 0.9921875, 0.33203125, 0.9921875, 0.99609375, 0.1015625, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.21484375, 0.046875, 0.99609375, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.3984375, 0.9921875, 0.9921875, 0.07421875, 0.0390625, 0.9921875, 0.99609375, 0.99609375, 0.99609375, 0.9921875, 0.125, 0.4921875, 0.5078125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.453125, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.4609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.109375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.11328125, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.1015625, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.99609375, 0.98828125, 0.015625, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.98828125, 0.4453125]

 sparsity of   [0.04296875, 0.8642578125, 0.0302734375, 0.8720703125, 0.037109375, 0.0244140625, 0.865234375, 0.998046875, 0.998046875, 0.076171875, 0.7763671875, 0.9423828125, 0.998046875, 0.1259765625, 0.939453125, 0.921875, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.126953125, 0.0693359375, 0.998046875, 0.859375, 0.0341796875, 0.0947265625, 0.064453125, 0.8525390625, 0.998046875, 0.080078125, 0.0234375, 0.0625, 0.9970703125, 0.0234375, 0.998046875, 0.07421875, 0.998046875, 0.0244140625, 0.998046875, 0.998046875, 0.1044921875, 0.205078125, 0.99609375, 0.998046875, 0.9970703125, 0.12890625, 0.03515625, 0.998046875, 0.1259765625, 0.033203125, 0.46875, 0.0546875, 0.998046875, 0.76171875, 0.0283203125, 0.998046875, 0.0341796875, 0.0263671875, 0.125, 0.841796875, 0.998046875, 0.0771484375, 0.0673828125, 0.0302734375, 0.0927734375, 0.076171875, 0.90234375, 0.998046875, 0.0849609375, 0.03515625, 0.037109375, 0.8095703125, 0.10546875, 0.04296875, 0.9990234375, 0.9970703125, 0.0283203125, 0.060546875, 0.9130859375, 0.90625, 0.9970703125, 0.7998046875, 0.9013671875, 0.185546875, 0.04296875, 0.998046875, 0.998046875, 0.0380859375, 0.0263671875, 0.9970703125, 0.0205078125, 0.998046875, 0.998046875, 0.8125, 0.9970703125, 0.072265625, 0.0322265625, 0.8125, 0.998046875, 0.998046875, 0.9990234375, 0.919921875, 0.998046875, 0.998046875, 0.0283203125, 0.998046875, 0.0302734375, 0.01953125, 0.998046875, 0.04296875, 0.1044921875, 0.9990234375, 0.9990234375, 0.998046875, 0.1572265625, 0.1396484375, 0.998046875, 0.998046875, 0.998046875, 0.1025390625, 0.236328125, 0.181640625, 0.953125, 0.005859375, 0.033203125, 0.1357421875, 0.998046875, 0.998046875, 0.9248046875, 0.08203125, 0.998046875, 0.029296875, 0.9970703125, 0.9970703125, 0.998046875, 0.998046875, 0.0849609375, 0.119140625, 0.04296875, 0.05078125, 0.0556640625, 0.7705078125, 0.1904296875, 0.041015625, 0.8984375, 0.08984375, 0.9072265625, 0.1591796875, 0.017578125, 0.234375, 0.943359375, 0.9130859375, 0.0986328125, 0.0625, 0.095703125, 0.998046875, 0.0615234375, 0.80078125, 0.06640625, 0.0859375, 0.8955078125, 0.078125, 0.998046875, 0.1181640625, 0.0908203125, 0.189453125, 0.07421875, 0.8134765625, 0.998046875, 0.177734375, 0.060546875, 0.044921875, 0.998046875, 0.9970703125, 0.998046875, 0.033203125, 0.068359375, 0.998046875, 0.1162109375, 0.0498046875, 0.998046875, 0.072265625, 0.998046875, 0.2548828125, 0.998046875, 0.806640625, 0.03515625, 0.998046875, 0.0537109375, 0.060546875, 0.0185546875, 0.08984375, 0.998046875, 0.244140625, 0.1171875, 0.998046875, 0.9521484375, 0.998046875, 0.32421875, 0.998046875, 0.0068359375, 0.046875, 0.1015625, 0.9501953125, 0.12890625, 0.8076171875, 0.998046875, 0.138671875, 0.998046875, 0.04296875, 0.029296875, 0.095703125, 0.0478515625, 0.9990234375, 0.037109375, 0.99609375, 0.048828125, 0.0244140625, 0.2392578125, 0.0595703125, 0.9990234375, 0.0400390625, 0.0537109375, 0.998046875, 0.0556640625, 0.998046875, 0.033203125, 0.201171875, 0.0, 0.998046875, 0.998046875, 0.0390625, 0.0341796875, 0.08984375, 0.998046875, 0.017578125, 0.13671875, 0.998046875, 0.05078125, 0.998046875, 0.046875, 0.015625, 0.095703125, 0.9970703125, 0.056640625, 0.0, 0.7822265625, 0.0439453125, 0.845703125, 0.998046875, 0.998046875, 0.998046875, 0.1533203125, 0.998046875, 0.13671875, 0.208984375]

 sparsity of   [0.02300347201526165, 0.1098090261220932, 0.1254340261220932, 0.999131977558136, 0.0533854179084301, 0.0954861119389534, 0.0381944440305233, 0.063368059694767, 0.0386284738779068, 0.0850694477558136, 0.0065104165114462376, 0.0967881977558136, 0.010416666977107525, 0.142361119389534, 0.828125, 0.0933159738779068, 0.0321180559694767, 0.0325520820915699, 0.0403645820915699, 0.1506076455116272, 0.0460069440305233, 0.0642361119389534, 0.0512152798473835, 0.0, 0.7591145634651184, 0.00390625, 0.1232638880610466, 0.1197916641831398, 0.146267369389534, 0.95703125, 0.0499131940305233, 0.006076388992369175, 0.015625, 0.0338541679084301, 0.1258680522441864, 0.1145833358168602, 0.013888888992369175, 0.3016493022441864, 0.0607638880610466, 0.1753472238779068, 0.0724826380610466, 0.0442708320915699, 0.8046875, 0.102430559694767, 0.8832465410232544, 0.01953125, 0.0572916679084301, 0.0655381977558136, 0.0368923619389534, 0.0377604179084301, 0.0325520820915699, 0.0325520820915699, 0.0481770820915699, 0.1271701455116272, 0.0703125, 0.0377604179084301, 0.9735243320465088, 0.0503472238779068, 0.0342881940305233, 0.1280381977558136, 0.453125, 0.0902777761220932, 0.1302083283662796, 0.0477430559694767, 0.6792534589767456, 0.03081597201526165, 0.01779513992369175, 0.0876736119389534, 0.02083333395421505, 0.0403645820915699, 0.9114583134651184, 0.0173611119389534, 0.0347222238779068, 0.0564236119389534, 0.0464409738779068, 0.009114583022892475, 0.9986979365348816, 0.7595486044883728, 0.0811631977558136, 0.046875, 0.106336809694767, 0.0577256940305233, 0.03081597201526165, 0.0685763880610466, 0.02951388992369175, 0.1041666641831398, 0.0494791679084301, 0.0911458358168602, 0.1419270783662796, 0.009114583022892475, 0.0959201380610466, 0.02083333395421505, 0.0364583320915699, 0.02387152798473835, 0.1002604141831398, 0.142361119389534, 0.02473958395421505, 0.0516493059694767, 0.0329861119389534, 0.03081597201526165, 0.03125, 0.0416666679084301, 0.0321180559694767, 0.0394965298473835, 0.0794270858168602, 0.01953125, 0.1072048619389534, 0.082899309694767, 0.5447048544883728, 0.2486979216337204, 0.01692708395421505, 0.3754340410232544, 0.6848958134651184, 0.0342881940305233, 0.7387152910232544, 0.0225694440305233, 0.0234375, 0.0347222238779068, 0.1341145783662796, 0.0755208358168602, 0.063368059694767, 0.02994791604578495, 0.010850694961845875, 0.01909722201526165, 0.0555555559694767, 0.9986979365348816, 0.0685763880610466, 0.0638020858168602, 0.6449652910232544, 0.1145833358168602, 0.0542534738779068, 0.098524309694767, 0.803819477558136, 0.013020833022892475, 0.999131977558136, 0.0442708320915699, 0.007378472480922937, 0.0078125, 0.0564236119389534, 0.0989583358168602, 0.0321180559694767, 0.999131977558136, 0.1779513955116272, 0.6393229365348816, 0.0798611119389534, 0.1848958283662796, 0.0577256940305233, 0.0646701380610466, 0.8641493320465088, 0.5412326455116272, 0.999131977558136, 0.0763888880610466, 0.1375868022441864, 0.02170138992369175, 0.0316840298473835, 0.010416666977107525, 0.015625, 0.0425347238779068, 0.1067708358168602, 0.386284738779068, 0.9986979365348816, 0.0759548619389534, 0.02300347201526165, 0.01519097201526165, 0.1297743022441864, 0.0434027798473835, 0.157986119389534, 0.0581597238779068, 0.0325520820915699, 0.2118055522441864, 0.1158854141831398, 0.23046875, 0.01605902798473835, 0.02777777798473835, 0.796875, 0.04296875, 0.0399305559694767, 0.0529513880610466, 0.0494791679084301, 0.8997395634651184, 0.1067708358168602, 0.0520833320915699, 0.0282118059694767, 0.5555555820465088, 0.0894097238779068, 0.9761284589767456, 0.01519097201526165, 0.02604166604578495, 0.02387152798473835, 0.0659722238779068, 0.0425347238779068, 0.0390625, 0.009982638992369175, 0.1085069477558136, 0.193142369389534, 0.0859375, 0.1927083283662796, 0.7274305820465088, 0.9500868320465088, 0.090711809694767, 0.015625, 0.999131977558136, 0.0668402761220932, 0.01171875, 0.0047743055038154125, 0.0034722222480922937, 0.0590277798473835, 0.01779513992369175, 0.1032986119389534, 0.00824652798473835, 0.0316840298473835, 0.0625, 0.1996527761220932, 0.9986979365348816, 0.9622395634651184, 0.1740451455116272, 0.01171875, 0.0481770820915699, 0.0568576380610466, 0.0282118059694767, 0.6106770634651184, 0.1527777761220932, 0.0225694440305233, 0.01822916604578495, 0.01605902798473835, 0.1575520783662796, 0.0052083334885537624, 0.0251736119389534, 0.01692708395421505, 0.0052083334885537624, 0.0555555559694767, 0.01215277798473835, 0.0824652761220932, 0.009548611007630825, 0.01171875, 0.01779513992369175, 0.03515625, 0.02560763992369175, 0.0538194440305233, 0.02170138992369175, 0.0251736119389534, 0.0555555559694767, 0.0763888880610466, 0.1449652761220932, 0.8980034589767456, 0.013020833022892475, 0.0403645820915699, 0.1184895858168602, 0.0368923619389534, 0.0651041641831398, 0.08203125, 0.0438368059694767, 0.1072048619389534, 0.0342881940305233, 0.1059027761220932, 0.03081597201526165]

 sparsity of   [0.9921875, 0.21484375, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.99609375, 0.10546875, 0.1484375, 0.90234375, 0.9921875, 0.98828125, 0.0859375, 0.99609375, 0.98828125, 0.10546875, 0.9921875, 0.98828125, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.515625, 0.09375, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.10546875, 0.10546875, 0.9921875, 0.00390625, 0.1171875, 0.9921875, 0.16015625, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.09375, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.2265625, 0.0859375, 0.11328125, 0.109375, 0.98828125, 0.0859375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.0390625, 0.9921875, 0.9921875, 0.15234375, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.07421875, 0.9921875, 0.9921875, 0.10546875, 0.9921875, 0.08203125, 0.98828125, 0.9921875, 0.34765625, 0.9921875, 0.08984375, 0.99609375, 0.98828125, 0.1015625, 0.99609375, 0.078125, 0.0234375, 0.1640625, 0.9921875, 0.98828125, 0.08984375, 0.9921875, 0.1015625, 0.9921875, 0.9921875, 0.98828125, 0.171875, 0.26953125, 0.9921875, 0.1875, 0.99609375, 0.1015625, 0.0390625, 0.171875, 0.98828125, 0.9921875, 0.9921875, 0.99609375, 0.0703125, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.859375, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.98828125, 0.99609375, 0.19921875, 0.03125, 0.9921875, 0.9921875, 0.99609375, 0.078125, 0.3671875, 0.98828125, 0.2734375, 0.9921875, 0.99609375, 0.08984375, 0.99609375, 0.99609375, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.14453125, 0.1015625, 0.36328125, 0.9921875, 0.14453125, 0.1171875, 0.58984375, 0.08203125, 0.171875, 0.0078125, 0.9921875, 0.140625, 0.9921875, 0.23828125, 0.99609375, 0.0625, 0.18359375, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.99609375, 0.08203125, 0.9921875, 0.98828125, 0.06640625, 0.9921875, 0.98828125, 0.99609375, 0.9921875, 0.125, 0.01171875, 0.0546875, 0.1171875, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.98828125, 0.99609375, 0.1015625, 0.05859375, 0.265625, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.046875, 0.21875, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.78515625, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.078125, 0.99609375, 0.9921875, 0.0234375, 0.0859375, 0.9921875, 0.0234375, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.2578125, 0.9921875, 0.9921875, 0.99609375, 0.07421875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0703125, 0.9921875, 0.9921875, 0.9921875, 0.03125, 0.9921875, 0.09765625, 0.04296875, 0.9921875, 0.12109375, 0.98828125, 0.10546875, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.02734375, 0.98828125, 0.16796875, 0.9921875, 0.11328125, 0.9921875, 0.99609375, 0.13671875, 0.15625, 0.078125, 0.9921875, 0.9921875, 0.8671875, 0.17578125, 0.08984375, 0.87890625, 0.76953125, 0.1171875, 0.98828125, 0.08984375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0625, 0.81640625, 0.9921875, 0.99609375, 0.29296875, 0.1171875, 0.4375, 0.9921875, 0.03125, 0.8515625, 0.99609375, 0.98828125, 0.99609375, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.06640625, 0.99609375, 0.9921875, 0.9921875, 0.98828125, 0.3359375, 0.9921875, 0.3984375, 0.9921875, 0.98828125, 0.0703125, 0.06640625, 0.98828125, 0.9921875, 0.34765625, 0.1171875, 0.9921875, 0.9921875, 0.1796875, 0.98828125, 0.9921875, 0.98828125, 0.1796875, 0.9921875, 0.421875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.3984375, 0.11328125, 0.98828125, 0.1015625, 0.9921875, 0.9921875, 0.99609375, 0.03125, 0.98828125, 0.99609375, 0.98828125, 0.03125, 0.99609375, 0.109375, 0.05859375, 0.9921875, 0.171875, 0.9921875, 0.15625, 0.08984375, 0.9921875, 0.98828125, 0.98828125, 0.890625, 0.9921875, 0.28515625, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.15234375, 0.9921875, 0.9921875, 0.99609375, 0.0546875, 0.12890625, 0.9921875, 0.98828125, 0.9921875, 0.25390625, 0.02734375, 0.046875, 0.9921875, 0.99609375, 0.078125, 0.9921875, 0.0390625, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.19921875, 0.109375, 0.0703125, 0.99609375, 0.98828125, 0.02734375, 0.9921875, 0.015625, 0.9921875, 0.9921875, 0.1484375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.12890625, 0.98828125, 0.5, 0.06640625, 0.9921875, 0.9921875, 0.14453125, 0.015625, 0.9921875, 0.09375, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.00390625, 0.046875, 0.9921875, 0.9921875, 0.1015625, 0.34765625, 0.99609375, 0.421875, 0.98828125, 0.9921875, 0.9921875, 0.984375, 0.9921875, 0.01171875, 0.9921875, 0.28125, 0.9921875, 0.07421875, 0.99609375, 0.05078125, 0.83984375, 0.171875, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.98828125, 0.98828125, 0.99609375, 0.99609375, 0.9921875, 0.12890625, 0.1328125, 0.01171875, 0.9921875, 0.98828125, 0.20703125, 0.98828125, 0.09375, 0.99609375, 0.02734375, 0.01953125, 0.078125, 0.98828125, 0.98828125, 0.99609375, 0.234375, 0.078125, 0.015625, 0.9921875, 0.28515625, 0.9921875, 0.20703125, 0.99609375, 0.99609375, 0.0390625, 0.0546875, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.078125, 0.1328125, 0.9921875, 0.91015625, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.1328125, 0.078125, 0.875, 0.9921875, 0.9921875, 0.99609375, 0.01171875, 0.05859375, 0.0078125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.87890625, 0.99609375, 0.98828125, 0.171875, 0.0234375, 0.99609375, 0.98828125, 0.234375, 0.9921875, 0.08203125, 0.04296875, 0.0625, 0.9921875, 0.40234375, 0.9921875, 0.9921875, 0.99609375, 0.07421875, 0.9921875, 0.9921875, 0.04296875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.10546875, 0.98828125, 0.99609375, 0.9921875, 0.9921875, 0.82421875, 0.99609375, 0.0703125, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.05859375, 0.98828125, 0.9921875, 0.12890625, 0.9921875, 0.99609375, 0.9921875, 0.046875, 0.9921875, 0.0390625, 0.36328125, 0.9921875, 0.9921875, 0.1015625, 0.01953125, 0.125, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.1796875, 0.9921875, 0.9921875, 0.16796875, 0.0625, 0.0390625, 0.1796875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.98828125, 0.98828125, 0.1796875, 0.12109375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.99609375, 0.171875, 0.16015625, 0.9921875, 0.99609375, 0.04296875, 0.99609375, 0.1171875, 0.125, 0.9921875, 0.98828125, 0.9921875, 0.0546875, 0.1171875, 0.9921875, 0.09375, 0.07421875, 0.9921875, 0.9921875, 0.98828125, 0.08984375, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.08203125, 0.9921875, 0.9921875, 0.0859375, 0.453125, 0.08203125, 0.1015625, 0.0625, 0.9921875, 0.05859375, 0.9921875, 0.98828125, 0.9921875, 0.046875, 0.86328125, 0.9921875, 0.9921875, 0.08203125, 0.12890625, 0.9921875, 0.03515625, 0.09375, 0.0703125, 0.9921875, 0.16015625, 0.98828125, 0.99609375, 0.9921875, 0.9921875, 0.12109375, 0.36328125, 0.9921875, 0.1640625, 0.9921875, 0.9921875, 0.06640625, 0.93359375, 0.18359375, 0.9921875, 0.9921875, 0.98828125, 0.99609375, 0.9921875, 0.22265625, 0.09765625, 0.9921875, 0.109375, 0.9921875, 0.99609375, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.0703125, 0.9921875, 0.08984375, 0.49609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.3359375, 0.984375, 0.9921875, 0.9921875, 0.9921875, 0.1953125, 0.15234375, 0.99609375, 0.984375, 0.9921875, 0.9921875, 0.09765625, 0.05078125, 0.046875, 0.98828125, 0.1640625, 0.98828125, 0.0546875, 0.3671875, 0.1171875, 0.08984375, 0.4921875, 0.06640625, 0.99609375, 0.99609375, 0.9921875, 0.0625, 0.05859375, 0.0625, 0.9921875, 0.9921875, 0.04296875, 0.9921875, 0.04296875, 0.0234375, 0.9921875, 0.99609375, 0.19140625, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.08984375, 0.99609375, 0.9921875, 0.99609375, 0.046875, 0.98828125, 0.99609375, 0.9921875, 0.9921875, 0.98828125, 0.08203125, 0.0390625, 0.1015625, 0.9921875, 0.1484375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.12109375, 0.078125, 0.9921875, 0.98828125, 0.13671875, 0.3828125, 0.9921875, 0.99609375, 0.1875, 0.9921875, 0.99609375, 0.1015625, 0.99609375, 0.13671875, 0.05078125, 0.99609375, 0.0390625, 0.79296875, 0.99609375, 0.140625, 0.9921875, 0.98828125, 0.99609375, 0.02734375, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.2421875, 0.03515625, 0.9921875, 0.1953125, 0.1171875, 0.99609375, 0.125, 0.99609375, 0.09765625, 0.9921875, 0.04296875, 0.9921875, 0.99609375, 0.3828125, 0.1015625, 0.1640625, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.99609375, 0.99609375, 0.1328125, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.98828125, 0.04296875, 0.9921875, 0.9921875, 0.1484375, 0.16015625, 0.03125, 0.9921875, 0.07421875, 0.9921875, 0.35546875, 0.99609375, 0.98828125, 0.9921875, 0.1875, 0.99609375, 0.9921875, 0.9921875, 0.98828125, 0.09375, 0.078125, 0.328125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.04296875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.10546875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.09375, 0.9921875, 0.25, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.11328125, 0.06640625, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.1484375, 0.9921875, 0.9921875, 0.3046875, 0.23828125, 0.9921875, 0.08984375, 0.99609375, 0.9921875, 0.9921875, 0.21875, 0.3984375, 0.0625, 0.15234375, 0.98828125, 0.9921875, 0.0625, 0.27734375, 0.0546875, 0.98828125, 0.1484375, 0.9921875, 0.0625, 0.9921875, 0.99609375, 0.08203125, 0.9921875, 0.09765625, 0.99609375, 0.9921875, 0.0234375, 0.2890625, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.12109375, 0.9921875, 0.9921875, 0.16796875, 0.890625, 0.0625, 0.03125, 0.9921875, 0.9921875, 0.15625, 0.9921875, 0.9921875, 0.9921875, 0.21484375, 0.98828125, 0.8203125, 0.99609375, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.20703125, 0.109375, 0.99609375, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.07421875, 0.5546875, 0.03515625, 0.3515625, 0.140625, 0.99609375, 0.9921875, 0.98828125, 0.6875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.08203125, 0.98828125, 0.0546875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.984375, 0.078125, 0.99609375, 0.23046875, 0.99609375, 0.54296875, 0.859375, 0.796875, 0.9921875, 0.19921875, 0.9921875, 0.9921875, 0.0625, 0.05859375, 0.98828125, 0.9921875, 0.0703125, 0.99609375, 0.9921875, 0.77734375, 0.99609375, 0.9921875, 0.125, 0.125, 0.9921875, 0.99609375, 0.83984375, 0.01953125, 0.99609375, 0.98828125, 0.2109375, 0.99609375, 0.99609375, 0.140625, 0.99609375, 0.99609375, 0.9921875, 0.16796875, 0.9921875, 0.9921875, 0.12890625, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.13671875, 0.9921875, 0.9921875, 0.046875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.44140625, 0.03125, 0.9921875, 0.9921875, 0.9921875, 0.05859375, 0.9921875, 0.99609375, 0.1953125, 0.00390625, 0.05078125, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.99609375, 0.16796875, 0.9140625, 0.9921875, 0.0859375, 0.07421875, 0.9921875, 0.0859375, 0.21875, 0.98828125, 0.40625, 0.08984375, 0.99609375, 0.99609375, 0.01953125, 0.98828125, 0.99609375, 0.140625]

 sparsity of   [0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.9990234375, 0.9990234375, 0.998046875, 0.4853515625, 0.07421875, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.1826171875, 0.9970703125, 0.99609375, 0.845703125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.99609375, 0.9970703125, 0.9970703125, 0.998046875, 0.998046875, 0.1650390625, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.13671875, 0.9970703125, 0.9990234375, 0.255859375, 0.9990234375, 0.9990234375, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.4931640625, 0.998046875, 0.0615234375, 0.9970703125, 0.0400390625, 0.9990234375, 0.4609375, 0.998046875, 0.9970703125, 0.998046875, 0.9990234375, 0.998046875, 0.134765625, 0.9990234375, 0.9990234375, 0.998046875, 0.9990234375, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.099609375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.1083984375, 0.998046875, 0.1201171875, 0.998046875, 0.13671875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.138671875, 0.998046875, 0.1201171875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.9970703125, 0.9990234375, 0.998046875, 0.9970703125, 0.9970703125, 0.9990234375, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.0849609375, 0.998046875, 0.9970703125, 0.9990234375, 0.9990234375, 0.0341796875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.99609375, 0.998046875, 0.998046875, 0.08203125, 0.998046875, 0.0986328125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.99609375, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.9970703125, 0.998046875, 0.9990234375, 0.998046875, 0.0771484375, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.9990234375, 0.28125, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.197265625, 0.998046875, 0.9970703125, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.1650390625, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.828125, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.0263671875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.162109375, 0.9990234375, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.9990234375, 0.138671875, 0.0556640625, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.9990234375, 0.9990234375, 0.9990234375, 0.998046875, 0.9970703125, 0.1650390625, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.11328125, 0.9990234375, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.2275390625, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.9990234375, 0.9990234375, 0.998046875, 0.9990234375, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.9990234375, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.0830078125, 0.998046875, 0.0859375, 0.998046875, 0.0517578125, 0.9970703125, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.896484375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.9990234375, 0.998046875, 0.0859375, 0.1083984375, 0.9990234375, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.9990234375, 0.4228515625, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.9970703125, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.255859375, 0.998046875, 0.998046875, 0.064453125, 0.9990234375, 0.998046875, 0.1142578125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.9990234375, 0.998046875, 0.9990234375, 0.9990234375, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.2353515625, 0.998046875, 0.998046875, 0.9990234375, 0.9970703125, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.1181640625, 0.255859375, 0.9970703125, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.4765625, 0.998046875, 0.998046875, 0.8583984375, 0.998046875, 0.5166015625, 0.9990234375, 0.9990234375, 0.998046875, 0.9990234375, 0.9990234375, 0.9970703125, 0.998046875, 0.9970703125, 0.4287109375, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.0703125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.4697265625, 0.998046875, 0.9990234375, 0.115234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9970703125, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.9970703125, 0.9990234375, 0.998046875]

 sparsity of   [0.1085069477558136, 0.9995659589767456, 0.9995659589767456, 0.0846354141831398, 0.148220494389534, 0.0668402761220932, 0.0442708320915699, 0.94921875, 0.9995659589767456, 0.9995659589767456, 0.9995659589767456, 0.9995659589767456, 0.0407986119389534, 0.0225694440305233, 0.1799045205116272, 0.9997829794883728, 0.0440538190305233, 0.0670572891831398, 0.9279513955116272, 0.0212673619389534, 0.0748697891831398, 0.0766059011220932, 0.89453125, 0.9995659589767456, 0.8695746660232544, 0.8704426884651184, 0.8582899570465088, 0.0915798619389534, 0.1026475727558136, 0.216796875, 0.0310329869389534, 0.0184461809694767, 0.9995659589767456, 0.9995659589767456, 0.0575086809694767, 0.2504340410232544, 0.1165364608168602, 0.0666232630610466, 0.9995659589767456, 0.9995659589767456, 0.9993489384651184, 0.0499131940305233, 0.0397135429084301, 0.9993489384651184, 0.04296875, 0.1243489608168602, 0.0353732630610466, 0.0740017369389534, 0.0618489570915699, 0.029296875, 0.9995659589767456, 0.9993489384651184, 0.9997829794883728, 0.0438368059694767, 0.2387152761220932, 0.0590277798473835, 0.9220920205116272, 0.025390625, 0.9819878339767456, 0.9995659589767456, 0.0486111119389534, 0.9839409589767456, 0.9993489384651184, 0.1640625, 0.8240017294883728, 0.9997829794883728, 0.169921875, 0.9995659589767456, 0.0473090298473835, 0.1634114533662796, 0.9995659589767456, 0.9995659589767456, 0.9995659589767456, 0.9487847089767456, 0.1085069477558136, 0.9995659589767456, 0.0631510391831398, 0.94921875, 0.9995659589767456, 0.9995659589767456, 0.095703125, 0.9995659589767456, 0.26953125, 0.248046875, 0.9995659589767456, 0.9995659589767456, 0.02734375, 0.9995659589767456, 0.9995659589767456, 0.9995659589767456, 0.0418836809694767, 0.9993489384651184, 0.9993489384651184, 0.2174479216337204, 0.0223524309694767, 0.9995659589767456, 0.1202256977558136, 0.0525173619389534, 0.9995659589767456, 0.9993489384651184, 0.9995659589767456, 0.0457899309694767, 0.9995659589767456, 0.921006977558136, 0.1182725727558136, 0.9997829794883728, 0.0470920130610466, 0.0698784738779068, 0.9995659589767456, 0.046875, 0.9997829794883728, 0.9993489384651184, 0.9997829794883728, 0.0549045130610466, 0.11328125, 0.9995659589767456, 0.044921875, 0.9993489384651184, 0.8064236044883728, 0.9997829794883728, 0.9995659589767456, 0.9995659589767456, 0.0438368059694767, 0.9995659589767456, 0.0983072891831398, 0.9995659589767456, 0.9995659589767456, 0.9995659589767456, 0.0544704869389534, 0.9995659589767456, 0.9995659589767456, 0.185329869389534, 0.0755208358168602, 0.9993489384651184, 0.9995659589767456, 0.0381944440305233, 0.9995659589767456, 0.0444878488779068, 0.1128472238779068, 0.0579427070915699, 0.1653645783662796, 0.9997829794883728, 0.9995659589767456, 0.0870225727558136, 0.0440538190305233, 0.1681857705116272, 0.04296875, 0.0677083358168602, 0.01822916604578495, 0.8993055820465088, 0.0243055559694767, 0.1694878488779068, 0.9995659589767456, 0.0668402761220932, 0.0581597238779068, 0.1189236119389534, 0.9993489384651184, 0.940538227558136, 0.0436197929084301, 0.0470920130610466, 0.9995659589767456, 0.8980034589767456, 0.9995659589767456, 0.021484375, 0.9995659589767456, 0.01996527798473835, 0.9995659589767456, 0.9995659589767456, 0.0601128488779068, 0.0462239570915699, 0.9997829794883728, 0.099609375, 0.087890625, 0.9995659589767456, 0.9997829794883728, 0.0763888880610466, 0.9995659589767456, 0.0833333358168602, 0.1851128488779068, 0.9995659589767456, 0.932725727558136, 0.9993489384651184, 0.2805989682674408, 0.9995659589767456, 0.1703559011220932, 0.02734375, 0.0440538190305233, 0.9993489384651184, 0.9993489384651184, 0.9995659589767456, 0.9995659589767456, 0.0477430559694767, 0.0492621548473835, 0.0338541679084301, 0.9997829794883728, 0.9997829794883728, 0.0987413227558136, 0.0466579869389534, 0.9993489384651184, 0.9995659589767456, 0.0329861119389534, 0.0392795130610466, 0.0401475690305233, 0.9995659589767456, 0.0503472238779068, 0.9995659589767456, 0.9995659589767456, 0.1050347238779068, 0.908203125, 0.02365451492369175, 0.9995659589767456, 0.9995659589767456, 0.9995659589767456, 0.9817708134651184, 0.0447048619389534, 0.0444878488779068, 0.1731770783662796, 0.0603298619389534, 0.0232204869389534, 0.0618489570915699, 0.0533854179084301, 0.9173176884651184, 0.873046875, 0.85546875, 0.8580729365348816, 0.0342881940305233, 0.083984375, 0.9995659589767456, 0.1145833358168602, 0.02170138992369175, 0.2039930522441864, 0.9995659589767456, 0.1002604141831398, 0.9993489384651184, 0.1623263955116272, 0.0379774309694767, 0.9993489384651184, 0.9995659589767456, 0.0614149309694767, 0.0416666679084301, 0.1245659738779068, 0.1089409738779068, 0.721788227558136, 0.0601128488779068, 0.0529513880610466, 0.0562065988779068, 0.0583767369389534, 0.9995659589767456, 0.9995659589767456, 0.1204427108168602, 0.0614149309694767, 0.0290798619389534, 0.0451388880610466, 0.9993489384651184, 0.9995659589767456, 0.0416666679084301, 0.9993489384651184, 0.1124131977558136, 0.9993489384651184, 0.02973090298473835, 0.0935329869389534, 0.0655381977558136, 0.0592447929084301, 0.02191840298473835, 0.0824652761220932, 0.0505642369389534, 0.1868489533662796, 0.9995659589767456, 0.9995659589767456, 0.0384114570915699, 0.9995659589767456, 0.0542534738779068, 0.9997829794883728, 0.09765625, 0.9401041865348816, 0.9995659589767456, 0.1937934011220932, 0.9993489384651184, 0.0364583320915699, 0.9995659589767456, 0.072265625, 0.02799479104578495, 0.0700954869389534, 0.9995659589767456, 0.0555555559694767, 0.9995659589767456, 0.0564236119389534, 0.0473090298473835, 0.037109375, 0.90625, 0.9995659589767456, 0.0544704869389534, 0.9995659589767456, 0.0442708320915699, 0.0421006940305233, 0.02734375, 0.0874565988779068, 0.9997829794883728, 0.9995659589767456, 0.0980902761220932, 0.9995659589767456, 0.0670572891831398, 0.0223524309694767, 0.0412326380610466, 0.1052517369389534, 0.126736119389534, 0.0203993059694767, 0.1145833358168602, 0.9995659589767456, 0.9995659589767456, 0.9016926884651184, 0.9997829794883728, 0.9995659589767456, 0.0590277798473835, 0.1171875, 0.0470920130610466, 0.1167534738779068, 0.284722238779068, 0.0818142369389534, 0.0345052070915699, 0.1744791716337204, 0.0568576380610466, 0.1009114608168602, 0.0397135429084301, 0.046875, 0.9429253339767456, 0.9993489384651184, 0.9995659589767456, 0.0607638880610466, 0.1480034738779068, 0.9995659589767456, 0.0638020858168602, 0.1608072966337204, 0.9997829794883728, 0.0512152798473835, 0.9995659589767456, 0.0342881940305233, 0.9995659589767456, 0.84765625, 0.9993489384651184, 0.0384114570915699, 0.1002604141831398, 0.8947482705116272, 0.1050347238779068, 0.0360243059694767, 0.870225727558136, 0.9995659589767456, 0.0833333358168602, 0.025390625, 0.8598090410232544, 0.0798611119389534, 0.9995659589767456, 0.073133684694767, 0.9995659589767456, 0.9450954794883728, 0.0648871511220932, 0.9995659589767456, 0.9995659589767456, 0.1875, 0.0475260429084301, 0.0744357630610466, 0.0590277798473835, 0.9051649570465088, 0.9995659589767456, 0.9997829794883728, 0.0397135429084301, 0.2039930522441864, 0.078125, 0.9995659589767456, 0.9995659589767456, 0.0388454869389534, 0.9995659589767456, 0.9995659589767456, 0.327690988779068, 0.0264756940305233, 0.0492621548473835, 0.0453559048473835, 0.0544704869389534, 0.9995659589767456, 0.169704869389534, 0.9995659589767456, 0.8767361044883728, 0.0974392369389534, 0.9995659589767456, 0.9359809160232544, 0.03081597201526165, 0.0494791679084301, 0.0724826380610466, 0.0323350690305233, 0.9468315839767456, 0.9997829794883728, 0.9993489384651184, 0.107421875, 0.0503472238779068, 0.9095051884651184, 0.02777777798473835, 0.0533854179084301, 0.0531684048473835, 0.0397135429084301, 0.0434027798473835, 0.0425347238779068, 0.9997829794883728, 0.9993489384651184, 0.0271267369389534, 0.1100260391831398, 0.9995659589767456, 0.0512152798473835, 0.0818142369389534, 0.9995659589767456, 0.9993489384651184, 0.072265625, 0.0403645820915699, 0.0457899309694767, 0.08984375, 0.0674913227558136, 0.1221788227558136, 0.9995659589767456, 0.9995659589767456, 0.9993489384651184, 0.0638020858168602, 0.8977864384651184, 0.9995659589767456, 0.9993489384651184, 0.9995659589767456, 0.9995659589767456, 0.8806423544883728, 0.9466145634651184, 0.9995659589767456, 0.02473958395421505, 0.9995659589767456, 0.9997829794883728, 0.1148003488779068, 0.0447048619389534, 0.02105034701526165, 0.9993489384651184, 0.9049479365348816, 0.9995659589767456, 0.9995659589767456, 0.0991753488779068, 0.9040798544883728, 0.9995659589767456, 0.9997829794883728, 0.0690104141831398, 0.1085069477558136, 0.9995659589767456, 0.9830729365348816, 0.9993489384651184, 0.868272602558136, 0.0549045130610466, 0.9995659589767456, 0.0505642369389534, 0.9995659589767456, 0.02018229104578495, 0.0223524309694767, 0.9993489384651184, 0.9993489384651184, 0.126953125, 0.9993489384651184, 0.8621962070465088, 0.8736979365348816, 0.9123263955116272, 0.9995659589767456, 0.0540364570915699, 0.0740017369389534, 0.9995659589767456, 0.0503472238779068, 0.9997829794883728, 0.9995659589767456, 0.9997829794883728, 0.0872395858168602, 0.9995659589767456, 0.1158854141831398, 0.125, 0.9255642294883728, 0.0438368059694767, 0.1124131977558136, 0.8246527910232544, 0.071180559694767, 0.03125, 0.067274309694767, 0.9995659589767456, 0.946397602558136, 0.1011284738779068, 0.9995659589767456, 0.0993923619389534, 0.9995659589767456, 0.9995659589767456, 0.0529513880610466, 0.0512152798473835, 0.9490017294883728, 0.0193142369389534, 0.9993489384651184, 0.9995659589767456, 0.1091579869389534, 0.0509982630610466, 0.9995659589767456, 0.1788194477558136, 0.02734375, 0.9995659589767456, 0.1108940988779068, 0.9995659589767456, 0.1226128488779068, 0.908203125, 0.9995659589767456, 0.013671875, 0.901475727558136, 0.0282118059694767, 0.02300347201526165, 0.9995659589767456, 0.02473958395421505, 0.9995659589767456, 0.9995659589767456]

 sparsity of   [0.673828125, 0.23828125, 0.015625, 0.91015625, 0.05078125, 0.994140625, 0.05859375, 0.017578125, 0.08203125, 0.216796875, 0.251953125, 0.064453125, 0.0546875, 0.001953125, 0.0078125, 0.904296875, 0.037109375, 0.03125, 0.025390625, 0.052734375, 0.037109375, 0.1484375, 0.025390625, 0.060546875, 0.015625, 0.013671875, 0.0078125, 0.0234375, 0.458984375, 0.029296875, 0.017578125, 0.091796875, 0.033203125, 0.01953125, 0.0078125, 0.103515625, 0.0078125, 0.01953125, 0.015625, 0.033203125, 0.134765625, 0.0, 0.99609375, 0.181640625, 0.046875, 0.97265625, 0.0234375, 0.01171875, 0.0234375, 0.033203125, 0.091796875, 0.013671875, 0.015625, 0.01171875, 0.0390625, 0.03125, 0.0078125, 0.02734375, 0.021484375, 0.03125, 0.021484375, 0.66015625, 0.205078125, 0.01171875, 0.044921875, 0.044921875, 0.041015625, 0.2578125, 0.99609375, 0.01953125, 0.970703125, 0.0625, 0.0234375, 0.021484375, 0.123046875, 0.0234375, 0.138671875, 0.037109375, 0.048828125, 0.01953125, 0.021484375, 0.025390625, 0.880859375, 0.998046875, 0.333984375, 0.01953125, 0.0390625, 0.86328125, 0.0703125, 0.0703125, 0.076171875, 0.955078125, 0.01953125, 0.01171875, 0.10546875, 0.056640625, 0.056640625, 0.947265625, 0.16796875, 0.01171875, 0.1328125, 0.013671875, 0.708984375, 0.05078125, 0.060546875, 0.12109375, 0.037109375, 0.033203125, 0.130859375, 0.900390625, 0.69140625, 0.013671875, 0.041015625, 0.021484375, 0.0, 0.033203125, 0.076171875, 0.046875, 0.03125, 0.896484375, 0.046875, 0.015625, 0.1328125, 0.033203125, 0.03515625, 0.015625, 0.037109375, 0.01953125, 0.08984375, 0.02734375, 0.935546875, 0.267578125, 0.68359375, 0.865234375, 0.013671875, 0.015625, 0.869140625, 0.021484375, 0.0, 0.658203125, 0.81640625, 0.099609375, 0.767578125, 0.8828125, 0.025390625, 0.068359375, 0.99609375, 0.017578125, 0.900390625, 0.01953125, 0.068359375, 0.375, 0.033203125, 0.029296875, 0.03125, 0.07421875, 0.001953125, 0.0234375, 0.54296875, 0.1484375, 0.021484375, 0.13671875, 0.029296875, 0.05859375, 0.755859375, 0.09375, 0.037109375, 0.01953125, 0.013671875, 0.029296875, 0.01953125, 0.001953125, 0.029296875, 0.16015625, 0.017578125, 0.06640625, 0.95703125, 0.029296875, 0.06640625, 0.86328125, 0.08984375, 0.041015625, 0.259765625, 0.89453125, 0.029296875, 0.021484375, 0.99609375, 0.0, 0.072265625, 0.044921875, 0.123046875, 0.0234375, 0.00390625, 0.04296875, 0.8671875, 0.0234375, 0.998046875, 0.078125, 0.923828125, 0.0078125, 0.90625, 0.6328125, 0.009765625, 0.021484375, 0.06640625, 0.025390625, 0.392578125, 0.0078125, 0.021484375, 0.044921875, 0.0546875, 0.115234375, 0.03125, 0.037109375, 0.0234375, 0.068359375, 0.005859375, 0.009765625, 0.0234375, 0.025390625, 0.009765625, 0.021484375, 0.021484375, 0.025390625, 0.029296875, 0.994140625, 0.896484375, 0.015625, 0.0078125, 0.052734375, 0.03125, 0.0234375, 0.02734375, 0.03125, 0.017578125, 0.99609375, 0.037109375, 0.01171875, 0.125, 0.888671875, 0.173828125, 0.0390625, 0.001953125, 0.080078125, 0.017578125, 0.2109375, 0.02734375, 0.00390625, 0.02734375, 0.033203125, 0.03515625, 0.083984375, 0.037109375, 0.025390625, 0.044921875, 0.037109375, 0.017578125, 0.056640625, 0.029296875, 0.05859375, 0.001953125, 0.052734375, 0.056640625, 0.029296875, 0.083984375, 0.560546875, 0.0390625, 0.994140625, 0.923828125, 0.01171875, 0.630859375, 0.859375, 0.021484375, 0.08984375, 0.89453125, 0.994140625, 0.04296875, 0.01953125, 0.896484375, 0.025390625, 0.17578125, 0.0234375, 0.90234375, 0.5, 0.00390625, 0.994140625, 0.060546875, 0.07421875, 0.02734375, 0.095703125, 0.033203125, 0.095703125, 0.015625, 0.01953125, 0.01171875, 0.017578125, 0.03515625, 0.8828125, 0.021484375, 0.01171875, 0.015625, 0.0234375, 0.015625, 0.99609375, 0.013671875, 0.0625, 0.0546875, 0.037109375, 0.015625, 0.654296875, 0.037109375, 0.01953125, 0.939453125, 0.935546875, 0.021484375, 0.013671875, 0.037109375, 0.044921875, 0.931640625, 0.021484375, 0.0, 0.087890625, 0.05078125, 0.015625, 0.142578125, 0.046875, 0.015625, 0.015625, 0.0703125, 0.15625, 0.08203125, 0.015625, 0.03125, 0.029296875, 0.49609375, 0.052734375, 0.57421875, 0.033203125, 0.2578125, 0.009765625, 0.0390625, 0.07421875, 0.01953125, 0.017578125, 0.03515625, 0.013671875, 0.0078125, 0.140625, 0.953125, 0.07421875, 0.029296875, 0.0234375, 0.048828125, 0.728515625, 0.009765625, 0.015625, 0.8828125, 0.091796875, 0.0234375, 0.083984375, 0.0546875, 0.013671875, 0.626953125, 0.0625, 0.021484375, 0.134765625, 0.076171875, 0.810546875, 0.013671875, 0.998046875, 0.03125, 0.08984375, 0.04296875, 0.96484375, 0.865234375, 0.078125, 0.02734375, 0.02734375, 0.03515625, 0.99609375, 0.109375, 0.013671875, 0.0703125, 0.791015625, 0.201171875, 0.046875, 0.916015625, 0.05078125, 0.11328125, 0.0234375, 0.015625, 0.818359375, 0.02734375, 0.052734375, 0.951171875, 0.0, 0.080078125, 0.015625, 0.0078125, 0.03515625, 0.201171875, 0.064453125, 0.205078125, 0.0, 0.01171875, 0.08984375, 0.017578125, 0.02734375, 0.134765625, 0.32421875, 0.873046875, 0.03125, 0.04296875, 0.03515625, 0.04296875, 0.001953125, 0.04296875, 0.0234375, 0.08203125, 0.005859375, 0.091796875, 0.904296875, 0.04296875, 0.03515625, 0.033203125, 0.05078125, 0.064453125, 0.994140625, 0.189453125, 0.025390625, 0.056640625, 0.060546875, 0.263671875, 0.033203125, 0.099609375, 0.259765625, 0.0, 0.02734375, 0.021484375, 0.0234375, 0.947265625, 0.734375, 0.044921875, 0.0390625, 0.8828125, 0.0234375, 0.00390625, 0.01171875, 0.021484375, 0.01953125, 0.0, 0.29296875, 0.009765625, 0.0234375, 0.021484375, 0.00390625, 0.029296875, 0.0234375, 0.056640625, 0.01171875, 0.99609375, 0.05078125, 0.0234375, 0.72265625, 0.0, 0.015625, 0.056640625, 0.013671875, 0.0390625, 0.154296875, 0.26171875, 0.0, 0.021484375, 0.921875, 0.025390625, 0.0390625, 0.013671875, 0.46875, 0.0078125, 0.041015625, 0.009765625, 0.0234375, 0.029296875, 0.109375, 0.25, 0.927734375, 0.0625, 0.005859375, 0.244140625, 0.013671875, 0.009765625, 0.09375, 0.01953125, 0.16796875, 0.046875, 0.029296875, 0.025390625, 0.41796875, 0.861328125, 0.021484375, 0.904296875, 0.060546875, 0.08203125, 0.021484375, 0.904296875, 0.802734375, 0.056640625, 0.009765625, 0.833984375, 0.0078125, 0.029296875, 0.05078125, 0.994140625, 0.01953125, 0.017578125, 0.080078125, 0.0546875, 0.017578125, 0.88671875, 0.884765625, 0.01171875, 0.01171875, 0.99609375, 0.05859375, 0.009765625, 0.015625, 0.009765625, 0.01953125, 0.189453125, 0.02734375, 0.001953125, 0.025390625, 0.015625, 0.93359375, 0.015625, 0.90234375, 0.025390625, 0.779296875, 0.0859375, 0.03125, 0.91796875, 0.01171875, 0.076171875, 0.0234375, 0.021484375, 0.015625, 0.009765625, 0.001953125, 0.009765625, 0.017578125, 0.025390625, 0.814453125, 0.076171875, 0.044921875, 0.013671875, 0.00390625, 0.0703125, 0.119140625, 0.009765625, 0.04296875, 0.013671875, 0.0390625, 0.08984375, 0.236328125, 0.77734375, 0.02734375, 0.02734375, 0.0546875, 0.876953125, 0.013671875, 0.07421875, 0.0234375, 0.02734375, 0.052734375, 0.048828125, 0.01171875, 0.21875, 0.025390625, 0.0703125, 0.056640625, 0.130859375, 0.00390625, 0.001953125, 0.0, 0.021484375, 0.0, 0.0390625, 0.080078125, 0.015625, 0.052734375, 0.99609375, 0.072265625, 0.8515625, 0.0390625, 0.85546875, 0.005859375, 0.03125, 0.91796875, 0.041015625, 0.013671875, 0.048828125, 0.03125, 0.0078125, 0.0390625, 0.046875, 0.080078125, 0.0234375, 0.095703125, 0.3359375, 0.640625, 0.5390625, 0.095703125, 0.013671875, 0.095703125, 0.08203125, 0.00390625, 0.09375, 0.03515625, 0.99609375, 0.041015625, 0.025390625, 0.0390625, 0.861328125, 0.03515625, 0.02734375, 0.01953125, 0.03515625, 0.02734375, 0.009765625, 0.998046875, 0.01953125, 0.99609375, 0.00390625, 0.033203125, 0.142578125, 0.99609375, 0.994140625, 0.95703125, 0.046875, 0.009765625, 0.078125, 0.03125, 0.025390625, 0.03125, 0.025390625, 0.017578125, 0.005859375, 0.025390625, 0.08203125, 0.001953125, 0.05078125, 0.029296875, 0.064453125, 0.013671875, 0.037109375, 0.87890625, 0.01953125, 0.88671875, 0.05078125, 0.103515625, 0.048828125, 0.12109375, 0.041015625, 0.025390625, 0.1328125, 0.904296875, 0.017578125, 0.01171875, 0.013671875, 0.021484375, 0.833984375, 0.13671875, 0.013671875, 0.021484375, 0.056640625, 0.673828125, 0.771484375, 0.908203125, 0.025390625, 0.01953125, 0.005859375, 0.052734375, 0.025390625, 0.048828125, 0.013671875, 0.875, 0.01953125, 0.16796875, 0.0078125, 0.0078125, 0.0, 0.89453125, 0.021484375, 0.12109375, 0.046875, 0.015625, 0.107421875, 0.11328125, 0.0390625, 0.041015625, 0.072265625, 0.013671875, 0.025390625, 0.01171875, 0.029296875, 0.11328125, 0.08203125, 0.005859375, 0.0, 0.03125, 0.01171875, 0.056640625, 0.03515625, 0.033203125, 0.126953125, 0.033203125, 0.021484375, 0.9296875, 0.0078125, 0.94140625, 0.9765625, 0.013671875, 0.041015625, 0.05078125, 0.015625, 0.0078125, 0.09375, 0.09375, 0.07421875, 0.5625, 0.0234375, 0.037109375, 0.8984375, 0.03125, 0.009765625, 0.416015625, 0.037109375, 0.107421875, 0.064453125, 0.08984375, 0.03515625, 0.068359375, 0.099609375, 0.99609375, 0.013671875, 0.892578125, 0.015625, 0.693359375, 0.02734375, 0.021484375, 0.025390625, 0.048828125, 0.1953125, 0.896484375, 0.025390625, 0.01953125, 0.041015625, 0.013671875, 0.0234375, 0.005859375, 0.9140625, 0.0390625, 0.06640625, 0.013671875, 0.8828125, 0.984375, 0.8671875, 0.1171875, 0.015625, 0.01953125, 0.994140625, 0.7734375, 0.05078125, 0.125, 0.048828125, 0.125, 0.1015625, 0.0390625, 0.09765625, 0.068359375, 0.021484375, 0.0234375, 0.01171875, 0.140625, 0.015625, 0.08203125, 0.677734375, 0.994140625, 0.03125, 0.9765625, 0.01171875, 0.013671875, 0.91015625, 0.095703125, 0.1484375, 0.01171875, 0.994140625, 0.021484375, 0.01953125, 0.03125, 0.025390625, 0.884765625, 0.224609375, 0.90234375, 0.90234375, 0.279296875, 0.033203125, 0.013671875, 0.99609375, 0.99609375, 0.8828125, 0.0, 0.16015625, 0.021484375, 0.080078125, 0.7578125, 0.0625, 0.044921875, 0.029296875, 0.017578125, 0.908203125, 0.080078125, 0.02734375, 0.005859375, 0.181640625, 0.638671875, 0.033203125, 0.0546875, 0.005859375, 0.017578125, 0.84765625, 0.0234375, 0.0234375, 0.01953125, 0.001953125, 0.05078125, 0.005859375, 0.01953125, 0.03515625, 0.021484375, 0.900390625, 0.01171875, 0.021484375, 0.072265625, 0.03125, 0.01953125, 0.037109375, 0.0, 0.0234375, 0.0, 0.015625, 0.060546875, 0.01171875, 0.04296875, 0.18359375, 0.14453125, 0.107421875, 0.208984375, 0.912109375, 0.083984375, 0.08203125, 0.34375, 0.060546875, 0.0859375, 0.005859375, 0.203125, 0.056640625, 0.046875, 0.03515625, 0.53515625, 0.095703125, 0.01953125, 0.037109375, 0.02734375, 0.013671875, 0.033203125, 0.009765625, 0.033203125, 0.009765625, 0.873046875, 0.01953125, 0.865234375, 0.041015625, 0.0234375, 0.03515625, 0.05859375, 0.015625, 0.87109375, 0.01953125, 0.95703125, 0.01953125, 0.0546875, 0.0703125, 0.017578125, 0.90625, 0.0390625, 0.037109375, 0.1640625, 0.7734375, 0.0078125, 0.02734375, 0.037109375, 0.123046875, 0.0859375, 0.0, 0.021484375, 0.03125, 0.037109375, 0.0859375, 0.583984375, 0.0390625, 0.078125, 0.255859375, 0.029296875, 0.998046875, 0.0078125, 0.021484375, 0.0, 0.005859375, 0.99609375, 0.70703125, 0.90234375, 0.025390625, 0.02734375, 0.05078125, 0.064453125, 0.02734375, 0.005859375, 0.0546875, 0.056640625, 0.15234375, 0.029296875, 0.029296875, 0.025390625, 0.056640625, 0.013671875, 0.0546875, 0.22265625, 0.044921875, 0.044921875, 0.310546875, 0.0625, 0.01171875, 0.02734375, 0.0078125, 0.880859375, 0.865234375, 0.029296875, 0.021484375, 0.01171875, 0.015625, 0.015625, 0.0234375, 0.13671875, 0.0, 0.009765625, 0.001953125, 0.005859375, 0.19140625, 0.123046875, 0.048828125, 0.015625, 0.03515625, 0.04296875, 0.009765625, 0.025390625, 0.037109375, 0.248046875, 0.998046875, 0.025390625, 0.029296875, 0.875, 0.009765625, 0.748046875, 0.123046875, 0.876953125, 0.677734375, 0.0, 0.02734375, 0.080078125, 0.01171875, 0.021484375, 0.03125, 0.095703125, 0.025390625, 0.001953125, 0.048828125, 0.1015625, 0.041015625, 0.068359375, 0.56640625, 0.01171875, 0.033203125, 0.642578125, 0.017578125, 0.103515625, 0.01953125, 0.029296875, 0.021484375, 0.0078125, 0.017578125, 0.041015625, 0.09765625, 0.025390625, 0.005859375, 0.994140625, 0.875, 0.021484375, 0.015625, 0.015625, 0.041015625, 0.109375, 0.029296875, 0.02734375, 0.013671875, 0.634765625, 0.0078125, 0.00390625, 0.0234375, 0.93359375, 0.05078125, 0.92578125, 0.19140625, 0.109375, 0.064453125, 0.99609375, 0.708984375, 0.0390625, 0.03515625, 0.138671875, 0.890625, 0.099609375, 0.87890625, 0.072265625, 0.9140625, 0.015625, 0.083984375, 0.01953125, 0.142578125, 0.021484375, 0.099609375, 0.009765625, 0.0703125, 0.03515625, 0.005859375, 0.99609375, 0.09375, 0.025390625, 0.810546875, 0.013671875, 0.8984375, 0.0, 0.994140625, 0.044921875, 0.80078125, 0.021484375, 0.02734375, 0.017578125, 0.015625, 0.650390625, 0.041015625, 0.005859375, 0.150390625, 0.076171875, 0.890625, 0.029296875, 0.015625, 0.876953125, 0.00390625, 0.02734375, 0.0, 0.046875, 0.03125, 0.029296875, 0.12109375, 0.080078125, 0.015625, 0.01953125, 0.013671875, 0.0234375, 0.076171875, 0.740234375, 0.08984375, 0.37890625, 0.0390625, 0.99609375, 0.021484375, 0.044921875, 0.994140625, 0.740234375, 0.013671875, 0.064453125, 0.03125, 0.025390625, 0.0078125, 0.99609375, 0.013671875, 0.908203125, 0.0, 0.001953125, 0.037109375, 0.017578125, 0.869140625, 0.06640625, 0.015625, 0.029296875, 0.0, 0.044921875, 0.529296875, 0.013671875, 0.62890625, 0.0390625, 0.015625, 0.02734375, 0.99609375, 0.029296875, 0.09375, 0.037109375, 0.03125, 0.041015625, 0.00390625, 0.015625, 0.0390625, 0.05078125, 0.837890625, 0.1484375, 0.029296875, 0.99609375, 0.013671875, 0.27734375, 0.193359375, 0.904296875, 0.021484375, 0.005859375, 0.01953125, 0.99609375, 0.90234375, 0.05859375, 0.025390625, 0.2421875, 0.03125, 0.99609375, 0.03125, 0.015625, 0.005859375, 0.2109375, 0.044921875, 0.8828125, 0.0234375, 0.046875, 0.033203125, 0.046875, 0.99609375, 0.041015625, 0.0390625, 0.02734375, 0.0, 0.009765625, 0.029296875, 0.853515625, 0.03515625, 0.107421875, 0.99609375, 0.138671875, 0.03125, 0.03515625, 0.017578125, 0.017578125, 0.021484375, 0.853515625, 0.033203125, 0.99609375, 0.091796875, 0.01171875, 0.03125, 0.126953125, 0.00390625, 0.021484375, 0.01171875, 0.552734375, 0.0234375, 0.009765625, 0.1015625, 0.8671875, 0.080078125, 0.0234375, 0.892578125, 0.998046875, 0.0078125, 0.818359375, 0.025390625, 0.859375, 0.935546875, 0.078125, 0.044921875, 0.09375, 0.033203125, 0.0234375, 0.943359375, 0.001953125, 0.291015625, 0.068359375, 0.083984375, 0.017578125, 0.064453125, 0.021484375, 0.6328125, 0.900390625, 0.076171875, 0.048828125, 0.04296875, 0.0234375, 0.962890625, 0.1328125, 0.943359375, 0.033203125, 0.03515625, 0.013671875, 0.15234375, 0.0234375, 0.267578125, 0.029296875, 0.03125, 0.10546875, 0.767578125, 0.044921875, 0.025390625, 0.99609375, 0.1484375, 0.04296875, 0.111328125, 0.15234375, 0.021484375, 0.02734375, 0.017578125, 0.365234375, 0.04296875, 0.017578125, 0.013671875, 0.013671875, 0.03125, 0.00390625, 0.033203125, 0.02734375, 0.091796875, 0.013671875, 0.029296875, 0.021484375, 0.48828125, 0.0, 0.095703125, 0.033203125, 0.05078125, 0.048828125, 0.046875, 0.029296875, 0.08984375, 0.994140625, 0.080078125, 0.818359375, 0.689453125, 0.02734375, 0.130859375, 0.01171875, 0.888671875, 0.025390625, 0.013671875, 0.04296875, 0.095703125, 0.0546875, 0.046875, 0.041015625, 0.89453125, 0.025390625, 0.021484375, 0.138671875, 0.0390625, 0.0234375, 0.94140625, 0.0, 0.044921875, 0.931640625, 0.01953125, 0.263671875, 0.021484375, 0.03515625, 0.04296875, 0.052734375, 0.013671875, 0.9375, 0.009765625, 0.0078125, 0.041015625, 0.01171875, 0.0078125, 0.048828125, 0.02734375, 0.93359375, 0.080078125, 0.021484375, 0.02734375, 0.87109375, 0.013671875, 0.046875, 0.171875, 0.033203125, 0.056640625, 0.01171875, 0.046875, 0.025390625, 0.087890625, 0.021484375, 0.9921875, 0.908203125, 0.099609375, 0.8671875, 0.56640625, 0.0234375, 0.04296875, 0.28515625, 0.06640625, 0.025390625, 0.806640625, 0.2421875, 0.859375, 0.76953125, 0.015625, 0.04296875, 0.91015625, 0.1171875, 0.029296875, 0.931640625, 0.853515625, 0.046875, 0.00390625, 0.0, 0.66796875, 0.01953125, 0.025390625, 0.029296875, 0.041015625, 0.029296875, 0.041015625, 0.09375, 0.02734375, 0.6015625, 0.994140625, 0.0859375, 0.060546875, 0.05078125, 0.029296875, 0.994140625, 0.029296875, 0.03125, 0.005859375, 0.033203125, 0.0234375, 0.0390625, 0.01953125, 0.0390625, 0.189453125, 0.123046875, 0.015625, 0.91796875, 0.9140625, 0.0234375, 0.044921875, 0.951171875, 0.99609375, 0.099609375, 0.060546875, 0.044921875, 0.994140625, 0.025390625, 0.0234375, 0.076171875, 0.009765625, 0.99609375, 0.99609375, 0.916015625, 0.01171875, 0.111328125, 0.89453125, 0.01953125, 0.0234375, 0.908203125, 0.08203125, 0.025390625, 0.046875, 0.01953125, 0.017578125, 0.01953125, 0.021484375, 0.55078125, 0.0078125, 0.75, 0.52734375, 0.0234375, 0.02734375, 0.0234375, 0.009765625, 0.0, 0.02734375, 0.021484375, 0.119140625, 0.01953125, 0.0234375, 0.888671875, 0.8984375, 0.03125, 0.009765625, 0.015625, 0.01953125, 0.84765625, 0.130859375, 0.015625, 0.015625, 0.587890625, 0.072265625, 0.025390625, 0.041015625, 0.84375, 0.0234375, 0.0234375, 0.033203125, 0.876953125, 0.04296875, 0.009765625, 0.080078125, 0.02734375, 0.02734375, 0.99609375, 0.009765625, 0.03515625, 0.01953125, 0.083984375, 0.109375, 0.0546875, 0.353515625, 0.060546875, 0.99609375, 0.203125, 0.037109375, 0.0703125, 0.05078125, 0.0859375, 0.068359375, 0.056640625, 0.1015625, 0.044921875, 0.044921875, 0.060546875, 0.03125, 0.01171875, 0.087890625, 0.017578125, 0.013671875, 0.001953125, 0.005859375, 0.078125, 0.041015625, 0.064453125, 0.021484375, 0.044921875, 0.685546875, 0.04296875, 0.24609375, 0.208984375, 0.021484375, 0.0625, 0.02734375, 0.048828125, 0.0234375, 0.919921875, 0.03125, 0.02734375, 0.4375, 0.025390625, 0.10546875, 0.310546875, 0.080078125, 0.134765625, 0.5859375, 0.013671875, 0.203125, 0.11328125, 0.0078125, 0.005859375, 0.865234375, 0.025390625, 0.8671875, 0.919921875, 0.98046875, 0.021484375, 0.0390625, 0.99609375, 0.001953125, 0.041015625, 0.005859375, 0.005859375, 0.025390625, 0.041015625, 0.23828125, 0.029296875, 0.09375, 0.0390625, 0.01171875, 0.0, 0.103515625, 0.078125, 0.01953125, 0.169921875, 0.015625, 0.005859375, 0.84765625, 0.865234375, 0.1328125, 0.0390625, 0.03515625, 0.017578125, 0.080078125, 0.91796875, 0.021484375, 0.017578125, 0.041015625, 0.0, 0.0546875, 0.724609375, 0.111328125, 0.017578125, 0.89453125, 0.99609375, 0.021484375, 0.029296875, 0.99609375, 0.90234375, 0.029296875, 0.005859375, 0.203125, 0.109375, 0.65234375, 0.23046875, 0.033203125, 0.908203125, 0.84375, 0.025390625, 0.044921875, 0.009765625, 0.00390625, 0.90625, 0.076171875, 0.044921875, 0.060546875, 0.033203125, 0.0234375, 0.091796875, 0.2734375, 0.0625, 0.13671875, 0.072265625, 0.001953125, 0.04296875, 0.4296875, 0.072265625, 0.076171875, 0.046875, 0.087890625, 0.0546875, 0.099609375, 0.033203125, 0.642578125, 0.0234375, 0.87109375, 0.0390625, 0.029296875, 0.58203125, 0.123046875, 0.34765625, 0.00390625, 0.01953125, 0.140625, 0.921875, 0.025390625, 0.078125, 0.017578125, 0.904296875, 0.0234375, 0.048828125, 0.021484375, 0.07421875, 0.876953125, 0.0390625, 0.931640625, 0.8984375, 0.017578125, 0.044921875, 0.0234375, 0.017578125, 0.037109375, 0.080078125, 0.03515625, 0.046875, 0.0078125, 0.033203125, 0.0234375, 0.04296875, 0.01953125, 0.041015625, 0.0625, 0.0703125, 0.025390625, 0.173828125, 0.021484375, 0.00390625, 0.01953125, 0.029296875, 0.080078125, 0.0390625, 0.017578125, 0.0390625, 0.046875, 0.09765625, 0.017578125, 0.01953125, 0.06640625, 0.99609375, 0.04296875, 0.87890625, 0.580078125, 0.869140625, 0.013671875, 0.994140625, 0.90234375, 0.822265625, 0.740234375, 0.03125, 0.056640625, 0.025390625, 0.0390625, 0.04296875, 0.966796875, 0.8515625, 0.107421875, 0.970703125, 0.03515625, 0.0703125, 0.029296875, 0.8671875, 0.06640625, 0.06640625, 0.908203125, 0.30078125, 0.99609375, 0.193359375, 0.541015625, 0.087890625, 0.017578125, 0.015625, 0.03125, 0.033203125, 0.0859375, 0.005859375, 0.013671875, 0.013671875, 0.85546875, 0.02734375, 0.046875, 0.99609375, 0.2578125, 0.017578125, 0.107421875, 0.0234375, 0.15625, 0.017578125, 0.041015625, 0.017578125, 0.099609375, 0.03515625, 0.021484375, 0.998046875, 0.0078125, 0.109375, 0.017578125, 0.00390625, 0.021484375, 0.91015625, 0.02734375, 0.060546875, 0.064453125, 0.033203125, 0.02734375, 0.998046875, 0.060546875, 0.01171875, 0.99609375, 0.01171875, 0.99609375, 0.021484375, 0.994140625, 0.072265625, 0.873046875, 0.04296875, 0.013671875, 0.01171875, 0.017578125, 0.154296875, 0.185546875, 0.693359375, 0.12890625, 0.025390625, 0.025390625, 0.01953125, 0.068359375, 0.001953125, 0.775390625, 0.015625, 0.017578125, 0.1015625, 0.123046875, 0.01953125, 0.02734375, 0.0234375, 0.037109375, 0.099609375, 0.12890625, 0.04296875, 0.001953125, 0.025390625, 0.046875, 0.900390625, 0.953125, 0.7109375, 0.1015625, 0.0078125, 0.921875, 0.05859375, 0.037109375, 0.99609375, 0.05859375, 0.015625, 0.001953125, 0.08984375, 0.03515625, 0.025390625, 0.017578125, 0.224609375, 0.03125, 0.009765625, 0.12890625, 0.00390625, 0.076171875, 0.017578125, 0.01953125, 0.27734375, 0.06640625, 0.75, 0.091796875, 0.0, 0.99609375, 0.015625, 0.048828125, 0.02734375, 0.994140625, 0.873046875, 0.017578125, 0.892578125, 0.033203125, 0.0234375, 0.041015625, 0.00390625, 0.994140625, 0.01953125, 0.86328125, 0.2421875, 0.271484375, 0.060546875, 0.892578125, 0.955078125, 0.9453125, 0.029296875, 0.08984375, 0.955078125, 0.033203125, 0.919921875, 0.171875, 0.044921875, 0.896484375, 0.03515625, 0.02734375, 0.00390625, 0.994140625, 0.017578125, 0.05859375, 0.91796875, 0.013671875, 0.17578125, 0.994140625, 0.033203125, 0.904296875, 0.0390625, 0.99609375, 0.787109375, 0.068359375, 0.0234375, 0.0234375, 0.892578125, 0.189453125, 0.935546875, 0.060546875, 0.056640625, 0.013671875, 0.064453125, 0.02734375, 0.03515625, 0.033203125, 0.09375, 0.03125, 0.994140625, 0.0390625, 0.00390625, 0.046875, 0.06640625, 0.078125, 0.06640625, 0.005859375, 0.791015625, 0.943359375, 0.021484375, 0.017578125, 0.958984375, 0.021484375, 0.033203125, 0.951171875, 0.0546875, 0.087890625, 0.0, 0.01171875, 0.025390625, 0.068359375, 0.04296875, 0.99609375, 0.763671875, 0.033203125, 0.005859375, 0.080078125, 0.03125, 0.79296875, 0.037109375, 0.01171875, 0.01953125, 0.994140625, 0.01953125, 0.064453125, 0.111328125, 0.99609375, 0.05078125, 0.041015625, 0.001953125, 0.150390625, 0.0859375, 0.01953125, 0.677734375, 0.015625, 0.8828125, 0.017578125, 0.025390625, 0.013671875, 0.037109375, 0.044921875, 0.01953125, 0.03125, 0.158203125, 0.044921875, 0.017578125, 0.671875, 0.076171875, 0.828125, 0.0390625, 0.015625, 0.037109375, 0.087890625, 0.017578125, 0.955078125, 0.001953125, 0.046875, 0.046875, 0.025390625, 0.029296875, 0.056640625, 0.05859375, 0.01953125, 0.03125, 0.998046875, 0.994140625, 0.041015625, 0.01953125, 0.005859375, 0.0390625, 0.029296875, 0.0078125, 0.037109375, 0.884765625, 0.99609375, 0.04296875, 0.07421875, 0.03125, 0.001953125, 0.16796875, 0.013671875, 0.041015625, 0.017578125, 0.021484375, 0.037109375, 0.064453125, 0.017578125, 0.02734375, 0.994140625, 0.013671875, 0.314453125, 0.0234375, 0.896484375, 0.11328125, 0.169921875, 0.0, 0.025390625, 0.83984375, 0.8359375, 0.0625, 0.19140625, 0.0234375, 0.041015625, 0.052734375, 0.109375, 0.017578125, 0.0234375, 0.03125, 0.998046875, 0.16015625, 0.0, 0.0625, 0.11328125, 0.037109375, 0.646484375, 0.87109375, 0.01171875, 0.029296875, 0.0078125, 0.015625, 0.0234375, 0.212890625, 0.0078125, 0.060546875, 0.994140625, 0.07421875, 0.080078125, 0.029296875, 0.0234375, 0.087890625, 0.029296875, 0.06640625, 0.943359375, 0.009765625, 0.05859375, 0.0078125, 0.04296875, 0.15234375, 0.01953125, 0.037109375, 0.0703125, 0.04296875, 0.060546875, 0.021484375, 0.017578125, 0.890625, 0.1015625, 0.0859375, 0.880859375, 0.0, 0.123046875, 0.005859375, 0.1171875, 0.0625, 0.01953125, 0.876953125, 0.029296875, 0.017578125, 0.0625, 0.134765625, 0.09765625, 0.099609375, 0.029296875, 0.056640625, 0.0390625, 0.103515625, 0.021484375, 0.033203125, 0.12109375, 0.02734375, 0.037109375, 0.96484375, 0.123046875, 0.015625, 0.0390625, 0.01953125, 0.0859375, 0.30078125, 0.125, 0.974609375, 0.0234375, 0.91015625, 0.03125, 0.69921875, 0.03515625, 0.251953125, 0.025390625, 0.001953125, 0.05859375, 0.02734375, 0.078125, 0.01171875, 0.896484375, 0.0625, 0.0234375, 0.4453125, 0.1953125, 0.017578125, 0.9453125, 0.599609375, 0.99609375, 0.015625, 0.02734375, 0.0, 0.013671875, 0.998046875, 0.16796875, 0.615234375, 0.052734375, 0.001953125, 0.228515625, 0.033203125, 0.025390625, 0.009765625, 0.033203125, 0.04296875, 0.0234375, 0.0, 0.0234375, 0.888671875]

 sparsity of   [0.109375, 0.0009765625, 0.00390625, 0.6669921875, 0.0009765625, 0.8251953125, 0.0048828125, 0.005859375, 0.0791015625, 0.220703125, 0.076171875, 0.0146484375, 0.0380859375, 0.03125, 0.0078125, 0.6435546875, 0.0087890625, 0.1142578125, 0.0087890625, 0.048828125, 0.0224609375, 0.94921875, 0.0029296875, 0.0009765625, 0.0087890625, 0.037109375, 0.380859375, 0.0419921875, 0.08203125, 0.3798828125, 0.0224609375, 0.1142578125, 0.0283203125, 0.0498046875, 0.0, 0.00390625, 0.005859375, 0.2470703125, 0.091796875, 0.009765625, 0.1416015625, 0.00390625, 0.005859375, 0.0, 0.7216796875, 0.03125, 0.0283203125, 0.0634765625, 0.05859375, 0.0537109375, 0.0302734375, 0.013671875, 0.0166015625, 0.935546875, 0.99609375, 0.001953125, 0.0224609375, 0.0048828125, 0.0703125, 0.00390625, 0.275390625, 0.03125, 0.12109375, 0.0048828125, 0.06640625, 0.0078125, 0.0107421875, 0.07421875, 0.0185546875, 0.1025390625, 0.02734375, 0.0078125, 0.0087890625, 0.1083984375, 0.50390625, 0.01171875, 0.1025390625, 0.029296875, 0.181640625, 0.0556640625, 0.00390625, 0.0107421875, 0.0, 0.03125, 0.1630859375, 0.076171875, 0.0244140625, 0.0654296875, 0.8349609375, 0.0771484375, 0.0771484375, 0.0302734375, 0.9296875, 0.0029296875, 0.0224609375, 0.0048828125, 0.2578125, 0.0224609375, 0.0087890625, 0.0361328125, 0.001953125, 0.0654296875, 0.0009765625, 0.0888671875, 0.001953125, 0.0107421875, 0.0859375, 0.708984375, 0.0205078125, 0.146484375, 0.03125, 0.9658203125, 0.03125, 0.9345703125, 0.80078125, 0.6923828125, 0.0, 0.005859375, 0.1044921875, 0.0546875, 0.326171875, 0.0869140625, 0.00390625, 0.021484375, 0.3271484375, 0.0595703125, 0.2861328125, 0.7451171875, 0.5556640625, 0.005859375, 0.0126953125, 0.0771484375, 0.00390625, 0.017578125, 0.1611328125, 0.0, 0.048828125, 0.00390625, 0.00390625, 0.0517578125, 0.0771484375, 0.0576171875, 0.0869140625, 0.1572265625, 0.0205078125, 0.00390625, 0.0439453125, 0.0859375, 0.05078125, 0.8115234375, 0.0390625, 0.0, 0.0859375, 0.1650390625, 0.0537109375, 0.0537109375, 0.03125, 0.947265625, 0.0087890625, 0.044921875, 0.0556640625, 0.08203125, 0.091796875, 0.6962890625, 0.0009765625, 0.01953125, 0.0068359375, 0.033203125, 0.2333984375, 0.0771484375, 0.10546875, 0.9970703125, 0.8544921875, 0.017578125, 0.0576171875, 0.0029296875, 0.6201171875, 0.0732421875, 0.0458984375, 0.0283203125, 0.0595703125, 0.0546875, 0.02734375, 0.583984375, 0.076171875, 0.1318359375, 0.0322265625, 0.3203125, 0.4208984375, 0.0126953125, 0.8583984375, 0.0439453125, 0.0673828125, 0.0869140625, 0.009765625, 0.6318359375, 0.056640625, 0.033203125, 0.080078125, 0.943359375, 0.7880859375, 0.041015625, 0.04296875, 0.001953125, 0.0087890625, 0.560546875, 0.134765625, 0.1220703125, 0.0078125, 0.021484375, 0.0, 0.0341796875, 0.0673828125, 0.00390625, 0.953125, 0.0078125, 0.0498046875, 0.052734375, 0.013671875, 0.0859375, 0.1005859375, 0.6474609375, 0.0087890625, 0.0078125, 0.0703125, 0.9970703125, 0.07421875, 0.0146484375, 0.080078125, 0.01953125, 0.0029296875, 0.0732421875, 0.046875, 0.0673828125, 0.0419921875, 0.0185546875, 0.0537109375, 0.9970703125, 0.0029296875, 0.0126953125, 0.0107421875, 0.00390625, 0.029296875, 0.005859375, 0.546875, 0.0029296875, 0.0009765625, 0.0, 0.015625, 0.0029296875, 0.001953125, 0.08984375, 0.0126953125, 0.072265625, 0.021484375, 0.0, 0.3310546875, 0.068359375, 0.029296875, 0.0, 0.013671875, 0.025390625, 0.1279296875, 0.9970703125, 0.017578125, 0.0234375, 0.5595703125, 0.0166015625, 0.046875, 0.0185546875, 0.0048828125, 0.021484375, 0.0, 0.0703125, 0.0546875, 0.021484375, 0.001953125, 0.0048828125, 0.2216796875, 0.0048828125, 0.9970703125, 0.001953125, 0.02734375, 0.8359375, 0.0166015625, 0.0, 0.0048828125, 0.0048828125, 0.0, 0.091796875, 0.025390625, 0.068359375, 0.0068359375, 0.0419921875, 0.0791015625, 0.9296875, 0.0712890625, 0.2119140625, 0.01171875, 0.037109375, 0.1484375, 0.001953125, 0.02734375, 0.01953125, 0.0634765625, 0.1123046875, 0.078125, 0.3505859375, 0.083984375, 0.0009765625, 0.3076171875, 0.029296875, 0.0107421875, 0.0185546875, 0.1376953125, 0.0078125, 0.0009765625, 0.0185546875, 0.015625, 0.1240234375, 0.0595703125, 0.0693359375, 0.099609375, 0.23828125, 0.84765625, 0.009765625, 0.2783203125, 0.0283203125, 0.0751953125, 0.0048828125, 0.1796875, 0.0234375, 0.3310546875, 0.0751953125, 0.013671875, 0.95703125, 0.115234375, 0.1318359375, 0.0302734375, 0.01953125, 0.9736328125, 0.048828125, 0.0888671875, 0.0, 0.0, 0.087890625, 0.0029296875, 0.033203125, 0.138671875, 0.103515625, 0.466796875, 0.017578125, 0.0205078125, 0.0048828125, 0.0322265625, 0.01953125, 0.107421875, 0.1015625, 0.0048828125, 0.0009765625, 0.31640625, 0.0107421875, 0.1044921875, 0.01953125, 0.9365234375, 0.0029296875, 0.0361328125, 0.03515625, 0.037109375, 0.0341796875, 0.0185546875, 0.0087890625, 0.779296875, 0.0283203125, 0.064453125, 0.2216796875, 0.0009765625, 0.0498046875, 0.0634765625, 0.9970703125, 0.0751953125, 0.005859375, 0.04296875, 0.009765625, 0.080078125, 0.126953125, 0.01953125, 0.0400390625, 0.0, 0.7578125, 0.1171875, 0.9072265625, 0.080078125, 0.0068359375, 0.1357421875, 0.869140625, 0.056640625, 0.017578125, 0.01171875, 0.0029296875, 0.8056640625, 0.00390625, 0.0712890625, 0.0537109375, 0.927734375, 0.4638671875, 0.0205078125, 0.0078125, 0.005859375, 0.2080078125, 0.9150390625, 0.0615234375, 0.048828125, 0.1240234375, 0.1494140625, 0.845703125, 0.802734375, 0.0791015625, 0.013671875, 0.04296875, 0.009765625, 0.751953125, 0.7998046875, 0.0771484375, 0.0107421875, 0.001953125, 0.9267578125, 0.0107421875, 0.0244140625, 0.0693359375, 0.0009765625, 0.9970703125, 0.1201171875, 0.0771484375, 0.3251953125, 0.037109375, 0.0126953125, 0.173828125, 0.02734375, 0.0068359375, 0.00390625, 0.021484375, 0.009765625, 0.083984375, 0.0087890625, 0.6533203125, 0.998046875, 0.060546875, 0.083984375, 0.041015625, 0.0283203125, 0.025390625, 0.0244140625, 0.001953125, 0.001953125, 0.0224609375, 0.021484375, 0.025390625, 0.0078125, 0.9306640625, 0.0166015625, 0.0205078125, 0.111328125, 0.04296875, 0.0771484375, 0.2109375, 0.001953125, 0.2265625, 0.046875, 0.7919921875, 0.091796875, 0.0, 0.8310546875, 0.9658203125, 0.03515625, 0.0048828125, 0.06640625, 0.1103515625, 0.0, 0.0, 0.998046875, 0.0712890625, 0.119140625, 0.2861328125, 0.021484375, 0.0478515625, 0.0576171875, 0.9990234375, 0.0009765625, 0.001953125, 0.001953125, 0.9990234375, 0.1484375, 0.119140625, 0.021484375, 0.9296875, 0.0, 0.0107421875, 0.1142578125, 0.8974609375, 0.041015625, 0.0048828125, 0.0791015625, 0.173828125, 0.0322265625, 0.0361328125, 0.0927734375, 0.029296875, 0.0732421875, 0.001953125, 0.0068359375, 0.2802734375, 0.083984375, 0.0390625, 0.025390625, 0.568359375, 0.0263671875, 0.01953125, 0.001953125, 0.0, 0.0751953125, 0.00390625, 0.9970703125, 0.009765625, 0.0126953125, 0.146484375, 0.0205078125, 0.9365234375, 0.9970703125, 0.052734375, 0.7646484375, 0.0048828125, 0.015625, 0.01953125, 0.0244140625, 0.009765625, 0.267578125, 0.0556640625, 0.0, 0.20703125, 0.9990234375, 0.04296875, 0.0908203125, 0.005859375, 0.0, 0.03515625, 0.0341796875, 0.0556640625, 0.1171875, 0.0244140625, 0.2353515625, 0.0029296875, 0.0732421875, 0.154296875, 0.0029296875, 0.013671875, 0.9453125, 0.0068359375, 0.080078125, 0.0478515625, 0.033203125, 0.0029296875, 0.0029296875, 0.021484375, 0.087890625, 0.0009765625, 0.0166015625, 0.0615234375, 0.0205078125, 0.162109375, 0.001953125, 0.0537109375, 0.0107421875, 0.0029296875, 0.13671875, 0.0, 0.091796875, 0.0791015625, 0.0380859375, 0.0419921875, 0.0576171875, 0.0048828125, 0.087890625, 0.91796875, 0.0126953125, 0.029296875, 0.0, 0.001953125, 0.03515625, 0.0029296875, 0.0400390625, 0.033203125, 0.0498046875, 0.8427734375, 0.0458984375, 0.0400390625, 0.0107421875, 0.0009765625, 0.0869140625, 0.1015625, 0.02734375, 0.0673828125, 0.9326171875, 0.0068359375, 0.0341796875, 0.0068359375, 0.01171875, 0.0537109375, 0.017578125, 0.0009765625, 0.005859375, 0.005859375, 0.0107421875, 0.0087890625, 0.00390625, 0.0, 0.0, 0.05859375, 0.05078125, 0.0791015625, 0.0244140625, 0.1337890625, 0.0341796875, 0.0703125, 0.0947265625, 0.1083984375, 0.2958984375, 0.021484375, 0.029296875, 0.0546875, 0.0849609375, 0.275390625, 0.34765625, 0.02734375, 0.005859375, 0.001953125, 0.015625, 0.056640625, 0.0478515625, 0.0244140625, 0.0810546875, 0.0791015625, 0.015625, 0.5048828125, 0.0078125, 0.005859375, 0.03515625, 0.2177734375, 0.9521484375, 0.0, 0.0400390625, 0.666015625, 0.1015625, 0.025390625, 0.0078125, 0.955078125, 0.0107421875, 0.9150390625, 0.015625, 0.0185546875, 0.0244140625, 0.0732421875, 0.87109375, 0.033203125, 0.087890625, 0.0, 0.0400390625, 0.1708984375, 0.001953125, 0.0078125, 0.1064453125, 0.0107421875, 0.9970703125, 0.0107421875, 0.078125, 0.0078125, 0.7158203125, 0.9365234375, 0.00390625, 0.0068359375, 0.09375, 0.021484375, 0.0361328125, 0.037109375, 0.005859375, 0.658203125, 0.0947265625, 0.576171875, 0.142578125, 0.9111328125, 0.0517578125, 0.998046875, 0.0361328125, 0.169921875, 0.0283203125, 0.2373046875, 0.037109375, 0.001953125, 0.005859375, 0.9970703125, 0.9970703125, 0.0849609375, 0.0380859375, 0.9033203125, 0.3203125, 0.85546875, 0.0302734375, 0.0400390625, 0.0048828125, 0.0439453125, 0.0244140625, 0.01953125, 0.1025390625, 0.0224609375, 0.00390625, 0.015625, 0.013671875, 0.9970703125, 0.01171875, 0.3505859375, 0.0634765625, 0.8203125, 0.744140625, 0.26953125, 0.0048828125, 0.05078125, 0.10546875, 0.1591796875, 0.107421875, 0.787109375, 0.52734375, 0.140625, 0.0244140625, 0.029296875, 0.9599609375, 0.0537109375, 0.0458984375, 0.0009765625, 0.9970703125, 0.9990234375, 0.552734375, 0.0361328125, 0.005859375, 0.0107421875, 0.1396484375, 0.9990234375, 0.0068359375, 0.0390625, 0.142578125, 0.0361328125, 0.00390625, 0.0107421875, 0.009765625, 0.072265625, 0.107421875, 0.037109375, 0.0703125, 0.02734375, 0.0029296875, 0.869140625, 0.8134765625, 0.072265625, 0.0, 0.73046875, 0.0458984375, 0.0732421875, 0.037109375, 0.02734375, 0.064453125, 0.0419921875, 0.0146484375, 0.001953125, 0.0009765625, 0.2734375, 0.0087890625, 0.025390625, 0.0, 0.9970703125, 0.099609375, 0.0068359375, 0.16015625, 0.0146484375, 0.1298828125, 0.00390625, 0.98828125, 0.02734375, 0.0029296875, 0.041015625, 0.81640625, 0.076171875, 0.00390625, 0.001953125, 0.017578125, 0.0107421875, 0.021484375, 0.0224609375, 0.873046875, 0.9521484375, 0.1279296875, 0.0771484375, 0.0283203125, 0.0, 0.91796875, 0.0615234375, 0.08984375, 0.013671875, 0.0, 0.103515625, 0.9970703125, 0.0048828125, 0.0048828125, 0.0068359375, 0.9970703125, 0.00390625, 0.46484375, 0.1650390625, 0.0185546875, 0.00390625, 0.005859375, 0.041015625, 0.2529296875, 0.03125, 0.0703125, 0.9970703125, 0.01171875, 0.0078125, 0.00390625, 0.0185546875, 0.0048828125, 0.0888671875, 0.03125, 0.0166015625, 0.044921875, 0.0048828125, 0.9453125, 0.9736328125, 0.001953125, 0.9970703125, 0.029296875, 0.08203125, 0.0107421875, 0.962890625, 0.0341796875, 0.0830078125, 0.544921875, 0.2099609375, 0.0126953125, 0.00390625, 0.001953125, 0.0693359375, 0.0068359375, 0.0, 0.0966796875, 0.0009765625, 0.0673828125, 0.0078125, 0.28125, 0.0029296875, 0.0166015625, 0.01953125, 0.1494140625, 0.7470703125, 0.072265625, 0.0654296875, 0.0, 0.12890625, 0.3310546875, 0.91015625, 0.0419921875, 0.0087890625, 0.0009765625, 0.0029296875, 0.00390625, 0.0078125, 0.00390625, 0.0048828125, 0.9970703125, 0.005859375, 0.005859375, 0.0244140625, 0.0, 0.0009765625, 0.0244140625, 0.0556640625, 0.0576171875, 0.02734375, 0.056640625, 0.65625, 0.0009765625, 0.0771484375, 0.005859375, 0.0, 0.0029296875, 0.013671875, 0.080078125, 0.2802734375, 0.1005859375, 0.009765625, 0.0087890625, 0.03515625, 0.0673828125, 0.0, 0.998046875, 0.0205078125, 0.0361328125, 0.044921875, 0.544921875, 0.0126953125, 0.251953125, 0.1103515625, 0.005859375, 0.0341796875, 0.072265625, 0.169921875, 0.005859375, 0.0703125, 0.1328125, 0.0361328125, 0.2021484375, 0.0087890625, 0.02734375, 0.0068359375, 0.0126953125, 0.0615234375, 0.2490234375, 0.0068359375, 0.009765625, 0.0009765625, 0.005859375, 0.00390625, 0.1201171875, 0.001953125, 0.00390625, 0.0068359375, 0.0654296875, 0.06640625, 0.3515625, 0.0048828125, 0.0498046875, 0.005859375, 0.005859375, 0.169921875, 0.009765625, 0.171875, 0.0205078125, 0.181640625, 0.060546875, 0.013671875, 0.0283203125, 0.1875, 0.0390625, 0.0068359375, 0.009765625, 0.001953125, 0.029296875, 0.078125, 0.0185546875, 0.0244140625, 0.1455078125, 0.0087890625, 0.052734375, 0.078125, 0.0029296875, 0.0966796875, 0.0244140625, 0.171875, 0.0263671875, 0.0009765625, 0.009765625, 0.0146484375, 0.13671875, 0.0126953125, 0.0068359375, 0.0, 0.0732421875, 0.8203125, 0.0400390625, 0.0537109375, 0.0029296875, 0.025390625, 0.8515625, 0.00390625, 0.28515625, 0.5986328125, 0.74609375, 0.0087890625, 0.0927734375, 0.00390625, 0.1025390625, 0.041015625, 0.0048828125, 0.779296875, 0.0400390625, 0.93359375, 0.0869140625, 0.0556640625, 0.037109375, 0.0244140625, 0.0029296875, 0.08984375, 0.158203125, 0.7041015625, 0.021484375, 0.0302734375, 0.9970703125, 0.208984375, 0.701171875, 0.0146484375, 0.3447265625, 0.0224609375, 0.00390625, 0.0029296875, 0.9970703125, 0.1640625, 0.8994140625, 0.0078125, 0.0224609375, 0.11328125, 0.2431640625, 0.041015625, 0.087890625, 0.9501953125, 0.07421875, 0.0107421875, 0.1640625, 0.5751953125, 0.1611328125, 0.0078125, 0.037109375, 0.0087890625, 0.1337890625, 0.041015625, 0.0078125, 0.00390625, 0.111328125, 0.2919921875, 0.9365234375, 0.02734375, 0.0224609375, 0.07421875, 0.0537109375, 0.0048828125, 0.828125, 0.0, 0.0146484375, 0.71875, 0.037109375, 0.0185546875, 0.0302734375, 0.517578125, 0.0234375, 0.0234375, 0.2861328125, 0.015625, 0.1455078125, 0.009765625, 0.021484375, 0.0322265625, 0.849609375, 0.12109375, 0.015625, 0.0244140625, 0.0009765625, 0.1474609375, 0.0009765625, 0.220703125, 0.8046875, 0.0, 0.0927734375, 0.080078125, 0.0869140625, 0.0107421875, 0.0, 0.080078125, 0.1494140625, 0.94140625, 0.0029296875, 0.0048828125, 0.0087890625, 0.001953125, 0.1240234375, 0.9970703125, 0.0029296875, 0.9560546875, 0.0185546875, 0.0693359375, 0.0029296875, 0.091796875, 0.0234375, 0.0029296875, 0.0361328125, 0.0751953125, 0.078125, 0.9677734375, 0.666015625, 0.0107421875, 0.0703125, 0.009765625, 0.265625, 0.150390625, 0.0732421875, 0.1337890625, 0.5849609375, 0.0654296875, 0.1826171875, 0.0048828125, 0.001953125, 0.091796875, 0.04296875, 0.390625, 0.0849609375, 0.0166015625, 0.0263671875, 0.0302734375, 0.099609375, 0.9345703125, 0.14453125, 0.01171875, 0.0185546875, 0.052734375, 0.0283203125, 0.244140625, 0.2021484375, 0.0048828125, 0.0009765625, 0.0654296875, 0.00390625, 0.83984375, 0.0048828125, 0.142578125, 0.9990234375, 0.1435546875, 0.0888671875, 0.0625, 0.0283203125, 0.13671875, 0.93359375, 0.6025390625, 0.0009765625, 0.0029296875, 0.015625, 0.0439453125, 0.47265625, 0.0244140625, 0.2685546875, 0.0029296875, 0.06640625, 0.015625, 0.0009765625, 0.025390625, 0.0029296875, 0.56640625, 0.0166015625, 0.0244140625, 0.021484375, 0.03125, 0.826171875, 0.0830078125, 0.37109375, 0.0, 0.0390625, 0.01953125, 0.0048828125, 0.0166015625, 0.0126953125, 0.0791015625, 0.9365234375, 0.0302734375, 0.0556640625, 0.017578125, 0.8798828125, 0.0, 0.779296875, 0.068359375, 0.1181640625, 0.0458984375, 0.673828125, 0.0029296875, 0.072265625, 0.001953125, 0.234375, 0.0419921875, 0.0341796875, 0.0087890625, 0.9970703125, 0.0390625, 0.0302734375, 0.0, 0.09765625, 0.0830078125, 0.0, 0.0283203125, 0.0029296875, 0.005859375, 0.8134765625, 0.1875, 0.0166015625, 0.177734375, 0.3447265625, 0.052734375, 0.1728515625, 0.0107421875, 0.087890625, 0.84765625, 0.00390625, 0.01171875, 0.0068359375, 0.0810546875, 0.017578125, 0.0791015625, 0.1591796875, 0.009765625, 0.0927734375, 0.0654296875, 0.9970703125, 0.0654296875, 0.5859375, 0.029296875, 0.0244140625, 0.09765625, 0.1748046875, 0.205078125, 0.00390625, 0.052734375, 0.041015625, 0.9970703125, 0.015625, 0.015625, 0.0283203125, 0.0107421875, 0.0390625, 0.037109375, 0.1044921875, 0.0087890625, 0.017578125, 0.1689453125, 0.0, 0.07421875, 0.8623046875, 0.1630859375, 0.0224609375, 0.0107421875, 0.046875, 0.267578125, 0.0107421875, 0.03515625, 0.033203125, 0.048828125, 0.125, 0.013671875, 0.037109375, 0.0029296875, 0.0556640625, 0.091796875, 0.072265625, 0.091796875, 0.5283203125, 0.9970703125, 0.00390625, 0.0, 0.00390625, 0.1201171875, 0.3515625, 0.208984375, 0.015625, 0.0830078125, 0.0732421875, 0.0107421875, 0.1337890625, 0.4345703125, 0.02734375, 0.9970703125, 0.0849609375, 0.0, 0.9970703125, 0.3193359375, 0.53515625, 0.00390625, 0.0087890625, 0.9609375, 0.130859375, 0.078125, 0.0205078125, 0.6650390625, 0.0390625, 0.0087890625, 0.041015625, 0.015625, 0.013671875, 0.0048828125, 0.0322265625, 0.0, 0.0927734375, 0.0166015625, 0.1533203125, 0.875, 0.0166015625, 0.0087890625, 0.0419921875, 0.0869140625, 0.017578125, 0.0, 0.9970703125, 0.0185546875, 0.021484375, 0.01171875, 0.087890625, 0.025390625, 0.0283203125, 0.7626953125, 0.0087890625, 0.1572265625, 0.0048828125, 0.0029296875, 0.89453125, 0.599609375, 0.037109375, 0.9970703125, 0.138671875, 0.0166015625, 0.03125, 0.091796875, 0.185546875, 0.08984375, 0.0615234375, 0.033203125, 0.0419921875, 0.9990234375, 0.060546875, 0.3974609375, 0.1064453125, 0.9970703125, 0.0, 0.0361328125, 0.7724609375, 0.0, 0.0458984375, 0.0029296875, 0.802734375, 0.92578125, 0.0029296875, 0.0, 0.03125, 0.0810546875, 0.0390625, 0.0029296875, 0.0009765625, 0.0234375, 0.0078125, 0.0087890625, 0.103515625, 0.0634765625, 0.0205078125, 0.005859375, 0.0634765625, 0.0087890625, 0.0087890625, 0.0126953125, 0.07421875, 0.033203125, 0.0146484375, 0.236328125, 0.0498046875, 0.47265625, 0.0341796875, 0.037109375, 0.046875, 0.0029296875, 0.0205078125, 0.0, 0.1533203125, 0.4169921875, 0.919921875, 0.865234375, 0.0224609375, 0.044921875, 0.0068359375, 0.0302734375, 0.001953125, 0.05078125, 0.1494140625, 0.0107421875, 0.13671875, 0.046875, 0.0009765625, 0.0068359375, 0.005859375, 0.005859375, 0.001953125, 0.078125, 0.0, 0.025390625, 0.0166015625, 0.0009765625, 0.0166015625, 0.0673828125, 0.0185546875, 0.013671875, 0.0, 0.0712890625, 0.08984375, 0.076171875, 0.01171875, 0.7861328125, 0.1083984375, 0.03515625, 0.0478515625, 0.037109375, 0.2138671875, 0.0048828125, 0.0078125, 0.8505859375, 0.05078125, 0.0029296875, 0.3359375, 0.07421875, 0.001953125, 0.9541015625, 0.6943359375, 0.005859375, 0.0048828125, 0.0361328125, 0.0146484375, 0.9970703125, 0.0625, 0.6650390625, 0.0986328125, 0.0751953125, 0.9970703125, 0.0029296875, 0.0625, 0.0244140625, 0.4423828125, 0.0380859375, 0.1044921875, 0.1318359375, 0.0146484375, 0.0146484375, 0.0810546875, 0.025390625, 0.029296875, 0.2392578125, 0.0146484375, 0.203125, 0.0283203125, 0.001953125, 0.00390625, 0.125, 0.0009765625, 0.0126953125, 0.0810546875, 0.0849609375, 0.1025390625, 0.8583984375, 0.0126953125, 0.083984375, 0.0947265625, 0.0068359375, 0.322265625, 0.0029296875, 0.0, 0.091796875, 0.0302734375, 0.0283203125, 0.0302734375, 0.0009765625, 0.0771484375, 0.017578125, 0.302734375, 0.1953125, 0.0029296875, 0.087890625, 0.0361328125, 0.091796875, 0.0615234375, 0.11328125, 0.0322265625, 0.9990234375, 0.8388671875, 0.8857421875, 0.0009765625, 0.017578125, 0.0810546875, 0.0361328125, 0.017578125, 0.0, 0.091796875, 0.0615234375, 0.0498046875, 0.0830078125, 0.01953125, 0.896484375, 0.18359375, 0.1796875, 0.091796875, 0.0478515625, 0.099609375, 0.0087890625, 0.0791015625, 0.0322265625, 0.2548828125, 0.5625, 0.03125, 0.09765625, 0.0712890625, 0.916015625, 0.0068359375, 0.052734375, 0.0, 0.0048828125, 0.90625, 0.5966796875, 0.005859375, 0.0810546875, 0.9990234375, 0.005859375, 0.8837890625, 0.001953125, 0.08203125, 0.005859375, 0.177734375, 0.048828125, 0.005859375, 0.201171875, 0.0576171875, 0.2353515625, 0.0029296875, 0.0341796875, 0.927734375, 0.150390625, 0.048828125, 0.16015625, 0.0, 0.0087890625, 0.080078125, 0.998046875, 0.0146484375, 0.8193359375, 0.0166015625, 0.857421875, 0.0205078125, 0.0234375, 0.0546875, 0.0419921875, 0.2646484375, 0.046875, 0.001953125, 0.0029296875, 0.091796875, 0.998046875, 0.091796875, 0.0771484375, 0.0078125, 0.0537109375, 0.130859375, 0.0654296875, 0.064453125, 0.0849609375, 0.8486328125, 0.021484375, 0.01953125, 0.0419921875, 0.609375, 0.0283203125, 0.0615234375, 0.009765625, 0.0185546875, 0.169921875, 0.033203125, 0.001953125, 0.0068359375, 0.009765625, 0.0322265625, 0.0, 0.0048828125, 0.837890625, 0.0341796875, 0.9541015625, 0.08203125, 0.9970703125, 0.9970703125, 0.0, 0.0869140625, 0.9208984375, 0.0009765625, 0.0419921875, 0.0634765625, 0.0400390625, 0.072265625, 0.1005859375, 0.0009765625, 0.01953125, 0.0009765625, 0.001953125, 0.0673828125, 0.02734375, 0.0712890625, 0.0146484375, 0.013671875, 0.73046875, 0.0771484375, 0.2607421875, 0.009765625, 0.001953125, 0.9033203125, 0.9716796875, 0.9970703125, 0.015625, 0.00390625, 0.00390625, 0.2939453125, 0.1962890625, 0.8671875, 0.0068359375, 0.0107421875, 0.00390625, 0.05859375, 0.2412109375, 0.0419921875, 0.0009765625, 0.0673828125, 0.017578125, 0.2998046875, 0.0048828125, 0.0263671875, 0.1083984375, 0.998046875, 0.0107421875, 0.0830078125, 0.0068359375, 0.7099609375, 0.76953125, 0.009765625, 0.0068359375, 0.005859375, 0.078125, 0.048828125, 0.8564453125, 0.0771484375, 0.06640625, 0.998046875, 0.0126953125, 0.017578125, 0.0068359375, 0.0341796875, 0.6396484375, 0.103515625, 0.083984375, 0.005859375, 0.0380859375, 0.08203125, 0.01171875, 0.9970703125, 0.013671875, 0.09375, 0.009765625, 0.2001953125, 0.4462890625, 0.078125, 0.083984375, 0.6904296875, 0.998046875, 0.0283203125, 0.9970703125, 0.169921875, 0.02734375, 0.0751953125, 0.123046875, 0.0390625, 0.078125, 0.158203125, 0.064453125, 0.00390625, 0.0595703125, 0.10546875, 0.0078125, 0.0224609375, 0.0107421875, 0.0048828125, 0.0107421875, 0.0068359375, 0.9296875, 0.00390625, 0.0205078125, 0.005859375, 0.03515625, 0.13671875, 0.03125, 0.6142578125, 0.0146484375, 0.0146484375, 0.0, 0.00390625, 0.0185546875, 0.0, 0.69921875, 0.0185546875, 0.08984375, 0.6162109375, 0.0068359375, 0.06640625, 0.01171875, 0.0087890625, 0.087890625, 0.029296875, 0.1591796875, 0.091796875, 0.00390625, 0.009765625, 0.048828125, 0.0771484375, 0.0322265625, 0.0166015625, 0.076171875, 0.1640625, 0.017578125, 0.94921875, 0.00390625, 0.025390625, 0.0087890625, 0.001953125, 0.029296875, 0.0703125, 0.0419921875, 0.0048828125, 0.02734375, 0.072265625, 0.0009765625, 0.140625, 0.0810546875, 0.033203125, 0.0166015625, 0.029296875, 0.1943359375, 0.00390625, 0.01171875, 0.015625, 0.0703125, 0.0126953125, 0.6435546875, 0.0654296875, 0.826171875, 0.0322265625, 0.0078125, 0.01171875, 0.0107421875, 0.1318359375, 0.013671875, 0.333984375, 0.0546875, 0.7392578125, 0.0205078125, 0.091796875, 0.9072265625, 0.0283203125, 0.001953125, 0.001953125, 0.07421875, 0.0, 0.009765625, 0.0498046875, 0.021484375, 0.0009765625, 0.103515625, 0.9970703125, 0.013671875, 0.0068359375, 0.080078125, 0.1484375, 0.0322265625, 0.048828125, 0.0, 0.9990234375, 0.0185546875, 0.0390625, 0.0205078125, 0.091796875, 0.6513671875, 0.9169921875, 0.9970703125, 0.0869140625, 0.0029296875, 0.015625, 0.111328125, 0.00390625, 0.134765625, 0.302734375, 0.064453125, 0.0029296875, 0.0009765625, 0.2763671875, 0.2470703125, 0.0, 0.0263671875, 0.064453125, 0.005859375, 0.08203125, 0.0029296875, 0.0478515625, 0.9736328125, 0.01953125, 0.03515625, 0.0, 0.3115234375, 0.005859375, 0.3076171875, 0.1279296875, 0.642578125, 0.142578125, 0.0087890625, 0.1083984375, 0.033203125, 0.029296875, 0.7646484375, 0.025390625, 0.080078125, 0.0029296875, 0.134765625, 0.0048828125, 0.73046875, 0.0048828125, 0.2197265625, 0.0029296875, 0.173828125, 0.001953125, 0.0224609375, 0.0322265625, 0.0478515625, 0.9990234375, 0.998046875, 0.130859375, 0.0625, 0.0634765625, 0.0419921875, 0.22265625, 0.609375, 0.9990234375, 0.0078125, 0.0439453125, 0.0107421875, 0.0029296875, 0.01953125, 0.0048828125, 0.005859375, 0.037109375, 0.033203125, 0.013671875, 0.00390625, 0.0439453125, 0.01953125, 0.318359375, 0.0087890625, 0.0302734375, 0.0126953125, 0.783203125, 0.0224609375, 0.01953125, 0.298828125, 0.0703125, 0.0322265625, 0.1083984375, 0.2666015625, 0.9970703125, 0.0087890625, 0.0517578125, 0.1240234375, 0.00390625, 0.0224609375, 0.0830078125, 0.001953125, 0.166015625, 0.0439453125, 0.009765625, 0.0107421875, 0.005859375, 0.00390625, 0.0126953125, 0.076171875, 0.0234375, 0.0068359375, 0.9033203125, 0.0380859375, 0.0244140625, 0.0, 0.86328125, 0.0029296875, 0.95703125, 0.056640625, 0.7080078125, 0.080078125, 0.03125, 0.951171875, 0.01171875, 0.09765625, 0.017578125, 0.943359375, 0.0, 0.169921875, 0.068359375, 0.0126953125, 0.0029296875, 0.9287109375, 0.0888671875, 0.6103515625, 0.0009765625, 0.0078125, 0.0, 0.00390625, 0.0, 0.0029296875, 0.0, 0.0, 0.01953125, 0.8447265625, 0.0791015625, 0.095703125, 0.0107421875, 0.5830078125, 0.3486328125, 0.00390625, 0.0693359375, 0.0146484375, 0.0810546875, 0.04296875, 0.064453125, 0.015625, 0.1259765625, 0.1611328125, 0.8134765625, 0.50390625, 0.0166015625, 0.0322265625, 0.8447265625, 0.0068359375, 0.0029296875, 0.041015625, 0.025390625, 0.0146484375, 0.96484375, 0.005859375, 0.017578125, 0.2314453125, 0.3388671875, 0.126953125, 0.015625, 0.021484375, 0.498046875, 0.7578125, 0.0322265625, 0.0068359375, 0.2412109375, 0.0751953125, 0.9970703125, 0.0224609375, 0.0830078125, 0.169921875, 0.009765625, 0.9970703125, 0.0068359375, 0.0107421875, 0.0419921875, 0.95703125, 0.0810546875, 0.0458984375, 0.0625, 0.548828125, 0.705078125, 0.2685546875, 0.0244140625, 0.013671875, 0.3369140625, 0.1044921875, 0.0, 0.8974609375, 0.234375, 0.0, 0.00390625, 0.4306640625, 0.0107421875, 0.1953125, 0.998046875, 0.03125, 0.1357421875, 0.005859375, 0.0673828125, 0.0849609375, 0.947265625, 0.1416015625, 0.974609375, 0.1396484375, 0.0126953125, 0.623046875, 0.0068359375, 0.0380859375, 0.0029296875, 0.06640625, 0.4248046875, 0.357421875, 0.00390625, 0.00390625, 0.04296875, 0.2744140625, 0.0869140625, 0.00390625, 0.0078125, 0.0029296875, 0.05078125, 0.0068359375, 0.13671875, 0.00390625, 0.0087890625, 0.0224609375, 0.005859375, 0.0302734375, 0.8935546875, 0.1005859375, 0.0224609375, 0.001953125, 0.9404296875, 0.0166015625, 0.181640625, 0.998046875, 0.0283203125, 0.1123046875, 0.001953125, 0.0087890625, 0.048828125, 0.29296875, 0.025390625, 0.9375, 0.25390625, 0.7294921875, 0.03515625, 0.9970703125, 0.0029296875, 0.0859375, 0.0166015625, 0.02734375, 0.1318359375, 0.00390625, 0.0029296875, 0.01171875, 0.001953125, 0.9990234375, 0.544921875, 0.138671875, 0.0029296875, 0.0029296875]

 sparsity of   [0.0341796875, 0.12109375, 0.193359375, 0.056640625, 0.08837890625, 0.06201171875, 0.439453125, 0.03271484375, 0.5400390625, 0.0234375, 0.078125, 0.5078125, 0.0322265625, 0.1875, 0.50244140625, 0.083984375, 0.076171875, 0.07080078125, 0.494140625, 0.029296875, 0.6611328125, 0.05810546875, 0.05859375, 0.03125, 0.55029296875, 0.03271484375, 0.5146484375, 0.02001953125, 0.50634765625, 0.107421875, 0.47412109375, 0.0234375, 0.533203125, 0.033203125, 0.03076171875, 0.09521484375, 0.599609375, 0.57080078125, 0.28271484375, 0.53466796875, 0.0146484375, 0.14111328125, 0.515625, 0.017578125, 0.65478515625, 0.05908203125, 0.044921875, 0.40673828125, 0.56982421875, 0.0751953125, 0.2939453125, 0.009765625, 0.47314453125, 0.05859375, 0.61376953125, 0.04296875, 0.43212890625, 0.02001953125, 0.056640625, 0.52783203125, 0.07568359375, 0.5546875, 0.0654296875, 0.015625, 0.32275390625, 0.04150390625, 0.27490234375, 0.07373046875, 0.05126953125, 0.0146484375, 0.02197265625, 0.02880859375, 0.052734375, 0.02880859375, 0.138671875, 0.5419921875, 0.63134765625, 0.2216796875, 0.046875, 0.35888671875, 0.52294921875, 0.29736328125, 0.6650390625, 0.458984375, 0.0302734375, 0.1630859375, 0.04296875, 0.08154296875, 0.10205078125, 0.3486328125, 0.013671875, 0.111328125, 0.50537109375, 0.19580078125, 0.1142578125, 0.4775390625, 0.1005859375, 0.0576171875, 0.07275390625, 0.11328125, 0.53271484375, 0.1005859375, 0.09619140625, 0.2421875, 0.03466796875, 0.0634765625, 0.7890625, 0.05908203125, 0.0068359375, 0.03857421875, 0.59765625, 0.0400390625, 0.267578125, 0.04150390625, 0.228515625, 0.13671875, 0.53271484375, 0.30029296875, 0.2763671875, 0.9990234375, 0.87158203125, 0.0439453125, 0.5380859375, 0.51220703125, 0.5244140625, 0.544921875, 0.04833984375, 0.06201171875, 0.07275390625, 0.5703125, 0.52783203125, 0.017578125, 0.0, 0.80517578125, 0.09765625, 0.0439453125, 0.52783203125, 0.193359375, 0.0732421875, 0.04296875, 0.36865234375, 0.1484375, 0.5732421875, 0.0390625, 0.05859375, 0.03759765625, 0.54150390625, 0.0283203125, 0.548828125, 0.59228515625, 0.533203125, 0.134765625, 0.19970703125, 0.052734375, 0.0380859375, 0.02685546875, 0.14599609375, 0.4921875, 0.81494140625, 0.1357421875, 0.19287109375, 0.06103515625, 0.1015625, 0.51806640625, 0.56298828125, 0.62548828125, 0.52001953125, 0.0478515625, 0.50244140625, 0.115234375, 0.509765625, 0.513671875, 0.1171875, 0.1171875, 0.17333984375, 0.0244140625, 0.037109375, 0.21484375, 0.0830078125, 0.48828125, 0.5458984375, 0.07373046875, 0.4384765625, 0.13623046875, 0.53515625, 0.09912109375, 0.03271484375, 0.193359375, 0.3740234375, 0.05029296875, 0.03564453125, 0.51904296875, 0.48291015625, 0.0166015625, 0.08349609375, 0.052734375, 0.01513671875, 0.16796875, 0.140625, 0.052734375, 0.05078125, 0.1689453125, 0.029296875, 0.10498046875, 0.52587890625, 0.03369140625, 0.05712890625, 0.115234375, 0.1630859375, 0.0732421875, 0.89453125, 0.046875, 0.01953125, 0.27880859375, 0.095703125, 0.14599609375, 0.38623046875, 0.0, 0.24169921875, 0.78955078125, 0.06640625, 0.53857421875, 0.57421875, 0.048828125, 0.533203125, 0.5390625, 0.6474609375, 0.06494140625, 0.01025390625, 0.08056640625, 0.08544921875, 0.52685546875, 0.06298828125, 0.00732421875, 0.01904296875, 0.0791015625, 0.12353515625, 0.0068359375, 0.03125, 0.18896484375, 0.6689453125, 0.01171875, 0.90673828125, 0.486328125, 0.1435546875, 0.5234375, 0.0615234375, 0.03955078125, 0.05126953125, 0.50244140625, 0.5869140625, 0.08251953125, 0.08935546875, 0.18115234375, 0.0908203125, 0.166015625, 0.05908203125, 0.57958984375, 0.09619140625, 0.0791015625, 0.5009765625, 0.01611328125, 0.0693359375, 0.54443359375, 0.40869140625, 0.095703125, 0.0341796875, 0.99951171875, 0.02197265625, 0.505859375, 0.0126953125, 0.59912109375, 0.00830078125, 0.58056640625, 0.0556640625, 0.52197265625, 0.01318359375, 0.99951171875, 0.03466796875, 0.03759765625, 0.8798828125, 0.56787109375, 0.5302734375, 0.078125, 0.01953125, 0.06982421875, 0.0546875, 0.18896484375, 0.08154296875, 0.552734375, 0.06982421875, 0.048828125, 0.16259765625, 0.3017578125, 0.5263671875, 0.470703125, 0.37841796875, 0.103515625, 0.10693359375, 0.04736328125, 0.02099609375, 0.53662109375, 0.04443359375, 0.05908203125, 0.04443359375, 0.0947265625, 0.0078125, 0.2177734375, 0.0625, 0.01416015625, 0.01025390625, 0.0185546875, 0.0283203125, 0.07568359375, 0.05224609375, 0.0546875, 0.94287109375, 0.99951171875, 0.537109375, 0.03369140625, 0.02099609375, 0.19091796875, 0.0888671875, 0.951171875, 0.99951171875, 0.03125, 0.02880859375, 0.03173828125, 0.52001953125, 0.0078125, 0.33251953125, 0.05224609375, 0.08984375, 0.33154296875, 0.0, 0.0576171875, 0.44775390625, 0.52001953125, 0.2578125, 0.5341796875, 0.09619140625, 0.9990234375, 0.0341796875, 0.04541015625, 0.9990234375, 0.529296875, 0.08984375, 0.548828125, 0.1337890625, 0.01318359375, 0.10986328125, 0.07666015625, 0.5, 0.896484375, 0.486328125, 0.7109375, 0.10302734375, 0.01318359375, 0.5458984375, 0.06640625, 0.96923828125, 0.03759765625, 0.12939453125, 0.13037109375, 0.04052734375, 0.20361328125, 0.54296875, 0.26806640625, 0.5185546875, 0.53369140625, 0.0908203125, 0.11328125, 0.08154296875, 0.14111328125, 0.49072265625, 0.125, 0.05078125, 0.0400390625, 0.0732421875, 0.1005859375, 0.0693359375, 0.40771484375, 0.20068359375, 0.53271484375, 0.07763671875, 0.04248046875, 0.54248046875, 0.07958984375, 0.0546875, 0.0810546875, 0.0078125, 0.02783203125, 0.08447265625, 0.9990234375, 0.54296875, 0.01904296875, 0.080078125, 0.021484375, 0.0810546875, 0.01611328125, 0.48095703125, 0.48388671875, 0.52783203125, 0.54248046875, 0.1015625, 0.0146484375, 0.11669921875, 0.04638671875, 0.1298828125, 0.0166015625, 0.3935546875, 0.52294921875, 0.470703125, 0.03662109375, 0.55029296875, 0.06494140625, 0.57568359375, 0.39990234375, 0.814453125, 0.068359375, 0.28857421875, 0.658203125, 0.1025390625, 0.2724609375, 0.482421875, 0.33642578125, 0.0283203125, 0.87109375, 0.29736328125, 0.01806640625, 0.63037109375, 0.154296875, 0.06201171875, 0.40673828125, 0.0703125, 0.07080078125, 0.48583984375, 0.0302734375, 0.0693359375, 0.04150390625, 0.515625, 0.53857421875, 0.521484375, 0.5576171875, 0.08154296875, 0.10498046875, 0.109375, 0.4248046875, 0.0859375, 0.13134765625, 0.0498046875, 0.04296875, 0.05126953125, 0.02392578125, 0.43896484375, 0.02734375, 0.0791015625, 0.0849609375, 0.54541015625, 0.10009765625, 0.7939453125, 0.255859375, 0.46630859375, 0.06005859375, 0.99951171875, 0.03369140625, 0.03857421875, 0.0537109375, 0.21826171875, 0.01171875, 0.029296875, 0.01513671875, 0.05908203125, 0.0947265625, 0.60302734375, 0.513671875, 0.142578125, 0.43408203125, 0.1591796875, 0.16748046875, 0.05712890625, 0.06201171875, 0.1181640625, 0.0498046875, 0.03857421875, 0.55908203125, 0.5498046875, 0.54541015625, 0.61083984375, 0.2099609375, 0.48876953125, 0.02392578125, 0.162109375, 0.13525390625, 0.810546875, 0.1494140625, 0.09716796875, 0.546875, 0.51171875, 0.20751953125, 0.2783203125, 0.16650390625, 0.0517578125, 0.4931640625, 0.04296875, 0.064453125, 0.01708984375, 0.583984375, 0.04248046875, 0.2333984375, 0.06884765625, 0.02880859375]

 sparsity of   [0.0, 0.0338541679084301, 0.0045572915114462376, 0.02387152798473835, 0.0403645820915699, 0.00021701389050576836, 0.01974826492369175, 0.0, 0.0349392369389534, 0.0, 0.0032552082557231188, 0.0106336809694767, 0.0568576380610466, 0.0, 0.013020833022892475, 0.1369357705116272, 0.0, 0.01215277798473835, 0.1087239608168602, 0.02495659701526165, 0.0, 0.0338541679084301, 0.00021701389050576836, 0.0, 0.0381944440305233, 0.0588107630610466, 0.0, 0.0, 0.0078125, 0.021484375, 0.0, 0.02278645895421505, 0.005425347480922937, 0.01171875, 0.0421006940305233, 0.0394965298473835, 0.0564236119389534, 0.0316840298473835, 0.0, 0.0, 0.0347222238779068, 0.00021701389050576836, 0.0538194440305233, 0.00021701389050576836, 0.015407986007630825, 0.0, 0.0065104165114462376, 0.0284288190305233, 0.0, 0.0008680555620230734, 0.1265190988779068, 0.01953125, 0.0028211805038154125, 0.0486111119389534, 0.00021701389050576836, 0.0616319440305233, 0.00021701389050576836, 0.0, 0.00021701389050576836, 0.02604166604578495, 0.0, 0.00021701389050576836, 0.0, 0.00021701389050576836, 0.0193142369389534, 0.0358072929084301, 0.009548611007630825, 0.0, 0.02278645895421505, 0.015625, 0.00021701389050576836, 0.0071614584885537624, 0.01953125, 0.0045572915114462376, 0.0, 0.0026041667442768812, 0.009548611007630825, 0.01171875, 0.0334201380610466, 0.0, 0.0, 0.0, 0.0, 0.00434027798473835, 0.0, 0.0225694440305233, 0.9993489384651184, 0.013671875, 0.0, 0.01888020895421505, 0.0004340277810115367, 0.001953125, 0.0, 0.0, 0.9867621660232544, 0.01519097201526165, 0.0008680555620230734, 0.00021701389050576836, 0.0366753488779068, 0.02669270895421505, 0.0, 0.075086809694767, 0.0831163227558136, 0.0, 0.0071614584885537624, 0.03081597201526165, 0.0, 0.0, 0.0, 0.00021701389050576836, 0.0, 0.0379774309694767, 0.0, 0.0336371548473835, 0.00021701389050576836, 0.0362413190305233, 0.9997829794883728, 0.0, 0.0, 0.0065104165114462376, 0.0327690988779068, 0.7580295205116272, 0.0015190972480922937, 0.0, 0.01519097201526165, 0.0, 0.01801215298473835, 0.0, 0.0518663190305233, 0.1000434011220932, 0.009982638992369175, 0.0045572915114462376, 0.0609809048473835, 0.0030381944961845875, 0.0173611119389534, 0.0, 0.02213541604578495, 0.9997829794883728, 0.0, 0.02300347201526165, 0.0, 0.0, 0.014322916977107525, 0.0, 0.0, 0.0015190972480922937, 0.03125, 0.02864583395421505, 0.912109375, 0.0301649309694767, 0.0, 0.0, 0.0, 0.0, 0.02300347201526165, 0.0401475690305233, 0.0, 0.01822916604578495, 0.0314670130610466, 0.0, 0.0, 0.0, 0.0, 0.0431857630610466, 0.02886284701526165, 0.0, 0.0329861119389534, 0.00021701389050576836, 0.0822482630610466, 0.0, 0.9763454794883728, 0.9748263955116272, 0.0010850694961845875, 0.0164930559694767, 0.008029513992369175, 0.0, 0.0366753488779068, 0.0, 0.0034722222480922937, 0.00021701389050576836, 0.0067274305038154125, 0.01627604104578495, 0.00021701389050576836, 0.01801215298473835, 0.01215277798473835, 0.0, 0.0223524309694767, 0.0930989608168602, 0.01909722201526165, 0.01410590298473835, 0.01584201492369175, 0.01822916604578495, 0.0045572915114462376, 0.0225694440305233, 0.0, 0.0, 0.01519097201526165, 0.00021701389050576836, 0.02387152798473835, 0.0, 0.0, 0.0314670130610466, 0.0319010429084301, 0.0, 0.0, 0.0713975727558136, 0.0, 0.0, 0.00933159701526165, 0.00021701389050576836, 0.0390625, 0.00021701389050576836, 0.0, 0.011067708022892475, 0.00021701389050576836, 0.0321180559694767, 0.0434027798473835, 0.0427517369389534, 0.01822916604578495, 0.00021701389050576836, 0.02213541604578495, 0.02213541604578495, 0.0004340277810115367, 0.0, 0.0013020833721384406, 0.0023871527519077063, 0.02387152798473835, 0.00021701389050576836, 0.01692708395421505, 0.02799479104578495, 0.015407986007630825, 0.0538194440305233, 0.0, 0.0362413190305233, 0.00021701389050576836, 0.0, 0.0538194440305233, 0.02365451492369175, 0.0, 0.0, 0.1215277761220932, 0.02690972201526165, 0.01605902798473835, 0.0, 0.0, 0.0, 0.0004340277810115367, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0245225690305233, 0.0440538190305233, 0.0, 0.0544704869389534, 0.0598958320915699, 0.0017361111240461469, 0.01519097201526165, 0.01779513992369175, 0.0, 0.0327690988779068, 0.0047743055038154125, 0.0735677108168602, 0.0442708320915699, 0.0, 0.02951388992369175, 0.037109375, 0.0, 0.014756944961845875, 0.0427517369389534, 0.0203993059694767, 0.00434027798473835, 0.0004340277810115367, 0.0045572915114462376, 0.0375434048473835, 0.0401475690305233, 0.00021701389050576836, 0.0, 0.0, 0.0483940988779068, 0.0004340277810115367, 0.0325520820915699, 0.0, 0.00021701389050576836, 0.0, 0.009982638992369175, 0.0, 0.01323784701526165, 0.0340711809694767, 0.9984809160232544, 0.0186631940305233, 0.00021701389050576836, 0.0015190972480922937, 0.00021701389050576836, 0.0, 0.04296875, 0.1690538227558136, 0.0303819440305233, 0.0, 0.0479600690305233, 0.00021701389050576836, 0.0223524309694767, 0.00021701389050576836, 0.0, 0.00021701389050576836, 0.05078125, 0.005425347480922937, 0.02018229104578495, 0.0416666679084301, 0.0, 0.0, 0.0347222238779068, 0.0251736119389534, 0.005859375, 0.015625, 0.0, 0.0327690988779068, 0.0045572915114462376, 0.0390625, 0.0340711809694767, 0.0340711809694767, 0.0, 0.009982638992369175, 0.0, 0.0, 0.1076388880610466, 0.1050347238779068, 0.009548611007630825, 0.02604166604578495, 0.0303819440305233, 0.00021701389050576836, 0.0440538190305233, 0.010416666977107525, 0.0, 0.0, 0.00629340298473835, 0.0, 0.0006510416860692203, 0.0373263880610466, 0.00021701389050576836, 0.0, 0.0282118059694767, 0.1056857630610466, 0.00021701389050576836, 0.01019965298473835, 0.0451388880610466, 0.00021701389050576836, 0.02473958395421505, 0.02083333395421505, 0.0, 0.0323350690305233, 0.0, 0.00021701389050576836, 0.005642361007630825, 0.0377604179084301, 0.0911458358168602, 0.0052083334885537624, 0.0, 0.0069444444961845875, 0.0540364570915699, 0.0412326380610466, 0.02170138992369175, 0.1009114608168602, 0.0045572915114462376, 0.0, 0.0264756940305233, 0.001953125, 0.02473958395421505, 0.0034722222480922937, 0.056640625, 0.0, 0.002170138992369175, 0.00021701389050576836, 0.0067274305038154125, 0.009765625, 0.0, 0.010416666977107525, 0.01410590298473835, 0.0355902798473835, 0.0, 0.0453559048473835, 0.0, 0.0008680555620230734, 0.01627604104578495, 0.0173611119389534, 0.00021701389050576836, 0.0, 0.02018229104578495, 0.0, 0.0173611119389534, 0.0, 0.02864583395421505, 0.0, 0.01974826492369175, 0.0553385429084301, 0.0173611119389534, 0.002170138992369175, 0.0486111119389534, 0.02213541604578495, 0.0, 0.0, 0.025390625, 0.0345052070915699, 0.005642361007630825, 0.00021701389050576836, 0.010416666977107525, 0.0755208358168602, 0.00933159701526165, 0.0, 0.0, 0.00021701389050576836, 0.0036892362404614687, 0.0785590261220932, 0.9997829794883728, 0.025390625, 0.0, 0.0, 0.0, 0.0, 0.1341145783662796, 0.0, 0.0, 0.0164930559694767, 0.02973090298473835, 0.0, 0.9993489384651184, 0.0, 0.0301649309694767, 0.0026041667442768812, 0.0023871527519077063, 0.048828125, 0.0, 0.9967448115348816, 0.0, 0.0032552082557231188, 0.00021701389050576836, 0.00021701389050576836, 0.01128472201526165, 0.01584201492369175, 0.0, 0.0, 0.0, 0.00021701389050576836, 0.00021701389050576836, 0.0, 0.01323784701526165, 0.0, 0.0, 0.0, 0.9989149570465088, 0.005859375, 0.00021701389050576836, 0.2463107705116272, 0.0, 0.0245225690305233, 0.0, 0.0, 0.0015190972480922937, 0.0, 0.009982638992369175, 0.0282118059694767, 0.0753038227558136, 0.0, 0.0, 0.0, 0.0, 0.0010850694961845875, 0.0, 0.0, 0.0390625, 0.01215277798473835, 0.0034722222480922937, 0.0, 0.008029513992369175, 0.0, 0.0, 0.00021701389050576836, 0.0, 0.0, 0.0316840298473835, 0.0078125, 0.00021701389050576836, 0.00629340298473835, 0.0466579869389534, 0.6812065839767456, 0.00021701389050576836, 0.0212673619389534, 0.0232204869389534, 0.0, 0.0049913194961845875, 0.0004340277810115367, 0.00021701389050576836, 0.0186631940305233, 0.0, 0.0360243059694767, 0.0067274305038154125, 0.0, 0.0, 0.0008680555620230734, 0.0, 0.0206163190305233, 0.02864583395421505, 0.0659722238779068, 0.010416666977107525, 0.9262152910232544, 0.0010850694961845875, 0.0, 0.0, 0.0, 0.0625, 0.0]

 sparsity of   [0.044921875, 0.033203125, 0.00390625, 0.95703125, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.04296875, 0.0, 0.0, 0.0, 0.037109375, 0.017578125, 0.0, 0.015625, 0.03515625, 0.00390625, 0.0, 0.04296875, 0.001953125, 0.0, 0.0, 0.046875, 0.0, 0.05078125, 0.0, 0.0, 0.048828125, 0.0, 0.0390625, 0.0, 0.0, 0.857421875, 0.0, 0.0, 0.00390625, 0.005859375, 0.123046875, 0.115234375, 0.0, 0.0, 0.03515625, 0.005859375, 0.0078125, 0.01171875, 0.0, 0.041015625, 0.0, 0.0078125, 0.935546875, 0.0, 0.0, 0.896484375, 0.017578125, 0.0, 0.013671875, 0.0, 0.0, 0.013671875, 0.00390625, 0.001953125, 0.0, 0.015625, 0.001953125, 0.001953125, 0.0, 0.0, 0.068359375, 0.0, 0.03125, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.005859375, 0.0, 0.005859375, 0.0, 0.0, 0.005859375, 0.0, 0.953125, 0.0, 0.01953125, 0.009765625, 0.0, 0.0, 0.00390625, 0.005859375, 0.001953125, 0.0234375, 0.076171875, 0.0, 0.0, 0.0, 0.00390625, 0.044921875, 0.001953125, 0.01171875, 0.0, 0.00390625, 0.0, 0.001953125, 0.0, 0.025390625, 0.0, 0.005859375, 0.013671875, 0.001953125, 0.0, 0.0, 0.013671875, 0.03125, 0.0, 0.029296875, 0.0, 0.001953125, 0.072265625, 0.005859375, 0.0078125, 0.0, 0.0, 0.0, 0.009765625, 0.0, 0.00390625, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.009765625, 0.001953125, 0.0078125, 0.0, 0.001953125, 0.0, 0.029296875, 0.033203125, 0.025390625, 0.009765625, 0.0, 0.0, 0.02734375, 0.0, 0.0, 0.013671875, 0.017578125, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.00390625, 0.0, 0.0, 0.00390625, 0.021484375, 0.0, 0.91015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013671875, 0.0, 0.0, 0.0, 0.02734375, 0.0078125, 0.0, 0.001953125, 0.861328125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.087890625, 0.0, 0.052734375, 0.0, 0.001953125, 0.107421875, 0.0, 0.0, 0.037109375, 0.984375, 0.0, 0.0, 0.033203125, 0.044921875, 0.01953125, 0.0, 0.00390625, 0.00390625, 0.0, 0.0, 0.013671875, 0.005859375, 0.013671875, 0.0, 0.0, 0.0, 0.04296875, 0.021484375, 0.005859375, 0.455078125, 0.00390625, 0.001953125, 0.0234375, 0.0, 0.0, 0.04296875, 0.0546875, 0.0, 0.001953125, 0.830078125, 0.03125, 0.0, 0.0, 0.001953125, 0.00390625, 0.078125, 0.01171875, 0.0, 0.00390625, 0.037109375, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.00390625, 0.001953125, 0.0, 0.0, 0.765625, 0.005859375, 0.01171875, 0.0, 0.00390625, 0.0, 0.0234375, 0.0, 0.001953125, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.029296875, 0.99609375, 0.0, 0.005859375, 0.05078125, 0.01171875, 0.015625, 0.001953125, 0.005859375, 0.021484375, 0.0, 0.00390625, 0.01953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.001953125, 0.0, 0.0, 0.0, 0.951171875, 0.00390625, 0.0, 0.001953125, 0.001953125, 0.0, 0.0, 0.009765625, 0.0, 0.0, 0.916015625, 0.0, 0.0, 0.02734375, 0.0, 0.001953125, 0.001953125, 0.865234375, 0.03125, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.025390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0078125, 0.029296875, 0.001953125, 0.001953125, 0.0, 0.0390625, 0.01953125, 0.0, 0.111328125, 0.001953125, 0.001953125, 0.005859375, 0.0, 0.0, 0.001953125, 0.021484375, 0.0, 0.0, 0.0, 0.017578125, 0.0234375, 0.4140625, 0.025390625, 0.001953125, 0.00390625, 0.005859375, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0078125, 0.009765625, 0.0, 0.0, 0.033203125, 0.0, 0.0, 0.013671875, 0.0, 0.0, 0.00390625, 0.001953125, 0.001953125, 0.0, 0.046875, 0.0, 0.005859375, 0.00390625, 0.8515625, 0.0, 0.0, 0.169921875, 0.017578125, 0.958984375, 0.0, 0.005859375, 0.021484375, 0.001953125, 0.0, 0.00390625, 0.0, 0.0, 0.00390625, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.013671875, 0.0, 0.0, 0.05078125, 0.001953125, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.025390625, 0.06640625, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.00390625, 0.00390625, 0.0234375, 0.0, 0.009765625, 0.001953125, 0.0, 0.021484375, 0.0, 0.060546875, 0.044921875, 0.01171875, 0.0, 0.001953125, 0.0, 0.001953125, 0.001953125, 0.0, 0.009765625, 0.04296875, 0.041015625, 0.015625, 0.001953125, 0.0, 0.0, 0.013671875, 0.03125, 0.0, 0.001953125, 0.0078125, 0.0, 0.904296875, 0.0, 0.068359375, 0.0, 0.0, 0.013671875, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.994140625, 0.05078125, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.005859375, 0.001953125, 0.0, 0.0703125, 0.001953125, 0.01953125, 0.0, 0.0, 0.0, 0.005859375, 0.001953125, 0.0078125, 0.02734375, 0.0, 0.0, 0.00390625, 0.0, 0.001953125, 0.0, 0.005859375, 0.0, 0.001953125, 0.0078125, 0.015625, 0.005859375, 0.00390625, 0.0, 0.0, 0.001953125, 0.0, 0.001953125, 0.0, 0.03125, 0.0, 0.015625, 0.001953125, 0.0, 0.0078125, 0.015625, 0.001953125, 0.0, 0.0, 0.0, 0.0078125, 0.04296875, 0.044921875, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.00390625, 0.0, 0.00390625, 0.0, 0.005859375, 0.0, 0.0, 0.005859375, 0.990234375, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.01953125, 0.013671875, 0.93359375, 0.001953125, 0.0, 0.00390625, 0.001953125, 0.21875, 0.0, 0.001953125, 0.0, 0.0, 0.001953125, 0.037109375, 0.009765625, 0.0234375, 0.02734375, 0.0, 0.013671875, 0.05078125, 0.0, 0.03125, 0.0, 0.0, 0.00390625, 0.029296875, 0.01171875, 0.0, 0.98828125, 0.064453125, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.013671875, 0.0, 0.0, 0.0078125, 0.0, 0.001953125, 0.01953125, 0.0234375, 0.0, 0.005859375, 0.0, 0.05078125, 0.017578125, 0.0, 0.00390625, 0.001953125, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.015625, 0.0, 0.0, 0.0, 0.0078125, 0.0078125, 0.009765625, 0.005859375, 0.029296875, 0.00390625, 0.0, 0.0, 0.009765625, 0.00390625, 0.0, 0.0, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.91796875, 0.0, 0.0, 0.0, 0.017578125, 0.0, 0.00390625, 0.0, 0.0, 0.03515625, 0.0078125, 0.017578125, 0.0, 0.005859375, 0.04296875, 0.001953125, 0.0, 0.013671875, 0.009765625, 0.0, 0.0, 0.0, 0.00390625, 0.0078125, 0.00390625, 0.05859375, 0.00390625, 0.0, 0.00390625, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.060546875, 0.0, 0.0, 0.00390625, 0.025390625, 0.00390625, 0.25, 0.015625, 0.0, 0.0, 0.03125, 0.0, 0.001953125, 0.009765625, 0.0, 0.0, 0.017578125, 0.0, 0.0, 0.009765625, 0.0, 0.009765625, 0.005859375, 0.0078125, 0.013671875, 0.001953125, 0.0, 0.0, 0.001953125, 0.001953125, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.009765625, 0.0, 0.0, 0.015625, 0.001953125, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.001953125, 0.0, 0.01953125, 0.001953125, 0.0, 0.0, 0.0, 0.02734375, 0.013671875, 0.0, 0.0, 0.017578125, 0.00390625, 0.00390625, 0.029296875, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.013671875, 0.001953125, 0.064453125, 0.001953125, 0.9921875, 0.0, 0.0, 0.0, 0.0234375, 0.001953125, 0.0, 0.0, 0.0, 0.009765625, 0.001953125, 0.015625, 0.0, 0.001953125, 0.00390625, 0.009765625, 0.0, 0.0, 0.08984375, 0.01953125, 0.0, 0.0, 0.00390625, 0.03515625, 0.0, 0.12890625, 0.0, 0.00390625, 0.0, 0.001953125, 0.0, 0.14453125, 0.0, 0.0, 0.0, 0.0, 0.005859375, 0.0078125, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.9921875, 0.0, 0.017578125, 0.0, 0.005859375, 0.0, 0.00390625, 0.009765625, 0.025390625, 0.00390625, 0.005859375, 0.017578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.017578125, 0.00390625, 0.00390625, 0.0, 0.001953125, 0.001953125, 0.00390625, 0.0, 0.01953125, 0.0, 0.00390625, 0.0, 0.001953125, 0.0, 0.01953125, 0.080078125, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.00390625, 0.0, 0.001953125, 0.01171875, 0.00390625, 0.05078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03125, 0.0, 0.00390625, 0.0, 0.0, 0.021484375, 0.01171875, 0.0, 0.0, 0.0, 0.001953125, 0.009765625, 0.00390625, 0.005859375, 0.0, 0.00390625, 0.009765625, 0.037109375, 0.0, 0.001953125, 0.0, 0.001953125, 0.0, 0.0, 0.916015625, 0.001953125, 0.052734375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.00390625, 0.00390625, 0.0, 0.0, 0.00390625, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.037109375, 0.0, 0.017578125, 0.001953125, 0.0, 0.001953125, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.0, 0.017578125, 0.0, 0.01953125, 0.0, 0.0, 0.001953125, 0.001953125, 0.009765625, 0.0, 0.0, 0.03125, 0.0, 0.0, 0.052734375, 0.001953125, 0.005859375, 0.017578125, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04296875, 0.0, 0.908203125, 0.0, 0.0, 0.001953125, 0.0078125, 0.017578125, 0.001953125, 0.001953125, 0.923828125, 0.0, 0.01171875, 0.0, 0.0, 0.01171875, 0.001953125, 0.005859375, 0.046875, 0.0078125, 0.0, 0.0, 0.0234375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02734375, 0.001953125, 0.0, 0.0, 0.912109375, 0.0, 0.0, 0.0, 0.00390625, 0.021484375, 0.0, 0.90625, 0.0, 0.0, 0.0, 0.02734375, 0.00390625, 0.0, 0.001953125, 0.001953125, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017578125, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009765625, 0.001953125, 0.0, 0.041015625, 0.0234375, 0.0, 0.009765625, 0.015625, 0.0, 0.001953125, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0078125, 0.013671875, 0.01953125, 0.0, 0.0, 0.0, 0.009765625, 0.0, 0.001953125, 0.0, 0.033203125, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013671875, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.0234375, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0078125, 0.00390625, 0.0, 0.03125, 0.0, 0.001953125, 0.005859375, 0.001953125, 0.00390625, 0.0, 0.00390625, 0.0, 0.0, 0.9609375, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.005859375, 0.0, 0.001953125, 0.033203125, 0.005859375, 0.005859375, 0.0, 0.0, 0.0, 0.09375, 0.0, 0.001953125, 0.0, 0.009765625, 0.0, 0.009765625, 0.001953125, 0.005859375, 0.0, 0.455078125, 0.0, 0.0, 0.021484375, 0.052734375, 0.0, 0.0078125, 0.015625, 0.01171875, 0.001953125, 0.0078125, 0.00390625, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.033203125, 0.0, 0.0, 0.0, 0.939453125, 0.0, 0.10546875, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.1015625, 0.021484375, 0.0, 0.0, 0.009765625, 0.03515625, 0.0, 0.0, 0.001953125, 0.029296875, 0.005859375, 0.052734375, 0.01171875, 0.00390625, 0.001953125, 0.0, 0.001953125, 0.001953125, 0.0078125, 0.01953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0390625, 0.0, 0.08203125, 0.013671875, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.009765625, 0.0, 0.0, 0.001953125, 0.0, 0.009765625, 0.041015625, 0.0, 0.0, 0.0078125, 0.01953125, 0.0, 0.001953125, 0.06640625, 0.0, 0.001953125, 0.0, 0.0078125, 0.0, 0.01953125, 0.001953125, 0.0, 0.021484375, 0.0, 0.0, 0.017578125, 0.0, 0.0, 0.048828125, 0.0078125, 0.033203125, 0.01953125, 0.001953125, 0.015625, 0.001953125, 0.009765625, 0.001953125, 0.0078125, 0.001953125, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.005859375, 0.0234375, 0.009765625, 0.0, 0.005859375, 0.021484375, 0.0, 0.00390625, 0.0, 0.009765625, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.02734375, 0.0, 0.01171875, 0.013671875, 0.0, 0.0, 0.0, 0.009765625, 0.0, 0.0, 0.001953125, 0.013671875, 0.0078125, 0.005859375, 0.0, 0.060546875, 0.0, 0.220703125, 0.0, 0.0, 0.07421875, 0.00390625, 0.0, 0.0546875, 0.0, 0.060546875, 0.0, 0.001953125, 0.005859375, 0.0, 0.30078125, 0.0, 0.01171875, 0.05859375, 0.0, 0.02734375, 0.0, 0.07421875, 0.009765625, 0.001953125, 0.001953125, 0.01171875, 0.0, 0.912109375, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.076171875, 0.013671875, 0.00390625, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.91015625, 0.0, 0.05078125, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.00390625, 0.015625, 0.02734375, 0.0, 0.00390625, 0.0, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.017578125, 0.021484375, 0.01171875, 0.060546875, 0.01953125, 0.01171875, 0.00390625, 0.0, 0.0, 0.0, 0.046875, 0.001953125, 0.005859375, 0.001953125, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.037109375, 0.0, 0.025390625, 0.0, 0.029296875, 0.0, 0.0078125, 0.001953125, 0.001953125, 0.0078125, 0.0, 0.0, 0.98828125, 0.0, 0.46875, 0.0, 0.0234375, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.005859375, 0.013671875, 0.0, 0.0, 0.0, 0.1796875, 0.005859375, 0.0, 0.00390625, 0.001953125, 0.0, 0.0, 0.0078125, 0.015625, 0.0, 0.994140625, 0.974609375, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.869140625, 0.0, 0.345703125, 0.025390625, 0.009765625, 0.001953125, 0.0, 0.0, 0.03515625, 0.0, 0.0, 0.0, 0.021484375, 0.0, 0.03125, 0.009765625, 0.0, 0.009765625, 0.0, 0.001953125, 0.0, 0.00390625, 0.001953125, 0.005859375, 0.005859375, 0.0, 0.001953125, 0.04296875, 0.00390625, 0.001953125, 0.001953125, 0.00390625, 0.001953125, 0.060546875, 0.046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.029296875, 0.0, 0.0, 0.0, 0.01953125, 0.994140625, 0.02734375, 0.0, 0.0, 0.046875, 0.0, 0.0859375, 0.001953125, 0.00390625, 0.0, 0.0078125, 0.037109375, 0.0234375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.015625, 0.4296875, 0.001953125, 0.005859375, 0.0078125, 0.001953125, 0.0, 0.001953125, 0.111328125, 0.0, 0.017578125, 0.01953125, 0.0, 0.001953125, 0.0078125, 0.001953125, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.025390625, 0.00390625, 0.015625, 0.0, 0.001953125, 0.853515625, 0.037109375, 0.0, 0.0, 0.005859375, 0.0, 0.029296875, 0.00390625, 0.0078125, 0.04296875, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.001953125, 0.0390625, 0.005859375, 0.068359375, 0.0, 0.998046875, 0.0, 0.0, 0.001953125, 0.005859375, 0.0, 0.001953125, 0.0, 0.00390625, 0.0, 0.0, 0.015625, 0.0, 0.12890625, 0.00390625, 0.001953125, 0.00390625, 0.005859375, 0.0, 0.01171875, 0.00390625, 0.0, 0.001953125, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.9921875, 0.0, 0.0, 0.033203125, 0.0, 0.00390625, 0.0, 0.021484375, 0.009765625, 0.00390625, 0.00390625, 0.001953125, 0.0, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.001953125, 0.01171875, 0.001953125, 0.037109375, 0.0, 0.001953125, 0.017578125, 0.00390625, 0.0, 0.0, 0.013671875, 0.046875, 0.013671875, 0.001953125, 0.0, 0.0, 0.013671875, 0.00390625, 0.0, 0.00390625, 0.0, 0.0, 0.02734375, 0.001953125, 0.001953125, 0.0, 0.005859375, 0.001953125, 0.009765625, 0.013671875, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0234375, 0.00390625, 0.005859375, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.041015625, 0.005859375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.001953125, 0.0078125, 0.001953125, 0.29296875, 0.0, 0.0, 0.0078125, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.00390625, 0.02734375, 0.005859375, 0.0, 0.044921875, 0.05859375, 0.0, 0.0, 0.005859375, 0.001953125, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013671875, 0.005859375, 0.001953125, 0.0546875, 0.0, 0.0, 0.001953125, 0.0234375, 0.0, 0.962890625, 0.0, 0.0, 0.025390625, 0.07421875, 0.01171875, 0.04296875, 0.009765625, 0.0234375, 0.00390625, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0234375, 0.0, 0.00390625, 0.0, 0.005859375, 0.00390625, 0.001953125, 0.99609375, 0.0, 0.00390625, 0.021484375, 0.005859375, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.001953125, 0.0, 0.009765625, 0.0078125, 0.001953125, 0.017578125, 0.9921875, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.041015625, 0.0, 0.005859375, 0.0, 0.0625, 0.0390625, 0.001953125, 0.0078125, 0.013671875, 0.0, 0.0, 0.0, 0.0, 0.009765625, 0.00390625, 0.0, 0.318359375, 0.001953125, 0.037109375, 0.0, 0.0, 0.001953125, 0.0, 0.013671875, 0.015625, 0.0, 0.0, 0.00390625, 0.005859375, 0.0, 0.0, 0.0, 0.021484375, 0.0, 0.041015625, 0.00390625, 0.0, 0.00390625, 0.0078125, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.94140625, 0.0078125, 0.005859375, 0.015625, 0.029296875, 0.0, 0.0, 0.01171875, 0.0, 0.03515625, 0.0, 0.001953125, 0.0, 0.005859375, 0.001953125, 0.001953125, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.025390625, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.052734375, 0.009765625, 0.0078125, 0.0078125, 0.0390625, 0.001953125, 0.0078125, 0.0, 0.0, 0.0, 0.03125, 0.001953125, 0.048828125, 0.958984375, 0.009765625, 0.001953125, 0.0, 0.01953125, 0.087890625, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.001953125, 0.001953125, 0.0, 0.0, 0.0, 0.001953125, 0.009765625, 0.00390625, 0.02734375, 0.0, 0.0, 0.0, 0.03515625, 0.001953125, 0.0, 0.001953125, 0.001953125, 0.04296875, 0.0, 0.001953125, 0.0, 0.0390625, 0.00390625, 0.0, 0.017578125, 0.0, 0.0078125, 0.0078125, 0.017578125, 0.0, 0.009765625, 0.001953125, 0.0, 0.001953125, 0.0, 0.037109375, 0.001953125, 0.03125, 0.029296875, 0.091796875, 0.00390625, 0.00390625, 0.001953125, 0.060546875, 0.0, 0.0, 0.154296875, 0.0, 0.0, 0.0, 0.00390625, 0.03515625, 0.01171875, 0.0, 0.0, 0.0, 0.017578125, 0.0, 0.009765625, 0.001953125, 0.001953125, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.884765625, 0.92578125, 0.0, 0.005859375, 0.0, 0.0078125, 0.021484375, 0.0, 0.00390625, 0.0, 0.0, 0.03125, 0.0, 0.0, 0.0, 0.001953125, 0.021484375, 0.0, 0.001953125, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.001953125, 0.005859375, 0.0, 0.001953125, 0.0, 0.0, 0.123046875, 0.021484375, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.017578125, 0.0, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.9921875, 0.0, 0.009765625, 0.001953125, 0.0, 0.05078125, 0.0, 0.0, 0.009765625, 0.001953125, 0.001953125, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.029296875, 0.0, 0.00390625, 0.009765625, 0.0, 0.076171875, 0.033203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052734375, 0.0, 0.0, 0.01953125, 0.005859375, 0.064453125, 0.0, 0.04296875, 0.009765625, 0.0, 0.0, 0.001953125, 0.0, 0.03125, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.048828125, 0.0, 0.021484375, 0.015625, 0.0, 0.0, 0.001953125, 0.0, 0.013671875, 0.0, 0.0078125, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.095703125, 0.001953125, 0.0, 0.0, 0.009765625, 0.0, 0.083984375, 0.0, 0.00390625, 0.0, 0.0, 0.013671875, 0.0, 0.025390625, 0.013671875, 0.0, 0.0, 0.01953125, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005859375, 0.919921875, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.015625, 0.001953125, 0.03515625, 0.0, 0.0, 0.005859375, 0.001953125, 0.00390625, 0.00390625, 0.033203125, 0.0, 0.0, 0.0078125, 0.0, 0.005859375, 0.041015625, 0.0, 0.0, 0.001953125, 0.00390625, 0.056640625, 0.0, 0.0078125, 0.0, 0.0, 0.048828125, 0.0, 0.0, 0.0, 0.00390625, 0.009765625, 0.0, 0.01953125, 0.03125, 0.0, 0.0, 0.0078125, 0.0, 0.0078125, 0.009765625, 0.0, 0.001953125, 0.001953125, 0.056640625, 0.005859375, 0.0, 0.03515625, 0.1328125, 0.0, 0.001953125]

 sparsity of   [0.03173828125, 0.03857421875, 0.044921875, 0.04345703125, 0.0302734375, 0.01513671875, 0.0224609375, 0.06982421875, 0.02099609375, 0.39697265625, 0.07421875, 0.0634765625, 0.015625, 0.00830078125, 0.02099609375, 0.04052734375, 0.0, 0.0, 0.03369140625, 0.03759765625, 0.02587890625, 0.03857421875, 0.01025390625, 0.0400390625, 0.02880859375, 0.00390625, 0.0576171875, 0.99755859375, 0.0009765625, 0.4951171875, 0.01123046875, 0.88525390625, 0.021484375, 0.4951171875, 0.06201171875, 0.0498046875, 0.00048828125, 0.072265625, 0.0146484375, 0.02294921875, 0.00048828125, 0.0478515625, 0.05078125, 0.044921875, 0.0322265625, 0.02734375, 0.01904296875, 0.01806640625, 0.16943359375, 0.01953125, 0.03515625, 0.01171875, 0.009765625, 0.00048828125, 0.00048828125, 0.03173828125, 0.05908203125, 0.0537109375, 0.0400390625, 0.037109375, 0.05078125, 0.20947265625, 0.044921875, 0.0498046875, 0.048828125, 0.35302734375, 0.0, 0.06640625, 0.0, 0.01513671875, 0.03662109375, 0.037109375, 0.0556640625, 0.04052734375, 0.04931640625, 0.02490234375, 0.03857421875, 0.68115234375, 0.02392578125, 0.021484375, 0.6708984375, 0.021484375, 0.05908203125, 0.04638671875, 0.0751953125, 0.005859375, 0.0625, 0.02880859375, 0.0419921875, 0.06103515625, 0.02197265625, 0.0625, 0.08251953125, 0.07666015625, 0.0, 0.1416015625, 0.0, 0.06298828125, 0.02099609375, 0.02880859375, 0.01513671875, 0.00048828125, 0.02685546875, 0.0576171875, 0.0302734375, 0.11572265625, 0.025390625, 0.02099609375, 0.154296875, 0.01708984375, 0.07080078125, 0.0458984375, 0.0341796875, 0.03125, 0.89990234375, 0.02685546875, 0.03125, 0.02099609375, 0.05615234375, 0.04638671875, 0.93603515625, 0.01513671875, 0.013671875, 0.0625, 0.0341796875, 0.03076171875, 0.037109375, 0.0234375, 0.0283203125, 0.02099609375, 0.0244140625, 0.0, 0.0244140625, 0.037109375, 0.0673828125, 0.021484375, 0.04296875, 0.0361328125, 0.0205078125, 0.0078125, 0.046875, 0.1279296875, 0.0947265625, 0.57470703125, 0.041015625, 0.06982421875, 0.03857421875, 0.0263671875, 0.0234375, 0.0234375, 0.00244140625, 0.0224609375, 0.126953125, 0.05859375, 0.06884765625, 0.005859375, 0.0, 0.1533203125, 0.04296875, 0.015625, 0.99853515625, 0.0166015625, 0.0234375, 0.03515625, 0.04296875, 0.11865234375, 0.04443359375, 0.06884765625, 0.02783203125, 0.068359375, 0.00048828125, 0.0283203125, 0.0166015625, 0.99951171875, 0.03271484375, 0.0302734375, 0.01171875, 0.0478515625, 0.02734375, 0.01708984375, 0.0, 0.07666015625, 0.1103515625, 0.025390625, 0.021484375, 0.0126953125, 0.0546875, 0.0, 0.06005859375, 0.0498046875, 0.02783203125, 0.00439453125, 0.0048828125, 0.03466796875, 0.5966796875, 0.02294921875, 0.02685546875, 0.01904296875, 0.0224609375, 0.02001953125, 0.02490234375, 0.0478515625, 0.1943359375, 0.10205078125, 0.0654296875, 0.1103515625, 0.0146484375, 0.0048828125, 0.00439453125, 0.03271484375, 0.02392578125, 0.01416015625, 0.03076171875, 0.00048828125, 0.01611328125, 0.03857421875, 0.0419921875, 0.0, 0.0, 0.03125, 0.05712890625, 0.02978515625, 0.04736328125, 0.0205078125, 0.0009765625, 0.67333984375, 0.0, 0.0419921875, 0.02880859375, 0.00048828125, 0.029296875, 0.08203125, 0.00048828125, 0.00048828125, 0.39990234375, 0.03564453125, 0.4931640625, 0.0244140625, 0.03173828125, 0.04345703125, 0.0283203125, 0.0361328125, 0.02685546875, 0.0224609375, 0.03271484375, 0.0068359375, 0.01708984375, 0.02490234375, 0.02978515625, 0.01953125, 0.00634765625, 0.0390625, 0.0283203125, 0.03515625, 0.0986328125, 0.00048828125, 0.015625, 0.03515625, 0.0341796875, 0.00048828125, 0.04638671875, 0.056640625, 0.05859375, 0.02978515625, 0.1142578125, 0.0595703125, 0.02294921875, 0.03466796875, 0.06787109375, 0.0439453125, 0.04248046875, 0.02099609375, 0.015625, 0.021484375, 0.02587890625, 0.05859375, 0.05078125, 0.83642578125, 0.90234375, 0.0576171875, 0.0, 0.02880859375, 0.0263671875, 0.01806640625, 0.03173828125, 0.06591796875, 0.30712890625, 0.03857421875, 0.021484375, 0.04150390625, 0.02197265625, 0.02392578125, 0.1162109375, 0.13037109375, 0.11083984375, 0.0556640625, 0.05224609375, 0.03466796875, 0.02294921875, 0.02490234375, 0.0390625, 0.0, 0.0205078125, 0.0234375, 0.0, 0.20166015625, 0.05908203125, 0.04443359375, 0.01953125, 0.43603515625, 0.00244140625, 0.03271484375, 0.03369140625, 0.02197265625, 0.5654296875, 0.01220703125, 0.04150390625, 0.0, 0.0205078125, 0.02587890625, 0.07666015625, 0.05078125, 0.0458984375, 0.19384765625, 0.06201171875, 0.0302734375, 0.00244140625, 0.013671875, 0.02490234375, 0.72216796875, 0.046875, 0.08544921875, 0.0224609375, 0.0078125, 0.05712890625, 0.013671875, 0.0224609375, 0.0, 0.080078125, 0.0458984375, 0.03662109375, 0.8330078125, 0.0546875, 0.0908203125, 0.119140625, 0.03662109375, 0.017578125, 0.06005859375, 0.48486328125, 0.02685546875, 0.0, 0.0, 0.03466796875, 0.05029296875, 0.04638671875, 0.01171875, 0.021484375, 0.02880859375, 0.025390625, 0.5390625, 0.037109375, 0.0185546875, 0.0537109375, 0.00048828125, 0.0, 0.10400390625, 0.03076171875, 0.02197265625, 0.05126953125, 0.12890625, 0.0302734375, 0.0859375, 0.087890625, 0.06396484375, 0.04736328125, 0.04248046875, 0.03125, 0.02880859375, 0.0283203125, 0.03369140625, 0.03271484375, 0.00048828125, 0.0205078125, 0.00048828125, 0.02001953125, 0.0869140625, 0.0380859375, 0.02978515625, 0.04541015625, 0.02734375, 0.01025390625, 0.02783203125, 0.02783203125, 0.0, 0.05126953125, 0.0, 0.02880859375, 0.02880859375, 0.306640625, 0.09375, 0.0478515625, 0.046875, 0.0234375, 0.083984375, 0.0166015625, 0.0263671875, 0.02294921875, 0.0, 0.02978515625, 0.01220703125, 0.38037109375, 0.02197265625, 0.05029296875, 0.03466796875, 0.0859375, 0.13330078125, 0.0, 0.0205078125, 0.0078125, 0.0283203125, 0.095703125, 0.52001953125, 0.40576171875, 0.0322265625, 0.05908203125, 0.0, 0.0322265625, 0.04052734375, 0.0, 0.029296875, 0.0341796875, 0.091796875, 0.04931640625, 0.021484375, 0.029296875, 0.03125, 0.01171875, 0.009765625, 0.04833984375, 0.02490234375, 0.0322265625, 0.0068359375, 0.00390625, 0.03662109375, 0.01611328125, 0.6279296875, 0.02001953125, 0.01708984375, 0.0146484375, 0.029296875, 0.0849609375, 0.0146484375, 0.0517578125, 0.0185546875, 0.0, 0.01708984375, 0.01416015625, 0.0341796875, 0.03369140625, 0.04736328125, 0.0791015625, 0.06298828125, 0.26904296875, 0.02685546875, 0.04931640625, 0.02880859375, 0.064453125, 0.025390625, 0.01025390625, 0.02392578125, 0.0234375, 0.12548828125, 0.05810546875, 0.74755859375, 0.01611328125, 0.033203125, 0.060546875, 0.041015625, 0.02587890625, 0.0390625, 0.142578125, 0.03076171875, 0.02099609375, 0.05615234375, 0.017578125, 0.00927734375, 0.05029296875, 0.0126953125, 0.0322265625, 0.0224609375, 0.01123046875, 0.02783203125, 0.0078125, 0.025390625, 0.02734375, 0.05615234375, 0.03515625, 0.00341796875, 0.01806640625, 0.46142578125, 0.0322265625, 0.0126953125, 0.03759765625, 0.1044921875, 0.0517578125, 0.0458984375, 0.0703125, 0.029296875, 0.02294921875, 0.220703125, 0.04150390625, 0.03857421875]

 sparsity of   [0.00021701389050576836, 0.0842013880610466, 0.0768229141831398, 0.0, 0.0436197929084301, 0.0401475690305233, 0.00021701389050576836, 0.0, 0.0, 0.0023871527519077063, 0.00021701389050576836, 0.021484375, 0.0203993059694767, 0.0, 0.0, 0.0, 0.0069444444961845875, 0.0, 0.0514322929084301, 0.056640625, 0.0, 0.0323350690305233, 0.00021701389050576836, 0.0004340277810115367, 0.0, 0.0164930559694767, 0.00021701389050576836, 0.02560763992369175, 0.0, 0.0212673619389534, 0.8930121660232544, 0.0355902798473835, 0.0, 0.0444878488779068, 0.00021701389050576836, 0.0, 0.00021701389050576836, 0.0405815988779068, 0.924913227558136, 0.0, 0.0, 0.0872395858168602, 0.0833333358168602, 0.00021701389050576836, 0.03515625, 0.0, 0.119140625, 0.456597238779068, 0.005425347480922937, 0.00021701389050576836, 0.01779513992369175, 0.0, 0.0, 0.0514322929084301, 0.0, 0.002170138992369175, 0.0, 0.0, 0.00021701389050576836, 0.01822916604578495, 0.0, 0.0026041667442768812, 0.0, 0.0345052070915699, 0.0726996511220932, 0.206814244389534, 0.012369791977107525, 0.00933159701526165, 0.0726996511220932, 0.0, 0.0, 0.00021701389050576836, 0.02669270895421505, 0.0822482630610466, 0.029296875, 0.00390625, 0.0792100727558136, 0.0516493059694767, 0.0700954869389534, 0.0013020833721384406, 0.9442274570465088, 0.559678852558136, 0.0436197929084301, 0.0186631940305233, 0.0475260429084301, 0.0394965298473835, 0.0386284738779068, 0.0032552082557231188, 0.01801215298473835, 0.8220486044883728, 0.0, 0.0470920130610466, 0.0, 0.0, 0.02387152798473835, 0.02300347201526165, 0.0, 0.0, 0.0067274305038154125, 0.00021701389050576836, 0.015625, 0.0234375, 0.1015625, 0.03125, 0.00021701389050576836, 0.0106336809694767, 0.0464409738779068, 0.0325520820915699, 0.025390625, 0.0423177070915699, 0.02387152798473835, 0.0874565988779068, 0.1078559011220932, 0.011935763992369175, 0.0, 0.00434027798473835, 0.0028211805038154125, 0.0362413190305233, 0.0559895820915699, 0.62109375, 0.00824652798473835, 0.007595486007630825, 0.1115451380610466, 0.009548611007630825, 0.0167100690305233, 0.004123263992369175, 0.0, 0.01822916604578495, 0.0, 0.0444878488779068, 0.02669270895421505, 0.0334201380610466, 0.0, 0.0, 0.3155381977558136, 0.012803819961845875, 0.03515625, 0.00434027798473835, 0.00434027798473835, 0.0559895820915699, 0.0, 0.5258246660232544, 0.0, 0.002170138992369175, 0.0319010429084301, 0.0744357630610466, 0.0425347238779068, 0.02690972201526165, 0.0, 0.0340711809694767, 0.0401475690305233, 0.0225694440305233, 0.010416666977107525, 0.001953125, 0.296440988779068, 0.0, 0.0284288190305233, 0.0078125, 0.0010850694961845875, 0.0551215298473835, 0.1629774272441864, 0.00933159701526165, 0.0052083334885537624, 0.0362413190305233, 0.0319010429084301, 0.0184461809694767, 0.014756944961845875, 0.0, 0.0, 0.0323350690305233, 0.0049913194961845875, 0.8895399570465088, 0.015407986007630825, 0.01692708395421505, 0.00390625, 0.01215277798473835, 0.0477430559694767, 0.00021701389050576836, 0.0375434048473835, 0.01019965298473835, 0.0479600690305233, 0.0, 0.0004340277810115367, 0.00021701389050576836, 0.086805559694767, 0.0, 0.0, 0.021484375, 0.0, 0.0004340277810115367, 0.00021701389050576836, 0.02777777798473835, 0.0607638880610466, 0.0, 0.0, 0.02560763992369175, 0.00021701389050576836, 0.0290798619389534, 0.00021701389050576836, 0.01974826492369175, 0.0355902798473835, 0.02973090298473835, 0.01779513992369175, 0.02669270895421505, 0.00021701389050576836, 0.0, 0.03059895895421505, 0.02473958395421505, 0.0, 0.011067708022892475, 0.0026041667442768812, 0.0, 0.0010850694961845875, 0.0030381944961845875, 0.0, 0.056640625, 0.999131977558136, 0.005859375, 0.0067274305038154125, 0.0006510416860692203, 0.0, 0.0, 0.00021701389050576836, 0.00021701389050576836, 0.9989149570465088, 0.008463541977107525, 0.015407986007630825, 0.0559895820915699, 0.05859375, 0.0434027798473835, 0.0, 0.9997829794883728, 0.8075087070465088, 0.005642361007630825, 0.0, 0.0, 0.00021701389050576836, 0.048828125, 0.01692708395421505, 0.0, 0.0, 0.0368923619389534, 0.1174045130610466, 0.0008680555620230734, 0.0874565988779068, 0.0913628488779068, 0.0594618059694767, 0.00021701389050576836, 0.0, 0.0, 0.01019965298473835, 0.0, 0.0, 0.0590277798473835, 0.8559027910232544, 0.00021701389050576836, 0.0004340277810115367, 0.014322916977107525, 0.001953125, 0.0540364570915699, 0.0013020833721384406, 0.00390625, 0.0544704869389534, 0.00021701389050576836, 0.0861545130610466, 0.00021701389050576836, 0.067274309694767, 0.0813802108168602, 0.015407986007630825, 0.02886284701526165, 0.00390625, 0.00434027798473835, 0.0451388880610466, 0.0006510416860692203, 0.0, 0.5329861044883728, 0.0859375, 0.0416666679084301, 0.0, 0.0872395858168602, 0.4700520932674408, 0.0844184011220932, 0.0564236119389534, 0.0, 0.0145399309694767, 0.0065104165114462376, 0.0245225690305233, 0.0, 0.01019965298473835, 0.006076388992369175, 0.0, 0.00021701389050576836, 0.0, 0.0, 0.102430559694767, 0.0798611119389534, 0.0234375, 0.0013020833721384406, 0.0301649309694767, 0.0490451380610466, 0.0490451380610466, 0.0193142369389534, 0.1032986119389534, 0.0006510416860692203, 0.0421006940305233, 0.0, 0.0746527761220932, 0.0, 0.0, 0.006076388992369175, 0.0627170130610466, 0.0963541641831398, 0.0581597238779068, 0.0, 0.00021701389050576836, 0.03125, 0.014322916977107525, 0.0, 0.0036892362404614687, 0.008897569961845875, 0.00021701389050576836, 0.013454861007630825, 0.011501736007630825, 0.01974826492369175, 0.009765625, 0.00021701389050576836, 0.0978732630610466, 0.0006510416860692203, 0.0475260429084301, 0.4978298544883728, 0.00021701389050576836, 0.0017361111240461469, 0.01822916604578495, 0.0186631940305233, 0.0414496548473835, 0.02083333395421505, 0.02018229104578495, 0.0023871527519077063, 0.044921875, 0.01822916604578495, 0.1256510466337204, 0.4602864682674408, 0.0438368059694767, 0.04296875, 0.00021701389050576836, 0.9986979365348816, 0.0342881940305233, 0.03081597201526165, 0.02669270895421505, 0.0, 0.0824652761220932, 0.0004340277810115367, 0.02886284701526165, 0.0375434048473835, 0.00021701389050576836, 0.0301649309694767, 0.0345052070915699, 0.0, 0.0008680555620230734, 0.0251736119389534, 0.0384114570915699, 0.134548619389534, 0.0316840298473835, 0.0, 0.013454861007630825, 0.0325520820915699, 0.02105034701526165, 0.02734375, 0.0347222238779068, 0.0036892362404614687, 0.0, 0.0952690988779068, 0.05078125, 0.012803819961845875, 0.0737847238779068, 0.0768229141831398, 0.0006510416860692203, 0.00021701389050576836, 0.0594618059694767, 0.0, 0.0034722222480922937, 0.0353732630610466, 0.0232204869389534, 0.00021701389050576836, 0.2628038227558136, 0.0052083334885537624, 0.0709635391831398, 0.00021701389050576836, 0.0049913194961845875, 0.0, 0.02777777798473835, 0.0399305559694767, 0.0, 0.9995659589767456, 0.02278645895421505, 0.0015190972480922937, 0.0, 0.0067274305038154125, 0.04296875, 0.00629340298473835, 0.0345052070915699, 0.02864583395421505, 0.01692708395421505, 0.1336805522441864, 0.1338975727558136, 0.0, 0.0418836809694767, 0.2782118022441864, 0.0, 0.4529079794883728, 0.0696614608168602, 0.9989149570465088, 0.0358072929084301, 0.0, 0.0023871527519077063, 0.002170138992369175, 0.072265625, 0.0030381944961845875, 0.00021701389050576836, 0.02365451492369175, 0.0, 0.0557725690305233, 0.0492621548473835, 0.0030381944961845875, 0.068359375, 0.0418836809694767, 0.02560763992369175, 0.0, 0.00021701389050576836, 0.0564236119389534, 0.02495659701526165, 0.1041666641831398, 0.0067274305038154125, 0.0316840298473835, 0.0362413190305233, 0.0861545130610466, 0.086805559694767, 0.9982638955116272, 0.00021701389050576836, 0.0026041667442768812, 0.0379774309694767, 0.0, 0.0, 0.0924479141831398, 0.00021701389050576836, 0.011935763992369175, 0.542100727558136, 0.02799479104578495, 0.0245225690305233, 0.0345052070915699, 0.1148003488779068, 0.0, 0.0, 0.0401475690305233, 0.01801215298473835, 0.0687934011220932, 0.0397135429084301, 0.0403645820915699, 0.0438368059694767, 0.7076823115348816, 0.009114583022892475, 0.0501302070915699, 0.0451388880610466, 0.0377604179084301, 0.0, 0.10546875, 0.9997829794883728, 0.0004340277810115367, 0.0234375, 0.00021701389050576836, 0.0032552082557231188, 0.0264756940305233, 0.0, 0.0442708320915699, 0.0032552082557231188, 0.0536024309694767, 0.0, 0.00021701389050576836, 0.0, 0.0729166641831398, 0.0301649309694767, 0.01953125, 0.0010850694961845875, 0.0026041667442768812, 0.8969184160232544, 0.0700954869389534, 0.0538194440305233, 0.0223524309694767, 0.0614149309694767, 0.0, 0.0, 0.0, 0.0334201380610466, 0.065321184694767, 0.014322916977107525, 0.0342881940305233, 0.0, 0.0855034738779068, 0.00021701389050576836, 0.0065104165114462376, 0.0516493059694767, 0.126953125, 0.0998263880610466, 0.0, 0.00021701389050576836, 0.0, 0.00390625, 0.0008680555620230734, 0.0755208358168602, 0.0, 0.0544704869389534, 0.0609809048473835]

 sparsity of   [0.21484375, 0.009765625, 0.080078125, 0.041015625, 0.044921875, 0.01171875, 0.0, 0.04296875, 0.029296875, 0.01171875, 0.064453125, 0.017578125, 0.01171875, 0.017578125, 0.0859375, 0.0390625, 0.02734375, 0.03125, 0.060546875, 0.001953125, 0.994140625, 0.05078125, 0.060546875, 0.1484375, 0.01171875, 0.052734375, 0.046875, 0.955078125, 0.04296875, 0.083984375, 0.01171875, 0.0859375, 0.017578125, 0.02734375, 0.015625, 0.998046875, 0.04296875, 0.0546875, 0.0546875, 0.16015625, 0.013671875, 0.12890625, 0.037109375, 0.03515625, 0.076171875, 0.06640625, 0.046875, 0.017578125, 0.0078125, 0.01953125, 0.169921875, 0.07421875, 0.025390625, 0.16015625, 0.138671875, 0.064453125, 0.205078125, 0.048828125, 0.005859375, 0.15625, 0.7890625, 0.4296875, 0.474609375, 0.04296875, 0.025390625, 0.00390625, 0.0234375, 0.083984375, 0.115234375, 0.94921875, 0.416015625, 0.005859375, 0.02734375, 0.015625, 0.029296875, 0.001953125, 0.833984375, 0.09765625, 0.017578125, 0.033203125, 0.89453125, 0.03125, 0.017578125, 0.02734375, 0.02734375, 0.51171875, 0.830078125, 0.048828125, 0.0234375, 0.037109375, 0.833984375, 0.009765625, 0.015625, 0.169921875, 0.005859375, 0.05078125, 0.01953125, 0.361328125, 0.029296875, 0.015625, 0.017578125, 0.078125, 0.15234375, 0.001953125, 0.060546875, 0.005859375, 0.0390625, 0.0703125, 0.02734375, 0.033203125, 0.998046875, 0.396484375, 0.03515625, 0.009765625, 0.013671875, 0.001953125, 0.015625, 0.033203125, 0.009765625, 0.85546875, 0.01171875, 0.814453125, 0.041015625, 0.01171875, 0.02734375, 0.033203125, 0.017578125, 0.083984375, 0.0234375, 0.009765625, 0.04296875, 0.09765625, 0.02734375, 0.046875, 0.037109375, 0.037109375, 0.048828125, 0.033203125, 0.013671875, 0.0234375, 0.001953125, 0.091796875, 0.09765625, 0.05078125, 0.021484375, 0.93359375, 0.052734375, 0.150390625, 0.068359375, 0.8125, 0.015625, 0.052734375, 0.00390625, 0.0234375, 0.056640625, 0.2421875, 0.0625, 0.103515625, 0.064453125, 0.017578125, 0.00390625, 0.05078125, 0.0625, 0.640625, 0.037109375, 0.638671875, 0.0390625, 0.052734375, 0.115234375, 0.0546875, 0.291015625, 0.0390625, 0.083984375, 0.087890625, 0.00390625, 0.099609375, 0.1015625, 0.021484375, 0.994140625, 0.017578125, 0.267578125, 0.005859375, 0.083984375, 0.01171875, 0.119140625, 0.01953125, 0.078125, 0.01953125, 0.046875, 0.998046875, 0.107421875, 0.140625, 0.994140625, 0.087890625, 0.064453125, 0.07421875, 0.875, 0.1015625, 0.03125, 0.044921875, 0.017578125, 0.01953125, 0.7265625, 0.603515625, 0.0625, 0.015625, 0.025390625, 0.03125, 0.103515625, 0.07421875, 0.01171875, 0.052734375, 0.0234375, 0.9296875, 0.03125, 0.0390625, 0.095703125, 0.03125, 0.03515625, 0.0703125, 0.01171875, 0.013671875, 0.0234375, 0.041015625, 0.009765625, 0.052734375, 0.068359375, 0.072265625, 0.046875, 0.021484375, 0.056640625, 0.03125, 0.04296875, 0.0390625, 0.09765625, 0.111328125, 0.08984375, 0.763671875, 0.04296875, 0.994140625, 0.03125, 0.08984375, 0.005859375, 0.06640625, 0.015625, 0.220703125, 0.994140625, 0.796875, 0.013671875, 0.994140625, 0.03125, 0.125, 0.013671875, 0.025390625, 0.0078125, 0.037109375, 0.046875, 0.224609375, 0.578125, 0.11328125, 0.017578125, 0.017578125, 0.529296875, 0.0078125, 0.037109375, 0.013671875, 0.025390625, 0.03125, 0.744140625, 0.025390625, 0.013671875, 0.15234375, 0.876953125, 0.099609375, 0.447265625, 0.103515625, 0.03125, 0.025390625, 0.025390625, 0.15234375, 0.169921875, 0.8984375, 0.99609375, 0.09765625, 0.08203125, 0.02734375, 0.04296875, 0.037109375, 0.94140625, 0.025390625, 0.017578125, 0.087890625, 0.01171875, 0.029296875, 0.021484375, 0.021484375, 0.044921875, 0.61328125, 0.013671875, 0.0078125, 0.02734375, 0.12109375, 0.09375, 0.017578125, 0.025390625, 0.087890625, 0.17578125, 0.115234375, 0.056640625, 0.0234375, 0.037109375, 0.1875, 0.04296875, 0.025390625, 0.146484375, 0.017578125, 0.048828125, 0.0078125, 0.1015625, 0.029296875, 0.046875, 0.068359375, 0.06640625, 0.0, 0.115234375, 0.04296875, 0.564453125, 0.029296875, 0.02734375, 0.029296875, 0.029296875, 0.158203125, 0.00390625, 0.80859375, 0.0078125, 0.0546875, 0.5703125, 0.056640625, 0.0, 0.0078125, 0.017578125, 0.0, 0.080078125, 0.30859375, 0.052734375, 0.0390625, 0.708984375, 0.9453125, 0.06640625, 0.04296875, 0.103515625, 0.083984375, 0.09375, 0.029296875, 0.095703125, 0.0078125, 0.03515625, 0.998046875, 0.0390625, 0.927734375, 0.296875, 0.009765625, 0.0546875, 0.033203125, 0.005859375, 0.0390625, 0.0234375, 0.994140625, 0.03125, 0.919921875, 0.046875, 0.091796875, 0.849609375, 0.021484375, 0.017578125, 0.009765625, 0.76953125, 0.119140625, 0.00390625, 0.103515625, 0.15234375, 0.89453125, 0.056640625, 0.083984375, 0.09765625, 0.03515625, 0.212890625, 0.044921875, 0.001953125, 0.896484375, 0.109375, 0.5703125, 0.06640625, 0.041015625, 0.013671875, 0.0546875, 0.869140625, 0.015625, 0.072265625, 0.044921875, 0.0546875, 0.072265625, 0.041015625, 0.05859375, 0.0703125, 0.140625, 0.03515625, 0.0078125, 0.123046875, 0.1796875, 0.03515625, 0.0234375, 0.015625, 0.064453125, 0.091796875, 0.013671875, 0.01171875, 0.994140625, 0.021484375, 0.083984375, 0.04296875, 0.126953125, 0.029296875, 0.015625, 0.607421875, 0.015625, 0.73828125, 0.01953125, 0.404296875, 0.041015625, 0.146484375, 0.064453125, 0.0078125, 0.044921875, 0.05859375, 0.091796875, 0.033203125, 0.0390625, 0.021484375, 0.01953125, 0.033203125, 0.0390625, 0.52734375, 0.005859375, 0.287109375, 0.0390625, 0.013671875, 0.791015625, 0.22265625, 0.029296875, 0.03515625, 0.02734375, 0.033203125, 0.048828125, 0.078125, 0.052734375, 0.029296875, 0.83203125, 0.005859375, 0.005859375, 0.998046875, 0.001953125, 0.037109375, 0.02734375, 0.9296875, 0.06640625, 0.005859375, 0.009765625, 0.046875, 0.013671875, 0.0390625, 0.029296875, 0.271484375, 0.001953125, 0.0625, 0.060546875, 0.01171875, 0.94921875, 0.09765625, 0.083984375, 0.025390625, 0.697265625, 0.0390625, 0.017578125, 0.994140625, 0.99609375, 0.203125, 0.025390625, 0.037109375, 0.095703125, 0.05078125, 0.0234375, 0.041015625, 0.080078125, 0.037109375, 0.05078125, 0.2578125, 0.015625, 0.048828125, 0.369140625, 0.013671875, 0.02734375, 0.009765625, 0.7578125, 0.017578125, 0.021484375, 0.087890625, 0.025390625, 0.615234375, 0.046875, 0.119140625, 0.05078125, 0.001953125, 0.662109375, 0.03125, 0.15625, 0.0390625, 0.015625, 0.994140625, 0.142578125, 0.01171875, 0.107421875, 0.017578125, 0.109375, 0.046875, 0.423828125, 0.16015625, 0.109375, 0.037109375, 0.05078125, 0.048828125, 0.0234375, 0.048828125, 0.060546875, 0.041015625, 0.0546875, 0.060546875, 0.033203125, 0.05078125, 0.060546875, 0.056640625, 0.06640625, 0.009765625, 0.08984375, 0.046875, 0.025390625, 0.01953125, 0.927734375, 0.146484375, 0.01171875, 0.51953125, 0.037109375, 0.99609375, 0.00390625, 0.03125, 0.12890625, 0.048828125, 0.033203125, 0.044921875, 0.076171875, 0.0234375, 0.015625, 0.03515625, 0.068359375, 0.021484375, 0.02734375, 0.0234375, 0.041015625, 0.02734375, 0.01953125, 0.056640625, 0.572265625, 0.103515625, 0.06640625, 0.03125, 0.5625, 0.009765625, 0.91796875, 0.126953125, 0.09765625, 0.01171875, 0.001953125, 0.015625, 0.015625, 0.0078125, 0.02734375, 0.0546875, 0.11328125, 0.037109375, 0.052734375, 0.00390625, 0.654296875, 0.0703125, 0.052734375, 0.013671875, 0.0234375, 0.0234375, 0.013671875, 0.08984375, 0.0078125, 0.03515625, 0.00390625, 0.009765625, 0.017578125, 0.994140625, 0.541015625, 0.0546875, 0.13671875, 0.033203125, 0.013671875, 0.998046875, 0.05078125, 0.017578125, 0.08203125, 0.015625, 0.017578125, 0.10546875, 0.0234375, 0.23046875, 0.05859375, 0.921875, 0.369140625, 0.0, 0.076171875, 0.0390625, 0.0546875, 0.009765625, 0.1015625, 0.234375, 0.80078125, 0.994140625, 0.029296875, 0.068359375, 0.103515625, 0.03125, 0.001953125, 0.994140625, 0.052734375, 0.109375, 0.29296875, 0.67578125, 0.07421875, 0.03125, 0.166015625, 0.005859375, 0.052734375, 0.25390625, 0.02734375, 0.068359375, 0.01953125, 0.025390625, 0.03125, 0.056640625, 0.0078125, 0.02734375, 0.033203125, 0.064453125, 0.01171875, 0.009765625, 0.0234375, 0.0546875, 0.078125, 0.005859375, 0.03515625, 0.791015625, 0.841796875, 0.0078125, 0.037109375, 0.568359375, 0.0234375, 0.03125, 0.064453125, 0.01171875, 0.02734375, 0.013671875, 0.06640625, 0.01171875, 0.01953125, 0.021484375, 0.03515625, 0.017578125, 0.01171875, 0.03125, 0.337890625, 0.837890625, 0.107421875, 0.029296875, 0.0078125, 0.060546875, 0.056640625, 0.228515625, 0.12890625, 0.015625, 0.23046875, 0.076171875, 0.029296875, 0.994140625, 0.06640625, 0.02734375, 0.060546875, 0.09765625, 0.533203125, 0.005859375, 0.044921875, 0.037109375, 0.265625, 0.021484375, 0.01953125, 0.005859375, 0.994140625, 0.037109375, 0.029296875, 0.03125, 0.134765625, 0.01953125, 0.79296875, 0.00390625, 0.060546875, 0.009765625, 0.017578125, 0.041015625, 0.166015625, 0.009765625, 0.04296875, 0.71484375, 0.099609375, 0.181640625, 0.904296875, 0.134765625, 0.021484375, 0.134765625, 0.220703125, 0.0078125, 0.03515625, 0.052734375, 0.181640625, 0.0078125, 0.037109375, 0.021484375, 0.02734375, 0.994140625, 0.017578125, 0.052734375, 0.037109375, 0.087890625, 0.017578125, 0.1171875, 0.041015625, 0.046875, 0.095703125, 0.0703125, 0.025390625, 0.650390625, 0.03515625, 0.14453125, 0.021484375, 0.029296875, 0.998046875, 0.037109375, 0.005859375, 0.01171875, 0.015625, 0.052734375, 0.0546875, 0.091796875, 0.923828125, 0.994140625, 0.1015625, 0.03515625, 0.0234375, 0.18359375, 0.0234375, 0.1796875, 0.02734375, 0.99609375, 0.541015625, 0.162109375, 0.859375, 0.08984375, 0.013671875, 0.33203125, 0.01953125, 0.0390625, 0.06640625, 0.00390625, 0.03125, 0.2578125, 0.0859375, 0.013671875, 0.126953125, 0.046875, 0.01171875, 0.044921875, 0.18359375, 0.16015625, 0.16015625, 0.005859375, 0.041015625, 0.03125, 0.994140625, 0.138671875, 0.59765625, 0.017578125, 0.0546875, 0.0625, 0.046875, 0.171875, 0.05078125, 0.994140625, 0.044921875, 0.04296875, 0.017578125, 0.99609375, 0.765625, 0.0234375, 0.037109375, 0.00390625, 0.994140625, 0.029296875, 0.0078125, 0.07421875, 0.046875, 0.017578125, 0.01171875, 0.017578125, 0.041015625, 0.029296875, 0.041015625, 0.779296875, 0.009765625, 0.42578125, 0.6796875, 0.052734375, 0.0390625, 0.03125, 0.111328125, 0.009765625, 0.0078125, 0.03515625, 0.994140625, 0.595703125, 0.029296875, 0.033203125, 0.876953125, 0.869140625, 0.052734375, 0.037109375, 0.9765625, 0.0078125, 0.056640625, 0.01171875, 0.041015625, 0.005859375, 0.6953125, 0.03125, 0.025390625, 0.173828125, 0.03125, 0.03125, 0.111328125, 0.0234375, 0.103515625, 0.052734375, 0.021484375, 0.060546875, 0.09765625, 0.0390625, 0.99609375, 0.029296875, 0.005859375, 0.59375, 0.046875, 0.744140625, 0.84765625, 0.0390625, 0.017578125, 0.001953125, 0.15234375, 0.021484375, 0.060546875, 0.05078125, 0.109375, 0.017578125, 0.0703125, 0.05859375, 0.125, 0.02734375, 0.03125, 0.041015625, 0.068359375, 0.033203125, 0.828125, 0.306640625, 0.04296875, 0.021484375, 0.037109375, 0.673828125, 0.0234375, 0.029296875, 0.044921875, 0.046875, 0.998046875, 0.025390625, 0.02734375, 0.0234375, 0.029296875, 0.01171875, 0.017578125, 0.05078125, 0.14453125, 0.92578125, 0.99609375, 0.044921875, 0.0390625, 0.03515625, 0.029296875, 0.11328125, 0.025390625, 0.107421875, 0.173828125, 0.01171875, 0.080078125, 0.662109375, 0.0078125, 0.763671875, 0.5703125, 0.02734375, 0.05859375, 0.30859375, 0.05078125, 0.029296875, 0.033203125, 0.064453125, 0.01171875, 0.107421875, 0.19140625, 0.02734375, 0.03125, 0.021484375, 0.01171875, 0.017578125, 0.10546875, 0.0078125, 0.126953125, 0.15234375, 0.029296875, 0.02734375, 0.150390625, 0.056640625, 0.001953125, 0.03515625, 0.044921875, 0.01953125, 0.04296875, 0.005859375, 0.044921875, 0.10546875, 0.05859375, 0.044921875, 0.763671875, 0.037109375, 0.029296875, 0.064453125, 0.01171875, 0.05078125, 0.04296875, 0.099609375, 0.03125, 0.021484375, 0.001953125, 0.068359375, 0.873046875, 0.0390625, 0.01171875, 0.05859375, 0.01171875, 0.21484375, 0.01953125, 0.060546875, 0.0625, 0.05078125, 0.05859375, 0.033203125, 0.009765625, 0.015625, 0.98046875, 0.068359375, 0.0078125, 0.115234375, 0.859375, 0.0390625, 0.04296875, 0.876953125, 0.375, 0.79296875, 0.994140625, 0.033203125, 0.015625, 0.134765625, 0.099609375, 0.017578125, 0.197265625, 0.09765625, 0.048828125, 0.13671875, 0.01953125, 0.033203125, 0.154296875, 0.21484375, 0.021484375, 0.99609375, 0.025390625, 0.328125, 0.017578125, 0.560546875, 0.095703125, 0.009765625, 0.935546875, 0.16796875, 0.025390625, 0.080078125, 0.03515625, 0.837890625, 0.994140625, 0.345703125, 0.072265625, 0.021484375, 0.06640625, 0.03125, 0.578125, 0.337890625, 0.033203125, 0.041015625, 0.646484375, 0.09375, 0.015625, 0.916015625, 0.099609375, 0.02734375, 0.046875, 0.044921875, 0.015625, 0.052734375, 0.833984375, 0.025390625, 0.11328125, 0.853515625, 0.265625, 0.078125, 0.5078125, 0.150390625, 0.1484375, 0.005859375, 0.04296875, 0.12109375, 0.08984375, 0.216796875, 0.001953125, 0.041015625, 0.08984375, 0.822265625, 0.056640625, 0.02734375, 0.005859375, 0.0234375, 0.994140625, 0.2578125, 0.328125, 0.671875, 0.69921875, 0.029296875, 0.001953125, 0.033203125, 0.068359375, 0.07421875, 0.013671875, 0.0078125, 0.93359375, 0.0625, 0.001953125, 0.00390625, 0.0546875, 0.046875, 0.09375, 0.01953125, 0.013671875, 0.021484375, 0.0234375, 0.287109375, 0.646484375, 0.1484375, 0.095703125, 0.0234375, 0.025390625, 0.4609375, 0.1484375, 0.0703125, 0.01171875, 0.01953125, 0.083984375, 0.12109375, 0.06640625, 0.994140625, 0.0703125, 0.041015625, 0.0390625, 0.064453125, 0.056640625, 0.0625, 0.064453125, 0.107421875, 0.630859375, 0.025390625, 0.06640625, 0.052734375, 0.01953125, 0.767578125, 0.015625, 0.03515625, 0.021484375, 0.009765625, 0.1484375, 0.01953125, 0.927734375, 0.55859375, 0.994140625, 0.125, 0.126953125, 0.994140625, 0.994140625, 0.044921875, 0.138671875, 0.671875, 0.0390625, 0.1796875, 0.115234375, 0.060546875, 0.03515625, 0.080078125, 0.076171875, 0.037109375, 0.224609375, 0.271484375, 0.04296875, 0.33203125, 0.0078125, 0.10546875, 0.015625, 0.037109375, 0.017578125, 0.033203125, 0.0078125, 0.052734375, 0.3203125, 0.109375, 0.94921875, 0.0625, 0.951171875, 0.537109375, 0.69921875, 0.04296875, 0.068359375, 0.603515625, 0.634765625, 0.0625, 0.009765625, 0.009765625, 0.150390625, 0.06640625, 0.80859375, 0.033203125, 0.134765625, 0.052734375, 0.013671875, 0.171875, 0.150390625, 0.03515625, 0.099609375, 0.021484375, 0.03125, 0.177734375, 0.087890625, 0.0078125, 0.00390625, 0.013671875, 0.873046875, 0.6484375, 0.087890625, 0.005859375, 0.01953125, 0.109375, 0.03515625, 0.02734375, 0.01171875, 0.005859375, 0.341796875, 0.04296875, 0.099609375, 0.02734375, 0.009765625, 0.048828125, 0.171875, 0.0390625, 0.05078125, 0.041015625, 0.04296875, 0.033203125, 0.017578125, 0.703125, 0.02734375, 0.0390625, 0.0078125, 0.009765625, 0.02734375, 0.53125, 0.072265625, 0.015625, 0.98046875, 0.044921875, 0.01953125, 0.01171875, 0.01953125, 0.052734375, 0.03515625, 0.662109375, 0.00390625, 0.177734375, 0.021484375, 0.140625, 0.05859375, 0.037109375, 0.029296875, 0.01171875, 0.072265625, 0.01953125, 0.32421875, 0.009765625, 0.05859375, 0.0390625, 0.005859375, 0.056640625, 0.994140625, 0.265625, 0.1171875, 0.8984375, 0.005859375, 0.1796875, 0.0234375, 0.052734375, 0.994140625, 0.072265625, 0.166015625, 0.16015625, 0.04296875, 0.029296875, 0.041015625, 0.00390625, 0.013671875, 0.08984375, 0.119140625, 0.52734375, 0.025390625, 0.0546875, 0.05859375, 0.0, 0.0078125, 0.033203125, 0.1171875, 0.015625, 0.00390625, 0.0234375, 0.015625, 0.810546875, 0.18359375, 0.041015625, 0.998046875, 0.759765625, 0.00390625, 0.029296875, 0.119140625, 0.0078125, 0.998046875, 0.138671875, 0.28125, 0.05859375, 0.2890625, 0.0, 0.30078125, 0.0234375, 0.01171875, 0.044921875, 0.126953125, 0.064453125, 0.041015625, 0.00390625, 0.037109375, 0.99609375, 0.01171875, 0.0546875, 0.037109375, 0.13671875, 0.109375, 0.02734375, 0.072265625, 0.029296875, 0.03125, 0.15625, 0.05078125, 0.056640625, 0.13671875, 0.029296875, 0.0390625, 0.01953125, 0.07421875, 0.01953125, 0.02734375, 0.013671875, 0.005859375, 0.03125, 0.041015625, 0.03515625, 0.025390625, 0.060546875, 0.02734375, 0.021484375, 0.029296875, 0.03515625, 0.0234375, 0.0234375, 0.041015625, 0.017578125, 0.025390625, 0.0234375, 0.04296875, 0.01953125, 0.03125, 0.056640625, 0.0390625, 0.732421875, 0.005859375, 0.09375, 0.017578125, 0.052734375, 0.162109375, 0.60546875, 0.994140625, 0.029296875, 0.779296875, 0.12890625, 0.009765625, 0.052734375, 0.53515625, 0.037109375, 0.029296875, 0.185546875, 0.103515625, 0.109375, 0.185546875, 0.06640625, 0.04296875, 0.033203125, 0.107421875, 0.029296875, 0.150390625, 0.01953125, 0.01953125, 0.01171875, 0.05078125, 0.013671875, 0.01171875, 0.0078125, 0.017578125, 0.91015625, 0.658203125, 0.044921875, 0.029296875, 0.48046875, 0.07421875, 0.494140625, 0.06640625, 0.03125, 0.06640625, 0.029296875, 0.0625, 0.0, 0.009765625, 0.0703125, 0.048828125, 0.01953125, 0.01171875, 0.033203125, 0.123046875, 0.00390625, 0.009765625, 0.015625, 0.0234375, 0.021484375, 0.59765625, 0.08203125, 0.080078125, 0.994140625, 0.140625, 0.115234375, 0.017578125, 0.447265625, 0.220703125, 0.05078125, 0.029296875, 0.046875, 0.126953125, 0.013671875, 0.025390625, 0.10546875, 0.03515625, 0.01953125, 0.017578125, 0.03125, 0.08984375, 0.05078125, 0.0, 0.076171875, 0.07421875, 0.08984375, 0.091796875, 0.02734375, 0.005859375, 0.033203125, 0.033203125, 0.994140625, 0.994140625, 0.095703125, 0.060546875, 0.01171875, 0.02734375, 0.06640625, 0.06640625, 0.994140625, 0.033203125, 0.287109375, 0.060546875, 0.6796875, 0.111328125, 0.029296875, 0.056640625, 0.078125, 0.025390625, 0.234375, 0.109375, 0.998046875, 0.0859375, 0.017578125, 0.03125, 0.044921875, 0.994140625, 0.076171875, 0.01953125, 0.013671875, 0.69921875, 0.0546875, 0.08984375, 0.10546875, 0.048828125, 0.138671875, 0.00390625, 0.048828125, 0.078125, 0.041015625, 0.03515625, 0.708984375, 0.03125, 0.142578125, 0.109375, 0.107421875, 0.078125, 0.021484375, 0.021484375, 0.013671875, 0.017578125, 0.0703125, 0.99609375, 0.001953125, 0.029296875, 0.13671875, 0.037109375, 0.060546875, 0.06640625, 0.037109375, 0.0, 0.05859375, 0.087890625, 0.013671875, 0.033203125, 0.08984375, 0.029296875, 0.078125, 0.052734375, 0.048828125, 0.14453125, 0.033203125, 0.099609375, 0.0078125, 0.224609375, 0.41015625, 0.09375, 0.146484375, 0.994140625, 0.05859375, 0.021484375, 0.099609375, 0.052734375, 0.138671875, 0.03515625, 0.74609375, 0.75, 0.0703125, 0.076171875, 0.01953125, 0.0546875, 0.19140625, 0.013671875, 0.994140625, 0.041015625, 0.072265625, 0.076171875, 0.021484375, 0.001953125, 0.072265625, 0.052734375, 0.009765625, 0.994140625, 0.0703125, 0.017578125, 0.005859375, 0.025390625, 0.080078125, 0.0078125, 0.11328125, 0.025390625, 0.037109375, 0.041015625, 0.056640625, 0.1015625, 0.158203125, 0.044921875, 0.03515625, 0.994140625, 0.0859375, 0.06640625, 0.0390625, 0.017578125, 0.6875, 0.3203125, 0.1953125, 0.189453125, 0.095703125, 0.01953125, 0.025390625, 0.03515625, 0.29296875, 0.056640625, 0.00390625, 0.998046875, 0.240234375, 0.041015625, 0.853515625, 0.056640625, 0.12109375, 0.03515625, 0.009765625, 0.0234375, 0.0390625, 0.03125, 0.033203125, 0.689453125, 0.017578125, 0.017578125, 0.734375, 0.0703125, 0.810546875, 0.009765625, 0.998046875, 0.0234375, 0.203125, 0.015625, 0.025390625, 0.04296875, 0.04296875, 0.09375, 0.04296875, 0.037109375, 0.845703125, 0.02734375, 0.02734375, 0.017578125, 0.048828125, 0.11328125, 0.10546875, 0.09375, 0.021484375, 0.0390625, 0.62890625, 0.0390625, 0.041015625, 0.244140625, 0.99609375, 0.2421875, 0.01171875, 0.126953125, 0.138671875, 0.060546875, 0.013671875, 0.015625, 0.34765625, 0.673828125, 0.998046875, 0.013671875, 0.009765625, 0.025390625, 0.021484375, 0.03515625, 0.189453125, 0.0390625, 0.166015625, 0.048828125, 0.08203125, 0.068359375, 0.056640625, 0.056640625, 0.01953125, 0.068359375, 0.140625, 0.91796875, 0.001953125, 0.087890625, 0.0390625, 0.998046875, 0.166015625, 0.078125, 0.115234375, 0.19921875, 0.025390625, 0.666015625, 0.99609375, 0.85546875, 0.13671875, 0.025390625, 0.02734375, 0.072265625, 0.12890625, 0.015625, 0.212890625, 0.03125, 0.021484375, 0.107421875, 0.076171875, 0.1796875, 0.0546875, 0.05859375, 0.126953125, 0.994140625, 0.037109375, 0.03125, 0.736328125, 0.16015625, 0.169921875, 0.080078125, 0.998046875, 0.05078125, 0.05859375, 0.05078125, 0.015625, 0.033203125, 0.013671875, 0.01953125, 0.189453125, 0.1171875, 0.0390625, 0.015625, 0.009765625, 0.02734375, 0.9296875, 0.87109375, 0.76171875, 0.0625, 0.083984375, 0.076171875, 0.07421875, 0.037109375, 0.12109375, 0.029296875, 0.01953125, 0.6953125, 0.06640625, 0.021484375, 0.046875, 0.03125, 0.046875, 0.0390625, 0.142578125, 0.38671875, 0.994140625, 0.080078125, 0.021484375, 0.12109375, 0.078125, 0.076171875, 0.001953125, 0.052734375, 0.01171875, 0.04296875, 0.041015625, 0.025390625, 0.03125, 0.994140625, 0.013671875, 0.0, 0.17578125, 0.55859375, 0.001953125, 0.875, 0.8671875, 0.01953125, 0.119140625, 0.658203125, 0.01953125, 0.0078125, 0.0078125, 0.095703125, 0.060546875, 0.07421875, 0.08984375, 0.095703125, 0.02734375, 0.0078125, 0.03125, 0.01953125, 0.013671875, 0.109375, 0.28515625, 0.046875, 0.013671875, 0.044921875, 0.064453125, 0.09765625, 0.064453125, 0.599609375, 0.970703125, 0.001953125, 0.81640625, 0.001953125, 0.115234375, 0.19921875, 0.068359375, 0.005859375, 0.005859375, 0.03125, 0.0390625, 0.0390625, 0.09375, 0.03515625, 0.921875, 0.029296875, 0.18359375, 0.5859375, 0.01171875, 0.01171875, 0.05078125, 0.0625, 0.056640625, 0.01953125, 0.716796875, 0.04296875, 0.0703125, 0.02734375, 0.01171875, 0.080078125, 0.134765625, 0.49609375, 0.0390625, 0.158203125, 0.01171875, 0.056640625, 0.08203125, 0.046875, 0.0390625, 0.11328125, 0.005859375, 0.05859375, 0.03515625, 0.005859375, 0.994140625, 0.0, 0.166015625, 0.091796875, 0.046875, 0.091796875, 0.017578125, 0.078125, 0.0625, 0.029296875, 0.10546875, 0.1640625, 0.03125, 0.18359375, 0.166015625, 0.10546875, 0.05859375, 0.09765625, 0.845703125, 0.994140625, 0.001953125, 0.01171875, 0.076171875, 0.0390625, 0.0859375, 0.994140625, 0.212890625, 0.34765625, 0.064453125, 0.005859375, 0.03125, 0.025390625, 0.091796875, 0.07421875, 0.5, 0.05859375, 0.01953125, 0.0546875, 0.474609375, 0.154296875, 0.05859375, 0.068359375, 0.033203125, 0.0234375, 0.103515625, 0.060546875, 0.138671875, 0.994140625, 0.06640625, 0.0078125, 0.04296875, 0.017578125, 0.166015625, 0.10546875, 0.033203125, 0.068359375, 0.0390625, 0.994140625, 0.994140625, 0.017578125, 0.060546875, 0.99609375, 0.01171875, 0.93359375, 0.00390625, 0.095703125, 0.0625, 0.0078125, 0.025390625, 0.041015625, 0.021484375, 0.025390625, 0.08203125, 0.779296875, 0.048828125, 0.056640625, 0.021484375, 0.11328125, 0.05859375, 0.908203125, 0.052734375, 0.025390625, 0.046875, 0.076171875, 0.029296875, 0.775390625, 0.0703125, 0.099609375, 0.033203125, 0.0390625, 0.876953125, 0.55859375, 0.0234375, 0.015625, 0.046875, 0.087890625, 0.009765625, 0.05859375, 0.626953125, 0.029296875, 0.009765625, 0.087890625, 0.021484375, 0.138671875, 0.01171875, 0.01953125, 0.025390625, 0.01171875, 0.064453125, 0.05078125, 0.0234375, 0.015625, 0.083984375, 0.8203125, 0.01171875, 0.02734375, 0.0390625, 0.783203125, 0.1796875, 0.12109375, 0.02734375, 0.0078125, 0.9765625, 0.998046875, 0.158203125, 0.634765625, 0.0078125, 0.033203125, 0.369140625, 0.0625, 0.12890625, 0.0, 0.03515625, 0.734375, 0.08203125, 0.03515625, 0.150390625, 0.05859375, 0.01953125, 0.048828125, 0.1171875, 0.037109375, 0.03125, 0.083984375, 0.021484375, 0.01171875, 0.876953125, 0.033203125, 0.05078125, 0.07421875, 0.0234375, 0.16015625, 0.419921875, 0.021484375, 0.037109375, 0.056640625, 0.00390625, 0.052734375, 0.689453125, 0.046875, 0.013671875, 0.994140625, 0.017578125, 0.013671875, 0.0546875, 0.05078125, 0.994140625, 0.001953125, 0.23046875, 0.048828125, 0.04296875, 0.017578125, 0.017578125, 0.076171875, 0.005859375, 0.8125, 0.501953125, 0.05078125, 0.00390625, 0.994140625, 0.052734375, 0.1015625, 0.005859375, 0.044921875, 0.560546875, 0.091796875, 0.076171875, 0.291015625, 0.17578125, 0.0625, 0.08203125, 0.05078125, 0.021484375, 0.11328125, 0.033203125, 0.03125, 0.138671875, 0.01171875, 0.0, 0.009765625, 0.0390625, 0.275390625, 0.0546875, 0.005859375, 0.044921875, 0.8828125, 0.083984375, 0.044921875, 0.033203125, 0.03515625, 0.033203125, 0.8125, 0.078125, 0.09375, 0.02734375, 0.048828125, 0.009765625, 0.224609375, 0.1171875, 0.322265625, 0.955078125, 0.998046875, 0.03515625, 0.009765625, 0.03125, 0.0078125, 0.162109375, 0.03125, 0.01953125, 0.99609375, 0.03515625, 0.01171875, 0.05859375, 0.0390625, 0.033203125, 0.009765625, 0.0546875, 0.359375, 0.078125, 0.08984375, 0.03125, 0.140625, 0.994140625, 0.05859375, 0.025390625, 0.005859375, 0.087890625, 0.029296875, 0.123046875, 0.01953125, 0.119140625, 0.05859375, 0.06640625, 0.125, 0.005859375, 0.03515625, 0.08203125, 0.7265625]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Total parameter pruned: 6388855.015899286 (unstructured) 0 (structured)

max weight is  tensor([2.6314e-09, 2.4531e-01, 2.6314e-09, 2.6314e-09, 3.3023e-01, 5.7305e-09,
        2.6314e-09, 1.7055e-01, 5.7305e-09, 2.3408e-01, 1.6196e-08, 3.4694e-01,
        1.1235e-09, 2.4725e-02, 2.6314e-09, 2.0858e-09, 1.2749e-02, 3.1893e-01,
        3.2038e-01, 5.5812e-01, 2.4127e-01, 6.4603e-01, 1.7407e-01, 1.9499e-09,
        1.3928e-09, 2.6314e-09, 7.4235e-09, 4.6909e-03, 2.6314e-09, 1.3482e-08,
        1.0545e-01, 3.9042e-02, 4.3273e-09, 2.6314e-09, 5.6990e-09, 1.9391e-01,
        7.5328e-03, 1.2250e-02, 3.0118e-09, 2.8096e-01, 2.0227e-02, 1.2431e-01,
        1.1758e-01, 9.5509e-02, 2.6314e-09, 3.3206e-02, 3.0118e-09, 2.5672e-02,
        6.1077e-02, 1.7043e-01, 2.6314e-09, 3.3717e-02, 5.7569e-01, 5.5193e-09,
        1.4813e-08, 5.1254e-09, 3.0118e-09, 5.1228e-01, 1.5484e-01, 1.1650e-01,
        2.9522e-01, 5.7305e-09, 7.2834e-01, 2.6849e-01], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([2.3616e-08, 8.3420e-02, 6.9395e-08, 1.1264e-08, 5.9678e-02, 1.7698e-01,
        2.9693e-08, 1.9895e-08, 1.3759e-08, 1.3759e-08, 7.4998e-02, 1.2178e-08,
        1.4321e-01, 1.9895e-08, 2.3616e-08, 1.7788e-08, 1.0180e-01, 8.5362e-02,
        2.0662e-01, 3.4707e-08, 5.2158e-02, 1.4424e-01, 6.9395e-08, 3.4707e-08,
        2.3446e-01, 2.3616e-08, 2.0428e-08, 1.6989e-02, 5.0235e-08, 6.9395e-08,
        6.8067e-02, 3.7045e-09, 1.1275e-08, 1.3759e-08, 1.9895e-08, 1.2178e-08,
        1.2704e-08, 1.3759e-08, 1.3759e-08, 1.0262e-01, 6.9395e-08, 1.3759e-08,
        1.3759e-08, 1.0998e-01, 1.9895e-08, 1.6953e-01, 7.5590e-02, 7.8699e-03,
        2.3616e-08, 1.9713e-01, 7.3544e-02, 1.9937e-01, 2.9693e-08, 2.1241e-01,
        1.3759e-08, 7.2936e-02, 2.0428e-08, 1.2974e-01, 1.3760e-08, 6.9395e-08,
        2.3676e-02, 7.3310e-02, 1.7788e-08, 5.0234e-08], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([3.6411e-07, 4.6670e-07, 2.0357e-07, 3.7427e-01, 8.3992e-07, 3.3340e-07,
        3.8186e-07, 2.4486e-02, 8.2225e-07, 8.3992e-07, 4.7553e-02, 3.6411e-07,
        3.0206e-07, 3.6411e-07, 5.5129e-07, 4.4266e-07, 3.8186e-07, 3.8186e-07,
        3.0581e-02, 2.0206e-07, 9.2213e-02, 5.5129e-07, 2.2638e-07, 6.8293e-02,
        1.8091e-01, 2.0343e-07, 1.6908e-07, 6.6572e-07, 1.5089e-07, 2.4124e-01,
        1.5089e-07, 2.0206e-07, 3.6687e-02, 3.6411e-07, 3.0206e-07, 1.0762e-07,
        6.3035e-02, 3.2555e-07, 1.5089e-07, 2.0577e-07, 6.1500e-02, 3.6462e-02,
        1.0762e-07, 5.7960e-02, 1.5089e-07, 3.2101e-07, 4.6365e-02, 3.8186e-07,
        5.5129e-07, 1.6908e-07, 4.8314e-02, 2.1300e-02, 1.3231e-07, 2.5819e-07,
        2.8470e-02, 3.8186e-07, 3.0206e-07, 6.2064e-03, 5.0190e-02, 1.5089e-07,
        4.7538e-02, 1.6908e-07, 2.0577e-07, 5.5129e-07], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([5.0106e-03, 3.3260e-08, 7.9015e-10, 3.2850e-08, 1.0558e-07, 3.5220e-08,
        3.7016e-02, 2.3099e-02, 9.6897e-02, 3.3289e-02, 1.0755e-07, 1.6369e-02,
        2.2833e-08, 1.4639e-02, 1.6454e-02, 1.8781e-08, 5.2280e-08, 3.9240e-02,
        1.0328e-01, 3.8580e-08, 8.7125e-02, 1.2670e-02, 2.6163e-08, 1.3767e-07,
        2.4173e-02, 2.0106e-02, 3.5241e-08, 5.3371e-08, 3.3143e-08, 3.0265e-08,
        1.1983e-02, 4.1407e-02, 5.8245e-08, 2.2785e-02, 2.2755e-08, 2.7188e-02,
        4.6531e-08, 3.2686e-08, 3.0129e-08, 8.7787e-03, 3.7606e-02, 3.0310e-02,
        2.3503e-08, 6.0321e-02, 2.1073e-08, 4.5792e-08, 9.8036e-02, 1.3483e-08,
        3.1964e-03, 4.0715e-08, 2.6792e-08, 5.3371e-08, 1.9187e-01, 2.3354e-08,
        6.3831e-02, 3.5678e-08, 8.6220e-02, 5.6968e-02, 3.1579e-08, 2.4279e-08,
        1.6425e-02, 1.5398e-08, 7.8265e-02, 2.9195e-08, 1.0658e-07, 2.2592e-02,
        5.2950e-02, 1.4992e-02, 4.6790e-08, 3.2042e-02, 1.0082e-07, 3.7296e-02,
        6.3858e-08, 3.0115e-08, 1.3473e-01, 2.3867e-02, 2.7410e-08, 5.6949e-08,
        5.2460e-08, 2.7410e-08, 2.3332e-08, 5.0252e-02, 3.0129e-08, 8.1401e-02,
        8.1743e-08, 9.9866e-02, 3.2578e-02, 3.6521e-08, 5.8164e-02, 3.4455e-02,
        2.4279e-08, 3.6524e-08, 1.0558e-07, 2.3102e-03, 6.8984e-02, 5.3371e-08,
        3.5241e-08, 5.5446e-08, 1.0585e-02, 5.2154e-02, 6.8207e-08, 3.6756e-03,
        2.9143e-08, 7.1703e-08, 2.7214e-08, 6.3324e-08, 4.9541e-08, 3.3212e-08,
        2.6571e-02, 5.3371e-08, 1.5572e-02, 1.3618e-01, 9.0665e-02, 5.1241e-08,
        8.8964e-08, 4.0084e-02, 7.5879e-02, 3.5246e-02, 1.1057e-01, 1.4991e-01,
        2.6739e-08, 1.6657e-07, 3.5057e-08, 2.3332e-08, 4.3744e-02, 1.6105e-02,
        3.8976e-02, 1.0693e-07, 2.4587e-02, 4.8059e-02, 3.3260e-08, 9.2683e-03,
        1.8893e-08, 3.7382e-02, 4.1807e-02, 7.3535e-08, 4.1680e-03, 3.6524e-08,
        1.8467e-02, 1.0484e-07, 4.9196e-02, 1.3201e-07, 1.2062e-02, 6.0208e-08,
        1.8768e-02, 7.9680e-02, 4.6332e-08, 1.3036e-02, 2.1368e-06, 2.3533e-02,
        6.7435e-08, 1.6822e-08, 3.9464e-02, 1.9175e-08, 1.5090e-01, 6.2375e-08,
        2.2434e-02, 6.8023e-08, 7.3351e-08, 2.3257e-08, 2.1328e-08, 3.6259e-02,
        7.3351e-08, 1.2716e-02, 3.3260e-08, 5.2207e-03, 3.5980e-02, 4.8359e-08,
        3.7694e-02, 2.3421e-02, 3.7135e-08, 3.9319e-03, 2.6247e-08, 4.9955e-08,
        6.5156e-08, 2.5786e-08, 2.1355e-08, 3.6524e-08, 2.6739e-08, 3.5220e-08,
        2.3009e-02, 1.0661e-07, 1.2884e-01, 1.6370e-01, 1.4772e-02, 6.7281e-08,
        6.6434e-02, 7.4319e-08, 2.0741e-02, 7.3351e-08, 2.2872e-08, 3.8669e-08,
        3.3366e-08, 2.3354e-08, 2.9894e-08, 1.6822e-08, 2.1608e-01, 1.0069e-02,
        4.9383e-09, 5.0008e-08, 1.7128e-02, 2.9464e-02, 8.2725e-03, 2.4317e-02,
        2.3249e-02, 2.3354e-08, 6.8821e-08, 1.9092e-02, 3.8669e-08, 9.7348e-03,
        6.3268e-03, 1.6822e-08, 7.3351e-08, 2.9865e-02, 4.9147e-08, 8.3089e-08,
        2.3503e-08, 9.7360e-08, 1.7410e-02, 1.1671e-02, 1.5496e-02, 3.8496e-08,
        7.0452e-02, 1.6822e-08, 1.8071e-02, 4.9828e-02, 5.8807e-08, 3.2988e-08,
        5.4649e-08, 1.4190e-01, 3.8917e-08, 4.6878e-03, 7.4288e-02, 3.3272e-08,
        3.2141e-03, 1.5440e-02, 6.9168e-02, 9.7941e-02, 3.2368e-08, 3.3260e-08,
        1.0698e-01, 3.7527e-02, 3.9958e-02, 5.8245e-08, 2.0238e-08, 5.5662e-02,
        4.5430e-08, 6.9168e-02, 9.7851e-02, 1.0320e-01, 1.7192e-02, 5.6589e-08,
        4.6800e-02, 1.5605e-02, 2.8170e-02, 1.6537e-02], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([1.0781e-01, 3.8554e-08, 2.3866e-08, 5.8052e-02, 2.1409e-08, 3.2403e-08,
        8.2088e-02, 1.2287e-02, 9.6242e-02, 8.3657e-02, 5.6033e-02, 1.7683e-01,
        1.0943e-01, 1.6674e-01, 4.3629e-02, 4.2137e-02, 5.9616e-02, 1.6341e-01,
        6.0977e-02, 3.1895e-09, 4.2922e-02, 6.2848e-02, 2.0326e-08, 9.4696e-09,
        3.9909e-02, 6.6823e-02, 1.9589e-08, 8.3320e-09, 6.0054e-02, 3.9411e-09,
        1.4226e-01, 8.8651e-02, 1.6902e-02, 1.2328e-01, 3.9705e-02, 9.3500e-02,
        7.8829e-02, 2.7248e-02, 2.0465e-08, 1.7462e-01, 5.6353e-02, 9.9370e-02,
        3.8559e-08, 7.2655e-02, 3.8559e-08, 1.1745e-01, 1.3988e-01, 1.1785e-01,
        2.7070e-02, 3.9853e-04, 2.1122e-02, 3.8559e-08, 1.2078e-01, 2.0326e-08,
        4.6996e-02, 7.1346e-02, 1.3640e-01, 5.8733e-02, 4.9607e-02, 1.3502e-02,
        2.0242e-01, 2.3866e-08, 6.7259e-02, 6.6657e-09, 1.3111e-08, 1.2640e-02,
        7.1837e-02, 1.8648e-02, 6.6705e-02, 1.0761e-01, 1.3610e-01, 1.5635e-01,
        9.6200e-02, 3.4604e-02, 1.3479e-01, 2.8468e-02, 1.2941e-09, 2.7426e-02,
        4.2998e-02, 5.9616e-08, 3.2403e-08, 1.0164e-01, 2.1409e-08, 1.1007e-08,
        6.2969e-02, 1.3991e-01, 2.7312e-02, 9.2471e-02, 3.0470e-02, 5.8852e-02,
        2.3866e-08, 2.3866e-08, 2.3866e-08, 4.2988e-03, 1.0224e-01, 3.1887e-09,
        6.6657e-09, 1.5931e-01, 6.9162e-02, 1.4648e-01, 8.7378e-02, 1.0933e-01,
        8.1360e-02, 2.0326e-08, 1.1260e-01, 1.5986e-01, 2.1965e-08, 2.4955e-02,
        4.6342e-02, 2.3866e-08, 1.7452e-01, 1.4448e-02, 5.8285e-02, 2.1409e-08,
        1.1545e-02, 8.8822e-02, 1.0105e-01, 3.5583e-02, 9.1795e-02, 7.2159e-02,
        1.5471e-08, 9.0176e-02, 4.2878e-02, 1.5324e-08, 3.4486e-02, 1.3498e-02,
        9.1062e-02, 1.9589e-08, 1.8854e-01, 1.2864e-01, 2.3866e-08, 1.1445e-04,
        6.8978e-02, 1.9905e-01, 6.6942e-02, 1.0174e-01, 1.7621e-01, 2.1409e-08,
        9.8161e-03, 1.3111e-08, 5.6105e-02, 2.8833e-02, 1.7373e-01, 9.6670e-03,
        1.0550e-02, 1.4119e-02, 1.3525e-01, 6.4061e-02, 1.5192e-01, 6.5666e-02,
        1.0561e-01, 2.3866e-08, 1.1961e-01, 2.3004e-02, 9.6029e-02, 9.1410e-02,
        1.1999e-02, 6.0939e-02, 1.3377e-08, 2.3866e-08, 3.7359e-02, 1.6529e-01,
        2.1409e-08, 7.0822e-03, 2.3866e-08, 9.2361e-02, 8.4074e-02, 2.2744e-08,
        1.0035e-01, 1.2360e-02, 3.4226e-02, 1.5088e-01, 2.7786e-02, 2.3866e-08,
        9.4656e-02, 5.1878e-02, 1.2571e-01, 3.1969e-09, 2.1409e-08, 1.5324e-08,
        1.5981e-01, 9.9613e-09, 1.4474e-01, 1.3816e-01, 4.5759e-02, 1.7164e-02,
        6.5998e-02, 1.6907e-01, 3.3857e-01, 8.3320e-09, 2.6484e-02, 2.1965e-08,
        9.5041e-02, 2.3866e-08, 6.9153e-02, 2.3866e-08, 2.0801e-01, 1.0958e-01,
        1.5324e-08, 2.3866e-08, 4.7332e-02, 1.5481e-01, 1.1623e-01, 1.0898e-01,
        1.2167e-02, 2.6432e-08, 2.6450e-08, 3.2654e-02, 2.1409e-08, 1.6568e-01,
        6.0593e-02, 1.3111e-08, 8.3320e-09, 6.9818e-02, 8.9041e-09, 8.2446e-02,
        8.3320e-09, 9.5551e-02, 1.7707e-01, 1.5678e-02, 1.0591e-01, 3.6649e-02,
        8.9445e-02, 5.5090e-08, 1.8127e-02, 1.2163e-01, 9.6926e-09, 4.4415e-08,
        2.7341e-02, 6.0753e-02, 8.9500e-02, 4.1693e-03, 8.6802e-02, 5.0975e-02,
        5.4316e-02, 1.4855e-02, 1.2489e-01, 8.7605e-02, 4.7670e-02, 8.3320e-09,
        9.7831e-02, 9.9885e-02, 9.9235e-02, 1.5324e-08, 8.3320e-09, 6.7330e-02,
        2.5394e-02, 1.1964e-01, 1.2066e-01, 1.0827e-01, 1.1597e-08, 3.8557e-08,
        1.3824e-01, 6.6015e-03, 2.0622e-02, 1.7179e-01], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([2.6084e-02, 6.8661e-08, 4.3843e-08, 1.4211e-07, 8.2248e-08, 7.3039e-03,
        4.0257e-02, 2.0161e-07, 8.2082e-08, 2.0161e-07, 7.3551e-08, 3.2697e-02,
        1.2246e-07, 9.1294e-08, 2.1958e-07, 2.2772e-02, 2.1958e-07, 6.0819e-08,
        7.3551e-08, 2.5098e-02, 5.9177e-02, 2.1958e-07, 3.7478e-07, 4.3859e-02,
        4.3406e-08, 1.1553e-07, 3.3483e-02, 5.9862e-03, 6.0834e-02, 4.6530e-02,
        6.7344e-02, 2.3035e-07, 2.0991e-02, 4.6187e-02, 7.3551e-08, 6.0819e-08,
        1.9818e-02, 1.5825e-07, 1.2050e-03, 7.4189e-08, 2.8951e-02, 1.9704e-07,
        9.9775e-02, 1.6635e-07, 5.4384e-02, 6.5186e-08, 1.5407e-07, 2.3035e-07,
        5.0342e-02, 7.5269e-02, 8.8078e-03, 1.5032e-07, 8.4780e-08, 2.3035e-07,
        7.3551e-08, 6.8661e-08, 5.6504e-02, 6.2912e-02, 2.8610e-07, 3.1555e-02,
        1.8825e-07, 9.8952e-08, 2.0825e-07, 3.3853e-03], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([3.7911e-07, 7.4003e-02, 4.9582e-07, 8.9236e-08, 3.4748e-07, 1.6212e-07,
        1.2131e-07, 3.8115e-07, 4.5536e-07, 6.6955e-07, 1.3036e-07, 9.4891e-03,
        2.6187e-02, 1.2042e-01, 8.3631e-02, 2.1015e-07, 3.4748e-07, 1.1233e-07,
        6.1557e-02, 3.4748e-07, 3.7911e-07, 2.1015e-07, 2.1015e-07, 4.0383e-07,
        3.8115e-07, 1.3036e-07, 1.1391e-01, 2.0479e-07, 6.9860e-02, 3.7365e-02,
        1.1233e-07, 1.3036e-07, 3.0467e-07, 1.1417e-07, 4.1020e-02, 3.7911e-07,
        3.4748e-07, 2.5906e-01, 3.8115e-07, 6.9826e-02, 2.1015e-07, 1.1233e-07,
        6.1069e-02, 3.7911e-07, 6.1235e-07, 1.9065e-07, 6.4999e-02, 3.0467e-07,
        4.9582e-07, 3.4748e-07, 6.1010e-02, 2.1015e-07, 1.3036e-07, 1.3036e-07,
        1.1046e-01, 6.3758e-02, 3.2811e-02, 2.3110e-01, 1.0030e-07, 1.1233e-07,
        1.8379e-07, 4.9582e-07, 3.4748e-07, 3.5399e-07], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([8.0098e-02, 6.4424e-08, 6.7617e-02, 4.7568e-03, 3.6928e-08, 4.4606e-08,
        5.3524e-08, 1.8054e-02, 1.1163e-01, 8.8396e-03, 1.9120e-08, 1.8198e-02,
        1.3323e-02, 1.9118e-02, 4.5237e-08, 1.8096e-08, 6.0061e-08, 7.9273e-03,
        5.0400e-08, 2.2489e-08, 1.9284e-08, 7.7137e-08, 7.7302e-02, 5.0803e-08,
        5.3075e-02, 1.0315e-02, 4.8305e-08, 2.3538e-08, 4.4909e-02, 1.7703e-02,
        1.3673e-02, 8.4101e-02, 3.9451e-03, 9.8312e-03, 2.3233e-08, 8.9610e-02,
        4.0111e-02, 2.2157e-08, 8.6141e-08, 1.6311e-02, 3.1065e-08, 3.2064e-08,
        1.0086e-08, 5.7926e-02, 2.3712e-02, 1.0084e-01, 1.2673e-02, 2.1602e-02,
        7.1771e-08, 1.8369e-02, 2.6089e-08, 4.4607e-08, 1.6216e-02, 7.1390e-02,
        2.6560e-08, 3.5216e-08, 8.1649e-02, 3.8889e-02, 8.9683e-08, 5.8182e-03,
        1.8291e-02, 1.7635e-08, 4.8889e-02, 1.9039e-08, 3.3747e-02, 1.9500e-02,
        1.1135e-02, 5.4609e-08, 5.9240e-02, 1.3899e-02, 6.6776e-08, 1.0831e-01,
        1.1801e-02, 8.4221e-08, 2.4414e-02, 2.4711e-02, 1.1458e-01, 6.5520e-08,
        6.9472e-08, 1.7635e-08, 1.0870e-07, 7.5807e-02, 1.0822e-01, 4.9661e-08,
        1.0043e-07, 1.5792e-02, 2.4946e-02, 1.0176e-02, 9.5981e-02, 4.4042e-08,
        2.7283e-02, 4.6772e-08, 3.6679e-08, 1.7673e-01, 1.2094e-02, 3.8424e-08,
        4.4607e-08, 2.7935e-02, 1.9517e-02, 1.5110e-02, 5.5816e-08, 9.5467e-03,
        1.2832e-02, 4.4607e-08, 5.0738e-08, 1.7451e-02, 4.4607e-08, 3.9761e-08,
        4.4879e-08, 9.8323e-02, 2.6990e-02, 5.0838e-08, 1.0441e-02, 4.2957e-08,
        4.4529e-08, 2.6267e-02, 9.7445e-03, 4.7755e-02, 6.2280e-02, 3.9513e-02,
        1.9643e-01, 5.8629e-02, 3.0276e-08, 7.1669e-02, 1.2012e-02, 3.6969e-08,
        9.2903e-03, 5.1930e-08, 2.7616e-02, 1.2484e-02, 1.0870e-07, 3.5350e-08,
        5.1607e-02, 2.3865e-02, 1.2465e-08, 1.5405e-02, 1.2132e-02, 2.2489e-08,
        2.0965e-08, 3.6928e-08, 6.7057e-02, 6.1986e-08, 2.2544e-02, 6.7431e-03,
        2.0367e-02, 3.5684e-02, 8.8237e-03, 7.9134e-08, 9.6421e-03, 5.4353e-02,
        1.5855e-02, 1.9051e-08, 1.0131e-02, 1.9457e-02, 7.9767e-02, 4.2863e-08,
        1.8727e-02, 2.8070e-08, 1.7749e-01, 9.1601e-02, 5.7137e-08, 7.8328e-02,
        8.4293e-02, 1.7121e-02, 1.0870e-07, 4.1611e-08, 7.1698e-03, 1.7873e-07,
        2.5676e-02, 3.3064e-08, 1.7859e-08, 6.4293e-02, 3.7766e-08, 7.9350e-03,
        2.6083e-02, 3.1873e-08, 8.3677e-03, 6.1484e-02, 6.7513e-08, 2.1136e-08,
        1.2994e-02, 3.0312e-08, 1.2146e-02, 6.3358e-02, 1.4800e-08, 2.6172e-08,
        7.3282e-03, 1.3853e-02, 2.8124e-02, 4.6772e-08, 3.3789e-08, 1.0421e-02,
        6.2241e-08, 5.1097e-08, 2.1039e-08, 8.7039e-02, 1.0126e-02, 7.8047e-03,
        2.3079e-02, 9.7736e-08, 6.5710e-08, 8.7962e-03, 1.3239e-02, 8.0960e-03,
        1.0749e-02, 2.2489e-08, 4.5586e-02, 7.8676e-08, 6.9464e-08, 1.8141e-02,
        5.5231e-08, 5.1930e-08, 1.9791e-08, 8.5860e-03, 2.4052e-02, 3.2141e-03,
        1.6034e-01, 1.7934e-02, 2.2418e-02, 1.8615e-08, 6.0464e-03, 7.1214e-08,
        1.6059e-02, 8.1160e-02, 4.3156e-08, 3.7840e-02, 2.0686e-01, 2.3538e-08,
        4.8755e-08, 1.0056e-02, 3.2676e-08, 6.9834e-03, 1.0228e-02, 5.4118e-08,
        4.8144e-08, 1.6056e-02, 2.2867e-02, 6.7009e-02, 4.3776e-08, 7.1935e-08,
        1.7109e-01, 1.8593e-02, 1.2157e-02, 5.1930e-08, 2.8834e-08, 4.9797e-02,
        5.1898e-03, 1.1831e-02, 1.0801e-02, 1.2103e-02, 9.7631e-03, 2.0952e-03,
        1.0695e-02, 8.9300e-03, 1.9391e-08, 1.5299e-02], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([4.5829e-02, 2.3113e-07, 2.0467e-01, 1.4002e-07, 1.4663e-02, 2.7114e-07,
        2.2944e-07, 4.6895e-07, 2.7014e-07, 3.5871e-07, 4.4283e-07, 1.4850e-01,
        2.2002e-07, 3.4621e-08, 2.3113e-07, 1.8289e-07, 5.1799e-03, 1.5952e-07,
        2.3612e-07, 9.7630e-08, 5.1869e-03, 1.8444e-01, 2.8115e-07, 1.5369e-07,
        4.2671e-07, 4.1579e-03, 9.7630e-08, 3.4697e-07, 1.0260e-07, 4.6944e-03,
        1.2347e-07, 2.7114e-07, 5.9150e-03, 2.3161e-07, 6.7020e-03, 2.3113e-07,
        6.2650e-07, 2.6221e-02, 8.0748e-02, 1.6409e-07, 4.6895e-07, 1.3620e-07,
        4.6895e-07, 2.8115e-07, 2.5584e-07, 1.2511e-01, 4.6699e-03, 4.0604e-07,
        2.3161e-07, 1.7175e-07, 3.3271e-07, 1.0260e-07, 4.3571e-07, 2.2944e-07,
        3.3956e-07, 2.8115e-07, 1.5285e-02, 1.7907e-07, 7.4739e-08, 1.6643e-07,
        7.0464e-08, 4.2163e-02, 2.3113e-07, 2.1003e-02], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([2.3872e-07, 9.0824e-07, 4.3811e-07, 1.0399e-02, 2.3342e-08, 1.1213e-06,
        2.9239e-03, 4.6325e-07, 1.3880e-06, 2.7595e-03, 2.5497e-07, 4.7580e-07,
        1.3706e-01, 1.7211e-01, 5.1762e-07, 4.4439e-07, 3.4689e-07, 3.6592e-07,
        2.5340e-01, 2.8007e-01, 5.6365e-07, 1.2727e-01, 4.8155e-07, 5.6555e-07,
        3.8264e-07, 2.5081e-03, 7.8938e-08, 7.0275e-07, 3.4689e-07, 1.3906e-01,
        9.0252e-07, 6.9035e-07, 2.7504e-07, 1.8944e-07, 6.4145e-07, 8.0885e-07,
        2.8179e-07, 1.7952e-02, 2.7372e-07, 2.1752e-07, 1.7696e-07, 2.1815e-01,
        7.9696e-07, 1.3880e-06, 7.4562e-07, 8.0475e-08, 8.4699e-07, 3.5569e-03,
        5.4460e-07, 6.5548e-07, 4.3855e-07, 1.0162e-06, 1.0579e-06, 3.3586e-07,
        4.7580e-07, 3.1046e-07, 3.0782e-07, 1.9604e-01, 5.5022e-07, 5.3057e-03,
        3.2028e-03, 5.5449e-07, 7.2835e-08, 5.2758e-07], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([7.2758e-03, 1.3827e-01, 4.7903e-08, 3.9270e-08, 1.3660e-01, 3.9056e-08,
        4.9272e-08, 8.8999e-03, 1.3257e-02, 4.9424e-08, 2.0799e-08, 2.0586e-02,
        1.8839e-02, 5.3815e-04, 5.3652e-08, 7.5832e-08, 7.9002e-08, 9.3605e-03,
        3.1509e-08, 7.1327e-03, 3.0675e-08, 6.5417e-08, 8.7233e-03, 1.5541e-01,
        8.7701e-08, 5.5138e-08, 3.1993e-08, 6.9571e-02, 7.8169e-08, 6.0392e-08,
        5.4376e-08, 4.4363e-08, 1.0494e-07, 8.5527e-08, 8.1671e-08, 6.7650e-08,
        7.4455e-08, 7.3613e-08, 3.4062e-08, 6.0852e-08, 6.7312e-08, 2.3382e-08,
        1.8480e-08, 5.2003e-08, 3.4501e-08, 6.9573e-03, 9.4625e-03, 4.9279e-02,
        3.8419e-08, 2.4212e-08, 6.2483e-08, 2.0896e-01, 8.9830e-03, 2.0989e-08,
        6.5283e-08, 1.0937e-07, 2.5451e-08, 3.5548e-08, 6.7698e-08, 5.3858e-08,
        9.0680e-03, 6.0038e-08, 5.7569e-08, 7.3068e-02, 4.3990e-08, 1.0614e-02,
        9.5033e-08, 5.9870e-08, 3.4136e-08, 4.9466e-02, 2.8485e-02, 1.0474e-02,
        6.5156e-08, 4.1917e-08, 8.4768e-08, 6.9371e-08, 8.4779e-03, 3.3167e-08,
        3.0517e-08, 2.0037e-08, 1.2641e-07, 9.0447e-08, 1.2997e-02, 3.6163e-08,
        3.8106e-08, 8.3329e-03, 5.7808e-08, 9.8321e-08, 9.9898e-03, 6.7332e-08,
        4.5747e-08, 1.5378e-01, 7.5623e-02, 9.6282e-03, 3.2425e-08, 1.6099e-01,
        1.2612e-01, 2.7757e-08, 9.0156e-08, 5.3980e-02, 5.8506e-08, 4.1279e-02,
        4.7547e-08, 1.0261e-01, 7.4711e-08, 5.0255e-08, 1.5730e-08, 7.4320e-08,
        7.2165e-08, 2.0356e-08, 2.1377e-03, 2.2609e-08, 4.2904e-08, 1.0596e-07,
        9.7635e-09, 7.1198e-03, 8.6415e-08, 1.0569e-08, 5.1794e-03, 5.6579e-08,
        3.7808e-03, 5.3666e-08, 1.0725e-07, 1.2132e-07, 1.3819e-07, 3.4665e-03,
        5.9664e-08, 2.5338e-08, 2.0253e-02, 7.7704e-03, 1.5504e-01, 4.8574e-08,
        4.0873e-08, 6.9375e-02, 2.9678e-02, 2.8497e-03, 1.5453e-07, 4.6105e-08,
        7.3775e-08, 1.0196e-01, 7.8759e-08, 8.9555e-08, 4.1331e-08, 5.7004e-08,
        9.8669e-03, 6.5934e-08, 4.0093e-08, 4.2186e-08, 3.0400e-08, 5.0014e-08,
        2.3773e-03, 3.4064e-08, 7.9438e-08, 7.0519e-08, 6.7484e-03, 1.1699e-08,
        8.0102e-03, 4.4218e-08, 4.6483e-03, 1.2566e-02, 4.5986e-08, 8.0985e-03,
        5.3126e-08, 7.6996e-03, 3.1732e-08, 2.6487e-02, 7.0264e-08, 3.5761e-08,
        1.4838e-08, 8.1367e-08, 9.3412e-08, 6.2795e-03, 1.0409e-08, 8.4211e-08,
        4.9627e-08, 7.5427e-08, 3.8816e-02, 4.7485e-08, 1.4873e-01, 1.2983e-01,
        1.0330e-02, 3.1633e-02, 9.6304e-03, 1.0435e-02, 6.0047e-08, 8.1547e-08,
        8.1596e-08, 2.0007e-08, 1.7946e-01, 2.6367e-08, 5.1975e-08, 3.9883e-08,
        7.2185e-08, 6.8293e-02, 7.0242e-08, 6.8050e-08, 1.3624e-02, 3.0600e-08,
        2.3026e-08, 1.5782e-01, 2.2336e-08, 8.0604e-03, 2.9758e-08, 3.6820e-08,
        6.5852e-08, 1.8963e-02, 4.9506e-08, 7.0545e-08, 1.9105e-01, 6.4213e-02,
        6.0275e-08, 3.1422e-08, 8.1082e-08, 3.9326e-08, 3.7376e-08, 4.6025e-08,
        1.0811e-02, 3.5391e-02, 1.5223e-02, 4.9498e-08, 2.3826e-08, 4.0949e-08,
        1.2467e-02, 4.6284e-08, 4.8861e-08, 8.0403e-03, 1.1780e-02, 1.3638e-01,
        3.4686e-08, 7.4072e-03, 4.3158e-08, 1.1411e-07, 4.9107e-03, 4.8888e-08,
        1.6446e-08, 5.1615e-08, 9.3395e-03, 9.5493e-08, 4.5143e-08, 1.2120e-01,
        1.4920e-02, 1.3991e-02, 3.9795e-08, 1.2027e-01, 1.4687e-01, 2.2481e-08,
        3.1180e-08, 8.5710e-03, 1.0667e-06, 9.4946e-08, 4.5515e-02, 2.5579e-08,
        8.4263e-03, 5.8577e-08, 9.4476e-08, 1.4660e-07], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([4.1761e-08, 1.5552e-07, 4.7089e-02, 4.1362e-07, 4.1362e-07, 4.2774e-07,
        6.6200e-02, 3.3455e-07, 3.3455e-07, 5.3609e-02, 1.9220e-07, 3.5468e-02,
        1.0399e-01, 3.7990e-07, 3.3455e-07, 2.2373e-07, 4.7278e-07, 1.0325e-07,
        1.4146e-07, 4.7569e-07, 2.7977e-02, 1.0325e-07, 4.4833e-02, 4.1362e-07,
        1.6799e-07, 2.3425e-07, 1.8871e-07, 1.7634e-07, 3.7903e-02, 1.1706e-07,
        4.1362e-07, 3.1658e-07, 3.0350e-07, 6.3285e-02, 2.4349e-07, 7.9452e-02,
        1.8889e-01, 6.4295e-08, 6.4295e-08, 3.3455e-07, 1.4916e-07, 7.0115e-08,
        4.7547e-02, 1.3914e-07, 2.1568e-07, 1.5552e-07, 4.9009e-07, 1.8936e-07,
        3.8948e-07, 4.9009e-07, 3.3455e-07, 4.9031e-07, 9.8154e-08, 2.8317e-07,
        4.7343e-02, 1.5655e-07, 1.3283e-07, 2.5710e-02, 4.9031e-07, 4.1876e-02,
        2.4349e-07, 9.8154e-08, 1.0215e-07, 2.9424e-02, 2.2218e-07, 3.6627e-02,
        4.7294e-02, 1.2467e-01, 1.2086e-01, 1.8871e-07, 4.1616e-02, 1.9957e-07,
        1.3314e-01, 4.1108e-02, 6.5543e-02, 1.5552e-07, 6.4264e-03, 6.2567e-07,
        1.6799e-07, 1.0325e-07, 2.7204e-07, 4.5980e-02, 4.6042e-02, 3.3455e-07,
        2.5419e-07, 1.0215e-07, 1.3283e-07, 6.6425e-08, 1.0567e-07, 2.7204e-07,
        5.4938e-02, 4.9009e-07, 1.2241e-07, 3.1578e-07, 4.0799e-02, 1.4921e-07,
        1.7618e-07, 2.2498e-02, 1.0991e-07, 8.0848e-08, 2.2878e-07, 3.6802e-07,
        8.9715e-08, 2.4349e-07, 7.2992e-02, 2.2821e-07, 3.3455e-07, 4.7350e-02,
        2.2218e-07, 6.4295e-08, 1.1870e-01, 1.2171e-07, 2.2898e-07, 4.9009e-07,
        6.4412e-08, 3.7395e-02, 4.8926e-07, 1.1026e-01, 1.3283e-07, 1.4783e-01,
        5.9382e-02, 5.3574e-08, 1.7264e-07, 6.2987e-07, 1.0863e-01, 5.5389e-02,
        2.7688e-07, 3.3783e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.6347e-06, 4.2476e-02, 3.0862e-02, 2.2031e-06, 3.1710e-02, 6.9102e-07,
        1.7412e-06, 1.9699e-06, 6.0550e-07, 1.0923e-06, 1.1432e-06, 3.9552e-02,
        3.6751e-02, 4.2481e-07, 4.1114e-02, 1.5590e-06, 1.0897e-06, 1.2848e-06,
        9.9841e-02, 9.0364e-02, 1.3152e-06, 3.6073e-02, 2.2318e-02, 1.1160e-06,
        1.9351e-02, 3.2746e-02, 4.5946e-02, 1.0368e-06, 3.8269e-02, 1.0822e-01,
        3.0202e-02, 1.2182e-07, 3.4136e-02, 1.5141e-06, 2.0229e-06, 9.7653e-07,
        3.3090e-02, 6.9102e-07, 1.0047e-01, 6.7489e-07, 2.0752e-06, 3.6682e-02,
        9.5481e-07, 8.3562e-07, 4.0950e-02, 3.5200e-02, 1.5362e-06, 3.4964e-07,
        6.8803e-02, 8.2022e-07, 4.4509e-02, 2.2730e-06, 2.3161e-06, 8.6356e-02,
        1.0630e-06, 1.7466e-01, 2.7385e-06, 3.8544e-02, 9.6016e-02, 1.4069e-06,
        1.4442e-06, 1.4245e-06, 1.2038e-06, 9.6337e-07, 3.1148e-02, 2.1249e-06,
        1.0923e-06, 3.7739e-02, 7.7615e-07, 9.2345e-07, 4.6679e-02, 1.6253e-06,
        8.6975e-02, 3.2962e-02, 8.2477e-07, 1.3545e-06, 2.0683e-06, 4.0460e-02,
        2.0229e-06, 3.4964e-07, 1.8399e-06, 8.5943e-02, 1.1679e-06, 1.8112e-06,
        8.6872e-07, 2.8156e-06, 5.6857e-08, 9.7674e-07, 1.9183e-06, 9.3952e-02,
        3.8550e-02, 2.8156e-06, 4.1099e-02, 2.4447e-06, 6.2270e-07, 1.0368e-06,
        1.1608e-06, 7.1868e-07, 1.2539e-01, 2.0778e-06, 3.7291e-02, 2.0229e-06,
        1.1160e-06, 9.3964e-07, 8.3464e-07, 9.2228e-02, 1.0866e-06, 3.6384e-02,
        2.9743e-02, 4.6625e-02, 9.8928e-02, 2.9426e-02, 4.0227e-02, 3.6175e-02,
        1.3152e-06, 1.3148e-06, 2.3161e-06, 3.6989e-02, 1.1468e-06, 3.5465e-02,
        2.7601e-02, 1.3152e-06, 1.0577e-06, 2.2516e-06, 1.0498e-06, 6.9102e-07,
        3.9478e-07, 3.3937e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.0655e-07, 6.1469e-03, 1.0133e-07, 4.1174e-08, 6.0888e-08, 7.6907e-08,
        6.8830e-08, 4.1020e-08, 2.0230e-07, 8.9558e-08, 9.3416e-08, 5.5468e-02,
        6.1167e-08, 9.8260e-03, 1.3971e-07, 2.4489e-02, 6.8830e-08, 9.5749e-08,
        1.4023e-02, 4.1174e-08, 6.1167e-08, 4.3366e-08, 2.3162e-07, 9.0357e-02,
        1.8040e-02, 4.1174e-08, 9.2188e-02, 8.8711e-08, 7.7362e-08, 5.3041e-02,
        1.0133e-07, 3.0997e-02, 3.4849e-02, 6.6739e-04, 5.5380e-08, 1.0036e-07,
        1.0253e-02, 9.7074e-02, 1.9316e-02, 3.3855e-02, 1.4271e-02, 1.0133e-07,
        4.2429e-08, 4.9746e-08, 1.3900e-02, 1.3023e-07, 8.8859e-08, 1.3898e-02,
        3.8270e-02, 8.8711e-08, 6.1770e-02, 1.2430e-07, 1.6247e-07, 5.3500e-03,
        6.3052e-08, 2.2775e-07, 1.5640e-01, 1.5441e-02, 1.0615e-02, 4.1174e-08,
        1.3023e-07, 3.7665e-02, 4.8956e-02, 1.4067e-02, 1.0133e-07, 4.6340e-02,
        2.8285e-08, 6.3052e-08, 4.9746e-08, 6.7509e-02, 8.2959e-02, 1.3971e-07,
        1.9830e-07, 1.0542e-01, 2.8068e-02, 4.4515e-02, 1.2467e-07, 1.3404e-02,
        1.0839e-07, 4.5708e-08, 4.9746e-08, 1.4378e-02, 7.8108e-08, 1.6397e-02,
        5.0314e-02, 1.9696e-01, 6.3803e-02, 1.1267e-01, 3.7104e-02, 3.9438e-08,
        6.3398e-08, 1.6306e-02, 9.4457e-08, 6.0888e-08, 1.3195e-02, 5.2918e-02,
        7.8108e-08, 3.0842e-02, 1.8570e-02, 1.3862e-02, 2.0984e-02, 1.2588e-02,
        1.8766e-07, 4.6273e-02, 4.9186e-08, 7.4540e-08, 4.7863e-02, 1.3101e-02,
        2.0897e-02, 2.5023e-02, 2.3162e-07, 4.9186e-08, 1.2075e-02, 8.2124e-04,
        4.5708e-08, 8.3302e-08, 4.9234e-02, 3.6945e-08, 6.5210e-02, 3.2172e-02,
        3.7440e-08, 9.7233e-08, 1.3971e-07, 6.1167e-08, 5.0680e-08, 6.8105e-03,
        8.7901e-02, 3.6945e-08, 1.3575e-02, 2.2775e-07, 2.3406e-02, 6.6947e-08,
        6.1167e-08, 2.8285e-08, 9.7805e-03, 3.4239e-08, 1.2519e-02, 2.6352e-02,
        1.3088e-02, 5.2822e-02, 2.6725e-02, 1.0342e-02, 3.4546e-02, 2.8587e-02,
        8.6756e-02, 1.1168e-02, 3.6945e-08, 4.9746e-08, 8.5684e-02, 5.5371e-08,
        1.3971e-07, 9.5892e-02, 2.1218e-02, 2.8285e-08, 1.8608e-07, 7.9216e-02,
        3.8158e-02, 5.5730e-02, 1.4589e-02, 2.2775e-07, 8.9522e-08, 6.7407e-08,
        5.0119e-02, 9.9057e-03, 7.9915e-03, 4.9746e-08, 4.2652e-02, 2.2775e-07,
        1.0292e-02, 3.7621e-02, 2.7435e-02, 2.1086e-08, 2.5034e-02, 1.0880e-07,
        2.5098e-02, 3.4239e-08, 3.4022e-02, 1.6439e-01, 1.9097e-02, 5.1399e-03,
        4.0426e-02, 4.7555e-02, 1.0133e-07, 2.0683e-02, 1.5430e-02, 4.1174e-08,
        4.9186e-08, 4.7841e-02, 1.1902e-02, 1.4346e-07, 7.4540e-08, 3.7096e-02,
        1.5852e-02, 2.3188e-07, 4.9746e-08, 6.7665e-02, 3.6945e-08, 5.2587e-08,
        4.1037e-08, 2.5475e-08, 5.1161e-02, 2.0513e-02, 2.0230e-07, 4.1174e-08,
        8.4238e-03, 1.7885e-02, 8.5361e-02, 1.0053e-01, 4.1174e-08, 2.4660e-02,
        3.6945e-08, 4.3366e-08, 8.8711e-08, 1.0880e-07, 7.8108e-08, 2.3699e-02,
        8.8711e-08, 1.3410e-07, 2.9174e-02, 7.8108e-08, 4.8184e-02, 1.3410e-07,
        8.8711e-08, 1.4233e-02, 5.6294e-03, 6.7407e-08, 3.4648e-04, 2.5685e-02,
        2.5559e-03, 5.1079e-02, 8.5048e-02, 4.9746e-08, 3.3940e-02, 1.9704e-02,
        3.1956e-02, 1.2747e-02, 6.7067e-03, 2.9516e-02, 1.1337e-02, 2.9263e-08,
        4.9358e-08, 1.3083e-02, 1.3718e-07, 2.0366e-02, 1.7265e-02, 7.4540e-08,
        7.7362e-08, 1.0281e-07, 1.5295e-02, 4.2325e-02, 1.4629e-02, 6.0114e-04,
        2.3623e-02, 6.6947e-08, 4.2429e-08, 8.8579e-03, 1.1267e-01, 1.7347e-02,
        4.6508e-08, 2.8479e-02, 3.6945e-08, 9.5258e-08, 6.0488e-08, 1.2467e-07,
        4.2736e-02, 3.1382e-02, 1.1500e-02, 4.5202e-02, 1.3023e-07, 3.6945e-08,
        4.6961e-02, 1.9441e-02, 4.1174e-08, 2.0111e-02, 4.1174e-08, 4.9186e-08,
        1.3357e-02, 4.0512e-02, 5.7018e-02, 1.7428e-07, 1.0349e-07, 1.0132e-01,
        8.2170e-02, 9.3416e-08, 6.0562e-03, 6.1167e-08, 2.3085e-02, 1.3971e-07,
        1.0094e-01, 4.1174e-08, 2.8874e-08, 9.3416e-08, 1.3023e-07, 2.9263e-08,
        2.0418e-02, 4.9746e-08, 8.8711e-08, 3.8858e-02, 1.2380e-07, 2.6351e-01,
        7.8108e-08, 1.2697e-07, 8.8858e-08, 7.6907e-08, 5.5371e-08, 6.9366e-08,
        6.9585e-08, 1.0880e-07, 1.6950e-02, 1.5537e-02, 1.3532e-01, 4.9746e-08,
        6.0184e-08, 1.3023e-07, 1.3971e-07, 2.3259e-02, 2.1206e-02, 7.8108e-08,
        1.7415e-02, 7.8108e-08, 2.3156e-02, 4.5708e-08, 1.0293e-01, 4.0014e-02,
        3.9941e-02, 1.2825e-01, 7.8428e-02, 6.6961e-08, 6.0888e-08, 4.7688e-02,
        6.2083e-02, 8.8309e-03, 1.8328e-02, 4.5708e-08, 1.2467e-07, 4.9746e-08,
        3.6195e-08, 9.4067e-03, 9.3416e-08, 4.5708e-08, 5.3417e-02, 4.0011e-02,
        2.1324e-02, 1.6958e-01, 2.2775e-07, 2.3866e-03, 1.3438e-02, 1.0166e-01,
        7.8488e-02, 1.4014e-02, 1.3900e-02, 5.4126e-02, 1.3839e-02, 6.8947e-02,
        5.5902e-02, 1.1751e-02, 7.3567e-02, 7.8108e-08, 1.5798e-07, 1.7576e-02,
        1.3971e-07, 1.0223e-01, 7.9134e-03, 2.4391e-02, 1.5423e-01, 2.0710e-02,
        2.9263e-08, 3.4090e-02, 4.0758e-02, 1.5798e-07, 1.1725e-02, 1.4540e-02,
        1.1416e-07, 4.1037e-08, 1.0839e-07, 7.8766e-02, 3.4520e-08, 4.1174e-08,
        1.2005e-07, 2.4197e-07, 1.9944e-02, 1.2697e-07, 9.3416e-08, 2.6143e-02,
        1.0901e-02, 5.3313e-02, 1.9632e-07, 1.2256e-07, 8.8711e-08, 2.7302e-02,
        7.3482e-02, 3.2370e-02, 1.1135e-02, 1.8073e-02, 1.1889e-02, 3.4551e-02,
        1.2697e-07, 8.0566e-02, 1.3023e-07, 8.8711e-08, 8.8858e-08, 1.6014e-02,
        2.2775e-07, 1.8948e-02, 7.7362e-08, 6.3052e-08, 1.1240e-02, 1.3184e-01,
        9.7149e-03, 8.8858e-08, 8.2133e-03, 2.5808e-02, 7.7181e-03, 1.2345e-02,
        3.5382e-08, 2.2598e-08, 6.8661e-02, 2.8298e-02, 1.4516e-02, 4.9460e-02,
        9.5258e-08, 2.9263e-08, 4.3366e-08, 3.6945e-08, 1.9429e-02, 6.1167e-08,
        5.5380e-08, 4.5708e-08, 5.6840e-02, 4.1174e-08, 2.1065e-02, 5.6486e-02,
        1.5172e-02, 1.9830e-07, 3.8232e-02, 1.5870e-02, 7.2434e-03, 4.0497e-08,
        4.8029e-03, 3.9426e-03, 2.8285e-08, 6.9696e-03, 1.0282e-07, 3.9631e-08,
        1.6655e-02, 7.8119e-02, 1.3148e-02, 8.6773e-02, 7.8932e-03, 4.5708e-08,
        1.0133e-07, 5.1417e-02, 7.7362e-08, 4.1385e-03, 2.2775e-07, 6.9372e-08,
        3.6945e-08, 7.8108e-08, 6.1167e-08, 1.4871e-02, 2.4687e-02, 8.8711e-08,
        3.0203e-02, 2.0217e-02, 1.0649e-02, 1.0008e-01, 2.2775e-07, 9.1599e-02,
        2.9263e-08, 1.3410e-07, 9.4604e-08, 4.0284e-02, 1.0036e-07, 5.1003e-03,
        1.8122e-02, 3.9412e-08, 5.8850e-03, 8.9080e-08, 1.1198e-02, 1.1209e-01,
        6.3052e-08, 3.9886e-08, 8.8711e-08, 1.3814e-02, 6.5607e-02, 3.9358e-08,
        1.2128e-02, 4.3316e-02, 7.6907e-08, 8.6604e-03, 5.2414e-02, 6.3052e-08,
        6.0221e-02, 2.2775e-07, 9.3422e-08, 4.9186e-08, 8.1135e-02, 5.3362e-02,
        1.5978e-02, 2.0708e-01, 1.8373e-02, 1.2262e-01, 8.8711e-08, 1.2030e-02,
        1.2697e-07, 2.5477e-02, 1.6318e-02, 1.2376e-02, 4.9746e-08, 3.6945e-08,
        1.7484e-02, 1.3114e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([7.4163e-08, 4.0640e-02, 1.1821e-07, 5.4237e-08, 3.9255e-07, 6.2036e-08,
        5.4237e-08, 1.5922e-07, 6.2036e-08, 4.3050e-08, 4.3050e-08, 4.5969e-03,
        2.1876e-07, 4.5326e-02, 4.9341e-08, 6.7358e-02, 2.9168e-07, 7.2262e-08,
        6.0957e-02, 4.3050e-08, 2.9309e-07, 9.0123e-08, 5.4237e-08, 1.0398e-02,
        5.2248e-02, 5.4237e-08, 9.5116e-03, 7.2262e-08, 1.8620e-07, 3.3890e-02,
        4.3050e-08, 4.2727e-02, 7.5065e-02, 2.2161e-07, 7.2262e-08, 1.8620e-07,
        6.8259e-02, 1.0640e-02, 7.2396e-02, 5.8427e-02, 5.5119e-02, 6.2036e-08,
        7.2262e-08, 4.9341e-08, 5.6325e-02, 1.2706e-07, 1.2706e-07, 9.3382e-02,
        3.6657e-02, 2.1876e-07, 5.5329e-03, 4.9341e-08, 7.2262e-08, 2.3436e-02,
        4.9341e-08, 2.1876e-07, 9.8437e-03, 6.4137e-02, 4.0588e-02, 4.9341e-08,
        1.9139e-08, 5.0911e-02, 6.1677e-03, 4.9561e-02, 2.0014e-07, 1.8768e-03,
        1.8620e-07, 5.4237e-08, 1.4120e-07, 2.6087e-02, 4.2488e-03, 3.8190e-07,
        7.2262e-08, 1.1744e-02, 5.5382e-02, 5.9298e-02, 2.6222e-08, 7.8479e-02,
        2.1876e-07, 2.9169e-07, 6.5016e-08, 7.4530e-02, 4.3050e-08, 5.7916e-02,
        4.9377e-02, 1.2243e-02, 1.5259e-07, 6.8039e-03, 3.3798e-03, 4.3050e-08,
        7.2262e-08, 2.8386e-02, 4.9341e-08, 2.1876e-07, 6.8572e-02, 1.3842e-07,
        4.9341e-08, 5.2808e-02, 6.1478e-02, 7.3725e-02, 6.6205e-02, 3.1026e-02,
        6.3190e-03, 2.9676e-03, 3.2313e-07, 2.1876e-07, 4.0459e-02, 2.3086e-02,
        5.9549e-02, 2.7354e-03, 2.1956e-07, 4.3050e-08, 8.3556e-02, 4.9341e-08,
        7.2262e-08, 1.8282e-07, 7.3320e-02, 2.1876e-07, 4.4944e-03, 6.9154e-02,
        7.4163e-08, 2.9627e-07, 1.2706e-07, 9.6479e-08, 5.4237e-08, 5.4697e-02,
        7.9464e-03, 2.8711e-08, 1.9100e-02, 3.8190e-07, 6.3520e-02, 1.8620e-07,
        7.2262e-08, 7.2262e-08, 1.8858e-02, 5.4237e-08, 4.9310e-02, 5.1760e-02,
        5.0546e-02, 7.3380e-02, 9.5467e-02, 6.8454e-02, 6.3339e-02, 4.1357e-02,
        4.7214e-03, 6.5748e-02, 1.8620e-07, 3.2313e-07, 6.9321e-03, 6.2036e-08,
        1.4812e-07, 1.1312e-02, 7.1412e-02, 5.4237e-08, 1.1224e-02, 8.7197e-03,
        7.2097e-02, 1.1075e-02, 1.5603e-07, 2.0014e-07, 2.9308e-07, 1.3760e-07,
        1.0414e-01, 2.4670e-02, 8.3546e-02, 1.8620e-07, 1.0230e-01, 1.8620e-07,
        4.5405e-02, 5.9150e-02, 2.5665e-02, 7.4163e-08, 3.1757e-02, 3.2313e-07,
        8.1944e-02, 1.7739e-07, 3.1709e-03, 6.4490e-03, 5.9421e-02, 2.7497e-02,
        5.3129e-02, 6.2630e-02, 1.0135e-07, 8.5206e-08, 4.0951e-02, 4.3050e-08,
        1.8620e-07, 2.0790e-02, 5.4038e-02, 6.2036e-08, 1.1566e-07, 5.2283e-02,
        7.2416e-02, 2.8213e-02, 4.3050e-08, 3.3653e-03, 4.9341e-08, 5.6513e-03,
        7.2262e-08, 6.2036e-08, 2.5465e-02, 7.3643e-02, 2.1876e-07, 4.9341e-08,
        6.1395e-02, 8.4739e-02, 4.1630e-03, 7.1510e-03, 1.0581e-07, 5.3472e-02,
        5.4237e-08, 1.0135e-07, 2.1096e-07, 2.1876e-07, 2.1518e-07, 3.6484e-02,
        5.4237e-08, 6.5016e-08, 4.0738e-02, 1.2706e-07, 3.9377e-03, 1.8620e-07,
        3.8190e-07, 4.0595e-02, 2.7226e-02, 9.1113e-08, 2.1754e-02, 2.5405e-02,
        1.2312e-02, 3.5671e-02, 3.6140e-03, 2.1518e-07, 8.9260e-08, 5.4811e-02,
        3.0102e-02, 5.5146e-02, 4.1683e-02, 5.8996e-02, 4.3967e-02, 4.3050e-08,
        2.8711e-08, 2.3988e-02, 8.1669e-03, 2.1267e-02, 6.8134e-02, 2.1876e-07,
        1.8620e-07, 4.3050e-08, 5.6917e-02, 5.4462e-02, 8.5823e-02, 2.9946e-02,
        3.4903e-02, 1.7754e-07, 2.9627e-07, 8.4306e-02, 8.1691e-03, 5.3616e-02,
        2.4048e-07, 7.3681e-02, 2.8711e-08, 6.5936e-08, 4.7257e-08, 3.9255e-07,
        1.9073e-07, 2.8268e-02, 3.6643e-02, 2.7586e-02, 6.5936e-08, 1.8620e-07,
        2.6950e-03, 7.7391e-02, 5.4237e-08, 1.3118e-06, 1.3928e-07, 2.1876e-07,
        5.9784e-02, 6.6272e-02, 8.7842e-02, 1.0521e-07, 3.2313e-07, 7.0192e-03,
        8.0437e-03, 2.4048e-07, 3.3361e-02, 1.8620e-07, 5.0272e-02, 7.2262e-08,
        8.3265e-03, 2.1876e-07, 5.4237e-08, 3.8190e-07, 2.5635e-07, 1.0135e-07,
        7.8064e-02, 2.1876e-07, 1.4764e-07, 1.7123e-07, 1.3928e-07, 6.4666e-03,
        1.1359e-07, 1.4764e-07, 2.1518e-07, 4.3050e-08, 1.6793e-07, 4.5346e-03,
        1.8620e-07, 2.8711e-08, 5.8512e-02, 3.5931e-02, 9.2394e-03, 7.4163e-08,
        6.2036e-08, 4.9341e-08, 5.4237e-08, 3.9312e-02, 5.1004e-02, 1.9139e-08,
        7.3284e-02, 7.2262e-08, 9.0460e-02, 7.2262e-08, 1.3055e-02, 7.9971e-02,
        4.6344e-02, 1.1511e-02, 8.7896e-03, 2.1956e-07, 2.1876e-07, 4.9268e-04,
        4.3454e-02, 6.9105e-02, 6.3814e-02, 7.4912e-08, 9.1090e-08, 7.2262e-08,
        1.8620e-07, 7.1981e-02, 2.9309e-07, 5.4237e-08, 9.0020e-02, 7.2584e-02,
        4.8997e-02, 5.2183e-03, 4.3050e-08, 5.2523e-03, 1.0038e-01, 3.4050e-03,
        2.5253e-03, 7.3321e-02, 6.5532e-02, 3.4376e-03, 5.0394e-02, 4.8262e-03,
        4.0937e-02, 7.6773e-02, 8.9079e-03, 5.4237e-08, 1.0135e-07, 6.7679e-02,
        2.9585e-07, 6.9821e-03, 6.5975e-02, 1.0056e-01, 5.3922e-03, 3.1273e-02,
        2.1518e-07, 5.5662e-02, 4.8528e-02, 2.9169e-07, 4.9524e-02, 2.9496e-02,
        6.2036e-08, 9.1113e-08, 2.1956e-07, 6.0669e-03, 1.8620e-07, 6.2036e-08,
        1.2934e-02, 1.8620e-07, 8.1638e-02, 2.4048e-07, 1.3942e-07, 7.4149e-02,
        3.7425e-02, 6.0674e-02, 7.2262e-08, 2.1198e-03, 2.9625e-07, 3.7783e-02,
        5.6634e-03, 5.2222e-02, 5.2723e-02, 8.8271e-02, 6.8268e-02, 2.9079e-03,
        2.9630e-07, 7.0704e-03, 1.9139e-08, 2.1876e-07, 1.4764e-07, 6.0263e-02,
        1.6561e-07, 3.6964e-02, 2.0352e-07, 2.9310e-07, 8.4618e-02, 7.8872e-03,
        4.6195e-02, 7.2262e-08, 5.4797e-02, 2.0773e-01, 2.1943e-02, 6.9584e-02,
        1.9953e-02, 1.0135e-07, 5.6696e-03, 8.8832e-02, 7.8836e-02, 8.4578e-02,
        7.2262e-08, 2.9628e-07, 5.4237e-08, 1.9139e-08, 7.3637e-02, 5.4237e-08,
        2.0352e-07, 2.8711e-08, 7.0042e-02, 7.2262e-08, 4.0931e-02, 9.2824e-03,
        6.0273e-02, 5.4237e-08, 1.0353e-07, 4.4747e-02, 4.8249e-02, 1.8620e-07,
        6.7401e-03, 4.1101e-02, 8.4567e-08, 4.1845e-02, 6.2101e-03, 1.4764e-07,
        5.3265e-02, 1.0709e-02, 6.8446e-02, 1.4341e-02, 3.9860e-02, 1.8448e-09,
        1.2706e-07, 6.8570e-02, 5.4237e-08, 1.1225e-02, 5.4237e-08, 1.6793e-07,
        6.2036e-08, 4.3050e-08, 2.1876e-07, 5.5552e-02, 1.3780e-07, 2.9169e-07,
        7.1191e-02, 6.3668e-02, 6.9768e-02, 4.5461e-03, 4.3050e-08, 1.4400e-02,
        5.4237e-08, 2.9169e-07, 1.3329e-07, 4.2138e-02, 2.8711e-08, 1.6956e-02,
        4.8154e-02, 2.4048e-07, 3.8486e-02, 4.9341e-08, 9.4863e-02, 9.6841e-03,
        4.3050e-08, 4.4126e-08, 4.1912e-08, 4.1241e-02, 4.2231e-03, 1.4764e-07,
        1.1312e-01, 2.6073e-03, 1.0339e-07, 5.8499e-02, 6.0921e-03, 7.2262e-08,
        6.3397e-03, 2.0799e-07, 1.2735e-02, 2.8951e-07, 5.3863e-03, 3.2732e-03,
        9.1323e-02, 7.2017e-03, 1.0387e-01, 8.9198e-03, 7.2262e-08, 7.7059e-02,
        5.4237e-08, 6.2456e-02, 7.5945e-02, 4.8995e-02, 4.9341e-08, 5.4237e-08,
        6.8516e-02, 4.6026e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([8.9391e-08, 4.4481e-02, 4.6154e-07, 3.8794e-02, 4.6154e-07, 1.3133e-07,
        3.4497e-07, 7.1297e-08, 7.1297e-08, 4.3913e-07, 2.8340e-02, 2.6093e-07,
        4.6154e-07, 1.2705e-07, 1.0026e-07, 7.0400e-07, 4.6154e-07, 1.2705e-07,
        4.0598e-02, 4.3913e-07, 5.2507e-07, 4.6154e-07, 8.2554e-02, 8.9391e-08,
        1.2705e-07, 1.3603e-07, 2.1658e-02, 4.4865e-02, 4.3913e-07, 5.0493e-07,
        3.5832e-02, 4.3913e-07, 4.3913e-07, 1.2705e-07, 3.2170e-07, 2.5017e-07,
        3.2437e-07, 4.3913e-07, 1.9132e-07, 1.2705e-07, 4.3913e-07, 4.1491e-02,
        5.3487e-08, 9.0650e-08, 9.0650e-08, 3.5382e-02, 3.8742e-02, 7.9492e-02,
        1.9065e-07, 1.9065e-07, 3.9946e-07, 6.0041e-02, 2.6606e-07, 3.9946e-07,
        1.9065e-07, 1.5341e-07, 3.7709e-02, 4.6154e-07, 2.8391e-02, 7.1298e-08,
        4.6383e-02, 4.4171e-08, 1.9005e-02, 3.2170e-07, 9.1285e-07, 3.7888e-03,
        2.9712e-02, 1.4291e-07, 1.5341e-07, 6.6396e-02, 4.3287e-02, 9.0650e-08,
        4.3651e-02, 1.9065e-07, 4.6154e-07, 3.2170e-07, 2.2688e-02, 3.9314e-07,
        1.2705e-07, 1.5341e-07, 4.6154e-07, 5.3487e-08, 4.3804e-02, 4.1162e-02,
        5.1804e-02, 4.3322e-07, 3.8330e-02, 1.4291e-07, 3.6674e-07, 9.4615e-02,
        1.5341e-07, 2.5017e-07, 6.8141e-07, 3.0561e-07, 1.9132e-07, 1.9132e-07,
        8.9151e-08, 1.4291e-07, 5.0493e-07, 4.6096e-02, 1.7083e-07, 2.6606e-07,
        9.0650e-08, 3.6456e-02, 2.7030e-07, 1.0466e-06, 7.0400e-07, 5.9166e-02,
        4.3233e-07, 4.7919e-02, 1.2705e-07, 4.0122e-02, 3.9946e-07, 1.2705e-07,
        1.9725e-07, 7.0400e-07, 7.0400e-07, 5.7333e-03, 4.6154e-07, 1.9065e-07,
        5.4880e-02, 5.3488e-08, 9.0650e-08, 5.2206e-02, 6.9066e-07, 6.8154e-07,
        1.7767e-07, 4.4435e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([9.8272e-02, 1.1821e-06, 6.9558e-02, 3.9685e-02, 6.7052e-07, 3.2092e-07,
        3.9433e-07, 7.2289e-07, 3.2091e-07, 7.8847e-02, 9.6178e-02, 5.3251e-07,
        1.5295e-07, 3.2091e-07, 1.1821e-06, 7.2867e-02, 6.1557e-02, 6.3566e-02,
        8.3628e-02, 8.9674e-07, 7.2289e-07, 7.6770e-02, 1.1696e-06, 1.9329e-03,
        3.2091e-07, 4.7257e-07, 2.4277e-03, 2.0661e-03, 2.5231e-07, 1.5175e-06,
        4.1488e-07, 2.3437e-07, 3.2172e-07, 4.0031e-07, 3.9909e-07, 8.0204e-02,
        7.2289e-07, 5.4369e-07, 1.2765e-06, 2.8418e-08, 7.2289e-07, 3.6906e-07,
        3.6693e-02, 2.1381e-07, 6.8000e-02, 3.3922e-02, 3.0881e-03, 1.1760e-07,
        5.0376e-07, 4.7257e-07, 1.5262e-07, 2.6785e-07, 2.1381e-07, 4.1488e-07,
        5.3251e-07, 3.3023e-03, 8.8433e-02, 2.6970e-07, 5.5690e-07, 2.1381e-07,
        8.9674e-07, 9.3223e-07, 8.1138e-02, 4.7257e-07, 2.5279e-07, 6.3980e-07,
        3.2091e-07, 5.0376e-07, 3.2091e-07, 2.5232e-07, 1.1821e-06, 8.1074e-02,
        7.8346e-02, 2.4081e-07, 4.5554e-02, 9.3069e-02, 2.4081e-07, 8.8338e-02,
        8.9674e-07, 8.6482e-07, 5.4369e-07, 2.1381e-07, 2.8038e-03, 6.7684e-02,
        1.1821e-06, 7.2289e-07, 7.0650e-02, 4.7257e-07, 1.0714e-01, 2.5231e-07,
        7.6748e-02, 1.9092e-07, 2.5231e-07, 7.2289e-07, 8.7207e-02, 3.3663e-07,
        7.2752e-02, 4.7257e-07, 3.8730e-02, 1.7250e-03, 1.7915e-07, 9.3223e-07,
        8.9397e-02, 1.1821e-06, 8.7697e-02, 3.4682e-07, 8.1047e-02, 8.4459e-02,
        7.8874e-07, 3.6906e-07, 5.2865e-02, 3.2091e-07, 1.1821e-06, 2.5700e-03,
        8.7388e-08, 3.6437e-07, 1.7915e-07, 5.0376e-07, 9.4389e-02, 8.0691e-02,
        2.5797e-07, 1.9736e-03, 3.6906e-07, 2.5231e-07, 4.7257e-07, 8.6780e-08,
        7.2289e-07, 3.0945e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([4.9240e-08, 2.2420e-02, 3.1741e-08, 7.5940e-02, 8.7470e-02, 8.1813e-08,
        1.5441e-07, 7.8693e-02, 6.3827e-08, 4.5409e-08, 2.9174e-08, 3.0313e-02,
        5.5834e-08, 2.5608e-02, 2.6438e-02, 2.6040e-02, 1.0345e-07, 6.3827e-08,
        1.0111e-07, 7.1377e-08, 5.6208e-08, 8.5073e-08, 3.7909e-08, 1.2931e-02,
        4.4558e-03, 4.3348e-02, 2.0155e-02, 1.0298e-06, 1.9338e-07, 4.2220e-03,
        3.7875e-08, 2.5027e-08, 6.4975e-03, 2.5283e-07, 2.1858e-07, 6.1440e-08,
        7.0000e-03, 3.0504e-02, 7.5434e-03, 2.2083e-01, 4.6578e-03, 4.1126e-08,
        2.3209e-07, 6.7011e-02, 7.9598e-03, 3.5534e-02, 5.2764e-08, 6.6037e-03,
        4.6135e-02, 6.1440e-08, 9.0258e-02, 1.6901e-01, 1.4539e-07, 4.5454e-08,
        4.5409e-08, 2.3837e-07, 1.3133e-02, 1.1007e-02, 7.6889e-08, 5.5834e-08,
        7.0171e-08, 1.5300e-03, 3.1895e-03, 4.8751e-08, 1.5441e-07, 4.3754e-02,
        1.4293e-07, 5.1371e-02, 4.6597e-02, 5.2873e-02, 7.3411e-03, 2.2448e-07,
        1.2887e-01, 1.1922e-02, 2.6618e-02, 2.8167e-02, 3.6566e-02, 4.6926e-02,
        4.0982e-02, 7.0209e-02, 1.0507e-07, 3.2793e-03, 2.2123e-07, 5.3265e-03,
        4.7418e-03, 7.9302e-02, 2.6271e-08, 6.1123e-03, 6.0554e-08, 8.9719e-02,
        4.6661e-08, 6.8730e-08, 4.9585e-02, 4.0943e-08, 3.6279e-03, 3.5311e-02,
        5.6424e-08, 5.0409e-08, 6.4724e-03, 1.9194e-02, 3.6445e-02, 1.6963e-02,
        3.2399e-08, 7.5445e-08, 1.4293e-07, 1.4711e-07, 3.3341e-02, 1.1245e-07,
        2.6549e-03, 1.6076e-01, 4.9240e-08, 3.7909e-08, 2.2012e-02, 1.0461e-07,
        1.0837e-07, 5.9618e-08, 2.3966e-02, 8.5732e-08, 4.9199e-03, 7.4738e-02,
        2.9640e-08, 6.1440e-08, 7.0171e-08, 1.6472e-08, 1.6473e-08, 1.6957e-02,
        9.5062e-03, 1.0430e-07, 3.8719e-02, 2.9678e-02, 3.8261e-02, 7.6933e-08,
        8.5732e-08, 1.7884e-07, 3.4074e-02, 3.6972e-08, 4.4991e-02, 2.4012e-02,
        7.1286e-03, 1.6718e-02, 4.4506e-02, 7.1242e-02, 5.8870e-02, 3.0540e-02,
        1.5743e-02, 9.9620e-03, 8.1813e-08, 1.5441e-07, 7.9299e-03, 2.3209e-07,
        1.6714e-07, 1.6223e-01, 8.1749e-03, 8.2580e-02, 2.3400e-08, 9.7300e-03,
        1.9715e-02, 1.2556e-01, 6.5363e-08, 7.3918e-08, 3.7910e-08, 1.3571e-01,
        4.5430e-02, 6.0319e-03, 5.7869e-03, 6.1957e-02, 1.2253e-02, 1.7005e-08,
        3.6111e-03, 6.5262e-02, 7.5320e-02, 7.6933e-08, 7.9188e-08, 8.5732e-08,
        2.3714e-03, 2.1982e-07, 6.0732e-02, 1.1573e-02, 4.6052e-02, 9.7421e-03,
        1.0347e-07, 4.4231e-03, 5.5547e-02, 1.4486e-07, 3.5213e-02, 6.1440e-08,
        9.5107e-02, 2.7794e-02, 6.2951e-08, 2.1998e-07, 3.1741e-08, 9.6741e-03,
        2.8739e-03, 9.8175e-08, 1.4293e-07, 4.3974e-03, 1.4539e-07, 1.4094e-07,
        6.1440e-08, 1.0430e-07, 2.9570e-03, 1.1561e-02, 9.7350e-08, 1.2054e-07,
        2.7841e-02, 1.3785e-02, 2.0204e-02, 7.3762e-03, 1.6110e-07, 7.5748e-03,
        1.8081e-01, 3.6529e-08, 1.3721e-07, 3.1741e-08, 6.3827e-08, 3.7633e-02,
        6.3827e-08, 8.8657e-08, 5.6507e-02, 7.6873e-08, 4.3119e-02, 6.1440e-08,
        1.5217e-01, 7.0238e-08, 2.6030e-02, 3.4412e-08, 1.3655e-07, 1.8312e-03,
        1.0655e-07, 2.0268e-03, 4.4488e-03, 7.6569e-02, 1.1407e-07, 1.5934e-07,
        5.0391e-02, 4.0122e-03, 5.4294e-04, 7.3061e-03, 5.2894e-08, 2.1858e-07,
        6.1440e-08, 1.6841e-02, 2.0544e-08, 1.4964e-02, 2.2941e-02, 9.4047e-08,
        1.0430e-07, 1.6472e-08, 3.3806e-02, 3.9848e-08, 3.3814e-02, 1.5765e-02,
        5.0274e-08, 4.3820e-08, 5.6588e-02, 1.3594e-02, 1.2025e-02, 4.6348e-02,
        1.0345e-07, 7.2051e-03, 6.3827e-08, 8.8657e-08, 1.1552e-07, 8.2888e-02,
        8.5932e-08, 1.8170e-02, 1.0809e-07, 1.0691e-02, 5.4255e-08, 1.3955e-07,
        6.8581e-02, 4.4454e-02, 1.6345e-07, 1.8445e-02, 4.2805e-08, 7.6826e-08,
        1.8695e-02, 2.6375e-03, 6.1294e-02, 5.6424e-08, 6.1440e-08, 7.6346e-03,
        1.0393e-02, 4.9130e-08, 1.6345e-07, 2.0556e-02, 6.2392e-08, 4.4385e-02,
        6.9942e-03, 1.0345e-07, 8.8657e-08, 1.2285e-07, 1.0345e-07, 8.6574e-02,
        1.1576e-02, 1.6165e-01, 1.0837e-07, 1.4480e-07, 1.0349e-01, 3.2732e-02,
        5.5834e-08, 7.4983e-08, 6.2692e-08, 6.1440e-08, 5.5834e-08, 8.7017e-03,
        3.2416e-08, 1.4293e-07, 5.6515e-03, 1.5599e-01, 8.5820e-03, 2.1303e-01,
        7.0171e-08, 5.2764e-08, 1.4715e-01, 2.3563e-07, 8.4197e-02, 3.7909e-08,
        5.5155e-02, 1.5161e-01, 5.9777e-02, 1.4539e-07, 1.1551e-02, 3.7925e-02,
        1.2455e-02, 1.0070e-02, 8.4389e-03, 1.4539e-07, 7.6826e-08, 6.4598e-08,
        6.3127e-02, 3.5519e-02, 3.6684e-03, 3.0420e-08, 3.8948e-08, 6.1440e-08,
        7.6368e-08, 1.3761e-07, 3.1861e-08, 1.5441e-07, 8.7073e-03, 4.0847e-03,
        4.4682e-02, 1.7767e-02, 8.8240e-02, 6.4629e-02, 5.3478e-03, 3.3173e-03,
        4.0137e-02, 6.7860e-02, 3.9922e-03, 1.5129e-07, 3.4232e-02, 8.6166e-03,
        1.6934e-02, 6.1314e-03, 7.6001e-03, 2.1858e-07, 4.0943e-08, 1.4198e-02,
        8.7179e-08, 2.7017e-02, 7.6523e-04, 1.0352e-02, 3.8544e-02, 4.1610e-02,
        7.6826e-08, 4.3252e-02, 5.0941e-02, 3.1741e-08, 1.1193e-07, 3.4931e-02,
        4.0980e-02, 4.8629e-08, 4.5953e-02, 6.5944e-03, 8.5073e-08, 1.5441e-07,
        4.6459e-03, 4.2924e-08, 1.3512e-02, 6.1440e-08, 7.6933e-08, 8.4999e-03,
        6.1027e-02, 6.2383e-03, 3.7909e-08, 8.5877e-08, 1.8265e-08, 1.2200e-02,
        1.1534e-02, 6.9523e-03, 2.6508e-07, 9.3246e-03, 2.5527e-02, 7.8093e-02,
        6.1440e-08, 1.4188e-02, 8.1813e-08, 3.1613e-08, 5.5666e-08, 7.2864e-02,
        8.2273e-02, 9.8818e-03, 1.4539e-07, 1.4293e-07, 5.3348e-02, 1.0731e-02,
        2.9090e-02, 2.1746e-07, 6.7305e-08, 1.2164e-02, 1.4674e-01, 5.9465e-02,
        1.9977e-07, 1.0269e-07, 4.0878e-08, 3.1600e-02, 6.9667e-03, 7.7609e-03,
        4.4467e-02, 2.2453e-07, 5.5834e-08, 1.3209e-01, 2.2195e-02, 5.4255e-08,
        2.1858e-07, 1.6092e-01, 1.0553e-02, 8.5732e-08, 5.1149e-08, 9.7810e-03,
        4.7071e-03, 8.4155e-08, 5.2453e-02, 3.1117e-03, 3.5986e-03, 3.7910e-08,
        2.1124e-08, 7.4305e-03, 7.6933e-08, 1.8442e-02, 4.8665e-08, 6.6089e-08,
        6.7321e-02, 1.9918e-01, 4.4323e-02, 7.4142e-02, 1.1953e-07, 8.1813e-08,
        2.1614e-02, 3.7450e-02, 1.0837e-07, 1.4405e-02, 5.5834e-08, 2.8918e-08,
        6.9815e-08, 3.0420e-08, 6.1440e-08, 1.2762e-02, 2.2553e-02, 6.4063e-02,
        5.4701e-08, 7.1418e-02, 4.0402e-02, 5.6868e-02, 6.1440e-08, 1.4447e-02,
        9.5894e-08, 7.6933e-08, 5.5049e-08, 5.8851e-02, 2.3209e-07, 1.5431e-02,
        6.7620e-03, 5.5230e-08, 1.8595e-02, 2.1858e-07, 1.2012e-02, 8.0604e-03,
        5.9539e-08, 2.4841e-02, 7.8210e-08, 1.8560e-01, 7.7624e-08, 7.9498e-02,
        4.3478e-02, 1.0646e-07, 2.7577e-08, 1.4881e-07, 6.8818e-03, 4.5682e-02,
        6.9962e-03, 2.1982e-07, 7.4991e-03, 7.1209e-02, 9.9328e-03, 2.3057e-02,
        1.6177e-02, 7.0356e-03, 8.0389e-03, 3.0531e-02, 8.5732e-08, 8.8457e-03,
        1.1908e-07, 9.3443e-03, 7.8939e-03, 5.7914e-02, 4.5409e-08, 4.1406e-02,
        9.1213e-03, 2.3845e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([3.5281e-02, 2.2987e-02, 3.6258e-02, 3.1265e-02, 3.5915e-02, 3.0152e-02,
        4.4642e-02, 2.0567e-07, 3.1532e-02, 3.5471e-02, 4.9481e-07, 3.5849e-02,
        9.3997e-08, 4.6985e-02, 7.7742e-07, 5.4801e-02, 2.5238e-02, 3.9538e-02,
        5.9667e-07, 3.5414e-02, 2.1678e-07, 3.4599e-07, 2.1127e-01, 4.0606e-07,
        2.6189e-02, 3.7328e-02, 5.4519e-02, 1.6414e-02, 3.4550e-07, 1.2389e-06,
        3.0036e-02, 2.3452e-02, 2.3775e-08, 4.0784e-07, 3.9067e-02, 3.4710e-02,
        1.4702e-07, 4.7131e-02, 6.9972e-07, 3.4371e-07, 1.8200e-07, 3.0762e-07,
        4.9057e-02, 4.4726e-02, 5.2101e-07, 4.5432e-07, 2.8497e-07, 3.4152e-02,
        1.0971e-06, 2.7851e-02, 3.3902e-02, 2.8696e-02, 4.0947e-02, 8.0012e-07,
        4.1717e-02, 1.1297e-01, 1.4060e-01, 3.7538e-02, 3.0236e-02, 2.6925e-02,
        3.7984e-07, 3.9954e-02, 1.4511e-07, 3.5834e-02, 3.2459e-07, 1.8200e-07,
        1.5919e-02, 4.0159e-07, 1.1770e-01, 3.3877e-07, 3.8757e-02, 2.6872e-07,
        4.2206e-02, 1.7129e-02, 4.3857e-03, 6.9972e-07, 3.0101e-07, 4.2829e-02,
        7.4185e-07, 4.7957e-02, 4.0215e-02, 1.4144e-07, 1.8659e-02, 1.1581e-06,
        9.2676e-03, 1.4550e-01, 8.3476e-07, 3.4559e-02, 4.2393e-07, 4.4409e-07,
        2.6087e-03, 3.6981e-02, 1.3894e-02, 3.1653e-02, 3.2541e-07, 2.4839e-02,
        2.5976e-02, 3.9568e-02, 1.4702e-07, 1.2771e-02, 5.2932e-07, 4.1950e-02,
        3.7970e-02, 2.8532e-02, 4.3763e-02, 3.1506e-07, 4.2852e-08, 8.9281e-07,
        1.9383e-01, 1.4233e-01, 3.0116e-07, 2.6878e-02, 5.0647e-02, 3.1686e-07,
        3.7543e-02, 5.5204e-07, 1.7697e-02, 3.3387e-04, 4.1714e-02, 2.6061e-02,
        4.8750e-02, 9.5851e-07, 2.4026e-02, 3.4405e-02, 4.3862e-02, 6.5671e-07,
        2.7779e-07, 1.7587e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([2.4353e-06, 3.9823e-02, 1.0621e-01, 1.5019e-06, 1.0105e-06, 2.7383e-07,
        2.8166e-02, 7.4246e-02, 7.4810e-02, 4.1658e-06, 1.4581e-07, 2.6202e-06,
        2.9042e-02, 1.4581e-07, 1.2723e-06, 9.6275e-07, 1.0174e-06, 1.7104e-06,
        1.5049e-06, 1.0921e-01, 7.4719e-02, 1.0964e-06, 1.9786e-06, 1.3423e-01,
        1.1821e-06, 9.6276e-07, 7.7413e-02, 2.5304e-02, 2.7015e-06, 2.1477e-06,
        8.0934e-07, 1.2655e-06, 1.0587e-01, 2.5567e-02, 1.8051e-06, 1.5633e-06,
        1.4581e-07, 5.0166e-07, 7.8667e-02, 7.3782e-02, 2.4718e-06, 2.7410e-06,
        9.8539e-02, 1.5584e-06, 7.4710e-08, 2.1531e-06, 1.5330e-06, 1.6144e-06,
        5.6260e-02, 1.2701e-01, 2.9031e-02, 8.3637e-02, 5.3166e-02, 9.3687e-02,
        3.0712e-02, 1.1378e-01, 1.3808e-06, 1.1335e-01, 1.2655e-06, 8.2242e-02,
        1.2261e-06, 1.6157e-01, 3.4246e-02, 9.0312e-07, 1.1305e-01, 9.0006e-02,
        8.8425e-07, 6.6404e-07, 2.3739e-06, 2.7383e-07, 1.3031e-06, 9.1711e-02,
        1.3913e-06, 8.9769e-07, 8.2350e-07, 5.7211e-07, 1.0092e-06, 3.2236e-06,
        2.3472e-06, 7.3508e-02, 1.0174e-06, 2.4718e-06, 1.4404e-01, 9.6221e-07,
        8.2610e-02, 2.1026e-02, 1.0421e-06, 1.0862e-01, 9.6024e-02, 1.4581e-07,
        6.7973e-07, 7.2824e-02, 2.5827e-06, 8.8425e-07, 1.0978e-01, 9.0180e-02,
        8.4995e-02, 7.5720e-02, 7.0120e-02, 2.3656e-07, 1.0451e-06, 7.9730e-02,
        7.4161e-07, 3.0503e-02, 1.1341e-01, 3.6952e-06, 3.1837e-02, 1.6911e-06,
        2.3739e-06, 8.8425e-07, 1.9585e-02, 9.8279e-02, 4.3868e-07, 8.2081e-02,
        1.0964e-06, 2.2024e-06, 1.4431e-06, 8.0429e-07, 2.3671e-02, 1.3808e-06,
        2.7621e-02, 5.2344e-07, 2.2521e-06, 7.9945e-02, 9.4226e-07, 1.4754e-01,
        8.9508e-07, 8.4020e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([2.9094e-02, 1.9527e-02, 2.3591e-07, 1.0479e-02, 1.3964e-02, 3.8737e-08,
        4.7163e-02, 1.1871e-02, 9.5690e-02, 7.6970e-02, 4.7127e-08, 2.6554e-03,
        5.3001e-02, 4.8015e-02, 3.0001e-02, 3.7935e-02, 2.8244e-02, 9.8004e-08,
        5.4489e-02, 8.1622e-03, 1.0999e-07, 1.1227e-07, 8.3664e-02, 2.1471e-02,
        6.0406e-02, 4.5464e-02, 3.9271e-02, 1.0882e-07, 1.5165e-07, 6.7204e-03,
        1.0999e-07, 3.7991e-02, 2.1291e-02, 6.6762e-08, 1.0999e-07, 5.8087e-02,
        3.1637e-02, 1.1384e-02, 6.9328e-02, 2.8650e-02, 5.1117e-02, 9.5851e-02,
        1.9953e-07, 2.8279e-02, 5.2924e-02, 4.6917e-08, 4.3369e-02, 4.6674e-02,
        1.0452e-02, 3.7776e-08, 1.2246e-02, 1.1262e-02, 1.0999e-07, 1.9621e-01,
        6.3976e-08, 5.6430e-08, 1.9748e-02, 1.5728e-02, 3.3518e-02, 1.1336e-01,
        1.5602e-07, 1.1903e-01, 4.9900e-03, 4.0936e-02, 3.5925e-02, 1.5497e-02,
        4.6218e-02, 1.8594e-07, 1.0816e-07, 7.4165e-03, 4.6545e-02, 6.3976e-08,
        2.7737e-02, 2.4050e-02, 6.3191e-02, 7.0810e-02, 1.9360e-02, 5.5675e-02,
        1.1122e-07, 1.9056e-02, 1.3443e-01, 1.0037e-02, 1.2034e-01, 6.8239e-02,
        4.6850e-02, 1.7867e-02, 2.5555e-02, 5.4377e-02, 9.5006e-02, 1.3525e-02,
        3.8737e-08, 2.4233e-02, 2.4103e-08, 5.9557e-02, 3.6826e-02, 2.1734e-07,
        4.2404e-02, 5.3707e-02, 5.2032e-02, 6.2295e-02, 4.3501e-02, 1.1575e-02,
        1.1336e-07, 1.1672e-07, 5.1942e-02, 7.0981e-02, 2.9045e-02, 3.7484e-02,
        4.4723e-02, 1.6064e-02, 5.1497e-02, 2.5377e-02, 6.6598e-02, 1.4343e-01,
        1.8617e-07, 7.2542e-02, 6.7449e-03, 2.7464e-02, 1.8445e-02, 6.0257e-02,
        1.6804e-07, 9.6924e-02, 1.8445e-01, 3.7775e-08, 1.7097e-07, 2.9782e-02,
        1.7109e-02, 7.0097e-02, 1.0895e-07, 2.4119e-08, 4.9675e-02, 7.1150e-02,
        2.6783e-02, 5.2927e-08, 4.2601e-02, 2.2901e-07, 2.0962e-02, 1.7225e-02,
        5.7278e-02, 2.3703e-02, 4.3529e-02, 5.2338e-02, 5.8287e-02, 2.2188e-02,
        2.0138e-02, 1.2521e-02, 5.5949e-08, 2.2730e-07, 1.3032e-02, 2.2283e-07,
        4.7686e-08, 2.2821e-02, 7.2735e-02, 2.4809e-07, 1.0858e-07, 7.0645e-02,
        5.6321e-02, 2.5071e-02, 1.1133e-07, 1.5958e-01, 1.2783e-07, 3.6861e-02,
        6.3000e-02, 1.2189e-02, 3.8505e-02, 1.9434e-08, 2.2476e-02, 8.5113e-08,
        4.0745e-02, 3.0698e-02, 4.9024e-02, 1.7885e-01, 3.2469e-02, 2.2284e-07,
        6.5699e-02, 3.0523e-08, 4.7861e-08, 1.5071e-02, 4.3276e-02, 3.1798e-02,
        2.7227e-02, 2.9904e-02, 1.0225e-02, 1.7186e-02, 8.3879e-02, 1.5117e-01,
        9.7937e-03, 3.3435e-02, 3.9623e-02, 1.0999e-07, 1.1293e-07, 3.5103e-02,
        4.1770e-02, 2.9310e-02, 2.2430e-02, 5.2351e-02, 9.5460e-02, 1.4554e-07,
        1.4747e-07, 7.3459e-09, 4.8506e-02, 7.5070e-02, 4.7846e-02, 5.1792e-02,
        5.9365e-02, 3.6017e-02, 5.4055e-02, 1.3570e-02, 1.4808e-01, 6.1163e-02,
        3.6126e-02, 1.8181e-01, 3.8737e-08, 4.5067e-02, 1.4628e-02, 7.3934e-02,
        1.9450e-07, 2.2730e-07, 2.5229e-02, 2.7765e-02, 8.8675e-03, 4.5348e-08,
        1.5239e-02, 5.2338e-02, 3.1953e-02, 1.9953e-07, 2.5206e-02, 3.4316e-02,
        5.1126e-08, 6.7063e-02, 4.1982e-02, 4.3931e-02, 4.1751e-02, 1.2822e-01,
        4.6187e-02, 4.1549e-02, 5.8991e-02, 6.6456e-02, 7.1369e-02, 2.5896e-02,
        1.4673e-02, 9.2888e-03, 5.4887e-03, 6.1386e-03, 5.6093e-02, 5.1143e-08,
        5.3216e-02, 4.9249e-03, 4.5618e-02, 5.1802e-02, 8.6534e-03, 1.2735e-02,
        3.9684e-02, 1.7890e-01, 6.2535e-08, 3.3218e-02, 9.5186e-02, 1.5698e-01,
        1.3072e-01, 7.4692e-02, 1.2790e-07, 2.4119e-08, 1.6976e-07, 1.5204e-02,
        2.4989e-02, 9.8508e-03, 1.0053e-02, 1.2582e-02, 6.3976e-08, 4.7700e-02,
        5.4480e-02, 2.3793e-02, 6.0347e-02, 1.0484e-02, 2.4809e-02, 8.1229e-08,
        6.3760e-02, 4.4414e-02, 4.8481e-02, 2.6339e-02, 5.5949e-08, 1.4281e-02,
        1.1794e-02, 8.9343e-02, 1.8544e-02, 3.6526e-02, 4.2086e-02, 7.9704e-08,
        1.0553e-02, 3.3083e-08, 2.3249e-08, 5.9537e-02, 5.3296e-08, 4.0314e-02,
        1.4864e-01, 5.0461e-02, 1.0989e-04, 2.8976e-02, 1.5616e-02, 1.2414e-02,
        3.2831e-08, 7.3195e-08, 9.3321e-02, 1.4747e-07, 7.4305e-08, 1.5041e-07,
        5.4430e-02, 8.9403e-08, 5.7056e-02, 2.6171e-02, 1.7474e-02, 1.1044e-02,
        3.8342e-08, 9.3472e-02, 7.3308e-08, 3.2232e-02, 1.4001e-02, 6.8393e-02,
        4.7369e-03, 1.2195e-02, 5.6884e-02, 5.2769e-02, 1.6543e-02, 3.6388e-02,
        1.8803e-02, 2.0306e-02, 2.1998e-02, 7.3776e-08, 5.2052e-02, 2.9823e-02,
        3.5540e-02, 2.9237e-02, 3.3011e-02, 7.5989e-02, 2.3591e-07, 1.5278e-07,
        6.2023e-02, 3.4630e-02, 1.4193e-02, 6.0440e-03, 3.0112e-02, 6.1853e-02,
        4.7911e-03, 5.4471e-02, 1.6170e-02, 5.8895e-02, 3.9941e-02, 3.0272e-02,
        1.4358e-01, 1.2614e-02, 4.8661e-02, 1.6795e-02, 3.7520e-02, 1.2366e-02,
        4.5961e-02, 5.1370e-02, 4.2448e-02, 1.4966e-01, 5.2927e-08, 3.3859e-02,
        4.2650e-08, 2.8101e-02, 2.3781e-02, 4.3701e-02, 1.8741e-02, 1.6832e-02,
        2.3249e-08, 1.5023e-01, 4.0062e-02, 9.2065e-08, 5.1894e-02, 3.5937e-02,
        5.9484e-08, 1.1719e-07, 1.7846e-01, 4.3066e-02, 6.6130e-02, 1.5613e-01,
        5.0672e-08, 2.4680e-02, 2.1538e-02, 3.4429e-08, 1.5178e-07, 3.5748e-02,
        5.1234e-02, 7.6826e-02, 2.1122e-02, 2.4310e-07, 1.5707e-01, 3.8945e-02,
        1.7566e-02, 7.1636e-02, 6.1371e-02, 2.1952e-02, 1.5532e-01, 5.8132e-02,
        5.6430e-08, 1.4142e-02, 1.1299e-07, 9.0837e-08, 7.7140e-02, 3.8847e-02,
        1.0534e-02, 1.6625e-01, 1.8617e-07, 1.9375e-01, 4.3798e-02, 1.2591e-01,
        5.8808e-02, 3.6314e-02, 2.6067e-02, 2.4647e-01, 5.0846e-02, 3.7692e-02,
        1.5818e-01, 4.4220e-02, 7.2842e-03, 4.2704e-02, 5.0408e-02, 1.4042e-02,
        1.1289e-02, 5.7312e-08, 2.7598e-02, 1.0747e-02, 5.9152e-02, 4.7124e-08,
        1.4747e-07, 2.3468e-02, 1.3903e-02, 8.3100e-08, 2.1402e-07, 2.7827e-02,
        1.3116e-01, 2.4119e-08, 2.9681e-08, 4.3970e-02, 2.0749e-02, 2.8149e-02,
        1.2926e-07, 1.3342e-02, 1.5178e-07, 6.0684e-02, 1.0999e-07, 5.6829e-02,
        4.5478e-02, 2.2611e-02, 1.8721e-02, 9.8964e-03, 3.0345e-02, 4.5658e-02,
        3.5618e-02, 1.5503e-02, 2.2525e-02, 1.7527e-02, 2.2732e-07, 7.2977e-08,
        4.4660e-02, 4.4907e-02, 1.7298e-01, 1.2745e-02, 3.2916e-02, 2.1294e-01,
        2.3532e-02, 2.7255e-02, 2.8721e-02, 2.0932e-02, 4.0319e-02, 6.0323e-02,
        4.4261e-08, 5.1149e-08, 3.8759e-02, 3.6931e-02, 8.1230e-08, 1.3043e-07,
        4.6257e-02, 4.0246e-02, 2.8001e-02, 6.1032e-02, 3.9039e-02, 4.7365e-02,
        6.9749e-02, 2.7144e-02, 1.3711e-01, 2.8499e-02, 1.8292e-02, 7.2961e-08,
        5.2750e-02, 1.7061e-02, 1.1375e-01, 6.0993e-03, 3.5296e-02, 2.5943e-02,
        3.5295e-02, 4.5236e-02, 9.6325e-03, 3.7821e-02, 7.7472e-03, 1.5330e-02,
        5.3221e-02, 2.0931e-02, 6.0022e-02, 3.5018e-02, 9.1618e-02, 4.8415e-02,
        5.5959e-08, 6.1117e-02, 6.6531e-02, 3.3028e-02, 2.3249e-08, 3.8185e-02,
        3.3670e-02, 5.3675e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([2.4875e-07, 1.3590e-01, 1.8082e-07, 4.3692e-02, 4.4483e-02, 9.9416e-02,
        1.1914e-01, 4.8712e-07, 9.2175e-02, 2.8991e-02, 5.6381e-02, 3.7307e-07,
        8.9911e-02, 4.1106e-02, 9.0221e-07, 1.0136e-06, 2.8408e-02, 4.1702e-02,
        1.0498e-06, 3.1389e-07, 5.2084e-07, 1.0987e-01, 4.6602e-02, 6.2449e-07,
        1.1561e-01, 1.3476e-07, 3.9663e-02, 3.9692e-02, 3.5106e-02, 1.5811e-01,
        1.0572e-01, 4.5976e-02, 4.9773e-07, 1.2378e-01, 1.0501e-01, 5.2207e-07,
        4.4330e-02, 7.9806e-07, 2.7873e-07, 4.1174e-02, 5.1766e-02, 2.4875e-07,
        2.1153e-07, 4.3411e-02, 2.3582e-07, 4.1913e-07, 1.4822e-01, 4.2627e-02,
        4.2302e-02, 5.0414e-07, 1.2459e-01, 3.0817e-07, 1.4784e-07, 4.0835e-02,
        1.2099e-01, 1.2186e-01, 5.0138e-07, 5.1144e-07, 4.2551e-02, 4.1435e-02,
        1.0295e-01, 4.6736e-02, 1.0678e-01, 9.2099e-08, 1.5557e-01, 3.7221e-07,
        1.0602e-01, 1.1951e-01, 1.3915e-01, 4.2946e-07, 1.0361e-01, 1.3367e-01,
        2.6412e-07, 8.6185e-07, 2.3360e-02, 4.2946e-07, 4.4712e-02, 1.8788e-07,
        5.0414e-07, 4.4848e-02, 9.6345e-02, 7.6599e-07, 4.3549e-07, 1.0026e-01,
        1.6751e-02, 4.4669e-02, 1.0571e-01, 8.1186e-02, 6.4076e-07, 1.4491e-01,
        4.1757e-02, 3.9615e-02, 4.6941e-02, 3.8739e-07, 4.3558e-07, 4.3736e-02,
        3.3688e-02, 4.4705e-02, 2.6920e-02, 1.7607e-07, 4.5967e-02, 3.7103e-07,
        8.8664e-02, 1.1941e-01, 3.9615e-02, 9.4203e-02, 1.2959e-01, 3.9783e-02,
        6.4076e-07, 5.2084e-07, 4.0246e-02, 1.1821e-01, 1.8824e-01, 3.8965e-02,
        8.3435e-07, 1.3118e-01, 4.5107e-07, 2.2777e-07, 9.9982e-02, 8.7386e-02,
        5.2207e-07, 6.8511e-07, 3.9666e-02, 5.3086e-07, 9.7671e-07, 2.5406e-07,
        4.8593e-07, 5.3123e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.2295e-06, 2.3893e-06, 1.0278e-06, 8.3155e-02, 1.3637e-06, 1.9148e-06,
        1.2295e-06, 4.7534e-02, 3.0166e-02, 1.4809e-06, 1.4961e-06, 9.2657e-07,
        2.4441e-06, 2.7771e-06, 1.3826e-06, 1.1915e-01, 4.9990e-02, 2.3348e-06,
        6.8511e-07, 8.3328e-02, 1.7527e-06, 2.1996e-06, 1.5209e-06, 8.5551e-02,
        1.1120e-01, 9.7675e-02, 4.1952e-02, 3.4926e-07, 4.5980e-07, 3.8855e-02,
        6.3389e-07, 1.0677e-01, 1.0291e-01, 1.0148e-06, 4.8406e-02, 4.3141e-02,
        4.7153e-02, 1.8943e-06, 9.1358e-07, 2.1937e-06, 5.3250e-02, 1.7527e-06,
        4.6394e-02, 9.4853e-02, 3.7816e-02, 1.4839e-06, 1.0246e-06, 1.4472e-07,
        4.7555e-02, 1.3069e-01, 3.6843e-07, 2.9704e-06, 9.1289e-02, 8.2873e-02,
        8.8078e-02, 1.9151e-06, 1.0388e-01, 4.4996e-02, 1.0217e-01, 1.0357e-06,
        8.4985e-02, 1.8707e-06, 3.5129e-02, 4.5005e-02, 1.1177e-01, 2.0374e-07,
        2.1311e-06, 5.2668e-02, 1.4809e-06, 4.1026e-02, 9.2826e-02, 7.2733e-07,
        1.3308e-01, 1.6073e-06, 3.6843e-07, 8.7790e-07, 3.2708e-06, 9.0687e-02,
        4.6012e-02, 4.4875e-02, 7.6960e-07, 1.0920e-06, 4.3172e-02, 3.1001e-02,
        9.3950e-02, 1.1626e-06, 1.1735e-01, 6.9988e-07, 1.0483e-01, 1.1270e-06,
        6.4531e-07, 1.6110e-06, 5.0251e-02, 1.8707e-06, 4.3219e-02, 1.3201e-01,
        7.4084e-07, 6.5991e-07, 3.4064e-02, 2.8696e-06, 1.3135e-01, 3.9692e-02,
        1.3161e-06, 1.3611e-06, 4.5264e-02, 1.2393e-01, 4.6735e-02, 1.5779e-06,
        1.0362e-01, 8.3893e-02, 1.0448e-06, 4.3706e-02, 7.5352e-07, 1.7741e-06,
        4.6461e-02, 4.4174e-02, 1.5027e-06, 1.7881e-06, 5.0005e-02, 2.9668e-06,
        2.1509e-06, 4.8803e-02, 9.5859e-02, 4.3154e-02, 4.9411e-02, 1.0446e-06,
        7.9593e-07, 2.0718e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([3.4127e-02, 1.1925e-07, 7.4874e-02, 4.9591e-02, 1.8647e-02, 8.2498e-08,
        3.7348e-02, 3.6562e-02, 1.7995e-02, 1.6757e-02, 1.8594e-02, 3.5179e-02,
        3.6458e-02, 6.6220e-02, 6.0883e-02, 2.9127e-02, 3.6704e-02, 1.0087e-07,
        2.9891e-02, 2.2193e-07, 8.9595e-08, 4.2524e-02, 6.8541e-02, 2.3119e-02,
        1.4031e-02, 5.3283e-02, 1.2917e-02, 5.1244e-02, 6.4013e-02, 4.6325e-02,
        1.4653e-07, 6.3894e-02, 1.2828e-02, 9.5362e-08, 1.4812e-07, 2.1143e-07,
        8.4158e-03, 2.3908e-02, 2.8612e-02, 1.6919e-02, 7.4519e-02, 3.3971e-02,
        1.1106e-07, 4.0100e-02, 4.8115e-02, 2.3927e-02, 6.5157e-02, 3.8663e-02,
        2.8255e-03, 8.6371e-08, 5.2179e-02, 3.6944e-02, 6.2264e-02, 2.6233e-02,
        6.2089e-03, 7.6690e-02, 1.9289e-02, 1.7621e-02, 4.1898e-02, 4.4363e-03,
        1.0281e-01, 2.5809e-02, 6.0481e-02, 2.2581e-02, 5.5879e-02, 4.6000e-02,
        4.6893e-02, 3.5980e-02, 1.7804e-02, 4.5523e-02, 3.1054e-02, 4.3633e-02,
        6.1549e-02, 7.3393e-02, 3.9907e-02, 2.3462e-02, 4.6211e-02, 3.7917e-02,
        3.8041e-03, 3.4317e-02, 6.3142e-02, 4.6770e-02, 1.3157e-02, 4.4758e-02,
        3.0561e-02, 1.9247e-02, 9.3231e-08, 2.1119e-02, 3.4626e-02, 8.7141e-03,
        8.5592e-02, 4.7203e-02, 5.0070e-02, 7.7009e-02, 3.0644e-02, 1.0961e-02,
        2.1064e-07, 3.0301e-02, 3.3591e-02, 2.8487e-02, 1.6864e-02, 6.4980e-02,
        6.6815e-04, 3.7207e-02, 4.1333e-08, 1.9049e-02, 4.1641e-02, 2.0134e-01,
        4.1273e-02, 4.0243e-02, 2.1273e-08, 7.4834e-02, 4.8452e-02, 1.9472e-02,
        7.4122e-02, 8.0766e-02, 2.7688e-02, 1.0642e-07, 2.3168e-02, 1.8253e-02,
        3.7289e-08, 6.6472e-02, 2.8327e-02, 4.6944e-02, 9.8958e-02, 2.4186e-02,
        1.3923e-02, 6.2855e-02, 3.5951e-02, 7.0456e-08, 5.0976e-02, 1.3377e-02,
        5.2989e-02, 6.6057e-02, 1.6792e-02, 3.6113e-02, 1.2828e-01, 2.3128e-02,
        5.0348e-02, 1.5712e-02, 1.5128e-02, 4.6610e-02, 3.5960e-02, 3.5989e-02,
        5.2592e-02, 2.5493e-02, 3.5070e-02, 7.7487e-08, 4.8928e-02, 6.9580e-02,
        3.8769e-02, 1.5845e-01, 5.2290e-02, 5.6487e-08, 5.5449e-02, 5.6761e-02,
        2.2275e-02, 1.5030e-02, 8.9440e-04, 5.2902e-02, 6.3199e-02, 5.6928e-02,
        4.1424e-02, 1.5789e-01, 3.7783e-02, 4.3007e-02, 1.9229e-02, 8.2735e-02,
        4.1092e-02, 3.2176e-02, 9.1320e-02, 6.6988e-02, 1.6922e-02, 2.2008e-07,
        2.2944e-02, 7.3732e-02, 3.1137e-02, 1.6156e-02, 2.3498e-02, 8.0189e-02,
        1.4405e-02, 5.4097e-02, 5.0337e-02, 3.4836e-02, 4.0856e-02, 2.4077e-02,
        4.6016e-02, 6.6899e-02, 1.5331e-02, 6.1893e-08, 5.0928e-02, 3.2957e-02,
        4.2241e-02, 3.0883e-02, 7.5892e-02, 1.5911e-02, 7.0038e-02, 2.0953e-02,
        1.4653e-07, 3.8249e-02, 1.4582e-01, 1.2617e-02, 7.2796e-02, 4.8247e-02,
        3.0993e-02, 4.3169e-02, 2.3750e-02, 1.9482e-02, 2.6411e-02, 5.9447e-02,
        6.2692e-02, 3.2061e-02, 1.0566e-07, 5.0338e-02, 3.8058e-02, 4.7012e-02,
        7.6593e-02, 1.0720e-01, 4.2379e-02, 4.4342e-02, 5.0816e-02, 7.7487e-08,
        4.1970e-02, 4.1652e-02, 4.6703e-02, 7.7487e-08, 5.5194e-02, 3.5622e-02,
        6.6289e-02, 6.3211e-02, 5.5003e-02, 4.8250e-02, 1.0257e-07, 2.5552e-02,
        5.3337e-02, 2.5779e-02, 8.1805e-03, 3.6935e-02, 4.5120e-02, 2.1037e-07,
        1.4999e-07, 1.6129e-01, 4.3110e-03, 5.7568e-02, 5.6083e-02, 2.9741e-02,
        1.3351e-01, 5.2362e-02, 4.1930e-02, 1.8785e-02, 2.3346e-02, 1.6928e-02,
        6.5218e-02, 1.6129e-01, 1.9607e-02, 3.8306e-02, 4.1782e-02, 2.4003e-02,
        2.1945e-02, 5.2733e-02, 2.2157e-01, 8.7542e-02, 2.3989e-07, 6.1630e-02,
        3.7447e-02, 8.2819e-02, 3.8560e-02, 1.3495e-02, 8.0946e-02, 6.4746e-02,
        2.3253e-01, 1.8616e-02, 4.0850e-02, 6.3198e-02, 1.3468e-02, 2.3155e-07,
        2.7656e-02, 2.1549e-02, 3.8793e-02, 5.4790e-02, 8.9595e-08, 6.7459e-02,
        5.7770e-02, 4.9064e-08, 3.2028e-02, 2.0786e-02, 5.1822e-02, 2.8829e-02,
        1.3113e-02, 2.0549e-01, 8.9625e-02, 5.5360e-02, 8.6371e-08, 3.2970e-02,
        4.0487e-02, 3.2540e-02, 8.9595e-08, 1.4625e-07, 5.6762e-02, 2.6113e-02,
        1.8466e-04, 7.4376e-02, 5.2635e-02, 4.3397e-02, 3.2580e-02, 1.8016e-07,
        8.6525e-03, 7.4771e-08, 4.1039e-02, 2.3271e-02, 2.3958e-02, 2.4930e-02,
        7.0014e-02, 2.4846e-02, 3.2716e-02, 3.8975e-02, 5.5045e-02, 2.7986e-02,
        3.8175e-02, 3.1089e-02, 3.9855e-02, 5.2718e-02, 3.4404e-02, 2.9279e-02,
        9.6865e-03, 5.9974e-02, 8.0405e-02, 2.1155e-02, 8.5602e-03, 5.1556e-02,
        8.0348e-02, 3.7046e-02, 3.1199e-02, 1.7698e-02, 3.9936e-02, 8.6371e-08,
        1.4907e-02, 1.6519e-02, 5.0015e-08, 8.6371e-08, 5.4451e-02, 2.7812e-02,
        5.8402e-02, 5.1548e-02, 1.2019e-02, 5.5483e-02, 2.0593e-02, 2.0928e-02,
        7.3338e-02, 3.7481e-02, 2.6462e-02, 1.1985e-02, 5.2770e-02, 3.0621e-02,
        6.2890e-02, 2.1229e-02, 5.1876e-02, 8.8982e-02, 7.7143e-03, 2.4142e-02,
        1.3958e-01, 5.4353e-02, 2.9456e-02, 4.7428e-02, 5.1203e-02, 1.6282e-02,
        4.5965e-02, 4.3082e-02, 5.4871e-02, 1.0088e-01, 6.1461e-03, 5.9066e-02,
        3.4346e-02, 6.2485e-02, 1.7320e-01, 2.5258e-02, 3.8496e-02, 5.5783e-02,
        3.4300e-02, 3.5419e-02, 1.6762e-02, 9.1628e-02, 1.5260e-01, 4.8783e-02,
        5.1270e-02, 5.1519e-02, 2.6581e-07, 1.8764e-02, 8.0641e-02, 5.9921e-02,
        7.9439e-03, 5.0526e-02, 2.9815e-02, 2.8376e-02, 4.5810e-02, 3.6355e-02,
        7.7487e-08, 1.3846e-02, 5.6861e-08, 2.5722e-07, 6.3611e-02, 2.5019e-02,
        3.2707e-02, 2.6642e-02, 1.0557e-01, 2.3149e-02, 3.0662e-02, 5.0072e-02,
        7.5736e-02, 7.1158e-02, 2.5436e-02, 6.3245e-02, 2.0121e-02, 4.7884e-02,
        1.4756e-01, 1.1912e-07, 1.8696e-02, 4.0136e-02, 1.5648e-02, 3.3458e-02,
        7.1037e-02, 5.2286e-02, 1.0571e-07, 2.7512e-02, 2.4296e-02, 4.5381e-02,
        4.6970e-08, 1.4726e-01, 1.2907e-02, 3.4844e-02, 1.1281e-01, 5.9112e-02,
        1.8555e-02, 1.5002e-01, 2.3649e-02, 6.2674e-02, 4.2286e-02, 5.6248e-02,
        2.1200e-02, 2.2843e-02, 1.5345e-02, 1.6353e-02, 9.0684e-08, 3.8325e-02,
        5.2835e-02, 1.1927e-01, 2.0327e-02, 5.0899e-02, 1.6172e-02, 7.0071e-02,
        1.4810e-07, 3.4453e-02, 7.0054e-02, 2.6504e-02, 8.2498e-08, 1.4653e-07,
        4.2193e-02, 4.0749e-08, 9.3641e-02, 3.3527e-02, 5.1015e-02, 6.2315e-02,
        2.6809e-02, 5.3968e-02, 5.3595e-02, 1.3450e-01, 9.2833e-03, 4.5944e-02,
        5.5340e-08, 7.0712e-08, 3.8807e-02, 6.4544e-02, 6.7711e-02, 1.4837e-07,
        1.6273e-02, 6.7827e-02, 7.4553e-02, 8.9428e-03, 3.8458e-02, 4.1614e-02,
        2.5713e-02, 5.4794e-02, 7.2387e-02, 5.5901e-02, 6.3055e-03, 5.0935e-02,
        2.9529e-02, 1.3747e-07, 2.3008e-02, 3.2801e-02, 4.3724e-02, 4.4838e-02,
        4.5137e-02, 4.3524e-02, 5.4775e-02, 3.3017e-02, 3.1530e-02, 3.4703e-02,
        3.4748e-02, 1.9513e-02, 3.5544e-02, 2.9467e-02, 1.8958e-02, 2.4238e-02,
        2.5715e-02, 4.4138e-02, 3.8087e-02, 1.7874e-02, 8.6910e-08, 2.9120e-02,
        3.3644e-02, 6.5968e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.1826e-01, 7.6310e-07, 4.3763e-07, 4.3763e-07, 7.8556e-02, 2.4663e-07,
        8.6123e-08, 6.7116e-02, 3.3596e-07, 8.2996e-02, 7.1706e-02, 9.1525e-02,
        4.3763e-07, 9.5520e-02, 9.5006e-02, 3.7252e-07, 1.1039e-01, 1.4457e-07,
        6.6948e-02, 4.0037e-07, 7.8557e-02, 3.5408e-07, 1.0893e-01, 1.8104e-07,
        3.7252e-07, 1.0850e-07, 2.0275e-07, 5.7534e-08, 8.2536e-02, 1.1836e-07,
        1.0895e-01, 8.7044e-02, 1.0850e-07, 9.7262e-02, 9.0569e-02, 8.5114e-02,
        1.4457e-07, 9.0789e-02, 1.2410e-07, 6.8999e-02, 8.4646e-02, 8.6886e-02,
        1.0850e-07, 2.5419e-07, 9.1755e-02, 9.1898e-02, 1.2954e-07, 4.3763e-07,
        1.2350e-01, 1.2292e-01, 7.9724e-02, 4.3763e-07, 4.0713e-07, 1.0850e-07,
        1.0466e-01, 6.3919e-02, 8.9855e-02, 1.0026e-01, 1.0599e-01, 8.8847e-02,
        8.5885e-02, 6.1833e-02, 8.6123e-08, 5.1284e-07, 5.7534e-08, 8.9361e-02,
        9.8414e-02, 1.0034e-01, 5.8115e-07, 1.0046e-01, 1.0643e-01, 1.0850e-07,
        8.3459e-02, 1.0539e-01, 7.9604e-02, 1.2025e-01, 9.3551e-02, 4.4446e-07,
        4.3046e-07, 1.0206e-01, 6.7306e-02, 9.9796e-02, 2.0275e-07, 1.0850e-07,
        9.6740e-02, 2.2646e-07, 2.0275e-07, 7.6794e-08, 2.8709e-07, 1.2410e-07,
        1.4457e-07, 1.0917e-01, 9.5895e-02, 1.0850e-07, 9.8709e-08, 1.0850e-07,
        9.8709e-08, 1.2410e-07, 9.2141e-02, 3.3596e-07, 5.8529e-07, 1.2410e-07,
        3.7252e-07, 4.3763e-07, 1.2954e-07, 8.6296e-02, 7.6799e-08, 3.5408e-07,
        9.9225e-02, 9.1126e-02, 2.0275e-07, 2.1169e-07, 7.6310e-07, 9.6553e-02,
        9.5743e-02, 3.7252e-07, 1.0850e-07, 1.0850e-07, 3.7252e-07, 4.0037e-07,
        8.8514e-02, 1.4471e-02, 1.0176e-01, 6.0394e-07, 1.0986e-01, 9.2306e-02,
        4.6433e-02, 9.4454e-02, 1.0604e-01, 1.4457e-07, 9.4921e-02, 1.4366e-01,
        8.6577e-02, 8.7563e-02, 9.3012e-02, 3.3596e-07, 9.5317e-02, 1.4836e-07,
        4.3763e-07, 1.0850e-07, 8.6123e-08, 8.0422e-02, 8.8963e-02, 8.4201e-08,
        1.4457e-07, 7.6577e-08, 7.0156e-02, 8.5246e-02, 8.2822e-02, 2.5419e-07,
        1.0298e-01, 9.7975e-02, 4.3763e-07, 1.8124e-07, 4.3763e-07, 1.4457e-07,
        6.4645e-07, 1.0439e-01, 3.7252e-07, 1.0647e-01, 9.8916e-02, 8.9474e-02,
        1.0059e-01, 8.9756e-02, 1.0165e-01, 1.2410e-07, 8.9996e-02, 4.3046e-07,
        2.0275e-07, 8.3515e-02, 5.9282e-07, 8.8270e-02, 1.0131e-01, 1.2410e-07,
        9.8326e-02, 8.8312e-08, 9.6014e-02, 8.1520e-02, 1.2410e-07, 1.3191e-07,
        9.6721e-02, 1.4836e-07, 7.6975e-02, 4.3763e-07, 9.5222e-02, 1.0591e-01,
        1.0850e-07, 4.3763e-07, 8.8235e-02, 1.4457e-07, 4.0713e-07, 9.6681e-02,
        4.3763e-07, 4.3417e-02, 1.0609e-01, 8.6520e-02, 8.6398e-02, 7.2855e-02,
        1.4457e-07, 1.1654e-01, 1.1057e-01, 9.5026e-02, 1.0533e-01, 1.4457e-07,
        8.8155e-02, 8.3126e-02, 1.4457e-07, 1.0850e-07, 9.6302e-02, 1.1608e-01,
        5.9021e-07, 7.6794e-08, 4.0713e-07, 1.0232e-01, 7.6794e-08, 7.6387e-02,
        1.0850e-07, 3.7252e-07, 9.0810e-02, 1.4457e-07, 1.0850e-07, 9.5215e-02,
        1.0463e-01, 9.9735e-02, 9.0218e-02, 1.1529e-01, 8.5966e-02, 8.4486e-08,
        9.0180e-02, 1.4457e-07, 1.0850e-07, 8.4127e-02, 1.5045e-07, 2.0276e-07,
        2.4663e-07, 9.1020e-08, 9.7865e-02, 9.3587e-02, 9.3962e-02, 8.7931e-02,
        1.0447e-01, 9.9675e-02, 3.0483e-07, 1.0870e-01, 1.0850e-07, 1.1462e-01,
        8.8308e-08, 1.0538e-01, 8.7296e-02, 8.9362e-02, 1.0147e-01, 6.5548e-02,
        1.0850e-07, 1.0548e-01, 1.0850e-07, 1.2410e-07], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([2.1801e-06, 6.1671e-07, 1.6365e-06, 1.0482e-06, 1.8157e-06, 2.2954e-07,
        3.4322e-06, 1.8058e-06, 8.3377e-02, 2.6980e-06, 3.3831e-06, 4.3980e-07,
        7.3774e-02, 9.8897e-07, 5.3617e-07, 1.5727e-06, 2.2852e-02, 1.8058e-06,
        1.0482e-06, 8.4224e-07, 8.4090e-02, 3.4322e-06, 5.3617e-07, 1.0875e-06,
        8.7576e-02, 2.2640e-06, 4.0876e-06, 8.2868e-07, 6.6367e-02, 8.4224e-07,
        1.0875e-06, 1.0969e-06, 7.0044e-02, 6.1671e-07, 2.2640e-06, 1.0482e-06,
        2.2640e-06, 1.0482e-06, 9.6177e-07, 7.3532e-02, 1.5604e-06, 6.2085e-07,
        1.8157e-06, 8.7594e-02, 9.2698e-02, 8.8042e-02, 1.0875e-06, 1.5604e-06,
        2.2640e-06, 6.1671e-07, 8.4224e-07, 5.3617e-07, 7.4342e-06, 1.8157e-06,
        3.4322e-06, 2.5205e-06, 1.8058e-06, 6.1671e-07, 2.1566e-06, 1.5604e-06,
        1.1496e-06, 3.3822e-06, 8.9914e-02, 1.5604e-06, 1.6365e-06, 3.3822e-06,
        2.3384e-06, 2.1567e-06, 9.6177e-07, 8.4224e-07, 8.4077e-02, 1.8157e-06,
        7.8285e-02, 6.1671e-07, 7.1877e-02, 7.9099e-02, 3.8012e-06, 8.2657e-02,
        6.1671e-07, 2.3137e-07, 8.3639e-02, 1.0482e-06, 2.6980e-06, 2.2640e-06,
        8.2740e-02, 8.2377e-02, 2.1567e-06, 2.1566e-06, 1.6774e-06, 7.9657e-02,
        1.0482e-06, 3.8012e-06, 3.8012e-06, 8.1804e-02, 8.7813e-02, 1.8058e-06,
        8.5395e-02, 1.8157e-06, 8.0814e-07, 7.9823e-02, 1.6989e-06, 3.4202e-06,
        2.3384e-06, 7.8682e-02, 2.7553e-06, 4.1229e-07, 2.2640e-06, 2.1801e-06,
        3.3822e-06, 8.4224e-07, 5.3617e-07, 6.9011e-07, 6.1671e-07, 2.1801e-06,
        7.7911e-02, 2.2640e-06, 1.8157e-06, 8.4224e-07, 3.3227e-06, 7.4266e-02,
        6.1671e-07, 8.3121e-07, 9.6177e-07, 1.0482e-06, 7.9508e-02, 8.3314e-02,
        8.9894e-02, 7.9542e-02, 9.0277e-02, 1.2914e-06, 2.2762e-07, 3.8012e-06,
        7.8131e-02, 8.3034e-02, 9.2123e-02, 7.4488e-02, 8.5943e-02, 2.0584e-06,
        6.9933e-07, 7.8434e-02, 2.3384e-06, 9.6177e-07, 1.0875e-06, 9.9941e-02,
        1.1496e-06, 1.2914e-06, 2.5205e-06, 2.6980e-06, 2.6980e-06, 2.9249e-06,
        8.8354e-02, 1.0875e-06, 1.3608e-06, 7.5483e-02, 8.0814e-07, 1.4897e-06,
        7.6661e-02, 9.0387e-02, 1.8058e-06, 2.6980e-06, 6.1671e-07, 3.8012e-06,
        8.0465e-02, 2.1566e-06, 1.1496e-06, 8.5557e-02, 1.5604e-06, 8.2368e-02,
        1.5604e-06, 2.2640e-06, 1.3446e-06, 8.4224e-07, 1.5604e-06, 8.0814e-07,
        7.8249e-02, 2.3384e-06, 9.0959e-02, 1.4897e-06, 6.1671e-07, 1.8157e-06,
        8.4224e-07, 2.0668e-06, 9.1747e-02, 1.2819e-06, 9.2750e-07, 3.4070e-06,
        1.5604e-06, 9.6177e-07, 8.5698e-02, 9.1601e-07, 7.7104e-02, 1.4897e-06,
        8.2868e-07, 6.1671e-07, 1.7793e-06, 6.1671e-07, 8.5841e-07, 1.2819e-06,
        1.8157e-06, 2.1801e-06, 6.9027e-02, 2.2640e-06, 2.6980e-06, 8.1464e-02,
        9.0051e-02, 1.5604e-06, 3.8012e-06, 1.5604e-06, 9.2932e-02, 8.5138e-02,
        8.1994e-02, 8.6654e-02, 6.1671e-07, 1.0875e-06, 2.2640e-06, 6.1671e-07,
        6.1671e-07, 1.1496e-06, 5.3617e-07, 2.2640e-06, 3.3227e-06, 2.1567e-06,
        2.1566e-06, 8.8895e-02, 2.2640e-06, 3.8012e-06, 7.7584e-02, 6.1671e-07,
        7.6634e-02, 1.3446e-06, 9.1693e-02, 1.8157e-06, 5.3617e-07, 6.9933e-07,
        8.0673e-02, 3.3830e-06, 8.4805e-02, 6.9011e-07, 1.8157e-06, 1.7793e-06,
        1.0875e-06, 8.0396e-02, 1.9070e-06, 3.3374e-06, 1.5604e-06, 8.2987e-02,
        1.8058e-06, 6.7104e-02, 6.9011e-07, 8.4500e-02, 5.3617e-07, 2.2640e-06,
        7.1758e-02, 9.1601e-07, 9.5435e-02, 3.3831e-06], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([4.2295e-02, 1.8784e-07, 7.5204e-02,  ..., 1.9419e-07, 1.1648e-07,
        1.0862e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.6201e-02, 1.2210e-07, 3.2712e-02,  ..., 5.7080e-07, 7.0555e-07,
        6.0422e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([4.1445e-02, 3.4265e-02, 3.7991e-02, 8.9907e-07, 1.1423e-06, 4.0310e-02,
        3.1112e-07, 4.7479e-02, 5.0626e-07, 5.8180e-07, 5.4117e-07, 4.7260e-07,
        7.4017e-07, 2.5065e-07, 2.6741e-02, 5.4538e-07, 7.4017e-07, 4.1990e-02,
        3.8990e-02, 9.8789e-07, 5.8892e-07, 4.1108e-02, 1.3493e-01, 4.0473e-02,
        1.0826e-06, 1.7452e-06, 5.8892e-07, 1.4081e-06, 3.6015e-02, 3.9139e-02,
        1.0187e-06, 7.1411e-07, 1.6413e-02, 9.0786e-07, 3.5316e-07, 9.0786e-07,
        3.9481e-02, 4.2243e-02, 9.6219e-07, 5.5578e-02, 4.6547e-02, 2.0432e-07,
        1.4081e-06, 4.3561e-07, 4.3015e-02, 4.6653e-02, 3.5401e-02, 4.3198e-02,
        4.2131e-02, 3.7512e-02, 4.5629e-07, 1.3194e-06, 3.5316e-07, 4.2546e-02,
        8.1533e-07, 4.6347e-07, 1.6074e-06, 5.8892e-07, 1.2974e-06, 4.4293e-02,
        9.8656e-07, 6.3642e-07, 4.7104e-07, 6.6793e-07, 3.6325e-07, 5.0600e-07,
        3.4961e-02, 1.5251e-06, 1.2974e-06, 4.8371e-02, 2.6318e-02, 4.1834e-02,
        3.9892e-02, 3.5316e-07, 3.5316e-07, 4.4546e-02, 2.0432e-07, 1.1768e-06,
        3.2935e-02, 3.7040e-02, 1.5021e-02, 7.5127e-07, 5.0600e-07, 1.4081e-06,
        5.0503e-07, 7.8503e-07, 3.5033e-02, 3.9147e-02, 1.2774e-06, 9.8656e-07,
        1.2134e-06, 3.2552e-02, 8.9907e-07, 7.2865e-07, 7.5144e-07, 4.5825e-02,
        5.4117e-07, 2.3268e-07, 2.1545e-06, 7.8156e-07, 3.2800e-02, 5.4538e-07,
        3.9869e-02, 4.6641e-02, 3.7768e-02, 1.4081e-06, 1.6209e-06, 1.5417e-06,
        3.6325e-07, 5.0600e-07, 2.8026e-07, 5.5213e-07, 1.4173e-06, 1.4906e-06,
        1.1661e-06, 1.4081e-06, 3.6835e-02, 1.3993e-06, 1.4906e-06, 3.9712e-02,
        1.5512e-06, 1.4282e-06, 5.0503e-07, 1.1423e-06, 4.6604e-02, 7.9679e-07,
        1.2134e-06, 3.6444e-02, 7.6509e-07, 9.1015e-07, 1.9782e-06, 4.0715e-02,
        4.4317e-02, 6.7962e-07, 4.4329e-02, 4.3847e-07, 5.8966e-07, 5.5213e-07,
        7.8503e-07, 1.1423e-06, 7.6509e-07, 2.8724e-02, 3.6325e-07, 4.8012e-02,
        1.4081e-06, 1.3993e-06, 3.8375e-02, 4.3907e-02, 3.9082e-02, 3.9654e-02,
        5.3786e-02, 1.6209e-06, 1.1423e-06, 3.7629e-02, 4.3196e-02, 4.2236e-07,
        2.6852e-02, 6.6793e-07, 9.8656e-07, 2.0432e-07, 5.3814e-07, 2.3701e-02,
        3.1876e-02, 1.4081e-06, 6.1702e-07, 4.3597e-02, 4.7537e-02, 4.4130e-07,
        4.5629e-02, 3.9258e-02, 4.7322e-02, 3.7843e-02, 1.3993e-06, 5.8892e-07,
        4.3129e-02, 4.5473e-02, 5.3088e-07, 4.0200e-02, 3.7802e-02, 1.0826e-06,
        2.2263e-06, 4.7541e-02, 4.2059e-02, 7.2672e-07, 1.4081e-06, 4.0889e-03,
        4.1995e-02, 1.0826e-06, 4.3561e-07, 4.4783e-02, 3.7130e-02, 5.3925e-07,
        8.7334e-07, 1.0197e-06, 4.3466e-02, 1.4173e-06, 7.1358e-07, 5.8892e-07,
        3.9146e-02, 1.1423e-06, 9.3961e-07, 3.5316e-07, 3.9957e-02, 5.0600e-07,
        4.8378e-07, 7.0503e-07, 4.1825e-02, 1.4282e-06, 1.4173e-06, 5.8966e-07,
        4.4762e-02, 1.4924e-06, 3.8646e-02, 2.2205e-06, 1.3714e-06, 7.6509e-07,
        4.5562e-02, 5.7343e-02, 3.9356e-07, 9.1015e-07, 5.2773e-07, 8.0482e-07,
        1.0024e-06, 1.4388e-06, 9.1263e-07, 4.4130e-07, 4.2398e-02, 4.1981e-02,
        3.7559e-02, 4.9309e-02, 5.8892e-07, 4.3448e-07, 9.5482e-07, 2.0432e-07,
        4.2410e-02, 3.5827e-02, 8.6535e-07, 5.8966e-07, 1.5512e-06, 3.6738e-02,
        4.2025e-07, 1.4081e-06, 4.7397e-07, 1.6209e-06, 8.2191e-07, 4.2536e-02,
        1.0826e-06, 4.3345e-02, 4.4468e-02, 1.4081e-06, 1.3194e-06, 1.6209e-06,
        2.0785e-06, 5.4117e-07, 4.0519e-02, 2.8026e-07], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([6.1105e-02, 5.0911e-02, 1.6708e-07, 5.9514e-07, 6.8244e-02, 1.3907e-06,
        6.3077e-02, 1.8563e-06, 1.6393e-06, 8.2714e-07, 3.6648e-06, 1.6313e-06,
        3.8847e-06, 7.0307e-02, 6.4920e-02, 8.4182e-07, 2.4422e-06, 2.3487e-06,
        7.5887e-07, 4.6937e-02, 3.6171e-06, 2.1048e-06, 8.8943e-07, 2.4599e-06,
        8.7521e-07, 8.4182e-07, 8.4092e-07, 2.8981e-06, 7.1585e-02, 1.1893e-06,
        3.7119e-02, 6.6894e-02, 7.0797e-02, 2.1179e-06, 2.1048e-06, 5.0665e-02,
        5.0277e-02, 1.3907e-06, 8.2714e-07, 8.3867e-07, 6.1562e-02, 6.1904e-02,
        8.8943e-07, 2.0398e-06, 6.1604e-02, 5.8509e-02, 2.6440e-06, 6.6508e-02,
        6.2430e-02, 8.8943e-07, 2.4229e-06, 5.8230e-02, 1.1893e-06, 1.3907e-06,
        1.3053e-06, 2.1048e-06, 1.9239e-06, 5.1417e-02, 6.7491e-02, 2.0130e-06,
        2.5295e-06, 6.0079e-02, 2.8041e-06, 8.4182e-07, 6.2391e-02, 2.1048e-06,
        3.9847e-02, 6.0801e-02, 3.8847e-06, 8.8943e-07, 2.1048e-06, 7.5887e-07,
        1.3166e-06, 1.1990e-06, 5.9514e-07, 2.6440e-06, 8.4092e-07, 2.6440e-06,
        8.4961e-07, 6.9191e-02, 1.4602e-06, 6.9578e-02, 3.5952e-06, 1.8563e-06,
        2.3787e-06, 2.3787e-06, 5.9514e-07, 5.7471e-02, 7.5887e-07, 6.8286e-02,
        6.0190e-02, 5.5503e-07, 5.4772e-02, 5.9514e-07, 6.2619e-02, 7.0090e-07,
        1.5786e-06, 6.8435e-02, 6.4624e-02, 1.1990e-06, 2.3787e-06, 7.3041e-02,
        5.5784e-02, 5.7288e-07, 2.4229e-06, 1.8563e-06, 5.5953e-02, 2.3487e-06,
        1.0909e-06, 5.9805e-02, 6.6681e-02, 9.6392e-07, 2.6440e-06, 8.7521e-07,
        1.7593e-06, 5.9663e-02, 1.6393e-06, 2.4810e-06, 5.3621e-02, 9.8763e-07,
        6.9892e-02, 2.3787e-06, 1.4602e-06, 5.6557e-02, 3.3264e-06, 2.4810e-06,
        7.1175e-02, 6.9436e-02, 2.3787e-06, 6.6525e-02, 1.3907e-06, 2.4810e-06,
        1.0862e-06, 1.4602e-06, 6.5629e-02, 1.8563e-06, 1.2703e-06, 2.1924e-06,
        9.6392e-07, 7.3651e-02, 1.4602e-06, 1.2703e-06, 6.4173e-02, 6.9771e-02,
        3.8847e-06, 1.6393e-06, 2.9058e-06, 1.1990e-06, 6.4422e-02, 8.3867e-07,
        2.5848e-06, 8.2714e-07, 1.8563e-06, 3.8848e-06, 4.8876e-02, 6.3101e-02,
        8.3867e-07, 6.6245e-02, 2.4599e-06, 7.1538e-02, 1.2695e-06, 7.6287e-02,
        2.6440e-06, 4.4158e-02, 5.6196e-02, 6.1117e-02, 1.4602e-06, 7.5888e-07,
        1.3197e-06, 1.0862e-06, 2.3787e-06, 7.3040e-02, 2.6440e-06, 6.2256e-02,
        7.4656e-02, 3.9304e-02, 2.3787e-06, 2.4810e-06, 4.9652e-06, 1.7716e-06,
        6.0194e-02, 2.6440e-06, 1.0862e-06, 9.6392e-07, 1.0556e-06, 8.8943e-07,
        8.4182e-07, 7.1772e-02, 5.5503e-07, 2.1048e-06, 1.3907e-06, 6.7459e-02,
        1.8470e-06, 1.3907e-06, 1.0909e-06, 6.2186e-02, 8.8943e-07, 7.5887e-07,
        2.4810e-06, 3.8365e-06, 5.5683e-02, 8.3867e-07, 6.2679e-02, 8.4182e-07,
        2.4422e-06, 1.0524e-06, 1.7858e-06, 9.9169e-07, 1.9239e-06, 9.4306e-07,
        6.5288e-02, 9.9169e-07, 6.9269e-02, 9.8763e-07, 6.8148e-02, 1.1893e-06,
        5.8105e-02, 1.4920e-06, 5.9514e-07, 6.2179e-02, 5.1102e-02, 1.1893e-06,
        1.0862e-06, 5.4534e-02, 2.6440e-06, 5.7288e-07, 5.0143e-02, 2.6440e-06,
        7.5887e-07, 3.7752e-06, 8.8943e-07, 8.2714e-07, 1.9239e-06, 6.2566e-02,
        2.6440e-06, 1.9239e-06, 5.9453e-02, 2.3487e-06, 6.6866e-02, 6.1012e-02,
        6.0681e-02, 2.4810e-06, 1.9239e-06, 1.3879e-06, 1.6393e-06, 7.0256e-02,
        5.8076e-02, 5.1094e-02, 7.5264e-02, 7.1375e-02, 1.1990e-06, 8.4092e-07,
        1.0909e-06, 6.9878e-02, 3.8357e-06, 8.4719e-07], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([5.4288e-02, 3.9508e-08, 8.0579e-02,  ..., 4.9731e-08, 1.4863e-07,
        3.5038e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([5.9543e-02, 4.6406e-02, 6.4585e-07, 4.4086e-07, 1.9578e-06, 3.3645e-07,
        5.8238e-02, 4.5659e-07, 6.2359e-02, 1.4916e-06, 7.0086e-07, 3.7183e-02,
        5.7970e-02, 5.1641e-02, 5.7065e-07, 1.3139e-06, 1.0080e-06, 4.8184e-07,
        9.5039e-07, 1.1353e-06, 1.3193e-06, 4.9615e-07, 1.0120e-06, 1.0080e-06,
        1.3198e-06, 3.3739e-07, 3.6805e-07, 5.5593e-02, 5.0364e-02, 6.3299e-07,
        5.0123e-07, 5.0915e-07, 3.6339e-07, 4.4943e-02, 7.2691e-07, 6.4585e-07,
        1.2395e-01, 4.5659e-07, 5.3063e-02, 8.5519e-07, 5.5838e-02, 1.0080e-06,
        5.2467e-02, 1.7155e-06, 1.0120e-06, 1.1697e-01, 7.1742e-07, 4.4300e-02,
        6.0629e-02, 1.9619e-06, 4.9868e-02, 5.4196e-02, 1.3139e-06, 6.3313e-07,
        4.9366e-02, 6.7378e-02, 1.0120e-06, 1.2495e-01, 1.3139e-06, 4.6060e-02,
        7.9812e-07, 6.5800e-02, 4.1045e-07, 4.9276e-02, 5.0915e-07, 1.0120e-06,
        5.7637e-02, 1.3139e-06, 2.1916e-07, 3.1018e-06, 4.7910e-02, 1.3654e-06,
        1.7038e-06, 6.2120e-02, 5.8867e-02, 9.3745e-07, 1.0080e-06, 7.0267e-07,
        9.4084e-07, 5.6320e-02, 5.1702e-02, 5.3494e-02, 5.8683e-02, 7.8128e-07,
        9.6809e-07, 5.8495e-02, 4.2939e-07, 5.4583e-02, 1.4916e-06, 1.0080e-06,
        1.3139e-06, 7.0086e-07, 5.5171e-07, 4.6928e-02, 1.0120e-06, 1.4916e-06,
        3.1919e-07, 6.2511e-02, 5.6102e-02, 7.9812e-07, 4.7760e-02, 4.2368e-02,
        2.0162e-06, 4.4809e-02, 4.7246e-02, 7.7065e-07, 4.0698e-07, 4.2138e-07,
        1.9340e-06, 4.8184e-07, 5.6573e-02, 1.2635e-06, 5.2015e-02, 5.7860e-07,
        4.4086e-07, 5.0649e-07, 9.5174e-07, 5.7733e-02, 5.8685e-02, 4.1170e-02,
        9.1896e-07, 4.2422e-02, 1.2481e-01, 7.1742e-07, 6.9796e-07, 5.4673e-02,
        5.5991e-02, 3.6805e-07, 3.9441e-07, 1.5629e-06, 1.0080e-06, 1.5236e-06,
        6.5394e-02, 5.1283e-02, 4.1045e-07, 5.7948e-02, 5.1424e-02, 6.1488e-07,
        3.3618e-07, 8.0405e-07, 3.8260e-02, 4.9868e-07, 5.8594e-02, 2.0757e-06,
        5.3781e-07, 5.0915e-07, 1.1846e-01, 1.0527e-06, 2.0161e-06, 5.9464e-02,
        9.3186e-07, 7.7966e-07, 3.6339e-07, 3.9112e-07, 6.1592e-02, 4.6960e-02,
        1.1485e-01, 4.8743e-02, 5.1120e-02, 1.0120e-06, 9.3745e-07, 5.4410e-02,
        3.9112e-07, 7.0267e-07, 6.7933e-07, 6.6554e-02, 4.9241e-02, 9.3745e-07,
        6.6001e-02, 1.0120e-06, 4.4868e-07, 1.2808e-06, 4.1174e-02, 1.3139e-06,
        6.0585e-02, 1.3139e-06, 1.2519e-06, 5.1628e-02, 3.6805e-07, 4.7473e-02,
        6.2842e-07, 5.0915e-07, 2.6649e-07, 4.4889e-07, 5.0930e-02, 5.0544e-02,
        5.7178e-07, 6.6727e-02, 1.0690e-06, 3.6805e-07, 4.5659e-07, 3.9095e-07,
        5.4968e-02, 1.3193e-06, 8.5519e-07, 6.8836e-07, 4.8577e-07, 4.1477e-07,
        1.6222e-06, 1.0316e-06, 4.3843e-02, 9.1896e-07, 4.0698e-07, 2.5722e-07,
        9.3745e-07, 2.0092e-06, 1.0690e-06, 1.4916e-06, 7.2691e-07, 1.3139e-06,
        4.6516e-07, 1.9795e-06, 5.8667e-02, 4.8652e-02, 4.4086e-07, 5.0915e-07,
        9.5174e-07, 4.4758e-02, 2.0092e-06, 1.3139e-06, 6.2848e-02, 5.8610e-02,
        5.7986e-07, 5.6552e-02, 4.1045e-07, 1.3914e-06, 6.0604e-02, 1.0690e-06,
        4.1858e-07, 4.9934e-02, 5.3046e-02, 1.0120e-06, 6.8836e-07, 7.3324e-07,
        4.4086e-07, 3.8191e-02, 7.7065e-07, 6.1488e-07, 5.9268e-02, 4.5659e-07,
        6.7933e-07, 3.6805e-07, 9.5039e-07, 5.7860e-07, 5.7053e-07, 8.5973e-02,
        2.7692e-07, 6.4012e-02, 1.3126e-06, 5.7783e-02, 1.0700e-06, 5.8275e-02,
        1.2337e-06, 5.5171e-07, 7.0086e-07, 9.3745e-07], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([1.7176e-02, 4.3038e-06, 3.4174e-06, 3.2713e-06, 3.3805e-06, 2.8393e-02,
        2.1107e-06, 2.8618e-06, 2.8823e-06, 1.0091e-06, 4.3923e-06, 1.3013e-06,
        6.8056e-06, 2.0061e-02, 1.5112e-06, 2.8502e-02, 9.4697e-02, 1.7475e-06,
        2.0314e-06, 6.6480e-06, 2.6970e-02, 2.6229e-06, 2.6018e-02, 9.9961e-07,
        2.3870e-06, 3.4174e-06, 2.8300e-06, 2.8823e-06, 3.2379e-06, 3.4783e-06,
        4.4891e-06, 3.0703e-06, 2.7220e-02, 2.3186e-02, 2.1107e-06, 3.2922e-06,
        3.1310e-06, 3.3913e-06, 1.4153e-06, 3.1660e-06, 2.4586e-02, 2.6266e-02,
        4.1214e-06, 1.9203e-06, 3.8267e-06, 2.6229e-06, 2.6582e-06, 1.7475e-06,
        1.4387e-06, 5.0864e-06, 5.1135e-06, 1.0632e-06, 8.1192e-02, 2.5927e-02,
        1.3635e-06, 1.4661e-06, 2.2493e-06, 2.5665e-02, 2.1107e-06, 1.9476e-02,
        2.4675e-02, 5.4748e-06, 2.9657e-06, 2.3932e-02, 1.3013e-06, 1.9530e-06,
        1.7655e-07, 2.4463e-06, 1.0977e-06, 2.7062e-02, 3.2988e-06, 7.8344e-02,
        1.4173e-06, 1.4117e-06, 1.0977e-06, 3.0231e-02, 1.5229e-06, 2.5035e-06,
        4.7370e-06, 2.1293e-06, 1.4117e-06, 9.2117e-02, 2.4911e-06, 3.7722e-06,
        6.0450e-06, 6.6902e-02, 3.7209e-06, 6.0307e-02, 1.9691e-06, 1.5526e-06,
        6.2838e-06, 2.2232e-06, 7.3505e-02, 9.2245e-06, 1.7175e-06, 6.8883e-02,
        1.7070e-06, 2.4682e-06, 3.2895e-02, 2.5227e-06, 4.6964e-06, 6.7158e-02,
        6.9034e-02, 1.0403e-06, 2.6466e-02, 2.8823e-06, 1.0403e-06, 2.0959e-02,
        1.9467e-06, 4.7920e-02, 2.9868e-06, 4.4238e-06, 4.6410e-06, 1.8465e-06,
        1.0895e-06, 2.9824e-06, 5.3148e-06, 1.3839e-06, 2.1865e-06, 1.7475e-06,
        5.4459e-06, 1.2673e-06, 1.7475e-06, 4.3639e-06, 2.0376e-02, 3.4276e-06,
        2.9681e-06, 3.5886e-06, 3.5744e-06, 2.9868e-06, 3.4174e-06, 2.3667e-02,
        3.5747e-06, 6.0450e-06, 3.4540e-06, 5.9686e-06, 1.3751e-06, 2.1170e-06,
        4.0274e-06, 3.3753e-02, 1.0971e-06, 3.7515e-06, 2.1098e-06, 2.9868e-06,
        3.9954e-06, 5.8740e-02, 1.5229e-06, 2.2879e-06, 5.0888e-06, 2.7998e-06,
        1.7474e-06, 6.2055e-06, 1.6793e-06, 5.0551e-06, 2.7901e-02, 2.4691e-06,
        2.2232e-06, 1.0166e-06, 3.8558e-06, 4.4748e-06, 1.7474e-06, 7.1721e-02,
        2.5227e-06, 6.0286e-06, 2.6582e-06, 5.0551e-06, 5.0888e-06, 4.1141e-06,
        2.9054e-06, 1.8465e-06, 1.9580e-02, 6.1045e-06, 5.2973e-06, 2.3527e-06,
        1.4153e-06, 4.0274e-06, 3.0374e-02, 5.1307e-06, 3.6577e-06, 2.3747e-06,
        6.7663e-02, 3.9626e-06, 2.0105e-06, 3.4636e-07, 6.2681e-06, 2.1107e-06,
        1.7655e-07, 2.2717e-06, 6.0286e-06, 2.4427e-06, 3.0166e-06, 1.9467e-06,
        1.7474e-06, 3.2217e-06, 9.2643e-02, 1.4781e-06, 5.0551e-06, 1.5122e-06,
        2.6623e-06, 2.8300e-06, 3.8767e-06, 1.7827e-06, 1.6842e-06, 3.1210e-06,
        1.8465e-06, 1.5229e-06, 2.2488e-02, 3.4174e-06, 1.0553e-06, 4.6207e-06,
        2.1107e-06, 2.6582e-06, 2.8691e-02, 2.1130e-06, 2.9868e-06, 5.0888e-06,
        2.8021e-06, 2.3870e-06, 3.4532e-02, 2.8300e-06, 2.3443e-06, 4.0344e-02,
        2.4068e-06, 2.6882e-06, 3.8063e-06, 2.9440e-02, 3.4088e-06, 2.6878e-06,
        3.4557e-06, 9.2547e-02, 9.7765e-07, 2.6554e-02, 6.9581e-02, 8.6843e-02,
        4.4395e-06, 3.4174e-06, 4.6958e-06, 1.8258e-06, 2.9821e-02, 2.8823e-06,
        3.5784e-06, 3.4926e-06, 1.2547e-06, 1.9691e-06, 2.0138e-06, 5.1754e-06,
        1.4387e-06, 1.7475e-06, 7.5375e-02, 2.6582e-06, 7.8273e-02, 2.2276e-06,
        2.8986e-02, 6.3752e-06, 5.0722e-06, 2.5469e-02], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([2.7674e-07, 3.4916e-07, 1.8395e-07,  ..., 1.5308e-07, 3.6467e-07,
        3.1686e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.0710e-06, 1.3681e-06, 7.2406e-07, 7.9646e-07, 7.2634e-07, 2.6286e-06,
        1.0278e-06, 2.3007e-06, 1.3265e-06, 3.6722e-07, 3.8281e-07, 2.2121e-06,
        2.3237e-07, 3.2295e-07, 1.3000e-06, 1.3459e-06, 1.0289e-06, 7.9820e-07,
        1.0425e-06, 2.4686e-06, 2.1568e-06, 1.5819e-06, 1.5565e-06, 3.4798e-06,
        1.1622e-06, 1.8379e-06, 1.8923e-06, 1.2436e-06, 5.1517e-07, 1.4681e-06,
        7.3584e-07, 1.4861e-06, 1.0425e-06, 2.9521e-06, 1.0980e-06, 1.0718e-06,
        7.9633e-07, 1.7649e-06, 3.8327e-07, 2.0296e-06, 1.8498e-06, 8.9882e-07,
        7.9646e-07, 7.9647e-07, 1.1368e-06, 1.4038e-06, 1.0546e-06, 1.8761e-06,
        6.5658e-07, 1.8732e-06, 1.9795e-06, 1.2410e-06, 1.0710e-06, 2.3270e-06,
        3.9514e-07, 9.5453e-07, 3.9513e-07, 6.1064e-07, 1.9500e-06, 6.3215e-07,
        8.3011e-07, 2.0130e-06, 1.4786e-06, 6.5714e-07, 1.2410e-06, 9.6476e-07,
        1.2201e-06, 1.9261e-06, 2.2121e-06, 1.4411e-06, 2.1150e-06, 8.6352e-07,
        1.3469e-06, 1.5285e-06, 3.0823e-06, 3.1152e-06, 8.7042e-07, 9.1024e-07,
        4.4668e-07, 1.2436e-06, 1.2880e-01, 1.7936e-06, 1.1311e-06, 1.3579e-06,
        4.2239e-07, 1.5396e-06, 2.1873e-06, 1.8923e-06, 2.1430e-06, 1.8236e-06,
        7.9646e-07, 7.4311e-07, 6.5001e-07, 3.9513e-07, 2.3149e-06, 1.3681e-06,
        3.0829e-06, 2.3237e-07, 5.2273e-07, 8.6718e-07, 9.5843e-07, 3.0823e-06,
        2.2553e-06, 5.7641e-07, 3.1003e-06, 8.2408e-07, 1.3121e-06, 1.4046e-06,
        2.1150e-06, 1.2746e-06, 1.7622e-06, 1.8140e-06, 2.2121e-06, 7.3584e-07,
        9.4473e-07, 1.7075e-06, 2.3605e-06, 8.3346e-07, 1.0958e-06, 2.2319e-06,
        1.9647e-06, 1.8568e-06, 1.0546e-06, 2.7163e-06, 1.5225e-06, 9.7964e-07,
        1.0710e-06, 5.1197e-07, 1.0546e-06, 3.3717e-06, 2.3237e-07, 2.4617e-07,
        1.5942e-06, 7.9646e-07, 1.8257e-06, 2.1235e-06, 4.9324e-07, 6.3713e-07,
        2.2484e-06, 8.6717e-07, 8.4892e-07, 1.1286e-06, 9.5843e-07, 9.6476e-07,
        1.9647e-06, 1.5347e-06, 1.2746e-06, 7.9646e-07, 2.2121e-06, 1.3458e-06,
        1.1402e-06, 1.5565e-06, 4.0520e-07, 1.3280e-06, 9.4291e-07, 1.6205e-06,
        7.3218e-07, 1.2073e-06, 6.1425e-07, 1.5127e-06, 1.6777e-06, 1.1402e-06,
        2.3535e-06, 2.0425e-06, 1.3529e-06, 1.3291e-06, 1.2335e-06, 1.3458e-06,
        4.0927e-07, 9.5451e-02, 1.1885e-06, 1.1674e-06, 5.1651e-07, 8.4344e-07,
        1.4786e-06, 7.9646e-07, 8.3852e-07, 9.5453e-07, 9.5843e-07, 2.5751e-06,
        1.8568e-06, 1.7649e-06, 8.3346e-07, 8.4892e-07, 2.1150e-06, 1.4180e-06,
        8.3689e-07, 1.2746e-06, 6.1425e-07, 1.0648e-06, 7.2587e-07, 1.8923e-06,
        7.4178e-07, 1.4194e-06, 1.8346e-06, 1.8568e-06, 1.8923e-06, 2.4686e-06,
        1.9923e-06, 6.5714e-07, 1.7209e-06, 1.4783e-06, 1.0058e-06, 6.8694e-07,
        6.8314e-07, 9.2071e-07, 6.0876e-07, 2.0474e-06, 1.8179e-06, 7.4311e-07,
        2.4686e-06, 3.9760e-06, 1.4987e-06, 1.3993e-06, 1.5071e-06, 3.1529e-06,
        1.8568e-06, 1.4517e-06, 9.6502e-07, 9.1024e-07, 1.9394e-06, 9.1024e-07,
        1.4865e-06, 1.3512e-06, 1.7587e-06, 2.2273e-06, 3.9513e-07, 1.1368e-06,
        1.8568e-06, 9.1024e-07, 1.3512e-06, 7.9646e-07, 2.4686e-06, 1.8568e-06,
        2.4617e-07, 9.5843e-07, 1.4921e-06, 1.4783e-06, 7.2634e-07, 1.2201e-06,
        1.9394e-06, 2.9349e-06, 6.8969e-07, 3.0823e-06, 1.4921e-06, 1.5565e-06,
        9.4473e-07, 5.9824e-07, 5.7641e-07, 1.5324e-06, 1.3944e-06, 9.9561e-07,
        9.1556e-07, 1.1956e-06, 6.5714e-07, 2.1430e-06], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([2.1260e-06, 6.7795e-07, 1.1879e-06, 2.9843e-06, 1.1196e-06, 2.9148e-06,
        3.4946e-06, 5.2258e-06, 4.2995e-06, 2.4121e-06, 5.8166e-06, 2.1260e-06,
        2.7478e-06, 5.3725e-06, 2.7666e-06, 6.3182e-06, 6.7866e-06, 1.8344e-06,
        3.7591e-06, 6.0596e-06, 3.0338e-06, 5.2197e-06, 5.3438e-06, 2.5272e-06,
        1.5878e-06, 9.1760e-06, 4.8518e-06, 4.6551e-06, 1.5258e-06, 2.4542e-06,
        1.1386e-06, 1.3906e-06, 8.5966e-06, 5.4644e-06, 3.2935e-06, 2.2371e-06,
        1.7071e-06, 4.6774e-06, 3.6613e-06, 1.7401e-06, 2.3672e-06, 7.0681e-06,
        8.5154e-07, 5.0681e-06, 4.7273e-06, 1.3823e-06, 5.5817e-06, 3.8811e-06,
        8.0793e-06, 6.6054e-06, 1.6967e-06, 3.7832e-06, 6.8774e-06, 7.5763e-06,
        4.4568e-06, 2.6133e-06, 3.1024e-06, 3.2815e-06, 7.9531e-06, 1.4051e-06,
        3.1268e-06, 6.0181e-06, 4.3495e-06, 4.1270e-06, 9.8281e-07, 4.7593e-06,
        5.6198e-06, 7.6702e-06, 1.2224e-06, 6.0872e-06, 7.3569e-06, 3.1827e-06,
        2.0015e-06, 7.5897e-06, 8.4746e-06, 3.2935e-06, 9.9624e-07, 6.6564e-06,
        3.3274e-06, 3.4376e-06, 2.0917e-06, 1.5878e-06, 3.9640e-06, 5.8338e-06,
        9.3931e-07, 2.0130e-06, 2.3672e-06, 2.4085e-06, 2.3921e-06, 5.0581e-06,
        3.2906e-06, 2.4865e-06, 5.2413e-06, 4.0041e-06, 6.7866e-06, 5.3199e-06,
        4.9934e-06, 5.7040e-06, 2.6281e-06, 1.5878e-06, 6.0872e-06, 2.4865e-06,
        2.3982e-06, 2.6215e-06, 4.0612e-06, 4.6774e-06, 3.5360e-06, 4.5716e-06,
        4.9927e-06, 5.9026e-06, 1.2734e-06, 6.1760e-06, 2.2439e-06, 3.7625e-06,
        7.5035e-06, 5.6338e-06, 1.5409e-06, 2.9397e-06, 3.4650e-06, 4.9927e-06,
        3.5867e-06, 2.3874e-06, 6.0596e-06, 4.8214e-06, 1.1386e-06, 2.7610e-06,
        4.2835e-06, 4.0336e-06, 1.7071e-06, 1.7240e-06, 1.4765e-06, 5.8166e-06,
        2.9802e-06, 4.5597e-06, 7.9152e-06, 1.1029e-06, 3.1141e-06, 6.4542e-06,
        5.1658e-06, 7.6106e-06, 1.7720e-06, 4.3478e-06, 3.3874e-06, 2.6319e-06,
        6.3980e-06, 4.4086e-06, 6.1420e-06, 6.1693e-06, 1.8410e-06, 4.0005e-06,
        3.2125e-06, 3.9032e-06, 2.8095e-06, 2.8335e-06, 6.5922e-06, 8.6527e-06,
        2.6947e-06, 3.6608e-06, 3.5975e-06, 3.3042e-06, 2.5958e-06, 5.2711e-06,
        4.2050e-06, 2.6215e-06, 4.0176e-06, 5.0735e-06, 2.2550e-06, 3.6033e-06,
        5.6338e-06, 5.2824e-06, 8.2417e-06, 3.1370e-06, 3.5360e-06, 5.2034e-06,
        6.0134e-06, 3.2936e-06, 3.5092e-06, 2.9431e-06, 1.8535e-06, 2.8909e-06,
        2.8095e-06, 3.8585e-06, 3.9619e-06, 4.6065e-06, 4.0807e-06, 3.5360e-06,
        4.1049e-06, 4.2835e-06, 4.2835e-06, 1.5878e-06, 1.2378e-05, 4.3744e-06,
        2.6431e-06, 2.8633e-06, 2.8524e-06, 3.7367e-06, 4.2674e-06, 3.2936e-06,
        4.2414e-06, 4.4264e-06, 6.2104e-06, 2.6133e-06, 9.2819e-07, 2.9255e-06,
        8.2096e-06, 4.2835e-06, 6.3929e-06, 4.2835e-06, 5.4739e-06, 1.3898e-06,
        4.0369e-06, 2.3874e-06, 2.0912e-06, 5.9026e-06, 6.0846e-06, 2.0015e-06,
        1.7984e-01, 9.2819e-07, 5.2258e-06, 4.8214e-06, 3.4376e-06, 3.3046e-06,
        1.7071e-06, 3.9210e-06, 7.1772e-06, 3.4593e-06, 1.6319e-06, 1.4051e-06,
        3.1633e-06, 4.6683e-06, 4.5850e-06, 5.1658e-06, 3.0567e-06, 4.9934e-06,
        4.3409e-06, 4.2835e-06, 3.5504e-06, 2.5309e-06, 5.3495e-06, 3.0567e-06,
        6.0872e-06, 1.0243e-05, 3.2033e-06, 2.6992e-06, 2.7014e-06, 3.4364e-06,
        2.9088e-06, 3.9640e-06, 3.8001e-06, 6.3929e-06, 9.2234e-07, 4.6774e-06,
        4.2835e-06, 4.4040e-06, 1.9463e-06, 8.1909e-06], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([3.9168e-07, 2.7524e-07, 2.6113e-07,  ..., 1.1651e-07, 1.8906e-07,
        4.1945e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([3.5881e-07, 3.2703e-07, 2.8544e-06, 9.1230e-07, 9.4703e-07, 1.0956e-06,
        1.6997e-06, 6.1961e-07, 1.5748e-06, 2.8553e-06, 1.0901e-06, 9.7256e-07,
        4.7839e-07, 8.1095e-07, 1.1631e-06, 2.1694e-06, 9.1252e-07, 1.0349e-06,
        1.5857e-06, 9.6395e-07, 2.4757e-06, 1.5557e-06, 3.1128e-07, 3.8152e-07,
        1.4358e-06, 1.2086e-06, 9.8111e-07, 1.2036e-06, 4.4298e-07, 4.4298e-07,
        7.8258e-07, 8.6624e-07, 9.8111e-07, 1.6997e-06, 1.9530e-06, 1.0914e-06,
        3.8152e-07, 1.5557e-06, 4.6622e-07, 1.8391e-06, 1.4358e-06, 1.3066e-06,
        2.5624e-06, 9.9311e-07, 1.5892e-06, 3.2703e-07, 1.1413e-06, 1.0913e-06,
        1.1250e-06, 9.9311e-07, 2.4562e-06, 4.7839e-07, 5.9685e-07, 3.7476e-07,
        4.7083e-07, 1.6605e-06, 1.0913e-06, 2.1694e-06, 2.0463e-06, 1.5760e-06,
        4.7244e-07, 1.2273e-06, 5.2123e-07, 6.8040e-07, 1.3289e-06, 2.8546e-06,
        9.0010e-07, 2.1694e-06, 4.4298e-07, 1.2036e-06, 5.1160e-07, 3.2703e-07,
        7.8317e-07, 9.8111e-07, 9.7256e-07, 1.0222e-06, 2.8887e-07, 1.0685e-06,
        1.8345e-06, 1.1137e-06, 9.0090e-07, 4.7839e-07, 7.2574e-07, 2.5624e-06,
        2.7652e-06, 2.1694e-06, 1.0713e-06, 1.5099e-06, 9.8111e-07, 5.6268e-07,
        1.1063e-06, 6.4560e-07, 4.4298e-07, 1.5372e-06, 3.1001e-07, 1.3066e-06,
        1.0851e-06, 9.1230e-07, 9.5375e-07, 1.9157e-06, 4.4298e-07, 1.8916e-06,
        3.8152e-07, 9.1230e-07, 1.0851e-06, 1.6047e-06, 9.1252e-07, 2.1209e-06,
        4.7839e-07, 1.0913e-06, 6.1961e-07, 1.2669e-06, 6.0151e-07, 1.5557e-06,
        2.4649e-06, 1.8391e-06, 8.7900e-07, 2.8461e-06, 1.6605e-06, 1.0335e-06,
        9.4517e-07, 1.8916e-06, 4.4298e-07, 5.2123e-07, 1.3289e-06, 1.6693e-06,
        4.0012e-07, 1.1754e-06, 5.8571e-07, 9.0090e-07, 1.0913e-06, 1.5099e-06,
        1.9398e-06, 1.5557e-06, 4.7839e-07, 1.2419e-06, 4.6622e-07, 2.7652e-06,
        1.5557e-06, 4.6622e-07, 7.2574e-07, 1.0004e-06, 5.6152e-07, 4.8850e-07,
        6.4560e-07, 4.6622e-07, 1.0499e-06, 1.0182e-06, 1.2083e-06, 1.8916e-06,
        2.7348e-06, 1.0004e-06, 1.8391e-06, 2.6334e-06, 1.2086e-06, 9.4517e-07,
        1.0189e-06, 9.4703e-07, 2.1209e-06, 2.1694e-06, 1.8916e-06, 7.7978e-07,
        1.5748e-06, 5.9685e-07, 4.7839e-07, 1.3066e-06, 1.1063e-06, 3.7476e-07,
        1.4358e-06, 1.0913e-06, 1.0040e-06, 1.8345e-06, 1.3782e-06, 9.4703e-07,
        1.2273e-06, 4.4298e-07, 1.0713e-06, 1.3237e-06, 6.4560e-07, 3.7086e-06,
        1.2273e-06, 1.0004e-06, 4.7839e-07, 1.5188e-06, 3.5244e-07, 8.0785e-07,
        9.1754e-07, 3.7086e-06, 1.6709e-06, 1.1063e-06, 1.2273e-06, 9.1252e-07,
        1.2086e-06, 9.0172e-07, 9.0025e-07, 1.7223e-06, 5.6152e-07, 1.1063e-06,
        1.9157e-06, 1.2669e-06, 1.8916e-06, 6.8314e-07, 9.0090e-07, 6.4560e-07,
        1.2273e-06, 1.6047e-06, 1.2273e-06, 4.9348e-07, 6.8314e-07, 4.7839e-07,
        4.4298e-07, 1.5748e-06, 6.1961e-07, 1.1137e-06, 6.4789e-07, 1.7234e-06,
        1.6271e-06, 7.7978e-07, 1.1260e-06, 1.4532e-06, 1.6011e-06, 1.4056e-06,
        4.6622e-07, 3.8152e-07, 6.1961e-07, 1.5099e-06, 9.8111e-07, 1.0763e-07,
        2.1694e-06, 1.5500e-06, 1.8391e-06, 1.2286e-06, 4.7839e-07, 3.8152e-07,
        2.1694e-06, 3.8152e-07, 8.2249e-07, 2.2732e-06, 1.3145e-06, 9.2745e-07,
        9.1230e-07, 5.6152e-07, 4.6622e-07, 6.1961e-07, 1.1582e-06, 3.6127e-07,
        8.7705e-07, 1.8916e-06, 3.7086e-06, 8.7705e-07, 1.3908e-06, 9.8111e-07,
        6.8314e-07, 1.5557e-06, 2.8557e-06, 1.2563e-06], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([1.8753e-06, 4.3183e-06, 5.1640e-06, 3.6744e-06, 3.1467e-06, 5.1005e-06,
        3.2980e-06, 2.4481e-06, 1.1613e-06, 3.4916e-06, 5.5635e-06, 1.8358e-06,
        2.6076e-06, 1.7374e-06, 1.1338e-06, 1.6969e-06, 1.6744e-06, 3.7219e-06,
        2.1589e-06, 2.2215e-06, 2.6113e-06, 4.4879e-06, 3.1184e-06, 4.8801e-06,
        3.7695e-06, 2.9494e-07, 3.2522e-06, 3.4848e-06, 4.0536e-06, 5.7335e-06,
        3.2688e-06, 4.9135e-06, 3.0524e-06, 3.4219e-06, 1.6969e-06, 2.8448e-06,
        3.5220e-06, 1.4170e-06, 5.1005e-06, 1.9583e-06, 1.5289e-06, 5.1452e-06,
        1.9576e-06, 3.0396e-06, 2.5047e-06, 1.0781e-06, 2.1152e-06, 2.2597e-06,
        3.9721e-06, 5.5346e-06, 6.5349e-07, 2.2104e-06, 1.0949e-06, 1.7374e-06,
        3.6186e-06, 4.2790e-06, 3.3300e-06, 2.9495e-07, 2.8657e-06, 3.6809e-07,
        3.0116e-06, 6.5134e-06, 3.2980e-06, 3.1024e-06, 4.4740e-06, 1.7085e-06,
        2.8657e-06, 4.6386e-06, 3.8532e-06, 1.9576e-06, 5.6555e-07, 2.0984e-06,
        2.2215e-06, 2.0974e-06, 1.3299e-07, 3.3890e-06, 3.3418e-06, 5.9579e-06,
        1.9679e-06, 2.2364e-06, 2.4666e-06, 2.2261e-06, 2.4463e-06, 4.5251e-06,
        3.6159e-06, 1.4918e-06, 5.6889e-06, 3.3418e-06, 1.6057e-06, 4.2790e-06,
        2.8448e-06, 3.3718e-06, 1.4967e-06, 5.3040e-06, 2.4547e-06, 4.0536e-06,
        2.8971e-06, 2.3434e-06, 5.6889e-06, 6.0535e-06, 2.5450e-06, 1.9758e-06,
        7.3514e-06, 5.3667e-06, 1.4759e-06, 4.3659e-06, 4.0623e-06, 1.1786e-06,
        2.9664e-06, 2.6426e-06, 5.3670e-06, 7.0264e-06, 1.9370e-06, 2.4907e-06,
        3.5235e-06, 2.6721e-06, 3.0396e-06, 9.1081e-07, 2.8534e-06, 3.3526e-06,
        2.9503e-06, 5.0589e-06, 4.6505e-06, 5.0589e-06, 6.7658e-06, 3.6744e-06,
        2.0984e-06, 2.1886e-06, 1.6337e-06, 5.6889e-06, 2.9495e-07, 1.8727e-06,
        8.5660e-07, 7.3069e-07, 3.5235e-06, 2.0984e-06, 2.8778e-06, 2.3729e-06,
        1.7695e-06, 1.9576e-06, 1.8753e-06, 2.9503e-06, 1.6744e-06, 5.9342e-06,
        2.8657e-06, 6.5349e-07, 2.3540e-06, 4.3975e-06, 1.4088e-06, 3.6992e-06,
        1.3300e-07, 2.4037e-06, 2.3729e-06, 9.0659e-07, 4.3809e-07, 5.0981e-06,
        3.1184e-06, 8.1588e-07, 1.7215e-06, 1.9679e-06, 1.4918e-06, 1.5140e-06,
        2.1720e-06, 3.4287e-06, 3.4218e-06, 3.6955e-06, 4.4740e-06, 3.2102e-06,
        2.4666e-06, 1.5289e-06, 2.4463e-06, 5.4063e-06, 7.1111e-06, 9.5002e-07,
        2.4662e-06, 2.8371e-06, 1.2935e-06, 3.4219e-06, 5.3667e-06, 1.4967e-06,
        3.1467e-06, 4.5112e-06, 1.7799e-06, 2.2215e-06, 1.8358e-06, 7.9473e-07,
        1.3298e-07, 2.0984e-06, 1.5906e-06, 1.7473e-07, 2.0984e-06, 2.9385e-06,
        2.0984e-06, 2.6426e-06, 3.4354e-06, 5.9342e-06, 4.5653e-06, 1.5140e-06,
        1.8753e-06, 2.3645e-06, 1.9252e-06, 2.4547e-06, 3.0036e-06, 2.2297e-06,
        3.1547e-06, 1.7473e-07, 1.4685e-06, 2.6903e-06, 5.2603e-06, 1.5093e-06,
        4.4740e-06, 1.0969e-06, 6.5349e-07, 1.7473e-07, 2.5118e-06, 2.9294e-06,
        1.4079e-06, 4.2298e-06, 4.4740e-06, 3.5655e-06, 1.8537e-06, 2.9294e-06,
        1.2591e-06, 1.7373e-06, 3.6385e-06, 2.0599e-06, 1.2824e-06, 3.6992e-06,
        5.6889e-06, 2.2578e-06, 1.5140e-06, 1.4107e-06, 8.8283e-07, 1.8358e-06,
        4.6717e-06, 7.1498e-06, 1.3299e-07, 1.9576e-06, 4.5112e-06, 2.0563e-06,
        4.5472e-07, 2.8657e-06, 5.3992e-06, 1.2106e-06, 1.6682e-06, 4.9648e-06,
        5.6555e-07, 4.2751e-06, 3.4076e-06, 3.2383e-06, 1.4759e-06, 5.2603e-06,
        3.1131e-06, 1.9576e-06, 2.3179e-06, 2.8371e-06], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([1.7898e-07, 4.7129e-07, 4.7116e-07,  ..., 1.0089e-07, 2.2386e-07,
        1.8325e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.3499e-06, 5.0728e-07, 1.4943e-06, 4.4905e-07, 1.1526e-06, 1.2470e-06,
        5.6074e-07, 1.0869e-07, 4.0491e-07, 6.3166e-07, 9.1442e-07, 8.8249e-07,
        4.5948e-07, 6.3166e-07, 1.3645e-06, 9.3264e-07, 5.0080e-07, 3.8487e-07,
        7.9342e-07, 9.1180e-07, 6.2942e-07, 1.8711e-06, 1.1732e-06, 1.0790e-06,
        2.8954e-07, 1.8518e-06, 6.7754e-07, 9.6622e-07, 9.1180e-07, 1.9467e-06,
        1.0854e-06, 5.9264e-07, 1.1284e-06, 5.8243e-07, 9.0534e-07, 1.6398e-06,
        5.3799e-07, 9.6622e-07, 1.1732e-06, 9.2950e-07, 7.6159e-07, 5.4139e-07,
        1.7469e-07, 1.8518e-06, 1.8518e-06, 1.2470e-06, 9.4839e-07, 1.8941e-07,
        2.8954e-07, 6.8062e-07, 2.4825e-06, 1.8711e-06, 9.1180e-07, 1.0099e-06,
        9.6622e-07, 9.1180e-07, 1.0854e-06, 4.0491e-07, 7.9342e-07, 1.0099e-06,
        8.5227e-07, 5.5239e-07, 8.2128e-07, 7.4864e-07, 4.6638e-07, 4.6639e-07,
        4.4905e-07, 1.3700e-06, 4.8896e-07, 7.4864e-07, 5.6136e-07, 6.5585e-07,
        5.5239e-07, 5.1018e-07, 2.4993e-06, 9.6864e-07, 8.7603e-07, 2.9503e-07,
        1.8518e-06, 1.0790e-06, 1.8711e-06, 1.0099e-06, 9.6622e-07, 9.6622e-07,
        9.1910e-07, 9.1430e-07, 3.8487e-07, 2.9546e-07, 1.1355e-06, 1.3132e-06,
        8.6822e-07, 9.1430e-07, 9.1180e-07, 1.0099e-06, 1.3703e-06, 4.8720e-07,
        8.8630e-07, 6.5585e-07, 1.6570e-07, 5.5239e-07, 3.7669e-09, 9.3264e-07,
        1.0869e-07, 4.7283e-07, 8.6369e-07, 1.3333e-06, 8.8743e-07, 9.4839e-07,
        8.6822e-07, 7.1089e-07, 5.9264e-07, 8.5351e-07, 1.4806e-06, 3.8564e-07,
        6.8062e-07, 1.0488e-06, 1.5074e-06, 8.4751e-07, 9.1430e-07, 6.3166e-07,
        4.8720e-07, 1.2470e-06, 9.2804e-07, 1.1355e-06, 9.6622e-07, 6.5876e-07,
        4.5295e-07, 1.2433e-06, 9.6622e-07, 4.5295e-07, 7.2181e-07, 8.5227e-07,
        1.4244e-06, 1.0602e-06, 5.6136e-07, 1.1732e-06, 4.6638e-07, 1.8711e-06,
        5.9059e-07, 5.1018e-07, 8.8630e-07, 9.1442e-07, 4.0491e-07, 5.8243e-07,
        1.8518e-06, 9.3264e-07, 4.7439e-07, 1.3444e-06, 1.7220e-06, 1.0488e-06,
        1.8518e-06, 6.7806e-07, 2.2821e-06, 1.2973e-06, 8.4279e-07, 1.7220e-06,
        9.2804e-07, 7.1736e-07, 1.7199e-06, 5.5239e-07, 9.6622e-07, 1.6030e-06,
        8.2133e-07, 5.5239e-07, 6.3166e-07, 4.8720e-07, 1.2470e-06, 4.8720e-07,
        1.3776e-06, 4.8720e-07, 5.8243e-07, 4.8100e-07, 5.3799e-07, 7.2181e-07,
        9.1430e-07, 6.6438e-07, 9.6622e-07, 1.7220e-06, 1.2973e-06, 8.8630e-07,
        8.0384e-07, 2.1490e-06, 7.9342e-07, 6.7743e-07, 9.1180e-07, 7.2181e-07,
        6.7743e-07, 5.3799e-07, 8.8630e-07, 2.6045e-06, 9.4851e-07, 1.1355e-06,
        2.2821e-06, 1.0488e-06, 7.2181e-07, 8.6369e-07, 1.0488e-06, 1.4401e-06,
        4.0491e-07, 8.2133e-07, 9.6622e-07, 8.8630e-07, 6.3166e-07, 1.8518e-06,
        2.2175e-06, 2.2821e-06, 5.9494e-07, 9.7567e-07, 8.6369e-07, 1.8518e-06,
        1.9314e-06, 6.3166e-07, 6.0396e-07, 1.4899e-07, 1.1355e-06, 1.7469e-07,
        7.9342e-07, 9.8517e-07, 7.0697e-07, 9.4619e-07, 5.8590e-07, 5.8243e-07,
        1.0790e-06, 7.2181e-07, 7.4196e-07, 7.9097e-07, 1.4570e-06, 7.0697e-07,
        1.1305e-06, 8.6822e-07, 1.2433e-06, 1.0790e-06, 1.3700e-06, 6.3166e-07,
        1.4401e-06, 6.2942e-07, 8.6369e-07, 1.2284e-06, 6.6438e-07, 2.2949e-06,
        1.1526e-06, 1.2470e-06, 6.7806e-07, 1.1538e-06, 6.8062e-07, 8.8630e-07,
        1.0099e-06, 5.1018e-07, 4.8720e-07, 2.5749e-07, 9.4839e-07, 9.1180e-07,
        2.2821e-06, 6.1561e-07, 4.7439e-07, 1.9706e-06], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([3.1372e-06, 9.2140e-07, 5.6328e-06, 2.1924e-06, 1.2721e-06, 1.9943e-06,
        6.3133e-06, 5.3503e-06, 3.6955e-06, 6.5258e-06, 7.0556e-06, 2.6090e-06,
        1.8685e-06, 3.8968e-06, 2.5746e-06, 2.7723e-06, 2.6053e-06, 4.5933e-06,
        3.8364e-06, 1.7239e-06, 3.5933e-06, 4.8089e-06, 2.3546e-06, 1.7514e-06,
        1.5699e-06, 7.0556e-06, 9.7453e-07, 1.0863e-06, 2.5216e-06, 3.0036e-06,
        3.2898e-06, 7.0556e-06, 5.3515e-06, 1.6707e-06, 1.8685e-06, 2.0542e-06,
        4.4856e-06, 8.0849e-07, 3.8880e-06, 2.7181e-06, 9.5029e-07, 1.9112e-06,
        2.0480e-06, 2.1428e-06, 1.6029e-06, 8.1295e-06, 2.3546e-06, 3.8571e-06,
        4.2605e-06, 1.4574e-06, 2.9441e-06, 1.2941e-06, 2.1453e-06, 2.8152e-06,
        1.7514e-06, 2.2827e-06, 9.8773e-07, 5.4121e-06, 2.6113e-06, 1.4734e-06,
        1.9250e-06, 1.0863e-06, 4.0478e-06, 5.3323e-06, 2.5039e-06, 1.9250e-06,
        1.5464e-06, 2.0542e-06, 1.5964e-06, 3.4110e-06, 3.0825e-06, 1.2211e-06,
        1.3299e-06, 2.4904e-06, 2.4677e-06, 1.6848e-06, 2.7561e-06, 1.9250e-06,
        6.2624e-06, 3.0680e-06, 2.7490e-06, 4.0895e-06, 3.8030e-06, 3.0429e-06,
        1.9073e-06, 8.0227e-06, 1.6444e-06, 2.7723e-06, 2.2024e-06, 1.6765e-06,
        2.2202e-06, 2.2202e-06, 3.8880e-06, 3.1085e-06, 3.5552e-06, 9.8083e-06,
        3.3933e-06, 2.2852e-06, 6.2791e-06, 9.8773e-07, 1.7586e-06, 9.8773e-07,
        2.0480e-06, 3.4453e-06, 2.8827e-06, 1.8685e-06, 4.0621e-06, 5.6711e-06,
        2.3838e-06, 3.2334e-06, 1.3700e-06, 2.6973e-06, 1.0497e-06, 2.0205e-06,
        2.0480e-06, 1.8685e-06, 3.1447e-06, 7.5040e-06, 1.9527e-07, 4.8317e-06,
        3.5311e-06, 1.8685e-06, 5.0047e-06, 2.2798e-06, 2.5216e-06, 2.7390e-06,
        1.8773e-06, 3.9348e-06, 2.5039e-06, 4.2264e-06, 1.9895e-06, 2.8843e-06,
        3.6623e-06, 1.8685e-06, 6.6436e-06, 6.2200e-06, 5.3230e-06, 8.7973e-06,
        2.9042e-06, 5.4589e-06, 3.9348e-06, 3.0036e-06, 4.8089e-06, 2.3838e-06,
        3.1372e-06, 5.6328e-06, 4.2712e-06, 5.5203e-06, 2.6162e-06, 4.5637e-06,
        1.6368e-06, 3.0036e-06, 5.8957e-07, 1.9402e-06, 4.5293e-06, 4.7827e-06,
        7.7269e-06, 3.0825e-06, 1.0636e-05, 2.1308e-06, 3.0429e-06, 9.0798e-06,
        3.9263e-06, 2.4904e-06, 3.4134e-06, 1.9010e-06, 2.6198e-06, 7.0852e-06,
        1.4016e-06, 2.5713e-06, 2.8843e-06, 3.8176e-06, 1.6848e-06, 1.4180e-06,
        2.7390e-06, 3.9348e-06, 4.4856e-06, 2.4904e-06, 2.6697e-06, 2.8607e-06,
        1.7239e-06, 4.8975e-06, 2.7816e-06, 4.3199e-06, 1.0863e-06, 2.0480e-06,
        1.4016e-06, 4.0695e-06, 3.4210e-06, 3.1447e-06, 1.5811e-06, 1.0887e-06,
        3.6655e-06, 3.1457e-06, 1.7459e-06, 5.7435e-06, 2.5746e-06, 3.7283e-06,
        2.5746e-06, 5.1622e-06, 1.4795e-06, 2.1925e-06, 9.5029e-07, 5.3230e-06,
        1.6782e-06, 1.0477e-06, 3.4912e-06, 2.5698e-06, 1.5886e-06, 7.0556e-06,
        2.3158e-06, 6.5539e-06, 3.0036e-06, 2.7723e-06, 9.8773e-07, 3.6814e-06,
        2.3001e-06, 3.5930e-06, 3.0811e-06, 3.1744e-06, 3.8364e-06, 3.3388e-06,
        1.0161e-06, 2.3121e-06, 3.4792e-06, 4.5562e-06, 2.0348e-06, 6.0992e-06,
        1.0477e-06, 1.6782e-06, 4.8244e-06, 4.7827e-06, 3.0825e-06, 4.7311e-06,
        1.8685e-06, 3.3933e-06, 9.7480e-07, 4.1322e-06, 5.1186e-06, 2.2798e-06,
        1.6418e-06, 3.9348e-06, 3.3951e-06, 1.3428e-06, 1.6029e-06, 5.3515e-06,
        1.1574e-06, 2.4904e-06, 3.5933e-06, 3.8176e-06, 5.7751e-06, 3.2569e-06,
        2.8843e-06, 7.9090e-06, 6.2791e-06, 3.4210e-06], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([2.1840e-07, 2.6576e-07, 6.2286e-08,  ..., 5.6311e-08, 4.9152e-07,
        3.1652e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([6.0375e-07, 4.3723e-07, 7.7462e-07, 1.8433e-06, 1.1549e-06, 4.3723e-07,
        1.5599e-06, 1.0052e-06, 3.3306e-07, 1.8475e-06, 2.9953e-07, 1.7840e-07,
        1.8433e-06, 1.8475e-06, 2.5610e-07, 5.2121e-07, 8.6574e-07, 2.3731e-07,
        1.0442e-06, 8.5905e-07, 3.9954e-07, 2.3661e-06, 6.3178e-07, 6.2588e-07,
        3.9946e-07, 1.1838e-06, 6.0070e-07, 6.6011e-07, 6.2653e-07, 6.0375e-07,
        3.3306e-07, 7.2332e-07, 8.5905e-07, 1.6269e-07, 9.2788e-07, 4.5928e-07,
        4.9971e-07, 1.1951e-06, 4.4770e-07, 1.4543e-06, 1.8229e-06, 6.6011e-07,
        7.4845e-07, 1.3306e-06, 5.8517e-07, 9.1490e-07, 3.0149e-07, 2.6568e-07,
        1.0932e-06, 4.5928e-07, 3.8573e-07, 1.1951e-06, 7.2333e-07, 4.2113e-07,
        1.3306e-06, 1.7446e-06, 3.7888e-07, 1.8475e-06, 1.6269e-07, 3.9715e-07,
        4.9283e-07, 8.5905e-07, 3.9954e-07, 5.7114e-07, 1.8475e-06, 7.2332e-07,
        6.9740e-07, 8.5905e-07, 3.7888e-07, 5.2623e-07, 9.2980e-07, 4.4770e-07,
        1.1951e-06, 5.2121e-07, 3.6931e-07, 1.2563e-06, 4.4106e-07, 8.6574e-07,
        1.6269e-07, 1.2207e-06, 1.1162e-06, 9.9723e-07, 1.2563e-06, 1.8433e-06,
        1.1838e-06, 8.8615e-07, 1.8475e-06, 1.6269e-07, 4.3723e-07, 1.6269e-07,
        1.1838e-06, 1.6269e-07, 2.3731e-07, 1.3122e-06, 4.3723e-07, 9.1490e-07,
        7.2349e-07, 6.2588e-07, 1.1838e-06, 1.1951e-06, 2.3661e-06, 4.0555e-07,
        3.3306e-07, 2.9953e-07, 4.2113e-07, 1.1951e-06, 4.7289e-07, 4.3723e-07,
        1.1838e-06, 1.4543e-06, 2.3661e-06, 7.7462e-07, 8.8169e-07, 7.2333e-07,
        3.2554e-07, 4.9971e-07, 3.9954e-07, 1.1366e-06, 1.2563e-06, 7.2332e-07,
        8.5905e-07, 1.8433e-06, 3.8573e-07, 8.5905e-07, 1.1838e-06, 4.3723e-07,
        4.9283e-07, 3.7724e-07, 4.9971e-07, 1.6269e-07, 4.5928e-07, 1.1921e-06,
        4.9971e-07, 1.7780e-06, 6.9740e-07, 3.9954e-07, 1.8475e-06, 7.7462e-07,
        6.2588e-07, 2.3731e-07, 1.2563e-06, 8.5905e-07, 1.1838e-06, 1.1838e-06,
        8.4146e-07, 3.0149e-07, 3.8573e-07, 1.8433e-06, 3.0149e-07, 1.5854e-06,
        1.2563e-06, 5.8517e-07, 4.4770e-07, 6.0070e-07, 9.9992e-07, 6.6011e-07,
        1.4543e-06, 1.1838e-06, 1.5727e-06, 7.2333e-07, 8.4146e-07, 8.4841e-07,
        4.5928e-07, 6.9740e-07, 1.1951e-06, 2.0407e-06, 3.3306e-07, 6.6011e-07,
        1.0932e-06, 1.8406e-06, 1.4543e-06, 1.2563e-06, 3.8573e-07, 2.9953e-07,
        1.7840e-07, 1.6269e-07, 3.6931e-07, 5.2012e-07, 1.2563e-06, 3.8573e-07,
        1.1838e-06, 3.0149e-07, 1.1951e-06, 2.0843e-06, 8.8169e-07, 1.1951e-06,
        3.8573e-07, 1.3103e-06, 2.3661e-06, 7.2333e-07, 3.9715e-07, 4.5928e-07,
        6.9740e-07, 4.9971e-07, 2.3731e-07, 1.2563e-06, 8.6574e-07, 1.7446e-06,
        4.5928e-07, 3.8573e-07, 1.6269e-07, 6.0070e-07, 4.3723e-07, 6.0070e-07,
        4.3723e-07, 7.2332e-07, 3.9954e-07, 4.5928e-07, 3.9946e-07, 1.8475e-06,
        6.9740e-07, 4.4770e-07, 1.4543e-06, 6.9740e-07, 9.7271e-07, 6.0375e-07,
        8.6027e-07, 7.7462e-07, 1.7766e-06, 3.9715e-07, 3.0149e-07, 3.8031e-07,
        1.7446e-06, 6.9740e-07, 1.0052e-06, 1.3103e-06, 6.0070e-07, 6.9740e-07,
        7.2332e-07, 7.2332e-07, 7.2349e-07, 7.2332e-07, 5.1797e-07, 3.6974e-07,
        4.3723e-07, 6.2653e-07, 2.3004e-07, 1.7780e-06, 1.7840e-07, 4.0555e-07,
        1.1838e-06, 3.7724e-07, 1.3306e-06, 5.1797e-07, 1.8412e-06, 1.7446e-06,
        4.4770e-07, 4.5928e-07, 5.2012e-07, 6.2588e-07, 4.4106e-07, 4.7289e-07,
        8.5905e-07, 4.5928e-07, 4.3723e-07, 3.9954e-07, 8.8615e-07, 8.3815e-07,
        8.8943e-07, 3.8573e-07, 1.3103e-06, 7.7462e-07, 4.5928e-07, 7.2332e-07,
        6.3177e-07, 9.1490e-07, 2.0407e-06, 9.2980e-07, 5.8517e-07, 1.1838e-06,
        1.4543e-06, 1.0007e-06, 3.8926e-07, 3.8573e-07, 3.8573e-07, 4.9283e-07,
        7.2332e-07, 6.9740e-07, 6.0070e-07, 5.7114e-07, 6.2642e-07, 6.9740e-07,
        3.3306e-07, 6.9740e-07, 4.9971e-07, 1.2563e-06, 4.3723e-07, 1.3122e-06,
        3.8573e-07, 4.5928e-07, 1.8433e-06, 3.9946e-07, 1.1951e-06, 4.4130e-07,
        1.8475e-06, 1.7840e-07, 9.9992e-07, 4.3723e-07, 1.8433e-06, 1.1951e-06,
        4.9112e-07, 4.4106e-07, 1.1868e-06, 5.7467e-07, 6.0070e-07, 1.1549e-06,
        1.4543e-06, 7.2332e-07, 1.1838e-06, 1.2563e-06, 1.1951e-06, 3.8573e-07,
        4.0084e-07, 3.9954e-07, 1.8475e-06, 1.7446e-06, 3.9954e-07, 3.8573e-07,
        8.8943e-07, 1.4543e-06, 4.9971e-07, 3.6939e-07, 6.9740e-07, 3.8031e-07,
        1.8475e-06, 2.3661e-06, 3.7724e-07, 2.6010e-07, 6.0960e-07, 4.4770e-07,
        1.8475e-06, 3.9715e-07, 8.5905e-07, 3.7411e-07, 3.8573e-07, 6.9740e-07,
        4.5928e-07, 7.2349e-07, 5.0428e-07, 3.3306e-07, 1.8475e-06, 5.1797e-07,
        1.1838e-06, 3.9954e-07, 1.3306e-06, 1.1838e-06, 1.5727e-06, 4.4770e-07,
        7.2349e-07, 7.2332e-07, 6.0070e-07, 7.2332e-07, 1.7882e-06, 4.3723e-07,
        1.1838e-06, 8.8169e-07, 6.2653e-07, 9.9992e-07, 3.9715e-07, 1.1951e-06,
        4.5928e-07, 2.8300e-07, 2.8300e-07, 2.9953e-07, 5.6875e-07, 4.9971e-07,
        1.7446e-06, 1.0932e-06, 2.3732e-06, 7.7462e-07, 4.5928e-07, 4.5928e-07,
        1.2563e-06, 1.8433e-06, 2.9953e-07, 3.8573e-07, 5.2121e-07, 5.8517e-07,
        1.8475e-06, 4.5928e-07, 4.4106e-07, 1.6269e-07, 3.6931e-07, 1.1838e-06,
        1.1838e-06, 1.8433e-06, 1.4543e-06, 4.9112e-07, 4.0555e-07, 6.2588e-07,
        4.4770e-07, 3.9954e-07, 8.8169e-07, 1.5727e-06, 1.8433e-06, 2.9953e-07,
        4.7289e-07, 1.1951e-06, 7.2332e-07, 2.9953e-07, 1.1838e-06, 1.1838e-06,
        4.5928e-07, 4.5928e-07, 1.3306e-06, 4.4106e-07, 2.9953e-07, 1.1838e-06,
        2.3731e-07, 3.6931e-07, 3.4935e-07, 1.1838e-06, 1.6269e-07, 1.1838e-06,
        3.8573e-07, 1.6269e-07, 4.3723e-07, 6.1934e-07, 3.9954e-07, 4.5928e-07,
        4.5928e-07, 1.7446e-06, 3.8520e-07, 1.1838e-06, 7.2332e-07, 5.8476e-07,
        4.4770e-07, 8.5905e-07, 3.9954e-07, 1.8433e-06, 1.4411e-06, 1.1838e-06,
        1.8246e-06, 4.9971e-07, 3.3306e-07, 1.1838e-06, 1.7882e-06, 1.0442e-06,
        9.1490e-07, 1.8226e-06, 3.3306e-07, 1.1838e-06, 5.2121e-07, 8.5905e-07,
        3.3306e-07, 6.2653e-07, 7.7462e-07, 5.2121e-07, 2.6010e-07, 3.8573e-07,
        1.3306e-06, 3.8573e-07, 1.6269e-07, 3.4935e-07, 7.2333e-07, 5.2012e-07,
        5.2121e-07, 5.6875e-07, 6.9740e-07, 4.3723e-07, 1.4543e-06, 8.4841e-07,
        5.8517e-07, 7.2332e-07, 3.9715e-07, 8.5905e-07, 6.2588e-07, 7.7462e-07,
        4.0555e-07, 4.3723e-07, 1.5860e-06, 1.1800e-06, 8.5905e-07, 4.9971e-07,
        5.6875e-07, 3.8573e-07, 7.7462e-07, 4.7552e-07, 3.6931e-07, 1.0932e-06,
        8.5418e-07, 2.3731e-07, 6.0070e-07, 1.6269e-07, 1.3306e-06, 6.9352e-07,
        6.0070e-07, 1.7780e-06, 1.1838e-06, 1.2207e-06, 3.1677e-07, 1.8235e-06,
        3.0149e-07, 5.1005e-07, 7.2332e-07, 1.3306e-06, 7.2332e-07, 1.1868e-06,
        3.9954e-07, 9.9992e-07, 1.0932e-06, 2.5610e-07, 4.4770e-07, 8.5905e-07,
        3.9946e-07, 4.0555e-07, 3.9954e-07, 1.8231e-06, 2.4107e-07, 3.5956e-07,
        3.8573e-07, 7.2333e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([7.3284e-06, 4.1804e-06, 4.1722e-06, 1.1308e-05, 1.9781e-06, 1.8520e-06,
        3.8978e-06, 3.1437e-06, 1.0500e-05, 1.0441e-05, 3.3010e-06, 5.1872e-06,
        3.1988e-06, 4.0611e-06, 1.8520e-06, 6.1572e-07, 4.8960e-06, 7.0886e-06,
        4.0354e-06, 8.5665e-06, 7.1373e-06, 4.2446e-06, 3.8746e-06, 3.4845e-06,
        1.0500e-05, 1.4866e-06, 2.8794e-06, 2.5414e-06, 6.2654e-06, 2.9616e-06,
        2.7740e-06, 7.7141e-06, 4.1722e-06, 2.4757e-06, 1.1308e-05, 2.1936e-06,
        3.1008e-06, 2.5033e-06, 2.2287e-06, 3.6283e-06, 5.7978e-06, 6.2654e-06,
        4.1414e-06, 2.0716e-06, 1.0045e-05, 4.0541e-06, 3.5782e-06, 2.7740e-06,
        2.7202e-06, 4.7961e-06, 2.4757e-06, 4.9070e-06, 1.1091e-06, 4.3375e-06,
        1.8520e-06, 2.7202e-06, 4.9070e-06, 2.4757e-06, 3.6082e-06, 8.6507e-07,
        3.1003e-06, 3.6082e-06, 4.1804e-06, 1.3490e-06, 2.4764e-06, 1.4477e-06,
        5.7036e-06, 3.0981e-06, 2.9616e-06, 5.7036e-06, 6.3813e-06, 3.3010e-06,
        2.0716e-06, 4.1804e-06, 9.8280e-06, 4.1804e-06, 1.3490e-06, 3.0182e-06,
        4.1722e-06, 4.7045e-06, 6.2654e-06, 4.1722e-06, 7.9926e-06, 6.2623e-06,
        1.8764e-06, 4.1804e-06, 7.8789e-06, 7.8789e-06, 2.5672e-06, 3.3010e-06,
        6.8938e-06, 2.2287e-06, 4.1804e-06, 2.4586e-06, 2.5414e-06, 4.1804e-06,
        4.9070e-06, 5.7721e-06, 4.2534e-06, 3.2128e-06, 2.9616e-06, 6.9472e-06,
        3.9497e-06, 2.5955e-06, 7.5026e-06, 3.0150e-06, 3.8978e-06, 6.1301e-06,
        3.3010e-06, 3.3010e-06, 1.5267e-06, 2.2287e-06, 1.8887e-06, 2.9437e-06,
        9.8280e-06, 2.5849e-06, 8.4636e-06, 2.2287e-06, 4.0541e-06, 6.1572e-07,
        2.3343e-06, 2.7740e-06, 4.8960e-06, 2.3343e-06, 7.6095e-06, 2.3343e-06,
        5.3663e-06, 4.1722e-06, 8.5665e-06, 2.3343e-06, 4.1722e-06, 5.7036e-06,
        1.1993e-06, 5.3395e-06, 1.0441e-05, 4.0555e-06, 5.4363e-06, 7.1658e-06,
        6.3813e-06, 3.8465e-06, 3.3010e-06, 6.1572e-07, 7.3725e-06, 5.3395e-06,
        7.8789e-06, 5.7036e-06, 4.0555e-06, 3.1003e-06, 8.7956e-06, 2.7202e-06,
        3.2320e-06, 1.8520e-06, 3.4845e-06, 3.4250e-06, 1.4866e-06, 5.1872e-06,
        2.2287e-06, 7.8789e-06, 6.8938e-06, 4.8960e-06, 4.1722e-06, 8.4636e-06,
        1.0901e-05, 2.3974e-06, 8.6507e-07, 2.7740e-06, 7.1658e-06, 3.2320e-06,
        4.0611e-06, 3.8981e-06, 6.1572e-07, 5.3395e-06, 2.0716e-06, 3.8978e-06,
        1.3550e-05, 1.1308e-05, 4.3375e-06, 2.8794e-06, 5.7036e-06, 4.1722e-06,
        2.8794e-06, 4.3375e-06, 3.3010e-06, 4.1722e-06, 5.7036e-06, 3.3010e-06,
        4.8755e-06, 2.2287e-06, 6.6678e-06, 2.5275e-06, 3.6283e-06, 4.8960e-06,
        4.8960e-06, 2.4654e-06, 1.5267e-06, 6.1572e-07, 4.2675e-06, 2.4757e-06,
        2.5033e-06, 2.5445e-06, 5.1597e-06, 4.8960e-06, 4.2630e-06, 3.3010e-06,
        1.0441e-05, 2.9616e-06, 4.2534e-06, 6.2654e-06, 4.0541e-06, 5.3663e-06,
        8.6507e-07, 5.6847e-06, 4.1804e-06, 3.6082e-06, 1.1308e-05, 4.4914e-06,
        8.9581e-07, 4.2630e-06, 5.4443e-06, 5.5199e-06, 3.8981e-06, 8.4636e-06,
        7.9784e-06, 2.4757e-06, 2.9553e-06, 1.9683e-06, 2.7740e-06, 2.7740e-06,
        5.3395e-06, 3.1051e-06, 1.1993e-06, 5.4363e-06, 8.4636e-06, 2.2287e-06,
        9.8280e-06, 4.6178e-06, 4.1804e-06, 1.0901e-05, 5.9699e-06, 3.8978e-06,
        6.0080e-06, 4.7961e-06, 3.5782e-06, 6.4745e-06, 4.2446e-06, 2.7202e-06,
        2.7630e-06, 5.3606e-06, 5.4363e-06, 8.9581e-07, 2.2363e-06, 4.6853e-06,
        2.5849e-06, 5.1617e-06, 5.3606e-06, 1.1308e-05, 4.0555e-06, 6.1301e-06,
        3.8817e-06, 4.3375e-06, 2.7202e-06, 1.0195e-05, 2.9616e-06, 8.4636e-06,
        3.1003e-06, 4.7441e-06, 2.6644e-06, 3.4306e-06, 4.1804e-06, 2.5414e-06,
        1.0148e-05, 1.8104e-06, 2.5396e-06, 6.2654e-06, 8.4636e-06, 4.1722e-06,
        3.9863e-06, 2.2287e-06, 3.2320e-06, 5.3663e-06, 1.8520e-06, 8.4636e-06,
        3.8981e-06, 8.6507e-07, 5.5199e-06, 3.4845e-06, 1.1308e-05, 3.8981e-06,
        3.3779e-06, 6.0017e-06, 2.4608e-06, 2.9616e-06, 4.1722e-06, 2.9616e-06,
        2.5033e-06, 6.8359e-06, 1.1308e-05, 6.1572e-07, 4.2618e-06, 3.3010e-06,
        1.8764e-06, 1.3490e-06, 2.1581e-06, 4.4914e-06, 6.2654e-06, 5.1872e-06,
        1.1308e-05, 9.8280e-06, 2.9616e-06, 5.5199e-06, 4.9070e-06, 2.7815e-06,
        3.2128e-06, 1.4866e-06, 4.1804e-06, 4.8960e-06, 3.8817e-06, 3.1003e-06,
        4.2446e-06, 3.8981e-06, 1.8520e-06, 2.4654e-06, 6.3813e-06, 4.7961e-06,
        2.6644e-06, 7.8789e-06, 5.3395e-06, 5.4363e-06, 3.8978e-06, 3.2128e-06,
        1.0441e-05, 4.8960e-06, 1.8520e-06, 1.1120e-05, 1.8520e-06, 3.2128e-06,
        1.9683e-06, 5.3663e-06, 2.2108e-06, 4.3375e-06, 4.6178e-06, 2.7202e-06,
        8.4636e-06, 8.4636e-06, 3.8981e-06, 1.0148e-05, 2.4608e-06, 6.1301e-06,
        5.7302e-06, 7.9784e-06, 2.9616e-06, 2.1016e-06, 3.1008e-06, 2.3343e-06,
        3.0182e-06, 7.3285e-06, 4.9070e-06, 4.1804e-06, 2.2108e-06, 4.4914e-06,
        4.2446e-06, 5.5199e-06, 4.9070e-06, 4.1804e-06, 1.7091e-06, 4.6178e-06,
        8.7956e-06, 5.7706e-06, 6.0967e-06, 3.6283e-06, 9.2511e-06, 2.2287e-06,
        3.3010e-06, 3.0033e-06, 8.4636e-06, 3.8981e-06, 2.5414e-06, 3.8978e-06,
        4.1804e-06, 5.3663e-06, 2.5849e-06, 2.4757e-06, 8.4636e-06, 1.1944e-06,
        7.8789e-06, 2.9616e-06, 8.7956e-06, 2.8794e-06, 8.4636e-06, 8.4636e-06,
        1.5267e-06, 4.1804e-06, 4.7045e-06, 4.9591e-06, 3.8465e-06, 7.8789e-06,
        8.5665e-06, 4.0555e-06, 9.2511e-06, 6.8938e-06, 3.1003e-06, 1.5267e-06,
        2.8437e-06, 4.4193e-06, 8.4636e-06, 2.9616e-06, 4.1414e-06, 1.1993e-06,
        3.4306e-06, 6.5125e-06, 2.5414e-06, 9.2511e-06, 8.5665e-06, 6.3813e-06,
        3.1008e-06, 4.2257e-06, 4.1722e-06, 4.6178e-06, 1.1944e-06, 2.5672e-06,
        8.4636e-06, 2.2803e-06, 3.6501e-06, 8.6507e-07, 4.1804e-06, 6.6678e-06,
        8.4636e-06, 4.2630e-06, 9.4294e-06, 2.7202e-06, 6.1572e-07, 5.3395e-06,
        4.0555e-06, 5.1617e-06, 5.7978e-06, 3.3010e-06, 3.4306e-06, 3.8978e-06,
        8.7956e-06, 2.7202e-06, 1.1308e-05, 1.5275e-07, 1.3490e-06, 1.0441e-05,
        3.4306e-06, 3.6082e-06, 2.5033e-06, 4.2154e-06, 7.8789e-06, 4.1722e-06,
        6.0053e-06, 3.0981e-06, 2.7630e-06, 5.1597e-06, 2.8794e-06, 7.4376e-06,
        7.4376e-06, 5.3150e-06, 2.4757e-06, 2.9553e-06, 4.0790e-06, 4.1722e-06,
        3.0136e-06, 2.7202e-06, 2.9616e-06, 3.1003e-06, 1.5267e-06, 4.1804e-06,
        1.8888e-06, 3.1003e-06, 4.1804e-06, 8.9581e-07, 9.8280e-06, 3.0981e-06,
        7.9784e-06, 3.1008e-06, 4.2630e-06, 4.2446e-06, 2.7202e-06, 5.0481e-06,
        5.4363e-06, 3.0182e-06, 1.0441e-05, 2.5414e-06, 3.1008e-06, 2.4524e-06,
        2.2902e-06, 2.5672e-06, 5.2771e-06, 8.4636e-06, 8.4635e-06, 7.9926e-06,
        4.1722e-06, 8.4636e-06, 6.2654e-06, 6.0967e-06, 5.7036e-06, 8.4636e-06,
        4.1804e-06, 5.3395e-06, 4.1722e-06, 8.9581e-07, 3.2863e-06, 1.4094e-06,
        3.9715e-06, 2.7202e-06, 6.3813e-06, 4.6853e-06, 2.9616e-06, 4.6287e-06,
        5.7036e-06, 5.3663e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.1053e-06, 3.2021e-07, 5.0656e-07,  ..., 1.7263e-06, 1.2946e-06,
        5.3854e-08], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.1544e-06, 2.0253e-06, 2.3968e-06,  ..., 7.7311e-07, 3.8565e-06,
        1.2461e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([3.9008e-07, 3.0296e-06, 3.0792e-06, 2.7709e-06, 2.3884e-06, 2.0294e-06,
        2.1084e-06, 1.4583e-06, 8.7608e-06, 2.6003e-06, 1.0706e-06, 2.7845e-06,
        1.7189e-06, 1.8042e-06, 9.6503e-06, 2.4652e-06, 1.6866e-06, 6.0969e-06,
        5.6153e-07, 4.2171e-06, 1.6631e-06, 2.2419e-06, 1.3042e-06, 1.4397e-06,
        4.7262e-06, 4.8937e-06, 1.8154e-06, 3.8884e-06, 9.5532e-07, 1.8162e-06,
        5.5168e-06, 1.8915e-06, 4.3828e-06, 2.4631e-06, 3.0591e-06, 3.1601e-06,
        1.8166e-06, 5.7823e-06, 4.6118e-06, 3.1952e-06, 3.3251e-06, 1.0214e-06,
        5.1102e-06, 2.8821e-06, 3.0872e-06, 6.0969e-06, 2.8767e-06, 8.1143e-07,
        6.1387e-06, 1.8033e-06, 3.0232e-06, 3.7650e-06, 1.5540e-06, 1.0434e-06,
        4.2158e-06, 4.7521e-06, 5.7526e-06, 6.0607e-06, 2.6076e-06, 3.8481e-06,
        3.0296e-06, 4.3992e-06, 3.0296e-06, 1.2100e-06, 2.8370e-06, 7.8796e-06,
        2.0902e-06, 1.8042e-06, 1.4848e-06, 2.6423e-06, 1.6482e-06, 3.4287e-06,
        1.5788e-06, 2.7371e-06, 2.6241e-06, 1.8697e-06, 5.1048e-06, 4.0372e-06,
        1.8300e-06, 8.1595e-07, 4.4640e-06, 4.4133e-06, 9.9064e-07, 1.2253e-06,
        6.1086e-06, 4.8937e-06, 5.2350e-06, 2.8428e-06, 3.3578e-06, 5.1342e-06,
        4.1438e-06, 1.5788e-06, 3.9429e-06, 3.5037e-06, 2.2451e-06, 2.5239e-06,
        2.3884e-06, 2.2467e-06, 1.5788e-06, 5.7570e-06, 3.9303e-06, 2.5436e-06,
        1.2863e-06, 6.6831e-06, 4.1915e-06, 1.2629e-06, 4.8859e-07, 3.4861e-06,
        3.6150e-06, 4.2952e-06, 2.3645e-06, 2.0392e-06, 1.6658e-06, 3.0846e-06,
        1.3475e-06, 6.1086e-06, 5.6051e-06, 4.6118e-06, 8.5858e-07, 2.5118e-06,
        9.6531e-06, 5.3004e-06, 5.4462e-06, 4.6030e-06, 7.5617e-06, 4.1734e-06,
        4.3813e-06, 3.3844e-06, 3.1773e-06, 2.9480e-06, 3.7072e-06, 3.4608e-06,
        3.0027e-01, 8.8393e-07, 1.2782e-06, 5.7362e-07, 4.3968e-06, 3.8445e-06,
        1.8042e-06, 2.6779e-06, 4.6118e-06, 1.2382e-06, 6.4057e-07, 3.2560e-06,
        3.8026e-06, 4.1917e-06, 2.2913e-06, 2.8211e-06, 1.6658e-06, 3.4736e-06,
        3.1555e-06, 1.3475e-06, 2.1106e-06, 7.8324e-07, 1.5293e-06, 2.2451e-06,
        3.0792e-06, 4.8859e-07, 1.3025e-06, 3.6808e-06, 1.5227e-06, 4.1917e-06,
        3.0188e-06, 2.2451e-06, 4.0206e-06, 2.9824e-06, 3.2352e-06, 3.8199e-06,
        2.8711e-06, 3.6808e-06, 3.7386e-06, 3.2832e-06, 1.2947e-06, 1.2957e-06,
        4.3611e-06, 2.4652e-06, 3.3204e-06, 6.3147e-06, 3.6982e-06, 1.2066e-06,
        3.0316e-06, 5.3004e-06, 4.1910e-06, 8.0184e-07, 1.2827e-06, 2.4181e-06,
        5.7823e-06, 1.0835e-06, 3.8790e-06, 1.7088e-06, 1.6825e-06, 1.6531e-06,
        4.1415e-06, 1.0593e-06, 3.0296e-06, 5.4539e-06, 1.4351e-06, 4.2149e-07,
        1.2133e-06, 2.4116e-06, 2.6367e-06, 5.6153e-07, 4.5735e-06, 1.6825e-06,
        1.5421e-06, 2.3585e-06, 4.1917e-06, 8.3760e-07, 1.2329e-06, 3.4605e-06,
        1.6987e-06, 1.8037e-06, 1.6825e-06, 4.2042e-06, 2.6782e-06, 3.6808e-06,
        2.0902e-06, 2.5055e-01, 3.1276e-06, 1.3025e-06, 3.0872e-06, 3.2867e-06,
        3.2548e-06, 2.2451e-06, 3.9532e-06, 4.6699e-06, 5.1048e-06, 3.8346e-06,
        2.9943e-06, 1.9216e-06, 1.0238e-06, 1.8695e-06, 7.3936e-06, 3.0296e-06,
        3.7191e-06, 2.2451e-06, 3.0792e-06, 1.6305e-06, 4.1737e-06, 4.8937e-06,
        3.0594e-06, 2.0392e-06, 1.6987e-06, 3.6399e-06, 1.9939e-06, 7.7596e-06,
        3.4928e-06, 3.6517e-06, 4.3484e-06, 6.8986e-06, 4.3714e-06, 4.4994e-06,
        3.1581e-06, 4.2952e-06, 1.1857e-06, 2.8318e-06, 4.8937e-06, 1.1585e-06,
        7.7645e-07, 2.0902e-06, 6.7748e-06, 2.2719e-06, 6.8046e-06, 3.1485e-06,
        1.7177e-06, 3.0296e-06, 3.7536e-06, 1.6282e-07, 2.4642e-06, 5.7519e-06,
        1.8915e-06, 1.9375e-06, 1.6658e-06, 2.2467e-06, 3.8649e-06, 2.6491e-06,
        4.9002e-06, 3.5335e-06, 2.8821e-06, 5.7570e-06, 3.4537e-06, 2.7371e-06,
        6.3968e-06, 8.9466e-07, 3.6517e-06, 2.5168e-06, 3.4125e-06, 6.3147e-06,
        2.3644e-06, 1.5791e-06, 4.3625e-06, 1.2758e-06, 2.8931e-06, 4.6118e-06,
        3.4537e-06, 1.6658e-06, 3.7650e-06, 3.1420e-06, 4.7585e-06, 3.7146e-06,
        1.3429e-06, 5.5832e-06, 3.6133e-06, 1.5293e-06, 7.8324e-07, 1.7606e-06,
        1.8300e-06, 3.6340e-06, 2.4916e-06, 4.3145e-06, 7.9670e-07, 4.4240e-06,
        3.8965e-06, 3.0296e-06, 1.8690e-06, 2.8083e-06, 5.6153e-07, 4.5037e-08,
        2.8979e-06, 1.8592e-06, 1.0407e-06, 6.6831e-06, 4.2952e-06, 2.5906e-06,
        1.3000e-08, 2.4652e-06, 7.7322e-06, 8.6776e-06, 4.5339e-06, 1.6079e-06,
        2.0523e-06, 1.6825e-06, 2.6779e-06, 2.7736e-06, 3.4400e-01, 1.5799e-06,
        4.6331e-06, 9.5568e-06, 2.2866e-06, 8.9199e-06, 4.2463e-06, 3.1900e-06,
        3.5341e-06, 4.7854e-06, 4.8937e-06, 1.5788e-06, 1.0593e-06, 1.2724e-06,
        3.6808e-06, 1.6482e-06, 5.8520e-06, 2.5450e-06, 3.6725e-06, 2.5906e-06,
        1.1873e-05, 1.4351e-06, 3.7438e-06, 3.6185e-06, 3.8921e-06, 2.7825e-06,
        3.1900e-06, 3.8759e-06, 2.5039e-06, 3.6982e-06, 1.8300e-06, 3.1276e-06,
        1.3988e-06, 4.6118e-06, 1.3081e-06, 4.0023e-06, 4.8937e-06, 2.3456e-06,
        2.5778e-06, 3.8199e-06, 1.2561e-05, 7.8796e-06, 8.9466e-07, 6.6145e-06,
        5.6153e-07, 2.6816e-06, 1.8558e-06, 2.0902e-06, 4.2952e-06, 1.0408e-05,
        2.1162e-06, 4.7248e-06, 3.2459e-06, 4.1755e-06, 2.5287e-06, 1.3354e-06,
        3.4604e-06, 2.4916e-06, 2.6367e-06, 3.7191e-06, 2.9071e-06, 2.7951e-06,
        1.3013e-06, 3.8903e-06, 2.7131e-06, 5.9816e-06, 2.6681e-06, 5.9198e-06,
        2.5509e-06, 2.8083e-06, 1.2548e-06, 3.1580e-06, 6.1086e-06, 8.3760e-07,
        1.6825e-06, 2.4164e-06, 1.4736e-06, 1.9253e-06, 3.0681e-06, 1.1242e-05,
        3.0188e-06, 7.4309e-06, 2.5618e-06, 1.5788e-06, 4.2158e-06, 8.9466e-07,
        1.3475e-06, 3.0594e-06, 1.9518e-06, 5.6153e-07, 8.8881e-06, 2.6226e-06,
        2.4257e-06, 1.3585e-06, 4.6118e-06, 6.8981e-06, 3.2437e-06, 3.2232e-06,
        6.8981e-06, 4.4133e-06, 1.0434e-06, 2.3186e-06, 2.4844e-06, 3.5943e-06,
        1.0214e-06, 9.2675e-07, 2.4392e-06, 6.6132e-06, 3.3393e-06, 3.1038e-06,
        2.1162e-06, 2.7371e-06, 3.3949e-06, 8.0406e-06, 1.1857e-06, 1.6482e-06,
        3.6517e-06, 3.0316e-06, 8.3760e-07, 1.5540e-06, 3.8790e-06, 7.7645e-07,
        2.3115e-06, 3.0370e-06, 4.2390e-06, 1.8690e-06, 1.6658e-06, 8.0406e-06,
        6.2781e-06, 1.0434e-06, 2.3321e-06, 4.8950e-06, 7.9351e-06, 2.8083e-06,
        2.6226e-06, 5.3582e-06, 2.0902e-06, 2.8545e-06, 2.1387e-06, 1.8222e-06,
        2.4940e-06, 1.3025e-06, 2.1551e-06, 3.0959e-06, 1.4397e-06, 2.6097e-06,
        2.5265e-06, 4.7585e-06, 3.6150e-06, 1.5786e-06, 2.6367e-06, 2.0902e-06,
        2.9915e-06, 8.9881e-06, 1.7189e-06, 1.5083e-06, 7.6355e-06, 1.2172e-06,
        2.7010e-06, 3.1773e-06, 3.0178e-06, 3.0475e-06, 4.8937e-06, 4.5021e-06,
        8.5623e-06, 1.3282e-06, 2.4652e-06, 7.8324e-07, 1.6125e-06, 3.4531e-06,
        1.8300e-06, 1.0796e-05, 1.6962e-06, 1.0969e-05, 2.2597e-06, 1.2880e-06,
        1.3025e-06, 2.9812e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([9.8963e-06, 8.6082e-06, 2.8406e-06, 4.3321e-06, 1.0138e-05, 4.1652e-06,
        5.8693e-06, 8.2187e-06, 8.0879e-06, 1.3355e-06, 1.9942e-05, 1.3981e-05,
        8.6167e-06, 1.2751e-05, 8.7695e-06, 9.7718e-06, 3.2518e-06, 9.3196e-06,
        1.8764e-05, 9.9125e-06, 3.8577e-06, 5.9669e-06, 4.1652e-06, 1.1549e-05,
        1.5892e-05, 1.0682e-05, 1.3688e-05, 1.7109e-05, 6.2854e-06, 8.6256e-06,
        1.0043e-05, 1.4685e-05, 6.4156e-06, 8.0268e-06, 1.0182e-05, 9.0506e-06,
        3.9007e-06, 1.9455e-05, 1.5232e-05, 1.0156e-05, 6.3953e-06, 1.1525e-05,
        3.5359e-06, 9.2646e-06, 1.1670e-05, 5.8538e-06, 1.2510e-05, 1.9423e-05,
        5.0437e-06, 1.5958e-05, 1.1389e-05, 4.6109e-06, 1.0228e-05, 3.9295e-06,
        4.1652e-06, 4.6489e-06, 1.1525e-05, 2.0233e-05, 9.8963e-06, 3.0452e-06,
        9.7322e-02, 1.0228e-05, 4.3564e-06, 4.1652e-06, 1.8983e-05, 1.9602e-05,
        3.0765e-06, 9.0544e-06, 1.1945e-05, 1.1525e-05, 1.6154e-05, 1.6514e-05,
        4.9972e-06, 6.8083e-06, 7.2309e-06, 1.1209e-05, 2.5093e-05, 9.6232e-06,
        1.5213e-05, 1.7009e-05, 6.0650e-06, 8.1016e-06, 8.5082e-06, 1.4671e-05,
        6.0137e-06, 1.9455e-05, 4.2778e-06, 1.3121e-05, 8.7315e-06, 1.1212e-05,
        8.8512e-06, 1.8319e-05, 9.1602e-06, 1.2004e-05, 2.8237e-06, 8.1616e-06,
        3.8316e-06, 1.1525e-05, 6.3952e-06, 7.7596e-06, 1.9706e-05, 5.8029e-06,
        6.9698e-06, 7.4153e-06, 7.9922e-06, 7.4023e-06, 9.7224e-06, 8.7181e-02,
        1.2268e-05, 1.4794e-05, 8.7001e-06, 1.1975e-05, 1.2127e-05, 1.0389e-05,
        1.1525e-05, 1.2888e-05, 5.0385e-06, 1.3153e-01, 7.8886e-06, 1.1267e-05,
        1.4062e-05, 6.9490e-07, 2.2021e-06, 1.3263e-01, 1.6513e-05, 3.1795e-06,
        8.7605e-06, 1.5892e-05, 2.0024e-05, 8.6082e-06, 8.6167e-06, 1.1945e-05,
        5.5861e-06, 5.6524e-06, 4.5349e-06, 9.0505e-06, 1.1164e-05, 1.3942e-05,
        1.0989e-05, 1.4109e-05, 1.2629e-05, 6.8332e-06, 7.6380e-06, 8.5427e-06,
        1.1223e-05, 5.1681e-06, 1.4096e-05, 1.2244e-05, 8.4861e-06, 1.2324e-05,
        1.7618e-05, 1.5940e-05, 7.6267e-06, 6.2854e-06, 2.2032e-05, 2.4393e-06,
        1.4683e-05, 9.6232e-06, 8.5180e-06, 1.0499e-05, 9.7289e-06, 9.5783e-06,
        1.1062e-05, 6.5664e-06, 4.7483e-06, 8.9462e-06, 1.0339e-05, 1.8603e-05,
        1.1294e-05, 1.0264e-05, 1.9239e-05, 5.7812e-06, 4.6940e-06, 1.6716e-05,
        1.1267e-05, 4.0534e-06, 1.1209e-05, 2.0477e-05, 1.2127e-05, 4.1385e-06,
        1.5775e-05, 6.3595e-06, 1.1861e-05, 8.8512e-06, 1.4089e-05, 1.1195e-05,
        8.8512e-06, 1.5950e-05, 8.6082e-06, 1.9216e-05, 9.6232e-06, 8.6167e-06,
        2.1101e-05, 7.9922e-06, 1.1267e-05, 2.5984e-06, 1.3430e-05, 1.0590e-05,
        2.4393e-06, 1.6045e-05, 1.2936e-05, 1.1471e-05, 1.1613e-05, 5.0437e-06,
        4.1385e-06, 6.9724e-06, 4.1573e-06, 1.3324e-05, 1.2020e-05, 1.4794e-05,
        4.1074e-06, 4.1652e-06, 1.3154e-05, 2.3458e-05, 5.4503e-06, 1.4265e-05,
        1.3121e-05, 4.4447e-06, 1.5892e-05, 1.1525e-05, 1.0743e-05, 6.9215e-06,
        1.7558e-05, 6.8320e-06, 2.2032e-05, 5.0065e-06, 1.9490e-05, 1.1525e-05,
        1.8983e-05, 5.4115e-06, 1.0735e-05, 4.1169e-06, 1.1210e-05, 5.2879e-06,
        6.8343e-06, 1.6180e-05, 2.0116e-05, 6.9217e-06, 1.0364e-05, 1.0244e-05,
        4.5553e-06, 4.1652e-06, 1.2004e-05, 6.7522e-06, 1.4394e-05, 9.1856e-06,
        9.5783e-06, 1.0934e-05, 3.8646e-06, 1.4794e-05, 6.0522e-06, 6.2452e-06,
        1.3218e-05, 7.9922e-06, 8.8156e-06, 3.2919e-06, 6.5910e-06, 6.2587e-06,
        6.4449e-06, 1.8983e-05, 6.3952e-06, 5.4115e-06, 1.1210e-05, 5.4503e-06,
        1.4035e-05, 2.0136e-05, 7.8970e-06, 2.0106e-05, 1.3566e-05, 8.8273e-06,
        1.1294e-05, 1.4794e-05, 8.6167e-06, 7.9922e-06, 1.9942e-05, 1.1952e-05,
        1.0182e-05, 1.1525e-05, 8.0879e-06, 6.4156e-06, 2.1269e-05, 4.9068e-06,
        1.1042e-05, 9.1866e-06, 1.1525e-05, 4.1347e-06, 1.3700e-05, 1.1294e-05,
        6.4156e-06, 1.1670e-05, 4.7483e-06, 1.1199e-05, 7.0684e-06, 1.4855e-05,
        8.7664e-06, 1.1195e-05, 9.5769e-06, 3.8726e-06, 1.1766e-05, 6.1151e-06,
        1.5958e-05, 3.6241e-06, 5.8734e-06, 2.3458e-05, 1.0043e-05, 6.0885e-06,
        8.0476e-06, 8.7695e-06, 3.7445e-06, 2.2680e-05, 1.1063e-05, 1.3939e-05,
        8.4845e-06, 1.1267e-05, 8.2664e-06, 1.4058e-05, 1.6149e-05, 7.1694e-06,
        9.2882e-06, 1.1173e-05, 8.4940e-06, 4.9948e-06, 2.0851e-05, 8.1857e-07,
        1.0641e-05, 9.0542e-06, 1.1657e-05, 3.9447e-06, 5.8693e-06, 1.2615e-05,
        1.3435e-05, 1.1525e-05, 7.9922e-06, 9.1496e-06, 1.5610e-05, 6.8332e-06,
        4.9403e-06, 3.4809e-06, 6.3052e-06, 7.8970e-06, 5.8972e-06, 5.8538e-06,
        5.9669e-06, 8.2664e-06, 4.1652e-06, 1.0684e-05, 1.0182e-05, 1.1525e-05,
        4.5789e-06, 5.8730e-06, 1.5577e-05, 1.2324e-05, 7.0684e-06, 1.2760e-05,
        6.4156e-06, 4.9462e-06, 1.5566e-05, 5.4762e-06, 6.0381e-06, 4.6278e-06,
        7.2211e-06, 9.5769e-06, 8.5427e-06, 8.9561e-06, 4.6278e-06, 1.5032e-05,
        4.2558e-06, 4.2809e-06, 7.6603e-06, 1.9423e-05, 6.4156e-06, 9.5359e-06,
        1.2324e-05, 1.1525e-05, 1.7579e-05, 5.8843e-06, 1.0459e-05, 1.7084e-05,
        8.6256e-06, 4.2558e-06, 1.6054e-05, 8.9779e-06, 4.9948e-06, 1.4998e-05,
        1.1975e-05, 9.6240e-06, 4.1652e-06, 1.3310e-05, 8.7169e-06, 5.9326e-06,
        3.5560e-06, 1.4549e-01, 1.3549e-05, 5.4503e-06, 9.8927e-06, 6.8332e-06,
        1.1542e-05, 8.5810e-06, 6.5421e-06, 1.1234e-05, 1.1212e-05, 3.4599e-06,
        2.2664e-06, 1.9423e-05, 5.1541e-06, 6.7850e-06, 5.1541e-06, 1.6081e-06,
        8.6113e-06, 1.3398e-05, 1.2232e-05, 1.1525e-05, 3.8316e-06, 9.7370e-06,
        1.3235e-05, 7.5921e-06, 4.1687e-06, 1.4195e-05, 8.8512e-06, 2.2845e-05,
        8.6082e-06, 1.6575e-05, 1.1070e-05, 1.6638e-05, 4.2558e-06, 6.2854e-06,
        1.2825e-05, 6.9281e-06, 2.6416e-05, 3.7445e-06, 7.7596e-06, 3.8316e-06,
        1.2127e-05, 5.8781e-06, 1.1020e-05, 8.2157e-06, 1.2702e-05, 7.4098e-06,
        1.5005e-05, 1.7102e-05, 6.3952e-06, 1.3782e-05, 2.6416e-05, 1.2581e-05,
        9.8963e-06, 8.2540e-06, 6.4463e-06, 7.7281e-06, 1.1670e-05, 5.9274e-06,
        1.6189e-05, 1.6250e-05, 8.0056e-06, 1.2833e-05, 8.6082e-06, 4.7416e-06,
        1.0526e-05, 8.7001e-06, 2.2032e-05, 1.2127e-05, 9.8963e-06, 1.2833e-05,
        1.2324e-05, 1.2751e-05, 1.7109e-05, 6.1381e-06, 7.5921e-06, 2.3244e-05,
        2.1559e-05, 3.3826e-06, 8.8512e-06, 2.0520e-05, 6.9152e-06, 5.4503e-06,
        1.1113e-05, 1.4035e-05, 1.0154e-05, 1.1525e-05, 3.3826e-06, 2.0838e-05,
        1.3121e-05, 2.1989e-05, 1.3525e-05, 1.1975e-05, 1.2664e-05, 1.7619e-05,
        4.1652e-06, 7.9922e-06, 4.9948e-06, 6.5421e-06, 1.1613e-05, 1.2324e-05,
        1.1525e-05, 7.9922e-06, 7.1845e-06, 1.0182e-05, 7.2442e-06, 7.5464e-06,
        9.2646e-06, 1.6575e-05, 1.5910e-05, 8.8512e-06, 8.7906e-06, 1.2756e-05,
        1.5892e-05, 3.6999e-06, 9.9831e-06, 1.0910e-01, 9.7757e-06, 1.8452e-05,
        9.7779e-06, 7.1773e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([3.6451e-07, 1.2347e-06, 7.6931e-07,  ..., 1.2620e-06, 7.6765e-07,
        6.2621e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([3.5775e-06, 3.4238e-06, 3.7188e-06, 5.1005e-06, 5.9746e-06, 1.4072e-06,
        6.1974e-06, 1.3805e-06, 1.5072e-06, 2.7117e-06, 5.9815e-06, 7.9633e-06,
        8.3158e-06, 2.8995e-06, 1.3986e-06, 3.2964e-06, 8.5904e-06, 5.6425e-06,
        5.1017e-06, 5.3810e-06, 4.0720e-06, 5.5716e-06, 4.4457e-06, 3.6335e-06,
        5.1017e-06, 4.1835e-06, 3.7936e-06, 3.2366e-06, 3.2977e-06, 3.2560e-06,
        4.9655e-06, 3.3873e-06, 5.6867e-06, 4.7229e-06, 3.5700e-06, 4.9255e-06,
        6.4681e-06, 1.7336e-06, 3.7471e-06, 3.4705e-06, 8.8872e-06, 2.5082e-06,
        3.0820e-06, 3.7188e-06, 1.8177e-06, 3.5820e-06, 5.9544e-06, 2.2456e-06,
        4.5725e-06, 2.0178e-06, 4.6717e-06, 5.5056e-06, 4.4088e-06, 2.8468e-06,
        7.5149e-06, 4.1029e-06, 4.0238e-06, 2.9171e-06, 1.7067e-06, 3.9354e-06,
        4.2100e-06, 1.5986e-06, 6.3811e-06, 3.0820e-06, 2.8514e-06, 4.5024e-06,
        9.9073e-07, 2.8347e-06, 7.2931e-06, 4.1269e-06, 3.5354e-06, 1.5460e-06,
        1.3491e-06, 2.9641e-06, 4.2205e-06, 5.8445e-06, 4.8757e-06, 3.7386e-06,
        2.3376e-06, 4.0524e-06, 7.8254e-06, 8.9963e-06, 3.4238e-06, 6.2336e-06,
        2.6457e-06, 5.5200e-06, 7.5149e-06, 4.3712e-06, 7.4793e-06, 4.5690e-06,
        2.3864e-06, 5.8044e-06, 5.6202e-06, 1.8833e-06, 1.7233e-06, 4.5904e-06,
        3.3763e-06, 3.2113e-06, 2.2456e-06, 1.7677e-06, 4.6922e-06, 3.6036e-06,
        6.4996e-06, 2.2988e-06, 7.0664e-06, 1.3582e-06, 3.3650e-06, 2.5143e-06,
        4.8893e-06, 4.0523e-06, 6.3298e-06, 5.1017e-06, 3.3269e-06, 2.3722e-06,
        7.1004e-06, 5.5420e-06, 3.3269e-06, 8.4081e-06, 3.8378e-06, 1.7312e-06,
        1.3103e-06, 6.4467e-06, 9.4044e-06, 9.5138e-07, 2.3739e-06, 6.0835e-06,
        1.7067e-06, 3.5193e-06, 4.4111e-06, 3.8900e-06, 4.5788e-06, 3.8370e-06,
        2.1535e-06, 1.3481e-06, 4.6828e-06, 5.5716e-06, 5.8044e-06, 2.0225e-06,
        3.9300e-06, 3.4005e-06, 3.5114e-06, 7.8254e-06, 7.8254e-06, 4.9097e-06,
        4.2879e-06, 8.2768e-06, 1.5860e-06, 5.2607e-06, 9.2908e-06, 3.0448e-06,
        3.8166e-06, 3.4358e-06, 2.7616e-06, 3.2964e-06, 3.3650e-06, 7.5601e-06,
        1.4832e-06, 4.3386e-06, 4.5804e-06, 2.6148e-06, 2.1508e-06, 6.2710e-06,
        5.3810e-06, 3.5649e-06, 3.4184e-06, 2.2842e-06, 1.7336e-06, 3.1056e-06,
        3.9661e-06, 3.2060e-06, 3.7188e-06, 6.3160e-06, 5.1017e-06, 8.2980e-06,
        3.9300e-06, 6.3762e-06, 9.4781e-06, 8.8872e-06, 2.8904e-06, 3.7188e-06,
        2.0379e-06, 5.3439e-06, 2.4775e-06, 2.1565e-06, 2.5588e-06, 4.4457e-06,
        6.3160e-06, 9.9073e-07, 3.8772e-06, 3.7024e-06, 4.0523e-06, 3.2703e-06,
        6.3160e-06, 3.9661e-06, 4.9097e-06, 2.2060e-06, 9.1256e-06, 4.2171e-06,
        3.0724e-06, 5.9836e-06, 4.8597e-06, 3.7471e-06, 1.7090e-06, 6.1426e-06,
        4.8667e-06, 1.7067e-06, 2.8502e-06, 2.1917e-06, 3.3220e-06, 1.3833e-06,
        7.2252e-06, 9.8498e-06, 3.7471e-06, 7.2252e-06, 2.6458e-06, 4.8216e-06,
        5.6025e-06, 4.9952e-06, 4.8893e-06, 2.2456e-06, 1.1772e-06, 5.2846e-06,
        3.9661e-06, 3.7471e-06, 6.3254e-06, 2.4433e-06, 3.4417e-06, 5.8741e-06,
        2.3672e-06, 1.8087e-06, 2.8502e-06, 2.0826e-06, 4.8838e-06, 4.8992e-06,
        1.9720e-06, 2.2060e-06, 1.8220e-06, 2.8502e-06, 3.4358e-06, 5.5420e-06,
        3.9833e-06, 1.9459e-06, 4.4599e-06, 5.1005e-06, 9.2879e-06, 7.9305e-06,
        8.7812e-06, 2.8468e-06, 7.6261e-06, 4.3854e-06, 5.3809e-06, 6.3650e-06,
        4.1269e-06, 3.7188e-06, 7.0663e-06, 3.7950e-06, 3.2964e-06, 3.0820e-06,
        5.4680e-06, 4.1059e-06, 3.0642e-06, 2.3797e-06, 2.2432e-06, 3.9300e-06,
        2.6135e-06, 8.4198e-06, 5.1005e-06, 7.6261e-06, 3.1108e-06, 3.6903e-06,
        3.9655e-06, 4.5993e-06, 5.5273e-06, 4.0231e-06, 4.8597e-06, 4.6828e-06,
        3.0584e-06, 2.2456e-06, 8.8872e-06, 1.3491e-06, 3.2924e-06, 7.4648e-06,
        8.9411e-06, 5.2755e-06, 3.8632e-06, 3.6641e-06, 4.3492e-07, 1.0910e-05,
        2.6511e-06, 7.3690e-06, 3.7471e-06, 3.0576e-06, 4.2405e-06, 2.9250e-06,
        3.6261e-06, 3.7471e-06, 6.6844e-06, 2.6961e-06, 1.3262e-06, 5.2755e-06,
        7.6261e-06, 3.7240e-06, 8.8872e-06, 5.8741e-06, 3.0448e-06, 4.5421e-06,
        9.1911e-06, 3.6622e-06, 3.2964e-06, 1.9720e-06, 2.6148e-06, 3.7188e-06,
        2.9111e-06, 3.5370e-06, 3.7154e-06, 2.4605e-06, 1.4409e-06, 4.0546e-06,
        4.6367e-06, 6.3571e-06, 5.8044e-06, 1.5478e-06, 4.7229e-06, 1.5986e-06,
        5.8316e-06, 6.3670e-06, 4.5149e-06, 6.3650e-06, 4.3575e-07, 4.5694e-06,
        3.9244e-06, 6.1974e-06, 4.6049e-06, 4.8597e-06, 3.9904e-06, 4.8587e-06,
        3.0724e-06, 2.6589e-06, 1.2405e-05, 1.2166e-06, 2.8502e-06, 3.5193e-06,
        3.7936e-06, 2.9438e-06, 2.6142e-06, 3.5284e-06, 2.4302e-06, 2.5302e-06,
        3.3177e-06, 2.6996e-06, 2.5607e-06, 4.8292e-06, 3.7630e-06, 4.9100e-06,
        4.7225e-06, 5.1348e-06, 4.4107e-06, 2.9130e-06, 1.9761e-06, 6.3254e-06,
        3.4664e-06, 5.8399e-06, 7.0956e-06, 2.5552e-06, 3.7964e-06, 3.1851e-06,
        2.0826e-06, 6.7225e-06, 7.5032e-06, 6.5511e-06, 6.2914e-06, 9.5138e-07,
        5.5314e-06, 2.1888e-06, 7.9845e-06, 7.3813e-06, 7.6261e-06, 4.1817e-07,
        5.9631e-06, 1.4409e-06, 3.7188e-06, 9.0581e-06, 2.9260e-06, 5.4438e-06,
        4.4274e-06, 7.7207e-06, 1.2624e-05, 2.8502e-06, 1.1040e-06, 6.2783e-06,
        4.3148e-06, 2.6436e-06, 7.3747e-06, 3.8268e-06, 2.8314e-06, 1.1723e-06,
        3.5241e-06, 2.5151e-06, 2.9914e-07, 2.2432e-06, 1.7067e-06, 2.5552e-06,
        7.1917e-06, 6.2684e-06, 4.9381e-06, 2.8502e-06, 1.6855e-06, 4.9392e-06,
        3.2489e-06, 3.0584e-06, 4.5421e-06, 2.4302e-06, 2.6515e-06, 7.6261e-06,
        4.6367e-06, 5.0004e-06, 3.6490e-06, 4.1269e-06, 4.4971e-06, 2.2886e-06,
        4.6717e-06, 4.9097e-06, 4.5788e-06, 6.2848e-06, 8.8872e-06, 3.7024e-06,
        2.5942e-06, 3.9933e-06, 1.7959e-06, 3.4358e-06, 2.3376e-06, 6.3926e-06,
        3.4443e-06, 7.6314e-06, 5.5420e-06, 2.4362e-06, 1.5460e-06, 3.3533e-06,
        2.1542e-06, 4.7819e-06, 4.4606e-06, 5.8673e-06, 2.9862e-06, 4.5738e-06,
        2.1647e-06, 2.9812e-06, 3.0323e-06, 3.2964e-06, 6.9674e-06, 4.2879e-06,
        3.6725e-06, 7.9591e-06, 5.6025e-06, 5.9746e-06, 3.3150e-06, 4.9092e-06,
        2.2456e-06, 1.9505e-06, 3.0576e-06, 2.0254e-06, 2.1183e-06, 2.9111e-06,
        3.2560e-06, 1.0910e-05, 3.0584e-06, 2.8502e-06, 3.9661e-06, 1.4811e-06,
        2.9294e-06, 3.7375e-06, 7.4256e-07, 1.2961e-06, 4.6068e-06, 1.7227e-06,
        6.6844e-06, 3.7821e-06, 5.9212e-06, 5.1005e-06, 3.7188e-06, 3.9833e-06,
        4.5725e-06, 4.4274e-06, 2.2432e-06, 7.2216e-06, 4.2263e-06, 2.2286e-06,
        9.5138e-07, 3.1782e-06, 3.4664e-06, 5.5273e-06, 4.6828e-06, 3.0724e-06,
        6.3155e-06, 1.5031e-06, 3.0194e-06, 3.7188e-06, 3.8321e-06, 8.5580e-07,
        7.7207e-06, 1.9720e-06, 4.5362e-06, 4.9983e-06, 2.2853e-06, 6.7455e-06,
        5.1302e-06, 7.3895e-06, 3.3650e-06, 5.0607e-06, 2.8502e-06, 1.5986e-06,
        1.8329e-06, 7.0956e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([7.6939e-06, 8.7313e-06, 1.2086e-05, 7.2644e-06, 4.7199e-06, 1.6319e-05,
        5.6132e-06, 8.4176e-06, 1.2802e-05, 5.8719e-06, 1.2362e-05, 9.0583e-06,
        8.4761e-06, 9.2661e-06, 4.8679e-06, 8.7787e-06, 8.6640e-06, 1.2601e-05,
        1.7194e-05, 7.6810e-06, 3.4561e-06, 6.3205e-06, 1.6628e-05, 1.5601e-05,
        1.0931e-05, 1.0679e-05, 9.1225e-06, 1.0688e-05, 1.1914e-05, 1.3206e-05,
        7.6939e-06, 9.9011e-06, 1.1207e-05, 1.2336e-05, 1.3601e-05, 9.4575e-06,
        3.1384e-06, 8.6769e-06, 7.0359e-06, 5.9198e-06, 7.4167e-06, 8.5519e-06,
        8.7423e-06, 6.1876e-06, 8.0823e-06, 6.1047e-06, 6.7664e-06, 6.1347e-06,
        9.2396e-06, 5.6130e-06, 1.1880e-05, 1.4613e-05, 6.0192e-06, 5.7280e-06,
        9.0801e-06, 1.4855e-05, 6.1119e-06, 7.6604e-06, 1.0292e-05, 1.2068e-05,
        5.4258e-06, 6.9313e-06, 9.4575e-06, 5.2377e-06, 6.4733e-06, 2.6388e-06,
        5.1480e-06, 5.1110e-06, 1.6857e-05, 1.1286e-05, 3.1705e-06, 1.6758e-05,
        1.2331e-05, 3.1722e-06, 2.1810e-05, 8.6149e-06, 1.2417e-05, 8.6769e-06,
        1.0931e-05, 5.4258e-06, 8.7302e-06, 1.2558e-05, 8.1657e-06, 1.6758e-05,
        1.4182e-05, 8.2009e-06, 1.6488e-05, 7.5856e-06, 9.5346e-06, 6.7951e-06,
        2.2359e-06, 5.6130e-06, 1.4849e-05, 9.9853e-06, 1.1728e-05, 1.3118e-05,
        7.0958e-06, 6.3637e-06, 1.2989e-05, 5.2034e-06, 1.0676e-05, 1.2260e-05,
        1.1534e-05, 9.4772e-06, 1.2863e-05, 1.1680e-05, 9.0145e-06, 1.5156e-05,
        9.9732e-06, 7.2583e-06, 1.0230e-05, 3.7160e-06, 1.0332e-05, 9.0583e-06,
        1.0213e-05, 1.0477e-05, 7.5856e-06, 6.2107e-06, 9.4052e-06, 7.8425e-06,
        8.6929e-06, 7.4758e-06, 1.3490e-05, 1.4334e-05, 6.3208e-06, 2.1236e-05,
        1.2362e-05, 1.9627e-05, 8.5161e-06, 4.3653e-06, 1.0605e-05, 4.3545e-06,
        1.0358e-05, 1.3911e-05, 9.0668e-06, 7.6939e-06, 8.8531e-06, 5.7553e-06,
        5.7553e-06, 1.7543e-05, 5.6130e-06, 2.7245e-06, 2.0076e-05, 1.0245e-05,
        1.7117e-05, 5.0521e-06, 7.7463e-06, 5.0521e-06, 7.2042e-06, 9.9372e-06,
        1.0230e-05, 1.1256e-05, 7.5528e-06, 9.0984e-06, 8.1406e-06, 3.5176e-06,
        1.0905e-05, 1.0511e-05, 1.2558e-05, 1.1612e-05, 6.9201e-06, 5.1480e-06,
        1.6040e-05, 8.3795e-06, 1.0932e-05, 9.0583e-06, 1.5274e-05, 6.1090e-06,
        6.9640e-06, 5.7087e-06, 5.5653e-06, 1.1459e-05, 6.0306e-06, 1.2280e-05,
        4.1546e-06, 1.7313e-05, 8.5519e-06, 1.2558e-05, 1.1341e-05, 1.2417e-05,
        1.9147e-06, 6.4732e-06, 8.7787e-06, 5.6130e-06, 2.1275e-06, 9.8267e-06,
        4.1473e-06, 1.0292e-05, 9.3513e-06, 7.1378e-06, 6.3205e-06, 7.6939e-06,
        1.1195e-05, 2.8600e-06, 1.3171e-05, 1.5670e-05, 4.6147e-06, 6.4733e-06,
        2.1961e-05, 1.2558e-05, 4.3653e-06, 5.0521e-06, 1.7543e-05, 4.3653e-06,
        2.1950e-05, 9.9966e-06, 5.2377e-06, 7.1914e-06, 2.0076e-05, 6.3208e-06,
        8.9376e-06, 2.0719e-05, 7.6978e-06, 6.1230e-06, 1.0563e-05, 4.5318e-06,
        8.3612e-06, 1.3585e-05, 6.9201e-06, 1.2336e-05, 2.9159e-06, 8.0276e-06,
        1.1290e-05, 2.1950e-05, 1.2775e-05, 8.2063e-06, 2.1275e-06, 9.3754e-06,
        5.8140e-06, 1.0126e-05, 5.5104e-06, 6.9991e-06, 4.4755e-06, 7.2415e-06,
        6.4519e-06, 1.1207e-05, 5.2377e-06, 1.4465e-05, 5.8488e-06, 1.1819e-05,
        1.0010e-05, 5.6929e-06, 4.2851e-06, 5.4497e-06, 8.6929e-06, 5.2029e-06,
        7.7809e-06, 1.4562e-06, 8.6394e-06, 1.2730e-05, 1.4140e-05, 8.0993e-06,
        1.0022e-05, 8.2475e-07, 3.1231e-06, 1.7543e-05, 5.2377e-06, 9.9372e-06,
        1.5418e-05, 8.5767e-06, 1.2622e-05, 9.1225e-06, 3.7224e-06, 1.7543e-05,
        5.1110e-06, 4.1916e-06, 6.7162e-06, 7.2583e-06, 6.9201e-06, 1.0635e-05,
        1.6263e-05, 5.8488e-06, 7.0904e-06, 7.0685e-06, 9.6338e-06, 3.8651e-06,
        2.1275e-06, 1.7043e-05, 8.8565e-06, 7.6412e-06, 5.0150e-06, 3.3275e-06,
        4.1915e-06, 1.1728e-05, 1.1691e-05, 4.1276e-06, 1.0969e-05, 1.0605e-05,
        3.2266e-06, 1.6920e-05, 1.3151e-05, 8.8674e-06, 5.7516e-06, 3.7930e-06,
        1.1534e-05, 7.6604e-06, 6.8251e-06, 8.7329e-06, 5.8541e-06, 3.9087e-06,
        6.4651e-06, 5.1457e-06, 1.2313e-05, 2.3172e-05, 5.2448e-06, 3.7262e-06,
        6.1013e-06, 8.8531e-06, 4.5361e-06, 7.6710e-06, 1.6530e-05, 9.2654e-06,
        1.7543e-05, 4.3820e-06, 2.1950e-05, 8.3197e-06, 4.2851e-06, 2.2205e-05,
        4.6432e-06, 1.1262e-05, 1.0741e-05, 8.6052e-06, 5.6203e-06, 8.1943e-06,
        9.4167e-06, 5.6130e-06, 1.3544e-05, 2.6576e-06, 8.6929e-06, 4.7396e-06,
        5.6130e-06, 5.8719e-06, 4.2713e-06, 1.2499e-05, 9.0583e-06, 5.1972e-06,
        7.7121e-06, 1.2558e-05, 5.1565e-06, 8.3534e-06, 1.1811e-05, 1.5509e-06,
        1.0503e-05, 8.1943e-06, 9.8594e-06, 2.1140e-05, 7.9336e-06, 5.3304e-06,
        5.0521e-06, 1.0017e-05, 2.0746e-05, 6.7686e-06, 8.6769e-06, 2.5192e-05,
        8.0277e-06, 9.8701e-06, 4.1118e-06, 9.6103e-06, 1.2389e-05, 4.4723e-06,
        1.1764e-05, 8.0825e-06, 4.5636e-06, 4.1276e-06, 1.0126e-05, 7.5986e-06,
        1.1525e-05, 1.1721e-05, 1.0969e-05, 1.0373e-05, 1.1890e-05, 9.5277e-06,
        8.1924e-06, 6.2396e-06, 6.4441e-06, 8.2006e-06, 1.9946e-05, 7.0296e-06,
        5.9556e-06, 6.9201e-06, 1.9676e-05, 8.2297e-06, 1.3001e-05, 8.3268e-06,
        1.0348e-05, 9.8701e-06, 1.0017e-05, 9.0004e-06, 2.1236e-05, 9.4584e-06,
        1.3428e-05, 8.6769e-06, 2.5312e-06, 7.5856e-06, 1.0082e-05, 1.1060e-05,
        4.3653e-06, 6.1230e-06, 1.2775e-05, 1.3965e-05, 9.3848e-06, 8.1943e-06,
        6.3156e-06, 5.0521e-06, 6.4733e-06, 5.2504e-06, 8.6769e-06, 3.5533e-06,
        1.1740e-05, 8.2009e-06, 9.7298e-06, 8.5519e-06, 1.1534e-05, 1.4855e-05,
        2.1810e-05, 1.1343e-05, 8.6769e-06, 2.0746e-05, 9.5346e-06, 9.0583e-06,
        9.1316e-06, 4.4542e-06, 4.9692e-06, 1.9147e-06, 9.1640e-06, 6.6426e-06,
        5.6985e-06, 1.0554e-05, 7.0904e-06, 1.3428e-05, 5.0964e-06, 2.1275e-06,
        9.1225e-06, 6.7489e-06, 8.4651e-06, 5.6663e-06, 5.0521e-06, 1.2775e-05,
        9.1225e-06, 4.1473e-06, 9.7549e-06, 1.4277e-05, 1.0189e-05, 8.5227e-06,
        1.5111e-05, 8.9736e-06, 1.1096e-05, 4.8591e-06, 2.2205e-05, 7.1548e-06,
        6.4598e-06, 1.9676e-05, 3.6999e-06, 7.7852e-06, 8.7302e-06, 1.7535e-05,
        5.2377e-06, 8.0993e-06, 1.2195e-05, 1.0545e-05, 9.0984e-06, 1.4980e-05,
        2.8390e-06, 7.2766e-06, 8.1068e-07, 5.0877e-06, 7.9283e-06, 9.8702e-06,
        5.2412e-06, 1.2946e-05, 1.0373e-05, 8.0197e-06, 1.7004e-05, 1.0017e-05,
        7.7937e-06, 8.5519e-06, 1.1288e-05, 8.7586e-06, 8.0714e-06, 1.1189e-05,
        2.0076e-05, 4.0845e-06, 1.2963e-05, 1.4231e-05, 4.8591e-06, 6.9201e-06,
        1.3838e-05, 1.4280e-05, 1.0675e-05, 9.1967e-06, 1.2730e-05, 1.4262e-05,
        1.0715e-05, 6.7708e-06, 9.5126e-06, 4.3653e-06, 9.5126e-06, 1.3143e-05,
        1.0192e-05, 4.1276e-06, 8.6769e-06, 6.4441e-06, 6.7951e-06, 6.6179e-06,
        5.2377e-06, 4.4093e-06, 7.1711e-06, 9.8311e-06, 3.2606e-06, 6.1026e-06,
        7.3367e-06, 8.5524e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([6.7059e-07, 4.4666e-07, 6.1198e-07,  ..., 9.7238e-07, 1.4462e-06,
        9.1844e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.9689, 1.3721, 1.1671, 0.9580, 1.1817, 1.0829, 1.7558, 1.2247, 1.3917,
        1.4848, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193,
        0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193,
        0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193,
        0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193,
        0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193,
        0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193,
        0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193,
        0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193,
        0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193,
        0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193, 0.0193,
        0.0193], device='cuda:0', grad_fn=<NormBackward1>)

 sparsity of   [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.03703703731298447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.03703703731298447, 1.0, 1.0, 1.0, 0.0, 0.0, 0.03703703731298447, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]

 sparsity of   [1.0, 0.4375, 1.0, 1.0, 0.4375, 0.453125, 1.0, 1.0, 1.0, 1.0, 0.4375, 1.0, 0.4375, 1.0, 1.0, 1.0, 0.4375, 0.4375, 0.4375, 1.0, 0.453125, 0.4375, 1.0, 1.0, 0.4375, 1.0, 1.0, 0.4375, 1.0, 1.0, 0.4375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4375, 1.0, 1.0, 1.0, 0.453125, 1.0, 0.453125, 0.4375, 0.484375, 1.0, 0.4375, 0.4375, 0.453125, 1.0, 0.4375, 1.0, 0.453125, 1.0, 0.453125, 1.0, 1.0, 0.453125, 0.4375, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 0.578125, 1.0, 1.0, 1.0, 0.59375, 1.0, 1.0, 0.5868055820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.59375, 1.0, 0.5833333134651184, 1.0, 1.0, 0.585069477558136, 0.5729166865348816, 1.0, 1.0, 1.0, 1.0, 0.5868055820465088, 1.0, 1.0, 0.5954861044883728, 1.0, 1.0, 1.0, 0.5954861044883728, 1.0, 1.0, 1.0, 0.5868055820465088, 0.5798611044883728, 1.0, 0.5729166865348816, 1.0, 1.0, 0.585069477558136, 1.0, 1.0, 1.0, 0.5833333134651184, 0.600694477558136, 1.0, 1.0, 0.5954861044883728, 1.0, 1.0, 0.6232638955116272, 0.5868055820465088, 1.0, 0.5798611044883728, 1.0, 1.0, 1.0]

 sparsity of   [0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.703125, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.703125, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 1.0, 0.703125, 0.703125, 0.6875, 1.0, 0.703125, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 0.703125, 1.0, 1.0, 1.0, 0.6875, 0.6875, 1.0, 1.0, 1.0, 0.703125, 0.703125, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.703125, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 0.703125, 1.0, 0.6875, 0.6875, 1.0, 0.703125, 1.0, 0.6875, 1.0, 0.703125, 1.0, 0.6875, 1.0, 0.6875, 0.703125, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.71875, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.703125, 0.703125, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.703125, 0.703125, 1.0, 1.0, 0.703125, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.703125, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875]

 sparsity of   [0.453125, 1.0, 1.0, 0.4375, 1.0, 1.0, 0.4375, 0.46875, 0.4375, 0.453125, 0.46875, 0.4375, 0.4375, 0.4375, 0.4375, 0.4375, 0.4375, 0.4375, 0.453125, 1.0, 0.453125, 0.4375, 1.0, 1.0, 0.4375, 0.46875, 1.0, 1.0, 0.484375, 1.0, 0.4375, 0.453125, 0.46875, 0.4375, 0.453125, 0.453125, 0.4375, 0.46875, 1.0, 0.453125, 0.453125, 0.4375, 1.0, 0.453125, 1.0, 0.453125, 0.453125, 0.4375, 0.453125, 0.75, 0.515625, 1.0, 0.4375, 1.0, 0.453125, 0.453125, 0.4375, 0.453125, 0.46875, 0.5, 0.4375, 1.0, 0.4375, 1.0, 1.0, 0.453125, 0.453125, 0.453125, 0.453125, 0.453125, 0.4375, 0.4375, 0.4375, 0.46875, 0.4375, 0.453125, 1.0, 0.46875, 0.46875, 1.0, 1.0, 0.453125, 1.0, 1.0, 0.4375, 0.4375, 0.46875, 0.4375, 0.4375, 0.4375, 1.0, 1.0, 1.0, 0.515625, 0.46875, 1.0, 1.0, 0.4375, 0.4375, 0.4375, 0.46875, 0.4375, 0.453125, 1.0, 0.4375, 0.4375, 1.0, 0.453125, 0.4375, 1.0, 0.4375, 0.453125, 0.4375, 1.0, 0.5, 0.4375, 0.46875, 0.453125, 0.4375, 0.4375, 1.0, 0.4375, 0.4375, 1.0, 0.46875, 0.453125, 0.4375, 1.0, 0.4375, 0.453125, 1.0, 0.953125, 0.4375, 0.4375, 0.4375, 0.4375, 0.4375, 1.0, 0.5, 1.0, 0.4375, 0.46875, 0.453125, 0.5, 0.484375, 0.4375, 0.4375, 0.4375, 0.453125, 0.453125, 0.453125, 1.0, 0.4375, 0.453125, 0.4375, 0.4375, 0.46875, 0.453125, 1.0, 1.0, 0.4375, 0.4375, 1.0, 0.5, 1.0, 0.4375, 0.4375, 1.0, 0.4375, 0.453125, 0.453125, 0.4375, 0.453125, 1.0, 0.484375, 0.453125, 0.453125, 1.0, 1.0, 1.0, 0.4375, 1.0, 0.4375, 0.4375, 0.4375, 0.4375, 0.4375, 0.4375, 0.4375, 1.0, 0.453125, 1.0, 0.453125, 1.0, 0.4375, 1.0, 0.4375, 0.4375, 1.0, 1.0, 0.4375, 0.453125, 0.4375, 0.46875, 0.453125, 1.0, 1.0, 0.453125, 1.0, 0.4375, 0.4375, 1.0, 1.0, 0.453125, 1.0, 0.453125, 1.0, 0.453125, 0.4375, 0.484375, 0.484375, 0.46875, 0.4375, 1.0, 0.453125, 0.453125, 1.0, 1.0, 0.46875, 0.4375, 0.4375, 0.484375, 0.453125, 0.453125, 0.4375, 0.453125, 0.4375, 0.46875, 0.4375, 1.0, 0.46875, 0.4375, 0.4375, 1.0, 1.0, 0.46875, 0.484375, 0.4375, 0.453125, 0.4375, 1.0, 1.0, 0.4375, 0.53125, 0.46875, 0.4375]

 sparsity of   [0.27734375, 1.0, 1.0, 1.0, 1.0, 0.30859375, 0.28125, 1.0, 1.0, 1.0, 1.0, 0.265625, 1.0, 1.0, 1.0, 0.28515625, 1.0, 1.0, 1.0, 0.28125, 0.26953125, 1.0, 1.0, 0.265625, 1.0, 1.0, 0.26171875, 0.30859375, 0.265625, 0.26171875, 0.26171875, 1.0, 0.265625, 0.265625, 1.0, 1.0, 0.28515625, 1.0, 0.421875, 1.0, 0.28125, 1.0, 0.25, 1.0, 0.26171875, 1.0, 1.0, 1.0, 0.2578125, 0.2578125, 0.296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.26953125, 0.2578125, 1.0, 0.296875, 1.0, 1.0, 1.0, 0.34765625]

 sparsity of   [1.0, 0.5815972089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6041666865348816, 0.5868055820465088, 0.5763888955116272, 0.578125, 1.0, 1.0, 1.0, 0.5815972089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5833333134651184, 1.0, 0.5815972089767456, 0.585069477558136, 1.0, 1.0, 1.0, 1.0, 0.5798611044883728, 1.0, 1.0, 0.5746527910232544, 1.0, 0.578125, 1.0, 1.0, 0.5798611044883728, 1.0, 1.0, 1.0, 0.585069477558136, 1.0, 1.0, 1.0, 0.5833333134651184, 1.0, 1.0, 1.0, 0.5763888955116272, 0.578125, 0.5885416865348816, 0.5815972089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.703125, 1.0, 0.703125, 0.703125, 1.0, 1.0, 1.0, 0.703125, 0.6875, 0.703125, 1.0, 0.703125, 0.703125, 0.71875, 1.0, 1.0, 1.0, 0.703125, 1.0, 1.0, 1.0, 1.0, 0.703125, 1.0, 0.6875, 0.71875, 1.0, 1.0, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 0.734375, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.703125, 1.0, 1.0, 1.0, 0.6875, 0.71875, 0.6875, 0.703125, 0.703125, 1.0, 0.703125, 1.0, 1.0, 0.703125, 0.703125, 1.0, 1.0, 0.703125, 0.6875, 1.0, 0.703125, 0.71875, 1.0, 0.6875, 1.0, 0.703125, 0.703125, 0.703125, 1.0, 0.6875, 0.703125, 1.0, 0.6875, 0.703125, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.71875, 0.703125, 0.703125, 0.703125, 1.0, 0.703125, 1.0, 1.0, 0.6875, 0.703125, 1.0, 1.0, 0.703125, 0.703125, 0.703125, 1.0, 0.703125, 0.703125, 1.0, 1.0, 0.734375, 1.0, 1.0, 1.0, 0.703125, 0.703125, 1.0, 0.703125, 1.0, 1.0, 0.703125, 0.71875, 0.6875, 0.703125, 0.6875, 0.6875, 0.703125, 1.0, 0.6875, 0.703125, 1.0, 0.703125, 1.0, 0.6875, 0.71875, 1.0, 1.0, 0.703125, 0.703125, 1.0, 0.703125, 0.71875, 1.0, 1.0, 1.0, 0.703125, 1.0, 0.703125, 0.703125, 0.71875, 0.703125, 0.703125, 1.0, 0.71875, 0.703125, 0.703125, 1.0, 0.71875, 0.703125, 0.703125, 1.0, 0.703125, 1.0, 0.703125, 0.6875, 1.0, 0.703125, 0.703125, 0.703125, 1.0, 1.0, 0.703125, 1.0, 0.703125, 1.0, 1.0, 0.6875, 1.0, 0.703125, 0.6875, 1.0, 0.703125, 0.703125, 1.0, 1.0, 0.6875, 1.0, 0.703125, 0.703125, 1.0, 1.0, 0.71875, 0.71875, 0.703125, 1.0, 1.0, 0.703125, 1.0, 1.0, 1.0, 0.6875, 0.703125, 0.703125, 0.703125, 1.0, 1.0, 0.71875, 0.703125, 0.703125, 0.703125, 1.0, 0.703125, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 1.0, 0.71875, 1.0, 0.71875, 0.703125, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.703125, 1.0, 0.703125, 0.703125, 1.0, 1.0, 0.703125, 0.703125, 0.703125, 1.0, 1.0, 0.6875, 0.6875, 0.703125, 1.0, 1.0, 0.6875, 0.703125, 0.71875, 0.6875, 0.71875, 0.703125, 0.703125, 0.703125, 0.703125, 1.0, 0.6875]

 sparsity of   [0.15625, 1.0, 0.1640625, 1.0, 0.16015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.171875, 1.0, 1.0, 1.0, 1.0, 0.203125, 1.0, 1.0, 1.0, 0.19140625, 0.16796875, 1.0, 1.0, 1.0, 0.203125, 1.0, 1.0, 1.0, 0.19140625, 1.0, 1.0, 0.171875, 1.0, 0.1796875, 1.0, 1.0, 0.16796875, 0.1796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1796875, 0.20703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.171875, 1.0, 1.0, 1.0, 1.0, 0.1640625, 1.0, 0.16015625]

 sparsity of   [1.0, 1.0, 1.0, 0.7274305820465088, 1.0, 1.0, 0.7309027910232544, 1.0, 1.0, 0.7309027910232544, 1.0, 1.0, 0.7065972089767456, 0.703125, 1.0, 1.0, 1.0, 1.0, 0.710069477558136, 0.7083333134651184, 1.0, 0.703125, 1.0, 1.0, 1.0, 0.7204861044883728, 1.0, 1.0, 1.0, 0.710069477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7222222089767456, 1.0, 1.0, 1.0, 0.7065972089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7291666865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7083333134651184, 1.0, 0.7239583134651184, 0.7222222089767456, 1.0, 1.0, 1.0]

 sparsity of   [0.71875, 0.671875, 1.0, 1.0, 0.734375, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 0.71875, 0.734375, 1.0, 1.0, 1.0, 0.703125, 1.0, 0.75, 1.0, 1.0, 0.71875, 0.6875, 1.0, 1.0, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.703125, 1.0, 1.0, 1.0, 0.671875, 0.734375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.734375, 1.0, 1.0, 0.703125, 1.0, 0.734375, 1.0, 1.0, 1.0, 0.6875, 0.671875, 0.703125, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.734375, 1.0, 1.0, 0.734375, 1.0, 1.0, 0.6875, 0.703125, 0.71875, 1.0, 0.703125, 0.671875, 1.0, 1.0, 0.671875, 1.0, 0.703125, 1.0, 0.671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.734375, 1.0, 1.0, 1.0, 1.0, 0.734375, 1.0, 1.0, 0.734375, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.734375, 1.0, 1.0, 0.734375, 0.75, 0.671875, 1.0, 1.0, 0.65625, 0.71875, 0.71875, 1.0, 1.0, 1.0, 0.671875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.734375, 1.0, 1.0, 1.0, 0.734375, 1.0, 0.734375, 1.0, 0.734375, 0.71875, 1.0, 0.71875, 1.0, 0.734375, 1.0, 0.703125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 0.703125, 1.0, 0.703125, 0.703125, 0.71875, 0.703125, 0.734375, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.65625, 1.0, 1.0, 1.0, 1.0, 0.671875, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.65625, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.703125, 0.65625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 0.71875, 0.65625, 1.0, 0.734375, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.65625, 0.71875, 0.71875, 1.0, 0.65625, 0.703125, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 0.734375, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 0.0703125, 1.0, 1.0, 1.0, 0.0546875, 1.0, 1.0, 0.0546875, 1.0, 0.0703125, 0.0546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0625, 1.0, 0.0546875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07421875, 1.0, 1.0, 1.0, 1.0, 0.0625, 1.0, 0.06640625, 0.05859375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.05859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.078125, 1.0, 1.0, 0.07421875, 1.0, 0.0625, 1.0, 1.0, 1.0, 0.06640625, 1.0, 0.07421875, 0.0625, 0.0546875, 0.0625, 1.0, 0.05859375, 1.0, 0.0625, 0.0703125, 0.05859375, 1.0, 0.08984375, 1.0, 1.0, 1.0, 1.0, 0.0625, 0.06640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0546875, 1.0, 1.0, 1.0, 0.06640625, 1.0, 1.0, 0.078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.05859375, 1.0, 1.0, 1.0, 1.0, 0.05859375, 1.0, 0.0703125, 1.0, 0.0703125, 0.05859375, 1.0, 1.0, 1.0, 0.06640625, 0.0625, 1.0, 0.0703125]

 sparsity of   [1.0, 0.6892361044883728, 0.6875, 1.0, 0.6883680820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6892361044883728, 0.6892361044883728, 1.0, 0.6883680820465088, 1.0, 1.0, 1.0, 0.6892361044883728, 0.6892361044883728, 1.0, 0.6875, 0.6892361044883728, 1.0, 0.6918402910232544, 0.6883680820465088, 0.6883680820465088, 1.0, 0.6875, 0.6875, 0.6901041865348816, 1.0, 0.6901041865348816, 1.0, 1.0, 1.0, 0.6883680820465088, 1.0, 0.6901041865348816, 1.0, 1.0, 0.6883680820465088, 1.0, 1.0, 0.6883680820465088, 0.6892361044883728, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6901041865348816, 1.0, 0.6883680820465088, 1.0, 0.6892361044883728, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6901041865348816, 1.0, 1.0, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6892361044883728, 0.6883680820465088, 1.0, 1.0, 1.0, 0.6892361044883728, 1.0, 1.0, 1.0, 0.6883680820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6901041865348816, 1.0, 0.6883680820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6892361044883728, 1.0, 0.6883680820465088, 1.0, 1.0, 1.0, 1.0, 0.6901041865348816, 1.0, 0.6875, 0.6892361044883728, 0.6883680820465088, 0.6883680820465088, 0.6883680820465088, 0.6892361044883728, 0.6892361044883728, 1.0, 1.0, 1.0, 0.6892361044883728, 1.0, 0.6883680820465088, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6883680820465088]

 sparsity of   [1.0, 0.59375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.59375, 1.0, 0.6015625, 1.0, 0.6015625, 1.0, 1.0, 0.6015625, 1.0, 1.0, 1.0, 1.0, 0.59375, 0.59375, 1.0, 0.59375, 1.0, 1.0, 0.59375, 1.0, 0.59375, 0.59375, 0.6328125, 1.0, 1.0, 0.59375, 0.6015625, 0.59375, 0.59375, 0.609375, 1.0, 1.0, 1.0, 0.59375, 1.0, 1.0, 0.59375, 0.59375, 1.0, 0.59375, 1.0, 1.0, 0.6015625, 1.0, 1.0, 0.59375, 0.609375, 0.59375, 1.0, 1.0, 0.59375, 0.59375, 0.6015625, 1.0, 0.59375, 1.0, 1.0, 1.0, 0.59375, 0.59375, 1.0, 1.0, 0.59375, 0.59375, 0.59375, 1.0, 0.6015625, 1.0, 1.0, 1.0, 0.6015625, 1.0, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 1.0, 1.0, 0.6015625, 1.0, 1.0, 0.59375, 0.59375, 1.0, 0.6015625, 0.59375, 0.6015625, 0.6015625, 0.59375, 1.0, 0.59375, 1.0, 1.0, 0.59375, 0.6015625, 0.59375, 0.59375, 1.0, 1.0, 0.59375, 0.6328125, 1.0, 1.0, 0.59375, 1.0, 0.59375, 0.6015625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.59375, 0.59375, 1.0, 0.59375, 1.0, 0.59375, 1.0, 1.0, 1.0, 0.6015625, 1.0, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.6015625, 0.59375, 0.59375, 0.6015625, 1.0, 1.0, 0.59375, 1.0, 1.0, 0.6015625, 0.6015625, 1.0, 1.0, 0.59375, 0.6015625, 0.59375, 0.6015625, 1.0, 1.0, 1.0, 0.6015625, 0.59375, 0.6015625, 1.0, 0.59375, 1.0, 0.609375, 0.59375, 0.59375, 1.0, 0.59375, 1.0, 0.6015625, 1.0, 0.609375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 1.0, 0.59375, 0.6015625, 1.0, 1.0, 0.59375, 0.59375, 1.0, 1.0, 0.59375, 0.59375, 1.0, 1.0, 0.59375, 1.0, 1.0, 1.0, 1.0, 0.59375, 0.6015625, 1.0, 1.0, 0.6015625, 0.59375, 0.59375, 0.59375, 1.0, 0.59375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.59375, 1.0, 1.0, 0.6015625, 1.0, 0.6015625, 1.0, 1.0, 0.59375, 0.59375, 1.0, 0.6953125, 0.6015625, 0.6015625, 0.59375, 0.6015625, 1.0, 0.59375, 0.6015625, 0.59375, 0.6015625, 0.6015625, 0.59375, 0.59375, 1.0, 1.0, 0.59375, 1.0, 0.59375, 0.59375, 1.0, 1.0, 1.0, 0.59375, 0.6015625, 0.6015625, 0.640625, 0.6015625, 1.0, 1.0, 0.6015625, 0.59375, 0.59375, 1.0, 0.59375, 1.0, 1.0, 1.0, 1.0, 0.59375, 0.59375, 0.59375, 0.59375, 1.0, 1.0, 0.59375, 0.6015625, 1.0, 0.6015625, 1.0, 1.0, 0.609375, 0.59375, 0.59375, 1.0, 1.0, 0.59375, 0.59375, 1.0, 0.59375, 1.0, 0.59375, 1.0, 0.6015625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.59375, 1.0, 1.0, 0.59375, 1.0, 0.59375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.59375, 0.6015625, 0.6015625, 1.0, 1.0, 1.0, 1.0, 0.59375, 0.59375, 1.0, 0.59375, 1.0, 0.59375, 1.0, 0.59375, 0.59375, 0.6015625, 0.59375, 0.59375, 1.0, 1.0, 0.6015625, 0.59375, 0.6015625, 0.59375, 1.0, 1.0, 1.0, 1.0, 0.59375, 1.0, 1.0, 0.59375, 0.6015625, 0.59375, 0.59375, 1.0, 0.609375, 0.6015625, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 1.0, 1.0, 0.6015625, 1.0, 0.59375, 0.609375, 0.59375, 0.59375, 0.59375, 1.0, 0.59375, 0.59375, 1.0, 0.6015625, 0.59375, 1.0, 1.0, 1.0, 0.6015625, 1.0, 1.0, 1.0, 1.0, 0.59375, 1.0, 1.0, 0.59375, 0.59375, 0.6015625, 1.0, 1.0, 1.0, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 1.0, 0.59375, 1.0, 1.0, 1.0, 0.59375, 1.0, 0.6015625, 1.0, 1.0, 0.59375, 0.59375, 0.6015625, 1.0, 0.59375, 0.59375, 0.59375, 0.6015625, 1.0, 1.0, 0.59375, 0.6015625, 0.59375, 0.59375, 1.0, 1.0, 1.0, 1.0, 0.59375, 1.0, 1.0, 1.0, 0.59375, 1.0, 0.59375, 0.59375, 0.59375, 1.0, 0.6015625, 0.59375, 0.59375, 1.0, 0.59375, 0.609375, 1.0, 0.59375, 1.0, 1.0, 0.59375, 0.6015625, 0.59375, 0.59375, 0.6015625, 1.0, 1.0, 0.59375, 1.0, 0.609375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6015625, 0.6015625, 1.0, 0.59375, 0.59375, 0.609375, 0.59375, 1.0, 0.59375, 1.0, 1.0, 1.0, 0.59375, 1.0, 0.6015625, 0.6015625, 1.0, 0.6015625, 1.0, 0.59375, 0.59375, 1.0, 1.0, 1.0, 0.6015625, 0.59375, 1.0, 0.609375, 0.59375, 1.0, 0.6015625, 0.59375, 1.0, 0.59375, 1.0, 1.0, 1.0, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.6015625, 1.0, 0.6015625, 1.0, 0.609375, 0.59375, 0.6015625, 1.0, 1.0, 0.59375, 0.609375]

 sparsity of   [1.0, 0.07421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1484375, 1.0, 0.0703125, 1.0, 0.0625, 1.0, 1.0, 0.07421875, 1.0, 1.0, 1.0, 1.0, 0.12890625, 0.0703125, 1.0, 0.09765625, 1.0, 1.0, 0.08203125, 1.0, 0.0703125, 0.05859375, 1.0, 1.0, 1.0, 0.06640625, 0.09765625, 0.06640625, 0.06640625, 0.0625, 1.0, 1.0, 1.0, 0.05859375, 1.0, 1.0, 0.0703125, 0.0625, 1.0, 0.1171875, 1.0, 1.0, 0.0703125, 1.0, 1.0, 0.078125, 0.0625, 0.06640625, 1.0, 1.0, 0.06640625, 0.109375, 0.06640625, 1.0, 0.25390625, 1.0, 1.0, 1.0, 0.06640625, 0.15625, 1.0, 1.0, 0.08984375, 0.0625, 0.0703125, 1.0, 0.0703125, 1.0, 1.0, 1.0, 0.07421875, 1.0, 0.0703125, 0.0625, 0.1171875, 1.0, 0.12109375, 0.1640625, 1.0, 1.0, 0.078125, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.05859375, 0.0703125, 0.0625, 0.0703125, 0.0703125, 0.12109375, 0.171875, 1.0, 1.0, 0.0703125, 0.06640625, 0.08203125, 0.203125, 1.0, 1.0, 0.07421875, 1.0, 1.0, 1.0, 0.06640625, 1.0, 0.13671875, 0.05859375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0703125, 0.10546875, 1.0, 0.07421875, 1.0, 0.05859375, 1.0, 1.0, 1.0, 0.08203125, 1.0, 0.07421875, 0.0703125, 0.0625, 0.0625, 0.0703125, 0.0625, 0.0625, 0.0625, 0.13671875, 0.08203125, 1.0, 1.0, 0.109375, 1.0, 1.0, 0.10546875, 0.05859375, 1.0, 0.09765625, 0.109375, 0.06640625, 0.09375, 1.0, 1.0, 1.0, 1.0, 0.05859375, 0.078125, 0.0625, 1.0, 0.0625, 1.0, 0.0703125, 0.0625, 0.09375, 1.0, 0.0703125, 1.0, 0.0625, 1.0, 0.1875, 0.15234375, 0.06640625, 0.0703125, 0.0625, 0.0703125, 1.0, 1.0, 0.06640625, 1.0, 1.0, 0.078125, 0.0703125, 1.0, 1.0, 0.05859375, 0.0625, 0.07421875, 1.0, 0.18359375, 1.0, 0.13671875, 1.0, 1.0, 0.08203125, 0.078125, 1.0, 1.0, 0.0625, 0.07421875, 0.14453125, 0.11328125, 1.0, 0.0703125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.078125, 1.0, 1.0, 0.06640625, 1.0, 0.140625, 1.0, 1.0, 0.05859375, 0.078125, 1.0, 0.1015625, 0.08203125, 0.11328125, 0.06640625, 0.18359375, 1.0, 1.0, 0.0625, 0.08984375, 0.0625, 0.08203125, 0.0625, 0.078125, 1.0, 1.0, 0.10546875, 0.08984375, 0.07421875, 0.0625, 1.0, 1.0, 1.0, 0.0703125, 0.06640625, 0.06640625, 0.0703125, 0.0703125, 1.0, 1.0, 0.06640625, 0.1015625, 0.06640625, 1.0, 0.0546875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08984375, 0.0625, 0.07421875, 1.0, 1.0, 0.19921875, 0.06640625, 1.0, 1.0, 1.0, 1.0, 0.06640625, 0.06640625, 0.0625, 1.0, 1.0, 0.08984375, 0.1171875, 1.0, 0.07421875, 1.0, 0.08203125, 1.0, 0.10546875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.05859375, 1.0, 1.0, 1.0, 1.0, 0.13671875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.125, 1.0, 1.0, 0.06640625, 0.0703125, 0.09375, 1.0, 1.0, 1.0, 1.0, 0.0625, 0.078125, 1.0, 0.078125, 1.0, 0.0625, 1.0, 0.0859375, 0.06640625, 0.07421875, 0.09375, 0.0859375, 1.0, 1.0, 0.55078125, 0.0859375, 0.06640625, 0.0546875, 1.0, 1.0, 1.0, 1.0, 0.078125, 1.0, 1.0, 0.0625, 0.06640625, 0.0546875, 0.125, 1.0, 0.13671875, 0.05859375, 0.18359375, 0.1796875, 0.0703125, 0.0625, 0.17578125, 0.0703125, 0.1484375, 0.06640625, 0.0703125, 0.07421875, 1.0, 1.0, 0.0625, 1.0, 0.14453125, 0.078125, 0.0625, 0.140625, 0.08984375, 1.0, 0.06640625, 0.06640625, 1.0, 0.06640625, 0.0703125, 1.0, 1.0, 1.0, 0.1328125, 1.0, 1.0, 0.0859375, 1.0, 0.0703125, 1.0, 1.0, 0.07421875, 0.0703125, 0.06640625, 1.0, 0.18359375, 1.0, 0.0703125, 0.15234375, 0.0625, 0.06640625, 0.07421875, 0.07421875, 0.1796875, 1.0, 0.12109375, 1.0, 1.0, 1.0, 0.05859375, 1.0, 0.06640625, 1.0, 1.0, 0.0625, 0.08203125, 0.0703125, 1.0, 0.0703125, 0.07421875, 0.08203125, 0.078125, 0.06640625, 1.0, 0.12890625, 0.05859375, 0.0703125, 0.0703125, 1.0, 1.0, 1.0, 1.0, 0.05859375, 1.0, 1.0, 1.0, 0.0625, 1.0, 0.078125, 0.1171875, 0.06640625, 1.0, 1.0, 0.0625, 0.07421875, 1.0, 0.125, 0.07421875, 1.0, 0.078125, 0.1171875, 1.0, 0.0625, 0.1015625, 0.05859375, 0.09375, 0.08203125, 1.0, 1.0, 0.0625, 1.0, 0.09375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0546875, 1.0, 1.0, 0.0625, 0.0703125, 0.0703125, 0.1484375, 1.0, 0.09375, 1.0, 1.0, 1.0, 0.07421875, 1.0, 0.08203125, 0.078125, 1.0, 0.0859375, 1.0, 0.0703125, 0.1328125, 1.0, 1.0, 1.0, 0.0703125, 0.1640625, 1.0, 0.05859375, 0.1875, 1.0, 0.05859375, 0.15234375, 1.0, 0.11328125, 1.0, 0.10546875, 1.0, 0.109375, 0.1875, 0.07421875, 0.109375, 0.0625, 0.09765625, 1.0, 0.078125, 1.0, 0.0625, 0.078125, 0.05859375, 1.0, 1.0, 0.07421875, 0.07421875]

 sparsity of   [1.0, 0.43359375, 1.0, 0.431640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.43359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.435546875, 1.0, 1.0, 1.0, 0.419921875, 1.0, 1.0, 1.0, 0.43359375, 0.43359375, 1.0, 1.0, 0.4375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.44140625, 1.0, 1.0, 1.0, 0.4375, 0.43359375, 0.421875, 1.0, 1.0, 1.0, 0.43359375, 1.0, 1.0, 1.0, 1.0, 0.427734375, 1.0, 0.439453125, 1.0, 0.43359375, 1.0, 0.4453125, 1.0, 1.0, 0.48828125, 0.4296875, 1.0, 1.0, 0.42578125, 0.4296875, 1.0, 0.4296875, 1.0, 1.0, 1.0, 0.443359375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4296875, 0.43359375, 0.42578125, 1.0, 0.43359375, 1.0, 1.0, 0.419921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4296875, 1.0, 1.0, 1.0, 0.435546875, 1.0, 1.0, 1.0, 0.42578125, 1.0, 0.4296875, 1.0, 0.44140625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.48046875, 1.0, 1.0, 0.423828125, 1.0, 1.0, 0.431640625, 1.0, 1.0, 1.0, 0.4296875]

 sparsity of   [0.7065972089767456, 1.0, 0.7092013955116272, 0.7144097089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7083333134651184, 0.7083333134651184, 1.0, 1.0, 1.0, 1.0, 0.7109375, 0.710069477558136, 0.7126736044883728, 0.710069477558136, 1.0, 1.0, 0.710069477558136, 1.0, 0.7769097089767456, 1.0, 1.0, 0.7664930820465088, 0.7734375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7144097089767456, 1.0, 0.7057291865348816, 0.7144097089767456, 0.7482638955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7473958134651184, 0.7109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.710069477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7083333134651184, 0.7074652910232544, 1.0, 0.7161458134651184, 0.7109375, 1.0, 0.7083333134651184, 1.0, 1.0, 1.0, 1.0, 0.7543402910232544, 0.7083333134651184, 1.0, 1.0, 0.710069477558136, 1.0, 0.7039930820465088, 1.0, 0.7109375, 1.0, 1.0, 1.0, 0.7057291865348816, 1.0, 0.7092013955116272, 1.0, 0.7170138955116272, 0.7951388955116272, 1.0, 1.0, 0.7048611044883728, 1.0, 0.7083333134651184, 1.0, 0.7074652910232544, 0.7126736044883728, 1.0, 1.0, 0.7135416865348816, 1.0, 1.0, 0.7743055820465088, 1.0, 1.0, 1.0, 1.0, 0.7065972089767456, 0.7083333134651184, 1.0, 0.7734375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 0.640625, 1.0, 0.640625, 0.6328125, 1.0, 1.0, 0.6328125, 1.0, 1.0, 1.0, 0.640625, 1.0, 0.640625, 0.640625, 0.6484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.640625, 0.6484375, 0.640625, 0.65625, 1.0, 1.0, 0.65625, 1.0, 1.0, 0.640625, 1.0, 1.0, 1.0, 0.640625, 0.640625, 0.6484375, 0.6484375, 0.640625, 1.0, 1.0, 0.640625, 0.6484375, 0.6484375, 1.0, 0.640625, 0.640625, 1.0, 0.640625, 0.6484375, 1.0, 1.0, 1.0, 1.0, 0.6484375, 0.640625, 1.0, 1.0, 1.0, 0.640625, 0.640625, 1.0, 1.0, 0.640625, 1.0, 0.640625, 0.640625, 0.640625, 0.640625, 1.0, 0.6328125, 0.640625, 0.6640625, 0.640625, 0.640625, 0.640625, 0.6484375, 0.6328125, 1.0, 0.6484375, 1.0, 0.65625, 0.6484375, 0.6328125, 1.0, 0.640625, 1.0, 0.640625, 1.0, 1.0, 0.640625, 1.0, 0.6484375, 0.640625, 1.0, 1.0, 0.6484375, 0.640625, 0.6484375, 0.640625, 1.0, 1.0, 1.0, 1.0, 0.640625, 1.0, 0.6484375, 0.640625, 1.0, 1.0, 0.640625, 1.0, 1.0, 1.0, 0.640625, 1.0, 0.640625, 0.6484375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.640625, 0.640625, 1.0, 0.640625, 0.640625, 0.6328125, 1.0, 1.0, 1.0, 0.640625, 1.0, 0.6484375, 0.640625, 0.6484375, 0.640625, 0.6484375, 0.640625, 0.640625, 0.640625, 0.640625, 0.640625, 1.0, 1.0, 0.671875, 1.0, 1.0, 0.640625, 0.640625, 0.640625, 1.0, 0.640625, 0.640625, 0.6328125, 1.0, 1.0, 1.0, 0.640625, 0.6328125, 0.640625, 0.640625, 0.640625, 0.6484375, 1.0, 0.65625, 0.6328125, 0.640625, 1.0, 1.0, 1.0, 0.6484375, 1.0, 0.640625, 0.640625, 0.6484375, 0.640625, 1.0, 0.6484375, 0.640625, 1.0, 0.6484375, 1.0, 0.6328125, 0.6484375, 1.0, 1.0, 1.0, 0.640625, 0.65625, 1.0, 1.0, 0.65625, 1.0, 1.0, 1.0, 1.0, 0.65625, 0.6484375, 1.0, 1.0, 0.640625, 0.640625, 0.640625, 0.6640625, 1.0, 0.640625, 0.6328125, 1.0, 1.0, 1.0, 1.0, 0.6328125, 1.0, 1.0, 0.640625, 1.0, 0.6484375, 1.0, 0.6328125, 1.0, 0.640625, 1.0, 1.0, 0.6484375, 1.0, 0.640625, 0.6484375, 0.6328125, 1.0, 1.0, 0.640625, 0.6484375, 0.6796875, 0.640625, 1.0, 1.0, 1.0, 0.640625, 1.0, 0.640625, 0.640625, 1.0, 1.0, 1.0, 0.640625, 1.0, 0.640625, 0.640625, 1.0, 1.0, 0.640625, 0.640625, 0.6484375, 0.640625, 1.0, 0.640625, 1.0, 1.0, 1.0, 0.6484375, 1.0, 0.640625, 1.0, 0.640625, 1.0, 1.0, 0.6328125, 0.640625, 1.0, 0.6484375, 1.0, 1.0, 0.65625, 0.6640625, 0.6484375, 1.0, 1.0, 0.640625, 0.640625, 1.0, 1.0, 0.640625, 1.0, 0.6484375, 0.640625, 1.0, 1.0, 1.0, 1.0, 0.640625, 0.640625, 0.640625, 1.0, 1.0, 0.6328125, 0.640625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.640625, 1.0, 1.0, 0.640625, 0.6328125, 0.65625, 0.640625, 1.0, 1.0, 0.640625, 1.0, 0.640625, 1.0, 0.640625, 0.640625, 0.640625, 1.0, 0.65625, 0.6484375, 0.640625, 0.640625, 0.640625, 1.0, 1.0, 1.0, 0.640625, 0.640625, 0.640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.65625, 0.65625, 0.640625, 0.640625, 0.6328125, 0.640625, 0.640625, 0.640625, 0.640625, 0.6328125, 0.6484375, 1.0, 0.6484375, 0.6484375, 0.640625, 0.640625, 0.6484375, 1.0, 1.0, 0.640625, 1.0, 0.6484375, 0.6640625, 0.640625, 0.6328125, 0.640625, 1.0, 0.6484375, 0.640625, 1.0, 1.0, 0.640625, 0.6484375, 1.0, 0.640625, 0.640625, 1.0, 1.0, 0.640625, 1.0, 0.6484375, 1.0, 1.0, 0.6484375, 0.640625, 0.640625, 1.0, 1.0, 1.0, 0.640625, 0.6484375, 0.640625, 1.0, 0.6484375, 0.640625, 0.640625, 1.0, 0.640625, 1.0, 1.0, 1.0, 0.6484375, 0.640625, 0.6484375, 1.0, 1.0, 0.640625, 0.6484375, 0.640625, 1.0, 1.0, 0.640625, 0.6328125, 0.640625, 1.0, 1.0, 1.0, 0.640625, 0.640625, 0.640625, 0.640625, 1.0, 1.0, 0.640625, 0.6484375, 1.0, 1.0, 0.6484375, 0.6484375, 1.0, 1.0, 0.640625, 0.6484375, 1.0, 0.640625, 0.640625, 0.6484375, 1.0, 1.0, 0.640625, 1.0, 0.6484375, 1.0, 1.0, 0.65625, 0.6484375, 0.65625, 0.640625, 1.0, 1.0, 0.6484375, 0.640625, 1.0, 0.640625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.65625, 0.640625, 0.640625, 1.0, 0.640625, 0.640625, 0.6328125, 1.0, 0.6484375, 1.0, 1.0, 1.0, 0.640625, 1.0, 0.6484375, 0.640625, 1.0, 0.6328125, 1.0, 0.640625, 0.65625, 1.0, 0.6484375, 1.0, 0.6328125, 1.0, 0.6484375, 0.640625, 1.0, 1.0, 1.0, 0.640625, 0.640625, 0.6484375, 1.0, 0.640625, 0.6328125, 0.640625, 0.640625, 0.640625, 0.6640625, 0.65625, 0.640625, 1.0, 0.640625, 1.0, 0.640625, 0.640625, 0.6328125, 1.0, 0.640625, 0.640625, 0.640625]

 sparsity of   [0.33984375, 0.337890625, 0.3359375, 0.3359375, 0.333984375, 0.333984375, 0.328125, 1.0, 0.333984375, 0.328125, 1.0, 0.33203125, 1.0, 0.328125, 1.0, 0.330078125, 0.3359375, 0.337890625, 1.0, 0.33984375, 1.0, 1.0, 0.33203125, 1.0, 0.333984375, 0.328125, 0.330078125, 0.33984375, 1.0, 1.0, 0.337890625, 0.337890625, 1.0, 1.0, 0.33203125, 0.330078125, 1.0, 0.328125, 1.0, 1.0, 1.0, 1.0, 0.32421875, 0.330078125, 1.0, 1.0, 1.0, 0.33984375, 1.0, 0.337890625, 0.33984375, 0.337890625, 0.33203125, 1.0, 0.333984375, 0.328125, 0.32421875, 0.330078125, 0.330078125, 0.3359375, 1.0, 0.333984375, 1.0, 0.33984375, 1.0, 1.0, 0.34765625, 1.0, 0.32421875, 1.0, 0.33203125, 1.0, 0.337890625, 0.353515625, 0.375, 1.0, 1.0, 0.330078125, 1.0, 0.337890625, 0.333984375, 1.0, 0.345703125, 1.0, 0.33984375, 0.326171875, 1.0, 0.328125, 1.0, 1.0, 0.40234375, 0.33984375, 0.33203125, 0.3359375, 1.0, 0.3359375, 0.33984375, 0.33203125, 1.0, 0.33984375, 1.0, 0.333984375, 0.33203125, 0.33203125, 0.330078125, 1.0, 1.0, 1.0, 0.330078125, 0.330078125, 1.0, 0.337890625, 0.32421875, 1.0, 0.330078125, 1.0, 0.345703125, 0.607421875, 0.330078125, 0.3359375, 0.330078125, 1.0, 0.337890625, 0.33984375, 0.328125, 1.0, 1.0, 0.33203125]

 sparsity of   [1.0, 0.3715277910232544, 0.3663194477558136, 1.0, 1.0, 1.0, 0.3715277910232544, 0.3680555522441864, 0.3689236044883728, 1.0, 1.0, 1.0, 0.3715277910232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3602430522441864, 0.3663194477558136, 1.0, 1.0, 0.3602430522441864, 1.0, 1.0, 0.3663194477558136, 0.3741319477558136, 1.0, 1.0, 1.0, 1.0, 0.3585069477558136, 0.3767361044883728, 1.0, 1.0, 1.0, 1.0, 0.3663194477558136, 0.362847238779068, 1.0, 1.0, 0.3611111044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 0.362847238779068, 0.3619791567325592, 0.3715277910232544, 0.3671875, 0.3611111044883728, 0.362847238779068, 0.3689236044883728, 0.3602430522441864, 1.0, 0.362847238779068, 1.0, 0.3645833432674408, 1.0, 0.3576388955116272, 0.3689236044883728, 1.0, 0.3585069477558136, 0.3619791567325592, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3697916567325592, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3645833432674408, 1.0, 1.0, 0.3619791567325592, 1.0, 0.3663194477558136, 0.3732638955116272, 1.0, 0.3611111044883728, 0.3680555522441864, 1.0, 1.0, 0.3611111044883728, 1.0, 1.0, 0.3619791567325592, 0.3671875, 0.3645833432674408, 0.378472238779068, 0.3671875, 1.0, 1.0, 0.3637152910232544, 1.0, 0.370659738779068, 0.3637152910232544, 1.0, 0.3723958432674408, 1.0, 1.0, 1.0, 0.375, 0.3671875, 1.0, 0.3602430522441864, 1.0, 1.0, 1.0, 1.0, 0.3758680522441864, 1.0, 0.3723958432674408, 1.0, 1.0, 0.3645833432674408, 1.0, 0.3654513955116272, 1.0, 0.362847238779068]

 sparsity of   [0.5625, 0.5703125, 1.0, 0.578125, 0.578125, 1.0, 0.578125, 0.5703125, 0.5546875, 0.5625, 1.0, 0.5859375, 0.5703125, 0.5625, 0.5625, 0.5625, 0.578125, 1.0, 0.5546875, 0.5703125, 1.0, 1.0, 0.5625, 0.5625, 0.5625, 0.5703125, 0.5703125, 1.0, 1.0, 0.578125, 1.0, 0.5625, 0.578125, 1.0, 1.0, 0.5546875, 0.5625, 0.5703125, 0.546875, 0.5703125, 0.5703125, 0.5625, 1.0, 0.5703125, 0.546875, 1.0, 0.5703125, 0.5625, 0.5703125, 1.0, 0.578125, 0.5859375, 1.0, 0.5625, 1.0, 1.0, 0.5703125, 0.5703125, 0.5703125, 0.5546875, 1.0, 0.5625, 0.5703125, 0.5546875, 0.5546875, 0.5703125, 0.5546875, 1.0, 1.0, 0.5703125, 0.5625, 1.0, 0.5703125, 0.5625, 0.5625, 0.5625, 0.5703125, 0.5703125, 1.0, 0.5703125, 0.5625, 0.5703125, 0.5625, 0.5625, 0.5546875, 0.5703125, 0.578125, 0.5625, 0.5625, 0.5703125, 1.0, 0.5703125, 1.0, 0.5546875, 0.5625, 1.0, 0.5625, 0.5625, 0.5546875, 0.5546875, 0.5703125, 0.5703125, 1.0, 1.0, 0.5546875, 0.5703125, 0.5703125, 0.546875, 0.5625, 0.578125, 0.5703125, 0.5703125, 0.5625, 0.5546875, 1.0, 0.5625, 0.5703125, 0.5703125, 0.5703125, 0.546875, 1.0, 0.5546875, 0.5703125, 1.0, 1.0, 0.5703125, 0.578125, 0.546875, 1.0, 1.0, 0.5390625, 0.546875, 0.5625, 1.0, 0.5703125, 1.0, 0.5703125, 0.578125, 0.5625, 0.5703125, 0.5625, 0.5625, 0.5703125, 0.5625, 0.578125, 0.5703125, 1.0, 1.0, 0.578125, 1.0, 1.0, 0.5625, 0.5625, 1.0, 1.0, 0.5625, 0.5546875, 0.5703125, 1.0, 0.5546875, 1.0, 0.5703125, 0.5625, 0.578125, 0.5703125, 1.0, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.5625, 0.5546875, 0.5625, 1.0, 0.5703125, 1.0, 1.0, 0.578125, 0.5546875, 0.5625, 0.5625, 0.5703125, 0.578125, 0.5703125, 0.546875, 0.5546875, 0.5703125, 0.5703125, 0.5625, 1.0, 1.0, 0.5703125, 0.5703125, 0.5703125, 0.5546875, 0.5546875, 0.5625, 1.0, 1.0, 1.0, 0.5625, 0.546875, 0.5703125, 0.5546875, 0.5625, 0.578125, 0.5546875, 0.5703125, 0.5546875, 0.5546875, 0.5625, 0.5546875, 1.0, 0.5625, 0.5703125, 0.5625, 1.0, 1.0, 0.5625, 0.5625, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.578125, 1.0, 0.5625, 0.5546875, 1.0, 0.5625, 0.5703125, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.578125, 0.5703125, 0.5703125, 0.59375, 0.578125, 0.5546875, 1.0, 0.5625, 0.578125, 0.5625, 0.5546875, 0.5703125, 0.5703125, 0.5625, 0.5546875, 1.0, 0.5625, 0.546875, 0.5625, 0.5546875, 0.546875, 1.0, 1.0, 1.0, 0.5625, 0.5625, 0.5703125, 0.578125, 0.5703125, 1.0, 0.5625, 0.5625, 0.5703125, 0.5546875, 0.578125, 0.5703125, 1.0, 0.5546875, 0.5625, 0.5625, 0.5703125, 1.0, 0.5625, 0.578125, 0.5625, 0.5703125, 0.5703125, 0.5625, 1.0, 0.5703125, 1.0, 1.0, 0.5625, 1.0, 0.5546875, 0.546875, 0.5625, 0.71875, 0.5625, 0.5703125, 0.578125, 1.0, 1.0, 0.5625, 1.0, 1.0, 1.0, 0.5703125, 1.0, 0.5625, 0.5625, 0.5625, 0.578125, 1.0, 0.5625, 1.0, 0.5703125, 0.5703125, 0.5625, 0.59375, 0.59375, 0.5703125, 0.5625, 0.5625, 0.5625, 0.5703125, 0.5703125, 0.5703125, 1.0, 0.5625, 0.5625, 0.5625, 0.5703125, 0.5703125, 0.5546875, 1.0, 1.0, 0.5703125, 0.5703125, 0.578125, 0.5703125, 0.5625, 0.5703125, 0.578125, 0.5625, 0.5703125, 0.5625, 0.5546875, 0.5625, 0.5546875, 0.578125, 0.5546875, 0.5703125, 0.5625, 0.5703125, 0.5625, 0.5546875, 0.5703125, 0.5546875, 1.0, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.5625, 0.5703125, 0.5703125, 1.0, 0.5546875, 0.5625, 1.0, 0.5703125, 0.5703125, 1.0, 1.0, 0.5546875, 0.5546875, 0.5625, 0.5546875, 1.0, 0.5625, 0.578125, 1.0, 1.0, 0.5625, 0.5625, 0.5546875, 0.5703125, 1.0, 0.5546875, 0.5625, 0.578125, 0.5546875, 0.5625, 0.5625, 0.5546875, 0.5703125, 1.0, 0.5703125, 1.0, 1.0, 0.5546875, 0.5625, 0.5703125, 0.5703125, 1.0, 0.5546875, 0.5625, 0.5546875, 0.5625, 0.5546875, 0.5703125, 0.5546875, 0.5625, 0.5625, 0.5546875, 0.5703125, 0.578125, 0.5625, 0.5703125, 0.5703125, 0.5703125, 1.0, 0.5703125, 0.578125, 0.5703125, 1.0, 1.0, 0.5625, 0.5703125, 1.0, 1.0, 0.5625, 0.5625, 1.0, 1.0, 0.5625, 0.5703125, 0.5546875, 1.0, 0.5703125, 1.0, 0.5625, 1.0, 0.5625, 0.5546875, 0.5703125, 0.578125, 0.5703125, 0.5625, 0.546875, 0.578125, 0.5625, 0.5703125, 0.5703125, 1.0, 1.0, 0.5703125, 0.5546875, 0.5546875, 0.578125, 0.5546875, 0.546875, 0.5703125, 0.5625, 0.5625, 0.578125, 0.5546875, 0.5625, 1.0, 1.0, 0.5703125, 0.5625, 1.0, 1.0, 0.5703125, 0.5703125, 0.5625, 0.5546875, 0.5546875, 0.5625, 0.546875, 0.5703125, 0.546875, 0.5625, 0.5703125, 1.0, 0.5625, 0.5625, 0.5625, 0.609375, 0.5703125, 0.5703125, 0.5625, 0.5703125, 0.578125, 0.5625, 0.5703125, 0.578125, 0.5625, 0.5703125, 0.5703125, 0.5546875, 0.5703125, 0.5625, 1.0, 0.5546875, 0.5625, 0.578125, 1.0, 0.5625, 0.5703125, 0.5625]

 sparsity of   [1.0, 0.15234375, 1.0, 0.166015625, 0.1640625, 0.162109375, 0.15625, 1.0, 0.15234375, 0.16015625, 0.15234375, 1.0, 0.158203125, 0.162109375, 1.0, 1.0, 0.166015625, 0.162109375, 1.0, 1.0, 1.0, 0.15234375, 0.162109375, 1.0, 0.15625, 1.0, 0.15625, 0.15625, 0.15625, 0.166015625, 0.15625, 0.158203125, 1.0, 0.150390625, 0.162109375, 1.0, 0.158203125, 1.0, 1.0, 0.16015625, 0.158203125, 1.0, 1.0, 0.16015625, 1.0, 1.0, 0.15625, 0.166015625, 0.16015625, 1.0, 0.154296875, 1.0, 1.0, 0.1640625, 0.15625, 0.15625, 1.0, 1.0, 0.162109375, 0.16796875, 0.158203125, 0.16015625, 0.158203125, 1.0, 0.162109375, 1.0, 0.158203125, 0.154296875, 0.158203125, 1.0, 0.15625, 0.15625, 1.0, 1.0, 0.16796875, 1.0, 0.158203125, 1.0, 1.0, 0.16796875, 0.15625, 1.0, 1.0, 0.16015625, 0.171875, 0.16015625, 0.16015625, 0.154296875, 1.0, 0.154296875, 0.1640625, 0.166015625, 0.158203125, 1.0, 1.0, 0.15625, 0.169921875, 0.162109375, 0.177734375, 1.0, 0.16015625, 1.0, 0.158203125, 0.15625, 0.162109375, 0.154296875, 0.15625, 0.15625, 1.0, 1.0, 0.17578125, 0.158203125, 0.15234375, 0.158203125, 1.0, 0.1640625, 1.0, 1.0, 0.15234375, 0.162109375, 1.0, 1.0, 0.166015625, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 0.3923611044883728, 1.0, 1.0, 1.0, 0.3949652910232544, 0.3958333432674408, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3958333432674408, 0.394097238779068, 1.0, 1.0, 0.394097238779068, 1.0, 1.0, 1.0, 0.3932291567325592, 0.3967013955116272, 0.3923611044883728, 0.4001736044883728, 1.0, 1.0, 0.3975694477558136, 1.0, 0.394097238779068, 0.3932291567325592, 1.0, 0.394097238779068, 0.3923611044883728, 0.394097238779068, 1.0, 1.0, 1.0, 0.3984375, 1.0, 0.3932291567325592, 0.3914930522441864, 0.3984375, 1.0, 1.0, 1.0, 0.394097238779068, 0.394097238779068, 1.0, 1.0, 0.3888888955116272, 0.394097238779068, 0.3993055522441864, 1.0, 0.3949652910232544, 0.3958333432674408, 0.3897569477558136, 1.0, 0.3932291567325592, 1.0, 0.3975694477558136, 0.394097238779068, 0.3932291567325592, 1.0, 1.0, 0.3932291567325592, 1.0, 0.3967013955116272, 0.3975694477558136, 1.0, 0.3949652910232544, 1.0, 1.0, 1.0, 1.0, 0.3932291567325592, 0.3958333432674408, 0.3949652910232544, 1.0, 1.0, 0.3949652910232544, 0.4053819477558136, 0.3932291567325592, 1.0, 0.390625, 1.0, 0.3914930522441864, 1.0, 1.0, 1.0, 0.3932291567325592, 1.0, 0.3923611044883728, 0.3949652910232544, 1.0, 1.0, 0.3984375, 1.0, 0.3932291567325592, 0.3993055522441864, 1.0, 1.0, 0.3984375, 0.3932291567325592, 0.3967013955116272, 1.0, 0.3949652910232544, 0.3967013955116272, 1.0, 0.3967013955116272, 1.0, 1.0, 0.3967013955116272, 0.3975694477558136, 1.0, 1.0, 0.3967013955116272, 1.0, 1.0, 0.3958333432674408, 0.394097238779068, 0.3967013955116272, 0.3949652910232544, 1.0, 1.0, 1.0]

 sparsity of   [0.5078125, 1.0, 0.5, 0.5078125, 0.5078125, 1.0, 0.515625, 0.4921875, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.5, 0.5078125, 1.0, 0.5, 1.0, 1.0, 0.5, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625, 0.5078125, 0.5, 0.4921875, 1.0, 0.5, 0.5078125, 1.0, 1.0, 1.0, 0.5234375, 0.5, 0.5, 0.5078125, 0.5078125, 0.4921875, 1.0, 0.5078125, 0.5, 0.515625, 0.5, 0.5078125, 0.5234375, 1.0, 0.5, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5234375, 0.5078125, 0.5078125, 0.5, 0.515625, 0.4921875, 0.5, 0.5, 0.5078125, 0.5, 0.5, 0.5078125, 0.5078125, 0.5, 0.5, 0.5078125, 0.5078125, 0.5078125, 0.5, 0.5234375, 0.5078125, 0.5078125, 0.5, 0.5234375, 0.5, 0.5, 0.5078125, 1.0, 0.5078125, 0.5, 0.5078125, 0.5, 0.5, 0.5078125, 0.5, 0.515625, 0.515625, 1.0, 0.515625, 0.5, 0.5, 0.5078125, 0.4921875, 0.59375, 0.5078125, 1.0, 0.5078125, 0.4921875, 0.5, 0.515625, 0.5, 1.0, 0.4921875, 0.5, 0.515625, 0.5, 0.5, 0.5078125, 1.0, 0.515625, 0.5078125, 1.0, 0.5078125, 0.53125, 0.5078125, 0.4921875, 0.5078125, 0.5234375, 0.4921875, 0.5078125, 1.0, 0.5, 0.5078125, 0.5, 0.5, 0.5078125, 0.5, 0.5, 0.5078125, 0.5, 0.515625, 0.5078125, 0.5078125, 0.5078125, 0.515625, 0.5, 0.5078125, 0.5078125, 1.0, 0.5, 0.5, 0.5078125, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5078125, 0.5078125, 0.5390625, 0.4921875, 0.5078125, 0.5, 0.5, 0.5, 0.515625, 0.5078125, 0.5, 0.5, 0.5, 0.5234375, 0.5, 0.5, 0.5078125, 1.0, 0.5, 0.5, 0.5078125, 0.515625, 0.515625, 0.5078125, 0.5078125, 0.4921875, 0.5, 0.5078125, 0.5, 0.5234375, 0.5, 0.5, 0.5078125, 1.0, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.4921875, 0.5078125, 0.4921875, 0.5078125, 1.0, 0.5078125, 0.4921875, 0.515625, 0.4921875, 0.5078125, 0.5078125, 0.5, 0.515625, 0.5234375, 0.5078125, 0.5078125, 0.4921875, 0.5, 1.0, 0.5, 0.5, 0.5078125, 0.5, 0.5, 0.5, 0.4921875, 0.5, 1.0, 0.5078125, 0.5, 0.515625, 1.0, 0.5, 0.5078125, 0.5, 0.5, 0.5078125, 0.4921875, 1.0, 0.5, 0.5, 0.5078125, 0.515625, 0.5078125, 0.4921875, 1.0, 1.0, 0.5, 0.515625, 0.4921875, 0.5, 0.515625, 0.4921875, 0.5, 0.5078125, 0.5078125, 0.5078125, 0.53125, 0.5, 0.5, 0.5078125, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.5, 0.4921875, 0.5078125, 1.0, 0.5, 0.5078125, 0.4921875, 0.515625, 0.5078125, 0.5, 0.4921875, 0.5078125, 0.5078125, 0.5, 0.5078125, 0.5078125, 1.0, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 1.0, 0.5, 0.5, 1.0, 0.5078125, 0.5078125, 0.5078125, 0.5, 0.5078125, 0.5, 0.4921875, 0.5, 1.0, 0.4921875, 0.5, 0.5078125, 1.0, 1.0, 0.5078125, 0.5078125, 0.6171875, 0.4921875, 0.5, 0.5078125, 0.5078125, 1.0, 0.515625, 1.0, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.5, 0.5, 0.515625, 0.5078125, 0.5, 0.5, 0.5078125, 0.5, 0.5078125, 0.4921875, 0.5, 0.5078125, 0.515625, 0.5078125, 0.5078125, 0.515625, 0.5234375, 0.5078125, 0.4921875, 0.4921875, 0.5078125, 0.5078125, 0.5, 1.0, 0.5078125, 0.5078125, 1.0, 1.0, 0.5078125, 0.5, 0.5, 0.4921875, 0.5078125, 0.5, 0.5078125, 0.515625, 0.4921875, 0.5234375, 0.5078125, 0.5078125, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.4921875, 0.5, 0.5078125, 0.515625, 0.4921875, 0.5078125, 0.5, 0.5, 0.5, 0.5234375, 0.5078125, 0.515625, 0.515625, 0.5078125, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.515625, 0.5, 0.515625, 0.515625, 0.5, 0.4921875, 1.0, 0.5234375, 0.5078125, 0.5, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.5, 0.5078125, 1.0, 0.5078125, 1.0, 1.0, 0.5078125, 0.5234375, 0.5, 0.5078125, 0.5, 0.5, 0.4921875, 0.4921875, 0.5078125, 0.5, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.4921875, 1.0, 0.5078125, 0.5, 0.5078125, 0.5, 0.5, 0.515625, 1.0, 0.515625, 0.515625, 0.5, 1.0, 0.5, 0.5078125, 0.5, 0.4921875, 0.5, 0.515625, 0.4921875, 0.5078125, 0.5, 0.5, 0.5078125, 0.515625, 0.5, 0.5078125, 0.5078125, 1.0, 0.5078125, 0.515625, 0.4921875, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 1.0, 0.5078125, 0.5078125, 0.5078125, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5078125, 0.5, 0.5, 0.5078125, 0.5078125, 0.4921875, 0.5, 0.5078125, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 1.0, 0.5078125, 0.5, 0.5, 0.5234375, 0.5078125, 0.515625, 0.5078125, 0.5, 0.5, 0.5, 0.515625, 0.5, 0.5078125, 1.0, 0.515625, 0.5, 0.5078125, 0.5078125, 0.4921875, 0.5078125, 0.5, 0.5, 0.515625, 0.515625, 0.5078125, 0.5234375, 0.5078125, 0.5078125, 0.515625, 0.5078125, 0.5078125, 0.4921875, 0.5, 0.5078125, 1.0, 0.515625, 0.515625, 0.5]

 sparsity of   [0.056640625, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.06640625, 1.0, 0.05859375, 0.0625, 0.0625, 1.0, 0.05859375, 0.0625, 1.0, 0.056640625, 1.0, 0.0625, 1.0, 0.064453125, 1.0, 0.0546875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0546875, 1.0, 0.056640625, 0.056640625, 1.0, 0.0546875, 0.064453125, 0.0546875, 1.0, 0.05078125, 1.0, 0.0625, 0.060546875, 0.05859375, 1.0, 1.0, 0.056640625, 0.05859375, 1.0, 1.0, 0.05859375, 0.052734375, 0.05859375, 1.0, 1.0, 1.0, 0.060546875, 0.06640625, 0.05078125, 0.0625, 0.056640625, 0.056640625, 0.056640625, 0.0625, 1.0, 1.0, 1.0, 0.0546875, 0.056640625, 0.056640625, 1.0, 0.056640625, 0.05859375, 1.0, 0.056640625, 0.0546875, 0.0625, 0.0546875, 0.068359375, 1.0, 1.0, 0.05859375, 0.068359375, 0.056640625, 1.0, 1.0, 0.05859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.056640625, 0.056640625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.056640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.060546875, 1.0, 1.0, 0.05078125, 0.0546875, 1.0, 1.0, 1.0, 0.0546875, 0.05078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0546875, 0.080078125, 0.056640625, 1.0, 0.056640625, 0.05859375, 0.068359375, 0.05859375, 0.056640625, 1.0, 0.05859375, 0.052734375, 0.060546875, 0.0625, 0.0546875, 1.0, 0.0625, 1.0, 1.0, 1.0, 1.0, 0.05859375, 0.0546875, 1.0, 1.0, 1.0, 0.056640625, 0.0625, 0.064453125, 1.0, 0.056640625, 0.052734375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0546875, 1.0, 0.060546875, 0.056640625, 0.05859375, 0.05859375, 0.052734375, 0.052734375, 1.0, 0.05859375, 1.0, 1.0, 0.060546875, 1.0, 0.0546875, 0.056640625, 1.0, 0.05859375, 1.0, 0.05859375, 0.056640625, 1.0, 1.0, 0.0625, 1.0, 0.060546875, 1.0, 0.05859375, 0.060546875, 1.0, 1.0, 0.0546875, 1.0, 1.0, 0.060546875, 1.0, 0.064453125, 0.05078125, 0.05859375, 0.052734375, 0.060546875, 1.0, 0.0546875, 0.056640625, 0.056640625, 0.060546875, 1.0, 0.056640625, 0.05859375, 1.0, 1.0, 0.0625, 0.0546875, 1.0, 1.0, 1.0, 0.052734375, 1.0, 0.05859375, 1.0, 1.0, 0.052734375, 1.0, 1.0, 0.0546875, 0.05859375, 0.05859375, 0.05859375, 0.052734375, 0.05859375, 1.0, 0.056640625, 1.0, 1.0, 0.060546875, 1.0, 1.0, 1.0, 1.0, 0.064453125, 0.060546875, 0.05859375, 0.0625, 0.056640625, 0.056640625, 1.0, 0.05859375, 1.0, 0.05859375, 1.0, 0.060546875, 0.0625, 0.0546875, 0.0546875, 0.060546875, 1.0, 0.05859375, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4713541567325592, 1.0, 1.0, 1.0, 0.4713541567325592, 1.0, 1.0, 1.0, 0.4817708432674408, 1.0, 1.0, 1.0, 0.4713541567325592, 1.0, 1.0, 1.0, 0.4704861044883728, 1.0, 1.0, 1.0, 0.4743923544883728, 1.0, 1.0, 1.0, 0.47265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4704861044883728, 1.0, 1.0, 1.0, 0.4713541567325592, 0.4700520932674408, 0.4713541567325592, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4717881977558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.472222238779068, 1.0, 0.4713541567325592, 1.0, 0.4704861044883728, 0.472222238779068, 1.0, 0.4709201455116272, 1.0, 1.0, 0.4709201455116272, 1.0, 1.0, 1.0, 0.4735243022441864, 0.4717881977558136, 1.0, 1.0, 1.0, 0.468315988779068, 1.0, 1.0, 1.0, 0.4713541567325592, 0.4704861044883728, 1.0, 0.47265625, 1.0, 1.0, 0.472222238779068, 1.0, 1.0, 1.0, 0.4704861044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.472222238779068, 1.0, 1.0, 1.0, 1.0, 0.4717881977558136, 1.0, 1.0, 1.0, 1.0, 0.468315988779068, 0.47265625, 0.4691840410232544, 0.4696180522441864, 0.4700520932674408, 1.0, 1.0, 1.0, 0.4713541567325592, 0.4730902910232544, 0.4717881977558136, 0.472222238779068, 0.4717881977558136, 1.0, 1.0, 0.47265625, 1.0, 1.0, 1.0, 0.468315988779068, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4691840410232544, 1.0, 1.0, 0.4717881977558136, 1.0, 1.0, 0.4730902910232544, 0.4700520932674408, 1.0, 1.0, 1.0, 1.0, 0.47265625, 1.0, 1.0, 0.4730902910232544, 1.0, 0.4748263955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4713541567325592, 1.0, 0.4691840410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4696180522441864, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4709201455116272, 1.0, 0.4713541567325592, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.472222238779068, 1.0, 1.0, 0.4735243022441864, 0.4696180522441864, 1.0, 1.0, 1.0, 0.4713541567325592, 0.4709201455116272, 0.4709201455116272, 0.4713541567325592, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4713541567325592, 1.0, 1.0, 0.4717881977558136, 1.0, 0.4713541567325592, 1.0, 0.472222238779068, 1.0, 1.0, 1.0, 0.472222238779068, 1.0, 0.472222238779068, 1.0, 1.0, 1.0, 1.0, 0.4709201455116272, 1.0, 1.0, 1.0, 0.472222238779068, 1.0, 0.4691840410232544, 1.0, 0.4700520932674408, 1.0, 1.0, 0.472222238779068, 1.0, 0.4735243022441864, 1.0]

 sparsity of   [0.7265625, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 0.7265625, 0.7265625, 0.7421875, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.7265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 0.7265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.7265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 0.7265625, 0.7265625, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.7265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.7265625, 0.72265625, 1.0, 0.7265625, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.7265625, 1.0, 0.72265625, 1.0, 0.7265625, 1.0, 0.73046875, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.7265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.7265625, 1.0, 0.7265625, 0.7265625, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.7265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.7265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.73046875, 0.7265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 0.734375, 1.0, 1.0, 1.0, 1.0, 0.7265625, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.7265625, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.7265625, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.7265625, 0.72265625, 0.7265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.7265625, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.73046875, 0.7265625, 1.0, 0.7265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.7265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.7265625, 1.0, 0.7265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.7265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.7265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.7265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.7265625, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.73046875, 1.0, 0.7265625, 0.72265625, 1.0, 0.72265625, 0.7265625, 0.72265625, 1.0, 1.0, 0.7265625, 1.0, 0.734375, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.7265625, 1.0, 0.7265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 0.7265625, 0.72265625, 0.72265625, 0.72265625, 0.7265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 0.7265625, 0.734375, 0.7265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.7265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.7265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 0.73828125, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.7265625, 0.7265625, 1.0, 0.72265625, 0.73046875, 0.72265625, 0.7265625, 0.72265625, 1.0, 0.7265625, 0.72265625, 1.0, 0.7265625, 0.72265625, 0.7265625, 0.72265625, 0.72265625, 0.73046875, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.73046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.7265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 0.7265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 0.7265625, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 0.7265625, 0.734375, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.73046875, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.7265625, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.7265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 0.7265625, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.7265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.7265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.7265625, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.7421875, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.796875, 0.7265625, 0.72265625, 0.72265625, 0.72265625, 0.7265625, 0.72265625, 0.72265625, 0.72265625, 0.7265625, 0.72265625, 0.734375, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.7265625, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.7265625, 0.72265625, 1.0, 0.72265625, 1.0, 0.73046875, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.7265625, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.75, 1.0, 0.7265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.7265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.7265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.7265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.7265625, 0.72265625, 0.7265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.7265625, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 0.7265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.7265625, 0.72265625, 0.72265625, 1.0, 1.0, 0.7265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.7265625, 0.73046875, 0.72265625, 0.7265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.7265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.7265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.7265625, 0.72265625, 0.72265625, 0.7265625, 1.0, 1.0, 0.7265625, 0.72265625, 1.0, 1.0, 0.7265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.7265625, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.078125, 1.0, 0.064453125, 1.0, 0.076171875, 1.0, 0.06640625, 0.0703125, 1.0, 0.060546875, 1.0, 1.0, 1.0, 1.0, 0.072265625, 0.068359375, 0.11328125, 1.0, 0.080078125, 1.0, 0.0703125, 1.0, 1.0, 1.0, 1.0, 0.064453125, 1.0, 1.0, 0.072265625, 1.0, 0.064453125, 0.0703125, 1.0, 0.0703125, 0.0703125, 0.0625, 1.0, 1.0, 1.0, 1.0, 0.068359375, 0.0625, 0.0625, 1.0, 0.064453125, 0.0703125, 1.0, 0.0859375, 1.0, 0.064453125, 1.0, 0.072265625, 0.06640625, 1.0, 1.0, 0.080078125, 0.05859375, 1.0, 0.060546875, 1.0, 1.0, 0.064453125, 1.0, 0.06640625, 1.0, 0.078125, 0.06640625, 0.0703125, 0.0703125, 0.0703125, 0.0625, 1.0, 0.08203125, 1.0, 0.060546875, 0.12109375, 0.064453125, 1.0, 0.060546875, 1.0, 1.0, 1.0, 1.0, 0.05859375, 0.158203125, 1.0, 1.0, 0.068359375, 0.06640625, 1.0, 0.064453125, 1.0, 0.05859375, 1.0, 0.06640625, 0.228515625, 1.0, 1.0, 1.0, 1.0, 0.0625, 0.072265625, 0.0703125, 0.06640625, 0.0703125, 0.060546875, 1.0, 1.0, 1.0, 0.072265625, 1.0, 0.068359375, 1.0, 0.060546875, 0.0703125, 1.0, 0.068359375, 1.0, 0.064453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.083984375, 0.072265625, 1.0, 1.0, 1.0, 0.06640625, 1.0, 0.06640625, 1.0, 0.0703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.068359375, 1.0, 1.0, 1.0, 0.060546875, 1.0, 1.0, 0.0703125, 0.078125, 0.068359375, 1.0, 0.06640625, 1.0, 1.0, 0.072265625, 0.076171875, 1.0, 0.06640625, 0.060546875, 0.060546875, 1.0, 1.0, 0.060546875, 1.0, 0.060546875, 1.0, 0.060546875, 1.0, 1.0, 0.0625, 0.064453125, 0.08984375, 0.0625, 1.0, 0.08984375, 1.0, 0.0625, 0.060546875, 1.0, 0.072265625, 0.07421875, 0.09375, 0.064453125, 1.0, 1.0, 0.060546875, 1.0, 1.0, 0.0703125, 1.0, 1.0, 1.0, 1.0, 0.0703125, 1.0, 0.06640625, 1.0, 1.0, 0.056640625, 1.0, 1.0, 0.0703125, 0.0625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.060546875, 1.0, 1.0, 1.0, 0.06640625, 1.0, 1.0, 0.076171875, 0.06640625, 1.0, 1.0, 0.06640625, 1.0, 1.0, 0.068359375, 0.06640625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.060546875, 0.06640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.068359375, 0.0625, 1.0, 0.0546875, 0.0859375, 0.060546875, 0.0703125, 0.0625, 0.068359375, 0.068359375, 1.0, 1.0, 1.0, 0.072265625, 1.0, 1.0, 1.0, 0.06640625, 1.0, 0.0625, 1.0, 0.0625, 1.0, 1.0, 1.0, 0.05859375, 1.0, 1.0, 0.060546875, 1.0, 1.0, 0.05859375, 0.068359375, 1.0, 0.0703125, 0.0703125, 0.099609375, 0.07421875, 1.0, 0.06640625, 1.0, 1.0, 1.0, 1.0, 0.0625, 0.076171875, 0.07421875, 1.0, 1.0, 0.060546875, 1.0, 1.0, 0.072265625, 0.095703125, 1.0, 0.158203125, 0.0703125, 1.0, 0.06640625, 1.0, 0.0625, 1.0, 1.0, 0.0703125, 0.0625, 0.0625, 1.0, 0.060546875, 1.0, 1.0, 1.0, 0.0703125, 0.068359375, 1.0, 1.0, 0.0703125, 0.06640625, 1.0, 0.0625, 1.0, 1.0, 0.068359375, 1.0, 0.068359375, 1.0, 1.0, 0.064453125, 1.0, 0.06640625, 0.06640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.06640625, 0.072265625, 0.068359375, 0.072265625, 0.06640625, 1.0, 1.0, 1.0, 1.0, 0.0703125, 1.0, 0.056640625, 1.0, 1.0, 1.0, 1.0, 0.068359375, 1.0, 1.0, 1.0, 0.080078125, 0.060546875, 0.0625, 1.0, 1.0, 1.0, 0.05859375, 1.0, 1.0, 1.0, 0.060546875, 1.0, 1.0, 0.05859375, 1.0, 0.05859375, 1.0, 0.07421875, 1.0, 1.0, 1.0, 0.064453125, 0.05859375, 0.056640625, 0.068359375, 1.0, 0.068359375, 0.064453125, 1.0, 1.0, 0.060546875, 1.0, 0.068359375, 1.0, 0.09765625, 1.0, 0.099609375, 0.08203125, 0.064453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0625, 1.0, 0.06640625, 1.0, 1.0, 1.0, 0.0703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.064453125, 0.05859375, 0.068359375, 0.05859375, 1.0, 1.0, 0.060546875, 1.0, 1.0, 0.0625, 1.0, 1.0, 1.0, 0.064453125, 1.0, 0.0703125, 1.0, 0.0625, 1.0, 1.0, 0.068359375, 1.0, 1.0, 1.0, 1.0, 0.07421875, 0.08984375, 0.06640625, 1.0, 1.0, 0.06640625, 0.0625, 1.0, 1.0, 0.068359375, 0.2109375, 1.0, 1.0, 0.0625, 1.0, 0.08984375, 0.07421875, 0.0625, 0.0703125, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.060546875, 1.0, 1.0, 1.0, 1.0, 0.064453125, 1.0, 0.068359375, 0.068359375, 0.068359375, 0.0625, 1.0, 1.0, 1.0, 0.068359375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.056640625, 0.072265625, 1.0, 0.068359375, 1.0, 0.06640625, 1.0, 0.06640625, 0.078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.060546875, 0.064453125, 0.0625, 1.0, 1.0, 1.0, 0.076171875, 1.0, 0.068359375, 1.0, 0.06640625, 1.0, 1.0, 0.072265625, 1.0, 0.05859375, 1.0, 1.0, 0.060546875, 1.0, 1.0, 0.06640625, 1.0, 1.0, 1.0, 0.06640625, 1.0, 0.068359375, 1.0, 1.0, 0.056640625, 0.068359375, 1.0, 1.0, 1.0, 0.060546875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.126953125, 1.0, 1.0, 0.060546875, 0.0625, 1.0, 1.0, 1.0, 0.060546875, 0.072265625, 1.0, 0.0625, 0.064453125, 1.0, 0.087890625, 0.06640625, 0.060546875, 0.06640625, 0.072265625, 1.0, 0.099609375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.068359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.078125, 1.0, 0.05859375, 0.068359375, 1.0, 1.0, 0.05859375, 0.05859375, 0.0625, 0.064453125, 1.0, 1.0, 0.06640625, 0.068359375, 1.0, 0.0703125, 0.06640625, 1.0, 0.06640625, 0.06640625, 1.0, 0.076171875, 1.0, 1.0, 0.056640625, 1.0, 0.064453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.060546875, 1.0, 0.0703125, 1.0, 1.0, 1.0, 0.0625, 1.0, 0.068359375, 0.068359375, 0.060546875, 1.0, 0.064453125, 1.0, 0.0625, 1.0, 0.09765625, 0.064453125, 0.060546875, 0.07421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.50390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.068359375, 0.064453125, 1.0, 1.0, 0.0703125, 0.068359375, 1.0, 1.0, 1.0, 0.064453125, 1.0, 1.0, 1.0, 1.0, 0.0703125, 1.0, 0.0703125, 1.0, 1.0, 1.0, 0.0703125, 0.068359375, 0.060546875, 1.0, 0.0703125, 0.0859375, 1.0, 0.064453125, 1.0, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 1.0, 0.06640625, 1.0, 0.0859375, 0.064453125, 0.0625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.05859375, 1.0, 0.125, 0.072265625, 0.0625, 1.0, 1.0, 0.064453125, 0.064453125, 0.0625, 0.064453125, 1.0, 0.10546875, 1.0, 0.068359375, 0.060546875, 0.072265625, 1.0, 1.0, 0.06640625, 1.0, 1.0, 1.0, 0.068359375, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.072265625, 1.0, 1.0, 1.0, 0.0703125, 0.06640625, 0.0703125, 0.076171875, 1.0, 0.064453125, 1.0, 0.06640625, 0.0703125, 1.0, 1.0, 0.064453125, 1.0, 1.0, 1.0, 1.0, 0.060546875, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.0703125, 1.0, 1.0, 1.0, 0.2734375, 1.0, 1.0, 0.0625, 0.060546875, 0.064453125, 0.064453125, 0.06640625, 1.0, 0.11328125, 0.072265625, 1.0, 0.060546875, 0.064453125, 1.0, 0.0703125, 1.0, 1.0, 1.0, 1.0, 0.064453125, 0.0625, 1.0, 0.05859375, 1.0, 0.07421875, 0.05859375, 1.0, 1.0, 1.0, 0.064453125, 1.0, 0.064453125, 0.06640625, 0.0625, 0.07421875, 0.06640625, 1.0, 0.060546875, 0.05859375, 1.0, 1.0, 1.0, 0.064453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0703125, 0.064453125, 0.05859375, 0.06640625, 1.0, 0.078125, 1.0, 1.0, 1.0, 0.060546875, 1.0, 1.0, 1.0, 0.064453125, 0.0625, 1.0, 0.07421875, 1.0, 1.0, 1.0, 0.068359375, 0.06640625, 0.091796875, 0.06640625, 0.064453125, 0.076171875, 0.05859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.095703125, 1.0, 1.0, 0.0625, 1.0, 1.0, 1.0, 0.064453125, 0.07421875, 1.0, 0.068359375, 1.0, 1.0, 1.0, 0.06640625, 0.07421875, 1.0, 0.060546875, 1.0, 1.0, 0.06640625, 0.076171875, 0.064453125, 1.0, 1.0, 0.0625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.064453125, 1.0, 1.0, 1.0, 1.0, 0.064453125, 0.072265625, 0.060546875, 0.060546875, 1.0, 0.0625, 1.0, 1.0, 0.0859375, 1.0, 0.068359375, 1.0, 0.068359375, 0.0546875, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.0625, 0.064453125, 1.0, 1.0, 0.07421875, 1.0, 1.0, 1.0, 0.068359375, 1.0, 1.0, 0.07421875, 1.0, 1.0, 1.0, 0.0703125, 0.076171875, 1.0, 1.0, 0.080078125, 0.12109375, 0.0625, 1.0, 1.0, 1.0, 1.0, 0.0703125, 0.0625, 1.0, 0.0625, 0.05859375, 0.072265625, 0.0703125, 1.0, 0.064453125, 0.060546875, 1.0, 1.0, 1.0, 0.064453125, 1.0, 0.06640625, 1.0, 0.064453125, 0.068359375, 1.0, 1.0, 0.05859375, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.0703125, 0.068359375, 0.0625, 0.154296875, 0.0703125, 1.0, 1.0, 1.0, 1.0, 0.0625, 0.072265625, 0.0625, 1.0, 1.0, 0.064453125, 0.0546875, 1.0, 1.0, 0.080078125, 1.0, 1.0, 0.060546875, 1.0, 0.0625, 1.0, 0.07421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.08203125, 0.080078125, 0.0625, 1.0, 1.0, 0.060546875, 1.0, 1.0, 1.0, 0.107421875, 1.0, 0.0703125, 0.06640625, 1.0, 0.060546875, 1.0, 0.0625, 1.0, 0.0625, 0.06640625, 1.0, 1.0, 0.078125, 1.0, 0.076171875, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.060546875, 1.0, 0.064453125, 0.06640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.498046875, 0.494140625, 0.494140625, 1.0, 1.0, 0.4990234375, 1.0, 0.4951171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5009765625, 1.0, 1.0, 0.494140625, 0.4912109375, 1.0, 1.0, 0.4931640625, 0.4892578125, 0.4931640625, 1.0, 1.0, 1.0, 1.0, 0.498046875, 0.4931640625, 1.0, 1.0, 0.5078125, 1.0, 1.0, 1.0, 0.4951171875, 0.4951171875, 1.0, 0.49609375, 0.48828125, 1.0, 1.0, 1.0, 0.4912109375, 0.4912109375, 0.5009765625, 0.498046875, 0.498046875, 0.49609375, 1.0, 1.0, 1.0, 0.498046875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.498046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.498046875, 1.0, 1.0, 0.4912109375, 0.498046875, 0.498046875, 0.49609375, 1.0, 1.0, 0.4951171875, 1.0, 1.0, 0.494140625, 0.4990234375, 0.505859375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.49609375, 1.0, 1.0, 1.0, 0.4990234375, 1.0, 1.0, 1.0, 0.498046875, 1.0, 1.0, 1.0, 1.0, 0.4951171875, 1.0, 0.4951171875, 0.49609375, 0.4970703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.498046875, 1.0, 1.0, 0.4970703125, 1.0, 1.0, 1.0, 1.0, 0.4921875, 1.0, 1.0, 0.5029296875, 1.0, 1.0, 1.0, 0.4970703125, 0.490234375, 1.0, 0.494140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5029296875, 1.0, 0.4892578125, 1.0, 1.0, 0.494140625, 0.4931640625, 0.5009765625, 0.4921875, 0.490234375, 1.0, 1.0, 0.4970703125, 0.498046875, 1.0, 0.5029296875, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5009765625, 1.0, 1.0, 0.49609375, 0.48828125, 1.0, 0.49609375, 0.50390625, 0.4912109375, 0.4990234375, 1.0, 1.0, 0.49609375, 0.4951171875, 1.0, 0.4951171875, 0.4990234375, 1.0, 1.0, 0.4931640625, 0.494140625, 1.0, 1.0, 0.5302734375, 0.4931640625, 1.0, 1.0, 0.5, 0.4970703125, 1.0, 1.0, 1.0, 0.4873046875, 1.0, 1.0, 1.0, 0.5009765625, 1.0, 1.0, 1.0, 0.4951171875, 1.0, 1.0, 1.0, 0.49609375, 1.0, 1.0, 1.0, 0.4951171875, 1.0, 0.4970703125, 1.0, 1.0, 1.0, 0.49609375, 0.4873046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4921875, 0.4970703125, 0.4990234375, 0.4931640625, 1.0, 1.0, 1.0, 1.0, 0.494140625, 0.4970703125, 1.0, 1.0, 1.0, 0.4951171875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.4951171875, 0.4931640625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49609375, 1.0]

 sparsity of   [0.6232638955116272, 0.6228298544883728, 1.0, 1.0, 0.624131977558136, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6223958134651184, 0.6236979365348816, 1.0, 1.0, 1.0, 1.0, 0.6236979365348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6236979365348816, 1.0, 0.6245659589767456, 0.6228298544883728, 0.6232638955116272, 1.0, 1.0, 0.6223958134651184, 0.625, 1.0, 1.0, 1.0, 0.6228298544883728, 0.6254340410232544, 1.0, 1.0, 0.6219618320465088, 0.6223958134651184, 1.0, 0.6228298544883728, 0.6232638955116272, 1.0, 1.0, 0.6232638955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 0.624131977558136, 0.6228298544883728, 1.0, 1.0, 0.6219618320465088, 1.0, 1.0, 0.6232638955116272, 1.0, 0.6219618320465088, 0.6232638955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.624131977558136, 1.0, 0.6223958134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 0.624131977558136, 1.0, 0.6215277910232544, 0.6232638955116272, 1.0, 0.6236979365348816, 1.0, 0.6223958134651184, 1.0, 1.0, 0.625, 0.6232638955116272, 1.0, 1.0, 0.6223958134651184, 0.6223958134651184, 1.0, 1.0, 1.0, 0.6228298544883728, 1.0, 1.0, 0.6219618320465088, 0.6215277910232544, 1.0, 1.0, 1.0, 1.0, 0.6219618320465088, 1.0, 1.0, 0.624131977558136, 1.0, 0.6223958134651184, 1.0, 1.0, 0.6254340410232544, 1.0, 1.0, 0.6236979365348816, 0.6228298544883728, 1.0, 0.6228298544883728, 1.0, 1.0, 1.0, 1.0, 0.6232638955116272, 1.0, 1.0, 1.0, 1.0, 0.6232638955116272, 1.0, 1.0, 0.6228298544883728, 0.6215277910232544, 1.0, 1.0, 1.0, 1.0, 0.6236979365348816, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6245659589767456, 0.6236979365348816, 1.0, 0.6223958134651184, 1.0, 0.6232638955116272, 1.0, 0.6223958134651184, 1.0, 0.624131977558136, 0.624131977558136, 0.6223958134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6223958134651184, 1.0, 0.6223958134651184, 0.6206597089767456, 0.6254340410232544, 1.0, 1.0, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6219618320465088, 1.0, 1.0, 1.0, 0.624131977558136, 1.0, 1.0, 1.0, 0.6215277910232544, 1.0, 1.0, 1.0, 1.0, 0.6245659589767456, 1.0, 0.6223958134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6232638955116272, 1.0, 0.6232638955116272, 1.0, 0.6223958134651184, 1.0, 0.6232638955116272, 1.0, 1.0, 0.6228298544883728, 0.6228298544883728, 1.0, 1.0, 0.6245659589767456, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6232638955116272, 1.0, 1.0, 0.6245659589767456, 1.0, 0.6223958134651184, 0.62109375, 0.6236979365348816, 1.0, 1.0, 1.0, 1.0, 0.6245659589767456, 0.6223958134651184, 0.6228298544883728, 0.6236979365348816, 0.6215277910232544, 1.0, 1.0, 1.0, 0.6228298544883728, 1.0, 1.0]

 sparsity of   [0.64453125, 1.0, 0.64453125, 1.0, 0.64453125, 0.64453125, 0.64453125, 1.0, 1.0, 0.6484375, 0.6484375, 1.0, 1.0, 1.0, 0.64453125, 0.6484375, 1.0, 1.0, 0.64453125, 0.64453125, 0.64453125, 1.0, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 0.6484375, 0.64453125, 0.64453125, 0.64453125, 0.65234375, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 0.64453125, 0.64453125, 0.64453125, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 0.6484375, 0.65234375, 0.6484375, 0.65234375, 1.0, 1.0, 0.6484375, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 0.6484375, 1.0, 0.64453125, 0.64453125, 0.64453125, 0.64453125, 0.66796875, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 0.65234375, 1.0, 0.64453125, 1.0, 1.0, 0.6484375, 1.0, 0.64453125, 1.0, 0.6484375, 1.0, 0.6484375, 0.65234375, 1.0, 0.64453125, 1.0, 0.6484375, 1.0, 0.64453125, 0.65234375, 0.65234375, 1.0, 0.6484375, 1.0, 0.6484375, 0.64453125, 0.6484375, 0.64453125, 0.64453125, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 0.6484375, 0.64453125, 0.65234375, 0.64453125, 0.64453125, 0.65234375, 0.64453125, 1.0, 1.0, 1.0, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 0.65234375, 1.0, 0.6484375, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.6484375, 0.64453125, 0.6484375, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 0.6484375, 1.0, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.6484375, 1.0, 0.6484375, 1.0, 0.64453125, 0.65234375, 0.64453125, 1.0, 0.64453125, 1.0, 0.64453125, 0.6484375, 1.0, 0.6484375, 1.0, 0.6484375, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.6484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.6484375, 0.65234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 0.64453125, 0.65234375, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.64453125, 0.6484375, 1.0, 1.0, 1.0, 0.65234375, 0.64453125, 1.0, 0.6484375, 0.64453125, 1.0, 0.6484375, 0.6484375, 0.64453125, 0.6484375, 0.6484375, 0.6484375, 0.65625, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 1.0, 0.65234375, 1.0, 0.64453125, 1.0, 0.6484375, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.6484375, 0.64453125, 0.64453125, 0.64453125, 1.0, 0.6484375, 0.6484375, 0.6484375, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 0.65234375, 1.0, 0.6484375, 0.64453125, 1.0, 0.65234375, 1.0, 0.65234375, 1.0, 0.65234375, 0.65234375, 0.64453125, 0.64453125, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 0.64453125, 0.6484375, 1.0, 0.64453125, 0.6484375, 0.6484375, 1.0, 0.640625, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 0.64453125, 1.0, 0.640625, 1.0, 0.6484375, 0.64453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.64453125, 0.65234375, 0.64453125, 0.64453125, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 0.6484375, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 0.6484375, 1.0, 1.0, 0.64453125, 0.6484375, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 0.64453125, 0.6484375, 1.0, 0.6484375, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 0.6484375, 0.64453125, 0.64453125, 0.6484375, 0.6484375, 1.0, 1.0, 0.6484375, 0.64453125, 0.65234375, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 1.0, 0.65234375, 1.0, 1.0, 0.64453125, 0.64453125, 0.64453125, 0.64453125, 1.0, 0.64453125, 0.65625, 1.0, 0.64453125, 0.640625, 1.0, 1.0, 1.0, 0.6484375, 1.0, 0.64453125, 0.65625, 0.65234375, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 0.6484375, 0.6640625, 0.6484375, 1.0, 1.0, 0.64453125, 0.64453125, 0.65234375, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 0.65234375, 1.0, 1.0, 0.64453125, 0.64453125, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 0.65234375, 1.0, 1.0, 0.6484375, 1.0, 0.64453125, 0.64453125, 1.0, 0.6484375, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 1.0, 0.65234375, 0.64453125, 0.64453125, 1.0, 0.65234375, 0.6484375, 0.6640625, 1.0, 0.65234375, 1.0, 1.0, 0.64453125, 0.64453125, 0.64453125, 0.6484375, 1.0, 1.0, 0.64453125, 0.65234375, 0.64453125, 1.0, 0.640625, 1.0, 1.0, 0.64453125, 1.0, 0.65234375, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.66796875, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.6484375, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 0.64453125, 1.0, 0.6484375, 0.64453125, 1.0, 1.0, 0.64453125, 0.64453125, 0.6484375, 0.6484375, 1.0, 0.65625, 1.0, 1.0, 1.0, 1.0, 0.6484375, 0.6484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 1.0, 0.65234375, 0.64453125, 0.6484375, 0.64453125, 0.6484375, 1.0, 0.6484375, 0.65234375, 0.64453125, 1.0, 0.64453125, 0.6484375, 1.0, 0.6484375, 0.64453125, 0.65625, 0.65234375, 1.0, 0.64453125, 0.64453125, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.6484375, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 0.64453125, 0.64453125, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 0.64453125, 0.6484375, 0.65234375, 0.64453125, 1.0, 1.0, 0.65625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 1.0, 0.64453125, 0.6484375, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 0.65625, 0.6484375, 1.0, 0.65234375, 0.64453125, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 0.6484375, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 0.64453125, 0.6484375, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 0.64453125, 0.6484375, 0.64453125, 0.64453125, 1.0, 0.6484375, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 1.0, 0.65234375, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 0.64453125, 1.0, 0.6484375, 1.0, 0.6484375, 1.0, 0.64453125, 0.6484375, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.65234375, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.65234375, 1.0, 1.0, 0.65234375, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 0.64453125, 0.64453125, 0.64453125, 0.64453125, 0.6484375, 0.6484375, 0.64453125, 0.64453125, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 0.64453125, 0.6484375, 1.0, 0.65234375, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 0.65234375, 0.6484375, 0.65234375, 0.65234375, 0.6484375, 0.6484375, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.64453125, 0.64453125, 0.6484375, 1.0, 0.64453125, 0.65234375, 1.0, 1.0, 0.6484375, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 1.0, 0.65234375, 1.0, 0.64453125, 0.6484375, 0.64453125, 0.6484375, 0.6484375, 0.6484375, 0.6484375, 0.65234375, 0.65234375, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.65625, 1.0, 1.0, 0.6484375, 0.6484375, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 0.6484375, 0.6484375, 1.0, 0.6484375, 0.65234375, 0.6484375, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 0.65625, 0.65234375, 1.0, 0.64453125, 1.0, 0.64453125, 0.65234375, 1.0, 0.64453125, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.6484375, 0.671875, 1.0, 1.0, 0.6484375, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.65234375, 0.64453125, 1.0, 1.0, 1.0, 0.65234375, 0.6484375, 0.65234375, 1.0, 1.0, 0.64453125, 0.64453125, 0.64453125, 1.0, 0.64453125, 0.6484375, 0.64453125, 0.65625, 1.0, 0.64453125, 0.65234375, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.6484375, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 0.64453125, 0.64453125, 0.64453125, 0.640625, 1.0, 1.0, 1.0, 1.0, 0.65234375, 0.64453125, 0.64453125, 1.0, 1.0, 0.6484375, 0.64453125, 0.64453125, 0.64453125, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.64453125, 0.6484375, 1.0, 1.0, 0.64453125, 0.64453125, 0.64453125, 1.0, 1.0, 0.6484375, 0.64453125, 1.0, 0.6484375, 0.65625, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 0.64453125, 0.64453125, 1.0, 0.6484375, 0.64453125, 1.0, 0.65625, 1.0, 1.0, 0.640625, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 0.65234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.4423828125, 0.4453125, 1.0, 1.0, 1.0, 1.0, 0.4423828125, 1.0, 0.4423828125, 1.0, 1.0, 0.4443359375, 0.443359375, 0.443359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.447265625, 0.443359375, 1.0, 1.0, 1.0, 1.0, 0.4462890625, 1.0, 1.0, 0.44140625, 1.0, 0.439453125, 1.0, 0.4404296875, 1.0, 0.443359375, 1.0, 1.0, 0.439453125, 1.0, 0.443359375, 0.443359375, 1.0, 0.4482421875, 0.439453125, 1.0, 1.0, 0.4423828125, 0.4365234375, 1.0, 0.4267578125, 1.0, 0.443359375, 1.0, 0.4287109375, 1.0, 0.443359375, 1.0, 1.0, 0.4423828125, 1.0, 1.0, 1.0, 0.4482421875, 1.0, 1.0, 0.443359375, 0.4384765625, 1.0, 1.0, 1.0, 1.0, 0.4423828125, 0.44140625, 0.4423828125, 0.4384765625, 1.0, 1.0, 0.4404296875, 1.0, 0.4384765625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4443359375, 1.0, 1.0, 1.0, 0.4345703125, 0.44140625, 1.0, 0.447265625, 0.4521484375, 1.0, 0.4521484375, 0.4443359375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4375, 1.0, 0.4453125, 1.0, 1.0, 1.0, 1.0, 0.4423828125, 0.4375, 0.447265625, 1.0, 0.4443359375, 0.439453125, 1.0, 1.0, 0.4423828125, 0.4482421875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.435546875, 0.447265625, 1.0, 0.44140625, 0.4404296875, 1.0, 1.0, 1.0, 0.451171875, 1.0, 0.435546875, 1.0, 1.0, 1.0, 0.4404296875, 1.0, 1.0, 0.44140625, 1.0, 1.0, 1.0, 1.0, 0.4375, 0.44921875, 0.43359375, 0.4404296875, 0.4443359375, 1.0, 1.0, 0.4404296875, 1.0, 1.0, 1.0, 0.4345703125, 0.4423828125, 1.0, 0.4345703125, 1.0, 1.0, 1.0, 0.4482421875, 1.0, 0.4384765625, 1.0, 1.0, 0.4453125, 1.0, 0.4462890625, 1.0, 1.0, 1.0, 1.0, 0.44140625, 0.4462890625, 1.0, 0.43359375, 1.0, 1.0, 1.0, 1.0, 0.4404296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4482421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4443359375, 0.443359375, 1.0, 1.0, 1.0, 0.44921875, 1.0, 1.0, 0.43359375, 0.44140625, 1.0, 0.44140625, 1.0, 1.0, 0.439453125, 1.0, 1.0, 0.4375, 0.4423828125, 1.0, 1.0, 1.0, 1.0, 0.4521484375, 1.0, 1.0, 0.439453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.435546875, 1.0, 0.4345703125, 1.0, 0.44140625, 1.0, 0.43359375, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.6410590410232544, 1.0, 1.0, 1.0, 1.0, 0.6380208134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6401909589767456, 1.0, 0.6393229365348816, 0.6375868320465088, 1.0, 1.0, 1.0, 0.6384548544883728, 1.0, 0.635850727558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.639756977558136, 0.6384548544883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6410590410232544, 0.639756977558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.63671875, 0.639756977558136, 1.0, 1.0, 1.0, 0.640625, 1.0, 0.6401909589767456, 0.6362847089767456, 1.0, 1.0, 0.6423611044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6388888955116272, 1.0, 0.639756977558136, 1.0, 1.0, 1.0, 0.6384548544883728, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6401909589767456, 1.0, 1.0, 1.0, 0.6388888955116272, 1.0, 0.6375868320465088, 1.0, 1.0, 1.0, 1.0, 0.640625, 1.0, 1.0, 0.6375868320465088, 1.0, 1.0, 0.6345486044883728, 1.0, 1.0, 0.6393229365348816, 0.6371527910232544, 1.0, 0.6414930820465088, 1.0, 1.0, 0.6388888955116272, 1.0, 0.6388888955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6410590410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6384548544883728, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6380208134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6388888955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6375868320465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6393229365348816, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6384548544883728, 1.0, 1.0, 1.0, 0.6345486044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6371527910232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.640625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.639756977558136, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6380208134651184, 1.0, 1.0, 0.635850727558136, 1.0, 1.0, 1.0, 0.6423611044883728, 1.0, 1.0, 1.0, 0.63671875, 1.0, 0.639756977558136, 0.63671875, 0.6349826455116272, 1.0, 1.0, 1.0, 1.0, 0.6384548544883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6380208134651184, 1.0, 0.63671875, 1.0, 0.63671875, 1.0, 1.0, 0.639756977558136]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.7890625, 0.7890625, 0.7890625, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 0.7890625, 0.78515625, 0.78515625, 0.79296875, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.79296875, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 0.7890625, 1.0, 1.0, 1.0, 0.7890625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.7890625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 0.7890625, 0.78515625, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 0.78515625, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.7890625, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 0.78515625, 0.78515625, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.78515625, 1.0, 1.0, 1.0, 0.796875, 0.78515625, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.7890625, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 0.79296875, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.7890625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 0.7890625, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 0.78515625, 0.78515625, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 0.7890625, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.7890625, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.80078125, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.7890625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.78515625, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 0.7890625, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 0.78515625, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4306640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4326171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4326171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.431640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.43359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.451171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4365234375, 1.0, 1.0, 1.0, 0.43359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4775390625, 1.0, 1.0, 0.4990234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9208984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.431640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42578125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4931640625, 0.4990234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4521484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4326171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.505859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.43359375, 0.4580078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4365234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4345703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.556640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4287109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.548828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.44921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.431640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4501953125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.435546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4326171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.427734375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4326171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5302734375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4326171875, 1.0, 1.0, 0.44140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.44140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.44140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4873046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.560546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.521484375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.443359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.427734375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5791015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.51171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4404296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7744140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4365234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4560546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.435546875, 1.0, 0.435546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4375, 1.0, 1.0, 0.4345703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96923828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9697265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96923828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7584635615348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7096354365348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7150607705116272, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7365451455116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6970486044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7057291865348816, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.69091796875, 0.67529296875, 0.658203125, 0.6611328125, 0.6640625, 0.65869140625, 0.6611328125, 0.66015625, 0.6640625, 0.66455078125, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875]

Total parameter pruned: 22529416.003780387 (unstructured) 21339380 (structured)

Test: [0/79]	Time 0.172 (0.172)	Loss 0.2975 (0.2975) ([0.183]+[0.114])	Prec@1 95.312 (95.312)
 * Prec@1 93.870

 Total elapsed time  3:53:57.034321 
 FINETUNING


 sparsity of   [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.03703703731298447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.03703703731298447, 1.0, 1.0, 1.0, 0.0, 0.0, 0.03703703731298447, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]

 sparsity of   [1.0, 0.4375, 1.0, 1.0, 0.4375, 0.453125, 1.0, 1.0, 1.0, 1.0, 0.4375, 1.0, 0.4375, 1.0, 1.0, 1.0, 0.4375, 0.4375, 0.4375, 1.0, 0.453125, 0.4375, 1.0, 1.0, 0.4375, 1.0, 1.0, 0.4375, 1.0, 1.0, 0.4375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4375, 1.0, 1.0, 1.0, 0.453125, 1.0, 0.453125, 0.4375, 0.484375, 1.0, 0.4375, 0.4375, 0.453125, 1.0, 0.4375, 1.0, 0.453125, 1.0, 0.453125, 1.0, 1.0, 0.453125, 0.4375, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 0.578125, 1.0, 1.0, 1.0, 0.59375, 1.0, 1.0, 0.5868055820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.59375, 1.0, 0.5833333134651184, 1.0, 1.0, 0.585069477558136, 0.5729166865348816, 1.0, 1.0, 1.0, 1.0, 0.5868055820465088, 1.0, 1.0, 0.5954861044883728, 1.0, 1.0, 1.0, 0.5954861044883728, 1.0, 1.0, 1.0, 0.5868055820465088, 0.5798611044883728, 1.0, 0.5729166865348816, 1.0, 1.0, 0.585069477558136, 1.0, 1.0, 1.0, 0.5833333134651184, 0.600694477558136, 1.0, 1.0, 0.5954861044883728, 1.0, 1.0, 0.6232638955116272, 0.5868055820465088, 1.0, 0.5798611044883728, 1.0, 1.0, 1.0]

 sparsity of   [0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.703125, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.703125, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 1.0, 0.703125, 0.703125, 0.6875, 1.0, 0.703125, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 0.703125, 1.0, 1.0, 1.0, 0.6875, 0.6875, 1.0, 1.0, 1.0, 0.703125, 0.703125, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.703125, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 0.703125, 1.0, 0.6875, 0.6875, 1.0, 0.703125, 1.0, 0.6875, 1.0, 0.703125, 1.0, 0.6875, 1.0, 0.6875, 0.703125, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.71875, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.703125, 0.703125, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.703125, 0.703125, 1.0, 1.0, 0.703125, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.703125, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875]

 sparsity of   [0.453125, 1.0, 1.0, 0.4375, 1.0, 1.0, 0.4375, 0.46875, 0.4375, 0.453125, 0.46875, 0.4375, 0.4375, 0.4375, 0.4375, 0.4375, 0.4375, 0.4375, 0.453125, 1.0, 0.453125, 0.4375, 1.0, 1.0, 0.4375, 0.46875, 1.0, 1.0, 0.484375, 1.0, 0.4375, 0.453125, 0.46875, 0.4375, 0.453125, 0.453125, 0.4375, 0.46875, 1.0, 0.453125, 0.453125, 0.4375, 1.0, 0.453125, 1.0, 0.453125, 0.453125, 0.4375, 0.453125, 0.75, 0.515625, 1.0, 0.4375, 1.0, 0.453125, 0.453125, 0.4375, 0.453125, 0.46875, 0.5, 0.4375, 1.0, 0.4375, 1.0, 1.0, 0.453125, 0.453125, 0.453125, 0.453125, 0.453125, 0.4375, 0.4375, 0.4375, 0.46875, 0.4375, 0.453125, 1.0, 0.46875, 0.46875, 1.0, 1.0, 0.453125, 1.0, 1.0, 0.4375, 0.4375, 0.46875, 0.4375, 0.4375, 0.4375, 1.0, 1.0, 1.0, 0.515625, 0.46875, 1.0, 1.0, 0.4375, 0.4375, 0.4375, 0.46875, 0.4375, 0.453125, 1.0, 0.4375, 0.4375, 1.0, 0.453125, 0.4375, 1.0, 0.4375, 0.453125, 0.4375, 1.0, 0.5, 0.4375, 0.46875, 0.453125, 0.4375, 0.4375, 1.0, 0.4375, 0.4375, 1.0, 0.46875, 0.453125, 0.4375, 1.0, 0.4375, 0.453125, 1.0, 0.953125, 0.4375, 0.4375, 0.4375, 0.4375, 0.4375, 1.0, 0.5, 1.0, 0.4375, 0.46875, 0.453125, 0.5, 0.484375, 0.4375, 0.4375, 0.4375, 0.453125, 0.453125, 0.453125, 1.0, 0.4375, 0.453125, 0.4375, 0.4375, 0.46875, 0.453125, 1.0, 1.0, 0.4375, 0.4375, 1.0, 0.5, 1.0, 0.4375, 0.4375, 1.0, 0.4375, 0.453125, 0.453125, 0.4375, 0.453125, 1.0, 0.484375, 0.453125, 0.453125, 1.0, 1.0, 1.0, 0.4375, 1.0, 0.4375, 0.4375, 0.4375, 0.4375, 0.4375, 0.4375, 0.4375, 1.0, 0.453125, 1.0, 0.453125, 1.0, 0.4375, 1.0, 0.4375, 0.4375, 1.0, 1.0, 0.4375, 0.453125, 0.4375, 0.46875, 0.453125, 1.0, 1.0, 0.453125, 1.0, 0.4375, 0.4375, 1.0, 1.0, 0.453125, 1.0, 0.453125, 1.0, 0.453125, 0.4375, 0.484375, 0.484375, 0.46875, 0.4375, 1.0, 0.453125, 0.453125, 1.0, 1.0, 0.46875, 0.4375, 0.4375, 0.484375, 0.453125, 0.453125, 0.4375, 0.453125, 0.4375, 0.46875, 0.4375, 1.0, 0.46875, 0.4375, 0.4375, 1.0, 1.0, 0.46875, 0.484375, 0.4375, 0.453125, 0.4375, 1.0, 1.0, 0.4375, 0.53125, 0.46875, 0.4375]

 sparsity of   [0.27734375, 1.0, 1.0, 1.0, 1.0, 0.30859375, 0.28125, 1.0, 1.0, 1.0, 1.0, 0.265625, 1.0, 1.0, 1.0, 0.28515625, 1.0, 1.0, 1.0, 0.28125, 0.26953125, 1.0, 1.0, 0.265625, 1.0, 1.0, 0.26171875, 0.30859375, 0.265625, 0.26171875, 0.26171875, 1.0, 0.265625, 0.265625, 1.0, 1.0, 0.28515625, 1.0, 0.421875, 1.0, 0.28125, 1.0, 0.25, 1.0, 0.26171875, 1.0, 1.0, 1.0, 0.2578125, 0.2578125, 0.296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.26953125, 0.2578125, 1.0, 0.296875, 1.0, 1.0, 1.0, 0.34765625]

 sparsity of   [1.0, 0.5815972089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6041666865348816, 0.5868055820465088, 0.5763888955116272, 0.578125, 1.0, 1.0, 1.0, 0.5815972089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5833333134651184, 1.0, 0.5815972089767456, 0.585069477558136, 1.0, 1.0, 1.0, 1.0, 0.5798611044883728, 1.0, 1.0, 0.5746527910232544, 1.0, 0.578125, 1.0, 1.0, 0.5798611044883728, 1.0, 1.0, 1.0, 0.585069477558136, 1.0, 1.0, 1.0, 0.5833333134651184, 1.0, 1.0, 1.0, 0.5763888955116272, 0.578125, 0.5885416865348816, 0.5815972089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.703125, 1.0, 0.703125, 0.703125, 1.0, 1.0, 1.0, 0.703125, 0.6875, 0.703125, 1.0, 0.703125, 0.703125, 0.71875, 1.0, 1.0, 1.0, 0.703125, 1.0, 1.0, 1.0, 1.0, 0.703125, 1.0, 0.6875, 0.71875, 1.0, 1.0, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 0.734375, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.703125, 1.0, 1.0, 1.0, 0.6875, 0.71875, 0.6875, 0.703125, 0.703125, 1.0, 0.703125, 1.0, 1.0, 0.703125, 0.703125, 1.0, 1.0, 0.703125, 0.6875, 1.0, 0.703125, 0.71875, 1.0, 0.6875, 1.0, 0.703125, 0.703125, 0.703125, 1.0, 0.6875, 0.703125, 1.0, 0.6875, 0.703125, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.71875, 0.703125, 0.703125, 0.703125, 1.0, 0.703125, 1.0, 1.0, 0.6875, 0.703125, 1.0, 1.0, 0.703125, 0.703125, 0.703125, 1.0, 0.703125, 0.703125, 1.0, 1.0, 0.734375, 1.0, 1.0, 1.0, 0.703125, 0.703125, 1.0, 0.703125, 1.0, 1.0, 0.703125, 0.71875, 0.6875, 0.703125, 0.6875, 0.6875, 0.703125, 1.0, 0.6875, 0.703125, 1.0, 0.703125, 1.0, 0.6875, 0.71875, 1.0, 1.0, 0.703125, 0.703125, 1.0, 0.703125, 0.71875, 1.0, 1.0, 1.0, 0.703125, 1.0, 0.703125, 0.703125, 0.71875, 0.703125, 0.703125, 1.0, 0.71875, 0.703125, 0.703125, 1.0, 0.71875, 0.703125, 0.703125, 1.0, 0.703125, 1.0, 0.703125, 0.6875, 1.0, 0.703125, 0.703125, 0.703125, 1.0, 1.0, 0.703125, 1.0, 0.703125, 1.0, 1.0, 0.6875, 1.0, 0.703125, 0.6875, 1.0, 0.703125, 0.703125, 1.0, 1.0, 0.6875, 1.0, 0.703125, 0.703125, 1.0, 1.0, 0.71875, 0.71875, 0.703125, 1.0, 1.0, 0.703125, 1.0, 1.0, 1.0, 0.6875, 0.703125, 0.703125, 0.703125, 1.0, 1.0, 0.71875, 0.703125, 0.703125, 0.703125, 1.0, 0.703125, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 1.0, 0.71875, 1.0, 0.71875, 0.703125, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.703125, 1.0, 0.703125, 0.703125, 1.0, 1.0, 0.703125, 0.703125, 0.703125, 1.0, 1.0, 0.6875, 0.6875, 0.703125, 1.0, 1.0, 0.6875, 0.703125, 0.71875, 0.6875, 0.71875, 0.703125, 0.703125, 0.703125, 0.703125, 1.0, 0.6875]

 sparsity of   [0.15625, 1.0, 0.1640625, 1.0, 0.16015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.171875, 1.0, 1.0, 1.0, 1.0, 0.203125, 1.0, 1.0, 1.0, 0.19140625, 0.16796875, 1.0, 1.0, 1.0, 0.203125, 1.0, 1.0, 1.0, 0.19140625, 1.0, 1.0, 0.171875, 1.0, 0.1796875, 1.0, 1.0, 0.16796875, 0.1796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1796875, 0.20703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.171875, 1.0, 1.0, 1.0, 1.0, 0.1640625, 1.0, 0.16015625]

 sparsity of   [1.0, 1.0, 1.0, 0.7274305820465088, 1.0, 1.0, 0.7309027910232544, 1.0, 1.0, 0.7309027910232544, 1.0, 1.0, 0.7065972089767456, 0.703125, 1.0, 1.0, 1.0, 1.0, 0.710069477558136, 0.7083333134651184, 1.0, 0.703125, 1.0, 1.0, 1.0, 0.7204861044883728, 1.0, 1.0, 1.0, 0.710069477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7222222089767456, 1.0, 1.0, 1.0, 0.7065972089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7291666865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7083333134651184, 1.0, 0.7239583134651184, 0.7222222089767456, 1.0, 1.0, 1.0]

 sparsity of   [0.71875, 0.671875, 1.0, 1.0, 0.734375, 1.0, 1.0, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 0.71875, 0.734375, 1.0, 1.0, 1.0, 0.703125, 1.0, 0.75, 1.0, 1.0, 0.71875, 0.6875, 1.0, 1.0, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.703125, 1.0, 1.0, 1.0, 0.671875, 0.734375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.734375, 1.0, 1.0, 0.703125, 1.0, 0.734375, 1.0, 1.0, 1.0, 0.6875, 0.671875, 0.703125, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.734375, 1.0, 1.0, 0.734375, 1.0, 1.0, 0.6875, 0.703125, 0.71875, 1.0, 0.703125, 0.671875, 1.0, 1.0, 0.671875, 1.0, 0.703125, 1.0, 0.671875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.734375, 1.0, 1.0, 1.0, 1.0, 0.734375, 1.0, 1.0, 0.734375, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.734375, 1.0, 1.0, 0.734375, 0.75, 0.671875, 1.0, 1.0, 0.65625, 0.71875, 0.71875, 1.0, 1.0, 1.0, 0.671875, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.734375, 1.0, 1.0, 1.0, 0.734375, 1.0, 0.734375, 1.0, 0.734375, 0.71875, 1.0, 0.71875, 1.0, 0.734375, 1.0, 0.703125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 0.703125, 1.0, 0.703125, 0.703125, 0.71875, 0.703125, 0.734375, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.65625, 1.0, 1.0, 1.0, 1.0, 0.671875, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.65625, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.703125, 0.65625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 0.71875, 0.65625, 1.0, 0.734375, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.65625, 0.71875, 0.71875, 1.0, 0.65625, 0.703125, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.71875, 1.0, 0.734375, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 0.0703125, 1.0, 1.0, 1.0, 0.0546875, 1.0, 1.0, 0.0546875, 1.0, 0.0703125, 0.0546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0625, 1.0, 0.0546875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07421875, 1.0, 1.0, 1.0, 1.0, 0.0625, 1.0, 0.06640625, 0.05859375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.05859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.078125, 1.0, 1.0, 0.07421875, 1.0, 0.0625, 1.0, 1.0, 1.0, 0.06640625, 1.0, 0.07421875, 0.0625, 0.0546875, 0.0625, 1.0, 0.05859375, 1.0, 0.0625, 0.0703125, 0.05859375, 1.0, 0.08984375, 1.0, 1.0, 1.0, 1.0, 0.0625, 0.06640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0546875, 1.0, 1.0, 1.0, 0.06640625, 1.0, 1.0, 0.078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.05859375, 1.0, 1.0, 1.0, 1.0, 0.05859375, 1.0, 0.0703125, 1.0, 0.0703125, 0.05859375, 1.0, 1.0, 1.0, 0.06640625, 0.0625, 1.0, 0.0703125]

 sparsity of   [1.0, 0.6892361044883728, 0.6875, 1.0, 0.6883680820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6892361044883728, 0.6892361044883728, 1.0, 0.6883680820465088, 1.0, 1.0, 1.0, 0.6892361044883728, 0.6892361044883728, 1.0, 0.6875, 0.6892361044883728, 1.0, 0.6918402910232544, 0.6883680820465088, 0.6883680820465088, 1.0, 0.6875, 0.6875, 0.6901041865348816, 1.0, 0.6901041865348816, 1.0, 1.0, 1.0, 0.6883680820465088, 1.0, 0.6901041865348816, 1.0, 1.0, 0.6883680820465088, 1.0, 1.0, 0.6883680820465088, 0.6892361044883728, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6901041865348816, 1.0, 0.6883680820465088, 1.0, 0.6892361044883728, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6901041865348816, 1.0, 1.0, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6892361044883728, 0.6883680820465088, 1.0, 1.0, 1.0, 0.6892361044883728, 1.0, 1.0, 1.0, 0.6883680820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6901041865348816, 1.0, 0.6883680820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6892361044883728, 1.0, 0.6883680820465088, 1.0, 1.0, 1.0, 1.0, 0.6901041865348816, 1.0, 0.6875, 0.6892361044883728, 0.6883680820465088, 0.6883680820465088, 0.6883680820465088, 0.6892361044883728, 0.6892361044883728, 1.0, 1.0, 1.0, 0.6892361044883728, 1.0, 0.6883680820465088, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6883680820465088]

 sparsity of   [1.0, 0.59375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.59375, 1.0, 0.6015625, 1.0, 0.6015625, 1.0, 1.0, 0.6015625, 1.0, 1.0, 1.0, 1.0, 0.59375, 0.59375, 1.0, 0.59375, 1.0, 1.0, 0.59375, 1.0, 0.59375, 0.59375, 0.6328125, 1.0, 1.0, 0.59375, 0.6015625, 0.59375, 0.59375, 0.609375, 1.0, 1.0, 1.0, 0.59375, 1.0, 1.0, 0.59375, 0.59375, 1.0, 0.59375, 1.0, 1.0, 0.6015625, 1.0, 1.0, 0.59375, 0.609375, 0.59375, 1.0, 1.0, 0.59375, 0.59375, 0.6015625, 1.0, 0.59375, 1.0, 1.0, 1.0, 0.59375, 0.59375, 1.0, 1.0, 0.59375, 0.59375, 0.59375, 1.0, 0.6015625, 1.0, 1.0, 1.0, 0.6015625, 1.0, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 1.0, 1.0, 0.6015625, 1.0, 1.0, 0.59375, 0.59375, 1.0, 0.6015625, 0.59375, 0.6015625, 0.6015625, 0.59375, 1.0, 0.59375, 1.0, 1.0, 0.59375, 0.6015625, 0.59375, 0.59375, 1.0, 1.0, 0.59375, 0.6328125, 1.0, 1.0, 0.59375, 1.0, 0.59375, 0.6015625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.59375, 0.59375, 1.0, 0.59375, 1.0, 0.59375, 1.0, 1.0, 1.0, 0.6015625, 1.0, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.6015625, 0.59375, 0.59375, 0.6015625, 1.0, 1.0, 0.59375, 1.0, 1.0, 0.6015625, 0.6015625, 1.0, 1.0, 0.59375, 0.6015625, 0.59375, 0.6015625, 1.0, 1.0, 1.0, 0.6015625, 0.59375, 0.6015625, 1.0, 0.59375, 1.0, 0.609375, 0.59375, 0.59375, 1.0, 0.59375, 1.0, 0.6015625, 1.0, 0.609375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 1.0, 0.59375, 0.6015625, 1.0, 1.0, 0.59375, 0.59375, 1.0, 1.0, 0.59375, 0.59375, 1.0, 1.0, 0.59375, 1.0, 1.0, 1.0, 1.0, 0.59375, 0.6015625, 1.0, 1.0, 0.6015625, 0.59375, 0.59375, 0.59375, 1.0, 0.59375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.59375, 1.0, 1.0, 0.6015625, 1.0, 0.6015625, 1.0, 1.0, 0.59375, 0.59375, 1.0, 0.6953125, 0.6015625, 0.6015625, 0.59375, 0.6015625, 1.0, 0.59375, 0.6015625, 0.59375, 0.6015625, 0.6015625, 0.59375, 0.59375, 1.0, 1.0, 0.59375, 1.0, 0.59375, 0.59375, 1.0, 1.0, 1.0, 0.59375, 0.6015625, 0.6015625, 0.640625, 0.6015625, 1.0, 1.0, 0.6015625, 0.59375, 0.59375, 1.0, 0.59375, 1.0, 1.0, 1.0, 1.0, 0.59375, 0.59375, 0.59375, 0.59375, 1.0, 1.0, 0.59375, 0.6015625, 1.0, 0.6015625, 1.0, 1.0, 0.609375, 0.59375, 0.59375, 1.0, 1.0, 0.59375, 0.59375, 1.0, 0.59375, 1.0, 0.59375, 1.0, 0.6015625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.59375, 1.0, 1.0, 0.59375, 1.0, 0.59375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.59375, 0.6015625, 0.6015625, 1.0, 1.0, 1.0, 1.0, 0.59375, 0.59375, 1.0, 0.59375, 1.0, 0.59375, 1.0, 0.59375, 0.59375, 0.6015625, 0.59375, 0.59375, 1.0, 1.0, 0.6015625, 0.59375, 0.6015625, 0.59375, 1.0, 1.0, 1.0, 1.0, 0.59375, 1.0, 1.0, 0.59375, 0.6015625, 0.59375, 0.59375, 1.0, 0.609375, 0.6015625, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 1.0, 1.0, 0.6015625, 1.0, 0.59375, 0.609375, 0.59375, 0.59375, 0.59375, 1.0, 0.59375, 0.59375, 1.0, 0.6015625, 0.59375, 1.0, 1.0, 1.0, 0.6015625, 1.0, 1.0, 1.0, 1.0, 0.59375, 1.0, 1.0, 0.59375, 0.59375, 0.6015625, 1.0, 1.0, 1.0, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 1.0, 0.59375, 1.0, 1.0, 1.0, 0.59375, 1.0, 0.6015625, 1.0, 1.0, 0.59375, 0.59375, 0.6015625, 1.0, 0.59375, 0.59375, 0.59375, 0.6015625, 1.0, 1.0, 0.59375, 0.6015625, 0.59375, 0.59375, 1.0, 1.0, 1.0, 1.0, 0.59375, 1.0, 1.0, 1.0, 0.59375, 1.0, 0.59375, 0.59375, 0.59375, 1.0, 0.6015625, 0.59375, 0.59375, 1.0, 0.59375, 0.609375, 1.0, 0.59375, 1.0, 1.0, 0.59375, 0.6015625, 0.59375, 0.59375, 0.6015625, 1.0, 1.0, 0.59375, 1.0, 0.609375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6015625, 0.6015625, 1.0, 0.59375, 0.59375, 0.609375, 0.59375, 1.0, 0.59375, 1.0, 1.0, 1.0, 0.59375, 1.0, 0.6015625, 0.6015625, 1.0, 0.6015625, 1.0, 0.59375, 0.59375, 1.0, 1.0, 1.0, 0.6015625, 0.59375, 1.0, 0.609375, 0.59375, 1.0, 0.6015625, 0.59375, 1.0, 0.59375, 1.0, 1.0, 1.0, 0.59375, 0.59375, 0.59375, 0.59375, 0.59375, 0.6015625, 1.0, 0.6015625, 1.0, 0.609375, 0.59375, 0.6015625, 1.0, 1.0, 0.59375, 0.609375]

 sparsity of   [1.0, 0.07421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1484375, 1.0, 0.0703125, 1.0, 0.0625, 1.0, 1.0, 0.07421875, 1.0, 1.0, 1.0, 1.0, 0.12890625, 0.0703125, 1.0, 0.09765625, 1.0, 1.0, 0.08203125, 1.0, 0.0703125, 0.05859375, 1.0, 1.0, 1.0, 0.06640625, 0.09765625, 0.06640625, 0.06640625, 0.0625, 1.0, 1.0, 1.0, 0.05859375, 1.0, 1.0, 0.0703125, 0.0625, 1.0, 0.1171875, 1.0, 1.0, 0.0703125, 1.0, 1.0, 0.078125, 0.0625, 0.06640625, 1.0, 1.0, 0.06640625, 0.109375, 0.06640625, 1.0, 0.25390625, 1.0, 1.0, 1.0, 0.06640625, 0.15625, 1.0, 1.0, 0.08984375, 0.0625, 0.0703125, 1.0, 0.0703125, 1.0, 1.0, 1.0, 0.07421875, 1.0, 0.0703125, 0.0625, 0.1171875, 1.0, 0.12109375, 0.1640625, 1.0, 1.0, 0.078125, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.05859375, 0.0703125, 0.0625, 0.0703125, 0.0703125, 0.12109375, 0.171875, 1.0, 1.0, 0.0703125, 0.06640625, 0.08203125, 0.203125, 1.0, 1.0, 0.07421875, 1.0, 1.0, 1.0, 0.06640625, 1.0, 0.13671875, 0.05859375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0703125, 0.10546875, 1.0, 0.07421875, 1.0, 0.05859375, 1.0, 1.0, 1.0, 0.08203125, 1.0, 0.07421875, 0.0703125, 0.0625, 0.0625, 0.0703125, 0.0625, 0.0625, 0.0625, 0.13671875, 0.08203125, 1.0, 1.0, 0.109375, 1.0, 1.0, 0.10546875, 0.05859375, 1.0, 0.09765625, 0.109375, 0.06640625, 0.09375, 1.0, 1.0, 1.0, 1.0, 0.05859375, 0.078125, 0.0625, 1.0, 0.0625, 1.0, 0.0703125, 0.0625, 0.09375, 1.0, 0.0703125, 1.0, 0.0625, 1.0, 0.1875, 0.15234375, 0.06640625, 0.0703125, 0.0625, 0.0703125, 1.0, 1.0, 0.06640625, 1.0, 1.0, 0.078125, 0.0703125, 1.0, 1.0, 0.05859375, 0.0625, 0.07421875, 1.0, 0.18359375, 1.0, 0.13671875, 1.0, 1.0, 0.08203125, 0.078125, 1.0, 1.0, 0.0625, 0.07421875, 0.14453125, 0.11328125, 1.0, 0.0703125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.078125, 1.0, 1.0, 0.06640625, 1.0, 0.140625, 1.0, 1.0, 0.05859375, 0.078125, 1.0, 0.1015625, 0.08203125, 0.11328125, 0.06640625, 0.18359375, 1.0, 1.0, 0.0625, 0.08984375, 0.0625, 0.08203125, 0.0625, 0.078125, 1.0, 1.0, 0.10546875, 0.08984375, 0.07421875, 0.0625, 1.0, 1.0, 1.0, 0.0703125, 0.06640625, 0.06640625, 0.0703125, 0.0703125, 1.0, 1.0, 0.06640625, 0.1015625, 0.06640625, 1.0, 0.0546875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08984375, 0.0625, 0.07421875, 1.0, 1.0, 0.19921875, 0.06640625, 1.0, 1.0, 1.0, 1.0, 0.06640625, 0.06640625, 0.0625, 1.0, 1.0, 0.08984375, 0.1171875, 1.0, 0.07421875, 1.0, 0.08203125, 1.0, 0.10546875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.05859375, 1.0, 1.0, 1.0, 1.0, 0.13671875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.125, 1.0, 1.0, 0.06640625, 0.0703125, 0.09375, 1.0, 1.0, 1.0, 1.0, 0.0625, 0.078125, 1.0, 0.078125, 1.0, 0.0625, 1.0, 0.0859375, 0.06640625, 0.07421875, 0.09375, 0.0859375, 1.0, 1.0, 0.55078125, 0.0859375, 0.06640625, 0.0546875, 1.0, 1.0, 1.0, 1.0, 0.078125, 1.0, 1.0, 0.0625, 0.06640625, 0.0546875, 0.125, 1.0, 0.13671875, 0.05859375, 0.18359375, 0.1796875, 0.0703125, 0.0625, 0.17578125, 0.0703125, 0.1484375, 0.06640625, 0.0703125, 0.07421875, 1.0, 1.0, 0.0625, 1.0, 0.14453125, 0.078125, 0.0625, 0.140625, 0.08984375, 1.0, 0.06640625, 0.06640625, 1.0, 0.06640625, 0.0703125, 1.0, 1.0, 1.0, 0.1328125, 1.0, 1.0, 0.0859375, 1.0, 0.0703125, 1.0, 1.0, 0.07421875, 0.0703125, 0.06640625, 1.0, 0.18359375, 1.0, 0.0703125, 0.15234375, 0.0625, 0.06640625, 0.07421875, 0.07421875, 0.1796875, 1.0, 0.12109375, 1.0, 1.0, 1.0, 0.05859375, 1.0, 0.06640625, 1.0, 1.0, 0.0625, 0.08203125, 0.0703125, 1.0, 0.0703125, 0.07421875, 0.08203125, 0.078125, 0.06640625, 1.0, 0.12890625, 0.05859375, 0.0703125, 0.0703125, 1.0, 1.0, 1.0, 1.0, 0.05859375, 1.0, 1.0, 1.0, 0.0625, 1.0, 0.078125, 0.1171875, 0.06640625, 1.0, 1.0, 0.0625, 0.07421875, 1.0, 0.125, 0.07421875, 1.0, 0.078125, 0.1171875, 1.0, 0.0625, 0.1015625, 0.05859375, 0.09375, 0.08203125, 1.0, 1.0, 0.0625, 1.0, 0.09375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0546875, 1.0, 1.0, 0.0625, 0.0703125, 0.0703125, 0.1484375, 1.0, 0.09375, 1.0, 1.0, 1.0, 0.07421875, 1.0, 0.08203125, 0.078125, 1.0, 0.0859375, 1.0, 0.0703125, 0.1328125, 1.0, 1.0, 1.0, 0.0703125, 0.1640625, 1.0, 0.05859375, 0.1875, 1.0, 0.05859375, 0.15234375, 1.0, 0.11328125, 1.0, 0.10546875, 1.0, 0.109375, 0.1875, 0.07421875, 0.109375, 0.0625, 0.09765625, 1.0, 0.078125, 1.0, 0.0625, 0.078125, 0.05859375, 1.0, 1.0, 0.07421875, 0.07421875]

 sparsity of   [1.0, 0.43359375, 1.0, 0.431640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.43359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.435546875, 1.0, 1.0, 1.0, 0.419921875, 1.0, 1.0, 1.0, 0.43359375, 0.43359375, 1.0, 1.0, 0.4375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.44140625, 1.0, 1.0, 1.0, 0.4375, 0.43359375, 0.421875, 1.0, 1.0, 1.0, 0.43359375, 1.0, 1.0, 1.0, 1.0, 0.427734375, 1.0, 0.439453125, 1.0, 0.43359375, 1.0, 0.4453125, 1.0, 1.0, 0.48828125, 0.4296875, 1.0, 1.0, 0.42578125, 0.4296875, 1.0, 0.4296875, 1.0, 1.0, 1.0, 0.443359375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4296875, 0.43359375, 0.42578125, 1.0, 0.43359375, 1.0, 1.0, 0.419921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4296875, 1.0, 1.0, 1.0, 0.435546875, 1.0, 1.0, 1.0, 0.42578125, 1.0, 0.4296875, 1.0, 0.44140625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.48046875, 1.0, 1.0, 0.423828125, 1.0, 1.0, 0.431640625, 1.0, 1.0, 1.0, 0.4296875]

 sparsity of   [0.7065972089767456, 1.0, 0.7092013955116272, 0.7144097089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7083333134651184, 0.7083333134651184, 1.0, 1.0, 1.0, 1.0, 0.7109375, 0.710069477558136, 0.7126736044883728, 0.710069477558136, 1.0, 1.0, 0.710069477558136, 1.0, 0.7769097089767456, 1.0, 1.0, 0.7664930820465088, 0.7734375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7144097089767456, 1.0, 0.7057291865348816, 0.7144097089767456, 0.7482638955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7473958134651184, 0.7109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.710069477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7083333134651184, 0.7074652910232544, 1.0, 0.7161458134651184, 0.7109375, 1.0, 0.7083333134651184, 1.0, 1.0, 1.0, 1.0, 0.7543402910232544, 0.7083333134651184, 1.0, 1.0, 0.710069477558136, 1.0, 0.7039930820465088, 1.0, 0.7109375, 1.0, 1.0, 1.0, 0.7057291865348816, 1.0, 0.7092013955116272, 1.0, 0.7170138955116272, 0.7951388955116272, 1.0, 1.0, 0.7048611044883728, 1.0, 0.7083333134651184, 1.0, 0.7074652910232544, 0.7126736044883728, 1.0, 1.0, 0.7135416865348816, 1.0, 1.0, 0.7743055820465088, 1.0, 1.0, 1.0, 1.0, 0.7065972089767456, 0.7083333134651184, 1.0, 0.7734375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 0.640625, 1.0, 0.640625, 0.6328125, 1.0, 1.0, 0.6328125, 1.0, 1.0, 1.0, 0.640625, 1.0, 0.640625, 0.640625, 0.6484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.640625, 0.6484375, 0.640625, 0.65625, 1.0, 1.0, 0.65625, 1.0, 1.0, 0.640625, 1.0, 1.0, 1.0, 0.640625, 0.640625, 0.6484375, 0.6484375, 0.640625, 1.0, 1.0, 0.640625, 0.6484375, 0.6484375, 1.0, 0.640625, 0.640625, 1.0, 0.640625, 0.6484375, 1.0, 1.0, 1.0, 1.0, 0.6484375, 0.640625, 1.0, 1.0, 1.0, 0.640625, 0.640625, 1.0, 1.0, 0.640625, 1.0, 0.640625, 0.640625, 0.640625, 0.640625, 1.0, 0.6328125, 0.640625, 0.6640625, 0.640625, 0.640625, 0.640625, 0.6484375, 0.6328125, 1.0, 0.6484375, 1.0, 0.65625, 0.6484375, 0.6328125, 1.0, 0.640625, 1.0, 0.640625, 1.0, 1.0, 0.640625, 1.0, 0.6484375, 0.640625, 1.0, 1.0, 0.6484375, 0.640625, 0.6484375, 0.640625, 1.0, 1.0, 1.0, 1.0, 0.640625, 1.0, 0.6484375, 0.640625, 1.0, 1.0, 0.640625, 1.0, 1.0, 1.0, 0.640625, 1.0, 0.640625, 0.6484375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.640625, 0.640625, 1.0, 0.640625, 0.640625, 0.6328125, 1.0, 1.0, 1.0, 0.640625, 1.0, 0.6484375, 0.640625, 0.6484375, 0.640625, 0.6484375, 0.640625, 0.640625, 0.640625, 0.640625, 0.640625, 1.0, 1.0, 0.671875, 1.0, 1.0, 0.640625, 0.640625, 0.640625, 1.0, 0.640625, 0.640625, 0.6328125, 1.0, 1.0, 1.0, 0.640625, 0.6328125, 0.640625, 0.640625, 0.640625, 0.6484375, 1.0, 0.65625, 0.6328125, 0.640625, 1.0, 1.0, 1.0, 0.6484375, 1.0, 0.640625, 0.640625, 0.6484375, 0.640625, 1.0, 0.6484375, 0.640625, 1.0, 0.6484375, 1.0, 0.6328125, 0.6484375, 1.0, 1.0, 1.0, 0.640625, 0.65625, 1.0, 1.0, 0.65625, 1.0, 1.0, 1.0, 1.0, 0.65625, 0.6484375, 1.0, 1.0, 0.640625, 0.640625, 0.640625, 0.6640625, 1.0, 0.640625, 0.6328125, 1.0, 1.0, 1.0, 1.0, 0.6328125, 1.0, 1.0, 0.640625, 1.0, 0.6484375, 1.0, 0.6328125, 1.0, 0.640625, 1.0, 1.0, 0.6484375, 1.0, 0.640625, 0.6484375, 0.6328125, 1.0, 1.0, 0.640625, 0.6484375, 0.6796875, 0.640625, 1.0, 1.0, 1.0, 0.640625, 1.0, 0.640625, 0.640625, 1.0, 1.0, 1.0, 0.640625, 1.0, 0.640625, 0.640625, 1.0, 1.0, 0.640625, 0.640625, 0.6484375, 0.640625, 1.0, 0.640625, 1.0, 1.0, 1.0, 0.6484375, 1.0, 0.640625, 1.0, 0.640625, 1.0, 1.0, 0.6328125, 0.640625, 1.0, 0.6484375, 1.0, 1.0, 0.65625, 0.6640625, 0.6484375, 1.0, 1.0, 0.640625, 0.640625, 1.0, 1.0, 0.640625, 1.0, 0.6484375, 0.640625, 1.0, 1.0, 1.0, 1.0, 0.640625, 0.640625, 0.640625, 1.0, 1.0, 0.6328125, 0.640625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.640625, 1.0, 1.0, 0.640625, 0.6328125, 0.65625, 0.640625, 1.0, 1.0, 0.640625, 1.0, 0.640625, 1.0, 0.640625, 0.640625, 0.640625, 1.0, 0.65625, 0.6484375, 0.640625, 0.640625, 0.640625, 1.0, 1.0, 1.0, 0.640625, 0.640625, 0.640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.65625, 0.65625, 0.640625, 0.640625, 0.6328125, 0.640625, 0.640625, 0.640625, 0.640625, 0.6328125, 0.6484375, 1.0, 0.6484375, 0.6484375, 0.640625, 0.640625, 0.6484375, 1.0, 1.0, 0.640625, 1.0, 0.6484375, 0.6640625, 0.640625, 0.6328125, 0.640625, 1.0, 0.6484375, 0.640625, 1.0, 1.0, 0.640625, 0.6484375, 1.0, 0.640625, 0.640625, 1.0, 1.0, 0.640625, 1.0, 0.6484375, 1.0, 1.0, 0.6484375, 0.640625, 0.640625, 1.0, 1.0, 1.0, 0.640625, 0.6484375, 0.640625, 1.0, 0.6484375, 0.640625, 0.640625, 1.0, 0.640625, 1.0, 1.0, 1.0, 0.6484375, 0.640625, 0.6484375, 1.0, 1.0, 0.640625, 0.6484375, 0.640625, 1.0, 1.0, 0.640625, 0.6328125, 0.640625, 1.0, 1.0, 1.0, 0.640625, 0.640625, 0.640625, 0.640625, 1.0, 1.0, 0.640625, 0.6484375, 1.0, 1.0, 0.6484375, 0.6484375, 1.0, 1.0, 0.640625, 0.6484375, 1.0, 0.640625, 0.640625, 0.6484375, 1.0, 1.0, 0.640625, 1.0, 0.6484375, 1.0, 1.0, 0.65625, 0.6484375, 0.65625, 0.640625, 1.0, 1.0, 0.6484375, 0.640625, 1.0, 0.640625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.65625, 0.640625, 0.640625, 1.0, 0.640625, 0.640625, 0.6328125, 1.0, 0.6484375, 1.0, 1.0, 1.0, 0.640625, 1.0, 0.6484375, 0.640625, 1.0, 0.6328125, 1.0, 0.640625, 0.65625, 1.0, 0.6484375, 1.0, 0.6328125, 1.0, 0.6484375, 0.640625, 1.0, 1.0, 1.0, 0.640625, 0.640625, 0.6484375, 1.0, 0.640625, 0.6328125, 0.640625, 0.640625, 0.640625, 0.6640625, 0.65625, 0.640625, 1.0, 0.640625, 1.0, 0.640625, 0.640625, 0.6328125, 1.0, 0.640625, 0.640625, 0.640625]

 sparsity of   [0.33984375, 0.337890625, 0.3359375, 0.3359375, 0.333984375, 0.333984375, 0.328125, 1.0, 0.333984375, 0.328125, 1.0, 0.33203125, 1.0, 0.328125, 1.0, 0.330078125, 0.3359375, 0.337890625, 1.0, 0.33984375, 1.0, 1.0, 0.33203125, 1.0, 0.333984375, 0.328125, 0.330078125, 0.33984375, 1.0, 1.0, 0.337890625, 0.337890625, 1.0, 1.0, 0.33203125, 0.330078125, 1.0, 0.328125, 1.0, 1.0, 1.0, 1.0, 0.32421875, 0.330078125, 1.0, 1.0, 1.0, 0.33984375, 1.0, 0.337890625, 0.33984375, 0.337890625, 0.33203125, 1.0, 0.333984375, 0.328125, 0.32421875, 0.330078125, 0.330078125, 0.3359375, 1.0, 0.333984375, 1.0, 0.33984375, 1.0, 1.0, 0.34765625, 1.0, 0.32421875, 1.0, 0.33203125, 1.0, 0.337890625, 0.353515625, 0.375, 1.0, 1.0, 0.330078125, 1.0, 0.337890625, 0.333984375, 1.0, 0.345703125, 1.0, 0.33984375, 0.326171875, 1.0, 0.328125, 1.0, 1.0, 0.40234375, 0.33984375, 0.33203125, 0.3359375, 1.0, 0.3359375, 0.33984375, 0.33203125, 1.0, 0.33984375, 1.0, 0.333984375, 0.33203125, 0.33203125, 0.330078125, 1.0, 1.0, 1.0, 0.330078125, 0.330078125, 1.0, 0.337890625, 0.32421875, 1.0, 0.330078125, 1.0, 0.345703125, 0.607421875, 0.330078125, 0.3359375, 0.330078125, 1.0, 0.337890625, 0.33984375, 0.328125, 1.0, 1.0, 0.33203125]

 sparsity of   [1.0, 0.3715277910232544, 0.3663194477558136, 1.0, 1.0, 1.0, 0.3715277910232544, 0.3680555522441864, 0.3689236044883728, 1.0, 1.0, 1.0, 0.3715277910232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3602430522441864, 0.3663194477558136, 1.0, 1.0, 0.3602430522441864, 1.0, 1.0, 0.3663194477558136, 0.3741319477558136, 1.0, 1.0, 1.0, 1.0, 0.3585069477558136, 0.3767361044883728, 1.0, 1.0, 1.0, 1.0, 0.3663194477558136, 0.362847238779068, 1.0, 1.0, 0.3611111044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 0.362847238779068, 0.3619791567325592, 0.3715277910232544, 0.3671875, 0.3611111044883728, 0.362847238779068, 0.3689236044883728, 0.3602430522441864, 1.0, 0.362847238779068, 1.0, 0.3645833432674408, 1.0, 0.3576388955116272, 0.3689236044883728, 1.0, 0.3585069477558136, 0.3619791567325592, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3697916567325592, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3645833432674408, 1.0, 1.0, 0.3619791567325592, 1.0, 0.3663194477558136, 0.3732638955116272, 1.0, 0.3611111044883728, 0.3680555522441864, 1.0, 1.0, 0.3611111044883728, 1.0, 1.0, 0.3619791567325592, 0.3671875, 0.3645833432674408, 0.378472238779068, 0.3671875, 1.0, 1.0, 0.3637152910232544, 1.0, 0.370659738779068, 0.3637152910232544, 1.0, 0.3723958432674408, 1.0, 1.0, 1.0, 0.375, 0.3671875, 1.0, 0.3602430522441864, 1.0, 1.0, 1.0, 1.0, 0.3758680522441864, 1.0, 0.3723958432674408, 1.0, 1.0, 0.3645833432674408, 1.0, 0.3654513955116272, 1.0, 0.362847238779068]

 sparsity of   [0.5625, 0.5703125, 1.0, 0.578125, 0.578125, 1.0, 0.578125, 0.5703125, 0.5546875, 0.5625, 1.0, 0.5859375, 0.5703125, 0.5625, 0.5625, 0.5625, 0.578125, 1.0, 0.5546875, 0.5703125, 1.0, 1.0, 0.5625, 0.5625, 0.5625, 0.5703125, 0.5703125, 1.0, 1.0, 0.578125, 1.0, 0.5625, 0.578125, 1.0, 1.0, 0.5546875, 0.5625, 0.5703125, 0.546875, 0.5703125, 0.5703125, 0.5625, 1.0, 0.5703125, 0.546875, 1.0, 0.5703125, 0.5625, 0.5703125, 1.0, 0.578125, 0.5859375, 1.0, 0.5625, 1.0, 1.0, 0.5703125, 0.5703125, 0.5703125, 0.5546875, 1.0, 0.5625, 0.5703125, 0.5546875, 0.5546875, 0.5703125, 0.5546875, 1.0, 1.0, 0.5703125, 0.5625, 1.0, 0.5703125, 0.5625, 0.5625, 0.5625, 0.5703125, 0.5703125, 1.0, 0.5703125, 0.5625, 0.5703125, 0.5625, 0.5625, 0.5546875, 0.5703125, 0.578125, 0.5625, 0.5625, 0.5703125, 1.0, 0.5703125, 1.0, 0.5546875, 0.5625, 1.0, 0.5625, 0.5625, 0.5546875, 0.5546875, 0.5703125, 0.5703125, 1.0, 1.0, 0.5546875, 0.5703125, 0.5703125, 0.546875, 0.5625, 0.578125, 0.5703125, 0.5703125, 0.5625, 0.5546875, 1.0, 0.5625, 0.5703125, 0.5703125, 0.5703125, 0.546875, 1.0, 0.5546875, 0.5703125, 1.0, 1.0, 0.5703125, 0.578125, 0.546875, 1.0, 1.0, 0.5390625, 0.546875, 0.5625, 1.0, 0.5703125, 1.0, 0.5703125, 0.578125, 0.5625, 0.5703125, 0.5625, 0.5625, 0.5703125, 0.5625, 0.578125, 0.5703125, 1.0, 1.0, 0.578125, 1.0, 1.0, 0.5625, 0.5625, 1.0, 1.0, 0.5625, 0.5546875, 0.5703125, 1.0, 0.5546875, 1.0, 0.5703125, 0.5625, 0.578125, 0.5703125, 1.0, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.5625, 0.5546875, 0.5625, 1.0, 0.5703125, 1.0, 1.0, 0.578125, 0.5546875, 0.5625, 0.5625, 0.5703125, 0.578125, 0.5703125, 0.546875, 0.5546875, 0.5703125, 0.5703125, 0.5625, 1.0, 1.0, 0.5703125, 0.5703125, 0.5703125, 0.5546875, 0.5546875, 0.5625, 1.0, 1.0, 1.0, 0.5625, 0.546875, 0.5703125, 0.5546875, 0.5625, 0.578125, 0.5546875, 0.5703125, 0.5546875, 0.5546875, 0.5625, 0.5546875, 1.0, 0.5625, 0.5703125, 0.5625, 1.0, 1.0, 0.5625, 0.5625, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.578125, 1.0, 0.5625, 0.5546875, 1.0, 0.5625, 0.5703125, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625, 0.578125, 0.5703125, 0.5703125, 0.59375, 0.578125, 0.5546875, 1.0, 0.5625, 0.578125, 0.5625, 0.5546875, 0.5703125, 0.5703125, 0.5625, 0.5546875, 1.0, 0.5625, 0.546875, 0.5625, 0.5546875, 0.546875, 1.0, 1.0, 1.0, 0.5625, 0.5625, 0.5703125, 0.578125, 0.5703125, 1.0, 0.5625, 0.5625, 0.5703125, 0.5546875, 0.578125, 0.5703125, 1.0, 0.5546875, 0.5625, 0.5625, 0.5703125, 1.0, 0.5625, 0.578125, 0.5625, 0.5703125, 0.5703125, 0.5625, 1.0, 0.5703125, 1.0, 1.0, 0.5625, 1.0, 0.5546875, 0.546875, 0.5625, 0.71875, 0.5625, 0.5703125, 0.578125, 1.0, 1.0, 0.5625, 1.0, 1.0, 1.0, 0.5703125, 1.0, 0.5625, 0.5625, 0.5625, 0.578125, 1.0, 0.5625, 1.0, 0.5703125, 0.5703125, 0.5625, 0.59375, 0.59375, 0.5703125, 0.5625, 0.5625, 0.5625, 0.5703125, 0.5703125, 0.5703125, 1.0, 0.5625, 0.5625, 0.5625, 0.5703125, 0.5703125, 0.5546875, 1.0, 1.0, 0.5703125, 0.5703125, 0.578125, 0.5703125, 0.5625, 0.5703125, 0.578125, 0.5625, 0.5703125, 0.5625, 0.5546875, 0.5625, 0.5546875, 0.578125, 0.5546875, 0.5703125, 0.5625, 0.5703125, 0.5625, 0.5546875, 0.5703125, 0.5546875, 1.0, 0.5703125, 1.0, 0.5703125, 0.5703125, 0.5625, 0.5703125, 0.5703125, 1.0, 0.5546875, 0.5625, 1.0, 0.5703125, 0.5703125, 1.0, 1.0, 0.5546875, 0.5546875, 0.5625, 0.5546875, 1.0, 0.5625, 0.578125, 1.0, 1.0, 0.5625, 0.5625, 0.5546875, 0.5703125, 1.0, 0.5546875, 0.5625, 0.578125, 0.5546875, 0.5625, 0.5625, 0.5546875, 0.5703125, 1.0, 0.5703125, 1.0, 1.0, 0.5546875, 0.5625, 0.5703125, 0.5703125, 1.0, 0.5546875, 0.5625, 0.5546875, 0.5625, 0.5546875, 0.5703125, 0.5546875, 0.5625, 0.5625, 0.5546875, 0.5703125, 0.578125, 0.5625, 0.5703125, 0.5703125, 0.5703125, 1.0, 0.5703125, 0.578125, 0.5703125, 1.0, 1.0, 0.5625, 0.5703125, 1.0, 1.0, 0.5625, 0.5625, 1.0, 1.0, 0.5625, 0.5703125, 0.5546875, 1.0, 0.5703125, 1.0, 0.5625, 1.0, 0.5625, 0.5546875, 0.5703125, 0.578125, 0.5703125, 0.5625, 0.546875, 0.578125, 0.5625, 0.5703125, 0.5703125, 1.0, 1.0, 0.5703125, 0.5546875, 0.5546875, 0.578125, 0.5546875, 0.546875, 0.5703125, 0.5625, 0.5625, 0.578125, 0.5546875, 0.5625, 1.0, 1.0, 0.5703125, 0.5625, 1.0, 1.0, 0.5703125, 0.5703125, 0.5625, 0.5546875, 0.5546875, 0.5625, 0.546875, 0.5703125, 0.546875, 0.5625, 0.5703125, 1.0, 0.5625, 0.5625, 0.5625, 0.609375, 0.5703125, 0.5703125, 0.5625, 0.5703125, 0.578125, 0.5625, 0.5703125, 0.578125, 0.5625, 0.5703125, 0.5703125, 0.5546875, 0.5703125, 0.5625, 1.0, 0.5546875, 0.5625, 0.578125, 1.0, 0.5625, 0.5703125, 0.5625]

 sparsity of   [1.0, 0.15234375, 1.0, 0.166015625, 0.1640625, 0.162109375, 0.15625, 1.0, 0.15234375, 0.16015625, 0.15234375, 1.0, 0.158203125, 0.162109375, 1.0, 1.0, 0.166015625, 0.162109375, 1.0, 1.0, 1.0, 0.15234375, 0.162109375, 1.0, 0.15625, 1.0, 0.15625, 0.15625, 0.15625, 0.166015625, 0.15625, 0.158203125, 1.0, 0.150390625, 0.162109375, 1.0, 0.158203125, 1.0, 1.0, 0.16015625, 0.158203125, 1.0, 1.0, 0.16015625, 1.0, 1.0, 0.15625, 0.166015625, 0.16015625, 1.0, 0.154296875, 1.0, 1.0, 0.1640625, 0.15625, 0.15625, 1.0, 1.0, 0.162109375, 0.16796875, 0.158203125, 0.16015625, 0.158203125, 1.0, 0.162109375, 1.0, 0.158203125, 0.154296875, 0.158203125, 1.0, 0.15625, 0.15625, 1.0, 1.0, 0.16796875, 1.0, 0.158203125, 1.0, 1.0, 0.16796875, 0.15625, 1.0, 1.0, 0.16015625, 0.171875, 0.16015625, 0.16015625, 0.154296875, 1.0, 0.154296875, 0.1640625, 0.166015625, 0.158203125, 1.0, 1.0, 0.15625, 0.169921875, 0.162109375, 0.177734375, 1.0, 0.16015625, 1.0, 0.158203125, 0.15625, 0.162109375, 0.154296875, 0.15625, 0.15625, 1.0, 1.0, 0.17578125, 0.158203125, 0.15234375, 0.158203125, 1.0, 0.1640625, 1.0, 1.0, 0.15234375, 0.162109375, 1.0, 1.0, 0.166015625, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 0.3923611044883728, 1.0, 1.0, 1.0, 0.3949652910232544, 0.3958333432674408, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3958333432674408, 0.394097238779068, 1.0, 1.0, 0.394097238779068, 1.0, 1.0, 1.0, 0.3932291567325592, 0.3967013955116272, 0.3923611044883728, 0.4001736044883728, 1.0, 1.0, 0.3975694477558136, 1.0, 0.394097238779068, 0.3932291567325592, 1.0, 0.394097238779068, 0.3923611044883728, 0.394097238779068, 1.0, 1.0, 1.0, 0.3984375, 1.0, 0.3932291567325592, 0.3914930522441864, 0.3984375, 1.0, 1.0, 1.0, 0.394097238779068, 0.394097238779068, 1.0, 1.0, 0.3888888955116272, 0.394097238779068, 0.3993055522441864, 1.0, 0.3949652910232544, 0.3958333432674408, 0.3897569477558136, 1.0, 0.3932291567325592, 1.0, 0.3975694477558136, 0.394097238779068, 0.3932291567325592, 1.0, 1.0, 0.3932291567325592, 1.0, 0.3967013955116272, 0.3975694477558136, 1.0, 0.3949652910232544, 1.0, 1.0, 1.0, 1.0, 0.3932291567325592, 0.3958333432674408, 0.3949652910232544, 1.0, 1.0, 0.3949652910232544, 0.4053819477558136, 0.3932291567325592, 1.0, 0.390625, 1.0, 0.3914930522441864, 1.0, 1.0, 1.0, 0.3932291567325592, 1.0, 0.3923611044883728, 0.3949652910232544, 1.0, 1.0, 0.3984375, 1.0, 0.3932291567325592, 0.3993055522441864, 1.0, 1.0, 0.3984375, 0.3932291567325592, 0.3967013955116272, 1.0, 0.3949652910232544, 0.3967013955116272, 1.0, 0.3967013955116272, 1.0, 1.0, 0.3967013955116272, 0.3975694477558136, 1.0, 1.0, 0.3967013955116272, 1.0, 1.0, 0.3958333432674408, 0.394097238779068, 0.3967013955116272, 0.3949652910232544, 1.0, 1.0, 1.0]

 sparsity of   [0.5078125, 1.0, 0.5, 0.5078125, 0.5078125, 1.0, 0.515625, 0.4921875, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.5, 0.5078125, 1.0, 0.5, 1.0, 1.0, 0.5, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625, 0.5078125, 0.5, 0.4921875, 1.0, 0.5, 0.5078125, 1.0, 1.0, 1.0, 0.5234375, 0.5, 0.5, 0.5078125, 0.5078125, 0.4921875, 1.0, 0.5078125, 0.5, 0.515625, 0.5, 0.5078125, 0.5234375, 1.0, 0.5, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5234375, 0.5078125, 0.5078125, 0.5, 0.515625, 0.4921875, 0.5, 0.5, 0.5078125, 0.5, 0.5, 0.5078125, 0.5078125, 0.5, 0.5, 0.5078125, 0.5078125, 0.5078125, 0.5, 0.5234375, 0.5078125, 0.5078125, 0.5, 0.5234375, 0.5, 0.5, 0.5078125, 1.0, 0.5078125, 0.5, 0.5078125, 0.5, 0.5, 0.5078125, 0.5, 0.515625, 0.515625, 1.0, 0.515625, 0.5, 0.5, 0.5078125, 0.4921875, 0.59375, 0.5078125, 1.0, 0.5078125, 0.4921875, 0.5, 0.515625, 0.5, 1.0, 0.4921875, 0.5, 0.515625, 0.5, 0.5, 0.5078125, 1.0, 0.515625, 0.5078125, 1.0, 0.5078125, 0.53125, 0.5078125, 0.4921875, 0.5078125, 0.5234375, 0.4921875, 0.5078125, 1.0, 0.5, 0.5078125, 0.5, 0.5, 0.5078125, 0.5, 0.5, 0.5078125, 0.5, 0.515625, 0.5078125, 0.5078125, 0.5078125, 0.515625, 0.5, 0.5078125, 0.5078125, 1.0, 0.5, 0.5, 0.5078125, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5078125, 0.5078125, 0.5390625, 0.4921875, 0.5078125, 0.5, 0.5, 0.5, 0.515625, 0.5078125, 0.5, 0.5, 0.5, 0.5234375, 0.5, 0.5, 0.5078125, 1.0, 0.5, 0.5, 0.5078125, 0.515625, 0.515625, 0.5078125, 0.5078125, 0.4921875, 0.5, 0.5078125, 0.5, 0.5234375, 0.5, 0.5, 0.5078125, 1.0, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.4921875, 0.5078125, 0.4921875, 0.5078125, 1.0, 0.5078125, 0.4921875, 0.515625, 0.4921875, 0.5078125, 0.5078125, 0.5, 0.515625, 0.5234375, 0.5078125, 0.5078125, 0.4921875, 0.5, 1.0, 0.5, 0.5, 0.5078125, 0.5, 0.5, 0.5, 0.4921875, 0.5, 1.0, 0.5078125, 0.5, 0.515625, 1.0, 0.5, 0.5078125, 0.5, 0.5, 0.5078125, 0.4921875, 1.0, 0.5, 0.5, 0.5078125, 0.515625, 0.5078125, 0.4921875, 1.0, 1.0, 0.5, 0.515625, 0.4921875, 0.5, 0.515625, 0.4921875, 0.5, 0.5078125, 0.5078125, 0.5078125, 0.53125, 0.5, 0.5, 0.5078125, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.5, 0.4921875, 0.5078125, 1.0, 0.5, 0.5078125, 0.4921875, 0.515625, 0.5078125, 0.5, 0.4921875, 0.5078125, 0.5078125, 0.5, 0.5078125, 0.5078125, 1.0, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 1.0, 0.5, 0.5, 1.0, 0.5078125, 0.5078125, 0.5078125, 0.5, 0.5078125, 0.5, 0.4921875, 0.5, 1.0, 0.4921875, 0.5, 0.5078125, 1.0, 1.0, 0.5078125, 0.5078125, 0.6171875, 0.4921875, 0.5, 0.5078125, 0.5078125, 1.0, 0.515625, 1.0, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.5, 0.5, 0.515625, 0.5078125, 0.5, 0.5, 0.5078125, 0.5, 0.5078125, 0.4921875, 0.5, 0.5078125, 0.515625, 0.5078125, 0.5078125, 0.515625, 0.5234375, 0.5078125, 0.4921875, 0.4921875, 0.5078125, 0.5078125, 0.5, 1.0, 0.5078125, 0.5078125, 1.0, 1.0, 0.5078125, 0.5, 0.5, 0.4921875, 0.5078125, 0.5, 0.5078125, 0.515625, 0.4921875, 0.5234375, 0.5078125, 0.5078125, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.4921875, 0.5, 0.5078125, 0.515625, 0.4921875, 0.5078125, 0.5, 0.5, 0.5, 0.5234375, 0.5078125, 0.515625, 0.515625, 0.5078125, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.515625, 0.5, 0.515625, 0.515625, 0.5, 0.4921875, 1.0, 0.5234375, 0.5078125, 0.5, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.5, 0.5078125, 1.0, 0.5078125, 1.0, 1.0, 0.5078125, 0.5234375, 0.5, 0.5078125, 0.5, 0.5, 0.4921875, 0.4921875, 0.5078125, 0.5, 0.5078125, 0.5, 0.5078125, 0.5078125, 0.4921875, 1.0, 0.5078125, 0.5, 0.5078125, 0.5, 0.5, 0.515625, 1.0, 0.515625, 0.515625, 0.5, 1.0, 0.5, 0.5078125, 0.5, 0.4921875, 0.5, 0.515625, 0.4921875, 0.5078125, 0.5, 0.5, 0.5078125, 0.515625, 0.5, 0.5078125, 0.5078125, 1.0, 0.5078125, 0.515625, 0.4921875, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 1.0, 0.5078125, 0.5078125, 0.5078125, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5078125, 0.5, 0.5, 0.5078125, 0.5078125, 0.4921875, 0.5, 0.5078125, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 1.0, 0.5078125, 0.5, 0.5, 0.5234375, 0.5078125, 0.515625, 0.5078125, 0.5, 0.5, 0.5, 0.515625, 0.5, 0.5078125, 1.0, 0.515625, 0.5, 0.5078125, 0.5078125, 0.4921875, 0.5078125, 0.5, 0.5, 0.515625, 0.515625, 0.5078125, 0.5234375, 0.5078125, 0.5078125, 0.515625, 0.5078125, 0.5078125, 0.4921875, 0.5, 0.5078125, 1.0, 0.515625, 0.515625, 0.5]

 sparsity of   [0.056640625, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.06640625, 1.0, 0.05859375, 0.0625, 0.0625, 1.0, 0.05859375, 0.0625, 1.0, 0.056640625, 1.0, 0.0625, 1.0, 0.064453125, 1.0, 0.0546875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0546875, 1.0, 0.056640625, 0.056640625, 1.0, 0.0546875, 0.064453125, 0.0546875, 1.0, 0.05078125, 1.0, 0.0625, 0.060546875, 0.05859375, 1.0, 1.0, 0.056640625, 0.05859375, 1.0, 1.0, 0.05859375, 0.052734375, 0.05859375, 1.0, 1.0, 1.0, 0.060546875, 0.06640625, 0.05078125, 0.0625, 0.056640625, 0.056640625, 0.056640625, 0.0625, 1.0, 1.0, 1.0, 0.0546875, 0.056640625, 0.056640625, 1.0, 0.056640625, 0.05859375, 1.0, 0.056640625, 0.0546875, 0.0625, 0.0546875, 0.068359375, 1.0, 1.0, 0.05859375, 0.068359375, 0.056640625, 1.0, 1.0, 0.05859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.056640625, 0.056640625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.056640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.060546875, 1.0, 1.0, 0.05078125, 0.0546875, 1.0, 1.0, 1.0, 0.0546875, 0.05078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0546875, 0.080078125, 0.056640625, 1.0, 0.056640625, 0.05859375, 0.068359375, 0.05859375, 0.056640625, 1.0, 0.05859375, 0.052734375, 0.060546875, 0.0625, 0.0546875, 1.0, 0.0625, 1.0, 1.0, 1.0, 1.0, 0.05859375, 0.0546875, 1.0, 1.0, 1.0, 0.056640625, 0.0625, 0.064453125, 1.0, 0.056640625, 0.052734375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0546875, 1.0, 0.060546875, 0.056640625, 0.05859375, 0.05859375, 0.052734375, 0.052734375, 1.0, 0.05859375, 1.0, 1.0, 0.060546875, 1.0, 0.0546875, 0.056640625, 1.0, 0.05859375, 1.0, 0.05859375, 0.056640625, 1.0, 1.0, 0.0625, 1.0, 0.060546875, 1.0, 0.05859375, 0.060546875, 1.0, 1.0, 0.0546875, 1.0, 1.0, 0.060546875, 1.0, 0.064453125, 0.05078125, 0.05859375, 0.052734375, 0.060546875, 1.0, 0.0546875, 0.056640625, 0.056640625, 0.060546875, 1.0, 0.056640625, 0.05859375, 1.0, 1.0, 0.0625, 0.0546875, 1.0, 1.0, 1.0, 0.052734375, 1.0, 0.05859375, 1.0, 1.0, 0.052734375, 1.0, 1.0, 0.0546875, 0.05859375, 0.05859375, 0.05859375, 0.052734375, 0.05859375, 1.0, 0.056640625, 1.0, 1.0, 0.060546875, 1.0, 1.0, 1.0, 1.0, 0.064453125, 0.060546875, 0.05859375, 0.0625, 0.056640625, 0.056640625, 1.0, 0.05859375, 1.0, 0.05859375, 1.0, 0.060546875, 0.0625, 0.0546875, 0.0546875, 0.060546875, 1.0, 0.05859375, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4713541567325592, 1.0, 1.0, 1.0, 0.4713541567325592, 1.0, 1.0, 1.0, 0.4817708432674408, 1.0, 1.0, 1.0, 0.4713541567325592, 1.0, 1.0, 1.0, 0.4704861044883728, 1.0, 1.0, 1.0, 0.4743923544883728, 1.0, 1.0, 1.0, 0.47265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4704861044883728, 1.0, 1.0, 1.0, 0.4713541567325592, 0.4700520932674408, 0.4713541567325592, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4717881977558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.472222238779068, 1.0, 0.4713541567325592, 1.0, 0.4704861044883728, 0.472222238779068, 1.0, 0.4709201455116272, 1.0, 1.0, 0.4709201455116272, 1.0, 1.0, 1.0, 0.4735243022441864, 0.4717881977558136, 1.0, 1.0, 1.0, 0.468315988779068, 1.0, 1.0, 1.0, 0.4713541567325592, 0.4704861044883728, 1.0, 0.47265625, 1.0, 1.0, 0.472222238779068, 1.0, 1.0, 1.0, 0.4704861044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.472222238779068, 1.0, 1.0, 1.0, 1.0, 0.4717881977558136, 1.0, 1.0, 1.0, 1.0, 0.468315988779068, 0.47265625, 0.4691840410232544, 0.4696180522441864, 0.4700520932674408, 1.0, 1.0, 1.0, 0.4713541567325592, 0.4730902910232544, 0.4717881977558136, 0.472222238779068, 0.4717881977558136, 1.0, 1.0, 0.47265625, 1.0, 1.0, 1.0, 0.468315988779068, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4691840410232544, 1.0, 1.0, 0.4717881977558136, 1.0, 1.0, 0.4730902910232544, 0.4700520932674408, 1.0, 1.0, 1.0, 1.0, 0.47265625, 1.0, 1.0, 0.4730902910232544, 1.0, 0.4748263955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4713541567325592, 1.0, 0.4691840410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4696180522441864, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4709201455116272, 1.0, 0.4713541567325592, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.472222238779068, 1.0, 1.0, 0.4735243022441864, 0.4696180522441864, 1.0, 1.0, 1.0, 0.4713541567325592, 0.4709201455116272, 0.4709201455116272, 0.4713541567325592, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4713541567325592, 1.0, 1.0, 0.4717881977558136, 1.0, 0.4713541567325592, 1.0, 0.472222238779068, 1.0, 1.0, 1.0, 0.472222238779068, 1.0, 0.472222238779068, 1.0, 1.0, 1.0, 1.0, 0.4709201455116272, 1.0, 1.0, 1.0, 0.472222238779068, 1.0, 0.4691840410232544, 1.0, 0.4700520932674408, 1.0, 1.0, 0.472222238779068, 1.0, 0.4735243022441864, 1.0]

 sparsity of   [0.7265625, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 0.7265625, 0.7265625, 0.7421875, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.7265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 0.7265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.7265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 0.7265625, 0.7265625, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.7265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.7265625, 0.72265625, 1.0, 0.7265625, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.7265625, 1.0, 0.72265625, 1.0, 0.7265625, 1.0, 0.73046875, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.7265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.7265625, 1.0, 0.7265625, 0.7265625, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.7265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.7265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.73046875, 0.7265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 0.734375, 1.0, 1.0, 1.0, 1.0, 0.7265625, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.7265625, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.7265625, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.7265625, 0.72265625, 0.7265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.7265625, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.73046875, 0.7265625, 1.0, 0.7265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.7265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.7265625, 1.0, 0.7265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.7265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.7265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.7265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.7265625, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.73046875, 1.0, 0.7265625, 0.72265625, 1.0, 0.72265625, 0.7265625, 0.72265625, 1.0, 1.0, 0.7265625, 1.0, 0.734375, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.7265625, 1.0, 0.7265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 0.7265625, 0.72265625, 0.72265625, 0.72265625, 0.7265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 0.7265625, 0.734375, 0.7265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.7265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.7265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 0.73828125, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.7265625, 0.7265625, 1.0, 0.72265625, 0.73046875, 0.72265625, 0.7265625, 0.72265625, 1.0, 0.7265625, 0.72265625, 1.0, 0.7265625, 0.72265625, 0.7265625, 0.72265625, 0.72265625, 0.73046875, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.73046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.7265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 0.7265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 0.7265625, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 0.7265625, 0.734375, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.73046875, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.7265625, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.7265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 0.7265625, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.7265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.7265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.7265625, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.7421875, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.796875, 0.7265625, 0.72265625, 0.72265625, 0.72265625, 0.7265625, 0.72265625, 0.72265625, 0.72265625, 0.7265625, 0.72265625, 0.734375, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.7265625, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.7265625, 0.72265625, 1.0, 0.72265625, 1.0, 0.73046875, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 0.7265625, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.75, 1.0, 0.7265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.7265625, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.7265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.7265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.7265625, 0.72265625, 0.7265625, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.7265625, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 0.7265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 0.72265625, 0.72265625, 1.0, 0.7265625, 0.72265625, 0.72265625, 1.0, 1.0, 0.7265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 0.7265625, 0.73046875, 0.72265625, 0.7265625, 1.0, 1.0, 1.0, 1.0, 0.72265625, 0.72265625, 0.72265625, 1.0, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 0.7265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.7265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 0.7265625, 0.72265625, 0.72265625, 0.7265625, 1.0, 1.0, 0.7265625, 0.72265625, 1.0, 1.0, 0.7265625, 1.0, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 0.72265625, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 1.0, 0.72265625, 1.0, 0.7265625, 0.72265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.078125, 1.0, 0.064453125, 1.0, 0.076171875, 1.0, 0.06640625, 0.0703125, 1.0, 0.060546875, 1.0, 1.0, 1.0, 1.0, 0.072265625, 0.068359375, 0.11328125, 1.0, 0.080078125, 1.0, 0.0703125, 1.0, 1.0, 1.0, 1.0, 0.064453125, 1.0, 1.0, 0.072265625, 1.0, 0.064453125, 0.0703125, 1.0, 0.0703125, 0.0703125, 0.0625, 1.0, 1.0, 1.0, 1.0, 0.068359375, 0.0625, 0.0625, 1.0, 0.064453125, 0.0703125, 1.0, 0.0859375, 1.0, 0.064453125, 1.0, 0.072265625, 0.06640625, 1.0, 1.0, 0.080078125, 0.05859375, 1.0, 0.060546875, 1.0, 1.0, 0.064453125, 1.0, 0.06640625, 1.0, 0.078125, 0.06640625, 0.0703125, 0.0703125, 0.0703125, 0.0625, 1.0, 0.08203125, 1.0, 0.060546875, 0.12109375, 0.064453125, 1.0, 0.060546875, 1.0, 1.0, 1.0, 1.0, 0.05859375, 0.158203125, 1.0, 1.0, 0.068359375, 0.06640625, 1.0, 0.064453125, 1.0, 0.05859375, 1.0, 0.06640625, 0.228515625, 1.0, 1.0, 1.0, 1.0, 0.0625, 0.072265625, 0.0703125, 0.06640625, 0.0703125, 0.060546875, 1.0, 1.0, 1.0, 0.072265625, 1.0, 0.068359375, 1.0, 0.060546875, 0.0703125, 1.0, 0.068359375, 1.0, 0.064453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.083984375, 0.072265625, 1.0, 1.0, 1.0, 0.06640625, 1.0, 0.06640625, 1.0, 0.0703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.068359375, 1.0, 1.0, 1.0, 0.060546875, 1.0, 1.0, 0.0703125, 0.078125, 0.068359375, 1.0, 0.06640625, 1.0, 1.0, 0.072265625, 0.076171875, 1.0, 0.06640625, 0.060546875, 0.060546875, 1.0, 1.0, 0.060546875, 1.0, 0.060546875, 1.0, 0.060546875, 1.0, 1.0, 0.0625, 0.064453125, 0.08984375, 0.0625, 1.0, 0.08984375, 1.0, 0.0625, 0.060546875, 1.0, 0.072265625, 0.07421875, 0.09375, 0.064453125, 1.0, 1.0, 0.060546875, 1.0, 1.0, 0.0703125, 1.0, 1.0, 1.0, 1.0, 0.0703125, 1.0, 0.06640625, 1.0, 1.0, 0.056640625, 1.0, 1.0, 0.0703125, 0.0625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.060546875, 1.0, 1.0, 1.0, 0.06640625, 1.0, 1.0, 0.076171875, 0.06640625, 1.0, 1.0, 0.06640625, 1.0, 1.0, 0.068359375, 0.06640625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.060546875, 0.06640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.068359375, 0.0625, 1.0, 0.0546875, 0.0859375, 0.060546875, 0.0703125, 0.0625, 0.068359375, 0.068359375, 1.0, 1.0, 1.0, 0.072265625, 1.0, 1.0, 1.0, 0.06640625, 1.0, 0.0625, 1.0, 0.0625, 1.0, 1.0, 1.0, 0.05859375, 1.0, 1.0, 0.060546875, 1.0, 1.0, 0.05859375, 0.068359375, 1.0, 0.0703125, 0.0703125, 0.099609375, 0.07421875, 1.0, 0.06640625, 1.0, 1.0, 1.0, 1.0, 0.0625, 0.076171875, 0.07421875, 1.0, 1.0, 0.060546875, 1.0, 1.0, 0.072265625, 0.095703125, 1.0, 0.158203125, 0.0703125, 1.0, 0.06640625, 1.0, 0.0625, 1.0, 1.0, 0.0703125, 0.0625, 0.0625, 1.0, 0.060546875, 1.0, 1.0, 1.0, 0.0703125, 0.068359375, 1.0, 1.0, 0.0703125, 0.06640625, 1.0, 0.0625, 1.0, 1.0, 0.068359375, 1.0, 0.068359375, 1.0, 1.0, 0.064453125, 1.0, 0.06640625, 0.06640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.06640625, 0.072265625, 0.068359375, 0.072265625, 0.06640625, 1.0, 1.0, 1.0, 1.0, 0.0703125, 1.0, 0.056640625, 1.0, 1.0, 1.0, 1.0, 0.068359375, 1.0, 1.0, 1.0, 0.080078125, 0.060546875, 0.0625, 1.0, 1.0, 1.0, 0.05859375, 1.0, 1.0, 1.0, 0.060546875, 1.0, 1.0, 0.05859375, 1.0, 0.05859375, 1.0, 0.07421875, 1.0, 1.0, 1.0, 0.064453125, 0.05859375, 0.056640625, 0.068359375, 1.0, 0.068359375, 0.064453125, 1.0, 1.0, 0.060546875, 1.0, 0.068359375, 1.0, 0.09765625, 1.0, 0.099609375, 0.08203125, 0.064453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0625, 1.0, 0.06640625, 1.0, 1.0, 1.0, 0.0703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.064453125, 0.05859375, 0.068359375, 0.05859375, 1.0, 1.0, 0.060546875, 1.0, 1.0, 0.0625, 1.0, 1.0, 1.0, 0.064453125, 1.0, 0.0703125, 1.0, 0.0625, 1.0, 1.0, 0.068359375, 1.0, 1.0, 1.0, 1.0, 0.07421875, 0.08984375, 0.06640625, 1.0, 1.0, 0.06640625, 0.0625, 1.0, 1.0, 0.068359375, 0.2109375, 1.0, 1.0, 0.0625, 1.0, 0.08984375, 0.07421875, 0.0625, 0.0703125, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.060546875, 1.0, 1.0, 1.0, 1.0, 0.064453125, 1.0, 0.068359375, 0.068359375, 0.068359375, 0.0625, 1.0, 1.0, 1.0, 0.068359375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.056640625, 0.072265625, 1.0, 0.068359375, 1.0, 0.06640625, 1.0, 0.06640625, 0.078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.060546875, 0.064453125, 0.0625, 1.0, 1.0, 1.0, 0.076171875, 1.0, 0.068359375, 1.0, 0.06640625, 1.0, 1.0, 0.072265625, 1.0, 0.05859375, 1.0, 1.0, 0.060546875, 1.0, 1.0, 0.06640625, 1.0, 1.0, 1.0, 0.06640625, 1.0, 0.068359375, 1.0, 1.0, 0.056640625, 0.068359375, 1.0, 1.0, 1.0, 0.060546875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.126953125, 1.0, 1.0, 0.060546875, 0.0625, 1.0, 1.0, 1.0, 0.060546875, 0.072265625, 1.0, 0.0625, 0.064453125, 1.0, 0.087890625, 0.06640625, 0.060546875, 0.06640625, 0.072265625, 1.0, 0.099609375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.068359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.078125, 1.0, 0.05859375, 0.068359375, 1.0, 1.0, 0.05859375, 0.05859375, 0.0625, 0.064453125, 1.0, 1.0, 0.06640625, 0.068359375, 1.0, 0.0703125, 0.06640625, 1.0, 0.06640625, 0.06640625, 1.0, 0.076171875, 1.0, 1.0, 0.056640625, 1.0, 0.064453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.060546875, 1.0, 0.0703125, 1.0, 1.0, 1.0, 0.0625, 1.0, 0.068359375, 0.068359375, 0.060546875, 1.0, 0.064453125, 1.0, 0.0625, 1.0, 0.09765625, 0.064453125, 0.060546875, 0.07421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.50390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.068359375, 0.064453125, 1.0, 1.0, 0.0703125, 0.068359375, 1.0, 1.0, 1.0, 0.064453125, 1.0, 1.0, 1.0, 1.0, 0.0703125, 1.0, 0.0703125, 1.0, 1.0, 1.0, 0.0703125, 0.068359375, 0.060546875, 1.0, 0.0703125, 0.0859375, 1.0, 0.064453125, 1.0, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 1.0, 0.06640625, 1.0, 0.0859375, 0.064453125, 0.0625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.05859375, 1.0, 0.125, 0.072265625, 0.0625, 1.0, 1.0, 0.064453125, 0.064453125, 0.0625, 0.064453125, 1.0, 0.10546875, 1.0, 0.068359375, 0.060546875, 0.072265625, 1.0, 1.0, 0.06640625, 1.0, 1.0, 1.0, 0.068359375, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.072265625, 1.0, 1.0, 1.0, 0.0703125, 0.06640625, 0.0703125, 0.076171875, 1.0, 0.064453125, 1.0, 0.06640625, 0.0703125, 1.0, 1.0, 0.064453125, 1.0, 1.0, 1.0, 1.0, 0.060546875, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.0703125, 1.0, 1.0, 1.0, 0.2734375, 1.0, 1.0, 0.0625, 0.060546875, 0.064453125, 0.064453125, 0.06640625, 1.0, 0.11328125, 0.072265625, 1.0, 0.060546875, 0.064453125, 1.0, 0.0703125, 1.0, 1.0, 1.0, 1.0, 0.064453125, 0.0625, 1.0, 0.05859375, 1.0, 0.07421875, 0.05859375, 1.0, 1.0, 1.0, 0.064453125, 1.0, 0.064453125, 0.06640625, 0.0625, 0.07421875, 0.06640625, 1.0, 0.060546875, 0.05859375, 1.0, 1.0, 1.0, 0.064453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0703125, 0.064453125, 0.05859375, 0.06640625, 1.0, 0.078125, 1.0, 1.0, 1.0, 0.060546875, 1.0, 1.0, 1.0, 0.064453125, 0.0625, 1.0, 0.07421875, 1.0, 1.0, 1.0, 0.068359375, 0.06640625, 0.091796875, 0.06640625, 0.064453125, 0.076171875, 0.05859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.095703125, 1.0, 1.0, 0.0625, 1.0, 1.0, 1.0, 0.064453125, 0.07421875, 1.0, 0.068359375, 1.0, 1.0, 1.0, 0.06640625, 0.07421875, 1.0, 0.060546875, 1.0, 1.0, 0.06640625, 0.076171875, 0.064453125, 1.0, 1.0, 0.0625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.064453125, 1.0, 1.0, 1.0, 1.0, 0.064453125, 0.072265625, 0.060546875, 0.060546875, 1.0, 0.0625, 1.0, 1.0, 0.0859375, 1.0, 0.068359375, 1.0, 0.068359375, 0.0546875, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.0625, 0.064453125, 1.0, 1.0, 0.07421875, 1.0, 1.0, 1.0, 0.068359375, 1.0, 1.0, 0.07421875, 1.0, 1.0, 1.0, 0.0703125, 0.076171875, 1.0, 1.0, 0.080078125, 0.12109375, 0.0625, 1.0, 1.0, 1.0, 1.0, 0.0703125, 0.0625, 1.0, 0.0625, 0.05859375, 0.072265625, 0.0703125, 1.0, 0.064453125, 0.060546875, 1.0, 1.0, 1.0, 0.064453125, 1.0, 0.06640625, 1.0, 0.064453125, 0.068359375, 1.0, 1.0, 0.05859375, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.0703125, 0.068359375, 0.0625, 0.154296875, 0.0703125, 1.0, 1.0, 1.0, 1.0, 0.0625, 0.072265625, 0.0625, 1.0, 1.0, 0.064453125, 0.0546875, 1.0, 1.0, 0.080078125, 1.0, 1.0, 0.060546875, 1.0, 0.0625, 1.0, 0.07421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.08203125, 0.080078125, 0.0625, 1.0, 1.0, 0.060546875, 1.0, 1.0, 1.0, 0.107421875, 1.0, 0.0703125, 0.06640625, 1.0, 0.060546875, 1.0, 0.0625, 1.0, 0.0625, 0.06640625, 1.0, 1.0, 0.078125, 1.0, 0.076171875, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.0625, 1.0, 1.0, 0.060546875, 1.0, 0.064453125, 0.06640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.498046875, 0.494140625, 0.494140625, 1.0, 1.0, 0.4990234375, 1.0, 0.4951171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5009765625, 1.0, 1.0, 0.494140625, 0.4912109375, 1.0, 1.0, 0.4931640625, 0.4892578125, 0.4931640625, 1.0, 1.0, 1.0, 1.0, 0.498046875, 0.4931640625, 1.0, 1.0, 0.5078125, 1.0, 1.0, 1.0, 0.4951171875, 0.4951171875, 1.0, 0.49609375, 0.48828125, 1.0, 1.0, 1.0, 0.4912109375, 0.4912109375, 0.5009765625, 0.498046875, 0.498046875, 0.49609375, 1.0, 1.0, 1.0, 0.498046875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.498046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.498046875, 1.0, 1.0, 0.4912109375, 0.498046875, 0.498046875, 0.49609375, 1.0, 1.0, 0.4951171875, 1.0, 1.0, 0.494140625, 0.4990234375, 0.505859375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.49609375, 1.0, 1.0, 1.0, 0.4990234375, 1.0, 1.0, 1.0, 0.498046875, 1.0, 1.0, 1.0, 1.0, 0.4951171875, 1.0, 0.4951171875, 0.49609375, 0.4970703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.498046875, 1.0, 1.0, 0.4970703125, 1.0, 1.0, 1.0, 1.0, 0.4921875, 1.0, 1.0, 0.5029296875, 1.0, 1.0, 1.0, 0.4970703125, 0.490234375, 1.0, 0.494140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5029296875, 1.0, 0.4892578125, 1.0, 1.0, 0.494140625, 0.4931640625, 0.5009765625, 0.4921875, 0.490234375, 1.0, 1.0, 0.4970703125, 0.498046875, 1.0, 0.5029296875, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5009765625, 1.0, 1.0, 0.49609375, 0.48828125, 1.0, 0.49609375, 0.50390625, 0.4912109375, 0.4990234375, 1.0, 1.0, 0.49609375, 0.4951171875, 1.0, 0.4951171875, 0.4990234375, 1.0, 1.0, 0.4931640625, 0.494140625, 1.0, 1.0, 0.5302734375, 0.4931640625, 1.0, 1.0, 0.5, 0.4970703125, 1.0, 1.0, 1.0, 0.4873046875, 1.0, 1.0, 1.0, 0.5009765625, 1.0, 1.0, 1.0, 0.4951171875, 1.0, 1.0, 1.0, 0.49609375, 1.0, 1.0, 1.0, 0.4951171875, 1.0, 0.4970703125, 1.0, 1.0, 1.0, 0.49609375, 0.4873046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4921875, 0.4970703125, 0.4990234375, 0.4931640625, 1.0, 1.0, 1.0, 1.0, 0.494140625, 0.4970703125, 1.0, 1.0, 1.0, 0.4951171875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.4951171875, 0.4931640625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49609375, 1.0]

 sparsity of   [0.6232638955116272, 0.6228298544883728, 1.0, 1.0, 0.624131977558136, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6223958134651184, 0.6236979365348816, 1.0, 1.0, 1.0, 1.0, 0.6236979365348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6236979365348816, 1.0, 0.6245659589767456, 0.6228298544883728, 0.6232638955116272, 1.0, 1.0, 0.6223958134651184, 0.625, 1.0, 1.0, 1.0, 0.6228298544883728, 0.6254340410232544, 1.0, 1.0, 0.6219618320465088, 0.6223958134651184, 1.0, 0.6228298544883728, 0.6232638955116272, 1.0, 1.0, 0.6232638955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 0.624131977558136, 0.6228298544883728, 1.0, 1.0, 0.6219618320465088, 1.0, 1.0, 0.6232638955116272, 1.0, 0.6219618320465088, 0.6232638955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.624131977558136, 1.0, 0.6223958134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 0.624131977558136, 1.0, 0.6215277910232544, 0.6232638955116272, 1.0, 0.6236979365348816, 1.0, 0.6223958134651184, 1.0, 1.0, 0.625, 0.6232638955116272, 1.0, 1.0, 0.6223958134651184, 0.6223958134651184, 1.0, 1.0, 1.0, 0.6228298544883728, 1.0, 1.0, 0.6219618320465088, 0.6215277910232544, 1.0, 1.0, 1.0, 1.0, 0.6219618320465088, 1.0, 1.0, 0.624131977558136, 1.0, 0.6223958134651184, 1.0, 1.0, 0.6254340410232544, 1.0, 1.0, 0.6236979365348816, 0.6228298544883728, 1.0, 0.6228298544883728, 1.0, 1.0, 1.0, 1.0, 0.6232638955116272, 1.0, 1.0, 1.0, 1.0, 0.6232638955116272, 1.0, 1.0, 0.6228298544883728, 0.6215277910232544, 1.0, 1.0, 1.0, 1.0, 0.6236979365348816, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6245659589767456, 0.6236979365348816, 1.0, 0.6223958134651184, 1.0, 0.6232638955116272, 1.0, 0.6223958134651184, 1.0, 0.624131977558136, 0.624131977558136, 0.6223958134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6223958134651184, 1.0, 0.6223958134651184, 0.6206597089767456, 0.6254340410232544, 1.0, 1.0, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6219618320465088, 1.0, 1.0, 1.0, 0.624131977558136, 1.0, 1.0, 1.0, 0.6215277910232544, 1.0, 1.0, 1.0, 1.0, 0.6245659589767456, 1.0, 0.6223958134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6232638955116272, 1.0, 0.6232638955116272, 1.0, 0.6223958134651184, 1.0, 0.6232638955116272, 1.0, 1.0, 0.6228298544883728, 0.6228298544883728, 1.0, 1.0, 0.6245659589767456, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6232638955116272, 1.0, 1.0, 0.6245659589767456, 1.0, 0.6223958134651184, 0.62109375, 0.6236979365348816, 1.0, 1.0, 1.0, 1.0, 0.6245659589767456, 0.6223958134651184, 0.6228298544883728, 0.6236979365348816, 0.6215277910232544, 1.0, 1.0, 1.0, 0.6228298544883728, 1.0, 1.0]

 sparsity of   [0.64453125, 1.0, 0.64453125, 1.0, 0.64453125, 0.64453125, 0.64453125, 1.0, 1.0, 0.6484375, 0.6484375, 1.0, 1.0, 1.0, 0.64453125, 0.6484375, 1.0, 1.0, 0.64453125, 0.64453125, 0.64453125, 1.0, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 0.6484375, 0.64453125, 0.64453125, 0.64453125, 0.65234375, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 0.64453125, 0.64453125, 0.64453125, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 0.6484375, 0.65234375, 0.6484375, 0.65234375, 1.0, 1.0, 0.6484375, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 0.6484375, 1.0, 0.64453125, 0.64453125, 0.64453125, 0.64453125, 0.66796875, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 0.65234375, 1.0, 0.64453125, 1.0, 1.0, 0.6484375, 1.0, 0.64453125, 1.0, 0.6484375, 1.0, 0.6484375, 0.65234375, 1.0, 0.64453125, 1.0, 0.6484375, 1.0, 0.64453125, 0.65234375, 0.65234375, 1.0, 0.6484375, 1.0, 0.6484375, 0.64453125, 0.6484375, 0.64453125, 0.64453125, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 0.6484375, 0.64453125, 0.65234375, 0.64453125, 0.64453125, 0.65234375, 0.64453125, 1.0, 1.0, 1.0, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 0.65234375, 1.0, 0.6484375, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.6484375, 0.64453125, 0.6484375, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 0.6484375, 1.0, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.6484375, 1.0, 0.6484375, 1.0, 0.64453125, 0.65234375, 0.64453125, 1.0, 0.64453125, 1.0, 0.64453125, 0.6484375, 1.0, 0.6484375, 1.0, 0.6484375, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.6484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.6484375, 0.65234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 0.64453125, 0.65234375, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.64453125, 0.6484375, 1.0, 1.0, 1.0, 0.65234375, 0.64453125, 1.0, 0.6484375, 0.64453125, 1.0, 0.6484375, 0.6484375, 0.64453125, 0.6484375, 0.6484375, 0.6484375, 0.65625, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 1.0, 0.65234375, 1.0, 0.64453125, 1.0, 0.6484375, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.6484375, 0.64453125, 0.64453125, 0.64453125, 1.0, 0.6484375, 0.6484375, 0.6484375, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 0.65234375, 1.0, 0.6484375, 0.64453125, 1.0, 0.65234375, 1.0, 0.65234375, 1.0, 0.65234375, 0.65234375, 0.64453125, 0.64453125, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 0.64453125, 0.6484375, 1.0, 0.64453125, 0.6484375, 0.6484375, 1.0, 0.640625, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 0.64453125, 1.0, 0.640625, 1.0, 0.6484375, 0.64453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.64453125, 0.65234375, 0.64453125, 0.64453125, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 0.6484375, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 0.6484375, 1.0, 1.0, 0.64453125, 0.6484375, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 0.64453125, 0.6484375, 1.0, 0.6484375, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 0.6484375, 0.64453125, 0.64453125, 0.6484375, 0.6484375, 1.0, 1.0, 0.6484375, 0.64453125, 0.65234375, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 1.0, 0.65234375, 1.0, 1.0, 0.64453125, 0.64453125, 0.64453125, 0.64453125, 1.0, 0.64453125, 0.65625, 1.0, 0.64453125, 0.640625, 1.0, 1.0, 1.0, 0.6484375, 1.0, 0.64453125, 0.65625, 0.65234375, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 0.6484375, 0.6640625, 0.6484375, 1.0, 1.0, 0.64453125, 0.64453125, 0.65234375, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 0.65234375, 1.0, 1.0, 0.64453125, 0.64453125, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 0.65234375, 1.0, 1.0, 0.6484375, 1.0, 0.64453125, 0.64453125, 1.0, 0.6484375, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 1.0, 0.65234375, 0.64453125, 0.64453125, 1.0, 0.65234375, 0.6484375, 0.6640625, 1.0, 0.65234375, 1.0, 1.0, 0.64453125, 0.64453125, 0.64453125, 0.6484375, 1.0, 1.0, 0.64453125, 0.65234375, 0.64453125, 1.0, 0.640625, 1.0, 1.0, 0.64453125, 1.0, 0.65234375, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.66796875, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.6484375, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 0.64453125, 1.0, 0.6484375, 0.64453125, 1.0, 1.0, 0.64453125, 0.64453125, 0.6484375, 0.6484375, 1.0, 0.65625, 1.0, 1.0, 1.0, 1.0, 0.6484375, 0.6484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 1.0, 0.65234375, 0.64453125, 0.6484375, 0.64453125, 0.6484375, 1.0, 0.6484375, 0.65234375, 0.64453125, 1.0, 0.64453125, 0.6484375, 1.0, 0.6484375, 0.64453125, 0.65625, 0.65234375, 1.0, 0.64453125, 0.64453125, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.6484375, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 0.64453125, 0.64453125, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 0.64453125, 0.6484375, 0.65234375, 0.64453125, 1.0, 1.0, 0.65625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 1.0, 0.64453125, 0.6484375, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 0.65625, 0.6484375, 1.0, 0.65234375, 0.64453125, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 0.6484375, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 0.64453125, 0.6484375, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 0.64453125, 0.6484375, 0.64453125, 0.64453125, 1.0, 0.6484375, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 1.0, 0.65234375, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 0.64453125, 1.0, 0.6484375, 1.0, 0.6484375, 1.0, 0.64453125, 0.6484375, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.65234375, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.65234375, 1.0, 1.0, 0.65234375, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 0.64453125, 0.64453125, 0.64453125, 0.64453125, 0.6484375, 0.6484375, 0.64453125, 0.64453125, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 0.64453125, 0.6484375, 1.0, 0.65234375, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 0.65234375, 0.6484375, 0.65234375, 0.65234375, 0.6484375, 0.6484375, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.64453125, 0.64453125, 0.6484375, 1.0, 0.64453125, 0.65234375, 1.0, 1.0, 0.6484375, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 1.0, 0.65234375, 1.0, 0.64453125, 0.6484375, 0.64453125, 0.6484375, 0.6484375, 0.6484375, 0.6484375, 0.65234375, 0.65234375, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.65625, 1.0, 1.0, 0.6484375, 0.6484375, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 0.6484375, 0.6484375, 1.0, 0.6484375, 0.65234375, 0.6484375, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 0.6484375, 0.64453125, 0.65625, 0.65234375, 1.0, 0.64453125, 1.0, 0.64453125, 0.65234375, 1.0, 0.64453125, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.6484375, 0.671875, 1.0, 1.0, 0.6484375, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.65234375, 0.64453125, 1.0, 1.0, 1.0, 0.65234375, 0.6484375, 0.65234375, 1.0, 1.0, 0.64453125, 0.64453125, 0.64453125, 1.0, 0.64453125, 0.6484375, 0.64453125, 0.65625, 1.0, 0.64453125, 0.65234375, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.6484375, 1.0, 0.64453125, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.64453125, 0.64453125, 0.64453125, 0.64453125, 0.640625, 1.0, 1.0, 1.0, 1.0, 0.65234375, 0.64453125, 0.64453125, 1.0, 1.0, 0.6484375, 0.64453125, 0.64453125, 0.64453125, 0.6484375, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.64453125, 0.6484375, 1.0, 1.0, 0.64453125, 0.64453125, 0.64453125, 1.0, 1.0, 0.6484375, 0.64453125, 1.0, 0.6484375, 0.65625, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 0.64453125, 1.0, 0.64453125, 0.64453125, 1.0, 0.6484375, 0.64453125, 1.0, 0.65625, 1.0, 1.0, 0.640625, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 1.0, 0.64453125, 1.0, 0.64453125, 0.65234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.4423828125, 0.4453125, 1.0, 1.0, 1.0, 1.0, 0.4423828125, 1.0, 0.4423828125, 1.0, 1.0, 0.4443359375, 0.443359375, 0.443359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.447265625, 0.443359375, 1.0, 1.0, 1.0, 1.0, 0.4462890625, 1.0, 1.0, 0.44140625, 1.0, 0.439453125, 1.0, 0.4404296875, 1.0, 0.443359375, 1.0, 1.0, 0.439453125, 1.0, 0.443359375, 0.443359375, 1.0, 0.4482421875, 0.439453125, 1.0, 1.0, 0.4423828125, 0.4365234375, 1.0, 0.4267578125, 1.0, 0.443359375, 1.0, 0.4287109375, 1.0, 0.443359375, 1.0, 1.0, 0.4423828125, 1.0, 1.0, 1.0, 0.4482421875, 1.0, 1.0, 0.443359375, 0.4384765625, 1.0, 1.0, 1.0, 1.0, 0.4423828125, 0.44140625, 0.4423828125, 0.4384765625, 1.0, 1.0, 0.4404296875, 1.0, 0.4384765625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4443359375, 1.0, 1.0, 1.0, 0.4345703125, 0.44140625, 1.0, 0.447265625, 0.4521484375, 1.0, 0.4521484375, 0.4443359375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4375, 1.0, 0.4453125, 1.0, 1.0, 1.0, 1.0, 0.4423828125, 0.4375, 0.447265625, 1.0, 0.4443359375, 0.439453125, 1.0, 1.0, 0.4423828125, 0.4482421875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.435546875, 0.447265625, 1.0, 0.44140625, 0.4404296875, 1.0, 1.0, 1.0, 0.451171875, 1.0, 0.435546875, 1.0, 1.0, 1.0, 0.4404296875, 1.0, 1.0, 0.44140625, 1.0, 1.0, 1.0, 1.0, 0.4375, 0.44921875, 0.43359375, 0.4404296875, 0.4443359375, 1.0, 1.0, 0.4404296875, 1.0, 1.0, 1.0, 0.4345703125, 0.4423828125, 1.0, 0.4345703125, 1.0, 1.0, 1.0, 0.4482421875, 1.0, 0.4384765625, 1.0, 1.0, 0.4453125, 1.0, 0.4462890625, 1.0, 1.0, 1.0, 1.0, 0.44140625, 0.4462890625, 1.0, 0.43359375, 1.0, 1.0, 1.0, 1.0, 0.4404296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4482421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4443359375, 0.443359375, 1.0, 1.0, 1.0, 0.44921875, 1.0, 1.0, 0.43359375, 0.44140625, 1.0, 0.44140625, 1.0, 1.0, 0.439453125, 1.0, 1.0, 0.4375, 0.4423828125, 1.0, 1.0, 1.0, 1.0, 0.4521484375, 1.0, 1.0, 0.439453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.435546875, 1.0, 0.4345703125, 1.0, 0.44140625, 1.0, 0.43359375, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.6410590410232544, 1.0, 1.0, 1.0, 1.0, 0.6380208134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6401909589767456, 1.0, 0.6393229365348816, 0.6375868320465088, 1.0, 1.0, 1.0, 0.6384548544883728, 1.0, 0.635850727558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.639756977558136, 0.6384548544883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6410590410232544, 0.639756977558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.63671875, 0.639756977558136, 1.0, 1.0, 1.0, 0.640625, 1.0, 0.6401909589767456, 0.6362847089767456, 1.0, 1.0, 0.6423611044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6388888955116272, 1.0, 0.639756977558136, 1.0, 1.0, 1.0, 0.6384548544883728, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6401909589767456, 1.0, 1.0, 1.0, 0.6388888955116272, 1.0, 0.6375868320465088, 1.0, 1.0, 1.0, 1.0, 0.640625, 1.0, 1.0, 0.6375868320465088, 1.0, 1.0, 0.6345486044883728, 1.0, 1.0, 0.6393229365348816, 0.6371527910232544, 1.0, 0.6414930820465088, 1.0, 1.0, 0.6388888955116272, 1.0, 0.6388888955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6410590410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6384548544883728, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6380208134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6388888955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6375868320465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6393229365348816, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6384548544883728, 1.0, 1.0, 1.0, 0.6345486044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6371527910232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.640625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.639756977558136, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6380208134651184, 1.0, 1.0, 0.635850727558136, 1.0, 1.0, 1.0, 0.6423611044883728, 1.0, 1.0, 1.0, 0.63671875, 1.0, 0.639756977558136, 0.63671875, 0.6349826455116272, 1.0, 1.0, 1.0, 1.0, 0.6384548544883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6380208134651184, 1.0, 0.63671875, 1.0, 0.63671875, 1.0, 1.0, 0.639756977558136]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.7890625, 0.7890625, 0.7890625, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 0.7890625, 0.78515625, 0.78515625, 0.79296875, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.79296875, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 0.7890625, 1.0, 1.0, 1.0, 0.7890625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.7890625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 0.7890625, 0.78515625, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 0.78515625, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.7890625, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 0.78515625, 0.78515625, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.78515625, 1.0, 1.0, 1.0, 0.796875, 0.78515625, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.7890625, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 0.79296875, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.7890625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 0.7890625, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 0.78515625, 0.78515625, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 0.7890625, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.7890625, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.80078125, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.7890625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.78515625, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 0.7890625, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 0.78515625, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4306640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4326171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4326171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.431640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.43359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.451171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4365234375, 1.0, 1.0, 1.0, 0.43359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4775390625, 1.0, 1.0, 0.4990234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9208984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.431640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42578125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4931640625, 0.4990234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4521484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4326171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.505859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.43359375, 0.4580078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4365234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4345703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.556640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4287109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.548828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.44921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.431640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4501953125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.435546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4326171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.427734375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4326171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5302734375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4326171875, 1.0, 1.0, 0.44140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.44140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.44140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4873046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.560546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.521484375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.443359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.427734375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5791015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4609375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.51171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4404296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7744140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4365234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4560546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.435546875, 1.0, 0.435546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4375, 1.0, 1.0, 0.4345703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96923828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9697265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96923828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7584635615348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7096354365348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7150607705116272, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7365451455116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6970486044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7057291865348816, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98828125, 1.0, 1.0, 0.98828125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.69091796875, 0.67529296875, 0.658203125, 0.6611328125, 0.6640625, 0.65869140625, 0.6611328125, 0.66015625, 0.6640625, 0.66455078125, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875]

Total parameter pruned: 22529416.003780387 (unstructured) 21339380 (structured)

Test: [0/79]	Time 0.168 (0.168)	Loss 0.2975 (0.2975) ([0.183]+[0.114])	Prec@1 95.312 (95.312)
 * Prec@1 93.870

 Elapsed time for training  3:54:04.251631

 sparsity of   [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]

 sparsity of   [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]

 sparsity of   [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.546875, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]

 sparsity of   [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]

 sparsity of   [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]

 sparsity of   [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]

 sparsity of   [0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]

 sparsity of   [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]

 sparsity of   [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]

 sparsity of   [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]

 sparsity of   [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]

 sparsity of   [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]

 sparsity of   [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0]

 sparsity of   [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]

 sparsity of   [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]

 sparsity of   [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.484375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4921875, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]

 sparsity of   [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]

 sparsity of   [0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]

 sparsity of   [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.69091796875, 0.67529296875, 0.658203125, 0.6611328125, 0.6640625, 0.65869140625, 0.6611328125, 0.66015625, 0.6640625, 0.66455078125, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875, 0.919921875]
Total parameter pruned: 21522736.0 (unstructured) 21339380 (structured)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.1831 (0.1831) ([0.183]+[0.000])	Prec@1 95.312 (95.312)
 * Prec@1 93.870
Best accuracy:  0
