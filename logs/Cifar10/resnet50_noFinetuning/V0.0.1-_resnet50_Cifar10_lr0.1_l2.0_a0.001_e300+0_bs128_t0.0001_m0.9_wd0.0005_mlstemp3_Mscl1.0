V0.0.1-_resnet50_Cifar10_lr0.1_l2.0_a0.001_e300+0_bs128_t0.0001_m0.9_wd0.0005_mlstemp3_Mscl1.0
Files already downloaded and verified
M values:
 {Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.5254763960838318, Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.24196940660476685, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.15759095549583435, Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.13501641154289246, Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.3461485505104065, Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.17473100125789642, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.21617008745670319, Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.14946585893630981, Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.09060623496770859, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.08498729020357132, Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.11497705429792404, Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.11804789304733276, Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False): 0.08379501849412918, Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.1424030363559723, Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False): 0.19753389060497284, Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.16684924066066742, Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.22829987108707428, Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.12801074981689453, Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.09603530913591385, Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.06901206821203232, Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.12272872775793076, Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.0835055485367775, Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.07954221963882446, Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.12703275680541992, Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.19747452437877655, Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False): 0.15407174825668335, Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.1602816879749298, Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False): 0.10645194351673126, Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.10600411146879196, Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.13483507931232452, Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.21709460020065308, Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.11353497207164764, Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.0660422295331955, Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.10686782747507095, Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.06808818876743317, Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.05323619768023491, Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.08759226649999619, Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.07965513318777084, Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.06643471866846085, Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.12164679169654846, Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.09185265004634857, Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.06330689787864685, Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.1110600158572197, Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.12582343816757202, Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False): 0.09035182744264603, Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.07410024106502533, Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False): 0.07018566876649857, Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.0687103122472763, Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.04065759852528572, Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.03755198046565056, Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.04725675657391548, Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.045549724251031876, Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False): 0.06192586570978165, Linear(in_features=2048, out_features=100, bias=True): 0.44340774416923523}
current lr 1.00000e-01
Grad=  tensor(5878.2705, device='cuda:0')
Epoch: [0][0/391]	Time 0.257 (0.257)	Data 0.119 (0.119)	Loss 7.2794 (7.2794) ([4.877]+[2.402])	Prec@1 0.000 (0.000)
Epoch: [0][100/391]	Time 0.113 (0.114)	Data 0.000 (0.001)	Loss 5.1185 (6.3429) ([2.083]+[3.035])	Prec@1 15.625 (14.558)
Epoch: [0][200/391]	Time 0.112 (0.113)	Data 0.000 (0.001)	Loss 4.5726 (5.6438) ([1.876]+[2.697])	Prec@1 28.125 (17.883)
Epoch: [0][300/391]	Time 0.110 (0.112)	Data 0.000 (0.000)	Loss 4.1797 (5.2669) ([1.795]+[2.385])	Prec@1 31.250 (19.838)
Test: [0/79]	Time 0.154 (0.154)	Loss 4.0036 (4.0036) ([1.881]+[2.122])	Prec@1 32.031 (32.031)
 * Prec@1 29.650
current lr 1.00000e-01
Grad=  tensor(0.4522, device='cuda:0')
Epoch: [1][0/391]	Time 0.241 (0.241)	Data 0.119 (0.119)	Loss 4.0175 (4.0175) ([1.895]+[2.122])	Prec@1 27.344 (27.344)
Epoch: [1][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 3.5923 (3.8132) ([1.739]+[1.853])	Prec@1 32.031 (30.500)
Epoch: [1][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 3.4461 (3.6681) ([1.824]+[1.622])	Prec@1 35.156 (31.518)
Epoch: [1][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 3.2159 (3.5298) ([1.799]+[1.417])	Prec@1 32.812 (32.504)
Test: [0/79]	Time 0.148 (0.148)	Loss 2.7751 (2.7751) ([1.521]+[1.254])	Prec@1 45.312 (45.312)
 * Prec@1 39.010
current lr 1.00000e-01
Grad=  tensor(1.0329, device='cuda:0')
Epoch: [2][0/391]	Time 0.244 (0.244)	Data 0.119 (0.119)	Loss 2.8747 (2.8747) ([1.621]+[1.254])	Prec@1 41.406 (41.406)
Epoch: [2][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 2.7048 (2.8372) ([1.584]+[1.121])	Prec@1 39.062 (38.297)
Epoch: [2][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 2.6885 (2.7702) ([1.657]+[1.032])	Prec@1 42.188 (39.129)
Epoch: [2][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 2.6842 (2.6784) ([1.777]+[0.907])	Prec@1 35.938 (40.545)
Test: [0/79]	Time 0.150 (0.150)	Loss 2.4525 (2.4525) ([1.601]+[0.852])	Prec@1 38.281 (38.281)
 * Prec@1 42.950
current lr 1.00000e-01
Grad=  tensor(1.2095, device='cuda:0')
Epoch: [3][0/391]	Time 0.237 (0.237)	Data 0.115 (0.115)	Loss 2.2025 (2.2025) ([1.351]+[0.852])	Prec@1 51.562 (51.562)
Epoch: [3][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 2.1636 (2.2707) ([1.422]+[0.742])	Prec@1 49.219 (45.119)
Epoch: [3][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 2.0472 (2.2070) ([1.378]+[0.670])	Prec@1 46.094 (45.857)
Epoch: [3][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 1.8892 (2.1458) ([1.275]+[0.614])	Prec@1 50.781 (47.026)
Test: [0/79]	Time 0.149 (0.149)	Loss 2.0699 (2.0699) ([1.491]+[0.579])	Prec@1 49.219 (49.219)
 * Prec@1 47.230
current lr 1.00000e-01
Grad=  tensor(1.3478, device='cuda:0')
Epoch: [4][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 1.8961 (1.8961) ([1.317]+[0.579])	Prec@1 50.000 (50.000)
Epoch: [4][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 1.8183 (1.8176) ([1.279]+[0.540])	Prec@1 44.531 (53.914)
Epoch: [4][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 1.6700 (1.7943) ([1.138]+[0.532])	Prec@1 57.031 (55.002)
Epoch: [4][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 1.6366 (1.7523) ([1.160]+[0.476])	Prec@1 62.500 (56.053)
Test: [0/79]	Time 0.150 (0.150)	Loss 1.6587 (1.6587) ([1.199]+[0.460])	Prec@1 53.125 (53.125)
 * Prec@1 55.440
current lr 1.00000e-01
Grad=  tensor(1.1123, device='cuda:0')
Epoch: [5][0/391]	Time 0.241 (0.241)	Data 0.119 (0.119)	Loss 1.4305 (1.4305) ([0.970]+[0.460])	Prec@1 60.938 (60.938)
Epoch: [5][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 1.2474 (1.5423) ([0.813]+[0.434])	Prec@1 67.969 (60.775)
Epoch: [5][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 1.6203 (1.5278) ([1.199]+[0.422])	Prec@1 57.812 (60.891)
Epoch: [5][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 1.4008 (1.5088) ([0.999]+[0.401])	Prec@1 67.188 (61.483)
Test: [0/79]	Time 0.147 (0.147)	Loss 1.4834 (1.4834) ([1.093]+[0.391])	Prec@1 56.250 (56.250)
 * Prec@1 60.340
current lr 1.00000e-01
Grad=  tensor(1.2323, device='cuda:0')
Epoch: [6][0/391]	Time 0.236 (0.236)	Data 0.117 (0.117)	Loss 1.3369 (1.3369) ([0.946]+[0.391])	Prec@1 62.500 (62.500)
Epoch: [6][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 1.3639 (1.3970) ([0.976]+[0.388])	Prec@1 67.969 (64.078)
Epoch: [6][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 1.3416 (1.3897) ([0.970]+[0.372])	Prec@1 61.719 (64.195)
Epoch: [6][300/391]	Time 0.111 (0.109)	Data 0.000 (0.000)	Loss 1.3092 (1.3657) ([0.952]+[0.358])	Prec@1 64.844 (64.867)
Test: [0/79]	Time 0.148 (0.148)	Loss 1.2972 (1.2972) ([0.940]+[0.357])	Prec@1 64.844 (64.844)
 * Prec@1 63.260
current lr 1.00000e-01
Grad=  tensor(1.2202, device='cuda:0')
Epoch: [7][0/391]	Time 0.239 (0.239)	Data 0.119 (0.119)	Loss 1.2156 (1.2156) ([0.859]+[0.357])	Prec@1 66.406 (66.406)
Epoch: [7][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 1.2397 (1.2921) ([0.892]+[0.348])	Prec@1 66.406 (66.507)
Epoch: [7][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 1.3744 (1.2789) ([1.034]+[0.340])	Prec@1 62.500 (66.935)
Epoch: [7][300/391]	Time 0.112 (0.110)	Data 0.000 (0.000)	Loss 1.1055 (1.2711) ([0.772]+[0.333])	Prec@1 68.750 (67.260)
Test: [0/79]	Time 0.149 (0.149)	Loss 1.3906 (1.3906) ([1.061]+[0.330])	Prec@1 59.375 (59.375)
 * Prec@1 62.270
current lr 1.00000e-01
Grad=  tensor(1.6925, device='cuda:0')
Epoch: [8][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 1.2455 (1.2455) ([0.916]+[0.330])	Prec@1 66.406 (66.406)
Epoch: [8][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 1.3468 (1.2312) ([0.999]+[0.348])	Prec@1 67.969 (68.673)
Epoch: [8][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 1.2316 (1.2133) ([0.904]+[0.327])	Prec@1 67.969 (69.108)
Epoch: [8][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 1.1804 (1.2070) ([0.855]+[0.325])	Prec@1 67.969 (69.119)
Test: [0/79]	Time 0.150 (0.150)	Loss 1.7986 (1.7986) ([1.465]+[0.334])	Prec@1 57.031 (57.031)
 * Prec@1 57.400
current lr 1.00000e-01
Grad=  tensor(1.5859, device='cuda:0')
Epoch: [9][0/391]	Time 0.236 (0.236)	Data 0.116 (0.116)	Loss 1.1232 (1.1232) ([0.789]+[0.334])	Prec@1 72.656 (72.656)
Epoch: [9][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 1.1467 (1.1531) ([0.823]+[0.324])	Prec@1 71.094 (71.403)
Epoch: [9][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 1.1112 (1.1501) ([0.785]+[0.327])	Prec@1 70.312 (71.308)
Epoch: [9][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 1.1391 (1.1476) ([0.821]+[0.318])	Prec@1 72.656 (71.384)
Test: [0/79]	Time 0.146 (0.146)	Loss 1.6665 (1.6665) ([1.349]+[0.317])	Prec@1 60.938 (60.938)
 * Prec@1 57.020
current lr 1.00000e-01
Grad=  tensor(1.8440, device='cuda:0')
Epoch: [10][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 1.0254 (1.0254) ([0.708]+[0.317])	Prec@1 75.781 (75.781)
Epoch: [10][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 1.0918 (1.0836) ([0.775]+[0.317])	Prec@1 75.781 (73.600)
Epoch: [10][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 1.0368 (1.0860) ([0.719]+[0.317])	Prec@1 80.469 (73.593)
Epoch: [10][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 1.0656 (1.0810) ([0.756]+[0.310])	Prec@1 76.562 (73.759)
Test: [0/79]	Time 0.144 (0.144)	Loss 1.0270 (1.0270) ([0.715]+[0.312])	Prec@1 76.562 (76.562)
 * Prec@1 70.120
current lr 1.00000e-01
Grad=  tensor(1.2771, device='cuda:0')
Epoch: [11][0/391]	Time 0.235 (0.235)	Data 0.114 (0.114)	Loss 0.9653 (0.9653) ([0.653]+[0.312])	Prec@1 78.125 (78.125)
Epoch: [11][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 1.0152 (1.0050) ([0.707]+[0.308])	Prec@1 76.562 (76.114)
Epoch: [11][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 1.0238 (1.0224) ([0.715]+[0.309])	Prec@1 77.344 (75.381)
Epoch: [11][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 1.0341 (1.0261) ([0.726]+[0.308])	Prec@1 73.438 (75.402)
Test: [0/79]	Time 0.147 (0.147)	Loss 1.4636 (1.4636) ([1.150]+[0.313])	Prec@1 66.406 (66.406)
 * Prec@1 63.760
current lr 1.00000e-01
Grad=  tensor(2.3983, device='cuda:0')
Epoch: [12][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 1.0936 (1.0936) ([0.780]+[0.313])	Prec@1 73.438 (73.438)
Epoch: [12][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 1.0758 (1.0165) ([0.766]+[0.310])	Prec@1 78.125 (75.828)
Epoch: [12][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.8461 (1.0079) ([0.538]+[0.308])	Prec@1 81.250 (76.162)
Epoch: [12][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 0.9386 (1.0078) ([0.627]+[0.312])	Prec@1 79.688 (76.025)
Test: [0/79]	Time 0.148 (0.148)	Loss 1.0973 (1.0973) ([0.789]+[0.308])	Prec@1 72.656 (72.656)
 * Prec@1 65.130
current lr 1.00000e-01
Grad=  tensor(1.9384, device='cuda:0')
Epoch: [13][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 1.0261 (1.0261) ([0.718]+[0.308])	Prec@1 75.000 (75.000)
Epoch: [13][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.9234 (0.9568) ([0.622]+[0.302])	Prec@1 81.250 (77.274)
Epoch: [13][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.9675 (0.9588) ([0.667]+[0.300])	Prec@1 82.031 (77.313)
Epoch: [13][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 0.8589 (0.9626) ([0.557]+[0.301])	Prec@1 78.125 (77.237)
Test: [0/79]	Time 0.147 (0.147)	Loss 1.3781 (1.3781) ([1.079]+[0.299])	Prec@1 65.625 (65.625)
 * Prec@1 62.490
current lr 1.00000e-01
Grad=  tensor(1.7129, device='cuda:0')
Epoch: [14][0/391]	Time 0.239 (0.239)	Data 0.117 (0.117)	Loss 0.9189 (0.9189) ([0.620]+[0.299])	Prec@1 76.562 (76.562)
Epoch: [14][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.9665 (0.9613) ([0.665]+[0.301])	Prec@1 77.344 (76.756)
Epoch: [14][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7863 (0.9545) ([0.490]+[0.296])	Prec@1 84.375 (77.231)
Epoch: [14][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8976 (0.9468) ([0.605]+[0.293])	Prec@1 75.781 (77.442)
Test: [0/79]	Time 0.144 (0.144)	Loss 1.1940 (1.1940) ([0.903]+[0.291])	Prec@1 69.531 (69.531)
 * Prec@1 68.910
current lr 1.00000e-01
Grad=  tensor(2.2352, device='cuda:0')
Epoch: [15][0/391]	Time 0.237 (0.237)	Data 0.117 (0.117)	Loss 1.0307 (1.0307) ([0.739]+[0.291])	Prec@1 70.312 (70.312)
Epoch: [15][100/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8884 (0.9216) ([0.598]+[0.290])	Prec@1 79.688 (78.295)
Epoch: [15][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8430 (0.9304) ([0.553]+[0.290])	Prec@1 83.594 (78.234)
Epoch: [15][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.9742 (0.9301) ([0.686]+[0.288])	Prec@1 73.438 (78.104)
Test: [0/79]	Time 0.150 (0.150)	Loss 1.1745 (1.1745) ([0.886]+[0.289])	Prec@1 72.656 (72.656)
 * Prec@1 73.390
current lr 1.00000e-01
Grad=  tensor(2.0676, device='cuda:0')
Epoch: [16][0/391]	Time 0.239 (0.239)	Data 0.119 (0.119)	Loss 0.9484 (0.9484) ([0.660]+[0.289])	Prec@1 78.125 (78.125)
Epoch: [16][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7705 (0.8920) ([0.485]+[0.286])	Prec@1 80.469 (79.301)
Epoch: [16][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8978 (0.8952) ([0.613]+[0.285])	Prec@1 82.031 (79.038)
Epoch: [16][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.8514 (0.9001) ([0.567]+[0.285])	Prec@1 79.688 (78.836)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.8750 (0.8750) ([0.592]+[0.283])	Prec@1 77.344 (77.344)
 * Prec@1 73.310
current lr 1.00000e-01
Grad=  tensor(1.8361, device='cuda:0')
Epoch: [17][0/391]	Time 0.231 (0.231)	Data 0.112 (0.112)	Loss 0.8550 (0.8550) ([0.572]+[0.283])	Prec@1 78.125 (78.125)
Epoch: [17][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7364 (0.8973) ([0.452]+[0.284])	Prec@1 84.375 (78.960)
Epoch: [17][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8696 (0.9033) ([0.585]+[0.284])	Prec@1 80.469 (78.731)
Epoch: [17][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.9653 (0.8994) ([0.680]+[0.285])	Prec@1 75.000 (78.945)
Test: [0/79]	Time 0.143 (0.143)	Loss 1.2152 (1.2152) ([0.930]+[0.285])	Prec@1 71.875 (71.875)
 * Prec@1 70.040
current lr 1.00000e-01
Grad=  tensor(1.7955, device='cuda:0')
Epoch: [18][0/391]	Time 0.237 (0.237)	Data 0.117 (0.117)	Loss 0.9095 (0.9095) ([0.625]+[0.285])	Prec@1 78.125 (78.125)
Epoch: [18][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8213 (0.8847) ([0.538]+[0.283])	Prec@1 79.688 (79.440)
Epoch: [18][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8776 (0.8854) ([0.596]+[0.281])	Prec@1 78.125 (79.322)
Epoch: [18][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 1.0393 (0.8838) ([0.757]+[0.283])	Prec@1 70.312 (79.316)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.9150 (0.9150) ([0.633]+[0.282])	Prec@1 76.562 (76.562)
 * Prec@1 76.630
current lr 1.00000e-01
Grad=  tensor(1.7097, device='cuda:0')
Epoch: [19][0/391]	Time 0.234 (0.234)	Data 0.114 (0.114)	Loss 0.8003 (0.8003) ([0.518]+[0.282])	Prec@1 82.812 (82.812)
Epoch: [19][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.9531 (0.8785) ([0.671]+[0.282])	Prec@1 75.000 (79.649)
Epoch: [19][200/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.8254 (0.8729) ([0.545]+[0.281])	Prec@1 78.906 (79.715)
Epoch: [19][300/391]	Time 0.108 (0.110)	Data 0.000 (0.000)	Loss 0.8802 (0.8722) ([0.600]+[0.280])	Prec@1 78.906 (79.791)
Test: [0/79]	Time 0.149 (0.149)	Loss 1.2873 (1.2873) ([1.007]+[0.280])	Prec@1 70.312 (70.312)
 * Prec@1 70.220
current lr 1.00000e-01
Grad=  tensor(1.8148, device='cuda:0')
Epoch: [20][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.8313 (0.8313) ([0.551]+[0.280])	Prec@1 79.688 (79.688)
Epoch: [20][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8632 (0.8679) ([0.583]+[0.280])	Prec@1 79.688 (80.105)
Epoch: [20][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8240 (0.8702) ([0.545]+[0.279])	Prec@1 82.812 (80.045)
Epoch: [20][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.7888 (0.8740) ([0.507]+[0.282])	Prec@1 80.469 (79.649)
Test: [0/79]	Time 0.150 (0.150)	Loss 1.0608 (1.0608) ([0.781]+[0.280])	Prec@1 73.438 (73.438)
 * Prec@1 68.430
current lr 1.00000e-01
Grad=  tensor(3.0716, device='cuda:0')
Epoch: [21][0/391]	Time 0.237 (0.237)	Data 0.118 (0.118)	Loss 0.9483 (0.9483) ([0.668]+[0.280])	Prec@1 78.906 (78.906)
Epoch: [21][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8764 (0.8481) ([0.597]+[0.279])	Prec@1 79.688 (80.531)
Epoch: [21][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.9037 (0.8575) ([0.624]+[0.279])	Prec@1 81.250 (80.123)
Epoch: [21][300/391]	Time 0.110 (0.110)	Data 0.000 (0.000)	Loss 0.8563 (0.8558) ([0.578]+[0.278])	Prec@1 82.031 (80.222)
Test: [0/79]	Time 0.149 (0.149)	Loss 1.0713 (1.0713) ([0.792]+[0.279])	Prec@1 76.562 (76.562)
 * Prec@1 75.370
current lr 1.00000e-01
Grad=  tensor(2.0509, device='cuda:0')
Epoch: [22][0/391]	Time 0.234 (0.234)	Data 0.115 (0.115)	Loss 0.8253 (0.8253) ([0.546]+[0.279])	Prec@1 78.906 (78.906)
Epoch: [22][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8232 (0.8388) ([0.545]+[0.279])	Prec@1 83.594 (80.747)
Epoch: [22][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.9322 (0.8465) ([0.654]+[0.278])	Prec@1 78.906 (80.585)
Epoch: [22][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.8249 (0.8505) ([0.547]+[0.278])	Prec@1 82.031 (80.505)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.9890 (0.9890) ([0.712]+[0.277])	Prec@1 75.781 (75.781)
 * Prec@1 70.780
current lr 1.00000e-01
Grad=  tensor(2.5708, device='cuda:0')
Epoch: [23][0/391]	Time 0.238 (0.238)	Data 0.118 (0.118)	Loss 0.9044 (0.9044) ([0.628]+[0.277])	Prec@1 78.125 (78.125)
Epoch: [23][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8353 (0.8478) ([0.559]+[0.277])	Prec@1 80.469 (80.113)
Epoch: [23][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8571 (0.8564) ([0.580]+[0.277])	Prec@1 79.688 (79.859)
Epoch: [23][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.7452 (0.8518) ([0.469]+[0.276])	Prec@1 84.375 (80.220)
Test: [0/79]	Time 0.145 (0.145)	Loss 1.0728 (1.0728) ([0.795]+[0.277])	Prec@1 75.000 (75.000)
 * Prec@1 76.470
current lr 1.00000e-01
Grad=  tensor(1.8818, device='cuda:0')
Epoch: [24][0/391]	Time 0.240 (0.240)	Data 0.119 (0.119)	Loss 0.8277 (0.8277) ([0.550]+[0.277])	Prec@1 78.906 (78.906)
Epoch: [24][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8240 (0.8364) ([0.547]+[0.277])	Prec@1 82.031 (81.080)
Epoch: [24][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8483 (0.8399) ([0.571]+[0.277])	Prec@1 78.906 (80.838)
Epoch: [24][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.8709 (0.8440) ([0.595]+[0.276])	Prec@1 75.781 (80.731)
Test: [0/79]	Time 0.149 (0.149)	Loss 1.0852 (1.0852) ([0.809]+[0.276])	Prec@1 71.094 (71.094)
 * Prec@1 69.490
current lr 1.00000e-01
Grad=  tensor(2.3080, device='cuda:0')
Epoch: [25][0/391]	Time 0.236 (0.236)	Data 0.116 (0.116)	Loss 1.0038 (1.0038) ([0.728]+[0.276])	Prec@1 75.000 (75.000)
Epoch: [25][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.8820 (0.8182) ([0.609]+[0.273])	Prec@1 83.594 (81.791)
Epoch: [25][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.9718 (0.8307) ([0.697]+[0.275])	Prec@1 75.781 (81.351)
Epoch: [25][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.6936 (0.8360) ([0.418]+[0.275])	Prec@1 86.719 (81.102)
Test: [0/79]	Time 0.150 (0.150)	Loss 1.1921 (1.1921) ([0.917]+[0.275])	Prec@1 71.875 (71.875)
 * Prec@1 68.660
current lr 1.00000e-01
Grad=  tensor(2.7751, device='cuda:0')
Epoch: [26][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 1.0149 (1.0149) ([0.740]+[0.275])	Prec@1 75.781 (75.781)
Epoch: [26][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.8153 (0.8371) ([0.540]+[0.275])	Prec@1 78.906 (80.593)
Epoch: [26][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8068 (0.8298) ([0.532]+[0.274])	Prec@1 83.594 (80.865)
Epoch: [26][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 0.8380 (0.8389) ([0.563]+[0.275])	Prec@1 78.906 (80.586)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.9956 (0.9956) ([0.721]+[0.275])	Prec@1 75.781 (75.781)
 * Prec@1 75.860
current lr 1.00000e-01
Grad=  tensor(2.3810, device='cuda:0')
Epoch: [27][0/391]	Time 0.237 (0.237)	Data 0.115 (0.115)	Loss 0.9175 (0.9175) ([0.643]+[0.275])	Prec@1 78.125 (78.125)
Epoch: [27][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8636 (0.8367) ([0.589]+[0.274])	Prec@1 78.125 (81.289)
Epoch: [27][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.8523 (0.8370) ([0.578]+[0.274])	Prec@1 78.125 (81.083)
Epoch: [27][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.8755 (0.8386) ([0.601]+[0.274])	Prec@1 80.469 (80.913)
Test: [0/79]	Time 0.150 (0.150)	Loss 1.1132 (1.1132) ([0.840]+[0.274])	Prec@1 71.094 (71.094)
 * Prec@1 71.150
current lr 1.00000e-01
Grad=  tensor(2.3767, device='cuda:0')
Epoch: [28][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.7947 (0.7947) ([0.521]+[0.274])	Prec@1 78.906 (78.906)
Epoch: [28][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7515 (0.8189) ([0.478]+[0.274])	Prec@1 85.156 (81.536)
Epoch: [28][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7994 (0.8166) ([0.526]+[0.274])	Prec@1 84.375 (81.343)
Epoch: [28][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.6494 (0.8191) ([0.377]+[0.273])	Prec@1 89.844 (81.268)
Test: [0/79]	Time 0.149 (0.149)	Loss 1.2632 (1.2632) ([0.990]+[0.273])	Prec@1 68.750 (68.750)
 * Prec@1 68.170
current lr 1.00000e-01
Grad=  tensor(1.8215, device='cuda:0')
Epoch: [29][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.8912 (0.8912) ([0.618]+[0.273])	Prec@1 80.469 (80.469)
Epoch: [29][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7174 (0.8108) ([0.445]+[0.272])	Prec@1 82.812 (81.474)
Epoch: [29][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 1.0325 (0.8071) ([0.760]+[0.272])	Prec@1 78.906 (81.545)
Epoch: [29][300/391]	Time 0.108 (0.110)	Data 0.000 (0.000)	Loss 0.7353 (0.8137) ([0.463]+[0.272])	Prec@1 83.594 (81.401)
Test: [0/79]	Time 0.146 (0.146)	Loss 1.0980 (1.0980) ([0.827]+[0.271])	Prec@1 70.312 (70.312)
 * Prec@1 70.500
current lr 1.00000e-01
Grad=  tensor(1.7750, device='cuda:0')
Epoch: [30][0/391]	Time 0.239 (0.239)	Data 0.121 (0.121)	Loss 0.7879 (0.7879) ([0.517]+[0.271])	Prec@1 83.594 (83.594)
Epoch: [30][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.8946 (0.8028) ([0.623]+[0.271])	Prec@1 75.000 (81.660)
Epoch: [30][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.8130 (0.8064) ([0.541]+[0.272])	Prec@1 79.688 (81.460)
Epoch: [30][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.7772 (0.8114) ([0.507]+[0.270])	Prec@1 82.812 (81.364)
Test: [0/79]	Time 0.146 (0.146)	Loss 0.8599 (0.8599) ([0.590]+[0.270])	Prec@1 75.781 (75.781)
 * Prec@1 78.390
current lr 1.00000e-01
Grad=  tensor(2.2950, device='cuda:0')
Epoch: [31][0/391]	Time 0.232 (0.232)	Data 0.114 (0.114)	Loss 0.8732 (0.8732) ([0.603]+[0.270])	Prec@1 82.031 (82.031)
Epoch: [31][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8916 (0.8126) ([0.621]+[0.271])	Prec@1 78.906 (81.544)
Epoch: [31][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.8098 (0.8177) ([0.539]+[0.271])	Prec@1 80.469 (81.238)
Epoch: [31][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.7432 (0.8152) ([0.472]+[0.271])	Prec@1 85.156 (81.341)
Test: [0/79]	Time 0.149 (0.149)	Loss 1.2074 (1.2074) ([0.936]+[0.271])	Prec@1 71.094 (71.094)
 * Prec@1 72.880
current lr 1.00000e-01
Grad=  tensor(1.5024, device='cuda:0')
Epoch: [32][0/391]	Time 0.235 (0.235)	Data 0.116 (0.116)	Loss 0.7338 (0.7338) ([0.463]+[0.271])	Prec@1 84.375 (84.375)
Epoch: [32][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.7009 (0.8053) ([0.430]+[0.271])	Prec@1 82.812 (82.147)
Epoch: [32][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.9046 (0.8100) ([0.634]+[0.270])	Prec@1 78.125 (81.646)
Epoch: [32][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.8755 (0.8153) ([0.604]+[0.271])	Prec@1 81.250 (81.450)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.9608 (0.9608) ([0.691]+[0.270])	Prec@1 77.344 (77.344)
 * Prec@1 75.350
current lr 1.00000e-01
Grad=  tensor(2.3625, device='cuda:0')
Epoch: [33][0/391]	Time 0.235 (0.235)	Data 0.116 (0.116)	Loss 0.7933 (0.7933) ([0.523]+[0.270])	Prec@1 78.906 (78.906)
Epoch: [33][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.9870 (0.8036) ([0.718]+[0.269])	Prec@1 76.562 (82.116)
Epoch: [33][200/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.8757 (0.7980) ([0.606]+[0.269])	Prec@1 78.906 (82.105)
Epoch: [33][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.6859 (0.8041) ([0.417]+[0.269])	Prec@1 84.375 (81.741)
Test: [0/79]	Time 0.149 (0.149)	Loss 1.0790 (1.0790) ([0.809]+[0.270])	Prec@1 75.000 (75.000)
 * Prec@1 75.490
current lr 1.00000e-01
Grad=  tensor(2.2543, device='cuda:0')
Epoch: [34][0/391]	Time 0.235 (0.235)	Data 0.114 (0.114)	Loss 0.8727 (0.8727) ([0.603]+[0.270])	Prec@1 82.031 (82.031)
Epoch: [34][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.9679 (0.7892) ([0.699]+[0.269])	Prec@1 77.344 (82.078)
Epoch: [34][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.7807 (0.7946) ([0.512]+[0.268])	Prec@1 82.031 (82.160)
Epoch: [34][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.7160 (0.8045) ([0.448]+[0.268])	Prec@1 85.156 (81.842)
Test: [0/79]	Time 0.150 (0.150)	Loss 1.6376 (1.6376) ([1.371]+[0.267])	Prec@1 60.156 (60.156)
 * Prec@1 61.660
current lr 1.00000e-01
Grad=  tensor(1.4013, device='cuda:0')
Epoch: [35][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.6438 (0.6438) ([0.377]+[0.267])	Prec@1 89.062 (89.062)
Epoch: [35][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6517 (0.7873) ([0.385]+[0.267])	Prec@1 87.500 (82.604)
Epoch: [35][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.9600 (0.8018) ([0.692]+[0.268])	Prec@1 75.000 (81.798)
Epoch: [35][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.7434 (0.8028) ([0.476]+[0.267])	Prec@1 80.469 (81.800)
Test: [0/79]	Time 0.148 (0.148)	Loss 1.0281 (1.0281) ([0.761]+[0.267])	Prec@1 74.219 (74.219)
 * Prec@1 76.050
current lr 1.00000e-01
Grad=  tensor(1.8765, device='cuda:0')
Epoch: [36][0/391]	Time 0.238 (0.238)	Data 0.116 (0.116)	Loss 0.7641 (0.7641) ([0.497]+[0.267])	Prec@1 86.719 (86.719)
Epoch: [36][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7814 (0.7871) ([0.515]+[0.266])	Prec@1 84.375 (82.395)
Epoch: [36][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8456 (0.8027) ([0.579]+[0.267])	Prec@1 76.562 (81.954)
Epoch: [36][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.9503 (0.8047) ([0.683]+[0.267])	Prec@1 75.000 (81.650)
Test: [0/79]	Time 0.149 (0.149)	Loss 1.0226 (1.0226) ([0.755]+[0.267])	Prec@1 82.031 (82.031)
 * Prec@1 78.090
current lr 1.00000e-01
Grad=  tensor(1.6746, device='cuda:0')
Epoch: [37][0/391]	Time 0.235 (0.235)	Data 0.114 (0.114)	Loss 0.7000 (0.7000) ([0.433]+[0.267])	Prec@1 83.594 (83.594)
Epoch: [37][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6811 (0.8104) ([0.414]+[0.267])	Prec@1 89.062 (81.467)
Epoch: [37][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7237 (0.8019) ([0.456]+[0.268])	Prec@1 82.812 (81.685)
Epoch: [37][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.8136 (0.8030) ([0.546]+[0.267])	Prec@1 78.125 (81.645)
Test: [0/79]	Time 0.148 (0.148)	Loss 1.0567 (1.0567) ([0.790]+[0.266])	Prec@1 70.312 (70.312)
 * Prec@1 70.010
current lr 1.00000e-01
Grad=  tensor(2.0303, device='cuda:0')
Epoch: [38][0/391]	Time 0.240 (0.240)	Data 0.119 (0.119)	Loss 0.7510 (0.7510) ([0.485]+[0.266])	Prec@1 79.688 (79.688)
Epoch: [38][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.8092 (0.7536) ([0.544]+[0.265])	Prec@1 78.125 (83.292)
Epoch: [38][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6953 (0.7721) ([0.430]+[0.265])	Prec@1 87.500 (82.610)
Epoch: [38][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.7756 (0.7840) ([0.510]+[0.266])	Prec@1 84.375 (82.280)
Test: [0/79]	Time 0.149 (0.149)	Loss 1.1664 (1.1664) ([0.901]+[0.265])	Prec@1 68.750 (68.750)
 * Prec@1 70.900
current lr 1.00000e-01
Grad=  tensor(1.8924, device='cuda:0')
Epoch: [39][0/391]	Time 0.238 (0.238)	Data 0.116 (0.116)	Loss 0.7476 (0.7476) ([0.482]+[0.265])	Prec@1 86.719 (86.719)
Epoch: [39][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.8596 (0.7691) ([0.595]+[0.264])	Prec@1 79.688 (82.782)
Epoch: [39][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.6925 (0.7741) ([0.428]+[0.264])	Prec@1 85.156 (82.661)
Epoch: [39][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.7891 (0.7852) ([0.525]+[0.265])	Prec@1 82.812 (82.247)
Test: [0/79]	Time 0.150 (0.150)	Loss 1.1913 (1.1913) ([0.926]+[0.265])	Prec@1 68.750 (68.750)
 * Prec@1 72.130
current lr 1.00000e-01
Grad=  tensor(2.3835, device='cuda:0')
Epoch: [40][0/391]	Time 0.238 (0.238)	Data 0.116 (0.116)	Loss 0.8052 (0.8052) ([0.540]+[0.265])	Prec@1 82.031 (82.031)
Epoch: [40][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.8600 (0.7872) ([0.595]+[0.265])	Prec@1 80.469 (82.085)
Epoch: [40][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.9772 (0.7999) ([0.712]+[0.265])	Prec@1 75.781 (81.534)
Epoch: [40][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.8033 (0.7975) ([0.538]+[0.265])	Prec@1 83.594 (81.645)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.8195 (0.8195) ([0.556]+[0.264])	Prec@1 79.688 (79.688)
 * Prec@1 79.700
current lr 1.00000e-01
Grad=  tensor(1.2451, device='cuda:0')
Epoch: [41][0/391]	Time 0.238 (0.238)	Data 0.118 (0.118)	Loss 0.5965 (0.5965) ([0.333]+[0.264])	Prec@1 91.406 (91.406)
Epoch: [41][100/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.9505 (0.7830) ([0.686]+[0.265])	Prec@1 78.125 (82.426)
Epoch: [41][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.8521 (0.7818) ([0.589]+[0.263])	Prec@1 81.250 (82.529)
Epoch: [41][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.7231 (0.7818) ([0.460]+[0.263])	Prec@1 85.156 (82.418)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.9945 (0.9945) ([0.732]+[0.263])	Prec@1 76.562 (76.562)
 * Prec@1 76.150
current lr 1.00000e-01
Grad=  tensor(2.7185, device='cuda:0')
Epoch: [42][0/391]	Time 0.242 (0.242)	Data 0.119 (0.119)	Loss 0.8667 (0.8667) ([0.604]+[0.263])	Prec@1 79.688 (79.688)
Epoch: [42][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.5639 (0.7874) ([0.300]+[0.264])	Prec@1 90.625 (82.140)
Epoch: [42][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6914 (0.7903) ([0.428]+[0.263])	Prec@1 82.812 (81.973)
Epoch: [42][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 0.7617 (0.7844) ([0.499]+[0.262])	Prec@1 84.375 (82.107)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.9268 (0.9268) ([0.664]+[0.263])	Prec@1 76.562 (76.562)
 * Prec@1 77.350
current lr 1.00000e-01
Grad=  tensor(2.1971, device='cuda:0')
Epoch: [43][0/391]	Time 0.241 (0.241)	Data 0.119 (0.119)	Loss 0.8071 (0.8071) ([0.544]+[0.263])	Prec@1 82.031 (82.031)
Epoch: [43][100/391]	Time 0.112 (0.113)	Data 0.000 (0.001)	Loss 0.7190 (0.7969) ([0.456]+[0.263])	Prec@1 85.938 (81.962)
Epoch: [43][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6608 (0.7916) ([0.398]+[0.263])	Prec@1 83.594 (82.000)
Epoch: [43][300/391]	Time 0.110 (0.112)	Data 0.000 (0.000)	Loss 0.6733 (0.7926) ([0.410]+[0.263])	Prec@1 86.719 (81.896)
Test: [0/79]	Time 0.151 (0.151)	Loss 1.0219 (1.0219) ([0.759]+[0.263])	Prec@1 77.344 (77.344)
 * Prec@1 74.320
current lr 1.00000e-01
Grad=  tensor(2.2129, device='cuda:0')
Epoch: [44][0/391]	Time 0.241 (0.241)	Data 0.118 (0.118)	Loss 0.7885 (0.7885) ([0.526]+[0.263])	Prec@1 80.469 (80.469)
Epoch: [44][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8472 (0.7800) ([0.584]+[0.263])	Prec@1 83.594 (82.519)
Epoch: [44][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.6958 (0.7852) ([0.432]+[0.264])	Prec@1 86.719 (82.105)
Epoch: [44][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.8126 (0.7872) ([0.550]+[0.262])	Prec@1 82.812 (82.018)
Test: [0/79]	Time 0.146 (0.146)	Loss 1.4330 (1.4330) ([1.171]+[0.262])	Prec@1 61.719 (61.719)
 * Prec@1 67.370
current lr 1.00000e-01
Grad=  tensor(2.5621, device='cuda:0')
Epoch: [45][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.8276 (0.8276) ([0.566]+[0.262])	Prec@1 79.688 (79.688)
Epoch: [45][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.9191 (0.7799) ([0.657]+[0.262])	Prec@1 78.906 (82.163)
Epoch: [45][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8951 (0.7810) ([0.634]+[0.261])	Prec@1 77.344 (82.175)
Epoch: [45][300/391]	Time 0.111 (0.110)	Data 0.000 (0.000)	Loss 0.8187 (0.7777) ([0.558]+[0.260])	Prec@1 78.906 (82.278)
Test: [0/79]	Time 0.149 (0.149)	Loss 1.0813 (1.0813) ([0.820]+[0.261])	Prec@1 71.875 (71.875)
 * Prec@1 72.970
current lr 1.00000e-01
Grad=  tensor(2.4482, device='cuda:0')
Epoch: [46][0/391]	Time 0.235 (0.235)	Data 0.116 (0.116)	Loss 0.7918 (0.7918) ([0.531]+[0.261])	Prec@1 81.250 (81.250)
Epoch: [46][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8762 (0.7535) ([0.616]+[0.260])	Prec@1 78.906 (83.377)
Epoch: [46][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8226 (0.7695) ([0.561]+[0.261])	Prec@1 79.688 (82.844)
Epoch: [46][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.7760 (0.7764) ([0.515]+[0.261])	Prec@1 85.938 (82.519)
Test: [0/79]	Time 0.148 (0.148)	Loss 1.2287 (1.2287) ([0.967]+[0.261])	Prec@1 69.531 (69.531)
 * Prec@1 74.450
current lr 1.00000e-01
Grad=  tensor(2.1568, device='cuda:0')
Epoch: [47][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.7877 (0.7877) ([0.526]+[0.261])	Prec@1 81.250 (81.250)
Epoch: [47][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7738 (0.7672) ([0.513]+[0.261])	Prec@1 82.031 (82.774)
Epoch: [47][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7603 (0.7706) ([0.500]+[0.261])	Prec@1 81.250 (82.540)
Epoch: [47][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.8041 (0.7752) ([0.544]+[0.260])	Prec@1 82.031 (82.345)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.9584 (0.9584) ([0.698]+[0.260])	Prec@1 74.219 (74.219)
 * Prec@1 76.950
current lr 1.00000e-01
Grad=  tensor(2.2105, device='cuda:0')
Epoch: [48][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.7051 (0.7051) ([0.445]+[0.260])	Prec@1 83.594 (83.594)
Epoch: [48][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.8024 (0.7691) ([0.542]+[0.260])	Prec@1 82.031 (82.774)
Epoch: [48][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.8123 (0.7714) ([0.552]+[0.260])	Prec@1 83.594 (82.708)
Epoch: [48][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.8340 (0.7778) ([0.574]+[0.260])	Prec@1 78.125 (82.366)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.9960 (0.9960) ([0.736]+[0.260])	Prec@1 73.438 (73.438)
 * Prec@1 75.900
current lr 1.00000e-01
Grad=  tensor(2.8080, device='cuda:0')
Epoch: [49][0/391]	Time 0.235 (0.235)	Data 0.116 (0.116)	Loss 0.8757 (0.8757) ([0.615]+[0.260])	Prec@1 75.000 (75.000)
Epoch: [49][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.9279 (0.7659) ([0.669]+[0.259])	Prec@1 77.344 (82.874)
Epoch: [49][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8237 (0.7752) ([0.565]+[0.259])	Prec@1 83.594 (82.758)
Epoch: [49][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.6278 (0.7708) ([0.369]+[0.259])	Prec@1 89.062 (82.737)
Test: [0/79]	Time 0.150 (0.150)	Loss 1.0940 (1.0940) ([0.836]+[0.258])	Prec@1 77.344 (77.344)
 * Prec@1 74.260
current lr 1.00000e-01
Grad=  tensor(1.9614, device='cuda:0')
Epoch: [50][0/391]	Time 0.235 (0.235)	Data 0.115 (0.115)	Loss 0.7289 (0.7289) ([0.471]+[0.258])	Prec@1 83.594 (83.594)
Epoch: [50][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.6316 (0.7834) ([0.374]+[0.258])	Prec@1 87.500 (82.163)
Epoch: [50][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.6610 (0.7858) ([0.403]+[0.258])	Prec@1 85.938 (81.988)
Epoch: [50][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.7985 (0.7834) ([0.540]+[0.259])	Prec@1 80.469 (81.990)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.9634 (0.9634) ([0.705]+[0.258])	Prec@1 75.000 (75.000)
 * Prec@1 76.460
current lr 1.00000e-01
Grad=  tensor(2.1034, device='cuda:0')
Epoch: [51][0/391]	Time 0.236 (0.236)	Data 0.116 (0.116)	Loss 0.7577 (0.7577) ([0.499]+[0.258])	Prec@1 80.469 (80.469)
Epoch: [51][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.9450 (0.7580) ([0.686]+[0.259])	Prec@1 77.344 (82.983)
Epoch: [51][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.6393 (0.7626) ([0.381]+[0.258])	Prec@1 87.500 (82.789)
Epoch: [51][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.7607 (0.7701) ([0.502]+[0.259])	Prec@1 78.125 (82.491)
Test: [0/79]	Time 0.151 (0.151)	Loss 1.1821 (1.1821) ([0.924]+[0.258])	Prec@1 71.094 (71.094)
 * Prec@1 72.490
current lr 1.00000e-01
Grad=  tensor(2.5359, device='cuda:0')
Epoch: [52][0/391]	Time 0.238 (0.238)	Data 0.116 (0.116)	Loss 0.7824 (0.7824) ([0.524]+[0.258])	Prec@1 78.906 (78.906)
Epoch: [52][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.8630 (0.7792) ([0.604]+[0.259])	Prec@1 78.125 (82.101)
Epoch: [52][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.8433 (0.7740) ([0.585]+[0.259])	Prec@1 79.688 (82.292)
Epoch: [52][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.7401 (0.7779) ([0.482]+[0.258])	Prec@1 85.156 (82.195)
Test: [0/79]	Time 0.151 (0.151)	Loss 1.0218 (1.0218) ([0.764]+[0.258])	Prec@1 74.219 (74.219)
 * Prec@1 75.160
current lr 1.00000e-01
Grad=  tensor(1.9425, device='cuda:0')
Epoch: [53][0/391]	Time 0.243 (0.243)	Data 0.118 (0.118)	Loss 0.6408 (0.6408) ([0.383]+[0.258])	Prec@1 84.375 (84.375)
Epoch: [53][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.7311 (0.7544) ([0.473]+[0.258])	Prec@1 84.375 (82.859)
Epoch: [53][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8851 (0.7714) ([0.627]+[0.259])	Prec@1 78.906 (82.323)
Epoch: [53][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.6541 (0.7740) ([0.397]+[0.257])	Prec@1 85.156 (82.267)
Test: [0/79]	Time 0.150 (0.150)	Loss 1.0460 (1.0460) ([0.789]+[0.257])	Prec@1 75.000 (75.000)
 * Prec@1 75.490
current lr 1.00000e-01
Grad=  tensor(2.2325, device='cuda:0')
Epoch: [54][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.7375 (0.7375) ([0.481]+[0.257])	Prec@1 80.469 (80.469)
Epoch: [54][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.7989 (0.7549) ([0.543]+[0.256])	Prec@1 78.906 (83.114)
Epoch: [54][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.8535 (0.7549) ([0.598]+[0.255])	Prec@1 79.688 (83.081)
Epoch: [54][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.6183 (0.7592) ([0.364]+[0.255])	Prec@1 84.375 (82.797)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.8102 (0.8102) ([0.555]+[0.255])	Prec@1 82.031 (82.031)
 * Prec@1 78.270
current lr 1.00000e-01
Grad=  tensor(1.4045, device='cuda:0')
Epoch: [55][0/391]	Time 0.235 (0.235)	Data 0.114 (0.114)	Loss 0.6210 (0.6210) ([0.366]+[0.255])	Prec@1 89.062 (89.062)
Epoch: [55][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8065 (0.7539) ([0.552]+[0.255])	Prec@1 82.031 (82.890)
Epoch: [55][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7226 (0.7589) ([0.467]+[0.256])	Prec@1 86.719 (82.789)
Epoch: [55][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.8223 (0.7631) ([0.567]+[0.255])	Prec@1 81.250 (82.716)
Test: [0/79]	Time 0.154 (0.154)	Loss 1.0312 (1.0312) ([0.776]+[0.255])	Prec@1 73.438 (73.438)
 * Prec@1 73.000
current lr 1.00000e-01
Grad=  tensor(1.9348, device='cuda:0')
Epoch: [56][0/391]	Time 0.243 (0.243)	Data 0.118 (0.118)	Loss 0.7384 (0.7384) ([0.484]+[0.255])	Prec@1 83.594 (83.594)
Epoch: [56][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.8108 (0.7696) ([0.556]+[0.255])	Prec@1 80.469 (82.310)
Epoch: [56][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 1.0097 (0.7713) ([0.755]+[0.255])	Prec@1 74.219 (82.299)
Epoch: [56][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.9479 (0.7627) ([0.693]+[0.255])	Prec@1 78.906 (82.602)
Test: [0/79]	Time 0.153 (0.153)	Loss 0.7926 (0.7926) ([0.538]+[0.255])	Prec@1 83.594 (83.594)
 * Prec@1 76.900
current lr 1.00000e-01
Grad=  tensor(1.3199, device='cuda:0')
Epoch: [57][0/391]	Time 0.240 (0.240)	Data 0.119 (0.119)	Loss 0.6450 (0.6450) ([0.390]+[0.255])	Prec@1 88.281 (88.281)
Epoch: [57][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7712 (0.7657) ([0.516]+[0.255])	Prec@1 83.594 (82.689)
Epoch: [57][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6865 (0.7642) ([0.432]+[0.254])	Prec@1 86.719 (82.739)
Epoch: [57][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.8191 (0.7667) ([0.564]+[0.255])	Prec@1 83.594 (82.662)
Test: [0/79]	Time 0.147 (0.147)	Loss 1.0893 (1.0893) ([0.835]+[0.255])	Prec@1 75.000 (75.000)
 * Prec@1 72.150
current lr 1.00000e-01
Grad=  tensor(2.6860, device='cuda:0')
Epoch: [58][0/391]	Time 0.240 (0.240)	Data 0.119 (0.119)	Loss 0.8375 (0.8375) ([0.583]+[0.255])	Prec@1 78.125 (78.125)
Epoch: [58][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7030 (0.7540) ([0.448]+[0.255])	Prec@1 85.156 (82.867)
Epoch: [58][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7686 (0.7585) ([0.515]+[0.254])	Prec@1 80.469 (82.684)
Epoch: [58][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.6673 (0.7590) ([0.414]+[0.254])	Prec@1 87.500 (82.662)
Test: [0/79]	Time 0.153 (0.153)	Loss 1.0401 (1.0401) ([0.788]+[0.253])	Prec@1 73.438 (73.438)
 * Prec@1 75.510
current lr 1.00000e-01
Grad=  tensor(2.1752, device='cuda:0')
Epoch: [59][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.7326 (0.7326) ([0.480]+[0.253])	Prec@1 82.031 (82.031)
Epoch: [59][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7112 (0.7449) ([0.459]+[0.252])	Prec@1 82.031 (83.168)
Epoch: [59][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.6265 (0.7548) ([0.373]+[0.253])	Prec@1 88.281 (82.673)
Epoch: [59][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.8269 (0.7587) ([0.574]+[0.253])	Prec@1 81.250 (82.701)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.8702 (0.8702) ([0.617]+[0.253])	Prec@1 84.375 (84.375)
 * Prec@1 76.390
current lr 1.00000e-01
Grad=  tensor(1.7975, device='cuda:0')
Epoch: [60][0/391]	Time 0.239 (0.239)	Data 0.119 (0.119)	Loss 0.7651 (0.7651) ([0.512]+[0.253])	Prec@1 83.594 (83.594)
Epoch: [60][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.8202 (0.7550) ([0.567]+[0.253])	Prec@1 79.688 (83.091)
Epoch: [60][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7114 (0.7615) ([0.458]+[0.253])	Prec@1 82.812 (82.696)
Epoch: [60][300/391]	Time 0.109 (0.111)	Data 0.000 (0.000)	Loss 0.7181 (0.7574) ([0.466]+[0.252])	Prec@1 84.375 (82.805)
Test: [0/79]	Time 0.151 (0.151)	Loss 1.0086 (1.0086) ([0.756]+[0.252])	Prec@1 71.094 (71.094)
 * Prec@1 71.490
current lr 1.00000e-01
Grad=  tensor(1.8266, device='cuda:0')
Epoch: [61][0/391]	Time 0.236 (0.236)	Data 0.117 (0.117)	Loss 0.7141 (0.7141) ([0.462]+[0.252])	Prec@1 84.375 (84.375)
Epoch: [61][100/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.8642 (0.7721) ([0.611]+[0.253])	Prec@1 78.125 (82.333)
Epoch: [61][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7694 (0.7650) ([0.518]+[0.252])	Prec@1 84.375 (82.568)
Epoch: [61][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.7535 (0.7663) ([0.501]+[0.252])	Prec@1 84.375 (82.444)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.8051 (0.8051) ([0.553]+[0.252])	Prec@1 82.812 (82.812)
 * Prec@1 80.410
current lr 1.00000e-01
Grad=  tensor(1.6268, device='cuda:0')
Epoch: [62][0/391]	Time 0.242 (0.242)	Data 0.116 (0.116)	Loss 0.6765 (0.6765) ([0.424]+[0.252])	Prec@1 85.156 (85.156)
Epoch: [62][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.9396 (0.7445) ([0.688]+[0.252])	Prec@1 77.344 (83.238)
Epoch: [62][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7904 (0.7551) ([0.540]+[0.251])	Prec@1 78.906 (83.046)
Epoch: [62][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.6107 (0.7530) ([0.360]+[0.250])	Prec@1 87.500 (83.031)
Test: [0/79]	Time 0.149 (0.149)	Loss 1.4861 (1.4861) ([1.236]+[0.250])	Prec@1 64.062 (64.062)
 * Prec@1 69.110
current lr 1.00000e-01
Grad=  tensor(1.4202, device='cuda:0')
Epoch: [63][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.6521 (0.6521) ([0.402]+[0.250])	Prec@1 88.281 (88.281)
Epoch: [63][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.7048 (0.7383) ([0.455]+[0.250])	Prec@1 82.031 (83.246)
Epoch: [63][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.9509 (0.7582) ([0.700]+[0.251])	Prec@1 78.125 (82.568)
Epoch: [63][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.6999 (0.7588) ([0.450]+[0.250])	Prec@1 87.500 (82.511)
Test: [0/79]	Time 0.149 (0.149)	Loss 1.0097 (1.0097) ([0.760]+[0.250])	Prec@1 75.781 (75.781)
 * Prec@1 77.420
current lr 1.00000e-01
Grad=  tensor(1.9036, device='cuda:0')
Epoch: [64][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.7370 (0.7370) ([0.487]+[0.250])	Prec@1 80.469 (80.469)
Epoch: [64][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7423 (0.7534) ([0.491]+[0.251])	Prec@1 82.812 (82.550)
Epoch: [64][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.6897 (0.7603) ([0.439]+[0.251])	Prec@1 87.500 (82.338)
Epoch: [64][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.7218 (0.7614) ([0.471]+[0.251])	Prec@1 85.938 (82.402)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.9342 (0.9342) ([0.684]+[0.250])	Prec@1 74.219 (74.219)
 * Prec@1 74.390
current lr 1.00000e-01
Grad=  tensor(2.3932, device='cuda:0')
Epoch: [65][0/391]	Time 0.237 (0.237)	Data 0.117 (0.117)	Loss 0.7251 (0.7251) ([0.475]+[0.250])	Prec@1 81.250 (81.250)
Epoch: [65][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.6853 (0.7662) ([0.435]+[0.251])	Prec@1 85.156 (82.348)
Epoch: [65][200/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.7876 (0.7690) ([0.537]+[0.251])	Prec@1 79.688 (82.303)
Epoch: [65][300/391]	Time 0.112 (0.110)	Data 0.000 (0.000)	Loss 0.7349 (0.7653) ([0.485]+[0.250])	Prec@1 82.031 (82.345)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.9125 (0.9125) ([0.663]+[0.249])	Prec@1 77.344 (77.344)
 * Prec@1 77.270
current lr 1.00000e-01
Grad=  tensor(1.5514, device='cuda:0')
Epoch: [66][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.6701 (0.6701) ([0.421]+[0.249])	Prec@1 84.375 (84.375)
Epoch: [66][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7692 (0.7537) ([0.520]+[0.250])	Prec@1 82.812 (82.735)
Epoch: [66][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7156 (0.7507) ([0.466]+[0.250])	Prec@1 84.375 (82.921)
Epoch: [66][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.7216 (0.7500) ([0.473]+[0.249])	Prec@1 82.812 (82.859)
Test: [0/79]	Time 0.149 (0.149)	Loss 1.1492 (1.1492) ([0.900]+[0.249])	Prec@1 70.312 (70.312)
 * Prec@1 68.330
current lr 1.00000e-01
Grad=  tensor(1.5327, device='cuda:0')
Epoch: [67][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.6198 (0.6198) ([0.371]+[0.249])	Prec@1 86.719 (86.719)
Epoch: [67][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.6898 (0.7362) ([0.441]+[0.249])	Prec@1 81.250 (82.898)
Epoch: [67][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6728 (0.7502) ([0.423]+[0.250])	Prec@1 86.719 (82.805)
Epoch: [67][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.8230 (0.7577) ([0.574]+[0.250])	Prec@1 81.250 (82.537)
Test: [0/79]	Time 0.149 (0.149)	Loss 1.0061 (1.0061) ([0.757]+[0.249])	Prec@1 72.656 (72.656)
 * Prec@1 72.700
current lr 1.00000e-01
Grad=  tensor(3.7498, device='cuda:0')
Epoch: [68][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.9421 (0.9421) ([0.693]+[0.249])	Prec@1 77.344 (77.344)
Epoch: [68][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.7576 (0.7353) ([0.509]+[0.248])	Prec@1 79.688 (83.455)
Epoch: [68][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7652 (0.7395) ([0.517]+[0.249])	Prec@1 78.906 (83.158)
Epoch: [68][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.8540 (0.7446) ([0.605]+[0.249])	Prec@1 77.344 (83.111)
Test: [0/79]	Time 0.151 (0.151)	Loss 1.1997 (1.1997) ([0.951]+[0.249])	Prec@1 67.969 (67.969)
 * Prec@1 71.430
current lr 1.00000e-01
Grad=  tensor(1.2985, device='cuda:0')
Epoch: [69][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.6378 (0.6378) ([0.389]+[0.249])	Prec@1 83.594 (83.594)
Epoch: [69][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7824 (0.7500) ([0.533]+[0.249])	Prec@1 83.594 (82.975)
Epoch: [69][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.9891 (0.7554) ([0.740]+[0.250])	Prec@1 71.094 (82.673)
Epoch: [69][300/391]	Time 0.113 (0.111)	Data 0.000 (0.000)	Loss 0.6787 (0.7620) ([0.429]+[0.250])	Prec@1 87.500 (82.395)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.8557 (0.8557) ([0.607]+[0.248])	Prec@1 79.688 (79.688)
 * Prec@1 78.020
current lr 1.00000e-01
Grad=  tensor(2.4724, device='cuda:0')
Epoch: [70][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.7735 (0.7735) ([0.525]+[0.248])	Prec@1 79.688 (79.688)
Epoch: [70][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7844 (0.7513) ([0.536]+[0.248])	Prec@1 83.594 (83.192)
Epoch: [70][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6550 (0.7597) ([0.407]+[0.248])	Prec@1 88.281 (82.638)
Epoch: [70][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.7959 (0.7606) ([0.548]+[0.248])	Prec@1 81.250 (82.571)
Test: [0/79]	Time 0.150 (0.150)	Loss 1.0688 (1.0688) ([0.821]+[0.248])	Prec@1 78.906 (78.906)
 * Prec@1 74.100
current lr 1.00000e-01
Grad=  tensor(1.6984, device='cuda:0')
Epoch: [71][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.7733 (0.7733) ([0.525]+[0.248])	Prec@1 81.250 (81.250)
Epoch: [71][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7004 (0.7387) ([0.452]+[0.248])	Prec@1 82.031 (83.052)
Epoch: [71][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7224 (0.7452) ([0.474]+[0.248])	Prec@1 83.594 (83.104)
Epoch: [71][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.7753 (0.7461) ([0.528]+[0.247])	Prec@1 80.469 (83.085)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.9304 (0.9304) ([0.683]+[0.248])	Prec@1 76.562 (76.562)
 * Prec@1 78.520
current lr 1.00000e-01
Grad=  tensor(1.9819, device='cuda:0')
Epoch: [72][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.6958 (0.6958) ([0.448]+[0.248])	Prec@1 82.031 (82.031)
Epoch: [72][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.8170 (0.7284) ([0.570]+[0.247])	Prec@1 79.688 (83.540)
Epoch: [72][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6625 (0.7368) ([0.415]+[0.247])	Prec@1 85.156 (82.987)
Epoch: [72][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.6884 (0.7457) ([0.441]+[0.248])	Prec@1 84.375 (82.753)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.7839 (0.7839) ([0.537]+[0.247])	Prec@1 82.812 (82.812)
 * Prec@1 79.620
current lr 1.00000e-01
Grad=  tensor(2.2254, device='cuda:0')
Epoch: [73][0/391]	Time 0.240 (0.240)	Data 0.119 (0.119)	Loss 0.7595 (0.7595) ([0.512]+[0.247])	Prec@1 80.469 (80.469)
Epoch: [73][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7046 (0.7493) ([0.457]+[0.248])	Prec@1 85.156 (82.727)
Epoch: [73][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.8999 (0.7533) ([0.652]+[0.248])	Prec@1 78.906 (82.770)
Epoch: [73][300/391]	Time 0.109 (0.111)	Data 0.000 (0.000)	Loss 0.7063 (0.7539) ([0.459]+[0.247])	Prec@1 85.938 (82.859)
Test: [0/79]	Time 0.149 (0.149)	Loss 1.3416 (1.3416) ([1.095]+[0.247])	Prec@1 68.750 (68.750)
 * Prec@1 66.450
current lr 1.00000e-01
Grad=  tensor(2.3378, device='cuda:0')
Epoch: [74][0/391]	Time 0.237 (0.237)	Data 0.117 (0.117)	Loss 0.7522 (0.7522) ([0.505]+[0.247])	Prec@1 78.906 (78.906)
Epoch: [74][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.6706 (0.7279) ([0.424]+[0.247])	Prec@1 85.156 (83.230)
Epoch: [74][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7704 (0.7425) ([0.524]+[0.246])	Prec@1 81.250 (82.933)
Epoch: [74][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7769 (0.7474) ([0.531]+[0.245])	Prec@1 84.375 (82.838)
Test: [0/79]	Time 0.144 (0.144)	Loss 0.7953 (0.7953) ([0.550]+[0.245])	Prec@1 82.031 (82.031)
 * Prec@1 80.700
current lr 1.00000e-01
Grad=  tensor(1.0804, device='cuda:0')
Epoch: [75][0/391]	Time 0.240 (0.240)	Data 0.119 (0.119)	Loss 0.5028 (0.5028) ([0.258]+[0.245])	Prec@1 91.406 (91.406)
Epoch: [75][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.6360 (0.7268) ([0.391]+[0.245])	Prec@1 88.281 (83.818)
Epoch: [75][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 1.0147 (0.7443) ([0.768]+[0.246])	Prec@1 77.344 (83.007)
Epoch: [75][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.7579 (0.7433) ([0.512]+[0.246])	Prec@1 82.031 (82.966)
Test: [0/79]	Time 0.150 (0.150)	Loss 1.1672 (1.1672) ([0.920]+[0.247])	Prec@1 71.094 (71.094)
 * Prec@1 71.960
current lr 1.00000e-01
Grad=  tensor(2.1255, device='cuda:0')
Epoch: [76][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.8476 (0.8476) ([0.601]+[0.247])	Prec@1 79.688 (79.688)
Epoch: [76][100/391]	Time 0.108 (0.111)	Data 0.000 (0.001)	Loss 0.6281 (0.7390) ([0.382]+[0.246])	Prec@1 85.156 (82.727)
Epoch: [76][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.6504 (0.7397) ([0.405]+[0.245])	Prec@1 83.594 (83.038)
Epoch: [76][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.6192 (0.7443) ([0.373]+[0.246])	Prec@1 88.281 (82.877)
Test: [0/79]	Time 0.146 (0.146)	Loss 1.2678 (1.2678) ([1.021]+[0.247])	Prec@1 70.312 (70.312)
 * Prec@1 68.170
current lr 1.00000e-01
Grad=  tensor(1.6505, device='cuda:0')
Epoch: [77][0/391]	Time 0.238 (0.238)	Data 0.118 (0.118)	Loss 0.6702 (0.6702) ([0.423]+[0.247])	Prec@1 83.594 (83.594)
Epoch: [77][100/391]	Time 0.108 (0.111)	Data 0.000 (0.001)	Loss 0.6960 (0.7346) ([0.450]+[0.246])	Prec@1 84.375 (83.300)
Epoch: [77][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7294 (0.7467) ([0.483]+[0.246])	Prec@1 81.250 (82.879)
Epoch: [77][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.7061 (0.7465) ([0.461]+[0.245])	Prec@1 82.812 (82.841)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.9291 (0.9291) ([0.684]+[0.246])	Prec@1 76.562 (76.562)
 * Prec@1 77.640
current lr 1.00000e-01
Grad=  tensor(1.6048, device='cuda:0')
Epoch: [78][0/391]	Time 0.239 (0.239)	Data 0.119 (0.119)	Loss 0.6754 (0.6754) ([0.430]+[0.246])	Prec@1 85.938 (85.938)
Epoch: [78][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7400 (0.7315) ([0.495]+[0.245])	Prec@1 85.156 (83.354)
Epoch: [78][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.6610 (0.7323) ([0.416]+[0.245])	Prec@1 84.375 (83.314)
Epoch: [78][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.9540 (0.7420) ([0.709]+[0.244])	Prec@1 76.562 (83.103)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.9348 (0.9348) ([0.691]+[0.244])	Prec@1 78.906 (78.906)
 * Prec@1 75.280
current lr 1.00000e-01
Grad=  tensor(2.2995, device='cuda:0')
Epoch: [79][0/391]	Time 0.237 (0.237)	Data 0.119 (0.119)	Loss 0.7880 (0.7880) ([0.544]+[0.244])	Prec@1 81.250 (81.250)
Epoch: [79][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7462 (0.7418) ([0.502]+[0.244])	Prec@1 79.688 (82.681)
Epoch: [79][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8377 (0.7393) ([0.594]+[0.244])	Prec@1 78.125 (82.875)
Epoch: [79][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.6975 (0.7476) ([0.453]+[0.245])	Prec@1 84.375 (82.615)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.9799 (0.9799) ([0.735]+[0.244])	Prec@1 78.125 (78.125)
 * Prec@1 78.570
current lr 1.00000e-01
Grad=  tensor(2.5184, device='cuda:0')
Epoch: [80][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.7624 (0.7624) ([0.518]+[0.244])	Prec@1 78.906 (78.906)
Epoch: [80][100/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.7556 (0.7207) ([0.512]+[0.244])	Prec@1 84.375 (83.501)
Epoch: [80][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7267 (0.7344) ([0.482]+[0.244])	Prec@1 82.031 (83.007)
Epoch: [80][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.8603 (0.7399) ([0.616]+[0.244])	Prec@1 82.031 (82.971)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.8536 (0.8536) ([0.609]+[0.244])	Prec@1 80.469 (80.469)
 * Prec@1 76.590
current lr 1.00000e-01
Grad=  tensor(1.8179, device='cuda:0')
Epoch: [81][0/391]	Time 0.243 (0.243)	Data 0.118 (0.118)	Loss 0.7373 (0.7373) ([0.493]+[0.244])	Prec@1 82.031 (82.031)
Epoch: [81][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.6959 (0.7384) ([0.452]+[0.244])	Prec@1 85.938 (83.122)
Epoch: [81][200/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.7602 (0.7390) ([0.517]+[0.243])	Prec@1 85.938 (82.941)
Epoch: [81][300/391]	Time 0.110 (0.110)	Data 0.000 (0.000)	Loss 0.7595 (0.7427) ([0.516]+[0.243])	Prec@1 84.375 (82.750)
Test: [0/79]	Time 0.149 (0.149)	Loss 1.1558 (1.1558) ([0.913]+[0.243])	Prec@1 74.219 (74.219)
 * Prec@1 72.730
current lr 1.00000e-01
Grad=  tensor(2.9468, device='cuda:0')
Epoch: [82][0/391]	Time 0.235 (0.235)	Data 0.116 (0.116)	Loss 0.8612 (0.8612) ([0.619]+[0.243])	Prec@1 78.906 (78.906)
Epoch: [82][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7501 (0.7345) ([0.508]+[0.242])	Prec@1 83.594 (82.890)
Epoch: [82][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8829 (0.7433) ([0.640]+[0.243])	Prec@1 77.344 (82.599)
Epoch: [82][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.7707 (0.7417) ([0.529]+[0.242])	Prec@1 80.469 (82.620)
Test: [0/79]	Time 0.147 (0.147)	Loss 1.2223 (1.2223) ([0.980]+[0.242])	Prec@1 67.969 (67.969)
 * Prec@1 70.340
current lr 1.00000e-01
Grad=  tensor(1.7407, device='cuda:0')
Epoch: [83][0/391]	Time 0.238 (0.238)	Data 0.118 (0.118)	Loss 0.7285 (0.7285) ([0.486]+[0.242])	Prec@1 85.156 (85.156)
Epoch: [83][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7933 (0.7411) ([0.551]+[0.242])	Prec@1 80.469 (83.292)
Epoch: [83][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7558 (0.7474) ([0.513]+[0.243])	Prec@1 84.375 (82.824)
Epoch: [83][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.6965 (0.7446) ([0.455]+[0.241])	Prec@1 86.719 (82.877)
Test: [0/79]	Time 0.149 (0.149)	Loss 1.0051 (1.0051) ([0.763]+[0.242])	Prec@1 76.562 (76.562)
 * Prec@1 75.450
current lr 1.00000e-01
Grad=  tensor(2.0640, device='cuda:0')
Epoch: [84][0/391]	Time 0.238 (0.238)	Data 0.118 (0.118)	Loss 0.7862 (0.7862) ([0.544]+[0.242])	Prec@1 81.250 (81.250)
Epoch: [84][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7393 (0.7465) ([0.497]+[0.242])	Prec@1 78.906 (82.735)
Epoch: [84][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.8739 (0.7462) ([0.632]+[0.242])	Prec@1 78.125 (82.828)
Epoch: [84][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7464 (0.7400) ([0.505]+[0.242])	Prec@1 84.375 (83.038)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.9573 (0.9573) ([0.716]+[0.242])	Prec@1 75.000 (75.000)
 * Prec@1 77.750
current lr 1.00000e-01
Grad=  tensor(1.7511, device='cuda:0')
Epoch: [85][0/391]	Time 0.238 (0.238)	Data 0.119 (0.119)	Loss 0.7156 (0.7156) ([0.474]+[0.242])	Prec@1 83.594 (83.594)
Epoch: [85][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.6780 (0.7404) ([0.436]+[0.242])	Prec@1 83.594 (83.045)
Epoch: [85][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.9014 (0.7560) ([0.659]+[0.243])	Prec@1 80.469 (82.509)
Epoch: [85][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.7487 (0.7452) ([0.507]+[0.242])	Prec@1 82.031 (82.870)
Test: [0/79]	Time 0.149 (0.149)	Loss 1.1584 (1.1584) ([0.917]+[0.241])	Prec@1 70.312 (70.312)
 * Prec@1 73.650
current lr 1.00000e-01
Grad=  tensor(1.8541, device='cuda:0')
Epoch: [86][0/391]	Time 0.239 (0.239)	Data 0.119 (0.119)	Loss 0.7149 (0.7149) ([0.474]+[0.241])	Prec@1 85.938 (85.938)
Epoch: [86][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.6478 (0.7375) ([0.406]+[0.241])	Prec@1 89.844 (83.106)
Epoch: [86][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7578 (0.7306) ([0.517]+[0.241])	Prec@1 82.031 (83.477)
Epoch: [86][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.9435 (0.7391) ([0.703]+[0.241])	Prec@1 75.781 (83.194)
Test: [0/79]	Time 0.148 (0.148)	Loss 1.0648 (1.0648) ([0.824]+[0.240])	Prec@1 69.531 (69.531)
 * Prec@1 74.360
current lr 1.00000e-01
Grad=  tensor(1.5756, device='cuda:0')
Epoch: [87][0/391]	Time 0.237 (0.237)	Data 0.118 (0.118)	Loss 0.6316 (0.6316) ([0.391]+[0.240])	Prec@1 88.281 (88.281)
Epoch: [87][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7821 (0.7140) ([0.542]+[0.240])	Prec@1 82.812 (83.957)
Epoch: [87][200/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.6865 (0.7344) ([0.445]+[0.241])	Prec@1 85.156 (83.341)
Epoch: [87][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.8367 (0.7420) ([0.596]+[0.241])	Prec@1 78.906 (82.942)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.9270 (0.9270) ([0.687]+[0.240])	Prec@1 75.781 (75.781)
 * Prec@1 73.070
current lr 1.00000e-01
Grad=  tensor(2.4160, device='cuda:0')
Epoch: [88][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.7475 (0.7475) ([0.507]+[0.240])	Prec@1 84.375 (84.375)
Epoch: [88][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.7956 (0.7467) ([0.555]+[0.241])	Prec@1 80.469 (82.666)
Epoch: [88][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.6412 (0.7404) ([0.401]+[0.240])	Prec@1 85.156 (83.015)
Epoch: [88][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.8015 (0.7365) ([0.561]+[0.240])	Prec@1 81.250 (83.031)
Test: [0/79]	Time 0.153 (0.153)	Loss 1.0373 (1.0373) ([0.797]+[0.240])	Prec@1 75.781 (75.781)
 * Prec@1 70.330
current lr 1.00000e-01
Grad=  tensor(2.3535, device='cuda:0')
Epoch: [89][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.8037 (0.8037) ([0.564]+[0.240])	Prec@1 77.344 (77.344)
Epoch: [89][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.5476 (0.7284) ([0.307]+[0.240])	Prec@1 90.625 (83.199)
Epoch: [89][200/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.8173 (0.7297) ([0.577]+[0.240])	Prec@1 77.344 (83.193)
Epoch: [89][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.7387 (0.7342) ([0.499]+[0.240])	Prec@1 83.594 (83.080)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.9423 (0.9423) ([0.703]+[0.240])	Prec@1 75.000 (75.000)
 * Prec@1 75.650
current lr 1.00000e-01
Grad=  tensor(1.8146, device='cuda:0')
Epoch: [90][0/391]	Time 0.239 (0.239)	Data 0.119 (0.119)	Loss 0.6455 (0.6455) ([0.406]+[0.240])	Prec@1 87.500 (87.500)
Epoch: [90][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7415 (0.7138) ([0.502]+[0.239])	Prec@1 80.469 (83.571)
Epoch: [90][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.6826 (0.7339) ([0.442]+[0.241])	Prec@1 85.156 (83.042)
Epoch: [90][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.9815 (0.7376) ([0.742]+[0.239])	Prec@1 78.125 (82.942)
Test: [0/79]	Time 0.151 (0.151)	Loss 1.3425 (1.3425) ([1.103]+[0.240])	Prec@1 63.281 (63.281)
 * Prec@1 70.560
current lr 1.00000e-01
Grad=  tensor(1.8980, device='cuda:0')
Epoch: [91][0/391]	Time 0.235 (0.235)	Data 0.116 (0.116)	Loss 0.7132 (0.7132) ([0.474]+[0.240])	Prec@1 81.250 (81.250)
Epoch: [91][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7620 (0.7218) ([0.523]+[0.239])	Prec@1 80.469 (83.400)
Epoch: [91][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7432 (0.7285) ([0.503]+[0.240])	Prec@1 82.812 (83.228)
Epoch: [91][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.7506 (0.7383) ([0.510]+[0.241])	Prec@1 84.375 (83.015)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.8547 (0.8547) ([0.615]+[0.240])	Prec@1 78.906 (78.906)
 * Prec@1 76.980
current lr 1.00000e-01
Grad=  tensor(1.1631, device='cuda:0')
Epoch: [92][0/391]	Time 0.238 (0.238)	Data 0.118 (0.118)	Loss 0.5439 (0.5439) ([0.304]+[0.240])	Prec@1 92.188 (92.188)
Epoch: [92][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.6985 (0.7201) ([0.459]+[0.239])	Prec@1 82.812 (83.748)
Epoch: [92][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.6951 (0.7339) ([0.455]+[0.240])	Prec@1 86.719 (83.298)
Epoch: [92][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.8269 (0.7342) ([0.587]+[0.240])	Prec@1 81.250 (83.230)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.9542 (0.9542) ([0.715]+[0.240])	Prec@1 78.125 (78.125)
 * Prec@1 78.150
current lr 1.00000e-01
Grad=  tensor(1.9898, device='cuda:0')
Epoch: [93][0/391]	Time 0.237 (0.237)	Data 0.117 (0.117)	Loss 0.7190 (0.7190) ([0.479]+[0.240])	Prec@1 82.812 (82.812)
Epoch: [93][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7540 (0.7354) ([0.514]+[0.240])	Prec@1 84.375 (82.959)
Epoch: [93][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.7033 (0.7313) ([0.464]+[0.240])	Prec@1 80.469 (83.139)
Epoch: [93][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.6424 (0.7349) ([0.403]+[0.240])	Prec@1 82.031 (82.958)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.8532 (0.8532) ([0.615]+[0.239])	Prec@1 78.125 (78.125)
 * Prec@1 74.780
current lr 1.00000e-01
Grad=  tensor(2.0058, device='cuda:0')
Epoch: [94][0/391]	Time 0.235 (0.235)	Data 0.116 (0.116)	Loss 0.6985 (0.6985) ([0.460]+[0.239])	Prec@1 82.812 (82.812)
Epoch: [94][100/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.7661 (0.7315) ([0.527]+[0.239])	Prec@1 80.469 (83.176)
Epoch: [94][200/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.5974 (0.7237) ([0.360]+[0.238])	Prec@1 85.156 (83.508)
Epoch: [94][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.6882 (0.7300) ([0.450]+[0.238])	Prec@1 83.594 (83.267)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.7445 (0.7445) ([0.507]+[0.237])	Prec@1 83.594 (83.594)
 * Prec@1 78.250
current lr 1.00000e-01
Grad=  tensor(1.6248, device='cuda:0')
Epoch: [95][0/391]	Time 0.241 (0.241)	Data 0.119 (0.119)	Loss 0.6459 (0.6459) ([0.409]+[0.237])	Prec@1 85.156 (85.156)
Epoch: [95][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7338 (0.7154) ([0.497]+[0.237])	Prec@1 82.812 (83.594)
Epoch: [95][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.7504 (0.7272) ([0.512]+[0.238])	Prec@1 82.031 (83.322)
Epoch: [95][300/391]	Time 0.112 (0.112)	Data 0.000 (0.000)	Loss 0.7743 (0.7322) ([0.537]+[0.238])	Prec@1 85.156 (83.137)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.9780 (0.9780) ([0.740]+[0.238])	Prec@1 78.906 (78.906)
 * Prec@1 75.640
current lr 1.00000e-01
Grad=  tensor(1.9305, device='cuda:0')
Epoch: [96][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.6632 (0.6632) ([0.425]+[0.238])	Prec@1 84.375 (84.375)
Epoch: [96][100/391]	Time 0.109 (0.112)	Data 0.000 (0.001)	Loss 0.6854 (0.7347) ([0.447]+[0.238])	Prec@1 85.156 (83.176)
Epoch: [96][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6834 (0.7314) ([0.445]+[0.238])	Prec@1 80.469 (83.174)
Epoch: [96][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.7805 (0.7305) ([0.543]+[0.237])	Prec@1 79.688 (83.191)
Test: [0/79]	Time 0.150 (0.150)	Loss 1.0735 (1.0735) ([0.836]+[0.237])	Prec@1 75.781 (75.781)
 * Prec@1 74.070
current lr 1.00000e-01
Grad=  tensor(2.0284, device='cuda:0')
Epoch: [97][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.7480 (0.7480) ([0.511]+[0.237])	Prec@1 82.031 (82.031)
Epoch: [97][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7072 (0.7285) ([0.470]+[0.237])	Prec@1 85.938 (83.199)
Epoch: [97][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.6002 (0.7351) ([0.362]+[0.238])	Prec@1 86.719 (82.844)
Epoch: [97][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.6605 (0.7329) ([0.423]+[0.237])	Prec@1 86.719 (82.940)
Test: [0/79]	Time 0.149 (0.149)	Loss 1.0668 (1.0668) ([0.830]+[0.237])	Prec@1 71.875 (71.875)
 * Prec@1 69.900
current lr 1.00000e-01
Grad=  tensor(2.6882, device='cuda:0')
Epoch: [98][0/391]	Time 0.239 (0.239)	Data 0.117 (0.117)	Loss 0.7483 (0.7483) ([0.512]+[0.237])	Prec@1 82.031 (82.031)
Epoch: [98][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.6335 (0.7401) ([0.396]+[0.237])	Prec@1 87.500 (82.696)
Epoch: [98][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.7450 (0.7454) ([0.507]+[0.238])	Prec@1 83.594 (82.568)
Epoch: [98][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.9455 (0.7404) ([0.708]+[0.237])	Prec@1 78.906 (82.742)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.8657 (0.8657) ([0.628]+[0.238])	Prec@1 78.906 (78.906)
 * Prec@1 77.330
current lr 1.00000e-01
Grad=  tensor(2.0070, device='cuda:0')
Epoch: [99][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.6690 (0.6690) ([0.431]+[0.238])	Prec@1 84.375 (84.375)
Epoch: [99][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.7868 (0.7278) ([0.550]+[0.237])	Prec@1 79.688 (83.176)
Epoch: [99][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.7730 (0.7312) ([0.536]+[0.237])	Prec@1 79.688 (83.112)
Epoch: [99][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.7315 (0.7341) ([0.494]+[0.238])	Prec@1 82.812 (83.033)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.9452 (0.9452) ([0.708]+[0.237])	Prec@1 73.438 (73.438)
 * Prec@1 78.000
current lr 1.00000e-02
Grad=  tensor(2.2182, device='cuda:0')
Epoch: [100][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.7329 (0.7329) ([0.496]+[0.237])	Prec@1 82.031 (82.031)
Epoch: [100][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.4329 (0.5823) ([0.214]+[0.219])	Prec@1 94.531 (87.709)
Epoch: [100][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.5809 (0.5494) ([0.364]+[0.217])	Prec@1 85.156 (88.779)
Epoch: [100][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.5947 (0.5345) ([0.380]+[0.215])	Prec@1 88.281 (89.273)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4965 (0.4965) ([0.283]+[0.214])	Prec@1 89.844 (89.844)
 * Prec@1 89.680
current lr 1.00000e-02
Grad=  tensor(1.4846, device='cuda:0')
Epoch: [101][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.5120 (0.5120) ([0.298]+[0.214])	Prec@1 91.406 (91.406)
Epoch: [101][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.4516 (0.4743) ([0.240]+[0.212])	Prec@1 92.969 (90.989)
Epoch: [101][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.4047 (0.4640) ([0.194]+[0.210])	Prec@1 92.188 (91.433)
Epoch: [101][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.4141 (0.4636) ([0.205]+[0.209])	Prec@1 92.188 (91.357)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4712 (0.4712) ([0.264]+[0.207])	Prec@1 91.406 (91.406)
 * Prec@1 90.330
current lr 1.00000e-02
Grad=  tensor(0.9098, device='cuda:0')
Epoch: [102][0/391]	Time 0.239 (0.239)	Data 0.119 (0.119)	Loss 0.3551 (0.3551) ([0.148]+[0.207])	Prec@1 93.750 (93.750)
Epoch: [102][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.4857 (0.4291) ([0.280]+[0.206])	Prec@1 86.719 (92.536)
Epoch: [102][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.4995 (0.4295) ([0.295]+[0.204])	Prec@1 89.844 (92.510)
Epoch: [102][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.3644 (0.4330) ([0.161]+[0.203])	Prec@1 94.531 (92.343)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4249 (0.4249) ([0.223]+[0.202])	Prec@1 92.188 (92.188)
 * Prec@1 90.580
current lr 1.00000e-02
Grad=  tensor(1.4781, device='cuda:0')
Epoch: [103][0/391]	Time 0.241 (0.241)	Data 0.119 (0.119)	Loss 0.4036 (0.4036) ([0.202]+[0.202])	Prec@1 92.969 (92.969)
Epoch: [103][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.4324 (0.4105) ([0.232]+[0.201])	Prec@1 90.625 (92.768)
Epoch: [103][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.4509 (0.4169) ([0.252]+[0.199])	Prec@1 89.844 (92.518)
Epoch: [103][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.4301 (0.4135) ([0.232]+[0.198])	Prec@1 92.188 (92.618)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4213 (0.4213) ([0.224]+[0.197])	Prec@1 94.531 (94.531)
 * Prec@1 90.860
current lr 1.00000e-02
Grad=  tensor(1.2683, device='cuda:0')
Epoch: [104][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.3316 (0.3316) ([0.135]+[0.197])	Prec@1 96.094 (96.094)
Epoch: [104][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.4192 (0.4032) ([0.224]+[0.196])	Prec@1 89.844 (92.559)
Epoch: [104][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3485 (0.4007) ([0.154]+[0.194])	Prec@1 93.750 (92.751)
Epoch: [104][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.3572 (0.3957) ([0.164]+[0.193])	Prec@1 94.531 (92.974)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4703 (0.4703) ([0.278]+[0.192])	Prec@1 91.406 (91.406)
 * Prec@1 91.000
current lr 1.00000e-02
Grad=  tensor(3.3076, device='cuda:0')
Epoch: [105][0/391]	Time 0.238 (0.238)	Data 0.118 (0.118)	Loss 0.4635 (0.4635) ([0.271]+[0.192])	Prec@1 89.844 (89.844)
Epoch: [105][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.3468 (0.3705) ([0.156]+[0.191])	Prec@1 95.312 (93.789)
Epoch: [105][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3409 (0.3752) ([0.151]+[0.190])	Prec@1 94.531 (93.711)
Epoch: [105][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.4085 (0.3796) ([0.220]+[0.189])	Prec@1 91.406 (93.483)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.4161 (0.4161) ([0.228]+[0.188])	Prec@1 92.969 (92.969)
 * Prec@1 91.090
current lr 1.00000e-02
Grad=  tensor(2.7018, device='cuda:0')
Epoch: [106][0/391]	Time 0.239 (0.239)	Data 0.119 (0.119)	Loss 0.4611 (0.4611) ([0.273]+[0.188])	Prec@1 92.969 (92.969)
Epoch: [106][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3816 (0.3680) ([0.195]+[0.187])	Prec@1 96.094 (93.967)
Epoch: [106][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3633 (0.3709) ([0.178]+[0.186])	Prec@1 92.188 (93.719)
Epoch: [106][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.3566 (0.3688) ([0.172]+[0.185])	Prec@1 96.094 (93.771)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4729 (0.4729) ([0.289]+[0.184])	Prec@1 91.406 (91.406)
 * Prec@1 91.020
current lr 1.00000e-02
Grad=  tensor(1.5752, device='cuda:0')
Epoch: [107][0/391]	Time 0.235 (0.235)	Data 0.114 (0.114)	Loss 0.2979 (0.2979) ([0.114]+[0.184])	Prec@1 96.094 (96.094)
Epoch: [107][100/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.4016 (0.3556) ([0.219]+[0.183])	Prec@1 94.531 (94.052)
Epoch: [107][200/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.4012 (0.3520) ([0.220]+[0.182])	Prec@1 94.531 (94.189)
Epoch: [107][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3070 (0.3512) ([0.126]+[0.181])	Prec@1 94.531 (94.155)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4029 (0.4029) ([0.223]+[0.180])	Prec@1 89.844 (89.844)
 * Prec@1 90.670
current lr 1.00000e-02
Grad=  tensor(2.7521, device='cuda:0')
Epoch: [108][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.3374 (0.3374) ([0.158]+[0.180])	Prec@1 92.969 (92.969)
Epoch: [108][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.3464 (0.3508) ([0.168]+[0.179])	Prec@1 96.094 (93.905)
Epoch: [108][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3447 (0.3516) ([0.167]+[0.178])	Prec@1 94.531 (93.968)
Epoch: [108][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.3635 (0.3515) ([0.186]+[0.177])	Prec@1 95.312 (93.989)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4490 (0.4490) ([0.273]+[0.176])	Prec@1 91.406 (91.406)
 * Prec@1 91.230
current lr 1.00000e-02
Grad=  tensor(2.7183, device='cuda:0')
Epoch: [109][0/391]	Time 0.240 (0.240)	Data 0.119 (0.119)	Loss 0.3487 (0.3487) ([0.172]+[0.176])	Prec@1 92.969 (92.969)
Epoch: [109][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3265 (0.3289) ([0.151]+[0.175])	Prec@1 96.094 (94.794)
Epoch: [109][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3484 (0.3331) ([0.174]+[0.175])	Prec@1 92.969 (94.558)
Epoch: [109][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.4717 (0.3338) ([0.298]+[0.174])	Prec@1 88.281 (94.464)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4369 (0.4369) ([0.264]+[0.173])	Prec@1 90.625 (90.625)
 * Prec@1 91.270
current lr 1.00000e-02
Grad=  tensor(3.4140, device='cuda:0')
Epoch: [110][0/391]	Time 0.240 (0.240)	Data 0.119 (0.119)	Loss 0.3546 (0.3546) ([0.181]+[0.173])	Prec@1 92.969 (92.969)
Epoch: [110][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3398 (0.3251) ([0.167]+[0.172])	Prec@1 93.750 (94.647)
Epoch: [110][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3022 (0.3278) ([0.131]+[0.172])	Prec@1 93.750 (94.702)
Epoch: [110][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.4144 (0.3318) ([0.243]+[0.171])	Prec@1 92.969 (94.555)
Test: [0/79]	Time 0.146 (0.146)	Loss 0.4244 (0.4244) ([0.254]+[0.170])	Prec@1 92.969 (92.969)
 * Prec@1 91.280
current lr 1.00000e-02
Grad=  tensor(2.8281, device='cuda:0')
Epoch: [111][0/391]	Time 0.241 (0.241)	Data 0.120 (0.120)	Loss 0.3063 (0.3063) ([0.136]+[0.170])	Prec@1 95.312 (95.312)
Epoch: [111][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2760 (0.3104) ([0.107]+[0.169])	Prec@1 96.094 (95.212)
Epoch: [111][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3518 (0.3162) ([0.183]+[0.169])	Prec@1 96.094 (94.990)
Epoch: [111][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3224 (0.3233) ([0.154]+[0.168])	Prec@1 94.531 (94.622)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4271 (0.4271) ([0.259]+[0.168])	Prec@1 91.406 (91.406)
 * Prec@1 90.380
current lr 1.00000e-02
Grad=  tensor(4.2959, device='cuda:0')
Epoch: [112][0/391]	Time 0.240 (0.240)	Data 0.119 (0.119)	Loss 0.3556 (0.3556) ([0.188]+[0.168])	Prec@1 93.750 (93.750)
Epoch: [112][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3389 (0.3190) ([0.172]+[0.167])	Prec@1 92.188 (94.609)
Epoch: [112][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2825 (0.3194) ([0.116]+[0.166])	Prec@1 95.312 (94.710)
Epoch: [112][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.4420 (0.3216) ([0.276]+[0.166])	Prec@1 88.281 (94.619)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.3884 (0.3884) ([0.223]+[0.165])	Prec@1 92.188 (92.188)
 * Prec@1 90.690
current lr 1.00000e-02
Grad=  tensor(2.4343, device='cuda:0')
Epoch: [113][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.2934 (0.2934) ([0.128]+[0.165])	Prec@1 96.094 (96.094)
Epoch: [113][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3308 (0.3079) ([0.166]+[0.164])	Prec@1 92.188 (94.988)
Epoch: [113][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2987 (0.3089) ([0.135]+[0.164])	Prec@1 93.750 (94.955)
Epoch: [113][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.4227 (0.3115) ([0.259]+[0.163])	Prec@1 90.625 (94.814)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4569 (0.4569) ([0.294]+[0.163])	Prec@1 90.625 (90.625)
 * Prec@1 90.450
current lr 1.00000e-02
Grad=  tensor(4.6361, device='cuda:0')
Epoch: [114][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.3112 (0.3112) ([0.148]+[0.163])	Prec@1 94.531 (94.531)
Epoch: [114][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3125 (0.3072) ([0.150]+[0.162])	Prec@1 95.312 (95.050)
Epoch: [114][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3190 (0.3098) ([0.157]+[0.162])	Prec@1 92.969 (94.912)
Epoch: [114][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2878 (0.3134) ([0.127]+[0.161])	Prec@1 95.312 (94.747)
Test: [0/79]	Time 0.146 (0.146)	Loss 0.3503 (0.3503) ([0.189]+[0.161])	Prec@1 91.406 (91.406)
 * Prec@1 90.840
current lr 1.00000e-02
Grad=  tensor(5.8769, device='cuda:0')
Epoch: [115][0/391]	Time 0.236 (0.236)	Data 0.116 (0.116)	Loss 0.3052 (0.3052) ([0.144]+[0.161])	Prec@1 95.312 (95.312)
Epoch: [115][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2911 (0.3129) ([0.131]+[0.160])	Prec@1 94.531 (94.810)
Epoch: [115][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2350 (0.3083) ([0.075]+[0.160])	Prec@1 96.875 (94.970)
Epoch: [115][300/391]	Time 0.112 (0.111)	Data 0.000 (0.000)	Loss 0.2790 (0.3093) ([0.120]+[0.159])	Prec@1 97.656 (94.889)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4401 (0.4401) ([0.281]+[0.159])	Prec@1 92.969 (92.969)
 * Prec@1 91.060
current lr 1.00000e-02
Grad=  tensor(4.5182, device='cuda:0')
Epoch: [116][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.2716 (0.2716) ([0.113]+[0.159])	Prec@1 96.875 (96.875)
Epoch: [116][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3259 (0.3035) ([0.167]+[0.158])	Prec@1 93.750 (95.073)
Epoch: [116][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2614 (0.3091) ([0.103]+[0.158])	Prec@1 95.312 (94.928)
Epoch: [116][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2910 (0.3119) ([0.133]+[0.158])	Prec@1 94.531 (94.866)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.4566 (0.4566) ([0.299]+[0.157])	Prec@1 89.844 (89.844)
 * Prec@1 91.310
current lr 1.00000e-02
Grad=  tensor(4.8346, device='cuda:0')
Epoch: [117][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.3202 (0.3202) ([0.163]+[0.157])	Prec@1 92.969 (92.969)
Epoch: [117][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.3320 (0.3022) ([0.175]+[0.157])	Prec@1 95.312 (95.034)
Epoch: [117][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2861 (0.3006) ([0.130]+[0.156])	Prec@1 94.531 (95.037)
Epoch: [117][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.3239 (0.3009) ([0.168]+[0.156])	Prec@1 91.406 (95.024)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4101 (0.4101) ([0.254]+[0.156])	Prec@1 92.969 (92.969)
 * Prec@1 91.130
current lr 1.00000e-02
Grad=  tensor(5.7231, device='cuda:0')
Epoch: [118][0/391]	Time 0.236 (0.236)	Data 0.117 (0.117)	Loss 0.2841 (0.2841) ([0.128]+[0.156])	Prec@1 95.312 (95.312)
Epoch: [118][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.3039 (0.2885) ([0.149]+[0.155])	Prec@1 94.531 (95.359)
Epoch: [118][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2216 (0.2961) ([0.067]+[0.155])	Prec@1 99.219 (95.180)
Epoch: [118][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.2672 (0.2997) ([0.113]+[0.155])	Prec@1 96.094 (95.027)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4016 (0.4016) ([0.247]+[0.155])	Prec@1 94.531 (94.531)
 * Prec@1 90.450
current lr 1.00000e-02
Grad=  tensor(4.0433, device='cuda:0')
Epoch: [119][0/391]	Time 0.242 (0.242)	Data 0.117 (0.117)	Loss 0.2445 (0.2445) ([0.090]+[0.155])	Prec@1 96.094 (96.094)
Epoch: [119][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.2677 (0.2954) ([0.114]+[0.154])	Prec@1 95.312 (95.050)
Epoch: [119][200/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.2759 (0.2986) ([0.122]+[0.154])	Prec@1 96.094 (95.002)
Epoch: [119][300/391]	Time 0.110 (0.110)	Data 0.000 (0.000)	Loss 0.3966 (0.3029) ([0.243]+[0.154])	Prec@1 90.625 (94.871)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3729 (0.3729) ([0.220]+[0.153])	Prec@1 92.969 (92.969)
 * Prec@1 90.880
current lr 1.00000e-02
Grad=  tensor(2.9698, device='cuda:0')
Epoch: [120][0/391]	Time 0.239 (0.239)	Data 0.119 (0.119)	Loss 0.2593 (0.2593) ([0.106]+[0.153])	Prec@1 98.438 (98.438)
Epoch: [120][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3467 (0.2921) ([0.194]+[0.153])	Prec@1 92.188 (95.212)
Epoch: [120][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2564 (0.3005) ([0.104]+[0.153])	Prec@1 96.875 (94.869)
Epoch: [120][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.2431 (0.3008) ([0.090]+[0.153])	Prec@1 97.656 (94.895)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4406 (0.4406) ([0.288]+[0.152])	Prec@1 92.969 (92.969)
 * Prec@1 90.760
current lr 1.00000e-02
Grad=  tensor(7.5626, device='cuda:0')
Epoch: [121][0/391]	Time 0.234 (0.234)	Data 0.115 (0.115)	Loss 0.2980 (0.2980) ([0.146]+[0.152])	Prec@1 94.531 (94.531)
Epoch: [121][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2048 (0.2871) ([0.053]+[0.152])	Prec@1 100.000 (95.506)
Epoch: [121][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2710 (0.2906) ([0.119]+[0.152])	Prec@1 96.094 (95.332)
Epoch: [121][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.3006 (0.2987) ([0.149]+[0.152])	Prec@1 95.312 (95.056)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4447 (0.4447) ([0.293]+[0.152])	Prec@1 90.625 (90.625)
 * Prec@1 90.770
current lr 1.00000e-02
Grad=  tensor(7.9555, device='cuda:0')
Epoch: [122][0/391]	Time 0.237 (0.237)	Data 0.117 (0.117)	Loss 0.3583 (0.3583) ([0.207]+[0.152])	Prec@1 92.188 (92.188)
Epoch: [122][100/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.2563 (0.2808) ([0.105]+[0.151])	Prec@1 96.094 (95.405)
Epoch: [122][200/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.3620 (0.2871) ([0.211]+[0.151])	Prec@1 94.531 (95.301)
Epoch: [122][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3030 (0.2937) ([0.152]+[0.151])	Prec@1 94.531 (95.089)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4313 (0.4313) ([0.281]+[0.151])	Prec@1 91.406 (91.406)
 * Prec@1 90.400
current lr 1.00000e-02
Grad=  tensor(5.3963, device='cuda:0')
Epoch: [123][0/391]	Time 0.238 (0.238)	Data 0.116 (0.116)	Loss 0.2833 (0.2833) ([0.133]+[0.151])	Prec@1 94.531 (94.531)
Epoch: [123][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2763 (0.2894) ([0.126]+[0.151])	Prec@1 96.094 (95.127)
Epoch: [123][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2597 (0.2963) ([0.109]+[0.150])	Prec@1 96.094 (94.932)
Epoch: [123][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3734 (0.2988) ([0.223]+[0.150])	Prec@1 92.969 (94.866)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4437 (0.4437) ([0.294]+[0.150])	Prec@1 90.625 (90.625)
 * Prec@1 90.800
current lr 1.00000e-02
Grad=  tensor(6.9074, device='cuda:0')
Epoch: [124][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.3113 (0.3113) ([0.161]+[0.150])	Prec@1 93.750 (93.750)
Epoch: [124][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2192 (0.2834) ([0.070]+[0.150])	Prec@1 99.219 (95.475)
Epoch: [124][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2822 (0.2867) ([0.133]+[0.149])	Prec@1 94.531 (95.386)
Epoch: [124][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3558 (0.2932) ([0.206]+[0.149])	Prec@1 91.406 (95.074)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3709 (0.3709) ([0.221]+[0.149])	Prec@1 93.750 (93.750)
 * Prec@1 90.110
current lr 1.00000e-02
Grad=  tensor(7.8908, device='cuda:0')
Epoch: [125][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.2589 (0.2589) ([0.109]+[0.149])	Prec@1 93.750 (93.750)
Epoch: [125][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3205 (0.2874) ([0.171]+[0.149])	Prec@1 92.188 (95.026)
Epoch: [125][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.3322 (0.2892) ([0.183]+[0.149])	Prec@1 92.969 (95.068)
Epoch: [125][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.2870 (0.2958) ([0.138]+[0.149])	Prec@1 92.969 (94.926)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4301 (0.4301) ([0.281]+[0.149])	Prec@1 92.188 (92.188)
 * Prec@1 89.900
current lr 1.00000e-02
Grad=  tensor(8.3594, device='cuda:0')
Epoch: [126][0/391]	Time 0.236 (0.236)	Data 0.116 (0.116)	Loss 0.3485 (0.3485) ([0.200]+[0.149])	Prec@1 92.969 (92.969)
Epoch: [126][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2573 (0.2885) ([0.109]+[0.149])	Prec@1 96.094 (95.135)
Epoch: [126][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3471 (0.2891) ([0.199]+[0.149])	Prec@1 95.312 (95.141)
Epoch: [126][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.2776 (0.2948) ([0.129]+[0.149])	Prec@1 96.094 (94.913)
Test: [0/79]	Time 0.146 (0.146)	Loss 0.3577 (0.3577) ([0.209]+[0.149])	Prec@1 93.750 (93.750)
 * Prec@1 89.720
current lr 1.00000e-02
Grad=  tensor(4.0596, device='cuda:0')
Epoch: [127][0/391]	Time 0.237 (0.237)	Data 0.117 (0.117)	Loss 0.2616 (0.2616) ([0.113]+[0.149])	Prec@1 96.094 (96.094)
Epoch: [127][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3820 (0.2801) ([0.234]+[0.148])	Prec@1 92.969 (95.475)
Epoch: [127][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2767 (0.2885) ([0.128]+[0.148])	Prec@1 94.531 (95.173)
Epoch: [127][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.2519 (0.2920) ([0.104]+[0.148])	Prec@1 98.438 (95.011)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4915 (0.4915) ([0.343]+[0.148])	Prec@1 89.844 (89.844)
 * Prec@1 88.910
current lr 1.00000e-02
Grad=  tensor(6.2611, device='cuda:0')
Epoch: [128][0/391]	Time 0.232 (0.232)	Data 0.113 (0.113)	Loss 0.3163 (0.3163) ([0.168]+[0.148])	Prec@1 92.188 (92.188)
Epoch: [128][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2803 (0.2828) ([0.132]+[0.148])	Prec@1 93.750 (95.498)
Epoch: [128][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.4253 (0.2870) ([0.277]+[0.148])	Prec@1 89.844 (95.274)
Epoch: [128][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.3329 (0.2920) ([0.185]+[0.148])	Prec@1 92.188 (95.131)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.4623 (0.4623) ([0.315]+[0.148])	Prec@1 92.969 (92.969)
 * Prec@1 90.430
current lr 1.00000e-02
Grad=  tensor(7.3245, device='cuda:0')
Epoch: [129][0/391]	Time 0.239 (0.239)	Data 0.119 (0.119)	Loss 0.3344 (0.3344) ([0.187]+[0.148])	Prec@1 94.531 (94.531)
Epoch: [129][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2189 (0.2833) ([0.071]+[0.148])	Prec@1 97.656 (95.552)
Epoch: [129][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2726 (0.2907) ([0.125]+[0.148])	Prec@1 96.094 (95.153)
Epoch: [129][300/391]	Time 0.108 (0.109)	Data 0.000 (0.000)	Loss 0.3511 (0.2930) ([0.204]+[0.148])	Prec@1 90.625 (95.040)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3671 (0.3671) ([0.220]+[0.148])	Prec@1 92.188 (92.188)
 * Prec@1 89.330
current lr 1.00000e-02
Grad=  tensor(6.1318, device='cuda:0')
Epoch: [130][0/391]	Time 0.238 (0.238)	Data 0.119 (0.119)	Loss 0.2925 (0.2925) ([0.145]+[0.148])	Prec@1 94.531 (94.531)
Epoch: [130][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2869 (0.2889) ([0.139]+[0.147])	Prec@1 95.312 (95.258)
Epoch: [130][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2894 (0.2962) ([0.142]+[0.147])	Prec@1 95.312 (94.959)
Epoch: [130][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.3038 (0.2968) ([0.156]+[0.147])	Prec@1 93.750 (94.993)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3989 (0.3989) ([0.251]+[0.147])	Prec@1 92.188 (92.188)
 * Prec@1 90.540
current lr 1.00000e-02
Grad=  tensor(2.7773, device='cuda:0')
Epoch: [131][0/391]	Time 0.239 (0.239)	Data 0.117 (0.117)	Loss 0.2194 (0.2194) ([0.072]+[0.147])	Prec@1 97.656 (97.656)
Epoch: [131][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2652 (0.2808) ([0.118]+[0.147])	Prec@1 96.094 (95.359)
Epoch: [131][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2448 (0.2842) ([0.098]+[0.147])	Prec@1 96.094 (95.239)
Epoch: [131][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3473 (0.2903) ([0.200]+[0.147])	Prec@1 93.750 (94.965)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4232 (0.4232) ([0.276]+[0.147])	Prec@1 91.406 (91.406)
 * Prec@1 89.790
current lr 1.00000e-02
Grad=  tensor(6.0583, device='cuda:0')
Epoch: [132][0/391]	Time 0.237 (0.237)	Data 0.115 (0.115)	Loss 0.2606 (0.2606) ([0.113]+[0.147])	Prec@1 96.094 (96.094)
Epoch: [132][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2945 (0.2971) ([0.147]+[0.147])	Prec@1 95.312 (94.655)
Epoch: [132][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3127 (0.2941) ([0.165]+[0.147])	Prec@1 93.750 (94.932)
Epoch: [132][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.3070 (0.2976) ([0.160]+[0.147])	Prec@1 93.750 (94.861)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3788 (0.3788) ([0.231]+[0.147])	Prec@1 92.969 (92.969)
 * Prec@1 89.770
current lr 1.00000e-02
Grad=  tensor(12.4993, device='cuda:0')
Epoch: [133][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.3057 (0.3057) ([0.158]+[0.147])	Prec@1 92.188 (92.188)
Epoch: [133][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2492 (0.2826) ([0.102]+[0.147])	Prec@1 96.875 (95.452)
Epoch: [133][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2248 (0.2823) ([0.078]+[0.147])	Prec@1 96.875 (95.347)
Epoch: [133][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2623 (0.2882) ([0.115]+[0.147])	Prec@1 96.875 (95.133)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.5719 (0.5719) ([0.425]+[0.147])	Prec@1 89.062 (89.062)
 * Prec@1 90.080
current lr 1.00000e-02
Grad=  tensor(4.6256, device='cuda:0')
Epoch: [134][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.2530 (0.2530) ([0.106]+[0.147])	Prec@1 96.094 (96.094)
Epoch: [134][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2601 (0.2756) ([0.113]+[0.147])	Prec@1 95.312 (95.560)
Epoch: [134][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2610 (0.2825) ([0.114]+[0.147])	Prec@1 96.875 (95.371)
Epoch: [134][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2715 (0.2841) ([0.124]+[0.147])	Prec@1 95.312 (95.325)
Test: [0/79]	Time 0.143 (0.143)	Loss 0.4182 (0.4182) ([0.271]+[0.147])	Prec@1 92.188 (92.188)
 * Prec@1 91.030
current lr 1.00000e-02
Grad=  tensor(5.9324, device='cuda:0')
Epoch: [135][0/391]	Time 0.239 (0.239)	Data 0.117 (0.117)	Loss 0.2611 (0.2611) ([0.114]+[0.147])	Prec@1 96.875 (96.875)
Epoch: [135][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2667 (0.2831) ([0.120]+[0.147])	Prec@1 96.094 (95.452)
Epoch: [135][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2697 (0.2873) ([0.123]+[0.147])	Prec@1 96.875 (95.188)
Epoch: [135][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2940 (0.2893) ([0.147]+[0.147])	Prec@1 95.312 (95.081)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.4352 (0.4352) ([0.288]+[0.147])	Prec@1 90.625 (90.625)
 * Prec@1 90.840
current lr 1.00000e-02
Grad=  tensor(6.5077, device='cuda:0')
Epoch: [136][0/391]	Time 0.236 (0.236)	Data 0.115 (0.115)	Loss 0.3006 (0.3006) ([0.153]+[0.147])	Prec@1 95.312 (95.312)
Epoch: [136][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2638 (0.2915) ([0.117]+[0.147])	Prec@1 96.094 (95.111)
Epoch: [136][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3278 (0.2959) ([0.181]+[0.147])	Prec@1 93.750 (94.924)
Epoch: [136][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3162 (0.2967) ([0.169]+[0.147])	Prec@1 93.750 (94.931)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3918 (0.3918) ([0.245]+[0.147])	Prec@1 92.969 (92.969)
 * Prec@1 90.060
current lr 1.00000e-02
Grad=  tensor(6.1664, device='cuda:0')
Epoch: [137][0/391]	Time 0.234 (0.234)	Data 0.113 (0.113)	Loss 0.2770 (0.2770) ([0.130]+[0.147])	Prec@1 96.875 (96.875)
Epoch: [137][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2863 (0.2766) ([0.139]+[0.147])	Prec@1 92.969 (95.506)
Epoch: [137][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3361 (0.2859) ([0.189]+[0.147])	Prec@1 92.969 (95.211)
Epoch: [137][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2660 (0.2897) ([0.119]+[0.147])	Prec@1 96.875 (95.118)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.5420 (0.5420) ([0.395]+[0.147])	Prec@1 89.844 (89.844)
 * Prec@1 87.740
current lr 1.00000e-02
Grad=  tensor(5.1405, device='cuda:0')
Epoch: [138][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.2488 (0.2488) ([0.102]+[0.147])	Prec@1 96.875 (96.875)
Epoch: [138][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2797 (0.2854) ([0.133]+[0.147])	Prec@1 95.312 (95.196)
Epoch: [138][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2214 (0.2858) ([0.074]+[0.147])	Prec@1 97.656 (95.254)
Epoch: [138][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3007 (0.2955) ([0.153]+[0.147])	Prec@1 96.875 (94.918)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4638 (0.4638) ([0.316]+[0.147])	Prec@1 88.281 (88.281)
 * Prec@1 90.210
current lr 1.00000e-02
Grad=  tensor(9.2748, device='cuda:0')
Epoch: [139][0/391]	Time 0.241 (0.241)	Data 0.121 (0.121)	Loss 0.3136 (0.3136) ([0.166]+[0.147])	Prec@1 95.312 (95.312)
Epoch: [139][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2724 (0.2795) ([0.125]+[0.147])	Prec@1 97.656 (95.398)
Epoch: [139][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3154 (0.2838) ([0.168]+[0.147])	Prec@1 92.188 (95.281)
Epoch: [139][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3022 (0.2883) ([0.155]+[0.147])	Prec@1 91.406 (95.115)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4048 (0.4048) ([0.257]+[0.147])	Prec@1 89.062 (89.062)
 * Prec@1 90.240
current lr 1.00000e-02
Grad=  tensor(10.4440, device='cuda:0')
Epoch: [140][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.3585 (0.3585) ([0.211]+[0.147])	Prec@1 93.750 (93.750)
Epoch: [140][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3380 (0.2853) ([0.191]+[0.147])	Prec@1 93.750 (95.266)
Epoch: [140][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2651 (0.2872) ([0.118]+[0.147])	Prec@1 95.312 (95.188)
Epoch: [140][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3223 (0.2890) ([0.175]+[0.147])	Prec@1 92.188 (95.144)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4392 (0.4392) ([0.292]+[0.147])	Prec@1 89.844 (89.844)
 * Prec@1 89.580
current lr 1.00000e-02
Grad=  tensor(8.3353, device='cuda:0')
Epoch: [141][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.3111 (0.3111) ([0.164]+[0.147])	Prec@1 95.312 (95.312)
Epoch: [141][100/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3068 (0.2823) ([0.160]+[0.147])	Prec@1 92.969 (95.490)
Epoch: [141][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3362 (0.2846) ([0.189]+[0.147])	Prec@1 93.750 (95.371)
Epoch: [141][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.4423 (0.2882) ([0.295]+[0.147])	Prec@1 85.938 (95.248)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4737 (0.4737) ([0.326]+[0.147])	Prec@1 91.406 (91.406)
 * Prec@1 90.090
current lr 1.00000e-02
Grad=  tensor(10.3623, device='cuda:0')
Epoch: [142][0/391]	Time 0.236 (0.236)	Data 0.116 (0.116)	Loss 0.2985 (0.2985) ([0.151]+[0.147])	Prec@1 92.969 (92.969)
Epoch: [142][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2745 (0.2875) ([0.127]+[0.147])	Prec@1 95.312 (95.019)
Epoch: [142][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2790 (0.2867) ([0.132]+[0.147])	Prec@1 95.312 (95.204)
Epoch: [142][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2080 (0.2866) ([0.061]+[0.147])	Prec@1 98.438 (95.250)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4431 (0.4431) ([0.296]+[0.148])	Prec@1 92.969 (92.969)
 * Prec@1 88.620
current lr 1.00000e-02
Grad=  tensor(13.8054, device='cuda:0')
Epoch: [143][0/391]	Time 0.240 (0.240)	Data 0.119 (0.119)	Loss 0.3360 (0.3360) ([0.188]+[0.148])	Prec@1 92.188 (92.188)
Epoch: [143][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3022 (0.2765) ([0.155]+[0.147])	Prec@1 96.094 (95.537)
Epoch: [143][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2205 (0.2810) ([0.073]+[0.148])	Prec@1 97.656 (95.355)
Epoch: [143][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3353 (0.2874) ([0.188]+[0.148])	Prec@1 92.969 (95.206)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4527 (0.4527) ([0.305]+[0.148])	Prec@1 92.188 (92.188)
 * Prec@1 90.230
current lr 1.00000e-02
Grad=  tensor(8.9237, device='cuda:0')
Epoch: [144][0/391]	Time 0.238 (0.238)	Data 0.116 (0.116)	Loss 0.3072 (0.3072) ([0.159]+[0.148])	Prec@1 93.750 (93.750)
Epoch: [144][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.3232 (0.2845) ([0.176]+[0.148])	Prec@1 95.312 (95.483)
Epoch: [144][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3258 (0.2906) ([0.178]+[0.148])	Prec@1 93.750 (95.122)
Epoch: [144][300/391]	Time 0.110 (0.110)	Data 0.000 (0.000)	Loss 0.3723 (0.2954) ([0.224]+[0.148])	Prec@1 94.531 (94.892)
Test: [0/79]	Time 0.146 (0.146)	Loss 0.3908 (0.3908) ([0.243]+[0.148])	Prec@1 93.750 (93.750)
 * Prec@1 90.360
current lr 1.00000e-02
Grad=  tensor(2.4580, device='cuda:0')
Epoch: [145][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.2260 (0.2260) ([0.078]+[0.148])	Prec@1 98.438 (98.438)
Epoch: [145][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2569 (0.2805) ([0.109]+[0.148])	Prec@1 96.094 (95.545)
Epoch: [145][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2783 (0.2931) ([0.130]+[0.148])	Prec@1 97.656 (95.017)
Epoch: [145][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3249 (0.2937) ([0.177]+[0.148])	Prec@1 91.406 (95.009)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4077 (0.4077) ([0.260]+[0.148])	Prec@1 92.188 (92.188)
 * Prec@1 89.640
current lr 1.00000e-02
Grad=  tensor(9.6324, device='cuda:0')
Epoch: [146][0/391]	Time 0.238 (0.238)	Data 0.116 (0.116)	Loss 0.3144 (0.3144) ([0.166]+[0.148])	Prec@1 94.531 (94.531)
Epoch: [146][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.3288 (0.2780) ([0.181]+[0.148])	Prec@1 94.531 (95.699)
Epoch: [146][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1990 (0.2808) ([0.051]+[0.148])	Prec@1 98.438 (95.503)
Epoch: [146][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.3924 (0.2870) ([0.244]+[0.148])	Prec@1 93.750 (95.198)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4243 (0.4243) ([0.276]+[0.148])	Prec@1 89.062 (89.062)
 * Prec@1 88.250
current lr 1.00000e-02
Grad=  tensor(4.7807, device='cuda:0')
Epoch: [147][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.2605 (0.2605) ([0.112]+[0.148])	Prec@1 96.094 (96.094)
Epoch: [147][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.3196 (0.2884) ([0.171]+[0.148])	Prec@1 94.531 (95.011)
Epoch: [147][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2830 (0.2860) ([0.135]+[0.148])	Prec@1 96.094 (95.239)
Epoch: [147][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3574 (0.2887) ([0.209]+[0.148])	Prec@1 95.312 (95.110)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.3693 (0.3693) ([0.221]+[0.148])	Prec@1 92.969 (92.969)
 * Prec@1 88.780
current lr 1.00000e-02
Grad=  tensor(10.8211, device='cuda:0')
Epoch: [148][0/391]	Time 0.240 (0.240)	Data 0.119 (0.119)	Loss 0.3101 (0.3101) ([0.162]+[0.148])	Prec@1 90.625 (90.625)
Epoch: [148][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2370 (0.2881) ([0.089]+[0.148])	Prec@1 97.656 (95.026)
Epoch: [148][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2804 (0.2859) ([0.132]+[0.148])	Prec@1 93.750 (95.184)
Epoch: [148][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2410 (0.2886) ([0.093]+[0.148])	Prec@1 96.875 (95.048)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4496 (0.4496) ([0.301]+[0.148])	Prec@1 91.406 (91.406)
 * Prec@1 90.850
current lr 1.00000e-02
Grad=  tensor(11.2951, device='cuda:0')
Epoch: [149][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.3129 (0.3129) ([0.165]+[0.148])	Prec@1 93.750 (93.750)
Epoch: [149][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3387 (0.2774) ([0.191]+[0.148])	Prec@1 93.750 (95.653)
Epoch: [149][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2404 (0.2828) ([0.092]+[0.148])	Prec@1 97.656 (95.456)
Epoch: [149][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3323 (0.2845) ([0.184]+[0.148])	Prec@1 95.312 (95.351)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.4462 (0.4462) ([0.298]+[0.148])	Prec@1 92.969 (92.969)
 * Prec@1 89.410
current lr 1.00000e-02
Grad=  tensor(5.2369, device='cuda:0')
Epoch: [150][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.2567 (0.2567) ([0.108]+[0.148])	Prec@1 94.531 (94.531)
Epoch: [150][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2320 (0.2784) ([0.084]+[0.148])	Prec@1 96.875 (95.452)
Epoch: [150][200/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.2555 (0.2846) ([0.107]+[0.148])	Prec@1 98.438 (95.301)
Epoch: [150][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3089 (0.2869) ([0.161]+[0.148])	Prec@1 95.312 (95.271)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4483 (0.4483) ([0.300]+[0.148])	Prec@1 90.625 (90.625)
 * Prec@1 89.470
current lr 1.00000e-02
Grad=  tensor(3.3470, device='cuda:0')
Epoch: [151][0/391]	Time 0.236 (0.236)	Data 0.115 (0.115)	Loss 0.2282 (0.2282) ([0.080]+[0.148])	Prec@1 97.656 (97.656)
Epoch: [151][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2413 (0.2794) ([0.093]+[0.148])	Prec@1 96.875 (95.645)
Epoch: [151][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2400 (0.2894) ([0.092]+[0.148])	Prec@1 98.438 (95.149)
Epoch: [151][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2616 (0.2897) ([0.113]+[0.149])	Prec@1 95.312 (95.128)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.5737 (0.5737) ([0.425]+[0.148])	Prec@1 86.719 (86.719)
 * Prec@1 89.560
current lr 1.00000e-02
Grad=  tensor(2.5498, device='cuda:0')
Epoch: [152][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.2121 (0.2121) ([0.064]+[0.148])	Prec@1 99.219 (99.219)
Epoch: [152][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2507 (0.2885) ([0.102]+[0.149])	Prec@1 96.094 (95.305)
Epoch: [152][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2476 (0.2853) ([0.099]+[0.148])	Prec@1 98.438 (95.367)
Epoch: [152][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.3006 (0.2880) ([0.152]+[0.148])	Prec@1 92.969 (95.240)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4239 (0.4239) ([0.275]+[0.149])	Prec@1 92.969 (92.969)
 * Prec@1 90.500
current lr 1.00000e-02
Grad=  tensor(6.1377, device='cuda:0')
Epoch: [153][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.2589 (0.2589) ([0.110]+[0.149])	Prec@1 96.094 (96.094)
Epoch: [153][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2567 (0.2687) ([0.108]+[0.149])	Prec@1 96.094 (95.924)
Epoch: [153][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2909 (0.2686) ([0.143]+[0.148])	Prec@1 96.094 (95.849)
Epoch: [153][300/391]	Time 0.112 (0.112)	Data 0.000 (0.000)	Loss 0.2813 (0.2759) ([0.133]+[0.148])	Prec@1 96.094 (95.624)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.4895 (0.4895) ([0.341]+[0.149])	Prec@1 92.188 (92.188)
 * Prec@1 89.960
current lr 1.00000e-02
Grad=  tensor(4.8540, device='cuda:0')
Epoch: [154][0/391]	Time 0.236 (0.236)	Data 0.116 (0.116)	Loss 0.2121 (0.2121) ([0.063]+[0.149])	Prec@1 98.438 (98.438)
Epoch: [154][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.3235 (0.2739) ([0.175]+[0.149])	Prec@1 94.531 (95.746)
Epoch: [154][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2407 (0.2826) ([0.092]+[0.149])	Prec@1 98.438 (95.402)
Epoch: [154][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.3908 (0.2866) ([0.242]+[0.149])	Prec@1 91.406 (95.250)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4747 (0.4747) ([0.326]+[0.149])	Prec@1 90.625 (90.625)
 * Prec@1 90.000
current lr 1.00000e-02
Grad=  tensor(3.9681, device='cuda:0')
Epoch: [155][0/391]	Time 0.237 (0.237)	Data 0.117 (0.117)	Loss 0.2339 (0.2339) ([0.085]+[0.149])	Prec@1 97.656 (97.656)
Epoch: [155][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2635 (0.2755) ([0.115]+[0.149])	Prec@1 96.875 (95.730)
Epoch: [155][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2562 (0.2800) ([0.107]+[0.149])	Prec@1 96.094 (95.499)
Epoch: [155][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.3094 (0.2805) ([0.160]+[0.149])	Prec@1 94.531 (95.432)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.5280 (0.5280) ([0.379]+[0.149])	Prec@1 92.188 (92.188)
 * Prec@1 90.650
current lr 1.00000e-02
Grad=  tensor(11.5563, device='cuda:0')
Epoch: [156][0/391]	Time 0.235 (0.235)	Data 0.116 (0.116)	Loss 0.3539 (0.3539) ([0.205]+[0.149])	Prec@1 92.969 (92.969)
Epoch: [156][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2412 (0.2783) ([0.092]+[0.149])	Prec@1 96.094 (95.560)
Epoch: [156][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2649 (0.2773) ([0.116]+[0.149])	Prec@1 96.875 (95.526)
Epoch: [156][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.2238 (0.2806) ([0.075]+[0.149])	Prec@1 97.656 (95.447)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.5317 (0.5317) ([0.383]+[0.149])	Prec@1 89.062 (89.062)
 * Prec@1 88.510
current lr 1.00000e-02
Grad=  tensor(8.1135, device='cuda:0')
Epoch: [157][0/391]	Time 0.233 (0.233)	Data 0.116 (0.116)	Loss 0.2614 (0.2614) ([0.112]+[0.149])	Prec@1 96.094 (96.094)
Epoch: [157][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2831 (0.2874) ([0.134]+[0.149])	Prec@1 95.312 (95.274)
Epoch: [157][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2738 (0.2849) ([0.125]+[0.149])	Prec@1 93.750 (95.386)
Epoch: [157][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.3418 (0.2890) ([0.193]+[0.149])	Prec@1 94.531 (95.229)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.5305 (0.5305) ([0.381]+[0.149])	Prec@1 92.188 (92.188)
 * Prec@1 88.540
current lr 1.00000e-02
Grad=  tensor(9.5483, device='cuda:0')
Epoch: [158][0/391]	Time 0.236 (0.236)	Data 0.116 (0.116)	Loss 0.3256 (0.3256) ([0.176]+[0.149])	Prec@1 94.531 (94.531)
Epoch: [158][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2608 (0.2863) ([0.112]+[0.149])	Prec@1 96.094 (95.104)
Epoch: [158][200/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2471 (0.2839) ([0.098]+[0.149])	Prec@1 96.875 (95.192)
Epoch: [158][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.2276 (0.2883) ([0.078]+[0.149])	Prec@1 98.438 (95.141)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3777 (0.3777) ([0.228]+[0.149])	Prec@1 92.969 (92.969)
 * Prec@1 90.270
current lr 1.00000e-02
Grad=  tensor(6.0616, device='cuda:0')
Epoch: [159][0/391]	Time 0.237 (0.237)	Data 0.117 (0.117)	Loss 0.2368 (0.2368) ([0.087]+[0.149])	Prec@1 97.656 (97.656)
Epoch: [159][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2607 (0.2641) ([0.112]+[0.149])	Prec@1 95.312 (96.171)
Epoch: [159][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2698 (0.2698) ([0.121]+[0.149])	Prec@1 96.875 (95.931)
Epoch: [159][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.3389 (0.2767) ([0.190]+[0.149])	Prec@1 94.531 (95.725)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.5255 (0.5255) ([0.376]+[0.150])	Prec@1 86.719 (86.719)
 * Prec@1 89.450
current lr 1.00000e-02
Grad=  tensor(2.5260, device='cuda:0')
Epoch: [160][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.1970 (0.1970) ([0.047]+[0.150])	Prec@1 99.219 (99.219)
Epoch: [160][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2899 (0.2739) ([0.140]+[0.149])	Prec@1 93.750 (95.823)
Epoch: [160][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2324 (0.2821) ([0.083]+[0.150])	Prec@1 98.438 (95.452)
Epoch: [160][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2734 (0.2869) ([0.124]+[0.150])	Prec@1 96.094 (95.248)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.3377 (0.3377) ([0.188]+[0.150])	Prec@1 94.531 (94.531)
 * Prec@1 90.370
current lr 1.00000e-02
Grad=  tensor(2.3238, device='cuda:0')
Epoch: [161][0/391]	Time 0.239 (0.239)	Data 0.117 (0.117)	Loss 0.1913 (0.1913) ([0.042]+[0.150])	Prec@1 99.219 (99.219)
Epoch: [161][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2587 (0.2765) ([0.109]+[0.149])	Prec@1 95.312 (95.661)
Epoch: [161][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2250 (0.2757) ([0.076]+[0.149])	Prec@1 96.875 (95.690)
Epoch: [161][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2245 (0.2754) ([0.075]+[0.149])	Prec@1 98.438 (95.697)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.4680 (0.4680) ([0.318]+[0.150])	Prec@1 91.406 (91.406)
 * Prec@1 90.890
current lr 1.00000e-02
Grad=  tensor(4.7920, device='cuda:0')
Epoch: [162][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.2346 (0.2346) ([0.085]+[0.150])	Prec@1 97.656 (97.656)
Epoch: [162][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3200 (0.2727) ([0.171]+[0.149])	Prec@1 92.188 (95.668)
Epoch: [162][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3245 (0.2766) ([0.175]+[0.150])	Prec@1 92.969 (95.581)
Epoch: [162][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3599 (0.2817) ([0.210]+[0.150])	Prec@1 94.531 (95.424)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.5168 (0.5168) ([0.367]+[0.150])	Prec@1 91.406 (91.406)
 * Prec@1 90.060
current lr 1.00000e-02
Grad=  tensor(6.0182, device='cuda:0')
Epoch: [163][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.2755 (0.2755) ([0.126]+[0.150])	Prec@1 94.531 (94.531)
Epoch: [163][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2512 (0.2754) ([0.101]+[0.150])	Prec@1 95.312 (95.645)
Epoch: [163][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2446 (0.2752) ([0.095]+[0.150])	Prec@1 96.875 (95.701)
Epoch: [163][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3498 (0.2781) ([0.200]+[0.150])	Prec@1 92.969 (95.577)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4166 (0.4166) ([0.267]+[0.150])	Prec@1 92.188 (92.188)
 * Prec@1 90.280
current lr 1.00000e-02
Grad=  tensor(6.8061, device='cuda:0')
Epoch: [164][0/391]	Time 0.238 (0.238)	Data 0.116 (0.116)	Loss 0.2576 (0.2576) ([0.108]+[0.150])	Prec@1 96.094 (96.094)
Epoch: [164][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2871 (0.2717) ([0.137]+[0.150])	Prec@1 93.750 (95.939)
Epoch: [164][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2095 (0.2761) ([0.060]+[0.150])	Prec@1 98.438 (95.771)
Epoch: [164][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.3100 (0.2790) ([0.160]+[0.150])	Prec@1 94.531 (95.608)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4504 (0.4504) ([0.300]+[0.150])	Prec@1 92.188 (92.188)
 * Prec@1 90.050
current lr 1.00000e-02
Grad=  tensor(5.2778, device='cuda:0')
Epoch: [165][0/391]	Time 0.241 (0.241)	Data 0.119 (0.119)	Loss 0.2189 (0.2189) ([0.069]+[0.150])	Prec@1 98.438 (98.438)
Epoch: [165][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2360 (0.2784) ([0.086]+[0.150])	Prec@1 96.094 (95.707)
Epoch: [165][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3119 (0.2757) ([0.162]+[0.150])	Prec@1 95.312 (95.771)
Epoch: [165][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2300 (0.2791) ([0.080]+[0.150])	Prec@1 97.656 (95.577)
Test: [0/79]	Time 0.146 (0.146)	Loss 0.5664 (0.5664) ([0.416]+[0.150])	Prec@1 89.844 (89.844)
 * Prec@1 89.250
current lr 1.00000e-02
Grad=  tensor(7.3980, device='cuda:0')
Epoch: [166][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.2738 (0.2738) ([0.124]+[0.150])	Prec@1 96.094 (96.094)
Epoch: [166][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2299 (0.2680) ([0.080]+[0.150])	Prec@1 97.656 (96.024)
Epoch: [166][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2531 (0.2728) ([0.103]+[0.150])	Prec@1 96.875 (95.783)
Epoch: [166][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.3361 (0.2758) ([0.186]+[0.150])	Prec@1 92.188 (95.728)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4055 (0.4055) ([0.255]+[0.150])	Prec@1 93.750 (93.750)
 * Prec@1 89.530
current lr 1.00000e-02
Grad=  tensor(11.6605, device='cuda:0')
Epoch: [167][0/391]	Time 0.239 (0.239)	Data 0.117 (0.117)	Loss 0.2582 (0.2582) ([0.108]+[0.150])	Prec@1 96.875 (96.875)
Epoch: [167][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2236 (0.2708) ([0.074]+[0.150])	Prec@1 96.875 (95.893)
Epoch: [167][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2769 (0.2770) ([0.127]+[0.150])	Prec@1 95.312 (95.674)
Epoch: [167][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2531 (0.2754) ([0.103]+[0.150])	Prec@1 96.875 (95.790)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.6424 (0.6424) ([0.492]+[0.150])	Prec@1 89.062 (89.062)
 * Prec@1 88.780
current lr 1.00000e-02
Grad=  tensor(10.5905, device='cuda:0')
Epoch: [168][0/391]	Time 0.238 (0.238)	Data 0.116 (0.116)	Loss 0.3058 (0.3058) ([0.156]+[0.150])	Prec@1 93.750 (93.750)
Epoch: [168][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3327 (0.2785) ([0.182]+[0.150])	Prec@1 95.312 (95.653)
Epoch: [168][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2373 (0.2813) ([0.087]+[0.150])	Prec@1 96.875 (95.507)
Epoch: [168][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2776 (0.2820) ([0.127]+[0.150])	Prec@1 95.312 (95.442)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4572 (0.4572) ([0.307]+[0.150])	Prec@1 90.625 (90.625)
 * Prec@1 90.160
current lr 1.00000e-02
Grad=  tensor(4.5448, device='cuda:0')
Epoch: [169][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.2513 (0.2513) ([0.101]+[0.150])	Prec@1 97.656 (97.656)
Epoch: [169][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2358 (0.2700) ([0.086]+[0.150])	Prec@1 98.438 (95.908)
Epoch: [169][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2558 (0.2757) ([0.106]+[0.150])	Prec@1 96.875 (95.771)
Epoch: [169][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2706 (0.2775) ([0.120]+[0.150])	Prec@1 95.312 (95.720)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4521 (0.4521) ([0.302]+[0.150])	Prec@1 92.969 (92.969)
 * Prec@1 89.560
current lr 1.00000e-02
Grad=  tensor(9.9129, device='cuda:0')
Epoch: [170][0/391]	Time 0.237 (0.237)	Data 0.115 (0.115)	Loss 0.2810 (0.2810) ([0.131]+[0.150])	Prec@1 96.094 (96.094)
Epoch: [170][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2953 (0.2772) ([0.145]+[0.150])	Prec@1 93.750 (95.483)
Epoch: [170][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2836 (0.2765) ([0.133]+[0.150])	Prec@1 94.531 (95.530)
Epoch: [170][300/391]	Time 0.109 (0.111)	Data 0.000 (0.000)	Loss 0.3963 (0.2818) ([0.246]+[0.150])	Prec@1 90.625 (95.351)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4821 (0.4821) ([0.332]+[0.151])	Prec@1 89.844 (89.844)
 * Prec@1 91.160
current lr 1.00000e-02
Grad=  tensor(4.1430, device='cuda:0')
Epoch: [171][0/391]	Time 0.233 (0.233)	Data 0.113 (0.113)	Loss 0.2124 (0.2124) ([0.062]+[0.151])	Prec@1 99.219 (99.219)
Epoch: [171][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.3075 (0.2636) ([0.157]+[0.150])	Prec@1 95.312 (96.125)
Epoch: [171][200/391]	Time 0.108 (0.111)	Data 0.000 (0.001)	Loss 0.2468 (0.2683) ([0.096]+[0.150])	Prec@1 98.438 (95.985)
Epoch: [171][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.3639 (0.2746) ([0.213]+[0.151])	Prec@1 92.969 (95.746)
Test: [0/79]	Time 0.144 (0.144)	Loss 0.3929 (0.3929) ([0.242]+[0.151])	Prec@1 89.844 (89.844)
 * Prec@1 89.910
current lr 1.00000e-02
Grad=  tensor(2.4626, device='cuda:0')
Epoch: [172][0/391]	Time 0.238 (0.238)	Data 0.119 (0.119)	Loss 0.2010 (0.2010) ([0.050]+[0.151])	Prec@1 98.438 (98.438)
Epoch: [172][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3244 (0.2854) ([0.174]+[0.151])	Prec@1 96.094 (95.444)
Epoch: [172][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2807 (0.2824) ([0.130]+[0.151])	Prec@1 93.750 (95.359)
Epoch: [172][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3018 (0.2851) ([0.151]+[0.151])	Prec@1 95.312 (95.261)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.5915 (0.5915) ([0.441]+[0.151])	Prec@1 87.500 (87.500)
 * Prec@1 89.560
current lr 1.00000e-02
Grad=  tensor(2.0219, device='cuda:0')
Epoch: [173][0/391]	Time 0.235 (0.235)	Data 0.117 (0.117)	Loss 0.2039 (0.2039) ([0.053]+[0.151])	Prec@1 99.219 (99.219)
Epoch: [173][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2878 (0.2700) ([0.137]+[0.151])	Prec@1 93.750 (96.047)
Epoch: [173][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2794 (0.2767) ([0.129]+[0.151])	Prec@1 95.312 (95.752)
Epoch: [173][300/391]	Time 0.108 (0.109)	Data 0.000 (0.000)	Loss 0.2717 (0.2773) ([0.121]+[0.151])	Prec@1 96.094 (95.723)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.5147 (0.5147) ([0.364]+[0.151])	Prec@1 89.062 (89.062)
 * Prec@1 90.980
current lr 1.00000e-02
Grad=  tensor(2.8232, device='cuda:0')
Epoch: [174][0/391]	Time 0.236 (0.236)	Data 0.117 (0.117)	Loss 0.2053 (0.2053) ([0.054]+[0.151])	Prec@1 99.219 (99.219)
Epoch: [174][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2889 (0.2577) ([0.138]+[0.151])	Prec@1 93.750 (96.434)
Epoch: [174][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2052 (0.2681) ([0.055]+[0.151])	Prec@1 98.438 (95.958)
Epoch: [174][300/391]	Time 0.108 (0.109)	Data 0.000 (0.000)	Loss 0.2916 (0.2740) ([0.141]+[0.151])	Prec@1 95.312 (95.681)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.5224 (0.5224) ([0.372]+[0.151])	Prec@1 87.500 (87.500)
 * Prec@1 89.890
current lr 1.00000e-02
Grad=  tensor(4.8564, device='cuda:0')
Epoch: [175][0/391]	Time 0.237 (0.237)	Data 0.118 (0.118)	Loss 0.2238 (0.2238) ([0.073]+[0.151])	Prec@1 97.656 (97.656)
Epoch: [175][100/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.2455 (0.2648) ([0.095]+[0.150])	Prec@1 97.656 (96.132)
Epoch: [175][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.4417 (0.2723) ([0.291]+[0.151])	Prec@1 92.188 (95.876)
Epoch: [175][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2636 (0.2798) ([0.113]+[0.151])	Prec@1 96.875 (95.582)
Test: [0/79]	Time 0.146 (0.146)	Loss 0.4598 (0.4598) ([0.309]+[0.151])	Prec@1 92.969 (92.969)
 * Prec@1 89.470
current lr 1.00000e-02
Grad=  tensor(7.4490, device='cuda:0')
Epoch: [176][0/391]	Time 0.243 (0.243)	Data 0.122 (0.122)	Loss 0.2855 (0.2855) ([0.135]+[0.151])	Prec@1 94.531 (94.531)
Epoch: [176][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3127 (0.2697) ([0.162]+[0.151])	Prec@1 95.312 (95.900)
Epoch: [176][200/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.2893 (0.2726) ([0.138]+[0.151])	Prec@1 92.969 (95.779)
Epoch: [176][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2425 (0.2778) ([0.092]+[0.151])	Prec@1 96.094 (95.593)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4034 (0.4034) ([0.253]+[0.151])	Prec@1 94.531 (94.531)
 * Prec@1 91.190
current lr 1.00000e-02
Grad=  tensor(7.4763, device='cuda:0')
Epoch: [177][0/391]	Time 0.235 (0.235)	Data 0.114 (0.114)	Loss 0.2604 (0.2604) ([0.110]+[0.151])	Prec@1 94.531 (94.531)
Epoch: [177][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3092 (0.2729) ([0.158]+[0.151])	Prec@1 92.969 (95.722)
Epoch: [177][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3278 (0.2731) ([0.177]+[0.151])	Prec@1 92.969 (95.810)
Epoch: [177][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2772 (0.2770) ([0.126]+[0.151])	Prec@1 94.531 (95.640)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.5371 (0.5371) ([0.386]+[0.151])	Prec@1 89.844 (89.844)
 * Prec@1 89.900
current lr 1.00000e-02
Grad=  tensor(5.2318, device='cuda:0')
Epoch: [178][0/391]	Time 0.239 (0.239)	Data 0.117 (0.117)	Loss 0.2426 (0.2426) ([0.092]+[0.151])	Prec@1 96.875 (96.875)
Epoch: [178][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2760 (0.2658) ([0.125]+[0.151])	Prec@1 95.312 (96.256)
Epoch: [178][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2253 (0.2741) ([0.074]+[0.151])	Prec@1 98.438 (95.833)
Epoch: [178][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.3122 (0.2798) ([0.161]+[0.151])	Prec@1 94.531 (95.634)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4999 (0.4999) ([0.349]+[0.151])	Prec@1 90.625 (90.625)
 * Prec@1 89.080
current lr 1.00000e-02
Grad=  tensor(11.6519, device='cuda:0')
Epoch: [179][0/391]	Time 0.242 (0.242)	Data 0.117 (0.117)	Loss 0.3083 (0.3083) ([0.157]+[0.151])	Prec@1 95.312 (95.312)
Epoch: [179][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2475 (0.2782) ([0.096]+[0.151])	Prec@1 96.094 (95.761)
Epoch: [179][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2850 (0.2797) ([0.134]+[0.151])	Prec@1 95.312 (95.697)
Epoch: [179][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3210 (0.2826) ([0.170]+[0.151])	Prec@1 94.531 (95.551)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.5103 (0.5103) ([0.359]+[0.151])	Prec@1 90.625 (90.625)
 * Prec@1 89.110
current lr 1.00000e-02
Grad=  tensor(8.5940, device='cuda:0')
Epoch: [180][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.2717 (0.2717) ([0.121]+[0.151])	Prec@1 95.312 (95.312)
Epoch: [180][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3036 (0.2688) ([0.153]+[0.151])	Prec@1 93.750 (95.978)
Epoch: [180][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2045 (0.2750) ([0.053]+[0.151])	Prec@1 99.219 (95.767)
Epoch: [180][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2856 (0.2774) ([0.134]+[0.151])	Prec@1 94.531 (95.678)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4550 (0.4550) ([0.304]+[0.151])	Prec@1 92.188 (92.188)
 * Prec@1 90.210
current lr 1.00000e-02
Grad=  tensor(5.3072, device='cuda:0')
Epoch: [181][0/391]	Time 0.237 (0.237)	Data 0.117 (0.117)	Loss 0.2308 (0.2308) ([0.080]+[0.151])	Prec@1 97.656 (97.656)
Epoch: [181][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2257 (0.2666) ([0.075]+[0.151])	Prec@1 98.438 (96.109)
Epoch: [181][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2089 (0.2659) ([0.058]+[0.151])	Prec@1 98.438 (96.086)
Epoch: [181][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2797 (0.2745) ([0.129]+[0.151])	Prec@1 96.094 (95.785)
Test: [0/79]	Time 0.146 (0.146)	Loss 0.6182 (0.6182) ([0.467]+[0.151])	Prec@1 86.719 (86.719)
 * Prec@1 89.390
current lr 1.00000e-02
Grad=  tensor(8.1591, device='cuda:0')
Epoch: [182][0/391]	Time 0.234 (0.234)	Data 0.113 (0.113)	Loss 0.2536 (0.2536) ([0.102]+[0.151])	Prec@1 96.875 (96.875)
Epoch: [182][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2637 (0.2679) ([0.113]+[0.151])	Prec@1 97.656 (95.978)
Epoch: [182][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3014 (0.2667) ([0.150]+[0.151])	Prec@1 93.750 (96.059)
Epoch: [182][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3318 (0.2703) ([0.181]+[0.151])	Prec@1 92.969 (95.954)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3951 (0.3951) ([0.244]+[0.151])	Prec@1 92.969 (92.969)
 * Prec@1 90.660
current lr 1.00000e-02
Grad=  tensor(6.8671, device='cuda:0')
Epoch: [183][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.2474 (0.2474) ([0.096]+[0.151])	Prec@1 96.094 (96.094)
Epoch: [183][100/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2402 (0.2678) ([0.089]+[0.151])	Prec@1 96.875 (96.047)
Epoch: [183][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2998 (0.2736) ([0.149]+[0.151])	Prec@1 95.312 (95.787)
Epoch: [183][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 0.3143 (0.2775) ([0.163]+[0.151])	Prec@1 95.312 (95.686)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4774 (0.4774) ([0.326]+[0.151])	Prec@1 89.844 (89.844)
 * Prec@1 90.340
current lr 1.00000e-02
Grad=  tensor(8.7317, device='cuda:0')
Epoch: [184][0/391]	Time 0.241 (0.241)	Data 0.120 (0.120)	Loss 0.2844 (0.2844) ([0.133]+[0.151])	Prec@1 96.875 (96.875)
Epoch: [184][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2247 (0.2638) ([0.074]+[0.151])	Prec@1 97.656 (96.218)
Epoch: [184][200/391]	Time 0.112 (0.110)	Data 0.000 (0.001)	Loss 0.2403 (0.2719) ([0.089]+[0.151])	Prec@1 96.875 (95.907)
Epoch: [184][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3271 (0.2764) ([0.176]+[0.151])	Prec@1 92.969 (95.746)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4532 (0.4532) ([0.302]+[0.152])	Prec@1 90.625 (90.625)
 * Prec@1 90.250
current lr 1.00000e-02
Grad=  tensor(15.5339, device='cuda:0')
Epoch: [185][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.3621 (0.3621) ([0.211]+[0.152])	Prec@1 92.969 (92.969)
Epoch: [185][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2764 (0.2632) ([0.125]+[0.151])	Prec@1 96.094 (96.148)
Epoch: [185][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1948 (0.2679) ([0.043]+[0.151])	Prec@1 99.219 (95.997)
Epoch: [185][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.3775 (0.2712) ([0.226]+[0.151])	Prec@1 92.188 (95.842)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.3477 (0.3477) ([0.196]+[0.151])	Prec@1 92.188 (92.188)
 * Prec@1 90.680
current lr 1.00000e-02
Grad=  tensor(9.5760, device='cuda:0')
Epoch: [186][0/391]	Time 0.240 (0.240)	Data 0.119 (0.119)	Loss 0.2539 (0.2539) ([0.102]+[0.151])	Prec@1 95.312 (95.312)
Epoch: [186][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2790 (0.2610) ([0.128]+[0.151])	Prec@1 92.969 (96.163)
Epoch: [186][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2945 (0.2709) ([0.143]+[0.151])	Prec@1 96.875 (95.725)
Epoch: [186][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2329 (0.2735) ([0.081]+[0.152])	Prec@1 96.875 (95.707)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.5151 (0.5151) ([0.364]+[0.151])	Prec@1 88.281 (88.281)
 * Prec@1 89.960
current lr 1.00000e-02
Grad=  tensor(8.2932, device='cuda:0')
Epoch: [187][0/391]	Time 0.237 (0.237)	Data 0.115 (0.115)	Loss 0.2560 (0.2560) ([0.105]+[0.151])	Prec@1 95.312 (95.312)
Epoch: [187][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2205 (0.2687) ([0.069]+[0.151])	Prec@1 99.219 (95.908)
Epoch: [187][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2657 (0.2749) ([0.114]+[0.152])	Prec@1 96.875 (95.713)
Epoch: [187][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2992 (0.2792) ([0.147]+[0.152])	Prec@1 92.969 (95.564)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.5668 (0.5668) ([0.415]+[0.152])	Prec@1 89.844 (89.844)
 * Prec@1 89.460
current lr 1.00000e-02
Grad=  tensor(10.0123, device='cuda:0')
Epoch: [188][0/391]	Time 0.237 (0.237)	Data 0.115 (0.115)	Loss 0.3109 (0.3109) ([0.159]+[0.152])	Prec@1 93.750 (93.750)
Epoch: [188][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2536 (0.2627) ([0.102]+[0.152])	Prec@1 96.094 (96.264)
Epoch: [188][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3018 (0.2755) ([0.150]+[0.152])	Prec@1 96.094 (95.709)
Epoch: [188][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2006 (0.2763) ([0.049]+[0.152])	Prec@1 98.438 (95.710)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4445 (0.4445) ([0.293]+[0.152])	Prec@1 89.062 (89.062)
 * Prec@1 89.600
current lr 1.00000e-02
Grad=  tensor(7.3513, device='cuda:0')
Epoch: [189][0/391]	Time 0.236 (0.236)	Data 0.115 (0.115)	Loss 0.2717 (0.2717) ([0.120]+[0.152])	Prec@1 95.312 (95.312)
Epoch: [189][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2299 (0.2658) ([0.078]+[0.152])	Prec@1 96.875 (96.187)
Epoch: [189][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2308 (0.2725) ([0.079]+[0.152])	Prec@1 96.875 (95.892)
Epoch: [189][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2436 (0.2769) ([0.092]+[0.152])	Prec@1 96.875 (95.733)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.4837 (0.4837) ([0.332]+[0.152])	Prec@1 89.062 (89.062)
 * Prec@1 88.890
current lr 1.00000e-02
Grad=  tensor(5.4541, device='cuda:0')
Epoch: [190][0/391]	Time 0.234 (0.234)	Data 0.113 (0.113)	Loss 0.2511 (0.2511) ([0.099]+[0.152])	Prec@1 96.875 (96.875)
Epoch: [190][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2694 (0.2569) ([0.118]+[0.152])	Prec@1 95.312 (96.403)
Epoch: [190][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2851 (0.2596) ([0.134]+[0.152])	Prec@1 93.750 (96.191)
Epoch: [190][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2669 (0.2658) ([0.115]+[0.152])	Prec@1 95.312 (96.068)
Test: [0/79]	Time 0.144 (0.144)	Loss 0.3680 (0.3680) ([0.216]+[0.152])	Prec@1 93.750 (93.750)
 * Prec@1 89.270
current lr 1.00000e-02
Grad=  tensor(9.5651, device='cuda:0')
Epoch: [191][0/391]	Time 0.236 (0.236)	Data 0.116 (0.116)	Loss 0.2726 (0.2726) ([0.121]+[0.152])	Prec@1 96.094 (96.094)
Epoch: [191][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3014 (0.2638) ([0.150]+[0.152])	Prec@1 94.531 (96.156)
Epoch: [191][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.3361 (0.2674) ([0.185]+[0.152])	Prec@1 93.750 (96.074)
Epoch: [191][300/391]	Time 0.112 (0.112)	Data 0.000 (0.000)	Loss 0.2922 (0.2704) ([0.141]+[0.152])	Prec@1 96.094 (95.920)
Test: [0/79]	Time 0.146 (0.146)	Loss 0.4852 (0.4852) ([0.334]+[0.152])	Prec@1 91.406 (91.406)
 * Prec@1 89.810
current lr 1.00000e-02
Grad=  tensor(4.5542, device='cuda:0')
Epoch: [192][0/391]	Time 0.240 (0.240)	Data 0.119 (0.119)	Loss 0.2129 (0.2129) ([0.061]+[0.152])	Prec@1 97.656 (97.656)
Epoch: [192][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3861 (0.2680) ([0.234]+[0.152])	Prec@1 90.625 (96.055)
Epoch: [192][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3105 (0.2726) ([0.159]+[0.152])	Prec@1 95.312 (95.814)
Epoch: [192][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3753 (0.2745) ([0.224]+[0.152])	Prec@1 93.750 (95.782)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3851 (0.3851) ([0.233]+[0.152])	Prec@1 92.188 (92.188)
 * Prec@1 90.220
current lr 1.00000e-02
Grad=  tensor(14.9382, device='cuda:0')
Epoch: [193][0/391]	Time 0.241 (0.241)	Data 0.119 (0.119)	Loss 0.3867 (0.3867) ([0.235]+[0.152])	Prec@1 92.188 (92.188)
Epoch: [193][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2335 (0.2660) ([0.082]+[0.152])	Prec@1 96.094 (96.109)
Epoch: [193][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2861 (0.2717) ([0.134]+[0.152])	Prec@1 95.312 (95.880)
Epoch: [193][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2956 (0.2724) ([0.144]+[0.152])	Prec@1 93.750 (95.834)
Test: [0/79]	Time 0.146 (0.146)	Loss 0.5002 (0.5002) ([0.348]+[0.152])	Prec@1 89.844 (89.844)
 * Prec@1 90.440
current lr 1.00000e-02
Grad=  tensor(3.4001, device='cuda:0')
Epoch: [194][0/391]	Time 0.239 (0.239)	Data 0.117 (0.117)	Loss 0.2294 (0.2294) ([0.078]+[0.152])	Prec@1 97.656 (97.656)
Epoch: [194][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2664 (0.2589) ([0.115]+[0.152])	Prec@1 96.094 (96.511)
Epoch: [194][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2532 (0.2654) ([0.102]+[0.152])	Prec@1 96.094 (96.296)
Epoch: [194][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.3272 (0.2723) ([0.175]+[0.152])	Prec@1 93.750 (95.980)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.5117 (0.5117) ([0.360]+[0.152])	Prec@1 89.844 (89.844)
 * Prec@1 90.240
current lr 1.00000e-02
Grad=  tensor(10.5639, device='cuda:0')
Epoch: [195][0/391]	Time 0.240 (0.240)	Data 0.119 (0.119)	Loss 0.3164 (0.3164) ([0.165]+[0.152])	Prec@1 94.531 (94.531)
Epoch: [195][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3329 (0.2590) ([0.181]+[0.152])	Prec@1 93.750 (96.519)
Epoch: [195][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2448 (0.2648) ([0.093]+[0.152])	Prec@1 96.875 (96.199)
Epoch: [195][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2784 (0.2707) ([0.127]+[0.152])	Prec@1 94.531 (96.006)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.5288 (0.5288) ([0.377]+[0.152])	Prec@1 89.062 (89.062)
 * Prec@1 90.250
current lr 1.00000e-02
Grad=  tensor(12.9683, device='cuda:0')
Epoch: [196][0/391]	Time 0.239 (0.239)	Data 0.117 (0.117)	Loss 0.3191 (0.3191) ([0.167]+[0.152])	Prec@1 92.188 (92.188)
Epoch: [196][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.3152 (0.2666) ([0.164]+[0.152])	Prec@1 94.531 (96.024)
Epoch: [196][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2918 (0.2713) ([0.140]+[0.152])	Prec@1 94.531 (95.919)
Epoch: [196][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2405 (0.2733) ([0.089]+[0.152])	Prec@1 96.875 (95.860)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4856 (0.4856) ([0.334]+[0.152])	Prec@1 92.188 (92.188)
 * Prec@1 89.320
current lr 1.00000e-02
Grad=  tensor(6.8947, device='cuda:0')
Epoch: [197][0/391]	Time 0.237 (0.237)	Data 0.118 (0.118)	Loss 0.2698 (0.2698) ([0.118]+[0.152])	Prec@1 96.875 (96.875)
Epoch: [197][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2341 (0.2635) ([0.082]+[0.152])	Prec@1 97.656 (96.295)
Epoch: [197][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2789 (0.2648) ([0.127]+[0.152])	Prec@1 96.875 (96.222)
Epoch: [197][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2550 (0.2696) ([0.103]+[0.152])	Prec@1 96.094 (96.008)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.3987 (0.3987) ([0.247]+[0.152])	Prec@1 92.188 (92.188)
 * Prec@1 91.100
current lr 1.00000e-02
Grad=  tensor(6.0468, device='cuda:0')
Epoch: [198][0/391]	Time 0.243 (0.243)	Data 0.118 (0.118)	Loss 0.2397 (0.2397) ([0.088]+[0.152])	Prec@1 98.438 (98.438)
Epoch: [198][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3320 (0.2667) ([0.180]+[0.152])	Prec@1 93.750 (96.078)
Epoch: [198][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2948 (0.2679) ([0.143]+[0.152])	Prec@1 95.312 (96.102)
Epoch: [198][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2446 (0.2736) ([0.093]+[0.152])	Prec@1 97.656 (95.847)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.3663 (0.3663) ([0.214]+[0.152])	Prec@1 90.625 (90.625)
 * Prec@1 90.400
current lr 1.00000e-02
Grad=  tensor(4.9430, device='cuda:0')
Epoch: [199][0/391]	Time 0.240 (0.240)	Data 0.117 (0.117)	Loss 0.2618 (0.2618) ([0.110]+[0.152])	Prec@1 96.875 (96.875)
Epoch: [199][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2547 (0.2703) ([0.103]+[0.152])	Prec@1 96.875 (95.769)
Epoch: [199][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2396 (0.2670) ([0.088]+[0.152])	Prec@1 95.312 (95.997)
Epoch: [199][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 0.2529 (0.2719) ([0.101]+[0.152])	Prec@1 96.875 (95.800)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.3937 (0.3937) ([0.242]+[0.152])	Prec@1 94.531 (94.531)
 * Prec@1 90.090
current lr 1.00000e-02
Grad=  tensor(4.2550, device='cuda:0')
Epoch: [200][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.2100 (0.2100) ([0.058]+[0.152])	Prec@1 99.219 (99.219)
Epoch: [200][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3231 (0.2466) ([0.171]+[0.152])	Prec@1 92.188 (96.921)
Epoch: [200][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2560 (0.2547) ([0.104]+[0.152])	Prec@1 96.094 (96.599)
Epoch: [200][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3737 (0.2649) ([0.222]+[0.152])	Prec@1 92.188 (96.182)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4442 (0.4442) ([0.292]+[0.152])	Prec@1 92.969 (92.969)
 * Prec@1 90.580
current lr 1.00000e-02
Grad=  tensor(5.7951, device='cuda:0')
Epoch: [201][0/391]	Time 0.236 (0.236)	Data 0.115 (0.115)	Loss 0.2684 (0.2684) ([0.116]+[0.152])	Prec@1 97.656 (97.656)
Epoch: [201][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2381 (0.2615) ([0.086]+[0.152])	Prec@1 96.875 (96.125)
Epoch: [201][200/391]	Time 0.108 (0.111)	Data 0.000 (0.001)	Loss 0.2505 (0.2692) ([0.098]+[0.152])	Prec@1 96.875 (95.915)
Epoch: [201][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.3520 (0.2739) ([0.200]+[0.152])	Prec@1 92.969 (95.795)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3944 (0.3944) ([0.242]+[0.152])	Prec@1 92.188 (92.188)
 * Prec@1 90.440
current lr 1.00000e-02
Grad=  tensor(6.0156, device='cuda:0')
Epoch: [202][0/391]	Time 0.232 (0.232)	Data 0.113 (0.113)	Loss 0.2505 (0.2505) ([0.098]+[0.152])	Prec@1 96.875 (96.875)
Epoch: [202][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2580 (0.2717) ([0.106]+[0.152])	Prec@1 94.531 (95.846)
Epoch: [202][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2498 (0.2682) ([0.098]+[0.152])	Prec@1 96.875 (96.051)
Epoch: [202][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.2394 (0.2707) ([0.087]+[0.152])	Prec@1 96.875 (95.915)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.3828 (0.3828) ([0.231]+[0.152])	Prec@1 92.969 (92.969)
 * Prec@1 89.780
current lr 1.00000e-02
Grad=  tensor(4.0690, device='cuda:0')
Epoch: [203][0/391]	Time 0.235 (0.235)	Data 0.116 (0.116)	Loss 0.2375 (0.2375) ([0.085]+[0.152])	Prec@1 97.656 (97.656)
Epoch: [203][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2922 (0.2546) ([0.140]+[0.152])	Prec@1 93.750 (96.542)
Epoch: [203][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3114 (0.2605) ([0.159]+[0.152])	Prec@1 92.969 (96.280)
Epoch: [203][300/391]	Time 0.108 (0.109)	Data 0.000 (0.000)	Loss 0.2835 (0.2655) ([0.131]+[0.152])	Prec@1 94.531 (96.044)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.5406 (0.5406) ([0.388]+[0.152])	Prec@1 86.719 (86.719)
 * Prec@1 89.010
current lr 1.00000e-02
Grad=  tensor(8.0526, device='cuda:0')
Epoch: [204][0/391]	Time 0.235 (0.235)	Data 0.116 (0.116)	Loss 0.2524 (0.2524) ([0.100]+[0.152])	Prec@1 95.312 (95.312)
Epoch: [204][100/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2593 (0.2663) ([0.107]+[0.152])	Prec@1 96.094 (96.078)
Epoch: [204][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2454 (0.2679) ([0.093]+[0.152])	Prec@1 95.312 (96.035)
Epoch: [204][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2499 (0.2703) ([0.098]+[0.152])	Prec@1 97.656 (95.977)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4854 (0.4854) ([0.333]+[0.152])	Prec@1 91.406 (91.406)
 * Prec@1 90.950
current lr 1.00000e-02
Grad=  tensor(6.1868, device='cuda:0')
Epoch: [205][0/391]	Time 0.238 (0.238)	Data 0.118 (0.118)	Loss 0.2518 (0.2518) ([0.099]+[0.152])	Prec@1 95.312 (95.312)
Epoch: [205][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2839 (0.2614) ([0.132]+[0.152])	Prec@1 96.875 (96.202)
Epoch: [205][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2396 (0.2632) ([0.087]+[0.152])	Prec@1 96.875 (96.105)
Epoch: [205][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2632 (0.2674) ([0.111]+[0.152])	Prec@1 94.531 (95.987)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4830 (0.4830) ([0.330]+[0.153])	Prec@1 91.406 (91.406)
 * Prec@1 89.030
current lr 1.00000e-02
Grad=  tensor(6.7157, device='cuda:0')
Epoch: [206][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.3167 (0.3167) ([0.164]+[0.153])	Prec@1 94.531 (94.531)
Epoch: [206][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2223 (0.2604) ([0.070]+[0.152])	Prec@1 97.656 (96.364)
Epoch: [206][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.2196 (0.2631) ([0.067]+[0.152])	Prec@1 97.656 (96.214)
Epoch: [206][300/391]	Time 0.109 (0.111)	Data 0.000 (0.000)	Loss 0.3201 (0.2648) ([0.168]+[0.152])	Prec@1 92.188 (96.156)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.5755 (0.5755) ([0.423]+[0.152])	Prec@1 89.062 (89.062)
 * Prec@1 89.190
current lr 1.00000e-02
Grad=  tensor(3.7254, device='cuda:0')
Epoch: [207][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.2032 (0.2032) ([0.051]+[0.152])	Prec@1 97.656 (97.656)
Epoch: [207][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2569 (0.2693) ([0.104]+[0.153])	Prec@1 96.875 (96.179)
Epoch: [207][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3068 (0.2728) ([0.154]+[0.153])	Prec@1 92.969 (95.829)
Epoch: [207][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.2418 (0.2745) ([0.089]+[0.153])	Prec@1 96.875 (95.780)
Test: [0/79]	Time 0.153 (0.153)	Loss 0.4375 (0.4375) ([0.285]+[0.153])	Prec@1 91.406 (91.406)
 * Prec@1 90.440
current lr 1.00000e-02
Grad=  tensor(7.5224, device='cuda:0')
Epoch: [208][0/391]	Time 0.236 (0.236)	Data 0.115 (0.115)	Loss 0.2662 (0.2662) ([0.113]+[0.153])	Prec@1 94.531 (94.531)
Epoch: [208][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2409 (0.2595) ([0.088]+[0.152])	Prec@1 96.875 (96.364)
Epoch: [208][200/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.2569 (0.2664) ([0.104]+[0.153])	Prec@1 96.094 (96.117)
Epoch: [208][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3590 (0.2665) ([0.206]+[0.153])	Prec@1 93.750 (96.140)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.5342 (0.5342) ([0.382]+[0.153])	Prec@1 90.625 (90.625)
 * Prec@1 89.370
current lr 1.00000e-02
Grad=  tensor(7.6426, device='cuda:0')
Epoch: [209][0/391]	Time 0.241 (0.241)	Data 0.119 (0.119)	Loss 0.2482 (0.2482) ([0.096]+[0.153])	Prec@1 97.656 (97.656)
Epoch: [209][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.2269 (0.2538) ([0.074]+[0.152])	Prec@1 98.438 (96.620)
Epoch: [209][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2801 (0.2572) ([0.128]+[0.152])	Prec@1 94.531 (96.436)
Epoch: [209][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 0.2820 (0.2607) ([0.130]+[0.152])	Prec@1 92.969 (96.283)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.5485 (0.5485) ([0.396]+[0.153])	Prec@1 87.500 (87.500)
 * Prec@1 89.340
current lr 1.00000e-02
Grad=  tensor(4.6196, device='cuda:0')
Epoch: [210][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.2409 (0.2409) ([0.088]+[0.153])	Prec@1 96.094 (96.094)
Epoch: [210][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2776 (0.2676) ([0.125]+[0.153])	Prec@1 95.312 (96.055)
Epoch: [210][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2125 (0.2716) ([0.060]+[0.153])	Prec@1 97.656 (95.946)
Epoch: [210][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2445 (0.2719) ([0.092]+[0.153])	Prec@1 97.656 (95.873)
Test: [0/79]	Time 0.146 (0.146)	Loss 0.5839 (0.5839) ([0.431]+[0.153])	Prec@1 90.625 (90.625)
 * Prec@1 90.560
current lr 1.00000e-02
Grad=  tensor(8.1430, device='cuda:0')
Epoch: [211][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.2678 (0.2678) ([0.115]+[0.153])	Prec@1 95.312 (95.312)
Epoch: [211][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.2339 (0.2658) ([0.081]+[0.153])	Prec@1 97.656 (96.055)
Epoch: [211][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.4619 (0.2663) ([0.309]+[0.153])	Prec@1 87.500 (96.070)
Epoch: [211][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2717 (0.2660) ([0.119]+[0.153])	Prec@1 97.656 (96.099)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4460 (0.4460) ([0.293]+[0.153])	Prec@1 93.750 (93.750)
 * Prec@1 90.070
current lr 1.00000e-02
Grad=  tensor(10.2349, device='cuda:0')
Epoch: [212][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.2968 (0.2968) ([0.144]+[0.153])	Prec@1 96.094 (96.094)
Epoch: [212][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2326 (0.2679) ([0.080]+[0.153])	Prec@1 97.656 (95.955)
Epoch: [212][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2861 (0.2683) ([0.133]+[0.153])	Prec@1 95.312 (95.888)
Epoch: [212][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2386 (0.2699) ([0.086]+[0.153])	Prec@1 96.875 (95.860)
Test: [0/79]	Time 0.146 (0.146)	Loss 0.4133 (0.4133) ([0.260]+[0.153])	Prec@1 91.406 (91.406)
 * Prec@1 89.440
current lr 1.00000e-02
Grad=  tensor(10.3996, device='cuda:0')
Epoch: [213][0/391]	Time 0.237 (0.237)	Data 0.117 (0.117)	Loss 0.2892 (0.2892) ([0.136]+[0.153])	Prec@1 96.094 (96.094)
Epoch: [213][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2865 (0.2652) ([0.133]+[0.153])	Prec@1 96.094 (96.411)
Epoch: [213][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2410 (0.2691) ([0.088]+[0.153])	Prec@1 97.656 (96.109)
Epoch: [213][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2526 (0.2700) ([0.100]+[0.153])	Prec@1 95.312 (96.050)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.2923 (0.2923) ([0.139]+[0.153])	Prec@1 94.531 (94.531)
 * Prec@1 90.640
current lr 1.00000e-02
Grad=  tensor(10.8065, device='cuda:0')
Epoch: [214][0/391]	Time 0.237 (0.237)	Data 0.117 (0.117)	Loss 0.2804 (0.2804) ([0.128]+[0.153])	Prec@1 94.531 (94.531)
Epoch: [214][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2413 (0.2599) ([0.089]+[0.153])	Prec@1 96.094 (96.426)
Epoch: [214][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2075 (0.2629) ([0.055]+[0.153])	Prec@1 99.219 (96.241)
Epoch: [214][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.2540 (0.2632) ([0.101]+[0.153])	Prec@1 96.094 (96.273)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3961 (0.3961) ([0.243]+[0.153])	Prec@1 92.188 (92.188)
 * Prec@1 90.130
current lr 1.00000e-02
Grad=  tensor(10.9859, device='cuda:0')
Epoch: [215][0/391]	Time 0.237 (0.237)	Data 0.117 (0.117)	Loss 0.2658 (0.2658) ([0.113]+[0.153])	Prec@1 96.094 (96.094)
Epoch: [215][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3758 (0.2595) ([0.223]+[0.153])	Prec@1 93.750 (96.550)
Epoch: [215][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2444 (0.2589) ([0.092]+[0.153])	Prec@1 96.094 (96.502)
Epoch: [215][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.2662 (0.2619) ([0.114]+[0.153])	Prec@1 97.656 (96.351)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4639 (0.4639) ([0.311]+[0.153])	Prec@1 90.625 (90.625)
 * Prec@1 90.350
current lr 1.00000e-02
Grad=  tensor(4.3850, device='cuda:0')
Epoch: [216][0/391]	Time 0.233 (0.233)	Data 0.113 (0.113)	Loss 0.2259 (0.2259) ([0.073]+[0.153])	Prec@1 96.875 (96.875)
Epoch: [216][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2249 (0.2575) ([0.072]+[0.152])	Prec@1 98.438 (96.496)
Epoch: [216][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2646 (0.2635) ([0.112]+[0.153])	Prec@1 96.094 (96.187)
Epoch: [216][300/391]	Time 0.110 (0.110)	Data 0.000 (0.000)	Loss 0.2805 (0.2673) ([0.128]+[0.153])	Prec@1 94.531 (96.011)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4336 (0.4336) ([0.281]+[0.153])	Prec@1 90.625 (90.625)
 * Prec@1 90.240
current lr 1.00000e-02
Grad=  tensor(13.8723, device='cuda:0')
Epoch: [217][0/391]	Time 0.235 (0.235)	Data 0.115 (0.115)	Loss 0.3487 (0.3487) ([0.196]+[0.153])	Prec@1 93.750 (93.750)
Epoch: [217][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2824 (0.2685) ([0.129]+[0.153])	Prec@1 96.875 (96.210)
Epoch: [217][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2793 (0.2664) ([0.126]+[0.153])	Prec@1 96.875 (96.187)
Epoch: [217][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 0.2535 (0.2654) ([0.101]+[0.153])	Prec@1 96.094 (96.208)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.5028 (0.5028) ([0.350]+[0.153])	Prec@1 93.750 (93.750)
 * Prec@1 90.780
current lr 1.00000e-02
Grad=  tensor(5.5176, device='cuda:0')
Epoch: [218][0/391]	Time 0.235 (0.235)	Data 0.116 (0.116)	Loss 0.2510 (0.2510) ([0.098]+[0.153])	Prec@1 97.656 (97.656)
Epoch: [218][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2621 (0.2658) ([0.109]+[0.153])	Prec@1 96.094 (96.442)
Epoch: [218][200/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2630 (0.2707) ([0.110]+[0.153])	Prec@1 93.750 (96.078)
Epoch: [218][300/391]	Time 0.108 (0.109)	Data 0.000 (0.000)	Loss 0.2748 (0.2749) ([0.122]+[0.153])	Prec@1 93.750 (95.899)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3984 (0.3984) ([0.245]+[0.153])	Prec@1 92.188 (92.188)
 * Prec@1 90.930
current lr 1.00000e-02
Grad=  tensor(4.9867, device='cuda:0')
Epoch: [219][0/391]	Time 0.236 (0.236)	Data 0.117 (0.117)	Loss 0.2501 (0.2501) ([0.097]+[0.153])	Prec@1 98.438 (98.438)
Epoch: [219][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2242 (0.2646) ([0.071]+[0.153])	Prec@1 96.875 (96.272)
Epoch: [219][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3348 (0.2610) ([0.182]+[0.153])	Prec@1 93.750 (96.315)
Epoch: [219][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3362 (0.2651) ([0.183]+[0.153])	Prec@1 92.969 (96.208)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4949 (0.4949) ([0.342]+[0.153])	Prec@1 90.625 (90.625)
 * Prec@1 90.820
current lr 1.00000e-02
Grad=  tensor(6.3372, device='cuda:0')
Epoch: [220][0/391]	Time 0.236 (0.236)	Data 0.115 (0.115)	Loss 0.2457 (0.2457) ([0.093]+[0.153])	Prec@1 96.094 (96.094)
Epoch: [220][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2544 (0.2499) ([0.102]+[0.153])	Prec@1 96.094 (96.782)
Epoch: [220][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2505 (0.2578) ([0.098]+[0.153])	Prec@1 96.094 (96.455)
Epoch: [220][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.3091 (0.2634) ([0.156]+[0.153])	Prec@1 93.750 (96.234)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.3540 (0.3540) ([0.201]+[0.153])	Prec@1 92.969 (92.969)
 * Prec@1 90.830
current lr 1.00000e-02
Grad=  tensor(3.2499, device='cuda:0')
Epoch: [221][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.2003 (0.2003) ([0.047]+[0.153])	Prec@1 98.438 (98.438)
Epoch: [221][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3249 (0.2750) ([0.172]+[0.153])	Prec@1 94.531 (95.993)
Epoch: [221][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3603 (0.2711) ([0.207]+[0.153])	Prec@1 93.750 (96.125)
Epoch: [221][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2686 (0.2700) ([0.116]+[0.153])	Prec@1 96.094 (96.140)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.3966 (0.3966) ([0.244]+[0.153])	Prec@1 92.969 (92.969)
 * Prec@1 90.220
current lr 1.00000e-02
Grad=  tensor(4.4362, device='cuda:0')
Epoch: [222][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.2082 (0.2082) ([0.055]+[0.153])	Prec@1 98.438 (98.438)
Epoch: [222][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2507 (0.2655) ([0.098]+[0.153])	Prec@1 96.094 (96.279)
Epoch: [222][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2190 (0.2675) ([0.066]+[0.153])	Prec@1 96.875 (96.199)
Epoch: [222][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2879 (0.2646) ([0.135]+[0.153])	Prec@1 97.656 (96.327)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4019 (0.4019) ([0.249]+[0.153])	Prec@1 93.750 (93.750)
 * Prec@1 89.230
current lr 1.00000e-02
Grad=  tensor(13.1793, device='cuda:0')
Epoch: [223][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.3081 (0.3081) ([0.155]+[0.153])	Prec@1 95.312 (95.312)
Epoch: [223][100/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.3004 (0.2633) ([0.147]+[0.153])	Prec@1 92.969 (96.434)
Epoch: [223][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3041 (0.2630) ([0.151]+[0.153])	Prec@1 92.969 (96.327)
Epoch: [223][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.2694 (0.2631) ([0.117]+[0.153])	Prec@1 95.312 (96.260)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.4426 (0.4426) ([0.289]+[0.153])	Prec@1 92.188 (92.188)
 * Prec@1 88.980
current lr 1.00000e-02
Grad=  tensor(5.6948, device='cuda:0')
Epoch: [224][0/391]	Time 0.242 (0.242)	Data 0.122 (0.122)	Loss 0.2282 (0.2282) ([0.075]+[0.153])	Prec@1 97.656 (97.656)
Epoch: [224][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1945 (0.2611) ([0.041]+[0.153])	Prec@1 99.219 (96.310)
Epoch: [224][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2130 (0.2687) ([0.060]+[0.153])	Prec@1 98.438 (96.039)
Epoch: [224][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2572 (0.2716) ([0.104]+[0.153])	Prec@1 95.312 (95.899)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.5487 (0.5487) ([0.395]+[0.153])	Prec@1 89.062 (89.062)
 * Prec@1 90.310
current lr 1.00000e-02
Grad=  tensor(8.7501, device='cuda:0')
Epoch: [225][0/391]	Time 0.238 (0.238)	Data 0.118 (0.118)	Loss 0.2461 (0.2461) ([0.093]+[0.153])	Prec@1 95.312 (95.312)
Epoch: [225][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2200 (0.2534) ([0.067]+[0.153])	Prec@1 96.875 (96.566)
Epoch: [225][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2615 (0.2583) ([0.109]+[0.153])	Prec@1 97.656 (96.416)
Epoch: [225][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.2657 (0.2641) ([0.113]+[0.153])	Prec@1 94.531 (96.198)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.5023 (0.5023) ([0.349]+[0.153])	Prec@1 89.062 (89.062)
 * Prec@1 89.930
current lr 1.00000e-02
Grad=  tensor(10.5379, device='cuda:0')
Epoch: [226][0/391]	Time 0.238 (0.238)	Data 0.119 (0.119)	Loss 0.3132 (0.3132) ([0.160]+[0.153])	Prec@1 94.531 (94.531)
Epoch: [226][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2815 (0.2655) ([0.129]+[0.153])	Prec@1 96.094 (96.009)
Epoch: [226][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2068 (0.2628) ([0.054]+[0.153])	Prec@1 97.656 (96.319)
Epoch: [226][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2696 (0.2605) ([0.117]+[0.153])	Prec@1 94.531 (96.356)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4611 (0.4611) ([0.308]+[0.153])	Prec@1 92.969 (92.969)
 * Prec@1 89.960
current lr 1.00000e-02
Grad=  tensor(1.5931, device='cuda:0')
Epoch: [227][0/391]	Time 0.239 (0.239)	Data 0.119 (0.119)	Loss 0.1923 (0.1923) ([0.039]+[0.153])	Prec@1 100.000 (100.000)
Epoch: [227][100/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2733 (0.2513) ([0.121]+[0.153])	Prec@1 92.969 (96.620)
Epoch: [227][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2750 (0.2582) ([0.122]+[0.153])	Prec@1 96.875 (96.428)
Epoch: [227][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3762 (0.2667) ([0.223]+[0.153])	Prec@1 93.750 (96.156)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4833 (0.4833) ([0.330]+[0.153])	Prec@1 93.750 (93.750)
 * Prec@1 89.950
current lr 1.00000e-02
Grad=  tensor(5.2838, device='cuda:0')
Epoch: [228][0/391]	Time 0.240 (0.240)	Data 0.120 (0.120)	Loss 0.2294 (0.2294) ([0.077]+[0.153])	Prec@1 98.438 (98.438)
Epoch: [228][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2093 (0.2556) ([0.057]+[0.153])	Prec@1 98.438 (96.542)
Epoch: [228][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2674 (0.2555) ([0.115]+[0.153])	Prec@1 95.312 (96.549)
Epoch: [228][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2537 (0.2643) ([0.101]+[0.153])	Prec@1 96.094 (96.213)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4416 (0.4416) ([0.289]+[0.153])	Prec@1 93.750 (93.750)
 * Prec@1 90.800
current lr 1.00000e-02
Grad=  tensor(10.5487, device='cuda:0')
Epoch: [229][0/391]	Time 0.237 (0.237)	Data 0.117 (0.117)	Loss 0.2884 (0.2884) ([0.135]+[0.153])	Prec@1 93.750 (93.750)
Epoch: [229][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2830 (0.2573) ([0.130]+[0.153])	Prec@1 95.312 (96.457)
Epoch: [229][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2593 (0.2611) ([0.106]+[0.153])	Prec@1 96.094 (96.276)
Epoch: [229][300/391]	Time 0.110 (0.110)	Data 0.000 (0.000)	Loss 0.2547 (0.2661) ([0.102]+[0.153])	Prec@1 96.094 (96.065)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.4826 (0.4826) ([0.329]+[0.153])	Prec@1 90.625 (90.625)
 * Prec@1 90.890
current lr 1.00000e-02
Grad=  tensor(10.7129, device='cuda:0')
Epoch: [230][0/391]	Time 0.236 (0.236)	Data 0.117 (0.117)	Loss 0.2942 (0.2942) ([0.141]+[0.153])	Prec@1 96.094 (96.094)
Epoch: [230][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2517 (0.2591) ([0.099]+[0.153])	Prec@1 98.438 (96.457)
Epoch: [230][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2716 (0.2579) ([0.118]+[0.153])	Prec@1 96.094 (96.412)
Epoch: [230][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.2611 (0.2600) ([0.108]+[0.153])	Prec@1 96.875 (96.353)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.5150 (0.5150) ([0.362]+[0.153])	Prec@1 89.844 (89.844)
 * Prec@1 90.270
current lr 1.00000e-02
Grad=  tensor(5.4184, device='cuda:0')
Epoch: [231][0/391]	Time 0.237 (0.237)	Data 0.117 (0.117)	Loss 0.2623 (0.2623) ([0.109]+[0.153])	Prec@1 97.656 (97.656)
Epoch: [231][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2745 (0.2542) ([0.121]+[0.153])	Prec@1 96.875 (96.658)
Epoch: [231][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2268 (0.2577) ([0.074]+[0.153])	Prec@1 98.438 (96.444)
Epoch: [231][300/391]	Time 0.111 (0.110)	Data 0.000 (0.000)	Loss 0.2862 (0.2613) ([0.133]+[0.153])	Prec@1 94.531 (96.265)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.4371 (0.4371) ([0.284]+[0.153])	Prec@1 92.188 (92.188)
 * Prec@1 90.830
current lr 1.00000e-02
Grad=  tensor(4.7794, device='cuda:0')
Epoch: [232][0/391]	Time 0.242 (0.242)	Data 0.120 (0.120)	Loss 0.2364 (0.2364) ([0.083]+[0.153])	Prec@1 97.656 (97.656)
Epoch: [232][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2570 (0.2573) ([0.104]+[0.153])	Prec@1 96.875 (96.426)
Epoch: [232][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2111 (0.2583) ([0.058]+[0.153])	Prec@1 99.219 (96.409)
Epoch: [232][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2239 (0.2639) ([0.071]+[0.153])	Prec@1 97.656 (96.221)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.5132 (0.5132) ([0.360]+[0.153])	Prec@1 90.625 (90.625)
 * Prec@1 90.230
current lr 1.00000e-02
Grad=  tensor(4.4394, device='cuda:0')
Epoch: [233][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.2147 (0.2147) ([0.061]+[0.153])	Prec@1 98.438 (98.438)
Epoch: [233][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2305 (0.2590) ([0.077]+[0.153])	Prec@1 97.656 (96.465)
Epoch: [233][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.2237 (0.2622) ([0.070]+[0.153])	Prec@1 96.875 (96.226)
Epoch: [233][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.2312 (0.2662) ([0.078]+[0.153])	Prec@1 96.875 (96.127)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4831 (0.4831) ([0.330]+[0.153])	Prec@1 90.625 (90.625)
 * Prec@1 89.540
current lr 1.00000e-02
Grad=  tensor(6.3243, device='cuda:0')
Epoch: [234][0/391]	Time 0.236 (0.236)	Data 0.117 (0.117)	Loss 0.2361 (0.2361) ([0.083]+[0.153])	Prec@1 96.875 (96.875)
Epoch: [234][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2147 (0.2615) ([0.061]+[0.153])	Prec@1 98.438 (96.395)
Epoch: [234][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2490 (0.2575) ([0.096]+[0.153])	Prec@1 97.656 (96.607)
Epoch: [234][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.2271 (0.2595) ([0.074]+[0.153])	Prec@1 96.094 (96.462)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.5687 (0.5687) ([0.415]+[0.153])	Prec@1 89.844 (89.844)
 * Prec@1 90.880
current lr 1.00000e-02
Grad=  tensor(6.9371, device='cuda:0')
Epoch: [235][0/391]	Time 0.236 (0.236)	Data 0.116 (0.116)	Loss 0.2265 (0.2265) ([0.073]+[0.153])	Prec@1 97.656 (97.656)
Epoch: [235][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2487 (0.2652) ([0.095]+[0.153])	Prec@1 96.094 (96.272)
Epoch: [235][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2633 (0.2673) ([0.110]+[0.153])	Prec@1 94.531 (96.117)
Epoch: [235][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.2614 (0.2688) ([0.108]+[0.153])	Prec@1 96.875 (96.052)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4468 (0.4468) ([0.294]+[0.153])	Prec@1 91.406 (91.406)
 * Prec@1 90.780
current lr 1.00000e-02
Grad=  tensor(4.4892, device='cuda:0')
Epoch: [236][0/391]	Time 0.240 (0.240)	Data 0.119 (0.119)	Loss 0.2123 (0.2123) ([0.059]+[0.153])	Prec@1 98.438 (98.438)
Epoch: [236][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3004 (0.2598) ([0.147]+[0.153])	Prec@1 94.531 (96.496)
Epoch: [236][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2300 (0.2642) ([0.077]+[0.153])	Prec@1 97.656 (96.218)
Epoch: [236][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.3487 (0.2649) ([0.195]+[0.153])	Prec@1 94.531 (96.224)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4466 (0.4466) ([0.293]+[0.153])	Prec@1 92.188 (92.188)
 * Prec@1 90.250
current lr 1.00000e-02
Grad=  tensor(4.0034, device='cuda:0')
Epoch: [237][0/391]	Time 0.237 (0.237)	Data 0.117 (0.117)	Loss 0.2257 (0.2257) ([0.072]+[0.153])	Prec@1 96.875 (96.875)
Epoch: [237][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2134 (0.2516) ([0.060]+[0.153])	Prec@1 99.219 (96.767)
Epoch: [237][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3177 (0.2567) ([0.165]+[0.153])	Prec@1 92.969 (96.467)
Epoch: [237][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.2166 (0.2593) ([0.063]+[0.153])	Prec@1 98.438 (96.408)
Test: [0/79]	Time 0.192 (0.192)	Loss 0.4009 (0.4009) ([0.248]+[0.153])	Prec@1 91.406 (91.406)
 * Prec@1 91.390
current lr 1.00000e-02
Grad=  tensor(9.0550, device='cuda:0')
Epoch: [238][0/391]	Time 0.241 (0.241)	Data 0.121 (0.121)	Loss 0.2818 (0.2818) ([0.128]+[0.153])	Prec@1 96.875 (96.875)
Epoch: [238][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2309 (0.2637) ([0.078]+[0.153])	Prec@1 97.656 (96.241)
Epoch: [238][200/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.3081 (0.2636) ([0.155]+[0.153])	Prec@1 95.312 (96.280)
Epoch: [238][300/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.2734 (0.2670) ([0.120]+[0.153])	Prec@1 96.094 (96.146)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.5118 (0.5118) ([0.358]+[0.154])	Prec@1 89.844 (89.844)
 * Prec@1 89.940
current lr 1.00000e-02
Grad=  tensor(3.5656, device='cuda:0')
Epoch: [239][0/391]	Time 0.237 (0.237)	Data 0.115 (0.115)	Loss 0.2159 (0.2159) ([0.062]+[0.154])	Prec@1 98.438 (98.438)
Epoch: [239][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2671 (0.2625) ([0.114]+[0.154])	Prec@1 94.531 (96.318)
Epoch: [239][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.2665 (0.2593) ([0.113]+[0.153])	Prec@1 94.531 (96.416)
Epoch: [239][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.2750 (0.2602) ([0.122]+[0.153])	Prec@1 95.312 (96.395)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4054 (0.4054) ([0.252]+[0.153])	Prec@1 92.969 (92.969)
 * Prec@1 87.780
current lr 1.00000e-02
Grad=  tensor(14.7076, device='cuda:0')
Epoch: [240][0/391]	Time 0.239 (0.239)	Data 0.119 (0.119)	Loss 0.3642 (0.3642) ([0.211]+[0.153])	Prec@1 93.750 (93.750)
Epoch: [240][100/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.3364 (0.2673) ([0.183]+[0.153])	Prec@1 94.531 (96.148)
Epoch: [240][200/391]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.2586 (0.2644) ([0.105]+[0.153])	Prec@1 97.656 (96.292)
Epoch: [240][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.2988 (0.2666) ([0.146]+[0.153])	Prec@1 93.750 (96.195)
Test: [0/79]	Time 0.146 (0.146)	Loss 0.4213 (0.4213) ([0.268]+[0.153])	Prec@1 91.406 (91.406)
 * Prec@1 90.200
current lr 1.00000e-02
Grad=  tensor(11.5172, device='cuda:0')
Epoch: [241][0/391]	Time 0.237 (0.237)	Data 0.117 (0.117)	Loss 0.2855 (0.2855) ([0.132]+[0.153])	Prec@1 94.531 (94.531)
Epoch: [241][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2067 (0.2546) ([0.053]+[0.153])	Prec@1 99.219 (96.550)
Epoch: [241][200/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2185 (0.2557) ([0.065]+[0.153])	Prec@1 96.875 (96.529)
Epoch: [241][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.3784 (0.2618) ([0.225]+[0.153])	Prec@1 93.750 (96.333)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.4043 (0.4043) ([0.251]+[0.153])	Prec@1 92.188 (92.188)
 * Prec@1 89.520
current lr 1.00000e-02
Grad=  tensor(4.9052, device='cuda:0')
Epoch: [242][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.1982 (0.1982) ([0.045]+[0.153])	Prec@1 98.438 (98.438)
Epoch: [242][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2921 (0.2601) ([0.139]+[0.153])	Prec@1 95.312 (96.326)
Epoch: [242][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2599 (0.2610) ([0.107]+[0.153])	Prec@1 96.875 (96.241)
Epoch: [242][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 0.2235 (0.2628) ([0.070]+[0.153])	Prec@1 98.438 (96.286)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.5132 (0.5132) ([0.360]+[0.153])	Prec@1 92.188 (92.188)
 * Prec@1 90.630
current lr 1.00000e-02
Grad=  tensor(7.2232, device='cuda:0')
Epoch: [243][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.2396 (0.2396) ([0.086]+[0.153])	Prec@1 97.656 (97.656)
Epoch: [243][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2894 (0.2644) ([0.136]+[0.153])	Prec@1 94.531 (96.218)
Epoch: [243][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.3785 (0.2680) ([0.225]+[0.154])	Prec@1 92.188 (96.168)
Epoch: [243][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 0.2161 (0.2668) ([0.063]+[0.154])	Prec@1 96.875 (96.156)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3204 (0.3204) ([0.167]+[0.154])	Prec@1 94.531 (94.531)
 * Prec@1 89.860
current lr 1.00000e-02
Grad=  tensor(3.1781, device='cuda:0')
Epoch: [244][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.2066 (0.2066) ([0.053]+[0.154])	Prec@1 99.219 (99.219)
Epoch: [244][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.2838 (0.2647) ([0.130]+[0.154])	Prec@1 95.312 (96.349)
Epoch: [244][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2109 (0.2674) ([0.057]+[0.154])	Prec@1 98.438 (96.148)
Epoch: [244][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 0.3023 (0.2683) ([0.149]+[0.154])	Prec@1 96.094 (96.029)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.3740 (0.3740) ([0.220]+[0.154])	Prec@1 92.969 (92.969)
 * Prec@1 90.210
current lr 1.00000e-02
Grad=  tensor(7.3752, device='cuda:0')
Epoch: [245][0/391]	Time 0.245 (0.245)	Data 0.120 (0.120)	Loss 0.2319 (0.2319) ([0.078]+[0.154])	Prec@1 97.656 (97.656)
Epoch: [245][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.2020 (0.2519) ([0.049]+[0.153])	Prec@1 99.219 (96.759)
Epoch: [245][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.3503 (0.2561) ([0.197]+[0.153])	Prec@1 90.625 (96.490)
Epoch: [245][300/391]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.3012 (0.2606) ([0.148]+[0.153])	Prec@1 93.750 (96.408)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.5813 (0.5813) ([0.428]+[0.154])	Prec@1 89.062 (89.062)
 * Prec@1 89.890
current lr 1.00000e-02
Grad=  tensor(7.7513, device='cuda:0')
Epoch: [246][0/391]	Time 0.236 (0.236)	Data 0.116 (0.116)	Loss 0.2571 (0.2571) ([0.104]+[0.154])	Prec@1 96.094 (96.094)
Epoch: [246][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2473 (0.2580) ([0.094]+[0.154])	Prec@1 96.875 (96.481)
Epoch: [246][200/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.2568 (0.2561) ([0.103]+[0.153])	Prec@1 94.531 (96.587)
Epoch: [246][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.2154 (0.2618) ([0.062]+[0.154])	Prec@1 98.438 (96.364)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.4746 (0.4746) ([0.321]+[0.153])	Prec@1 91.406 (91.406)
 * Prec@1 90.150
current lr 1.00000e-02
Grad=  tensor(14.2842, device='cuda:0')
Epoch: [247][0/391]	Time 0.235 (0.235)	Data 0.116 (0.116)	Loss 0.3177 (0.3177) ([0.164]+[0.153])	Prec@1 93.750 (93.750)
Epoch: [247][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2398 (0.2579) ([0.086]+[0.153])	Prec@1 96.875 (96.334)
Epoch: [247][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3026 (0.2624) ([0.149]+[0.154])	Prec@1 94.531 (96.245)
Epoch: [247][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.2966 (0.2646) ([0.143]+[0.153])	Prec@1 96.094 (96.198)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.4565 (0.4565) ([0.303]+[0.154])	Prec@1 89.844 (89.844)
 * Prec@1 89.990
current lr 1.00000e-02
Grad=  tensor(5.8512, device='cuda:0')
Epoch: [248][0/391]	Time 0.238 (0.238)	Data 0.116 (0.116)	Loss 0.2225 (0.2225) ([0.069]+[0.154])	Prec@1 97.656 (97.656)
Epoch: [248][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.2164 (0.2600) ([0.063]+[0.153])	Prec@1 97.656 (96.341)
Epoch: [248][200/391]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2105 (0.2618) ([0.057]+[0.153])	Prec@1 98.438 (96.292)
Epoch: [248][300/391]	Time 0.112 (0.112)	Data 0.000 (0.000)	Loss 0.2741 (0.2648) ([0.121]+[0.153])	Prec@1 95.312 (96.226)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3469 (0.3469) ([0.193]+[0.154])	Prec@1 94.531 (94.531)
 * Prec@1 90.850
current lr 1.00000e-02
Grad=  tensor(5.3766, device='cuda:0')
Epoch: [249][0/391]	Time 0.238 (0.238)	Data 0.116 (0.116)	Loss 0.2307 (0.2307) ([0.077]+[0.154])	Prec@1 97.656 (97.656)
Epoch: [249][100/391]	Time 0.112 (0.114)	Data 0.000 (0.001)	Loss 0.2342 (0.2582) ([0.081]+[0.154])	Prec@1 97.656 (96.395)
Epoch: [249][200/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.3464 (0.2602) ([0.193]+[0.154])	Prec@1 92.969 (96.323)
Epoch: [249][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 0.2416 (0.2608) ([0.088]+[0.154])	Prec@1 96.875 (96.390)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.3950 (0.3950) ([0.241]+[0.154])	Prec@1 93.750 (93.750)
 * Prec@1 89.870
current lr 1.00000e-03
Grad=  tensor(12.5914, device='cuda:0')
Epoch: [250][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.3082 (0.3082) ([0.154]+[0.154])	Prec@1 92.969 (92.969)
Epoch: [250][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2309 (0.2354) ([0.079]+[0.152])	Prec@1 96.875 (97.161)
Epoch: [250][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.2419 (0.2225) ([0.090]+[0.152])	Prec@1 97.656 (97.722)
Epoch: [250][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.1787 (0.2154) ([0.027]+[0.152])	Prec@1 100.000 (98.025)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3168 (0.3168) ([0.165]+[0.152])	Prec@1 95.312 (95.312)
 * Prec@1 93.690
current lr 1.00000e-03
Grad=  tensor(3.0820, device='cuda:0')
Epoch: [251][0/391]	Time 0.238 (0.238)	Data 0.118 (0.118)	Loss 0.2005 (0.2005) ([0.049]+[0.152])	Prec@1 99.219 (99.219)
Epoch: [251][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1834 (0.1956) ([0.032]+[0.151])	Prec@1 99.219 (98.731)
Epoch: [251][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1808 (0.1929) ([0.029]+[0.151])	Prec@1 100.000 (98.853)
Epoch: [251][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1852 (0.1921) ([0.034]+[0.151])	Prec@1 99.219 (98.887)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3250 (0.3250) ([0.174]+[0.151])	Prec@1 95.312 (95.312)
 * Prec@1 93.840
current lr 1.00000e-03
Grad=  tensor(1.4793, device='cuda:0')
Epoch: [252][0/391]	Time 0.241 (0.241)	Data 0.120 (0.120)	Loss 0.1734 (0.1734) ([0.022]+[0.151])	Prec@1 100.000 (100.000)
Epoch: [252][100/391]	Time 0.109 (0.112)	Data 0.000 (0.001)	Loss 0.1741 (0.1819) ([0.023]+[0.151])	Prec@1 100.000 (99.265)
Epoch: [252][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1840 (0.1809) ([0.033]+[0.151])	Prec@1 99.219 (99.304)
Epoch: [252][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.1705 (0.1808) ([0.020]+[0.151])	Prec@1 99.219 (99.307)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3319 (0.3319) ([0.182]+[0.150])	Prec@1 95.312 (95.312)
 * Prec@1 93.970
current lr 1.00000e-03
Grad=  tensor(3.6586, device='cuda:0')
Epoch: [253][0/391]	Time 0.239 (0.239)	Data 0.120 (0.120)	Loss 0.2032 (0.2032) ([0.053]+[0.150])	Prec@1 99.219 (99.219)
Epoch: [253][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1756 (0.1764) ([0.025]+[0.150])	Prec@1 99.219 (99.304)
Epoch: [253][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1776 (0.1768) ([0.028]+[0.150])	Prec@1 99.219 (99.335)
Epoch: [253][300/391]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.2077 (0.1773) ([0.058]+[0.150])	Prec@1 97.656 (99.328)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.3131 (0.3131) ([0.163]+[0.150])	Prec@1 95.312 (95.312)
 * Prec@1 94.060
current lr 1.00000e-03
Grad=  tensor(0.7913, device='cuda:0')
Epoch: [254][0/391]	Time 0.239 (0.239)	Data 0.119 (0.119)	Loss 0.1641 (0.1641) ([0.014]+[0.150])	Prec@1 100.000 (100.000)
Epoch: [254][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.1609 (0.1745) ([0.011]+[0.150])	Prec@1 100.000 (99.451)
Epoch: [254][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1627 (0.1737) ([0.013]+[0.150])	Prec@1 100.000 (99.471)
Epoch: [254][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1596 (0.1734) ([0.010]+[0.149])	Prec@1 100.000 (99.471)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3537 (0.3537) ([0.204]+[0.149])	Prec@1 95.312 (95.312)
 * Prec@1 94.160
current lr 1.00000e-03
Grad=  tensor(0.3589, device='cuda:0')
Epoch: [255][0/391]	Time 0.240 (0.240)	Data 0.121 (0.121)	Loss 0.1573 (0.1573) ([0.008]+[0.149])	Prec@1 100.000 (100.000)
Epoch: [255][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1893 (0.1704) ([0.040]+[0.149])	Prec@1 99.219 (99.567)
Epoch: [255][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1592 (0.1709) ([0.010]+[0.149])	Prec@1 100.000 (99.502)
Epoch: [255][300/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1762 (0.1715) ([0.027]+[0.149])	Prec@1 99.219 (99.460)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3167 (0.3167) ([0.168]+[0.149])	Prec@1 95.312 (95.312)
 * Prec@1 94.040
current lr 1.00000e-03
Grad=  tensor(0.3153, device='cuda:0')
Epoch: [256][0/391]	Time 0.236 (0.236)	Data 0.117 (0.117)	Loss 0.1564 (0.1564) ([0.008]+[0.149])	Prec@1 100.000 (100.000)
Epoch: [256][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1585 (0.1692) ([0.010]+[0.149])	Prec@1 100.000 (99.636)
Epoch: [256][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1557 (0.1693) ([0.007]+[0.148])	Prec@1 100.000 (99.600)
Epoch: [256][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.1719 (0.1689) ([0.024]+[0.148])	Prec@1 99.219 (99.582)
Test: [0/79]	Time 0.146 (0.146)	Loss 0.3048 (0.3048) ([0.157]+[0.148])	Prec@1 94.531 (94.531)
 * Prec@1 94.160
current lr 1.00000e-03
Grad=  tensor(0.7289, device='cuda:0')
Epoch: [257][0/391]	Time 0.236 (0.236)	Data 0.117 (0.117)	Loss 0.1621 (0.1621) ([0.014]+[0.148])	Prec@1 100.000 (100.000)
Epoch: [257][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1910 (0.1662) ([0.043]+[0.148])	Prec@1 98.438 (99.683)
Epoch: [257][200/391]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.1652 (0.1663) ([0.017]+[0.148])	Prec@1 99.219 (99.654)
Epoch: [257][300/391]	Time 0.111 (0.110)	Data 0.000 (0.000)	Loss 0.1548 (0.1663) ([0.007]+[0.148])	Prec@1 100.000 (99.639)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3066 (0.3066) ([0.159]+[0.148])	Prec@1 95.312 (95.312)
 * Prec@1 94.300
current lr 1.00000e-03
Grad=  tensor(1.7843, device='cuda:0')
Epoch: [258][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.1688 (0.1688) ([0.021]+[0.148])	Prec@1 100.000 (100.000)
Epoch: [258][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1732 (0.1643) ([0.026]+[0.147])	Prec@1 99.219 (99.667)
Epoch: [258][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1518 (0.1640) ([0.004]+[0.147])	Prec@1 100.000 (99.685)
Epoch: [258][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1534 (0.1649) ([0.006]+[0.147])	Prec@1 100.000 (99.639)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3128 (0.3128) ([0.166]+[0.147])	Prec@1 95.312 (95.312)
 * Prec@1 94.190
current lr 1.00000e-03
Grad=  tensor(0.8442, device='cuda:0')
Epoch: [259][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.1596 (0.1596) ([0.013]+[0.147])	Prec@1 100.000 (100.000)
Epoch: [259][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1596 (0.1634) ([0.013]+[0.147])	Prec@1 99.219 (99.722)
Epoch: [259][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1624 (0.1636) ([0.016]+[0.147])	Prec@1 100.000 (99.720)
Epoch: [259][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.1688 (0.1635) ([0.022]+[0.147])	Prec@1 100.000 (99.709)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3010 (0.3010) ([0.154]+[0.147])	Prec@1 95.312 (95.312)
 * Prec@1 94.270
current lr 1.00000e-03
Grad=  tensor(1.2102, device='cuda:0')
Epoch: [260][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.1572 (0.1572) ([0.011]+[0.147])	Prec@1 99.219 (99.219)
Epoch: [260][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1661 (0.1611) ([0.020]+[0.146])	Prec@1 100.000 (99.729)
Epoch: [260][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1752 (0.1613) ([0.029]+[0.146])	Prec@1 99.219 (99.712)
Epoch: [260][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1575 (0.1611) ([0.011]+[0.146])	Prec@1 100.000 (99.727)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.3074 (0.3074) ([0.161]+[0.146])	Prec@1 95.312 (95.312)
 * Prec@1 94.250
current lr 1.00000e-03
Grad=  tensor(1.4643, device='cuda:0')
Epoch: [261][0/391]	Time 0.240 (0.240)	Data 0.120 (0.120)	Loss 0.1609 (0.1609) ([0.015]+[0.146])	Prec@1 99.219 (99.219)
Epoch: [261][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1542 (0.1622) ([0.008]+[0.146])	Prec@1 100.000 (99.660)
Epoch: [261][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1565 (0.1613) ([0.011]+[0.146])	Prec@1 100.000 (99.705)
Epoch: [261][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.1599 (0.1612) ([0.014]+[0.146])	Prec@1 100.000 (99.702)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.2866 (0.2866) ([0.141]+[0.146])	Prec@1 95.312 (95.312)
 * Prec@1 94.150
current lr 1.00000e-03
Grad=  tensor(2.8829, device='cuda:0')
Epoch: [262][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.1758 (0.1758) ([0.030]+[0.146])	Prec@1 99.219 (99.219)
Epoch: [262][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1620 (0.1589) ([0.017]+[0.145])	Prec@1 100.000 (99.768)
Epoch: [262][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1882 (0.1593) ([0.043]+[0.145])	Prec@1 98.438 (99.751)
Epoch: [262][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1581 (0.1597) ([0.013]+[0.145])	Prec@1 100.000 (99.730)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.3240 (0.3240) ([0.179]+[0.145])	Prec@1 95.312 (95.312)
 * Prec@1 94.270
current lr 1.00000e-03
Grad=  tensor(0.2090, device='cuda:0')
Epoch: [263][0/391]	Time 0.235 (0.235)	Data 0.114 (0.114)	Loss 0.1504 (0.1504) ([0.005]+[0.145])	Prec@1 100.000 (100.000)
Epoch: [263][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1560 (0.1599) ([0.011]+[0.145])	Prec@1 100.000 (99.675)
Epoch: [263][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1516 (0.1595) ([0.007]+[0.145])	Prec@1 100.000 (99.697)
Epoch: [263][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1657 (0.1595) ([0.021]+[0.145])	Prec@1 100.000 (99.702)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.3124 (0.3124) ([0.168]+[0.145])	Prec@1 95.312 (95.312)
 * Prec@1 94.460
current lr 1.00000e-03
Grad=  tensor(0.8071, device='cuda:0')
Epoch: [264][0/391]	Time 0.242 (0.242)	Data 0.120 (0.120)	Loss 0.1585 (0.1585) ([0.014]+[0.145])	Prec@1 100.000 (100.000)
Epoch: [264][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1528 (0.1564) ([0.008]+[0.144])	Prec@1 100.000 (99.814)
Epoch: [264][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1753 (0.1565) ([0.031]+[0.144])	Prec@1 98.438 (99.825)
Epoch: [264][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1616 (0.1566) ([0.017]+[0.144])	Prec@1 100.000 (99.831)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3188 (0.3188) ([0.175]+[0.144])	Prec@1 96.094 (96.094)
 * Prec@1 94.280
current lr 1.00000e-03
Grad=  tensor(1.4572, device='cuda:0')
Epoch: [265][0/391]	Time 0.238 (0.238)	Data 0.116 (0.116)	Loss 0.1589 (0.1589) ([0.015]+[0.144])	Prec@1 100.000 (100.000)
Epoch: [265][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1679 (0.1573) ([0.024]+[0.144])	Prec@1 99.219 (99.706)
Epoch: [265][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1624 (0.1571) ([0.018]+[0.144])	Prec@1 100.000 (99.751)
Epoch: [265][300/391]	Time 0.113 (0.112)	Data 0.000 (0.000)	Loss 0.1600 (0.1565) ([0.016]+[0.144])	Prec@1 100.000 (99.785)
Test: [0/79]	Time 0.152 (0.152)	Loss 0.3180 (0.3180) ([0.174]+[0.144])	Prec@1 96.094 (96.094)
 * Prec@1 94.400
current lr 1.00000e-03
Grad=  tensor(0.8058, device='cuda:0')
Epoch: [266][0/391]	Time 0.243 (0.243)	Data 0.120 (0.120)	Loss 0.1553 (0.1553) ([0.012]+[0.144])	Prec@1 100.000 (100.000)
Epoch: [266][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.1533 (0.1572) ([0.010]+[0.144])	Prec@1 100.000 (99.768)
Epoch: [266][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1507 (0.1567) ([0.007]+[0.143])	Prec@1 100.000 (99.771)
Epoch: [266][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.1515 (0.1562) ([0.008]+[0.143])	Prec@1 100.000 (99.779)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3179 (0.3179) ([0.175]+[0.143])	Prec@1 95.312 (95.312)
 * Prec@1 94.330
current lr 1.00000e-03
Grad=  tensor(0.3415, device='cuda:0')
Epoch: [267][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.1511 (0.1511) ([0.008]+[0.143])	Prec@1 100.000 (100.000)
Epoch: [267][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1468 (0.1558) ([0.004]+[0.143])	Prec@1 100.000 (99.807)
Epoch: [267][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1571 (0.1553) ([0.014]+[0.143])	Prec@1 100.000 (99.786)
Epoch: [267][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1630 (0.1552) ([0.020]+[0.143])	Prec@1 99.219 (99.785)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.3211 (0.3211) ([0.178]+[0.143])	Prec@1 94.531 (94.531)
 * Prec@1 94.240
current lr 1.00000e-03
Grad=  tensor(0.7306, device='cuda:0')
Epoch: [268][0/391]	Time 0.249 (0.249)	Data 0.128 (0.128)	Loss 0.1545 (0.1545) ([0.012]+[0.143])	Prec@1 100.000 (100.000)
Epoch: [268][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1523 (0.1549) ([0.010]+[0.143])	Prec@1 100.000 (99.814)
Epoch: [268][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1588 (0.1545) ([0.016]+[0.142])	Prec@1 99.219 (99.810)
Epoch: [268][300/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1529 (0.1541) ([0.011]+[0.142])	Prec@1 100.000 (99.824)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.3146 (0.3146) ([0.172]+[0.142])	Prec@1 96.094 (96.094)
 * Prec@1 94.380
current lr 1.00000e-03
Grad=  tensor(0.8219, device='cuda:0')
Epoch: [269][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.1560 (0.1560) ([0.014]+[0.142])	Prec@1 100.000 (100.000)
Epoch: [269][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1560 (0.1532) ([0.014]+[0.142])	Prec@1 99.219 (99.807)
Epoch: [269][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1501 (0.1530) ([0.008]+[0.142])	Prec@1 100.000 (99.813)
Epoch: [269][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 0.1501 (0.1531) ([0.008]+[0.142])	Prec@1 100.000 (99.816)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3210 (0.3210) ([0.179]+[0.142])	Prec@1 95.312 (95.312)
 * Prec@1 94.160
current lr 1.00000e-03
Grad=  tensor(1.7429, device='cuda:0')
Epoch: [270][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.1545 (0.1545) ([0.013]+[0.142])	Prec@1 100.000 (100.000)
Epoch: [270][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.1480 (0.1530) ([0.006]+[0.142])	Prec@1 100.000 (99.814)
Epoch: [270][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1533 (0.1528) ([0.012]+[0.141])	Prec@1 100.000 (99.841)
Epoch: [270][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1539 (0.1526) ([0.012]+[0.141])	Prec@1 99.219 (99.824)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3188 (0.3188) ([0.178]+[0.141])	Prec@1 95.312 (95.312)
 * Prec@1 94.190
current lr 1.00000e-03
Grad=  tensor(0.5098, device='cuda:0')
Epoch: [271][0/391]	Time 0.240 (0.240)	Data 0.118 (0.118)	Loss 0.1496 (0.1496) ([0.008]+[0.141])	Prec@1 100.000 (100.000)
Epoch: [271][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1516 (0.1516) ([0.010]+[0.141])	Prec@1 100.000 (99.861)
Epoch: [271][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1476 (0.1521) ([0.007]+[0.141])	Prec@1 100.000 (99.833)
Epoch: [271][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1526 (0.1520) ([0.012]+[0.141])	Prec@1 100.000 (99.826)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.3103 (0.3103) ([0.170]+[0.141])	Prec@1 95.312 (95.312)
 * Prec@1 94.280
current lr 1.00000e-03
Grad=  tensor(0.6843, device='cuda:0')
Epoch: [272][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.1501 (0.1501) ([0.009]+[0.141])	Prec@1 100.000 (100.000)
Epoch: [272][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1460 (0.1500) ([0.005]+[0.141])	Prec@1 100.000 (99.923)
Epoch: [272][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1806 (0.1510) ([0.040]+[0.141])	Prec@1 99.219 (99.860)
Epoch: [272][300/391]	Time 0.109 (0.111)	Data 0.000 (0.000)	Loss 0.1503 (0.1510) ([0.010]+[0.140])	Prec@1 99.219 (99.862)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3205 (0.3205) ([0.180]+[0.140])	Prec@1 94.531 (94.531)
 * Prec@1 94.250
current lr 1.00000e-03
Grad=  tensor(3.6171, device='cuda:0')
Epoch: [273][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.1643 (0.1643) ([0.024]+[0.140])	Prec@1 99.219 (99.219)
Epoch: [273][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1438 (0.1504) ([0.004]+[0.140])	Prec@1 100.000 (99.838)
Epoch: [273][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1504 (0.1502) ([0.010]+[0.140])	Prec@1 100.000 (99.829)
Epoch: [273][300/391]	Time 0.110 (0.109)	Data 0.000 (0.000)	Loss 0.1587 (0.1506) ([0.019]+[0.140])	Prec@1 99.219 (99.805)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.3325 (0.3325) ([0.193]+[0.140])	Prec@1 96.094 (96.094)
 * Prec@1 94.210
current lr 1.00000e-03
Grad=  tensor(0.4751, device='cuda:0')
Epoch: [274][0/391]	Time 0.237 (0.237)	Data 0.117 (0.117)	Loss 0.1467 (0.1467) ([0.007]+[0.140])	Prec@1 100.000 (100.000)
Epoch: [274][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1440 (0.1498) ([0.004]+[0.140])	Prec@1 100.000 (99.845)
Epoch: [274][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1459 (0.1500) ([0.006]+[0.140])	Prec@1 100.000 (99.845)
Epoch: [274][300/391]	Time 0.109 (0.111)	Data 0.000 (0.000)	Loss 0.1561 (0.1499) ([0.017]+[0.140])	Prec@1 100.000 (99.844)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3324 (0.3324) ([0.193]+[0.139])	Prec@1 95.312 (95.312)
 * Prec@1 94.380
current lr 1.00000e-03
Grad=  tensor(0.2658, device='cuda:0')
Epoch: [275][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.1438 (0.1438) ([0.004]+[0.139])	Prec@1 100.000 (100.000)
Epoch: [275][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1461 (0.1474) ([0.007]+[0.139])	Prec@1 100.000 (99.938)
Epoch: [275][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1436 (0.1475) ([0.004]+[0.139])	Prec@1 100.000 (99.922)
Epoch: [275][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1445 (0.1480) ([0.005]+[0.139])	Prec@1 100.000 (99.917)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.3164 (0.3164) ([0.177]+[0.139])	Prec@1 95.312 (95.312)
 * Prec@1 94.170
current lr 1.00000e-03
Grad=  tensor(2.1503, device='cuda:0')
Epoch: [276][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.1538 (0.1538) ([0.015]+[0.139])	Prec@1 100.000 (100.000)
Epoch: [276][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1537 (0.1489) ([0.015]+[0.139])	Prec@1 100.000 (99.853)
Epoch: [276][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1415 (0.1488) ([0.003]+[0.139])	Prec@1 100.000 (99.864)
Epoch: [276][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1465 (0.1482) ([0.008]+[0.139])	Prec@1 100.000 (99.881)
Test: [0/79]	Time 0.191 (0.191)	Loss 0.2905 (0.2905) ([0.152]+[0.138])	Prec@1 96.875 (96.875)
 * Prec@1 94.300
current lr 1.00000e-03
Grad=  tensor(1.5823, device='cuda:0')
Epoch: [277][0/391]	Time 0.312 (0.312)	Data 0.156 (0.156)	Loss 0.1505 (0.1505) ([0.012]+[0.138])	Prec@1 100.000 (100.000)
Epoch: [277][100/391]	Time 0.109 (0.111)	Data 0.000 (0.002)	Loss 0.1534 (0.1473) ([0.015]+[0.138])	Prec@1 99.219 (99.861)
Epoch: [277][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1456 (0.1472) ([0.007]+[0.138])	Prec@1 100.000 (99.868)
Epoch: [277][300/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1520 (0.1474) ([0.014]+[0.138])	Prec@1 99.219 (99.852)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3003 (0.3003) ([0.162]+[0.138])	Prec@1 96.875 (96.875)
 * Prec@1 94.300
current lr 1.00000e-03
Grad=  tensor(1.0383, device='cuda:0')
Epoch: [278][0/391]	Time 0.240 (0.240)	Data 0.117 (0.117)	Loss 0.1481 (0.1481) ([0.010]+[0.138])	Prec@1 100.000 (100.000)
Epoch: [278][100/391]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.1408 (0.1461) ([0.003]+[0.138])	Prec@1 100.000 (99.899)
Epoch: [278][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1534 (0.1465) ([0.016]+[0.138])	Prec@1 100.000 (99.887)
Epoch: [278][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 0.1445 (0.1467) ([0.007]+[0.138])	Prec@1 100.000 (99.881)
Test: [0/79]	Time 0.145 (0.145)	Loss 0.3141 (0.3141) ([0.176]+[0.138])	Prec@1 96.875 (96.875)
 * Prec@1 94.400
current lr 1.00000e-03
Grad=  tensor(7.6510, device='cuda:0')
Epoch: [279][0/391]	Time 0.238 (0.238)	Data 0.116 (0.116)	Loss 0.1688 (0.1688) ([0.031]+[0.138])	Prec@1 97.656 (97.656)
Epoch: [279][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1510 (0.1463) ([0.013]+[0.137])	Prec@1 100.000 (99.869)
Epoch: [279][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1475 (0.1465) ([0.010]+[0.137])	Prec@1 100.000 (99.876)
Epoch: [279][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1416 (0.1466) ([0.004]+[0.137])	Prec@1 100.000 (99.875)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3264 (0.3264) ([0.189]+[0.137])	Prec@1 96.094 (96.094)
 * Prec@1 94.330
current lr 1.00000e-03
Grad=  tensor(0.5299, device='cuda:0')
Epoch: [280][0/391]	Time 0.239 (0.239)	Data 0.118 (0.118)	Loss 0.1434 (0.1434) ([0.006]+[0.137])	Prec@1 100.000 (100.000)
Epoch: [280][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1453 (0.1449) ([0.008]+[0.137])	Prec@1 100.000 (99.923)
Epoch: [280][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1429 (0.1447) ([0.006]+[0.137])	Prec@1 100.000 (99.907)
Epoch: [280][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.1414 (0.1451) ([0.005]+[0.137])	Prec@1 100.000 (99.883)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3288 (0.3288) ([0.192]+[0.137])	Prec@1 94.531 (94.531)
 * Prec@1 94.350
current lr 1.00000e-03
Grad=  tensor(1.4755, device='cuda:0')
Epoch: [281][0/391]	Time 0.233 (0.233)	Data 0.112 (0.112)	Loss 0.1473 (0.1473) ([0.011]+[0.137])	Prec@1 100.000 (100.000)
Epoch: [281][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1471 (0.1454) ([0.010]+[0.137])	Prec@1 100.000 (99.923)
Epoch: [281][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1442 (0.1454) ([0.008]+[0.136])	Prec@1 100.000 (99.907)
Epoch: [281][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.1436 (0.1452) ([0.007]+[0.136])	Prec@1 100.000 (99.899)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.3176 (0.3176) ([0.181]+[0.136])	Prec@1 95.312 (95.312)
 * Prec@1 94.360
current lr 1.00000e-03
Grad=  tensor(0.1510, device='cuda:0')
Epoch: [282][0/391]	Time 0.236 (0.236)	Data 0.116 (0.116)	Loss 0.1392 (0.1392) ([0.003]+[0.136])	Prec@1 100.000 (100.000)
Epoch: [282][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1457 (0.1448) ([0.010]+[0.136])	Prec@1 100.000 (99.899)
Epoch: [282][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1454 (0.1445) ([0.009]+[0.136])	Prec@1 100.000 (99.903)
Epoch: [282][300/391]	Time 0.109 (0.111)	Data 0.000 (0.000)	Loss 0.1419 (0.1443) ([0.006]+[0.136])	Prec@1 100.000 (99.907)
Test: [0/79]	Time 0.146 (0.146)	Loss 0.3128 (0.3128) ([0.177]+[0.136])	Prec@1 95.312 (95.312)
 * Prec@1 94.330
current lr 1.00000e-03
Grad=  tensor(1.0537, device='cuda:0')
Epoch: [283][0/391]	Time 0.236 (0.236)	Data 0.117 (0.117)	Loss 0.1465 (0.1465) ([0.011]+[0.136])	Prec@1 100.000 (100.000)
Epoch: [283][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1617 (0.1436) ([0.026]+[0.136])	Prec@1 99.219 (99.938)
Epoch: [283][200/391]	Time 0.109 (0.109)	Data 0.000 (0.001)	Loss 0.1389 (0.1433) ([0.003]+[0.136])	Prec@1 100.000 (99.938)
Epoch: [283][300/391]	Time 0.111 (0.109)	Data 0.000 (0.000)	Loss 0.1433 (0.1432) ([0.008]+[0.135])	Prec@1 100.000 (99.933)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.2973 (0.2973) ([0.162]+[0.135])	Prec@1 95.312 (95.312)
 * Prec@1 94.470
current lr 1.00000e-03
Grad=  tensor(0.2633, device='cuda:0')
Epoch: [284][0/391]	Time 0.239 (0.239)	Data 0.117 (0.117)	Loss 0.1408 (0.1408) ([0.005]+[0.135])	Prec@1 100.000 (100.000)
Epoch: [284][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1444 (0.1433) ([0.009]+[0.135])	Prec@1 100.000 (99.899)
Epoch: [284][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1406 (0.1431) ([0.005]+[0.135])	Prec@1 100.000 (99.903)
Epoch: [284][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1480 (0.1433) ([0.013]+[0.135])	Prec@1 100.000 (99.883)
Test: [0/79]	Time 0.151 (0.151)	Loss 0.2968 (0.2968) ([0.162]+[0.135])	Prec@1 96.094 (96.094)
 * Prec@1 94.530
current lr 1.00000e-03
Grad=  tensor(0.1637, device='cuda:0')
Epoch: [285][0/391]	Time 0.240 (0.240)	Data 0.120 (0.120)	Loss 0.1380 (0.1380) ([0.003]+[0.135])	Prec@1 100.000 (100.000)
Epoch: [285][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1398 (0.1428) ([0.005]+[0.135])	Prec@1 100.000 (99.899)
Epoch: [285][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1414 (0.1425) ([0.007]+[0.135])	Prec@1 100.000 (99.918)
Epoch: [285][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1385 (0.1423) ([0.004]+[0.134])	Prec@1 100.000 (99.917)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3083 (0.3083) ([0.174]+[0.134])	Prec@1 95.312 (95.312)
 * Prec@1 94.440
current lr 1.00000e-03
Grad=  tensor(0.3325, device='cuda:0')
Epoch: [286][0/391]	Time 0.241 (0.241)	Data 0.118 (0.118)	Loss 0.1404 (0.1404) ([0.006]+[0.134])	Prec@1 100.000 (100.000)
Epoch: [286][100/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1407 (0.1419) ([0.006]+[0.134])	Prec@1 100.000 (99.946)
Epoch: [286][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1374 (0.1420) ([0.003]+[0.134])	Prec@1 100.000 (99.918)
Epoch: [286][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.1373 (0.1416) ([0.003]+[0.134])	Prec@1 100.000 (99.925)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3067 (0.3067) ([0.173]+[0.134])	Prec@1 96.094 (96.094)
 * Prec@1 94.410
current lr 1.00000e-03
Grad=  tensor(0.1435, device='cuda:0')
Epoch: [287][0/391]	Time 0.235 (0.235)	Data 0.116 (0.116)	Loss 0.1356 (0.1356) ([0.002]+[0.134])	Prec@1 100.000 (100.000)
Epoch: [287][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1525 (0.1410) ([0.019]+[0.134])	Prec@1 99.219 (99.938)
Epoch: [287][200/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.1399 (0.1408) ([0.006]+[0.134])	Prec@1 100.000 (99.942)
Epoch: [287][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.1403 (0.1410) ([0.007]+[0.134])	Prec@1 100.000 (99.925)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.2885 (0.2885) ([0.155]+[0.133])	Prec@1 95.312 (95.312)
 * Prec@1 94.210
current lr 1.00000e-03
Grad=  tensor(5.0993, device='cuda:0')
Epoch: [288][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.1557 (0.1557) ([0.022]+[0.133])	Prec@1 99.219 (99.219)
Epoch: [288][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1403 (0.1410) ([0.007]+[0.133])	Prec@1 100.000 (99.930)
Epoch: [288][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1368 (0.1407) ([0.004]+[0.133])	Prec@1 100.000 (99.922)
Epoch: [288][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.1388 (0.1406) ([0.006]+[0.133])	Prec@1 100.000 (99.922)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3085 (0.3085) ([0.175]+[0.133])	Prec@1 96.094 (96.094)
 * Prec@1 94.440
current lr 1.00000e-03
Grad=  tensor(0.8649, device='cuda:0')
Epoch: [289][0/391]	Time 0.236 (0.236)	Data 0.116 (0.116)	Loss 0.1439 (0.1439) ([0.011]+[0.133])	Prec@1 100.000 (100.000)
Epoch: [289][100/391]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.1406 (0.1400) ([0.008]+[0.133])	Prec@1 100.000 (99.946)
Epoch: [289][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1376 (0.1405) ([0.005]+[0.133])	Prec@1 100.000 (99.934)
Epoch: [289][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.1399 (0.1404) ([0.007]+[0.133])	Prec@1 100.000 (99.938)
Test: [0/79]	Time 0.147 (0.147)	Loss 0.3059 (0.3059) ([0.173]+[0.133])	Prec@1 96.094 (96.094)
 * Prec@1 94.400
current lr 1.00000e-03
Grad=  tensor(0.2309, device='cuda:0')
Epoch: [290][0/391]	Time 0.234 (0.234)	Data 0.114 (0.114)	Loss 0.1368 (0.1368) ([0.004]+[0.133])	Prec@1 100.000 (100.000)
Epoch: [290][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1366 (0.1389) ([0.004]+[0.132])	Prec@1 100.000 (99.923)
Epoch: [290][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1470 (0.1391) ([0.015]+[0.132])	Prec@1 99.219 (99.934)
Epoch: [290][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.1362 (0.1391) ([0.004]+[0.132])	Prec@1 100.000 (99.933)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3020 (0.3020) ([0.170]+[0.132])	Prec@1 95.312 (95.312)
 * Prec@1 94.240
current lr 1.00000e-03
Grad=  tensor(0.1665, device='cuda:0')
Epoch: [291][0/391]	Time 0.241 (0.241)	Data 0.121 (0.121)	Loss 0.1348 (0.1348) ([0.003]+[0.132])	Prec@1 100.000 (100.000)
Epoch: [291][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1349 (0.1383) ([0.003]+[0.132])	Prec@1 100.000 (99.954)
Epoch: [291][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1362 (0.1385) ([0.004]+[0.132])	Prec@1 100.000 (99.918)
Epoch: [291][300/391]	Time 0.108 (0.111)	Data 0.000 (0.001)	Loss 0.1439 (0.1387) ([0.012]+[0.132])	Prec@1 99.219 (99.922)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.3056 (0.3056) ([0.174]+[0.132])	Prec@1 96.094 (96.094)
 * Prec@1 94.400
current lr 1.00000e-03
Grad=  tensor(0.2024, device='cuda:0')
Epoch: [292][0/391]	Time 0.235 (0.235)	Data 0.116 (0.116)	Loss 0.1349 (0.1349) ([0.003]+[0.132])	Prec@1 100.000 (100.000)
Epoch: [292][100/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1429 (0.1384) ([0.011]+[0.132])	Prec@1 99.219 (99.938)
Epoch: [292][200/391]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.1363 (0.1383) ([0.005]+[0.131])	Prec@1 100.000 (99.934)
Epoch: [292][300/391]	Time 0.109 (0.109)	Data 0.000 (0.000)	Loss 0.1358 (0.1384) ([0.004]+[0.131])	Prec@1 100.000 (99.927)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3111 (0.3111) ([0.180]+[0.131])	Prec@1 95.312 (95.312)
 * Prec@1 94.330
current lr 1.00000e-03
Grad=  tensor(1.0211, device='cuda:0')
Epoch: [293][0/391]	Time 0.235 (0.235)	Data 0.115 (0.115)	Loss 0.1367 (0.1367) ([0.005]+[0.131])	Prec@1 100.000 (100.000)
Epoch: [293][100/391]	Time 0.110 (0.112)	Data 0.000 (0.001)	Loss 0.1388 (0.1384) ([0.008]+[0.131])	Prec@1 100.000 (99.876)
Epoch: [293][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1431 (0.1384) ([0.012]+[0.131])	Prec@1 100.000 (99.895)
Epoch: [293][300/391]	Time 0.110 (0.111)	Data 0.000 (0.000)	Loss 0.1349 (0.1382) ([0.004]+[0.131])	Prec@1 100.000 (99.907)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.3015 (0.3015) ([0.171]+[0.131])	Prec@1 96.094 (96.094)
 * Prec@1 94.390
current lr 1.00000e-03
Grad=  tensor(0.2430, device='cuda:0')
Epoch: [294][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.1346 (0.1346) ([0.004]+[0.131])	Prec@1 100.000 (100.000)
Epoch: [294][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1350 (0.1383) ([0.004]+[0.131])	Prec@1 100.000 (99.923)
Epoch: [294][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1335 (0.1377) ([0.003]+[0.131])	Prec@1 100.000 (99.926)
Epoch: [294][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1326 (0.1379) ([0.002]+[0.130])	Prec@1 100.000 (99.917)
Test: [0/79]	Time 0.149 (0.149)	Loss 0.2883 (0.2883) ([0.158]+[0.130])	Prec@1 96.094 (96.094)
 * Prec@1 94.380
current lr 1.00000e-03
Grad=  tensor(0.2772, device='cuda:0')
Epoch: [295][0/391]	Time 0.237 (0.237)	Data 0.116 (0.116)	Loss 0.1355 (0.1355) ([0.005]+[0.130])	Prec@1 100.000 (100.000)
Epoch: [295][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1350 (0.1368) ([0.005]+[0.130])	Prec@1 100.000 (99.954)
Epoch: [295][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1358 (0.1371) ([0.006]+[0.130])	Prec@1 100.000 (99.934)
Epoch: [295][300/391]	Time 0.111 (0.112)	Data 0.000 (0.000)	Loss 0.1337 (0.1371) ([0.004]+[0.130])	Prec@1 100.000 (99.938)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.3172 (0.3172) ([0.187]+[0.130])	Prec@1 95.312 (95.312)
 * Prec@1 94.410
current lr 1.00000e-03
Grad=  tensor(0.2064, device='cuda:0')
Epoch: [296][0/391]	Time 0.237 (0.237)	Data 0.115 (0.115)	Loss 0.1331 (0.1331) ([0.003]+[0.130])	Prec@1 100.000 (100.000)
Epoch: [296][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1359 (0.1359) ([0.006]+[0.130])	Prec@1 100.000 (99.954)
Epoch: [296][200/391]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.1354 (0.1358) ([0.006]+[0.130])	Prec@1 100.000 (99.961)
Epoch: [296][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1412 (0.1363) ([0.012]+[0.130])	Prec@1 99.219 (99.935)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.3114 (0.3114) ([0.182]+[0.129])	Prec@1 94.531 (94.531)
 * Prec@1 94.370
current lr 1.00000e-03
Grad=  tensor(0.2630, device='cuda:0')
Epoch: [297][0/391]	Time 0.238 (0.238)	Data 0.117 (0.117)	Loss 0.1334 (0.1334) ([0.004]+[0.129])	Prec@1 100.000 (100.000)
Epoch: [297][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1377 (0.1362) ([0.008]+[0.129])	Prec@1 100.000 (99.923)
Epoch: [297][200/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1372 (0.1357) ([0.008]+[0.129])	Prec@1 100.000 (99.949)
Epoch: [297][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1328 (0.1358) ([0.004]+[0.129])	Prec@1 100.000 (99.945)
Test: [0/79]	Time 0.150 (0.150)	Loss 0.3124 (0.3124) ([0.183]+[0.129])	Prec@1 94.531 (94.531)
 * Prec@1 94.320
current lr 1.00000e-03
Grad=  tensor(1.6094, device='cuda:0')
Epoch: [298][0/391]	Time 0.241 (0.241)	Data 0.120 (0.120)	Loss 0.1381 (0.1381) ([0.009]+[0.129])	Prec@1 100.000 (100.000)
Epoch: [298][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1350 (0.1356) ([0.006]+[0.129])	Prec@1 100.000 (99.930)
Epoch: [298][200/391]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.1332 (0.1352) ([0.004]+[0.129])	Prec@1 100.000 (99.938)
Epoch: [298][300/391]	Time 0.111 (0.111)	Data 0.000 (0.000)	Loss 0.1313 (0.1353) ([0.003]+[0.129])	Prec@1 100.000 (99.914)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3232 (0.3232) ([0.195]+[0.129])	Prec@1 95.312 (95.312)
 * Prec@1 94.380
current lr 1.00000e-03
Grad=  tensor(0.1636, device='cuda:0')
Epoch: [299][0/391]	Time 0.239 (0.239)	Data 0.117 (0.117)	Loss 0.1317 (0.1317) ([0.003]+[0.129])	Prec@1 100.000 (100.000)
Epoch: [299][100/391]	Time 0.111 (0.112)	Data 0.000 (0.001)	Loss 0.1321 (0.1353) ([0.004]+[0.128])	Prec@1 100.000 (99.907)
Epoch: [299][200/391]	Time 0.109 (0.111)	Data 0.000 (0.001)	Loss 0.1304 (0.1355) ([0.002]+[0.128])	Prec@1 100.000 (99.911)
Epoch: [299][300/391]	Time 0.109 (0.110)	Data 0.000 (0.000)	Loss 0.1315 (0.1353) ([0.003]+[0.128])	Prec@1 100.000 (99.914)
Test: [0/79]	Time 0.148 (0.148)	Loss 0.3273 (0.3273) ([0.199]+[0.128])	Prec@1 94.531 (94.531)
 * Prec@1 94.410

 Elapsed time for training  3:52:52.221041

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.9629629850387573, 0.0, 0.9629629850387573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9629629850387573, 0.9629629850387573, 0.8518518805503845, 0.9629629850387573, 0.0, 0.0, 0.0, 0.0, 0.5185185074806213, 0.0, 0.0, 0.9629629850387573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7037037014961243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9629629850387573, 0.9629629850387573, 0.9629629850387573, 0.0, 0.9259259104728699]

 sparsity of   [0.96875, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.96875, 0.96875, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.984375, 0.96875, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.96875, 0.96875, 0.96875, 0.0, 0.0, 0.203125, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.96875, 0.96875, 0.96875, 0.0, 0.96875, 0.0, 0.203125, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.2916666567325592, 0.9965277910232544, 0.9965277910232544, 0.0, 0.9965277910232544, 0.9965277910232544, 0.0, 0.9947916865348816, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9965277910232544, 0.9965277910232544, 0.9982638955116272, 0.9965277910232544, 0.0, 0.0, 0.9947916865348816, 0.9965277910232544, 0.9982638955116272, 0.0, 0.9965277910232544, 0.9982638955116272, 0.0, 0.0, 0.3125, 0.9965277910232544, 0.9982638955116272, 0.9982638955116272, 0.9965277910232544, 0.0, 0.0, 0.9965277910232544, 0.0, 0.0, 0.9965277910232544, 0.3125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9965277910232544, 0.0, 0.9965277910232544, 0.0, 0.3125, 0.9965277910232544, 0.0, 0.0, 0.9965277910232544, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 0.046875, 0.0, 0.0, 0.0, 0.0, 0.40625, 0.0, 0.0, 0.453125, 0.4375, 0.0, 0.984375, 0.0, 0.0, 0.453125, 0.0, 0.0, 0.0, 0.0, 0.453125, 0.96875, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.453125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.453125, 0.0, 0.453125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.453125, 0.984375, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.453125, 0.0, 0.0, 0.0, 0.984375, 0.953125, 0.453125, 0.09375, 0.0, 0.0, 0.453125, 0.0, 0.453125, 0.0, 0.0, 0.96875, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.453125, 0.03125, 0.0, 0.0, 0.453125, 0.0, 0.96875, 0.0, 0.0, 0.453125, 0.953125, 0.453125, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.453125, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.140625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.453125, 0.0, 0.453125, 0.4375, 0.0, 0.0, 0.453125, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.421875, 0.984375, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.453125, 0.96875, 0.0, 0.96875, 0.96875, 0.453125, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03125, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.453125, 0.0, 0.0, 0.0, 0.453125, 0.96875, 0.984375, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.984375, 0.96875, 0.0, 0.96875, 0.96875, 0.0, 0.0, 0.953125, 0.96875, 0.0, 0.0, 0.0, 0.453125, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.453125, 0.96875, 0.96875, 0.0, 0.96875, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.96875, 0.96875, 0.0, 0.984375, 0.96875, 0.015625, 0.0, 0.96875, 0.984375, 0.03125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.203125, 0.0, 0.96875, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.96875, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.203125, 0.0, 0.0, 0.0, 0.96875, 0.96875, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.96875, 0.0, 0.203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.203125, 0.0, 0.0, 0.0, 0.96875, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.203125, 0.96875, 0.984375, 0.203125, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.203125, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.96875, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.96875, 0.96875, 0.203125, 0.96875, 0.96875, 0.0, 0.0, 0.96875, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.96875, 0.96875, 0.0, 0.96875, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.984375, 0.96875, 0.0, 0.984375, 0.96875, 0.203125, 0.0, 0.96875, 0.96875, 0.0, 0.0, 0.203125, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [0.9921875, 0.0, 0.0, 0.98828125, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.21484375, 0.9921875, 0.0, 0.9921875, 0.21484375, 0.9921875, 0.9921875, 0.21484375, 0.0, 0.21484375, 0.99609375, 0.99609375, 0.98828125, 0.99609375, 0.0, 0.21484375, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.98828125, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.21484375, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.0]

 sparsity of   [0.9965277910232544, 0.0, 0.9965277910232544, 0.9965277910232544, 0.0, 0.9965277910232544, 0.0, 0.0, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.0, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.9982638955116272, 0.0, 0.9965277910232544, 0.9965277910232544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9982638955116272, 0.9965277910232544, 0.0, 0.9965277910232544, 0.9965277910232544, 0.9982638955116272, 0.9965277910232544, 0.9965277910232544, 0.9965277910232544, 0.0, 0.9965277910232544, 0.0, 0.9982638955116272, 0.9965277910232544, 0.0, 0.9965277910232544, 0.9965277910232544, 0.46875, 0.9965277910232544, 0.9965277910232544, 0.9982638955116272, 0.9982638955116272, 0.4670138955116272, 0.9965277910232544, 0.9982638955116272, 0.0, 0.9965277910232544, 0.0, 0.0, 0.0, 0.9965277910232544, 0.9982638955116272, 0.9965277910232544, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 0.4375, 0.0, 0.0, 0.0, 0.0, 0.65625, 0.0, 0.0, 0.65625, 0.65625, 0.65625, 0.96875, 0.65625, 0.0, 0.65625, 0.65625, 0.0, 0.0, 0.0, 0.65625, 0.96875, 0.0, 0.96875, 0.65625, 0.65625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.65625, 0.65625, 0.0, 0.0, 0.0, 0.65625, 0.0, 0.65625, 0.0, 0.0, 0.0, 0.65625, 0.65625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.65625, 0.65625, 0.0, 0.0, 0.65625, 0.0, 0.0, 0.0, 0.65625, 0.0, 0.65625, 0.0, 0.0, 0.96875, 0.65625, 0.0, 0.0, 0.0, 0.0, 0.65625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.65625, 0.0, 0.0, 0.0, 0.984375, 0.96875, 0.0, 0.9375, 0.65625, 0.0, 0.65625, 0.0, 0.65625, 0.0, 0.0, 0.96875, 0.0, 0.65625, 0.0, 0.0, 0.984375, 0.65625, 0.65625, 0.65625, 0.0, 0.0, 0.0, 0.96875, 0.65625, 0.0, 0.65625, 0.96875, 0.65625, 0.96875, 0.0, 0.65625, 0.0, 0.0, 0.0, 0.65625, 0.65625, 0.65625, 0.0, 0.0, 0.0, 0.0, 0.96875, 0.0, 0.0, 0.984375, 0.65625, 0.0, 0.0, 0.65625, 0.65625, 0.0, 0.65625, 0.0, 0.65625, 0.65625, 0.65625, 0.0, 0.65625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.65625, 0.0, 0.65625, 0.0, 0.96875, 0.0, 0.0, 0.0, 0.65625, 0.9375, 0.0, 0.65625, 0.0, 0.0, 0.0, 0.65625, 0.0, 0.65625, 0.96875, 0.0, 0.65625, 0.65625, 0.65625, 0.0, 0.65625, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.65625, 0.234375, 0.0, 0.0, 0.0, 0.65625, 0.65625, 0.65625, 0.65625, 0.0, 0.65625, 0.65625, 0.0, 0.0, 0.96875, 0.96875, 0.0, 0.0, 0.65625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.96875, 0.65625, 0.96875, 0.96875, 0.0, 0.65625, 0.96875, 0.0, 0.0, 0.0, 0.0, 0.65625, 0.0, 0.65625, 0.65625, 0.0, 0.96875, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.65625, 0.0, 0.0, 0.0, 0.96875, 0.96875, 0.0, 0.0, 0.96875, 0.65625, 0.0, 0.0, 0.96875, 0.65625, 0.0, 0.65625, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [0.265625, 0.9921875, 0.0, 0.0, 0.0546875, 0.7421875, 0.0, 0.1875, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.99609375, 0.06640625, 0.0, 0.0, 0.015625, 0.0, 0.0078125, 0.0, 0.0234375, 0.0, 0.1171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4375, 0.0, 0.015625, 0.0, 0.0, 0.09375, 0.82421875, 0.9921875, 0.13671875, 0.0, 0.12109375, 0.00390625, 0.0234375, 0.0, 0.9921875, 0.99609375, 0.26171875, 0.0390625, 0.953125, 0.0, 0.125, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.19921875, 0.0, 0.04296875, 0.0, 0.21875, 0.0, 0.03515625, 0.125]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.378472238779068, 0.1701388955116272, 0.0, 0.01909722201526165, 0.0694444477558136, 0.9114583134651184, 0.0, 0.4045138955116272, 0.9479166865348816, 0.0, 0.0503472238779068, 0.0, 0.0, 0.0225694440305233, 0.0, 0.0, 0.01909722201526165, 0.0, 0.0, 0.0, 0.0, 0.9982638955116272, 0.0, 0.0347222238779068, 0.0, 0.0381944440305233, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01909722201526165, 0.140625, 0.7291666865348816, 0.0, 0.9184027910232544, 0.0, 0.0, 0.8697916865348816, 0.9965277910232544, 0.0329861119389534, 0.0, 0.0, 0.0, 0.0364583320915699, 0.9965277910232544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01215277798473835, 0.3819444477558136, 0.0, 0.1041666641831398]

 sparsity of   [0.0, 0.03125, 0.015625, 0.28125, 0.25, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21875, 0.0, 0.0, 0.0, 0.0, 0.28125, 0.0, 0.28125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34375, 0.28125, 0.0, 0.28125, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.28125, 0.28125, 0.0, 0.0, 0.015625, 0.28125, 0.0, 0.0, 0.28125, 0.0, 0.0, 0.0, 0.0, 0.265625, 0.0, 0.0, 0.0, 0.28125, 0.25, 0.0, 0.0, 0.0, 0.28125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28125, 0.0, 0.0, 0.109375, 0.171875, 0.0, 0.28125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28125, 0.0, 0.28125, 0.0, 0.28125, 0.28125, 0.140625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.28125, 0.0, 0.0, 0.0, 0.25, 0.0, 0.28125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28125, 0.0, 0.046875, 0.0, 0.0, 0.484375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28125, 0.0, 0.0, 0.0, 0.28125, 0.0, 0.265625, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 0.0078125, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0078125, 0.9921875, 0.0, 0.9921875, 0.0, 0.0078125, 0.40625, 0.15625, 0.16796875, 0.0, 0.98828125, 0.98828125, 0.98828125, 0.9921875, 0.0, 0.0, 0.01171875, 0.99609375, 0.0, 0.99609375, 0.5625, 0.0, 0.0, 0.99609375, 0.98828125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.98828125, 0.0, 0.0, 0.046875, 0.99609375, 0.0078125, 0.9921875, 0.99609375, 0.0, 0.0078125, 0.0, 0.0078125, 0.99609375, 0.0, 0.0, 0.0, 0.1328125, 0.9921875, 0.00390625, 0.99609375, 0.9921875, 0.0078125, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.98828125, 0.0, 0.0, 0.98828125, 0.0, 0.00390625, 0.0, 0.9921875, 0.02734375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.76953125, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.1796875, 0.0, 0.21875, 0.00390625, 0.0, 0.39453125, 0.1171875, 0.9921875, 0.98828125, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0859375, 0.0, 0.484375, 0.9921875]

 sparsity of   [0.8828125, 0.0564236119389534, 0.02864583395421505, 0.9973958134651184, 0.0, 0.0, 0.0, 0.0590277798473835, 0.0234375, 0.0164930559694767, 0.0, 0.0, 0.0920138880610466, 0.0, 0.0251736119389534, 0.0, 0.1328125, 0.0, 0.0173611119389534, 0.0512152798473835, 0.0625, 0.1440972238779068, 0.0364583320915699, 0.999131977558136, 0.9982638955116272, 0.0, 0.0, 0.02777777798473835, 0.0, 0.0, 0.9973958134651184, 0.03125, 0.0329861119389534, 0.150173619389534, 0.0, 0.0434027798473835, 0.3602430522441864, 0.8723958134651184, 0.0, 0.0685763880610466, 0.0, 0.4348958432674408, 0.013888888992369175, 0.999131977558136, 0.9982638955116272, 0.5112847089767456, 0.0, 0.9418402910232544, 0.999131977558136, 0.9253472089767456, 0.0086805559694767, 0.0, 0.9973958134651184, 0.0, 0.9982638955116272, 0.9088541865348816, 0.02777777798473835, 0.858506977558136, 0.0, 0.015625, 0.0, 0.9982638955116272, 0.9982638955116272, 0.0, 0.8142361044883728, 0.0, 0.0, 0.0, 0.9982638955116272, 0.9305555820465088, 0.0486111119389534, 0.0164930559694767, 0.0434027798473835, 0.0, 0.0598958320915699, 0.4001736044883728, 0.1145833358168602, 0.02083333395421505, 0.0, 0.9357638955116272, 0.999131977558136, 0.9973958134651184, 0.9565972089767456, 0.009548611007630825, 0.9982638955116272, 0.0, 0.9401041865348816, 0.0, 0.9453125, 0.046875, 0.3654513955116272, 0.0824652761220932, 0.02777777798473835, 0.5234375, 0.01128472201526165, 0.0, 0.0, 0.0, 0.5104166865348816, 0.2152777761220932, 0.0, 0.013020833022892475, 0.0564236119389534, 0.9982638955116272, 0.0434027798473835, 0.0590277798473835, 0.1467013955116272, 0.0407986119389534, 0.02951388992369175, 0.9973958134651184, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.0, 0.0, 0.02864583395421505, 0.9982638955116272, 0.0, 0.0, 0.0, 0.01128472201526165, 0.063368059694767, 0.0529513880610466, 0.02170138992369175, 0.0, 0.9982638955116272, 0.928819477558136, 0.071180559694767]

 sparsity of   [0.9765625, 0.0, 0.625, 0.0, 0.0, 0.625, 0.0, 0.984375, 0.0, 0.984375, 0.0, 0.984375, 0.9921875, 0.0, 0.984375, 0.984375, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.9921875, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.984375, 0.984375, 0.984375, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.984375, 0.9765625, 0.984375, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.984375, 0.984375, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.984375, 0.9765625, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.984375, 0.625, 0.625, 0.625, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.9765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.625, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.9765625, 0.0, 0.984375, 0.984375, 0.9921875, 0.0, 0.0, 0.9765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.625, 0.9921875, 0.625, 0.9921875, 0.984375, 0.0, 0.0, 0.0, 0.984375, 0.9765625, 0.9921875, 0.984375, 0.625, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.9765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.6875, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.984375, 0.0, 0.984375, 0.984375, 0.984375, 0.9765625, 0.0, 0.984375, 0.0, 0.0, 0.984375, 0.0, 0.3046875, 0.0, 0.984375, 0.0, 0.9921875, 0.984375, 0.984375, 0.03125, 0.625, 0.625, 0.0, 0.984375, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.984375, 0.09375, 0.0, 0.984375, 0.0, 0.0, 0.625, 0.9765625, 0.0, 0.984375, 0.0, 0.625, 0.9765625, 0.0, 0.984375, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.9765625, 0.0, 0.984375, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.3828125, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.984375, 0.984375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.625, 0.984375, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.625, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0078125, 0.984375, 0.0, 0.96875, 0.0, 0.625, 0.984375, 0.625, 0.15625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6328125, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.9921875, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.9765625, 0.0, 0.0, 0.984375, 0.9765625, 0.984375, 0.0, 0.9765625, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.625, 0.9921875, 0.984375, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6171875, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.9921875, 0.0, 0.984375, 0.9921875, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.984375, 0.0, 0.984375, 0.0, 0.984375, 0.0, 0.0, 0.984375, 0.0, 0.9921875, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.984375, 0.984375, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9765625, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.9921875, 0.625, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.984375, 0.625, 0.0, 0.0, 0.0, 0.0, 0.046875, 0.984375, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.984375, 0.625, 0.0, 0.0, 0.734375, 0.625, 0.2734375, 0.0, 0.625, 0.46875, 0.9921875, 0.9765625, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.984375, 0.0, 0.625, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.6171875]

 sparsity of   [0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.99609375, 0.0078125, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0078125, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.65625, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.98828125, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.64453125, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0078125, 0.0, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0078125, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0078125, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0078125, 0.99609375, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.72265625, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0078125, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0078125, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.99609375, 0.0078125, 0.99609375, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0078125, 0.0, 0.0, 0.0078125, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.0, 0.326171875, 0.99609375, 0.326171875, 0.99609375, 0.0, 0.99609375, 0.32421875, 0.99609375, 0.0, 0.326171875, 0.994140625, 0.326171875, 0.326171875, 0.99609375, 0.326171875, 0.99609375, 0.99609375, 0.0, 0.0, 0.998046875, 0.99609375, 0.326171875, 0.0, 0.99609375, 0.32421875, 0.326171875, 0.99609375, 0.326171875, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.326171875, 0.0, 0.99609375, 0.99609375, 0.326171875, 0.326171875, 0.0, 0.0, 0.0, 0.0, 0.994140625, 0.998046875, 0.99609375, 0.99609375, 0.0, 0.0, 0.326171875, 0.326171875, 0.0, 0.326171875, 0.0, 0.99609375, 0.998046875, 0.0, 0.998046875, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.326171875, 0.99609375, 0.326171875, 0.326171875, 0.326171875, 0.326171875, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.326171875, 0.99609375, 0.32421875, 0.326171875, 0.99609375, 0.326171875, 0.326171875, 0.0, 0.3125, 0.99609375, 0.3125, 0.326171875, 0.326171875, 0.326171875, 0.0, 0.326171875, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.32421875, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.326171875, 0.998046875, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.322265625, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.326171875]

 sparsity of   [0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.0, 0.9982638955116272, 0.9982638955116272, 0.0, 0.0, 0.0, 0.0, 0.9982638955116272, 0.0, 0.9982638955116272, 0.999131977558136, 0.9982638955116272, 0.0, 0.9982638955116272, 0.999131977558136, 0.9982638955116272, 0.0, 0.0, 0.9982638955116272, 0.0, 0.9982638955116272, 0.0, 0.0, 0.0, 0.999131977558136, 0.0, 0.0, 0.9982638955116272, 0.999131977558136, 0.9982638955116272, 0.0, 0.9982638955116272, 0.9982638955116272, 0.999131977558136, 0.0, 0.9982638955116272, 0.0, 0.9982638955116272, 0.9982638955116272, 0.0, 0.9982638955116272, 0.999131977558136, 0.9982638955116272, 0.0, 0.0, 0.9982638955116272, 0.999131977558136, 0.999131977558136, 0.9982638955116272, 0.9982638955116272, 0.999131977558136, 0.0, 0.9982638955116272, 0.999131977558136, 0.0, 0.0, 0.999131977558136, 0.0, 0.9982638955116272, 0.0, 0.9982638955116272, 0.999131977558136, 0.0, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.0, 0.999131977558136, 0.9982638955116272, 0.999131977558136, 0.9982638955116272, 0.9982638955116272, 0.0, 0.0, 0.0, 0.999131977558136, 0.9982638955116272, 0.9982638955116272, 0.999131977558136, 0.999131977558136, 0.0, 0.0, 0.0, 0.999131977558136, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.0, 0.999131977558136, 0.9982638955116272, 0.0, 0.0, 0.0, 0.9982638955116272, 0.999131977558136, 0.0, 0.9982638955116272, 0.9982638955116272, 0.0, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.999131977558136, 0.999131977558136, 0.9982638955116272, 0.0, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.9982638955116272, 0.999131977558136, 0.9982638955116272, 0.0, 0.0, 0.9982638955116272, 0.9982638955116272]

 sparsity of   [0.359375, 0.0, 0.625, 0.0, 0.0, 0.0078125, 0.0, 0.078125, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.625, 0.25, 0.6171875, 0.0, 0.0, 0.0, 0.0, 0.4453125, 0.5390625, 0.0, 0.0, 0.984375, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.984375, 0.625, 0.0, 0.984375, 0.0, 0.9765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6171875, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.046875, 0.0, 0.0, 0.625, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.984375, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.625, 0.984375, 0.0, 0.0, 0.0, 0.625, 0.0, 0.6015625, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.15625, 0.9765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.9921875, 0.0, 0.0, 0.0, 0.625, 0.984375, 0.40625, 0.9765625, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.5234375, 0.0, 0.0, 0.625, 0.9921875, 0.0, 0.984375, 0.984375, 0.9921875, 0.984375, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.2734375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.625, 0.625, 0.0, 0.625, 0.625, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.625, 0.0, 0.0, 0.0, 0.1875, 0.0, 0.0, 0.0, 0.6171875, 0.9921875, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1328125, 0.7265625, 0.984375, 0.9921875, 0.0, 0.0, 0.0, 0.3359375, 0.0, 0.625, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.9921875, 0.0, 0.0, 0.6171875, 0.984375, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.53125, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.6328125, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.6171875, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.296875, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.9765625, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.625, 0.0, 0.0, 0.625, 0.984375, 0.0, 0.625, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.625, 0.90625, 0.0, 0.0, 0.984375, 0.0, 0.53125, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.984375, 0.625, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.984375, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3359375, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.984375, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.296875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.984375, 0.625, 0.0, 0.0, 0.0, 0.984375, 0.4453125, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.625, 0.625, 0.0, 0.8671875, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0390625, 0.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625]

 sparsity of   [0.99609375, 0.99609375, 0.25, 0.0, 0.0, 0.0, 0.513671875, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.134765625, 0.0, 0.99609375, 0.0, 0.08203125, 0.064453125, 0.173828125, 0.99609375, 0.0, 0.125, 0.998046875, 0.82421875, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.146484375, 0.337890625, 0.0, 0.0, 0.044921875, 0.0, 0.99609375, 0.998046875, 0.005859375, 0.005859375, 0.06640625, 0.0, 0.99609375, 0.0, 0.03125, 0.0, 0.0, 0.0625, 0.0, 0.0, 0.400390625, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.03125, 0.08984375, 0.0, 0.0, 0.146484375, 0.015625, 0.125, 0.0, 0.072265625, 0.052734375, 0.0, 0.109375, 0.013671875, 0.0, 0.021484375, 0.0, 0.0546875, 0.0, 0.0, 0.0, 0.0, 0.10546875, 0.0, 0.99609375, 0.7890625, 0.0, 0.99609375, 0.126953125, 0.99609375, 0.140625, 0.0, 0.0, 0.126953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.146484375, 0.306640625, 0.0, 0.0, 0.0546875, 0.005859375, 0.0, 0.0, 0.0, 0.994140625, 0.083984375, 0.0, 0.0, 0.025390625, 0.99609375, 0.994140625, 0.0, 0.0, 0.99609375, 0.130859375, 0.0, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.0052083334885537624, 0.1770833283662796, 0.01215277798473835, 0.0355902798473835, 0.0703125, 0.0416666679084301, 0.0338541679084301, 0.0, 0.0, 0.0477430559694767, 0.0885416641831398, 0.9973958134651184, 0.0442708320915699, 0.02951388992369175, 0.0034722222480922937, 0.0, 0.0, 0.02170138992369175, 0.9626736044883728, 0.0, 0.8203125, 0.0243055559694767, 0.9982638955116272, 0.0642361119389534, 0.0512152798473835, 0.0, 0.0, 0.0251736119389534, 0.9973958134651184, 0.0, 0.118055559694767, 0.014756944961845875, 0.0407986119389534, 0.0381944440305233, 0.1145833358168602, 0.9982638955116272, 0.0, 0.02951388992369175, 0.0, 0.0486111119389534, 0.0815972238779068, 0.0225694440305233, 0.749131977558136, 0.0, 0.0321180559694767, 0.0, 0.0607638880610466, 0.02604166604578495, 0.0347222238779068, 0.0355902798473835, 0.7534722089767456, 0.0, 0.0069444444961845875, 0.0, 0.9418402910232544, 0.1319444477558136, 0.0416666679084301, 0.2734375, 0.0, 0.01215277798473835, 0.013020833022892475, 0.999131977558136, 0.0, 0.0520833320915699, 0.0564236119389534, 0.1050347238779068, 0.6640625, 0.0, 0.9973958134651184, 0.0850694477558136, 0.0086805559694767, 0.0980902761220932, 0.0078125, 0.3524305522441864, 0.0425347238779068, 0.010416666977107525, 0.0, 0.0, 0.0, 0.0017361111240461469, 0.02170138992369175, 0.0407986119389534, 0.0243055559694767, 0.9973958134651184, 0.0251736119389534, 0.8342013955116272, 0.0, 0.0355902798473835, 0.0, 0.8871527910232544, 0.0, 0.0, 0.0, 0.3203125, 0.0703125, 0.0, 0.0, 0.8932291865348816, 0.0442708320915699, 0.0, 0.0, 0.0486111119389534, 0.02864583395421505, 0.0381944440305233, 0.8611111044883728, 0.0, 0.0755208358168602, 0.02951388992369175, 0.046875, 0.0486111119389534, 0.0, 0.0, 0.013888888992369175, 0.0954861119389534, 0.0, 0.8142361044883728, 0.0, 0.0477430559694767, 0.0, 0.0, 0.9565972089767456, 0.0078125, 0.0355902798473835, 0.0034722222480922937]

 sparsity of   [0.0, 0.0, 0.03125, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.6796875, 0.0, 0.0, 0.6796875, 0.984375, 0.6171875, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.984375, 0.6796875, 0.0, 0.0, 0.6796875, 0.6796875, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.6796875, 0.0, 0.984375, 0.0, 0.0, 0.6796875, 0.0, 0.6796875, 0.6796875, 0.0, 0.1015625, 0.6796875, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.6796875, 0.6796875, 0.6796875, 0.0, 0.0, 0.6796875, 0.984375, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.5703125, 0.6796875, 0.0, 0.671875, 0.0, 0.0078125, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.046875, 0.6796875, 0.6796875, 0.6796875, 0.6796875, 0.6796875, 0.0, 0.0, 0.0, 0.6796875, 0.6796875, 0.6796875, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.6640625, 0.6796875, 0.6796875, 0.4296875, 0.6796875, 0.0, 0.0, 0.6796875, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.1015625, 0.984375, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.6796875, 0.6796875, 0.0, 0.0, 0.0, 0.6796875, 0.984375, 0.6796875, 0.0, 0.0, 0.0, 0.984375, 0.6796875, 0.0, 0.6796875, 0.0, 0.234375, 0.0, 0.5625, 0.0, 0.0, 0.6796875, 0.0, 0.984375, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.6796875, 0.0, 0.6796875, 0.0, 0.0, 0.6796875, 0.671875, 0.0, 0.0, 0.6796875, 0.6796875, 0.9921875, 0.0, 0.6796875, 0.6796875, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.6796875, 0.0, 0.6796875, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0390625, 0.0, 0.6796875, 0.6796875, 0.0, 0.6796875, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.765625, 0.9921875, 0.9765625, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.6796875, 0.0, 0.6796875, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.6796875, 0.0, 0.6796875, 0.6796875, 0.0, 0.0, 0.6796875, 0.6796875, 0.0, 0.0, 0.0, 0.578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.6796875, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.6796875, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.6796875, 0.6796875, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.6796875, 0.6796875, 0.0, 0.6796875, 0.6796875, 0.0, 0.0, 0.6796875, 0.0, 0.984375, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.640625, 0.9765625, 0.0, 0.6796875, 0.0, 0.0, 0.6796875, 0.984375, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.6796875, 0.671875, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.6796875, 0.6796875, 0.7734375, 0.671875, 0.6796875, 0.0, 0.0, 0.6796875, 0.984375, 0.0, 0.0625, 0.6796875, 0.0390625, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.9765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.28125, 0.6796875, 0.6796875, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.1953125, 0.6796875, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.671875, 0.0, 0.984375, 0.6796875, 0.0, 0.0, 0.0, 0.0390625, 0.984375, 0.0, 0.0, 0.6796875, 0.6796875, 0.6796875, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.765625, 0.6796875, 0.0, 0.0, 0.4140625, 0.0, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.0546875, 0.0, 0.0, 0.0, 0.0, 0.03125, 0.0, 0.0, 0.6796875, 0.0, 0.6796875]

 sparsity of   [0.12890625, 0.0, 0.0, 0.0, 0.04296875, 0.0, 0.06640625, 0.037109375, 0.1484375, 0.103515625, 0.0234375, 0.0, 0.9453125, 0.919921875, 0.0, 0.029296875, 0.0546875, 0.0, 0.044921875, 0.0, 0.03125, 0.0, 0.859375, 0.3125, 0.0, 0.0, 0.01953125, 0.0, 0.056640625, 0.0, 0.0078125, 0.0, 0.0, 0.046875, 0.03125, 0.033203125, 0.857421875, 0.0, 0.0, 0.0, 0.044921875, 0.890625, 0.060546875, 0.0, 0.984375, 0.0, 0.994140625, 0.0, 0.99609375, 0.99609375, 0.0, 0.017578125, 0.0, 0.0, 0.0, 0.0, 0.0234375, 0.0, 0.0, 0.263671875, 0.0, 0.03125, 0.0, 0.828125, 0.0, 0.16796875, 0.28125, 0.0, 0.0, 0.82421875, 0.99609375, 0.0, 0.99609375, 0.0078125, 0.19921875, 0.0, 0.0, 0.99609375, 0.0, 0.00390625, 0.97265625, 0.0, 0.0, 0.06640625, 0.0, 0.013671875, 0.0, 0.037109375, 0.0, 0.99609375, 0.158203125, 0.0, 0.0, 0.0390625, 0.12109375, 0.087890625, 0.0, 0.95703125, 0.046875, 0.068359375, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.8984375, 0.892578125, 0.99609375, 0.00390625, 0.10546875, 0.0, 0.12109375, 0.001953125, 0.072265625, 0.0078125, 0.0, 0.0, 0.048828125, 0.00390625, 0.0, 0.017578125, 0.0, 0.99609375, 0.056640625, 0.06640625, 0.05859375, 0.02734375, 0.0]

 sparsity of   [0.9973958134651184, 0.433159738779068, 0.2013888955116272, 0.0, 0.02083333395421505, 0.0972222238779068, 0.0677083358168602, 0.0425347238779068, 0.6145833134651184, 0.0164930559694767, 0.3029513955116272, 0.013888888992369175, 0.9982638955116272, 0.0, 0.1371527761220932, 0.9982638955116272, 0.1927083283662796, 0.0225694440305233, 0.2447916716337204, 0.9973958134651184, 0.02777777798473835, 0.0243055559694767, 0.0, 0.4157986044883728, 0.01909722201526165, 0.0963541641831398, 0.2239583283662796, 0.0, 0.0164930559694767, 0.6258680820465088, 0.999131977558136, 0.1128472238779068, 0.4296875, 0.0052083334885537624, 0.0, 0.9982638955116272, 0.3967013955116272, 0.9982638955116272, 0.9861111044883728, 0.0451388880610466, 0.9973958134651184, 0.102430559694767, 0.0, 0.0, 0.02170138992369175, 0.01215277798473835, 0.0581597238779068, 0.0, 0.9157986044883728, 0.4288194477558136, 0.5894097089767456, 0.0807291641831398, 0.9973958134651184, 0.0225694440305233, 0.8368055820465088, 0.7873263955116272, 0.0, 0.5017361044883728, 0.8723958134651184, 0.0355902798473835, 0.0338541679084301, 0.00434027798473835, 0.347222238779068, 0.0, 0.0, 0.9982638955116272, 0.071180559694767, 0.4001736044883728, 0.717881977558136, 0.1510416716337204, 0.0659722238779068, 0.0920138880610466, 0.0251736119389534, 0.0164930559694767, 0.4479166567325592, 0.9982638955116272, 0.0225694440305233, 0.0, 0.375, 0.0078125, 0.02777777798473835, 0.0303819440305233, 0.0, 0.9982638955116272, 0.0303819440305233, 0.0460069440305233, 0.0225694440305233, 0.0, 0.0234375, 0.0, 0.0, 0.0243055559694767, 0.0399305559694767, 0.0434027798473835, 0.0928819477558136, 0.0477430559694767, 0.0842013880610466, 0.0, 0.0251736119389534, 0.0, 0.3993055522441864, 0.02777777798473835, 0.9244791865348816, 0.90625, 0.015625, 0.0581597238779068, 0.0390625, 0.0078125, 0.013888888992369175, 0.999131977558136, 0.9982638955116272, 0.0, 0.02690972201526165, 0.4140625, 0.8411458134651184, 0.0, 0.3793402910232544, 0.0, 0.0, 0.09375, 0.1015625, 0.9661458134651184, 0.0677083358168602, 0.0347222238779068, 0.4340277910232544, 0.0355902798473835, 0.0, 0.0746527761220932]

 sparsity of   [0.0, 0.6796875, 0.7265625, 0.765625, 0.0, 0.0, 0.09375, 0.6171875, 0.3671875, 0.0, 0.0, 0.0, 0.6953125, 0.0, 0.7109375, 0.75, 0.0, 0.71875, 0.7265625, 0.0, 0.984375, 0.0, 0.7734375, 0.0, 0.703125, 0.7734375, 0.0, 0.0, 0.7265625, 0.0, 0.765625, 0.0, 0.71875, 0.7578125, 0.0, 0.625, 0.7734375, 0.65625, 0.7109375, 0.7265625, 0.0, 0.0, 0.7109375, 0.0, 0.0, 0.71875, 0.0, 0.71875, 0.7734375, 0.71875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.6953125, 0.984375, 0.71875, 0.703125, 0.7109375, 0.0, 0.7265625, 0.7421875, 0.71875, 0.9765625, 0.1484375, 0.7734375, 0.0, 0.765625, 0.7109375, 0.0, 0.578125, 0.7109375, 0.7421875, 0.0, 0.734375, 0.0, 0.6953125, 0.0, 0.703125, 0.1171875, 0.703125, 0.0, 0.703125, 0.6796875, 0.7109375, 0.0, 0.0, 0.6796875, 0.7109375, 0.0, 0.7109375, 0.0, 0.703125, 0.765625, 0.71875, 0.0, 0.0, 0.7734375, 0.5703125, 0.71875, 0.7109375, 0.7734375, 0.0, 0.703125, 0.0, 0.6640625, 0.0, 0.0, 0.7265625, 0.7265625, 0.0, 0.71875, 0.7265625, 0.0, 0.6875, 0.703125, 0.7109375, 0.734375, 0.734375, 0.0, 0.7265625, 0.0, 0.0, 0.734375, 0.6640625, 0.0, 0.0, 0.7421875, 0.0, 0.0, 0.7734375, 0.7734375, 0.6484375, 0.6953125, 0.7734375, 0.0, 0.703125, 0.7265625, 0.6796875, 0.0, 0.6953125, 0.71875, 0.0, 0.765625, 0.0, 0.0, 0.6953125, 0.0, 0.0, 0.7734375, 0.7734375, 0.609375, 0.0, 0.6796875, 0.703125, 0.0, 0.6953125, 0.0, 0.7109375, 0.6953125, 0.0, 0.703125, 0.0390625, 0.984375, 0.7109375, 0.6796875, 0.734375, 0.0, 0.7265625, 0.0, 0.0, 0.6875, 0.0, 0.7109375, 0.7265625, 0.0, 0.09375, 0.0, 0.7734375, 0.0, 0.0, 0.6796875, 0.0, 0.7734375, 0.7734375, 0.0, 0.75, 0.6953125, 0.7265625, 0.0, 0.75, 0.0, 0.6875, 0.6953125, 0.7734375, 0.0, 0.6953125, 0.0, 0.671875, 0.765625, 0.0, 0.6875, 0.0, 0.0, 0.7109375, 0.984375, 0.6875, 0.6796875, 0.71875, 0.0, 0.703125, 0.7109375, 0.0, 0.0, 0.6953125, 0.0, 0.0, 0.0, 0.6171875, 0.5, 0.9453125, 0.1171875, 0.6796875, 0.0, 0.0, 0.7734375, 0.0, 0.0, 0.7109375, 0.7578125, 0.03125, 0.7734375, 0.7109375, 0.0, 0.7421875, 0.7109375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7421875, 0.0, 0.640625, 0.0, 0.1953125, 0.0, 0.703125, 0.0, 0.0, 0.0, 0.6875, 0.0, 0.6796875, 0.0, 0.0, 0.0, 0.6796875, 0.7265625, 0.7734375, 0.6953125, 0.7578125, 0.7109375, 0.0, 0.0, 0.5546875, 0.0, 0.0, 0.0, 0.71875, 0.71875, 0.0, 0.6640625, 0.671875, 0.703125, 0.6796875, 0.734375, 0.6953125, 0.703125, 0.0, 0.0, 0.71875, 0.0, 0.0, 0.6953125, 0.71875, 0.7109375, 0.7109375, 0.7734375, 0.7734375, 0.703125, 0.71875, 0.7265625, 0.0, 0.140625, 0.6953125, 0.7734375, 0.7109375, 0.0, 0.71875, 0.625, 0.6796875, 0.0, 0.0, 0.703125, 0.7734375, 0.0, 0.6875, 0.765625, 0.0, 0.359375, 0.0, 0.7265625, 0.71875, 0.0234375, 0.734375, 0.7265625, 0.0, 0.0, 0.7265625, 0.7265625, 0.7109375, 0.0, 0.0, 0.0, 0.7734375, 0.09375, 0.75, 0.0, 0.0, 0.7578125, 0.71875, 0.0, 0.0, 0.7421875, 0.0, 0.6875, 0.0, 0.109375, 0.6953125, 0.703125, 0.6796875, 0.0, 0.71875, 0.703125, 0.0, 0.0, 0.71875, 0.7734375, 0.0, 0.0, 0.0, 0.6953125, 0.7109375, 0.0, 0.7734375, 0.984375, 0.6875, 0.7421875, 0.640625, 0.71875, 0.703125, 0.7734375, 0.0, 0.703125, 0.078125, 0.7265625, 0.0, 0.6484375, 0.7109375, 0.0, 0.640625, 0.0, 0.984375, 0.03125, 0.0, 0.7734375, 0.6953125, 0.71875, 0.0, 0.671875, 0.6953125, 0.0, 0.09375, 0.0, 0.7265625, 0.0, 0.0, 0.0, 0.0703125, 0.71875, 0.6953125, 0.6953125, 0.6953125, 0.0, 0.6875, 0.0, 0.0, 0.0, 0.7734375, 0.7734375, 0.7734375, 0.75, 0.7734375, 0.0, 0.71875, 0.671875, 0.0, 0.765625, 0.703125, 0.0, 0.0, 0.765625, 0.0, 0.71875, 0.71875, 0.0, 0.7265625, 0.0, 0.703125, 0.0, 0.7109375, 0.7109375, 0.7109375, 0.71875, 0.0, 0.0, 0.671875, 0.71875, 0.71875, 0.0, 0.0, 0.6875, 0.0, 0.15625, 0.703125, 0.0, 0.7421875, 0.0, 0.6953125, 0.0, 0.0, 0.7734375, 0.0, 0.0, 0.703125, 0.703125, 0.6953125, 0.7734375, 0.0, 0.0, 0.578125, 0.0, 0.0, 0.7109375, 0.7421875, 0.0, 0.0, 0.0, 0.71875, 0.6875, 0.71875, 0.0, 0.984375, 0.109375, 0.7734375, 0.0, 0.703125, 0.0, 0.71875, 0.0, 0.71875, 0.7734375, 0.984375, 0.6953125, 0.0, 0.0, 0.0, 0.453125, 0.71875, 0.703125, 0.0, 0.984375, 0.7109375, 0.6875, 0.0, 0.0, 0.734375, 0.109375, 0.0, 0.0, 0.7734375, 0.0, 0.7734375, 0.0, 0.1796875, 0.0, 0.0, 0.7734375, 0.71875, 0.703125, 0.765625, 0.0, 0.0, 0.6953125, 0.734375, 0.7109375, 0.0, 0.0, 0.71875, 0.7421875]

 sparsity of   [0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.998046875, 0.99609375, 0.99609375, 0.0, 0.0, 0.0234375, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0234375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.998046875, 0.0, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.998046875, 0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.0, 0.998046875, 0.998046875, 0.99609375, 0.0, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.99609375, 0.998046875, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.998046875, 0.0, 0.99609375, 0.998046875, 0.0234375, 0.998046875, 0.99609375, 0.99609375, 0.998046875, 0.99609375, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.99609375, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.994140625, 0.99609375, 0.998046875, 0.998046875, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.0, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.99609375, 0.998046875, 0.998046875, 0.998046875, 0.99609375, 0.0, 0.99609375, 0.0, 0.998046875, 0.99609375, 0.99609375, 0.998046875, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.998046875, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.0, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.998046875, 0.0, 0.99609375, 0.998046875, 0.0, 0.99609375, 0.0, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.99609375, 0.0, 0.998046875, 0.0, 0.99609375, 0.998046875, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.0234375, 0.99609375, 0.998046875, 0.0, 0.998046875, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.0, 0.99609375]

 sparsity of   [0.0, 0.999131977558136, 0.9986979365348816, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.2795138955116272, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.405815988779068, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.0, 0.0, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.9986979365348816, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.625, 0.999131977558136, 0.6219618320465088, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.9986979365348816, 0.0, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.9995659589767456, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.9986979365348816, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.625, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.0, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.625, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.1154513880610466, 0.999131977558136, 0.0, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.0, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.999131977558136, 0.4309895932674408, 0.999131977558136, 0.999131977558136, 0.0, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.9986979365348816, 0.999131977558136, 0.0, 0.9995659589767456, 0.625, 0.0, 0.999131977558136, 0.6219618320465088, 0.9995659589767456, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.0, 0.0, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.1050347238779068, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.625, 0.9995659589767456, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136]

 sparsity of   [0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.7734375, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.98828125, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.98046875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.7734375, 0.99609375, 0.9921875, 0.0, 0.7734375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.7734375, 0.0, 0.0, 0.9921875, 0.7734375, 0.0, 0.7734375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.98828125, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.7734375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.7734375, 0.9921875, 0.0, 0.0, 0.99609375, 0.99609375, 0.9921875, 0.7734375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.7734375, 0.9921875, 0.7734375, 0.7734375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.7734375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.7734375, 0.99609375, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.98828125, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.98046875, 0.99609375, 0.7734375, 0.98828125, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.7734375, 0.9921875, 0.0, 0.7734375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.98046875, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.3984375, 0.9921875, 0.0, 0.0, 0.99609375, 0.7734375, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.7734375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.98828125, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.7734375, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.7734375, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.7734375, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.7734375, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.7734375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.7734375, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.7734375, 0.0, 0.9921875, 0.9921875, 0.7734375, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.7734375, 0.9921875, 0.0, 0.7734375, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.7734375, 0.99609375, 0.0, 0.0, 0.99609375, 0.9921875, 0.74609375, 0.99609375, 0.98828125, 0.9921875, 0.98828125, 0.0, 0.9921875, 0.7734375, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.7734375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.984375, 0.0, 0.9921875, 0.7734375, 0.99609375, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.98046875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.7734375, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.078125, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.7734375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.0, 0.9921875, 0.7734375, 0.7734375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.7734375, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.7734375, 0.9921875, 0.9921875, 0.0, 0.7734375, 0.9921875, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.984375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.7734375, 0.97265625, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.984375, 0.0, 0.0, 0.9921875, 0.7734375, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.7734375, 0.9921875, 0.0, 0.0, 0.98046875, 0.99609375, 0.0, 0.0, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.7734375, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.7734375, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.98828125, 0.0, 0.0, 0.9921875, 0.7734375, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.16015625, 0.9921875, 0.0, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.98828125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.7734375, 0.0, 0.99609375, 0.0, 0.0, 0.7734375, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.98046875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.7734375, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.7734375, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.7734375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.7734375, 0.0, 0.0, 0.0, 0.0, 0.98828125, 0.0, 0.0, 0.7734375, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0, 0.43359375, 0.7734375, 0.9921875, 0.9921875, 0.7734375, 0.9921875, 0.99609375, 0.7734375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.7734375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.7734375, 0.0, 0.0, 0.9921875, 0.34765625, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.99609375, 0.44140625, 0.9921875, 0.234375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.98828125, 0.0, 0.9921875, 0.7734375, 0.9921875, 0.0, 0.0, 0.0, 0.7734375, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.7734375, 0.7734375, 0.98046875, 0.0, 0.0, 0.82421875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.7734375, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.98828125, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.7734375, 0.7734375, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.7734375, 0.9921875, 0.0, 0.0, 0.0, 0.41015625, 0.0]

 sparsity of   [0.0, 0.994140625, 0.99609375, 0.998046875, 0.109375, 0.181640625, 0.99609375, 0.0859375, 0.556640625, 0.0, 0.01171875, 0.994140625, 0.0, 0.4296875, 0.00390625, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.20703125, 0.99609375, 0.00390625, 0.99609375, 0.0, 0.06640625, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0234375, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.21875, 0.0, 0.0, 0.0234375, 0.99609375, 0.4375, 0.447265625, 0.0, 0.3828125, 0.994140625, 0.16796875, 0.529296875, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0078125, 0.99609375, 0.998046875, 0.0, 0.05859375, 0.99609375, 0.1328125, 0.099609375, 0.0, 0.197265625, 0.99609375, 0.0, 0.0, 0.0, 0.23046875, 0.998046875, 0.162109375, 0.0, 0.064453125, 0.1328125, 0.0, 0.0, 0.994140625, 0.99609375, 0.84375, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0234375, 0.14453125, 0.021484375, 0.0, 0.0, 0.99609375, 0.00390625, 0.0, 0.0, 0.0, 0.0390625, 0.0, 0.0, 0.0, 0.994140625, 0.0, 0.498046875, 0.99609375, 0.0, 0.0, 0.0703125, 0.99609375, 0.0, 0.0, 0.859375, 0.841796875, 0.015625, 0.99609375, 0.998046875, 0.060546875, 0.998046875, 0.99609375, 0.99609375, 0.013671875, 0.275390625, 0.0, 0.99609375, 0.0, 0.994140625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.158203125, 0.88671875, 0.01953125, 0.0, 0.037109375, 0.998046875, 0.4921875, 0.16796875, 0.0, 0.0234375, 0.33203125, 0.0, 0.0, 0.998046875, 0.998046875, 0.05859375, 0.0, 0.99609375, 0.294921875, 0.99609375, 0.99609375, 0.0078125, 0.9921875, 0.99609375, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.1953125, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.998046875, 0.99609375, 0.001953125, 0.0, 0.0, 0.43359375, 0.0, 0.0, 0.005859375, 0.787109375, 0.0, 0.0, 0.0, 0.0, 0.20703125, 0.08984375, 0.0, 0.998046875, 0.99609375, 0.4296875, 0.119140625, 0.021484375, 0.99609375, 0.994140625, 0.119140625, 0.0, 0.99609375, 0.99609375, 0.0390625, 0.439453125, 0.1953125, 0.076171875, 0.0, 0.99609375, 0.056640625, 0.0, 0.0, 0.009765625, 0.99609375, 0.4140625, 0.060546875, 0.00390625, 0.052734375, 0.0703125, 0.140625, 0.0, 0.0, 0.0, 0.0234375, 0.3515625, 0.0, 0.00390625, 0.17578125, 0.99609375, 0.998046875, 0.8046875, 0.0, 0.0546875, 0.0, 0.998046875, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.998046875, 0.99609375, 0.0859375, 0.0, 0.99609375, 0.0, 0.0, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3125, 0.998046875, 0.197265625, 0.048828125, 0.146484375, 0.994140625, 0.998046875, 0.224609375, 0.0, 0.0, 0.0, 0.0, 0.376953125, 0.99609375, 0.0, 0.0, 0.296875, 0.015625, 0.0390625, 0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.064453125, 0.0, 0.125, 0.0, 0.087890625, 0.99609375, 0.0, 0.99609375, 0.0, 0.35546875, 0.0, 0.99609375, 0.0, 0.99609375, 0.041015625, 0.04296875, 0.01953125, 0.99609375, 0.0, 0.99609375, 0.005859375, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.814453125, 0.6796875, 0.279296875, 0.99609375, 0.99609375, 0.994140625, 0.048828125, 0.998046875, 0.0, 0.216796875, 0.0234375, 0.0, 0.99609375, 0.060546875, 0.99609375, 0.998046875, 0.0, 0.0, 0.19921875, 0.169921875, 0.0, 0.0, 0.0, 0.005859375, 0.19921875, 0.015625, 0.884765625, 0.0, 0.998046875, 0.083984375, 0.99609375, 0.0, 0.05078125, 0.99609375, 0.99609375, 0.998046875, 0.00390625, 0.994140625, 0.02734375, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.021484375, 0.0, 0.998046875, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.0, 0.0, 0.021484375, 0.99609375, 0.0, 0.05078125, 0.0, 0.99609375, 0.1171875, 0.0, 0.99609375, 0.99609375, 0.0, 0.994140625, 0.0, 0.0, 0.0, 0.857421875, 0.99609375, 0.998046875, 0.0, 0.998046875, 0.10546875, 0.45703125, 0.99609375, 0.0, 0.99609375, 0.06640625, 0.0, 0.0, 0.998046875, 0.998046875, 0.0234375, 0.0, 0.337890625, 0.310546875, 0.00390625, 0.0, 0.20703125, 0.0, 0.09375, 0.181640625, 0.0, 0.111328125, 0.017578125, 0.19140625, 0.0, 0.0, 0.181640625, 0.0, 0.119140625, 0.0, 0.998046875, 0.998046875, 0.0, 0.19140625, 0.0, 0.0, 0.89453125, 0.99609375, 0.0, 0.998046875, 0.5390625, 0.193359375, 0.21875, 0.0, 0.99609375, 0.0, 0.0, 0.28515625, 0.99609375, 0.0, 0.994140625, 0.0, 0.0, 0.021484375, 0.99609375, 0.994140625, 0.78515625, 0.333984375, 0.0, 0.99609375, 0.0, 0.548828125, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.013671875, 0.0, 0.2109375, 0.99609375, 0.115234375, 0.998046875, 0.99609375, 0.224609375, 0.0, 0.998046875, 0.015625, 0.99609375, 0.0, 0.0, 0.001953125, 0.0, 0.013671875, 0.482421875, 0.0, 0.998046875, 0.4375, 0.0, 0.15625, 0.138671875, 0.07421875, 0.99609375, 0.0, 0.796875, 0.0, 0.0, 0.998046875, 0.0, 0.30078125, 0.078125, 0.017578125, 0.009765625, 0.0, 0.142578125, 0.0, 0.0, 0.99609375, 0.00390625, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.0, 0.064453125, 0.99609375, 0.3671875, 0.0, 0.0, 0.0, 0.1484375, 0.998046875, 0.99609375, 0.00390625, 0.046875, 0.0, 0.01171875, 0.0, 0.0, 0.43359375, 0.99609375, 0.099609375, 0.0, 0.0078125, 0.0, 0.99609375, 0.90625, 0.0, 0.0, 0.224609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.087890625, 0.998046875, 0.0, 0.01171875, 0.99609375, 0.99609375, 0.99609375, 0.8359375, 0.998046875, 0.0, 0.998046875, 0.021484375, 0.0, 0.05078125, 0.134765625, 0.09765625, 0.99609375, 0.0, 0.0, 0.0, 0.998046875, 0.0, 0.125, 0.01953125, 0.99609375, 0.998046875, 0.0, 0.0, 0.0, 0.107421875, 0.99609375, 0.060546875, 0.994140625, 0.763671875, 0.99609375, 0.0, 0.998046875, 0.01953125, 0.001953125, 0.0078125, 0.541015625, 0.0, 0.578125, 0.0, 0.0, 0.998046875, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.994140625, 0.99609375, 0.61328125, 0.0, 0.0, 0.26171875, 0.998046875, 0.0, 0.99609375, 0.0234375, 0.0390625, 0.998046875, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39453125, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.994140625, 0.0, 0.99609375, 0.095703125, 0.0, 0.99609375, 0.0234375, 0.0, 0.0, 0.0, 0.99609375, 0.044921875, 0.0, 0.115234375, 0.279296875, 0.998046875, 0.8984375, 0.0, 0.0, 0.0, 0.0, 0.0234375, 0.99609375, 0.0, 0.169921875, 0.998046875, 0.0078125, 0.998046875, 0.0, 0.0, 0.998046875, 0.734375, 0.0, 0.0, 0.0, 0.201171875, 0.998046875, 0.0, 0.009765625, 0.048828125, 0.99609375, 0.99609375, 0.998046875, 0.994140625, 0.0, 0.0, 0.05078125, 0.0, 0.123046875, 0.998046875, 0.0, 0.994140625, 0.0, 0.021484375, 0.0, 0.0, 0.99609375, 0.994140625, 0.0, 0.0234375, 0.0, 0.091796875, 0.0, 0.0, 0.021484375, 0.0, 0.0, 0.998046875, 0.005859375, 0.0, 0.994140625, 0.0, 0.0, 0.0, 0.994140625, 0.03125, 0.0, 0.0, 0.0, 0.03125, 0.99609375, 0.2109375, 0.99609375, 0.0, 0.09375, 0.0, 0.080078125, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.076171875, 0.865234375, 0.0, 0.0, 0.998046875, 0.205078125, 0.5078125, 0.0, 0.0, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.806640625, 0.0, 0.99609375, 0.0, 0.22265625, 0.0, 0.0, 0.03125, 0.13671875, 0.0, 0.0, 0.130859375, 0.0, 0.0, 0.0, 0.99609375, 0.01953125, 0.005859375, 0.0234375, 0.0, 0.0, 0.287109375, 0.998046875, 0.99609375, 0.99609375, 0.998046875, 0.01953125, 0.0, 0.02734375, 0.0, 0.0, 0.0078125, 0.99609375, 0.09375, 0.19140625, 0.494140625, 0.0, 0.0, 0.17578125, 0.03515625, 0.0, 0.998046875, 0.0, 0.0, 0.0, 0.99609375, 0.013671875, 0.0, 0.0, 0.033203125, 0.056640625, 0.99609375, 0.1484375, 0.296875, 0.046875, 0.99609375, 0.0, 0.0, 0.025390625, 0.0, 0.912109375, 0.0, 0.056640625, 0.05078125, 0.216796875, 0.0, 0.0, 0.0, 0.048828125, 0.294921875, 0.0, 0.0, 0.0, 0.998046875, 0.150390625, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.404296875, 0.0, 0.0, 0.99609375, 0.99609375, 0.998046875, 0.99609375, 0.0, 0.005859375, 0.0, 0.0, 0.09375, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0703125, 0.99609375, 0.99609375, 0.044921875, 0.0, 0.0, 0.99609375, 0.068359375, 0.994140625, 0.28125, 0.99609375, 0.0078125, 0.20703125, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.0, 0.037109375, 0.0, 0.0, 0.0234375, 0.0, 0.08203125, 0.080078125, 0.0, 0.0, 0.03125, 0.12109375, 0.0, 0.0, 0.994140625, 0.87890625, 0.0546875, 0.0, 0.0, 0.142578125, 0.0, 0.9921875, 0.998046875, 0.001953125, 0.05078125, 0.99609375, 0.0, 0.99609375, 0.99609375, 0.208984375, 0.208984375, 0.99609375, 0.0, 0.0, 0.0, 0.99609375, 0.033203125, 0.05859375, 0.060546875, 0.0, 0.0, 0.0, 0.99609375, 0.091796875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28125, 0.0, 0.080078125, 0.076171875, 0.234375, 0.0, 0.998046875, 0.0, 0.99609375, 0.001953125, 0.0, 0.0, 0.005859375, 0.99609375, 0.11328125, 0.0078125, 0.0, 0.0, 0.998046875, 0.99609375, 0.0, 0.267578125, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.998046875, 0.0, 0.99609375, 0.0, 0.10546875, 0.060546875, 0.0, 0.083984375, 0.99609375, 0.99609375, 0.994140625, 0.259765625, 0.0, 0.998046875, 0.0, 0.228515625, 0.0, 0.115234375, 0.09375, 0.0, 0.0, 0.99609375, 0.541015625, 0.99609375, 0.99609375, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.359375, 0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.001953125, 0.01171875, 0.0, 0.0, 0.994140625, 0.99609375, 0.064453125, 0.0, 0.021484375, 0.99609375, 0.0, 0.0, 0.576171875, 0.005859375, 0.0, 0.0, 0.998046875, 0.0, 0.109375, 0.99609375, 0.99609375, 0.0, 0.125, 0.025390625, 0.0, 0.8359375, 0.0, 0.0, 0.998046875, 0.0, 0.48046875, 0.0, 0.0, 0.0546875, 0.0, 0.998046875, 0.234375, 0.01171875, 0.99609375, 0.99609375, 0.0078125, 0.0, 0.998046875, 0.177734375, 0.078125, 0.0, 0.0, 0.0, 0.99609375, 0.06640625, 0.99609375, 0.0, 0.1875, 0.359375, 0.0, 0.173828125, 0.99609375, 0.0, 0.0, 0.20703125, 0.998046875, 0.087890625, 0.0, 0.994140625, 0.0, 0.0, 0.0, 0.49609375, 0.0]

 sparsity of   [0.1240234375, 0.998046875, 0.5009765625, 0.998046875, 0.044921875, 0.134765625, 0.224609375, 0.998046875, 0.9970703125, 0.0, 0.501953125, 0.2880859375, 0.998046875, 0.998046875, 0.01953125, 0.99609375, 0.0849609375, 0.0, 0.0, 0.501953125, 0.03125, 0.484375, 0.1044921875, 0.998046875, 0.4365234375, 0.0, 0.0, 0.0, 0.4814453125, 0.0302734375, 0.4814453125, 0.0791015625, 0.13671875, 0.9384765625, 0.0, 0.0751953125, 0.5009765625, 0.0673828125, 0.0, 0.2041015625, 0.3994140625, 0.0, 0.0, 0.9990234375, 0.0, 0.0, 0.029296875, 0.0830078125, 0.435546875, 0.0458984375, 0.4697265625, 0.138671875, 0.0, 0.998046875, 0.81640625, 0.041015625, 0.0654296875, 0.501953125, 0.4873046875, 0.4794921875, 0.0, 0.998046875, 0.0, 0.20703125, 0.0, 0.0, 0.998046875, 0.501953125, 0.9990234375, 0.23046875, 0.0625, 0.0, 0.0361328125, 0.998046875, 0.0380859375, 0.4912109375, 0.0, 0.0, 0.0, 0.125, 0.5009765625, 0.4814453125, 0.0263671875, 0.2255859375, 0.501953125, 0.501953125, 0.501953125, 0.501953125, 0.0, 0.998046875, 0.044921875, 0.501953125, 0.4912109375, 0.998046875, 0.484375, 0.423828125, 0.0, 0.19921875, 0.998046875, 0.501953125, 0.0, 0.501953125, 0.1142578125, 0.501953125, 0.998046875, 0.0185546875, 0.501953125, 0.107421875, 0.998046875, 0.0, 0.5009765625, 0.4736328125, 0.474609375, 0.05859375, 0.056640625, 0.4208984375, 0.1669921875, 0.501953125, 0.0419921875, 0.0, 0.998046875, 0.833984375, 0.0546875, 0.998046875, 0.099609375, 0.0, 0.1044921875, 0.3486328125, 0.0, 0.046875, 0.072265625, 0.0791015625, 0.46875, 0.4794921875, 0.0625, 0.2138671875, 0.8408203125, 0.0, 0.494140625, 0.9970703125, 0.0908203125, 0.0, 0.4267578125, 0.0419921875, 0.998046875, 0.9990234375, 0.2783203125, 0.0, 0.0830078125, 0.0361328125, 0.03125, 0.5009765625, 0.451171875, 0.76953125, 0.451171875, 0.8447265625, 0.0, 0.4794921875, 0.0869140625, 0.0, 0.482421875, 0.0, 0.1142578125, 0.1533203125, 0.0400390625, 0.10546875, 0.0283203125, 0.0283203125, 0.4833984375, 0.0, 0.998046875, 0.0, 0.5009765625, 0.5009765625, 0.0, 0.037109375, 0.5009765625, 0.0439453125, 0.1083984375, 0.998046875, 0.5009765625, 0.0869140625, 0.9970703125, 0.5009765625, 0.0, 0.0, 0.0, 0.412109375, 0.0, 0.0908203125, 0.0, 0.0673828125, 0.0, 0.1923828125, 0.205078125, 0.619140625, 0.0, 0.998046875, 0.1015625, 0.998046875, 0.138671875, 0.998046875, 0.9990234375, 0.046875, 0.501953125, 0.357421875, 0.0, 0.48828125, 0.0, 0.998046875, 0.501953125, 0.9111328125, 0.4736328125, 0.2626953125, 0.0, 0.998046875, 0.1982421875, 0.0, 0.05859375, 0.48046875, 0.3994140625, 0.0, 0.0, 0.0556640625, 0.4443359375, 0.501953125, 0.4794921875, 0.5009765625, 0.501953125, 0.4833984375, 0.0, 0.0, 0.0595703125, 0.0, 0.0, 0.9990234375, 0.998046875, 0.2626953125, 0.0, 0.46875, 0.4853515625, 0.0458984375, 0.115234375, 0.0, 0.4892578125, 0.48046875, 0.0478515625, 0.5009765625, 0.12890625, 0.337890625, 0.501953125, 0.2021484375, 0.5009765625, 0.1142578125, 0.998046875, 0.892578125]

 sparsity of   [0.0, 0.999131977558136, 0.5494791865348816, 0.0, 0.999131977558136, 0.999131977558136, 0.0, 0.9986979365348816, 0.999131977558136, 0.3168402910232544, 0.999131977558136, 0.9986979365348816, 0.0, 0.339409738779068, 0.999131977558136, 0.1223958358168602, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.08984375, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.3285590410232544, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.4952256977558136, 0.9995659589767456, 0.0, 0.999131977558136, 0.1245659738779068, 0.0, 0.0, 0.999131977558136, 0.0, 0.9995659589767456, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.0, 0.999131977558136, 0.9986979365348816, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.3402777910232544, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9986979365348816, 0.9995659589767456, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.0, 0.0, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.0, 0.9986979365348816, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.0, 0.9995659589767456, 0.999131977558136, 0.0, 0.0, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.0, 0.9995659589767456, 0.0, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9986979365348816, 0.999131977558136, 0.9986979365348816, 0.999131977558136, 0.4314236044883728, 0.3177083432674408, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.2200520783662796, 0.0, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.9986979365348816, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.234375, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.0, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.0, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.1723090261220932, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.0, 0.0, 0.0, 0.0915798619389534, 0.0, 0.0, 0.999131977558136, 0.0, 0.9995659589767456, 0.0, 0.999131977558136, 0.999131977558136, 0.0, 0.0, 0.0, 0.9986979365348816, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9986979365348816, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.9986979365348816, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.3389756977558136, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.9986979365348816, 0.9986979365348816, 0.999131977558136, 0.0, 0.0, 0.0, 0.1328125, 0.999131977558136, 0.9995659589767456, 0.9995659589767456, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.9995659589767456, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.999131977558136, 0.0, 0.999131977558136, 0.0, 0.9995659589767456]

 sparsity of   [0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.0, 0.98828125, 0.9921875, 0.0, 0.99609375, 0.79296875, 0.0, 0.0, 0.79296875, 0.79296875, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.79296875, 0.79296875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.79296875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.79296875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.79296875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.79296875, 0.9921875, 0.79296875, 0.0, 0.0, 0.79296875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.0, 0.79296875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.79296875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.79296875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.79296875, 0.79296875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.79296875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.79296875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.79296875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.7890625, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.79296875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.79296875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.79296875, 0.9921875, 0.0, 0.9921875, 0.79296875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.79296875, 0.9921875, 0.0, 0.9921875, 0.0, 0.99609375, 0.79296875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.79296875, 0.9921875, 0.0, 0.0, 0.79296875, 0.0, 0.0, 0.0, 0.79296875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.98828125, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.79296875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.9921875, 0.79296875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.0, 0.79296875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.79296875, 0.0, 0.79296875, 0.9921875, 0.99609375, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.99609375, 0.79296875, 0.0, 0.0, 0.79296875, 0.0, 0.0, 0.9921875, 0.0, 0.79296875, 0.9921875, 0.0, 0.9921875, 0.79296875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.79296875, 0.9921875, 0.9921875, 0.79296875, 0.9921875, 0.0, 0.0, 0.99609375, 0.9921875, 0.79296875, 0.9921875, 0.0, 0.0, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.79296875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.98828125, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.79296875, 0.0, 0.79296875, 0.79296875, 0.79296875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.79296875, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.79296875, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.79296875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.0, 0.79296875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.79296875, 0.9921875, 0.99609375, 0.0, 0.79296875, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.99609375, 0.79296875, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.79296875, 0.0, 0.79296875, 0.79296875, 0.0, 0.9921875, 0.0, 0.79296875, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.79296875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.98828125, 0.79296875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.79296875, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.79296875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.79296875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.79296875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.79296875, 0.9921875, 0.79296875, 0.9921875, 0.79296875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.79296875, 0.79296875, 0.0, 0.0, 0.79296875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.79296875, 0.0, 0.92578125, 0.0, 0.79296875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.79296875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.0, 0.79296875, 0.0, 0.0, 0.79296875, 0.9921875, 0.9921875, 0.79296875, 0.79296875, 0.0, 0.0, 0.9921875, 0.0, 0.98828125, 0.79296875, 0.9921875, 0.9921875, 0.0, 0.0, 0.79296875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.79296875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.99609375, 0.0, 0.9921875, 0.99609375, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.79296875, 0.0, 0.9921875, 0.79296875, 0.79296875, 0.0, 0.99609375, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.97265625, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.79296875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.0, 0.9921875, 0.79296875, 0.9921875, 0.0, 0.79296875, 0.9921875, 0.79296875, 0.0, 0.9921875, 0.79296875, 0.9921875, 0.9921875, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.79296875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.79296875, 0.0, 0.99609375, 0.0, 0.79296875, 0.0, 0.0, 0.9921875, 0.99609375, 0.79296875, 0.99609375, 0.9921875, 0.79296875, 0.0, 0.9921875, 0.79296875, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.79296875, 0.99609375, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.79296875, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.79296875, 0.9921875, 0.0, 0.0, 0.0, 0.99609375, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.0869140625, 0.0, 0.0, 0.0, 0.3134765625, 0.4091796875, 0.0, 0.998046875, 0.0, 0.998046875, 0.9990234375, 0.9970703125, 0.998046875, 0.0, 0.998046875, 0.998046875, 0.0, 0.0, 0.998046875, 0.0, 0.0, 0.0, 0.998046875, 0.0, 0.9990234375, 0.0, 0.1025390625, 0.998046875, 0.0, 0.087890625, 0.0, 0.42578125, 0.0, 0.0, 0.998046875, 0.0, 0.0, 0.0, 0.4091796875, 0.0263671875, 0.0, 0.0, 0.998046875, 0.099609375, 0.0, 0.998046875, 0.0, 0.9990234375, 0.0, 0.185546875, 0.0, 0.048828125, 0.9990234375, 0.998046875, 0.0, 0.046875, 0.9970703125, 0.998046875, 0.0, 0.0, 0.9970703125, 0.9990234375, 0.0, 0.0, 0.0, 0.0986328125, 0.8486328125, 0.998046875, 0.22265625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.408203125, 0.0, 0.998046875, 0.9990234375, 0.9970703125, 0.99609375, 0.0, 0.9970703125, 0.998046875, 0.0, 0.9990234375, 0.998046875, 0.8662109375, 0.1748046875, 0.9970703125, 0.048828125, 0.998046875, 0.0, 0.0, 0.0, 0.998046875, 0.998046875, 0.4091796875, 0.0, 0.1337890625, 0.0, 0.0, 0.0751953125, 0.0, 0.4482421875, 0.998046875, 0.0, 0.0, 0.9990234375, 0.0, 0.171875, 0.0478515625, 0.0, 0.0, 0.998046875, 0.9990234375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.0, 0.02734375, 0.9990234375, 0.0, 0.0, 0.998046875, 0.3798828125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1904296875, 0.0, 0.998046875, 0.6962890625, 0.0, 0.0, 0.0, 0.0, 0.9990234375, 0.0, 0.0, 0.0, 0.0537109375, 0.998046875, 0.0830078125, 0.998046875, 0.9990234375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0234375, 0.998046875, 0.9990234375, 0.0, 0.9990234375, 0.0, 0.099609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.0, 0.9970703125, 0.0, 0.0, 0.0, 0.9990234375, 0.0, 0.0, 0.0, 0.0, 0.068359375, 0.0, 0.0, 0.0, 0.998046875, 0.998046875, 0.0, 0.052734375, 0.0, 0.228515625, 0.150390625, 0.0, 0.0, 0.998046875, 0.998046875, 0.0, 0.1875, 0.998046875, 0.0, 0.0, 0.3701171875, 0.0, 0.0, 0.0, 0.0, 0.0673828125, 0.9990234375, 0.361328125, 0.9990234375, 0.263671875, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9990234375, 0.0, 0.0, 0.998046875, 0.1416015625, 0.8876953125, 0.9990234375, 0.0, 0.998046875, 0.0, 0.0, 0.0, 0.9990234375, 0.0, 0.0, 0.0, 0.9990234375, 0.0, 0.998046875]

 sparsity of   [0.292534738779068, 0.0, 0.01605902798473835, 0.0885416641831398, 0.0, 0.02777777798473835, 0.0, 0.0, 0.70703125, 0.0, 0.0, 0.03081597201526165, 0.0, 0.9214409589767456, 0.1154513880610466, 0.0, 0.0, 0.2395833283662796, 0.4704861044883728, 0.0, 0.02213541604578495, 0.0, 0.0338541679084301, 0.02604166604578495, 0.01909722201526165, 0.0, 0.0355902798473835, 0.0, 0.1206597238779068, 0.0, 0.0998263880610466, 0.0, 0.999131977558136, 0.0, 0.0668402761220932, 0.0, 0.0, 0.0164930559694767, 0.0234375, 0.02951388992369175, 0.0212673619389534, 0.0455729179084301, 0.1410590261220932, 0.0, 0.6219618320465088, 0.0, 0.01822916604578495, 0.01605902798473835, 0.0, 0.0186631940305233, 0.0434027798473835, 0.8480902910232544, 0.0590277798473835, 0.02083333395421505, 0.9995659589767456, 0.0, 0.0, 0.0, 0.01779513992369175, 0.9986979365348816, 0.0, 0.0, 0.02560763992369175, 0.01909722201526165, 0.9709201455116272, 0.02604166604578495, 0.0, 0.01605902798473835, 0.0, 0.9995659589767456, 0.0, 0.1961805522441864, 0.01128472201526165, 0.0, 0.0, 0.0251736119389534, 0.02300347201526165, 0.1119791641831398, 0.0329861119389534, 0.0, 0.0, 0.0460069440305233, 0.0629340261220932, 0.0, 0.0, 0.0, 0.0, 0.02994791604578495, 0.0716145858168602, 0.02387152798473835, 0.9696180820465088, 0.0, 0.0065104165114462376, 0.0034722222480922937, 0.0, 0.0438368059694767, 0.0, 0.03081597201526165, 0.0, 0.0, 0.0, 0.0, 0.999131977558136, 0.0164930559694767, 0.01128472201526165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6480034589767456, 0.02690972201526165, 0.0, 0.0173611119389534, 0.0390625, 0.01692708395421505, 0.8402777910232544, 0.0486111119389534, 0.0, 0.0, 0.02951388992369175, 0.0733506977558136, 0.0690104141831398, 0.05859375, 0.0434027798473835, 0.01996527798473835, 0.01128472201526165, 0.1124131977558136, 0.0065104165114462376, 0.0, 0.0381944440305233, 0.010850694961845875, 0.8684895634651184, 0.02387152798473835, 0.0086805559694767, 0.02170138992369175, 0.1566840261220932, 0.006076388992369175, 0.13671875, 0.0516493059694767, 0.0, 0.0243055559694767, 0.0, 0.0, 0.009114583022892475, 0.0, 0.0251736119389534, 0.870225727558136, 0.0499131940305233, 0.0, 0.0, 0.0, 0.0394965298473835, 0.0, 0.0078125, 0.0, 0.02560763992369175, 0.02994791604578495, 0.0, 0.0, 0.7430555820465088, 0.0, 0.0, 0.0, 0.0338541679084301, 0.0, 0.02994791604578495, 0.8315972089767456, 0.02690972201526165, 0.9626736044883728, 0.1545138955116272, 0.02300347201526165, 0.0616319440305233, 0.999131977558136, 0.02300347201526165, 0.0, 0.01822916604578495, 0.0, 0.1427951455116272, 0.5529513955116272, 0.0, 0.9396701455116272, 0.0, 0.0, 0.9995659589767456, 0.01171875, 0.0772569477558136, 0.0, 0.07421875, 0.0772569477558136, 0.0564236119389534, 0.0, 0.2239583283662796, 0.0, 0.1488715261220932, 0.0, 0.0, 0.0, 0.9262152910232544, 0.8120659589767456, 0.1284722238779068, 0.9375, 0.9396701455116272, 0.0928819477558136, 0.02083333395421505, 0.1909722238779068, 0.1280381977558136, 0.0377604179084301, 0.0, 0.1801215261220932, 0.0, 0.082899309694767, 0.0282118059694767, 0.0590277798473835, 0.0, 0.0512152798473835, 0.999131977558136, 0.0, 0.009982638992369175, 0.01822916604578495, 0.0, 0.0, 0.0, 0.0, 0.999131977558136, 0.0, 0.0598958320915699, 0.2096354216337204, 0.02690972201526165, 0.0447048619389534, 0.0, 0.0, 0.83984375, 0.009114583022892475, 0.0941840261220932, 0.0, 0.010416666977107525, 0.01605902798473835, 0.02734375, 0.0659722238779068, 0.013454861007630825, 0.0, 0.0, 0.0086805559694767, 0.0, 0.02083333395421505, 0.999131977558136, 0.0, 0.02777777798473835, 0.125, 0.0, 0.1497395783662796, 0.009548611007630825, 0.0, 0.0651041641831398]

 sparsity of   [0.0, 0.62109375, 0.58203125, 0.37890625, 0.046875, 0.99609375, 0.0, 0.98828125, 0.66796875, 0.0, 0.99609375, 0.70703125, 0.62109375, 0.75390625, 0.62109375, 0.62109375, 0.0, 0.0, 0.62109375, 0.0, 0.98828125, 0.08203125, 0.0, 0.9921875, 0.0, 0.98828125, 0.9921875, 0.0, 0.0, 0.41796875, 0.0, 0.0, 0.9921875, 0.9921875, 0.0, 0.0, 0.09765625, 0.0, 0.9921875, 0.05078125, 0.0, 0.6171875, 0.49609375, 0.62109375, 0.62109375, 0.0, 0.03515625, 0.0, 0.62109375, 0.99609375, 0.31640625, 0.0, 0.6171875, 0.0, 0.0, 0.62109375, 0.078125, 0.0, 0.62109375, 0.0, 0.62109375, 0.0, 0.45703125, 0.07421875, 0.0, 0.1796875, 0.11328125, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.55078125, 0.98046875, 0.03125, 0.0, 0.0, 0.60546875, 0.62109375, 0.1484375, 0.58203125, 0.99609375, 0.14453125, 0.0, 0.24609375, 0.0, 0.0, 0.0, 0.203125, 0.0, 0.60546875, 0.9921875, 0.0, 0.0, 0.9921875, 0.9921875, 0.2109375, 0.04296875, 0.0, 0.58984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.828125, 0.7734375, 0.0, 0.0, 0.9609375, 0.09765625, 0.0, 0.0, 0.9921875, 0.58203125, 0.03125, 0.98828125, 0.0, 0.9921875, 0.9921875, 0.78125, 0.0546875, 0.62109375, 0.61328125, 0.0, 0.6015625, 0.0, 0.62109375, 0.0, 0.0, 0.0, 0.0, 0.62109375, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.0, 0.11328125, 0.0546875, 0.625, 0.0, 0.0, 0.0, 0.99609375, 0.59765625, 0.6171875, 0.6171875, 0.98828125, 0.0, 0.41796875, 0.8984375, 0.62109375, 0.609375, 0.0, 0.0, 0.61328125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.62109375, 0.2109375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.3828125, 0.0, 0.0, 0.0, 0.0625, 0.796875, 0.0, 0.08203125, 0.61328125, 0.0, 0.0, 0.62109375, 0.0, 0.0, 0.99609375, 0.375, 0.0, 0.99609375, 0.296875, 0.0, 0.1171875, 0.9921875, 0.65234375, 0.0, 0.98828125, 0.0, 0.9921875, 0.0859375, 0.62109375, 0.9921875, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.62109375, 0.14453125, 0.7265625, 0.03125, 0.77734375, 0.8515625, 0.07421875, 0.62109375, 0.0, 0.0, 0.0, 0.60546875, 0.203125, 0.02734375, 0.9921875, 0.99609375, 0.06640625, 0.17578125, 0.6171875, 0.0, 0.53515625, 0.62109375, 0.6171875, 0.0, 0.0, 0.52734375, 0.10546875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.0546875, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0390625, 0.07421875, 0.02734375, 0.9921875, 0.53515625, 0.08203125, 0.0546875, 0.61328125, 0.62109375, 0.0, 0.3359375, 0.0, 0.73828125, 0.99609375, 0.0, 0.0, 0.11328125, 0.99609375, 0.5625, 0.0, 0.9921875, 0.0, 0.13671875, 0.03515625, 0.99609375, 0.0, 0.0, 0.12109375, 0.9921875, 0.05859375, 0.0, 0.921875, 0.0, 0.55078125, 0.62109375, 0.57421875, 0.0, 0.99609375, 0.59765625, 0.99609375, 0.62109375, 0.3671875, 0.0, 0.62109375, 0.546875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0546875, 0.046875, 0.2734375, 0.99609375, 0.9921875, 0.0703125, 0.59765625, 0.9921875, 0.0, 0.99609375, 0.08984375, 0.62109375, 0.62109375, 0.09765625, 0.0078125, 0.6171875, 0.0, 0.62109375, 0.0390625, 0.10546875, 0.0, 0.0, 0.62109375, 0.75, 0.58984375, 0.0, 0.99609375, 0.0, 0.98828125, 0.93359375, 0.03515625, 0.62109375, 0.9921875, 0.98828125, 0.99609375, 0.0, 0.63671875, 0.99609375, 0.62109375, 0.0, 0.0390625, 0.9921875, 0.0, 0.05078125, 0.9921875, 0.0, 0.62109375, 0.99609375, 0.62109375, 0.0, 0.9921875, 0.0, 0.0, 0.05859375, 0.109375, 0.0, 0.9921875, 0.0, 0.83984375, 0.60546875, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.61328125, 0.0, 0.9921875, 0.9921875, 0.03125, 0.0, 0.0859375, 0.9921875, 0.4765625, 0.10546875, 0.55859375, 0.24609375, 0.9921875, 0.0, 0.0, 0.99609375, 0.0, 0.2109375, 0.0, 0.11328125, 0.0, 0.9921875, 0.0, 0.60546875, 0.51171875, 0.9921875, 0.25390625, 0.62109375, 0.82421875, 0.62109375, 0.59375, 0.0, 0.0, 0.0, 0.59765625, 0.9921875, 0.0, 0.9921875, 0.83203125, 0.60546875, 0.9921875, 0.62109375, 0.0, 0.99609375, 0.9921875, 0.44921875, 0.0, 0.6171875, 0.4296875, 0.99609375, 0.62109375, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.6171875, 0.98828125, 0.0, 0.0, 0.24609375, 0.359375, 0.98828125, 0.9921875, 0.109375, 0.0, 0.0546875, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.61328125, 0.0, 0.6171875, 0.62109375, 0.0, 0.80859375, 0.99609375, 0.56640625, 0.9921875, 0.0, 0.9921875, 0.0, 0.21875, 0.9921875, 0.62109375, 0.0, 0.0, 0.84375, 0.0, 0.62109375, 0.0, 0.0, 0.42578125, 0.015625, 0.0, 0.0, 0.9921875, 0.9921875, 0.0859375, 0.0, 0.9921875, 0.0, 0.0, 0.63671875, 0.0, 0.62109375, 0.9921875, 0.99609375, 0.0, 0.0, 0.60546875, 0.62109375, 0.62109375, 0.9921875, 0.62109375, 0.0, 0.1171875, 0.9921875, 0.0, 0.0, 0.62109375, 0.9921875, 0.62109375, 0.9921875, 0.01171875, 0.0, 0.62109375, 0.99609375, 0.58984375, 0.0, 0.0, 0.0, 0.58203125, 0.98828125, 0.30078125, 0.9921875, 0.4765625, 0.18359375, 0.6171875, 0.0, 0.0, 0.01953125, 0.0, 0.11328125, 0.0, 0.61328125, 0.0, 0.9921875, 0.98828125, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.99609375, 0.0, 0.01171875, 0.99609375, 0.46875, 0.6015625, 0.0625, 0.13671875, 0.140625, 0.08203125, 0.62109375, 0.9921875, 0.0078125, 0.62109375, 0.6015625, 0.62109375, 0.9921875, 0.62109375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.2109375, 0.0, 0.9921875, 0.62109375, 0.0, 0.08984375, 0.0, 0.0, 0.0, 0.1015625, 0.078125, 0.9921875, 0.9921875, 0.9921875, 0.1171875, 0.0390625, 0.140625, 0.98828125, 0.0, 0.5546875, 0.54296875, 0.0, 0.8359375, 0.0390625, 0.0, 0.91015625, 0.0, 0.0, 0.03515625, 0.0, 0.6171875, 0.0, 0.9921875, 0.5078125, 0.0, 0.0, 0.19921875, 0.62109375, 0.0, 0.0, 0.625, 0.01953125, 0.99609375, 0.0, 0.31640625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.76171875, 0.0, 0.0, 0.98828125, 0.0, 0.0, 0.5859375, 0.0, 0.02734375, 0.61328125, 0.0, 0.9921875, 0.00390625, 0.0, 0.0, 0.0, 0.78515625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.109375, 0.60546875, 0.6015625, 0.0, 0.140625, 0.52734375, 0.05859375, 0.0, 0.0625, 0.83984375, 0.35546875, 0.171875, 0.0, 0.0, 0.9921875, 0.484375, 0.0, 0.0, 0.0, 0.99609375, 0.25390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0703125, 0.0, 0.0, 0.1015625, 0.0, 0.0, 0.1171875, 0.0, 0.6796875, 0.0, 0.05078125, 0.0, 0.0, 0.0, 0.53515625, 0.0, 0.58203125, 0.0, 0.65625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.109375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.62109375, 0.0, 0.0, 0.0, 0.0, 0.14453125, 0.6171875, 0.83203125, 0.03125, 0.57421875, 0.62109375, 0.62109375, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.47265625, 0.9921875, 0.0, 0.0, 0.0078125, 0.421875, 0.61328125, 0.0, 0.0, 0.9921875, 0.58984375, 0.0, 0.62109375, 0.0, 0.9921875, 0.5859375, 0.56640625, 0.62109375, 0.99609375, 0.9921875, 0.62109375, 0.61328125, 0.99609375, 0.0, 0.16015625, 0.62109375, 0.62109375, 0.0, 0.62109375, 0.0, 0.0, 0.62109375, 0.0, 0.0, 0.0, 0.08203125, 0.62109375, 0.6171875, 0.62109375, 0.05859375, 0.62109375, 0.99609375, 0.9921875, 0.0625, 0.9921875, 0.8046875, 0.51953125, 0.0, 0.16796875, 0.0, 0.0, 0.65234375, 0.0, 0.13671875, 0.99609375, 0.16796875, 0.0, 0.11328125, 0.08984375, 0.234375, 0.0, 0.02734375, 0.0, 0.05859375, 0.5859375, 0.9921875, 0.0078125, 0.6015625, 0.0, 0.99609375, 0.17578125, 0.9921875, 0.65625, 0.9921875, 0.08203125, 0.0, 0.0, 0.0, 0.99609375, 0.05078125, 0.9921875, 0.0, 0.56640625, 0.9921875, 0.5859375, 0.0, 0.0859375, 0.0, 0.3515625, 0.9921875, 0.02734375, 0.0, 0.0, 0.6015625, 0.765625, 0.62109375, 0.62109375, 0.0, 0.9921875, 0.0, 0.671875, 0.0, 0.0, 0.9921875, 0.6171875, 0.0, 0.61328125, 0.0, 0.6171875, 0.0, 0.48046875, 0.5703125, 0.98828125, 0.9921875, 0.0, 0.59765625, 0.0, 0.02734375, 0.578125, 0.0, 0.9921875, 0.0546875, 0.0859375, 0.59375, 0.0, 0.0, 0.9921875, 0.09375, 0.99609375, 0.11328125, 0.62109375, 0.55078125, 0.0, 0.61328125, 0.0, 0.0, 0.0, 0.62109375, 0.5625, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.05078125, 0.09375, 0.6171875, 0.99609375, 0.9921875, 0.0, 0.0, 0.62109375, 0.98828125, 0.0, 0.0, 0.5859375, 0.82421875, 0.9921875, 0.55859375, 0.0, 0.9921875, 0.046875, 0.9921875, 0.9921875, 0.04296875, 0.0, 0.49609375, 0.62109375, 0.99609375, 0.0, 0.3828125, 0.9921875, 0.6171875, 0.62109375, 0.0, 0.99609375, 0.0, 0.9921875, 0.03125, 0.0625, 0.0, 0.0, 0.0, 0.62109375, 0.03515625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48046875, 0.0, 0.08203125, 0.08984375, 0.08984375, 0.62109375, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.078125, 0.109375, 0.98828125, 0.72265625, 0.62109375, 0.0, 0.0, 0.12890625, 0.9921875, 0.0, 0.03125, 0.6171875, 0.98828125, 0.0, 0.0, 0.62109375, 0.328125, 0.0, 0.0, 0.0, 0.9921875, 0.5703125, 0.0, 0.99609375, 0.609375, 0.62109375, 0.9921875, 0.0, 0.0, 0.9921875, 0.62109375, 0.0546875, 0.0, 0.59375, 0.55078125, 0.0, 0.0, 0.14453125, 0.62109375, 0.1328125, 0.078125, 0.6015625, 0.05859375, 0.0, 0.0, 0.0, 0.0, 0.62109375, 0.0, 0.98828125, 0.0, 0.09765625, 0.0, 0.62109375, 0.6171875, 0.625, 0.05078125, 0.61328125, 0.6171875, 0.0, 0.99609375, 0.99609375, 0.4140625, 0.0625, 0.9921875, 0.0, 0.0, 0.75, 0.0546875, 0.0, 0.0, 0.0, 0.0, 0.07421875, 0.0, 0.609375, 0.6171875, 0.88671875, 0.0, 0.0, 0.02734375, 0.0, 0.0, 0.0390625, 0.62109375, 0.90625, 0.0, 0.0, 0.0546875, 0.0, 0.99609375, 0.6171875, 0.62109375, 0.08984375, 0.9921875, 0.66015625, 0.0546875, 0.5859375, 0.60546875, 0.9921875, 0.0, 0.61328125, 0.0, 0.80859375, 0.0, 0.0, 0.0, 0.62109375, 0.2890625, 0.0, 0.05078125, 0.0, 0.58203125, 0.0, 0.9921875, 0.19921875, 0.9921875, 0.17578125, 0.46484375, 0.0, 0.0, 0.0, 0.9921875, 0.0]

 sparsity of   [0.017578125, 0.0283203125, 0.0, 0.0, 0.1767578125, 0.0126953125, 0.0, 0.013671875, 0.0849609375, 0.333984375, 0.1142578125, 0.8994140625, 0.0, 0.228515625, 0.015625, 0.0, 0.2509765625, 0.998046875, 0.0732421875, 0.015625, 0.0205078125, 0.0, 0.0224609375, 0.0126953125, 0.0380859375, 0.04296875, 0.2431640625, 0.0322265625, 0.119140625, 0.0068359375, 0.0, 0.7421875, 0.08203125, 0.0361328125, 0.0087890625, 0.0634765625, 0.0, 0.1572265625, 0.0, 0.0322265625, 0.0, 0.9990234375, 0.0341796875, 0.0, 0.025390625, 0.28515625, 0.74609375, 0.0654296875, 0.10546875, 0.8408203125, 0.86328125, 0.013671875, 0.037109375, 0.115234375, 0.1240234375, 0.08203125, 0.0, 0.0380859375, 0.0322265625, 0.265625, 0.0810546875, 0.052734375, 0.0, 0.017578125, 0.099609375, 0.0, 0.072265625, 0.0908203125, 0.0126953125, 0.0498046875, 0.0, 0.0, 0.1064453125, 0.0, 0.01171875, 0.052734375, 0.0, 0.017578125, 0.0, 0.0, 0.4755859375, 0.0, 0.013671875, 0.0, 0.044921875, 0.0234375, 0.013671875, 0.0146484375, 0.0, 0.0, 0.0546875, 0.01171875, 0.310546875, 0.0615234375, 0.0, 0.0, 0.0, 0.0, 0.0419921875, 0.0185546875, 0.0, 0.0185546875, 0.0693359375, 0.0283203125, 0.0, 0.0087890625, 0.150390625, 0.0087890625, 0.0, 0.0673828125, 0.052734375, 0.0673828125, 0.0, 0.0361328125, 0.0263671875, 0.9970703125, 0.013671875, 0.0, 0.0, 0.033203125, 0.078125, 0.0, 0.025390625, 0.02734375, 0.0166015625, 0.2099609375, 0.0, 0.0, 0.998046875, 0.0, 0.0166015625, 0.0341796875, 0.0283203125, 0.0, 0.0, 0.0, 0.6875, 0.0341796875, 0.0615234375, 0.01953125, 0.33984375, 0.013671875, 0.017578125, 0.0322265625, 0.0, 0.322265625, 0.32421875, 0.0, 0.0, 0.9990234375, 0.021484375, 0.0, 0.314453125, 0.0673828125, 0.0341796875, 0.0361328125, 0.0, 0.09375, 0.0, 0.0185546875, 0.0, 0.033203125, 0.025390625, 0.0048828125, 0.0, 0.0224609375, 0.2392578125, 0.1630859375, 0.2177734375, 0.1640625, 0.0908203125, 0.009765625, 0.0, 0.251953125, 0.0546875, 0.056640625, 0.025390625, 0.068359375, 0.1865234375, 0.326171875, 0.0, 0.02734375, 0.9267578125, 0.0087890625, 0.01171875, 0.7333984375, 0.2177734375, 0.0263671875, 0.0, 0.0, 0.0, 0.052734375, 0.03515625, 0.9794921875, 0.0, 0.0146484375, 0.2099609375, 0.0947265625, 0.27734375, 0.0, 0.1162109375, 0.0224609375, 0.0390625, 0.0361328125, 0.0146484375, 0.056640625, 0.0, 0.3251953125, 0.9990234375, 0.0224609375, 0.2265625, 0.0, 0.099609375, 0.0390625, 0.03515625, 0.025390625, 0.0927734375, 0.240234375, 0.181640625, 0.01171875, 0.375, 0.037109375, 0.064453125, 0.0, 0.103515625, 0.013671875, 0.0146484375, 0.0185546875, 0.0224609375, 0.0458984375, 0.025390625, 0.2724609375, 0.185546875, 0.7822265625, 0.0, 0.0166015625, 0.0146484375, 0.0302734375, 0.01171875, 0.02734375, 0.833984375, 0.0439453125, 0.103515625, 0.0, 0.01171875, 0.126953125, 0.013671875, 0.0322265625, 0.0244140625, 0.0, 0.0283203125, 0.0849609375, 0.3466796875, 0.0, 0.0, 0.0]

 sparsity of   [0.0390625, 0.1041666641831398, 0.09765625, 0.0538194440305233, 0.0373263880610466, 0.0, 0.0590277798473835, 0.0381944440305233, 0.0303819440305233, 0.0, 0.0203993059694767, 0.03081597201526165, 0.0607638880610466, 0.0512152798473835, 0.1241319477558136, 0.2604166567325592, 0.0720486119389534, 0.0, 0.0737847238779068, 0.1484375, 0.6566840410232544, 0.0438368059694767, 0.390625, 0.0625, 0.3524305522441864, 0.015625, 0.0525173619389534, 0.0, 0.0, 0.0186631940305233, 0.010416666977107525, 0.1154513880610466, 0.0321180559694767, 0.01909722201526165, 0.1419270783662796, 0.0438368059694767, 0.071180559694767, 0.0368923619389534, 0.1440972238779068, 0.0850694477558136, 0.999131977558136, 0.03515625, 0.0, 0.0407986119389534, 0.078993059694767, 0.0421006940305233, 0.078125, 0.9978298544883728, 0.0203993059694767, 0.1471354216337204, 0.0, 0.921875, 0.0434027798473835, 0.2864583432674408, 0.02994791604578495, 0.02951388992369175, 0.0225694440305233, 0.0698784738779068, 0.0, 0.2170138955116272, 0.0, 0.02951388992369175, 0.0798611119389534, 0.5598958134651184, 0.02864583395421505, 0.7252604365348816, 0.0481770820915699, 0.0, 0.02951388992369175, 0.0, 0.0412326380610466, 0.0342881940305233, 0.0959201380610466, 0.03125, 0.1558159738779068, 0.0659722238779068, 0.5798611044883728, 0.0, 0.02170138992369175, 0.1545138955116272, 0.07421875, 0.0, 0.02951388992369175, 0.0, 0.05078125, 0.1072048619389534, 0.0, 0.0360243059694767, 0.0, 0.0516493059694767, 0.086805559694767, 0.1536458283662796, 0.02387152798473835, 0.0, 0.1228298619389534, 0.0677083358168602, 0.0642361119389534, 0.4361979067325592, 0.0681423619389534, 0.0533854179084301, 0.1354166716337204, 0.0638020858168602, 0.0490451380610466, 0.08203125, 0.0, 0.9045138955116272, 0.0, 0.0412326380610466, 0.1861979216337204, 0.0, 0.0850694477558136, 0.0785590261220932, 0.02170138992369175, 0.0729166641831398, 0.0785590261220932, 0.121961809694767, 0.0125868059694767, 0.0, 0.1072048619389534, 0.0, 0.0, 0.00434027798473835, 0.02170138992369175, 0.0876736119389534, 0.0225694440305233, 0.0551215298473835, 0.0681423619389534, 0.009114583022892475, 0.01779513992369175, 0.0941840261220932, 0.0703125, 0.0321180559694767, 0.08203125, 0.4075520932674408, 0.02170138992369175, 0.0412326380610466, 0.0243055559694767, 0.0368923619389534, 0.0173611119389534, 0.1983506977558136, 0.0086805559694767, 0.0, 0.0, 0.1319444477558136, 0.4418402910232544, 0.0551215298473835, 0.0824652761220932, 0.15625, 0.0421006940305233, 0.0837673619389534, 0.0394965298473835, 0.0529513880610466, 0.0334201380610466, 0.02560763992369175, 0.0, 0.9613715410232544, 0.0, 0.02734375, 0.0603298619389534, 0.02864583395421505, 0.0720486119389534, 0.1471354216337204, 0.02604166604578495, 0.0390625, 0.0390625, 0.0729166641831398, 0.02864583395421505, 0.0329861119389534, 0.0876736119389534, 0.0, 0.0203993059694767, 0.03125, 0.0, 0.3684895932674408, 0.014756944961845875, 0.0, 0.1393229216337204, 0.8589409589767456, 0.0243055559694767, 0.0516493059694767, 0.1549479216337204, 0.0394965298473835, 0.0282118059694767, 0.1822916716337204, 0.0920138880610466, 0.1996527761220932, 0.102430559694767, 0.1358506977558136, 0.009982638992369175, 0.5251736044883728, 0.1115451380610466, 0.00824652798473835, 0.01692708395421505, 0.12109375, 0.0026041667442768812, 0.0, 0.0, 0.0607638880610466, 0.01996527798473835, 0.0173611119389534, 0.082899309694767, 0.0785590261220932, 0.01779513992369175, 0.02213541604578495, 0.0, 0.2196180522441864, 0.0290798619389534, 0.02170138992369175, 0.03515625, 0.0490451380610466, 0.02387152798473835, 0.1545138955116272, 0.0203993059694767, 0.4861111044883728, 0.20703125, 0.0173611119389534, 0.078125, 0.0, 0.09375, 0.0212673619389534, 0.0412326380610466, 0.1766493022441864, 0.04296875, 0.02560763992369175, 0.0846354141831398, 0.04296875, 0.0473090298473835, 0.0538194440305233, 0.538194477558136, 0.0225694440305233, 0.0078125, 0.0, 0.4756944477558136, 0.0, 0.0004340277810115367, 0.0086805559694767, 0.0399305559694767, 0.0, 0.2170138955116272, 0.7782118320465088, 0.1280381977558136, 0.0, 0.2747395932674408, 0.02473958395421505, 0.0, 0.0499131940305233, 0.220486119389534, 0.0846354141831398, 0.0464409738779068, 0.0399305559694767, 0.0707465261220932, 0.4153645932674408, 0.0, 0.0, 0.009982638992369175, 0.0]

 sparsity of   [0.79296875, 0.7734375, 0.80078125, 0.0, 0.0859375, 0.57421875, 0.8046875, 0.9921875, 0.54296875, 0.0, 0.09765625, 0.07421875, 0.65625, 0.1015625, 0.58984375, 0.8046875, 0.0, 0.67578125, 0.703125, 0.60546875, 0.578125, 0.046875, 0.53515625, 0.9296875, 0.76171875, 0.41796875, 0.171875, 0.640625, 0.6640625, 0.69140625, 0.0, 0.5859375, 0.7109375, 0.05078125, 0.58984375, 0.0, 0.6796875, 0.6484375, 0.76171875, 0.58984375, 0.00390625, 0.6328125, 0.50390625, 0.60546875, 0.5703125, 0.55859375, 0.8046875, 0.0, 0.0390625, 0.5546875, 0.4296875, 0.8046875, 0.6640625, 0.03125, 0.6015625, 0.6875, 0.8046875, 0.609375, 0.69921875, 0.0, 0.71875, 0.4453125, 0.6640625, 0.9921875, 0.0625, 0.578125, 0.0859375, 0.90234375, 0.03515625, 0.0, 0.52734375, 0.78515625, 0.49609375, 0.05859375, 0.52734375, 0.5625, 0.0, 0.46875, 0.453125, 0.6328125, 0.48046875, 0.9921875, 0.63671875, 0.59375, 0.0546875, 0.0, 0.0, 0.62109375, 0.61328125, 0.67578125, 0.08984375, 0.6015625, 0.0, 0.66015625, 0.49609375, 0.5859375, 0.0, 0.06640625, 0.578125, 0.5703125, 0.0, 0.0, 0.0, 0.62890625, 0.0, 0.88671875, 0.47265625, 0.4765625, 0.72265625, 0.18359375, 0.890625, 0.6328125, 0.0, 0.02734375, 0.63671875, 0.8046875, 0.56640625, 0.0, 0.8046875, 0.48046875, 0.03515625, 0.0859375, 0.60546875, 0.61328125, 0.671875, 0.08984375, 0.0, 0.8046875, 0.0, 0.0, 0.0, 0.71484375, 0.0, 0.6875, 0.41796875, 0.98046875, 0.51953125, 0.69140625, 0.671875, 0.0, 0.89453125, 0.8046875, 0.9921875, 0.68359375, 0.8046875, 0.0, 0.046875, 0.6171875, 0.69140625, 0.60546875, 0.09375, 0.73046875, 0.5234375, 0.01953125, 0.61328125, 0.13671875, 0.00390625, 0.01171875, 0.58984375, 0.02734375, 0.0, 0.59375, 0.6015625, 0.69921875, 0.0, 0.0, 0.8046875, 0.70703125, 0.05078125, 0.44921875, 0.6953125, 0.03125, 0.9296875, 0.0390625, 0.23046875, 0.80078125, 0.46875, 0.6328125, 0.28515625, 0.58203125, 0.09765625, 0.6328125, 0.6796875, 0.5625, 0.68359375, 0.67578125, 0.14453125, 0.9921875, 0.6875, 0.8046875, 0.875, 0.55859375, 0.0, 0.6484375, 0.078125, 0.9921875, 0.0, 0.546875, 0.6640625, 0.8046875, 0.09375, 0.1328125, 0.1171875, 0.5625, 0.0, 0.16015625, 0.02734375, 0.0, 0.6328125, 0.58203125, 0.71875, 0.8046875, 0.03125, 0.625, 0.54296875, 0.02734375, 0.625, 0.8046875, 0.8046875, 0.0, 0.80078125, 0.9921875, 0.9921875, 0.640625, 0.61328125, 0.06640625, 0.8046875, 0.53515625, 0.69140625, 0.0, 0.0234375, 0.0, 0.9921875, 0.6796875, 0.0, 0.0859375, 0.58984375, 0.09765625, 0.0, 0.03125, 0.4921875, 0.0, 0.34765625, 0.0625, 0.0, 0.0078125, 0.6484375, 0.0, 0.0, 0.05078125, 0.0, 0.0390625, 0.14453125, 0.34375, 0.65234375, 0.79296875, 0.01953125, 0.49609375, 0.125, 0.5078125, 0.00390625, 0.0, 0.8046875, 0.6875, 0.59375, 0.9921875, 0.0, 0.69921875, 0.6875, 0.99609375, 0.5546875, 0.078125, 0.52734375, 0.8046875, 0.12890625, 0.69921875, 0.03515625, 0.0, 0.14453125, 0.58203125, 0.6171875, 0.484375, 0.5859375, 0.1015625, 0.0, 0.56640625, 0.59375, 0.80078125, 0.5625, 0.671875, 0.9921875, 0.1171875, 0.70703125, 0.59375, 0.57421875, 0.8046875, 0.625, 0.69921875, 0.71875, 0.0, 0.640625, 0.6796875, 0.671875, 0.80078125, 0.0234375, 0.9921875, 0.125, 0.01953125, 0.078125, 0.9921875, 0.0, 0.0234375, 0.05078125, 0.8046875, 0.59765625, 0.0390625, 0.4375, 0.08984375, 0.0, 0.8046875, 0.50390625, 0.8046875, 0.0078125, 0.01953125, 0.62890625, 0.62890625, 0.52734375, 0.625, 0.9921875, 0.62890625, 0.58203125, 0.26953125, 0.8046875, 0.65625, 0.72265625, 0.09765625, 0.9921875, 0.72265625, 0.78125, 0.0625, 0.6328125, 0.0, 0.9921875, 0.59375, 0.0, 0.6875, 0.9921875, 0.01953125, 0.98828125, 0.5859375, 0.62890625, 0.46484375, 0.6328125, 0.0, 0.80078125, 0.41015625, 0.9921875, 0.0, 0.03125, 0.8046875, 0.8046875, 0.0625, 0.6796875, 0.796875, 0.07421875, 0.5859375, 0.046875, 0.5859375, 0.60546875, 0.62109375, 0.828125, 0.56640625, 0.13671875, 0.69140625, 0.0, 0.0625, 0.6328125, 0.578125, 0.6796875, 0.1171875, 0.94921875, 0.125, 0.0, 0.6015625, 0.5546875, 0.62109375, 0.48046875, 0.78125, 0.19140625, 0.64453125, 0.0, 0.9921875, 0.35546875, 0.5625, 0.7109375, 0.53515625, 0.015625, 0.125, 0.8046875, 0.67578125, 0.5234375, 0.0, 0.58984375, 0.0546875, 0.64453125, 0.31640625, 0.8046875, 0.58984375, 0.58203125, 0.55859375, 0.09765625, 0.61328125, 0.53125, 0.9921875, 0.0, 0.54296875, 0.625, 0.046875, 0.0703125, 0.046875, 0.0, 0.7578125, 0.0, 0.09375, 0.66796875, 0.0234375, 0.0, 0.0, 0.9921875, 0.15234375, 0.6328125, 0.9921875, 0.9921875, 0.0, 0.7265625, 0.0, 0.68359375, 0.02734375, 0.5859375, 0.01171875, 0.8046875, 0.0, 0.640625, 0.4375, 0.0, 0.58203125, 0.66796875, 0.80078125, 0.52734375, 0.8046875, 0.55078125, 0.0, 0.64453125, 0.6640625, 0.59765625, 0.0703125, 0.39453125, 0.515625, 0.5703125, 0.6875, 0.71875, 0.6796875, 0.7578125, 0.75, 0.0, 0.59375, 0.5546875, 0.4765625, 0.03515625, 0.7578125, 0.9921875, 0.53125, 0.0, 0.01171875, 0.0, 0.0, 0.109375, 0.9921875, 0.8046875, 0.60546875, 0.0390625, 0.5390625, 0.66796875, 0.6640625, 0.6640625, 0.0, 0.0703125, 0.953125, 0.08984375, 0.0234375, 0.671875, 0.78125, 0.3828125, 0.57421875, 0.0, 0.078125, 0.0, 0.06640625, 0.13671875, 0.0, 0.0, 0.63671875, 0.8046875, 0.9921875, 0.625, 0.546875, 0.3671875, 0.40625, 0.46484375, 0.78125, 0.0, 0.14453125, 0.0, 0.12109375, 0.0, 0.625, 0.7421875, 0.2421875, 0.55859375, 0.0, 0.0, 0.74609375, 0.06640625, 0.0, 0.6875, 0.8046875, 0.8046875, 0.60546875, 0.0234375, 0.0, 0.03515625, 0.03515625, 0.4609375, 0.62890625, 0.3203125, 0.4921875, 0.109375, 0.1015625, 0.57421875, 0.99609375, 0.54296875, 0.640625, 0.76953125, 0.75, 0.15234375, 0.6015625, 0.44921875, 0.5390625, 0.046875, 0.0, 0.609375, 0.4765625, 0.0, 0.5078125, 0.55078125, 0.0, 0.8046875, 0.0, 0.015625, 0.625, 0.6875, 0.09375, 0.0078125, 0.05078125, 0.52734375, 0.46875, 0.58984375, 0.109375, 0.92578125, 0.55078125, 0.48828125, 0.12890625, 0.1171875, 0.17578125, 0.1015625, 0.09765625, 0.51953125, 0.0, 0.11328125, 0.74609375, 0.0, 0.5625, 0.73046875, 0.46484375, 0.046875, 0.0, 0.74609375, 0.48046875, 0.5, 0.5390625, 0.0, 0.99609375, 0.9921875, 0.75, 0.0, 0.62890625, 0.0, 0.0, 0.0, 0.65625, 0.0, 0.9609375, 0.62890625, 0.0, 0.6015625, 0.0234375, 0.0, 0.93359375, 0.0, 0.68359375, 0.46875, 0.0, 0.51953125, 0.5859375, 0.8046875, 0.58984375, 0.62890625, 0.51953125, 0.0, 0.00390625, 0.68359375, 0.51171875, 0.0, 0.05859375, 0.45703125, 0.60546875, 0.62890625, 0.0, 0.80078125, 0.9921875, 0.75390625, 0.77734375, 0.5859375, 0.515625, 0.6015625, 0.72265625, 0.0, 0.5859375, 0.52734375, 0.0, 0.0, 0.0, 0.0, 0.6796875, 0.8046875, 0.0, 0.0, 0.125, 0.0, 0.8046875, 0.64453125, 0.68359375, 0.0, 0.9609375, 0.0, 0.796875, 0.66015625, 0.0, 0.58984375, 0.671875, 0.09765625, 0.8046875, 0.0, 0.8046875, 0.9921875, 0.5234375, 0.765625, 0.07421875, 0.05078125, 0.0, 0.0, 0.7421875, 0.0, 0.01171875, 0.3046875, 0.7265625, 0.0, 0.0, 0.6796875, 0.0, 0.546875, 0.51171875, 0.0, 0.8046875, 0.8046875, 0.74609375, 0.8046875, 0.08984375, 0.5078125, 0.07421875, 0.8046875, 0.16015625, 0.8046875, 0.046875, 0.0, 0.0078125, 0.42578125, 0.109375, 0.9453125, 0.98828125, 0.4296875, 0.6484375, 0.51953125, 0.8046875, 0.5390625, 0.48828125, 0.64453125, 0.0, 0.55859375, 0.0390625, 0.80078125, 0.5703125, 0.0, 0.99609375, 0.53125, 0.4765625, 0.0546875, 0.5625, 0.5, 0.54296875, 0.58984375, 0.046875, 0.0, 0.71875, 0.62109375, 0.640625, 0.0, 0.515625, 0.0, 0.0, 0.53125, 0.0, 0.00390625, 0.125, 0.2109375, 0.54296875, 0.58203125, 0.66015625, 0.72265625, 0.7421875, 0.03125, 0.59765625, 0.08203125, 0.5078125, 0.3984375, 0.1015625, 0.61328125, 0.65234375, 0.0, 0.24609375, 0.06640625, 0.0, 0.40625, 0.53515625, 0.9921875, 0.0, 0.0, 0.54296875, 0.58984375, 0.0, 0.60546875, 0.8046875, 0.60546875, 0.8046875, 0.71484375, 0.6015625, 0.3984375, 0.65234375, 0.0234375, 0.16015625, 0.8046875, 0.109375, 0.03125, 0.08203125, 0.57421875, 0.67578125, 0.8046875, 0.9921875, 0.8046875, 0.54296875, 0.0, 0.62109375, 0.5390625, 0.625, 0.578125, 0.8046875, 0.0, 0.0390625, 0.0546875, 0.0, 0.71875, 0.0, 0.33984375, 0.10546875, 0.00390625, 0.140625, 0.6015625, 0.8828125, 0.8046875, 0.80859375, 0.80078125, 0.54296875, 0.0625, 0.46875, 0.0, 0.04296875, 0.0078125, 0.46484375, 0.60546875, 0.79296875, 0.9921875, 0.6171875, 0.91015625, 0.0, 0.5234375, 0.8046875, 0.8046875, 0.62109375, 0.015625, 0.71875, 0.6640625, 0.76171875, 0.078125, 0.0, 0.41015625, 0.03515625, 0.03515625, 0.9921875, 0.921875, 0.10546875, 0.9921875, 0.0, 0.67578125, 0.69140625, 0.0, 0.3828125, 0.5078125, 0.0, 0.0, 0.0, 0.8046875, 0.71875, 0.65625, 0.8046875, 0.52734375, 0.5, 0.4921875, 0.46484375, 0.1171875, 0.0, 0.46875, 0.59375, 0.05078125, 0.0, 0.6328125, 0.6015625, 0.9921875, 0.671875, 0.00390625, 0.7734375, 0.9921875, 0.08203125, 0.99609375, 0.98828125, 0.0, 0.3125, 0.05078125, 0.5625, 0.56640625, 0.05859375, 0.0546875, 0.0859375, 0.57421875, 0.6484375, 0.6171875, 0.69140625, 0.4609375, 0.515625, 0.03125, 0.65234375, 0.57421875, 0.0, 0.08984375, 0.64453125, 0.26171875, 0.0, 0.0, 0.8046875, 0.15625, 0.015625, 0.0, 0.58203125, 0.56640625, 0.46484375, 0.59375, 0.0, 0.62109375, 0.0859375, 0.0, 0.62890625, 0.65625, 0.78515625, 0.4921875, 0.60546875, 0.4921875, 0.0, 0.65625, 0.0, 0.5546875, 0.8046875, 0.8984375, 0.5859375, 0.0390625, 0.0, 0.75390625, 0.6640625, 0.5234375, 0.0, 0.0, 0.60546875, 0.046875, 0.15234375, 0.0078125, 0.58203125, 0.9921875, 0.546875, 0.0390625, 0.0, 0.796875, 0.5, 0.57421875, 0.9921875, 0.11328125, 0.484375, 0.08984375, 0.6640625, 0.0, 0.51953125, 0.62109375, 0.9765625, 0.24609375, 0.13671875, 0.33203125, 0.68359375, 0.7421875, 0.80078125, 0.0, 0.5546875, 0.60546875, 0.03125, 0.6015625, 0.80078125, 0.57421875, 0.59375, 0.0859375, 0.0625, 0.55859375, 0.8046875, 0.578125, 0.609375, 0.015625, 0.5, 0.8046875, 0.62109375, 0.57421875, 0.109375, 0.0, 0.578125, 0.62890625, 0.0, 0.05859375, 0.6484375, 0.0, 0.0859375, 0.0, 0.01171875, 0.06640625, 0.99609375, 0.0, 0.578125, 0.50390625, 0.80078125, 0.8046875, 0.109375, 0.72265625, 0.70703125, 0.0, 0.59765625, 0.046875, 0.0, 0.046875, 0.6015625, 0.6875, 0.65625, 0.29296875, 0.13671875, 0.8046875, 0.0546875, 0.5859375, 0.9921875, 0.09375, 0.60546875, 0.00390625, 0.9921875, 0.0, 0.0, 0.05859375, 0.8046875, 0.078125, 0.61328125, 0.05078125, 0.0, 0.61328125, 0.6015625, 0.51171875, 0.3671875, 0.8515625, 0.53515625, 0.80078125, 0.078125, 0.0, 0.18359375, 0.796875, 0.0]

 sparsity of   [0.951171875, 0.896484375, 0.0205078125, 0.025390625, 0.998046875, 0.111328125, 0.74609375, 0.177734375, 0.7978515625, 0.8681640625, 0.0283203125, 0.998046875, 0.0361328125, 0.7734375, 0.9013671875, 0.1064453125, 0.03125, 0.021484375, 0.0283203125, 0.1142578125, 0.2744140625, 0.998046875, 0.998046875, 0.9990234375, 0.0390625, 0.0888671875, 0.171875, 0.447265625, 0.0146484375, 0.9990234375, 0.0361328125, 0.0791015625, 0.0166015625, 0.0439453125, 0.0556640625, 0.154296875, 0.0537109375, 0.998046875, 0.05078125, 0.0419921875, 0.0595703125, 0.029296875, 0.0390625, 0.021484375, 0.2255859375, 0.0146484375, 0.0546875, 0.908203125, 0.1083984375, 0.802734375, 0.052734375, 0.044921875, 0.017578125, 0.115234375, 0.1630859375, 0.92578125, 0.021484375, 0.0859375, 0.998046875, 0.107421875, 0.0244140625, 0.03125, 0.8984375, 0.8984375, 0.0810546875, 0.9990234375, 0.044921875, 0.998046875, 0.0439453125, 0.6162109375, 0.7412109375, 0.0849609375, 0.1337890625, 0.0439453125, 0.0595703125, 0.1025390625, 0.9990234375, 0.998046875, 0.998046875, 0.9990234375, 0.8818359375, 0.92578125, 0.951171875, 0.0205078125, 0.02734375, 0.021484375, 0.005859375, 0.0458984375, 0.04296875, 0.068359375, 0.810546875, 0.06640625, 0.8359375, 0.0478515625, 0.0068359375, 0.0244140625, 0.09375, 0.998046875, 0.962890625, 0.998046875, 0.1865234375, 0.015625, 0.021484375, 0.09765625, 0.228515625, 0.0283203125, 0.0859375, 0.0166015625, 0.8017578125, 0.9970703125, 0.029296875, 0.0263671875, 0.7822265625, 0.0634765625, 0.0107421875, 0.068359375, 0.998046875, 0.212890625, 0.0224609375, 0.9990234375, 0.03125, 0.025390625, 0.0302734375, 0.0263671875, 0.9404296875, 0.017578125, 0.068359375, 0.7880859375, 0.0927734375, 0.0302734375, 0.0458984375, 0.1103515625, 0.0341796875, 0.0390625, 0.0869140625, 0.8046875, 0.0380859375, 0.072265625, 0.1982421875, 0.0419921875, 0.0126953125, 0.02734375, 0.0732421875, 0.06640625, 0.1015625, 0.0478515625, 0.0078125, 0.951171875, 0.0224609375, 0.064453125, 0.06640625, 0.0888671875, 0.9970703125, 0.193359375, 0.10546875, 0.9140625, 0.029296875, 0.005859375, 0.02734375, 0.0380859375, 0.119140625, 0.06640625, 0.9990234375, 0.8916015625, 0.7998046875, 0.02734375, 0.998046875, 0.9296875, 0.0234375, 0.01171875, 0.9990234375, 0.0546875, 0.998046875, 0.0419921875, 0.0244140625, 0.9990234375, 0.7607421875, 0.2431640625, 0.0205078125, 0.9990234375, 0.7880859375, 0.029296875, 0.1259765625, 0.099609375, 0.0126953125, 0.9970703125, 0.927734375, 0.0234375, 0.0341796875, 0.1396484375, 0.1611328125, 0.55078125, 0.765625, 0.087890625, 0.8212890625, 0.0087890625, 0.0283203125, 0.05078125, 0.810546875, 0.0498046875, 0.02734375, 0.14453125, 0.1923828125, 0.4130859375, 0.8984375, 0.916015625, 0.765625, 0.068359375, 0.0341796875, 0.0634765625, 0.9990234375, 0.0439453125, 0.9833984375, 0.0537109375, 0.0458984375, 0.9970703125, 0.0126953125, 0.046875, 0.072265625, 0.0400390625, 0.0986328125, 0.08984375, 0.0419921875, 0.998046875, 0.0244140625, 0.107421875, 0.998046875, 0.828125, 0.009765625, 0.0263671875, 0.0244140625, 0.0830078125, 0.91796875, 0.0048828125, 0.01953125, 0.12109375, 0.03125, 0.9990234375, 0.87109375, 0.998046875, 0.998046875, 0.1337890625, 0.8046875, 0.8984375, 0.998046875, 0.0546875, 0.955078125, 0.1943359375, 0.0185546875, 0.033203125, 0.9697265625, 0.9990234375, 0.0439453125, 0.033203125, 0.14453125, 0.1064453125]

 sparsity of   [0.09375, 0.6206597089767456, 0.01996527798473835, 0.0798611119389534, 0.01996527798473835, 0.09765625, 0.9995659589767456, 0.0243055559694767, 0.1080729141831398, 0.1740451455116272, 0.0442708320915699, 0.1089409738779068, 0.01909722201526165, 0.0316840298473835, 0.8550347089767456, 0.013020833022892475, 0.7513020634651184, 0.9149305820465088, 0.05078125, 0.0464409738779068, 0.005642361007630825, 0.9995659589767456, 0.0321180559694767, 0.0203993059694767, 0.0546875, 0.6510416865348816, 0.01519097201526165, 0.05078125, 0.8285590410232544, 0.0746527761220932, 0.009982638992369175, 0.0954861119389534, 0.00824652798473835, 0.071180559694767, 0.013454861007630825, 0.0125868059694767, 0.01215277798473835, 0.01519097201526165, 0.999131977558136, 0.9609375, 0.1310763955116272, 0.0251736119389534, 0.0399305559694767, 0.0164930559694767, 0.0399305559694767, 0.0607638880610466, 0.0993923619389534, 0.0685763880610466, 0.0373263880610466, 0.181423619389534, 0.0963541641831398, 0.0559895820915699, 0.014756944961845875, 0.0008680555620230734, 0.0381944440305233, 0.0360243059694767, 0.0186631940305233, 0.02213541604578495, 0.1076388880610466, 0.0243055559694767, 0.010416666977107525, 0.0503472238779068, 0.01605902798473835, 0.00824652798473835, 0.0473090298473835, 0.01822916604578495, 0.082899309694767, 0.0611979179084301, 0.0681423619389534, 0.0017361111240461469, 0.0234375, 0.0451388880610466, 0.0473090298473835, 0.9223090410232544, 0.082899309694767, 0.01215277798473835, 0.0824652761220932, 0.999131977558136, 0.0203993059694767, 0.0234375, 0.1788194477558136, 0.02951388992369175, 0.009548611007630825, 0.2118055522441864, 0.3493923544883728, 0.9032118320465088, 0.0529513880610466, 0.0685763880610466, 0.0290798619389534, 0.0078125, 0.0863715261220932, 0.1332465261220932, 0.0399305559694767, 0.4539930522441864, 0.01953125, 0.01128472201526165, 0.0546875, 0.14453125, 0.1671006977558136, 0.01909722201526165, 0.678819477558136, 0.0381944440305233, 0.013454861007630825, 0.02300347201526165, 0.9995659589767456, 0.828125, 0.02560763992369175, 0.0347222238779068, 0.02560763992369175, 0.999131977558136, 0.6888020634651184, 0.0668402761220932, 0.009548611007630825, 0.8971354365348816, 0.0234375, 0.0303819440305233, 0.010416666977107525, 0.02560763992369175, 0.00824652798473835, 0.0724826380610466, 0.0434027798473835, 0.02213541604578495, 0.0069444444961845875, 0.0225694440305233, 0.9995659589767456, 0.009982638992369175, 0.9986979365348816, 0.1666666716337204, 0.9153645634651184, 0.02560763992369175, 0.1223958358168602, 0.009982638992369175, 0.013020833022892475, 0.0355902798473835, 0.01519097201526165, 0.7018229365348816, 0.013020833022892475, 0.9986979365348816, 0.01605902798473835, 0.0460069440305233, 0.0768229141831398, 0.0425347238779068, 0.009982638992369175, 0.0173611119389534, 0.013020833022892475, 0.02560763992369175, 0.0251736119389534, 0.6111111044883728, 0.03125, 0.01996527798473835, 0.0203993059694767, 0.0425347238779068, 0.9266493320465088, 0.9340277910232544, 0.9995659589767456, 0.9995659589767456, 0.02213541604578495, 0.02170138992369175, 0.12109375, 0.0243055559694767, 0.01215277798473835, 0.999131977558136, 0.0607638880610466, 0.7378472089767456, 0.8298611044883728, 0.0394965298473835, 0.0243055559694767, 0.2348090261220932, 0.8763020634651184, 0.09375, 0.1059027761220932, 0.014756944961845875, 0.9223090410232544, 0.5885416865348816, 0.01692708395421505, 0.9006076455116272, 0.0078125, 0.7786458134651184, 0.8168402910232544, 0.0611979179084301, 0.02213541604578495, 0.02170138992369175, 0.0516493059694767, 0.01996527798473835, 0.01692708395421505, 0.0364583320915699, 0.02734375, 0.0065104165114462376, 0.010416666977107525, 0.9995659589767456, 0.0290798619389534, 0.1653645783662796, 0.0203993059694767, 0.0490451380610466, 0.220486119389534, 0.1974826455116272, 0.0325520820915699, 0.01779513992369175, 0.01996527798473835, 0.01215277798473835, 0.0416666679084301, 0.0616319440305233, 0.9986979365348816, 0.208767369389534, 0.0503472238779068, 0.1284722238779068, 0.0364583320915699, 0.0186631940305233, 0.0503472238779068, 0.009548611007630825, 0.01215277798473835, 0.01996527798473835, 0.009982638992369175, 0.01909722201526165, 0.009982638992369175, 0.0590277798473835, 0.0386284738779068, 0.0503472238779068, 0.1545138955116272, 0.1532118022441864, 0.0316840298473835, 0.010850694961845875, 0.0360243059694767, 0.9188368320465088, 0.03125, 0.0542534738779068, 0.0321180559694767, 0.02170138992369175, 0.03081597201526165, 0.0590277798473835, 0.1875, 0.1649305522441864, 0.009982638992369175, 0.0451388880610466, 0.0811631977558136, 0.0013020833721384406, 0.01215277798473835, 0.0321180559694767, 0.0086805559694767, 0.0173611119389534, 0.9457465410232544, 0.013020833022892475, 0.8880208134651184, 0.0373263880610466, 0.0551215298473835, 0.0347222238779068, 0.02387152798473835, 0.03125, 0.9479166865348816, 0.01692708395421505, 0.9995659589767456, 0.010850694961845875, 0.0651041641831398, 0.04296875, 0.0125868059694767, 0.01779513992369175]

 sparsity of   [0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.1015625, 0.99609375, 0.1171875, 0.9921875, 0.99609375, 0.21875, 0.9921875, 0.98828125, 0.015625, 0.9921875, 0.09375, 0.99609375, 0.98828125, 0.98828125, 0.0859375, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.9921875, 0.078125, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.04296875, 0.9921875, 0.99609375, 0.09765625, 0.9921875, 0.30078125, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.05078125, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.109375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.06640625, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.98828125, 0.99609375, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.09375, 0.05859375, 0.03125, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.47265625, 0.99609375, 0.98828125, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.11328125, 0.99609375, 0.98828125, 0.99609375, 0.40625, 0.99609375, 0.99609375, 0.99609375, 0.11328125, 0.9921875, 0.09375, 0.1484375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.26953125, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.98828125, 0.05078125, 0.99609375, 0.9921875, 0.9921875, 0.09375, 0.9921875, 0.9921875, 0.99609375, 0.3828125, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.09375, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.125, 0.08203125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.421875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.140625, 0.9921875, 0.99609375, 0.98828125, 0.99609375, 0.9921875, 0.046875, 0.9921875, 0.9921875, 0.9921875, 0.08984375, 0.9921875, 0.99609375, 0.98828125, 0.54296875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.125, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.0859375, 0.4375, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.05859375, 0.9921875, 0.08203125, 0.99609375, 0.984375, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.171875, 0.0390625, 0.9921875, 0.99609375, 0.09765625, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.03515625, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.24609375, 0.98828125, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.06640625, 0.9921875, 0.98828125, 0.0859375, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.1640625, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.203125, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.0625, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.08984375, 0.9921875, 0.9921875, 0.99609375, 0.12109375, 0.99609375, 0.9921875, 0.9921875, 0.12109375, 0.9921875, 0.51171875, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.08984375, 0.99609375, 0.99609375, 0.0546875, 0.11328125, 0.12890625, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.140625, 0.1875, 0.98828125, 0.08984375, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.125, 0.29296875, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.1015625, 0.99609375, 0.9921875, 0.9921875, 0.08984375, 0.9921875, 0.47265625, 0.9921875, 0.1484375, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.2421875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.37109375, 0.9921875, 0.09765625, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.1328125, 0.9921875, 0.13671875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.33203125, 0.9921875, 0.99609375, 0.99609375, 0.99609375, 0.9921875, 0.453125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.19140625, 0.8515625, 0.9921875, 0.9921875, 0.07421875, 0.3828125, 0.17578125, 0.9921875, 0.9921875, 0.02734375, 0.98828125, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.09375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.38671875, 0.9921875, 0.9921875, 0.9921875, 0.046875, 0.98828125, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.0703125, 0.0625, 0.11328125, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.25, 0.99609375, 0.1171875, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.08203125, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.109375, 0.99609375, 0.0859375, 0.4921875, 0.9921875, 0.9921875, 0.9921875, 0.15625, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.0234375, 0.9921875, 0.9921875, 0.0234375, 0.9921875, 0.1015625, 0.9921875, 0.99609375, 0.98828125, 0.0625, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.05859375, 0.99609375, 0.9921875, 0.9921875, 0.0859375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.1796875, 0.9921875, 0.0625, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.12890625, 0.234375, 0.9921875, 0.9921875, 0.12890625, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.0859375, 0.9921875, 0.9921875, 0.3984375, 0.99609375, 0.82421875, 0.9921875, 0.99609375, 0.0703125, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.19140625, 0.21875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.13671875, 0.0390625, 0.08984375, 0.0625, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.99609375, 0.9921875, 0.20703125, 0.1484375, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.99609375, 0.15234375, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.1640625, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.03515625, 0.14453125, 0.9921875, 0.98828125, 0.98828125, 0.0625, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.08984375, 0.9921875, 0.98828125, 0.08203125, 0.9921875, 0.98828125, 0.0859375, 0.99609375, 0.9921875, 0.9921875, 0.84765625, 0.9921875, 0.29296875, 0.9921875, 0.41015625, 0.99609375, 0.98828125, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.04296875, 0.9921875, 0.9921875, 0.0390625, 0.9921875, 0.99609375, 0.2109375, 0.11328125, 0.08984375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.99609375, 0.98828125, 0.0703125, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.09375, 0.99609375, 0.99609375, 0.9921875, 0.1484375, 0.9921875, 0.9921875, 0.99609375, 0.98828125, 0.99609375, 0.99609375, 0.0859375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.1953125, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.06640625, 0.02734375, 0.08203125, 0.9921875, 0.0625, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.265625, 0.1484375, 0.99609375, 0.1328125, 0.98828125, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.11328125, 0.9921875, 0.98828125, 0.046875, 0.9921875, 0.9921875, 0.9921875, 0.17578125, 0.15625, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.05859375, 0.9921875, 0.15625, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.98828125, 0.98828125, 0.99609375, 0.99609375, 0.3984375, 0.9921875, 0.99609375, 0.98828125, 0.05859375, 0.9921875, 0.9921875, 0.9921875, 0.3125, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.99609375, 0.171875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.99609375, 0.4765625, 0.9921875, 0.99609375, 0.98828125, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.35546875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.08203125, 0.9921875, 0.9921875, 0.0234375, 0.0625, 0.99609375, 0.1953125, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.07421875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.23828125, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.828125, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.9921875, 0.1171875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.06640625, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.171875, 0.9921875, 0.1953125, 0.99609375, 0.9921875, 0.4609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.04296875, 0.09375, 0.9921875, 0.890625, 0.99609375, 0.99609375, 0.9921875, 0.38671875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.109375, 0.34375, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.08203125, 0.9921875, 0.9921875, 0.9921875, 0.0703125, 0.9921875, 0.40234375, 0.4609375, 0.99609375, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.1328125, 0.109375, 0.99609375, 0.9921875, 0.078125, 0.9921875, 0.10546875, 0.98828125, 0.99609375, 0.078125, 0.9921875, 0.98828125, 0.99609375, 0.07421875, 0.9921875, 0.99609375, 0.125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.265625, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.28515625, 0.99609375, 0.13671875, 0.28125, 0.98828125, 0.99609375, 0.82421875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.07421875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.09765625, 0.9921875, 0.9921875, 0.8671875, 0.984375, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.484375, 0.9921875, 0.9921875, 0.27734375, 0.98828125, 0.9921875, 0.09375]

 sparsity of   [0.0615234375, 0.998046875, 0.04296875, 0.998046875, 0.9970703125, 0.0439453125, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.1171875, 0.044921875, 0.146484375, 0.0263671875, 0.998046875, 0.0322265625, 0.9970703125, 0.150390625, 0.03515625, 0.0791015625, 0.0361328125, 0.2939453125, 0.998046875, 0.068359375, 0.1357421875, 0.0478515625, 0.7978515625, 0.0615234375, 0.9990234375, 0.115234375, 0.998046875, 0.87890625, 0.0400390625, 0.998046875, 0.9970703125, 0.998046875, 0.1591796875, 0.8994140625, 0.9970703125, 0.998046875, 0.998046875, 0.1455078125, 0.921875, 0.8857421875, 0.03515625, 0.0859375, 0.7978515625, 0.998046875, 0.21484375, 0.9931640625, 0.16796875, 0.01953125, 0.04296875, 0.998046875, 0.892578125, 0.998046875, 0.873046875, 0.998046875, 0.033203125, 0.998046875, 0.1201171875, 0.1484375, 0.095703125, 0.798828125, 0.998046875, 0.9970703125, 0.3115234375, 0.087890625, 0.111328125, 0.904296875, 0.0244140625, 0.0322265625, 0.08203125, 0.083984375, 0.8310546875, 0.9228515625, 0.99609375, 0.998046875, 0.998046875, 0.0751953125, 0.998046875, 0.0283203125, 0.998046875, 0.998046875, 0.0185546875, 0.0673828125, 0.01171875, 0.9970703125, 0.9990234375, 0.828125, 0.427734375, 0.998046875, 0.998046875, 0.1494140625, 0.0361328125, 0.0419921875, 0.998046875, 0.998046875, 0.9970703125, 0.8984375, 0.9970703125, 0.8984375, 0.998046875, 0.095703125, 0.046875, 0.0576171875, 0.08203125, 0.125, 0.1611328125, 0.919921875, 0.08203125, 0.0673828125, 0.029296875, 0.9970703125, 0.078125, 0.1435546875, 0.8583984375, 0.9521484375, 0.998046875, 0.0859375, 0.7587890625, 0.0751953125, 0.8125, 0.146484375, 0.89453125, 0.0595703125, 0.1845703125, 0.6728515625, 0.9462890625, 0.998046875, 0.998046875, 0.998046875, 0.9130859375, 0.1064453125, 0.1376953125, 0.998046875, 0.123046875, 0.890625, 0.7861328125, 0.873046875, 0.009765625, 0.091796875, 0.166015625, 0.154296875, 0.9970703125, 0.0927734375, 0.146484375, 0.1455078125, 0.01953125, 0.0703125, 0.998046875, 0.9970703125, 0.998046875, 0.8984375, 0.998046875, 0.09375, 0.0732421875, 0.9970703125, 0.080078125, 0.9990234375, 0.998046875, 0.037109375, 0.091796875, 0.1513671875, 0.173828125, 0.0263671875, 0.2265625, 0.998046875, 0.0068359375, 0.037109375, 0.998046875, 0.099609375, 0.0712890625, 0.998046875, 0.0458984375, 0.1328125, 0.1513671875, 0.0390625, 0.0888671875, 0.0693359375, 0.205078125, 0.1064453125, 0.033203125, 0.0654296875, 0.998046875, 0.9990234375, 0.794921875, 0.998046875, 0.998046875, 0.01171875, 0.9970703125, 0.0341796875, 0.8583984375, 0.033203125, 0.998046875, 0.931640625, 0.998046875, 0.998046875, 0.99609375, 0.111328125, 0.99609375, 0.904296875, 0.9140625, 0.05078125, 0.998046875, 0.0595703125, 0.1953125, 0.0537109375, 0.9228515625, 0.0390625, 0.046875, 0.947265625, 0.998046875, 0.0771484375, 0.10546875, 0.9208984375, 0.154296875, 0.998046875, 0.041015625, 0.998046875, 0.0654296875, 0.998046875, 0.10546875, 0.1689453125, 0.0576171875, 0.8984375, 0.865234375, 0.998046875, 0.0849609375, 0.0341796875, 0.998046875, 0.8076171875, 0.0, 0.04296875, 0.998046875, 0.998046875, 0.015625, 0.1708984375, 0.0927734375, 0.185546875, 0.041015625, 0.998046875, 0.9970703125, 0.896484375, 0.037109375, 0.13671875, 0.1220703125, 0.7763671875, 0.0400390625, 0.9970703125, 0.111328125, 0.4365234375, 0.03125, 0.998046875, 0.998046875, 0.033203125]

 sparsity of   [0.0017361111240461469, 0.9344618320465088, 0.0416666679084301, 0.0590277798473835, 0.3741319477558136, 0.0677083358168602, 0.0642361119389534, 0.819444477558136, 0.0421006940305233, 0.0577256940305233, 0.9986979365348816, 0.02864583395421505, 0.0381944440305233, 0.03081597201526165, 0.013454861007630825, 0.0373263880610466, 0.8550347089767456, 0.0034722222480922937, 0.913194477558136, 0.1341145783662796, 0.0364583320915699, 0.02690972201526165, 0.0659722238779068, 0.0407986119389534, 0.0030381944961845875, 0.0768229141831398, 0.1032986119389534, 0.01996527798473835, 0.007378472480922937, 0.0859375, 0.0290798619389534, 0.063368059694767, 0.8541666865348816, 0.823350727558136, 0.02387152798473835, 0.0703125, 0.013020833022892475, 0.02951388992369175, 0.0034722222480922937, 0.0655381977558136, 0.6328125, 0.0034722222480922937, 0.5807291865348816, 0.0703125, 0.01953125, 0.0638020858168602, 0.8472222089767456, 0.4813368022441864, 0.0325520820915699, 0.0516493059694767, 0.9865451455116272, 0.0421006940305233, 0.0290798619389534, 0.8433159589767456, 0.0920138880610466, 0.0959201380610466, 0.0421006940305233, 0.0512152798473835, 0.7339409589767456, 0.0086805559694767, 0.05859375, 0.0546875, 0.0434027798473835, 0.9986979365348816, 0.9986979365348816, 0.0407986119389534, 0.1710069477558136, 0.2699652910232544, 0.01779513992369175, 0.253472238779068, 0.157986119389534, 0.2022569477558136, 0.0551215298473835, 0.0360243059694767, 0.0282118059694767, 0.999131977558136, 0.0390625, 0.0342881940305233, 0.0251736119389534, 0.0, 0.0355902798473835, 0.9995659589767456, 0.0611979179084301, 0.1059027761220932, 0.1527777761220932, 0.1128472238779068, 0.0334201380610466, 0.0186631940305233, 0.009982638992369175, 0.0442708320915699, 0.01128472201526165, 0.0434027798473835, 0.0451388880610466, 0.0403645820915699, 0.0373263880610466, 0.11328125, 0.0703125, 0.0321180559694767, 0.0763888880610466, 0.0842013880610466, 0.3815104067325592, 0.140625, 0.09375, 0.0785590261220932, 0.0243055559694767, 0.01605902798473835, 0.725694477558136, 0.0282118059694767, 0.0, 0.0494791679084301, 0.02300347201526165, 0.0724826380610466, 0.0438368059694767, 0.01996527798473835, 0.0490451380610466, 0.0620659738779068, 0.6775173544883728, 0.999131977558136, 0.01996527798473835, 0.0603298619389534, 0.0486111119389534, 0.03125, 0.009982638992369175, 0.0911458358168602, 0.0212673619389534, 0.0855034738779068, 0.0494791679084301, 0.0316840298473835, 0.8619791865348816, 0.0203993059694767, 0.0724826380610466, 0.694444477558136, 0.0412326380610466, 0.0473090298473835, 0.0564236119389534, 0.02213541604578495, 0.0490451380610466, 0.1315104216337204, 0.0390625, 0.8645833134651184, 0.01605902798473835, 0.01519097201526165, 0.009548611007630825, 0.0460069440305233, 0.071180559694767, 0.7708333134651184, 0.0928819477558136, 0.7400173544883728, 0.0407986119389534, 0.9075520634651184, 0.009548611007630825, 0.2404513955116272, 0.01909722201526165, 0.944444477558136, 0.4127604067325592, 0.0490451380610466, 0.0368923619389534, 0.02473958395421505, 0.0447048619389534, 0.0434027798473835, 0.02994791604578495, 0.01215277798473835, 0.1488715261220932, 0.0967881977558136, 0.0577256940305233, 0.013888888992369175, 0.0512152798473835, 0.6575520634651184, 0.0460069440305233, 0.0473090298473835, 0.0347222238779068, 0.2113715261220932, 0.0373263880610466, 0.9188368320465088, 0.02864583395421505, 0.2135416716337204, 0.0368923619389534, 0.0533854179084301, 0.01822916604578495, 0.5590277910232544, 0.0390625, 0.0321180559694767, 0.01779513992369175, 0.0651041641831398, 0.0811631977558136, 0.0212673619389534, 0.067274309694767, 0.01822916604578495, 0.5525173544883728, 0.02864583395421505, 0.2682291567325592, 0.009548611007630825, 0.02083333395421505, 0.0598958320915699, 0.0243055559694767, 0.0490451380610466, 0.0173611119389534, 0.0225694440305233, 0.0334201380610466, 0.0407986119389534, 0.0203993059694767, 0.999131977558136, 0.01128472201526165, 0.2074652761220932, 0.0442708320915699, 0.0, 0.0, 0.0421006940305233, 0.0421006940305233, 0.1506076455116272, 0.0889756977558136, 0.013020833022892475, 0.067274309694767, 0.082899309694767, 0.0329861119389534, 0.0846354141831398, 0.0390625, 0.063368059694767, 0.0490451380610466, 0.7738715410232544, 0.7660590410232544, 0.9995659589767456, 0.009548611007630825, 0.01779513992369175, 0.0125868059694767, 0.0529513880610466, 0.8875868320465088, 0.1323784738779068, 0.0486111119389534, 0.0, 0.6067708134651184, 0.0251736119389534, 0.009982638992369175, 0.0390625, 0.577256977558136, 0.02300347201526165, 0.005642361007630825, 0.0407986119389534, 0.0455729179084301, 0.0616319440305233, 0.00824652798473835, 0.5316840410232544, 0.1206597238779068, 0.0455729179084301, 0.1028645858168602, 0.0720486119389534, 0.0173611119389534, 0.063368059694767, 0.0520833320915699, 0.013888888992369175, 0.01215277798473835, 0.3767361044883728, 0.831163227558136, 0.0889756977558136, 0.1944444477558136, 0.0425347238779068]

 sparsity of   [0.98828125, 0.99609375, 0.06640625, 0.85546875, 0.9921875, 0.9921875, 0.9921875, 0.14453125, 0.9921875, 0.17578125, 0.9921875, 0.05859375, 0.0625, 0.9921875, 0.0625, 0.98828125, 0.9921875, 0.9921875, 0.0625, 0.99609375, 0.078125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9375, 0.09765625, 0.99609375, 0.98828125, 0.98828125, 0.98828125, 0.9921875, 0.99609375, 0.98828125, 0.07421875, 0.99609375, 0.98828125, 0.99609375, 0.00390625, 0.0625, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.21484375, 0.0703125, 0.99609375, 0.0546875, 0.9921875, 0.99609375, 0.0625, 0.9921875, 0.40234375, 0.109375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.171875, 0.9921875, 0.12109375, 0.9921875, 0.99609375, 0.99609375, 0.99609375, 0.7265625, 0.0625, 0.1484375, 0.37890625, 0.0, 0.9921875, 0.0625, 0.02734375, 0.06640625, 0.16796875, 0.05859375, 0.16015625, 0.05078125, 0.9921875, 0.109375, 0.99609375, 0.15234375, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.00390625, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0078125, 0.05078125, 0.3828125, 0.9921875, 0.9921875, 0.0546875, 0.0, 0.99609375, 0.9921875, 0.1328125, 0.90234375, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.0625, 0.9921875, 0.9921875, 0.99609375, 0.06640625, 0.9921875, 0.98828125, 0.0703125, 0.99609375, 0.18359375, 0.11328125, 0.09765625, 0.99609375, 0.05859375, 0.9921875, 0.99609375, 0.13671875, 0.98828125, 0.99609375, 0.9921875, 0.80078125, 0.9921875, 0.9921875, 0.99609375, 0.13671875, 0.9921875, 0.9921875, 0.171875, 0.76953125, 0.9921875, 0.125, 0.99609375, 0.98828125, 0.9921875, 0.05859375, 0.9921875, 0.1015625, 0.08203125, 0.98828125, 0.9921875, 0.9921875, 0.078125, 0.08984375, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.99609375, 0.98828125, 0.19140625, 0.125, 0.9921875, 0.9921875, 0.00390625, 0.3125, 0.9921875, 0.9921875, 0.98828125, 0.984375, 0.9921875, 0.9921875, 0.13671875, 0.99609375, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.109375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0859375, 0.9921875, 0.99609375, 0.9921875, 0.03515625, 0.0546875, 0.9921875, 0.9921875, 0.9921875, 0.45703125, 0.99609375, 0.06640625, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.08203125, 0.11328125, 0.8515625, 0.9921875, 0.01953125, 0.9921875, 0.9921875, 0.98046875, 0.0, 0.08984375, 0.109375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.12109375, 0.0390625, 0.06640625, 0.9921875, 0.09375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.140625, 0.99609375, 0.9921875, 0.9921875, 0.98828125, 0.1015625, 0.2421875, 0.9921875, 0.99609375, 0.9921875, 0.32421875, 0.9921875, 0.99609375, 0.08984375, 0.9921875, 0.98828125, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.84375, 0.9921875, 0.9921875, 0.98828125, 0.99609375, 0.9921875, 0.984375, 0.98828125, 0.16015625, 0.98828125, 0.22265625, 0.06640625, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.0, 0.19921875, 0.9921875, 0.99609375, 0.9921875, 0.6953125, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.05078125, 0.98828125, 0.328125, 0.9921875, 0.05859375, 0.98828125, 0.06640625, 0.9921875, 0.10546875, 0.21875, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.2265625, 0.13671875, 0.9921875, 0.9921875, 0.0625, 0.98828125, 0.06640625, 0.99609375, 0.9921875, 0.98828125, 0.3125, 0.9921875, 0.1640625, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.046875, 0.17578125, 0.99609375, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.1015625, 0.99609375, 0.04296875, 0.0703125, 0.04296875, 0.98828125, 0.9921875, 0.99609375, 0.98828125, 0.05859375, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.98828125, 0.234375, 0.99609375, 0.0, 0.99609375, 0.77734375, 0.08203125, 0.1484375, 0.99609375, 0.98828125, 0.2578125, 0.0390625, 0.05859375, 0.98828125, 0.9921875, 0.9921875, 0.98828125, 0.12109375, 0.9921875, 0.99609375, 0.9921875, 0.21875, 0.88671875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.0859375, 0.16796875, 0.0, 0.02734375, 0.99609375, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.0703125, 0.81640625, 0.99609375, 0.98828125, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.99609375, 0.98828125, 0.89453125, 0.9921875, 0.9921875, 0.2890625, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.26953125, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.0390625, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.046875, 0.12109375, 0.0625, 0.99609375, 0.9921875, 0.0546875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.1015625, 0.9921875, 0.9921875, 0.9921875, 0.125, 0.0859375, 0.9921875, 0.9921875, 0.98828125, 0.05859375, 0.09765625, 0.98828125, 0.0546875, 0.99609375, 0.99609375, 0.984375, 0.21484375, 0.9921875, 0.26953125, 0.98828125, 0.0390625, 0.9921875, 0.07421875, 0.99609375, 0.9921875, 0.0859375, 0.99609375, 0.9921875, 0.99609375, 0.12890625, 0.9921875, 0.9921875, 0.08984375, 0.06640625, 0.9921875, 0.9921875, 0.17578125, 0.9921875, 0.99609375, 0.99609375, 0.9921875, 0.99609375, 0.03125, 0.98828125, 0.9921875, 0.1171875, 0.078125, 0.99609375, 0.06640625, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.98828125, 0.0625, 0.99609375, 0.0234375, 0.0234375, 0.9921875, 0.09765625, 0.0625, 0.9921875, 0.109375, 0.98828125, 0.9921875, 0.9921875, 0.34765625, 0.9921875, 0.0390625, 0.25, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.05078125, 0.109375, 0.0625, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.08984375, 0.02734375, 0.99609375, 0.14453125, 0.15234375, 0.9921875, 0.99609375, 0.09375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.08203125, 0.99609375, 0.0, 0.26171875, 0.98828125, 0.99609375, 0.0234375, 0.0390625, 0.0703125, 0.26171875, 0.99609375, 0.109375, 0.98828125, 0.9921875, 0.98828125, 0.40625, 0.99609375, 0.98828125, 0.98828125, 0.08984375, 0.98828125, 0.86328125, 0.99609375, 0.15234375, 0.99609375, 0.9921875, 0.9921875, 0.0703125, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.99609375, 0.99609375, 0.0, 0.12109375, 0.14453125, 0.12109375, 0.98828125, 0.09375, 0.9921875, 0.9921875, 0.99609375, 0.91015625, 0.9921875, 0.2265625, 0.10546875, 0.91796875, 0.046875, 0.99609375, 0.0234375, 0.9921875, 0.07421875, 0.99609375, 0.98828125, 0.03125, 0.22265625, 0.3125, 0.9921875, 0.03515625, 0.9921875, 0.9921875, 0.15234375, 0.99609375, 0.9921875, 0.05859375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.0, 0.19140625, 0.24609375, 0.99609375, 0.05078125, 0.08203125, 0.08203125, 0.99609375, 0.03125, 0.98828125, 0.99609375, 0.03515625, 0.76171875, 0.9921875, 0.9921875, 0.9921875, 0.0703125, 0.71875, 0.03125, 0.9921875, 0.0, 0.109375, 0.9921875, 0.98828125, 0.24609375, 0.9921875, 0.9921875, 0.26171875, 0.05078125, 0.06640625, 0.9921875, 0.8515625, 0.24609375, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.2578125, 0.9921875, 0.99609375, 0.98828125, 0.9921875, 0.15234375, 0.9921875, 0.08984375, 0.08203125, 0.9921875, 0.86328125, 0.98828125, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.16796875, 0.890625, 0.0703125, 0.1015625, 0.09765625, 0.234375, 0.9921875, 0.98828125, 0.99609375, 0.98828125, 0.09765625, 0.12109375, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.07421875, 0.99609375, 0.9921875, 0.9921875, 0.5546875, 0.98828125, 0.98828125, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.98828125, 0.0546875, 0.9921875, 0.0390625, 0.9921875, 0.99609375, 0.3125, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.9921875, 0.125, 0.9921875, 0.9921875, 0.9921875, 0.09765625, 0.9921875, 0.0390625, 0.11328125, 0.9921875, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.05078125, 0.9921875, 0.99609375, 0.9921875, 0.109375, 0.9921875, 0.9921875, 0.37890625, 0.12890625, 0.0546875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.13671875, 0.02734375, 0.21484375, 0.9921875, 0.0078125, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.0546875, 0.0703125, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.11328125, 0.10546875, 0.06640625, 0.99609375, 0.9921875, 0.1484375, 0.9921875, 0.9921875, 0.01953125, 0.9921875, 0.9921875, 0.08203125, 0.98828125, 0.9921875, 0.8046875, 0.9921875, 0.984375, 0.0, 0.109375, 0.98828125, 0.0859375, 0.9921875, 0.84375, 0.05859375, 0.15234375, 0.9921875, 0.12890625, 0.9921875, 0.05078125, 0.0, 0.1015625, 0.9921875, 0.9921875, 0.140625, 0.9921875, 0.9921875, 0.98828125, 0.14453125, 0.515625, 0.9921875, 0.40234375, 0.0546875, 0.98828125, 0.9921875, 0.9921875, 0.99609375, 0.99609375, 0.28125, 0.0, 0.9921875, 0.78515625, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.17578125, 0.9921875, 0.33203125, 0.98828125, 0.02734375, 0.9921875, 0.0234375, 0.9921875, 0.9921875, 0.85546875, 0.03515625, 0.06640625, 0.9921875, 0.99609375, 0.9921875, 0.0, 0.9921875, 0.078125, 0.9921875, 0.1640625, 0.9921875, 0.98828125, 0.359375, 0.2734375, 0.4375, 0.08203125, 0.99609375, 0.98828125, 0.99609375, 0.140625, 0.9921875, 0.09765625, 0.9921875, 0.9921875, 0.03515625, 0.9921875, 0.12109375, 0.9921875, 0.99609375, 0.99609375, 0.13671875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.921875, 0.9921875, 0.99609375, 0.04296875, 0.98828125, 0.9921875, 0.9921875, 0.98828125, 0.07421875, 0.9921875, 0.99609375, 0.9921875, 0.1875, 0.98828125, 0.9921875, 0.0234375, 0.1796875, 0.08984375, 0.13671875, 0.9921875, 0.13671875, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.9921875, 0.9921875, 0.99609375, 0.48828125, 0.9921875, 0.9921875, 0.9921875, 0.0, 0.9921875, 0.09765625, 0.9921875, 0.99609375, 0.9921875, 0.99609375, 0.3046875, 0.9921875, 0.99609375, 0.23828125, 0.23046875, 0.10546875, 0.05859375, 0.9921875, 0.9921875, 0.99609375, 0.12890625, 0.99609375, 0.98828125, 0.20703125, 0.9921875, 0.05859375, 0.9921875, 0.9921875, 0.1328125, 0.9921875, 0.04296875, 0.33203125, 0.9921875, 0.98828125, 0.984375, 0.99609375, 0.99609375, 0.34375, 0.9921875, 0.06640625, 0.98828125, 0.02734375, 0.99609375, 0.25390625, 0.9921875, 0.9921875, 0.9921875, 0.9921875, 0.04296875, 0.390625, 0.9921875, 0.98828125, 0.0703125, 0.91015625, 0.0, 0.99609375, 0.140625, 0.109375, 0.98828125, 0.05859375, 0.03515625, 0.99609375, 0.9921875, 0.33984375, 0.9921875, 0.0859375, 0.9921875, 0.9921875, 0.06640625, 0.99609375, 0.9921875, 0.9921875, 0.56640625, 0.98828125, 0.9921875, 0.9921875, 0.3828125, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9140625, 0.9921875, 0.99609375, 0.9921875, 0.9921875, 0.09375, 0.2109375, 0.04296875, 0.9921875, 0.9921875, 0.98828125, 0.9921875, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.0, 0.0546875, 0.9921875, 0.3984375, 0.09765625, 0.99609375, 0.98828125, 0.99609375, 0.15625, 0.98828125, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.015625, 0.08984375, 0.99609375, 0.9921875, 0.046875, 0.09375, 0.9921875, 0.98828125, 0.99609375, 0.9921875, 0.9921875, 0.44140625, 0.9921875, 0.9921875, 0.08984375, 0.0546875, 0.9921875, 0.2265625, 0.9921875, 0.08203125, 0.09765625, 0.0625, 0.9921875, 0.9921875, 0.0703125, 0.98828125, 0.28515625, 0.125, 0.99609375, 0.9921875, 0.9921875, 0.9921875, 0.99609375, 0.9921875, 0.98828125, 0.34375, 0.99609375, 0.9921875, 0.9921875, 0.0546875, 0.98828125]

 sparsity of   [0.998046875, 0.998046875, 0.998046875, 0.5380859375, 0.9990234375, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.99609375, 0.4501953125, 0.998046875, 0.9990234375, 0.998046875, 0.236328125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.3193359375, 0.998046875, 0.998046875, 0.998046875, 0.12890625, 0.998046875, 0.1259765625, 0.998046875, 0.9970703125, 0.1044921875, 0.998046875, 0.111328125, 0.9990234375, 0.998046875, 0.998046875, 0.9990234375, 0.9990234375, 0.0966796875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.4931640625, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.08984375, 0.2158203125, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.12109375, 0.9990234375, 0.998046875, 0.0947265625, 0.998046875, 0.0830078125, 0.998046875, 0.998046875, 0.2587890625, 0.9970703125, 0.998046875, 0.998046875, 0.10546875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.103515625, 0.998046875, 0.998046875, 0.9990234375, 0.9990234375, 0.9990234375, 0.998046875, 0.9990234375, 0.0966796875, 0.998046875, 0.9990234375, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.0849609375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.4619140625, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.9990234375, 0.9990234375, 0.9990234375, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.44140625, 0.998046875, 0.9970703125, 0.998046875, 0.9990234375, 0.9990234375, 0.9990234375, 0.12109375, 0.9990234375, 0.998046875, 0.29296875, 0.998046875, 0.998046875, 0.0, 0.998046875, 0.998046875, 0.1005859375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.4765625, 0.998046875, 0.453125, 0.998046875, 0.0927734375, 0.998046875, 0.998046875, 0.998046875, 0.146484375, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.4716796875, 0.9970703125, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.27734375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.0, 0.998046875, 0.9990234375, 0.998046875, 0.9990234375, 0.9990234375, 0.998046875, 0.9990234375, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.4716796875, 0.998046875, 0.998046875, 0.9990234375, 0.3974609375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.134765625, 0.9990234375, 0.462890625, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.9990234375, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.2607421875, 0.998046875, 0.9990234375, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.869140625, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.0, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.9990234375, 0.998046875, 0.9990234375, 0.9970703125, 0.9970703125, 0.1435546875, 0.9990234375, 0.998046875, 0.9990234375, 0.2900390625, 0.998046875, 0.9970703125, 0.998046875, 0.1181640625, 0.099609375, 0.9990234375, 0.998046875, 0.998046875, 0.9970703125, 0.140625, 0.9970703125, 0.998046875, 0.427734375, 0.1181640625, 0.85546875, 0.998046875, 0.2421875, 0.3056640625, 0.998046875, 0.998046875, 0.998046875, 0.12109375, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.4521484375, 0.9990234375, 0.9970703125, 0.080078125, 0.9990234375, 0.9990234375, 0.107421875, 0.0, 0.998046875, 0.998046875, 0.837890625, 0.998046875, 0.998046875, 0.1416015625, 0.998046875, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.9990234375, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.4755859375, 0.2900390625, 0.1474609375, 0.998046875, 0.998046875, 0.998046875, 0.1103515625, 0.998046875, 0.9990234375, 0.267578125, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.7822265625, 0.9990234375, 0.998046875, 0.439453125, 0.998046875, 0.4453125, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.9990234375, 0.1552734375, 0.9970703125, 0.998046875, 0.998046875, 0.998046875, 0.2431640625, 0.998046875, 0.998046875, 0.279296875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.9970703125, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.9990234375, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.4951171875, 0.998046875, 0.9990234375, 0.998046875, 0.095703125, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.966796875, 0.998046875, 0.1572265625, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.9990234375, 0.998046875, 0.08203125, 0.4521484375, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.0986328125, 0.998046875, 0.1005859375, 0.548828125, 0.9990234375, 0.998046875, 0.3564453125, 0.998046875, 0.998046875, 0.45703125, 0.998046875, 0.1201171875, 0.9990234375, 0.9990234375, 0.9970703125, 0.2490234375, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.1025390625, 0.998046875, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.4677734375, 0.0947265625, 0.9990234375, 0.998046875, 0.998046875, 0.9990234375, 0.9990234375, 0.998046875, 0.998046875, 0.998046875, 0.111328125, 0.9970703125, 0.2548828125, 0.1123046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.45703125, 0.1171875, 0.998046875, 0.1376953125, 0.998046875, 0.998046875, 0.1142578125, 0.9990234375, 0.998046875, 0.998046875]

 sparsity of   [0.989366352558136, 0.0703125, 0.8559027910232544, 0.9993489384651184, 0.9765625, 0.104383684694767, 0.01215277798473835, 0.9995659589767456, 0.048828125, 0.8200954794883728, 0.3426649272441864, 0.0865885391831398, 0.9887152910232544, 0.9084201455116272, 0.9995659589767456, 0.044921875, 0.1369357705116272, 0.9995659589767456, 0.308159738779068, 0.075086809694767, 0.9051649570465088, 0.9995659589767456, 0.9995659589767456, 0.9997829794883728, 0.9880642294883728, 0.0753038227558136, 0.8255208134651184, 0.0470920130610466, 0.864366352558136, 0.9997829794883728, 0.3292100727558136, 0.1241319477558136, 0.3040364682674408, 0.9852430820465088, 0.3407118022441864, 0.8990885615348816, 0.0889756977558136, 0.1888020783662796, 0.96875, 0.1447482705116272, 0.2447916716337204, 0.0492621548473835, 0.9995659589767456, 0.9995659589767456, 0.2265625, 0.0679253488779068, 0.337456613779068, 0.9997829794883728, 0.3715277910232544, 0.8372395634651184, 0.3309461772441864, 0.173611119389534, 0.0388454869389534, 0.9800347089767456, 0.1477864533662796, 0.060546875, 0.2549913227558136, 0.2528211772441864, 0.5512152910232544, 0.9498698115348816, 0.9995659589767456, 0.9995659589767456, 0.9175347089767456, 0.9995659589767456, 0.0342881940305233, 0.1108940988779068, 0.1349826455116272, 0.1484375, 0.0509982630610466, 0.1343315988779068, 0.9754774570465088, 0.1011284738779068, 0.2007378488779068, 0.3118489682674408, 0.0310329869389534, 0.7523871660232544, 0.8600260615348816, 0.1655815988779068, 0.0212673619389534, 0.6089409589767456, 0.9950087070465088, 0.9995659589767456, 0.7087673544883728, 0.9995659589767456, 0.0338541679084301, 0.0896267369389534, 0.2491319477558136, 0.9993489384651184, 0.0679253488779068, 0.4474826455116272, 0.2973090410232544, 0.1866319477558136, 0.9997829794883728, 0.991319477558136, 0.073133684694767, 0.2198350727558136, 0.1204427108168602, 0.9108073115348816, 0.6449652910232544, 0.4151475727558136, 0.3157552182674408, 0.9995659589767456, 0.9995659589767456, 0.1328125, 0.2934027910232544, 0.9995659589767456, 0.9911024570465088, 0.9995659589767456, 0.090711809694767, 0.9997829794883728, 0.7801649570465088, 0.7684462070465088, 0.1627604216337204, 0.982421875, 0.251953125, 0.108289934694767, 0.0368923619389534, 0.3059895932674408, 0.19140625, 0.265625, 0.1221788227558136, 0.8680555820465088, 0.132595494389534, 0.9995659589767456, 0.3483072817325592, 0.3546006977558136, 0.8923611044883728, 0.9995659589767456, 0.2860243022441864, 0.9995659589767456, 0.9995659589767456, 0.6371527910232544, 0.9997829794883728, 0.02886284701526165, 0.9696180820465088, 0.9858940839767456, 0.9930555820465088, 0.064453125, 0.9878472089767456, 0.8832465410232544, 0.075086809694767, 0.9939236044883728, 0.9993489384651184, 0.9911024570465088, 0.9995659589767456, 0.4166666567325592, 0.9865451455116272, 0.8342013955116272, 0.1052517369389534, 0.1690538227558136, 0.0655381977558136, 0.9995659589767456, 0.9993489384651184, 0.9995659589767456, 0.148220494389534, 0.347222238779068, 0.9995659589767456, 0.07421875, 0.0776909738779068, 0.9997829794883728, 0.9997829794883728, 0.2814670205116272, 0.9995659589767456, 0.0483940988779068, 0.9995659589767456, 0.3064236044883728, 0.8893229365348816, 0.9995659589767456, 0.8051215410232544, 0.3396267294883728, 0.982421875, 0.2337239533662796, 0.2456597238779068, 0.3528645932674408, 0.986328125, 0.0635850727558136, 0.9995659589767456, 0.134765625, 0.9995659589767456, 0.1310763955116272, 0.3565538227558136, 0.4275173544883728, 0.146267369389534, 0.9993489384651184, 0.1838107705116272, 0.751953125, 0.9995659589767456, 0.9995659589767456, 0.9997829794883728, 0.9995659589767456, 0.173828125, 0.4079861044883728, 0.9997829794883728, 0.9995659589767456, 0.9967448115348816, 0.0627170130610466, 0.9891493320465088, 0.9995659589767456, 0.9995659589767456, 0.3187934160232544, 0.9880642294883728, 0.9995659589767456, 0.8081597089767456, 0.0536024309694767, 0.9995659589767456, 0.0963541641831398, 0.2037760466337204, 0.2840711772441864, 0.1154513880610466, 0.9995659589767456, 0.8246527910232544, 0.1065538227558136, 0.072265625, 0.9450954794883728, 0.080078125, 0.4244791567325592, 0.1017795130610466, 0.9995659589767456, 0.0876736119389534, 0.2747395932674408, 0.0726996511220932, 0.214626744389534, 0.291015625, 0.8923611044883728, 0.9995659589767456, 0.9995659589767456, 0.0831163227558136, 0.9995659589767456, 0.6896701455116272, 0.2777777910232544, 0.02083333395421505, 0.0470920130610466, 0.173611119389534, 0.61328125, 0.329644113779068, 0.05859375, 0.9498698115348816, 0.9995659589767456, 0.0501302070915699, 0.0416666679084301, 0.0889756977558136, 0.9995659589767456, 0.9995659589767456, 0.3446180522441864, 0.9995659589767456, 0.12109375, 0.9787326455116272, 0.3142361044883728, 0.2111545205116272, 0.9997829794883728, 0.9027777910232544, 0.9993489384651184, 0.1475694477558136, 0.9995659589767456, 0.0414496548473835, 0.3211805522441864, 0.3650173544883728, 0.9995659589767456, 0.114149309694767, 0.4505208432674408, 0.3958333432674408, 0.1019965261220932, 0.9993489384651184, 0.1215277761220932, 0.12109375, 0.9995659589767456, 0.0807291641831398, 0.3231336772441864, 0.3806423544883728, 0.356987863779068, 0.2094184011220932, 0.9995659589767456, 0.7521701455116272, 0.9266493320465088, 0.9246962070465088, 0.9947916865348816, 0.9997829794883728, 0.0334201380610466, 0.3736979067325592, 0.1590711772441864, 0.4348958432674408, 0.7621527910232544, 0.0763888880610466, 0.9995659589767456, 0.9997829794883728, 0.3485243022441864, 0.0494791679084301, 0.2829861044883728, 0.869140625, 0.0347222238779068, 0.7821180820465088, 0.388671875, 0.0661892369389534, 0.9995659589767456, 0.9997829794883728, 0.8930121660232544, 0.9995659589767456, 0.0570746548473835, 0.1358506977558136, 0.8198784589767456, 0.02560763992369175, 0.3930121660232544, 0.9995659589767456, 0.3591579794883728, 0.8276909589767456, 0.0759548619389534, 0.0948350727558136, 0.0423177070915699, 0.3415798544883728, 0.9995659589767456, 0.8541666865348816, 0.240234375, 0.0598958320915699, 0.3168402910232544, 0.3098958432674408, 0.891710102558136, 0.120008684694767, 0.9993489384651184, 0.9997829794883728, 0.0551215298473835, 0.8684895634651184, 0.0959201380610466, 0.4544270932674408, 0.0520833320915699, 0.9997829794883728, 0.9995659589767456, 0.0811631977558136, 0.9995659589767456, 0.1091579869389534, 0.923828125, 0.1408420205116272, 0.037109375, 0.146484375, 0.9956597089767456, 0.0894097238779068, 0.9995659589767456, 0.125, 0.9995659589767456, 0.5032551884651184, 0.0353732630610466, 0.067274309694767, 0.0824652761220932, 0.7322048544883728, 0.183376744389534, 0.9995659589767456, 0.9997829794883728, 0.9995659589767456, 0.152126744389534, 0.9995659589767456, 0.3020833432674408, 0.9079861044883728, 0.9924045205116272, 0.9993489384651184, 0.3763020932674408, 0.9995659589767456, 0.0948350727558136, 0.3426649272441864, 0.1731770783662796, 0.0900607630610466, 0.9995659589767456, 0.9997829794883728, 0.9286024570465088, 0.0310329869389534, 0.9995659589767456, 0.9231770634651184, 0.2747395932674408, 0.9995659589767456, 0.9908854365348816, 0.1295572966337204, 0.347222238779068, 0.9157986044883728, 0.2174479216337204, 0.0601128488779068, 0.9995659589767456, 0.2022569477558136, 0.8402777910232544, 0.9995659589767456, 0.0774739608168602, 0.9995659589767456, 0.919921875, 0.114149309694767, 0.7417534589767456, 0.1653645783662796, 0.9993489384651184, 0.0785590261220932, 0.1032986119389534, 0.1087239608168602, 0.144314244389534, 0.1343315988779068, 0.021484375, 0.9010416865348816, 0.0555555559694767, 0.0386284738779068, 0.02951388992369175, 0.8023003339767456, 0.9995659589767456, 0.0963541641831398, 0.138454869389534, 0.8430989384651184, 0.9995659589767456, 0.222439244389534, 0.0583767369389534, 0.8884548544883728, 0.9995659589767456, 0.8383246660232544, 0.5099826455116272, 0.0792100727558136, 0.9016926884651184, 0.3079427182674408, 0.9997829794883728, 0.3519965410232544, 0.9995659589767456, 0.9741753339767456, 0.0355902798473835, 0.9993489384651184, 0.9995659589767456, 0.1178385391831398, 0.1100260391831398, 0.9904513955116272, 0.9993489384651184, 0.298394113779068, 0.577256977558136, 0.2198350727558136, 0.05859375, 0.0726996511220932, 0.3111979067325592, 0.939453125, 0.9259982705116272, 0.9993489384651184, 0.8650173544883728, 0.278862863779068, 0.09765625, 0.388671875, 0.1343315988779068, 0.3235677182674408, 0.9993489384651184, 0.9915364384651184, 0.1263020783662796, 0.2743055522441864, 0.356987863779068, 0.989366352558136, 0.9097222089767456, 0.9995659589767456, 0.0733506977558136, 0.2630208432674408, 0.4576822817325592, 0.9806857705116272, 0.1488715261220932, 0.3068576455116272, 0.1028645858168602, 0.3083767294883728, 0.0679253488779068, 0.9997829794883728, 0.1278211772441864, 0.9474826455116272, 0.0518663190305233, 0.343315988779068, 0.1432291716337204, 0.9995659589767456, 0.1167534738779068, 0.9997829794883728, 0.9908854365348816, 0.9995659589767456, 0.9995659589767456, 0.9995659589767456, 0.1712239533662796, 0.9995659589767456, 0.9995659589767456, 0.5006510615348816, 0.8786892294883728, 0.10546875, 0.3552517294883728, 0.3192274272441864, 0.9995659589767456, 0.9995659589767456, 0.0694444477558136, 0.6371527910232544, 0.0555555559694767, 0.9995659589767456, 0.1009114608168602, 0.7484809160232544, 0.1742621511220932, 0.9095051884651184, 0.9993489384651184, 0.0889756977558136, 0.3561197817325592, 0.0842013880610466, 0.0846354141831398, 0.7662760615348816, 0.102430559694767, 0.0668402761220932, 0.319878488779068, 0.9995659589767456, 0.9995659589767456, 0.4993489682674408, 0.090711809694767, 0.1076388880610466, 0.2482638955116272, 0.0768229141831398, 0.9995659589767456, 0.9407551884651184, 0.3174913227558136, 0.9194878339767456, 0.0568576380610466, 0.9995659589767456, 0.388237863779068, 0.078993059694767, 0.9995659589767456, 0.3365885317325592, 0.9448784589767456, 0.98828125, 0.9995659589767456]

 sparsity of   [0.958984375, 0.025390625, 0.44921875, 0.482421875, 0.009765625, 0.634765625, 0.494140625, 0.03515625, 0.443359375, 0.12109375, 0.013671875, 0.646484375, 0.09765625, 0.0, 0.75, 0.876953125, 0.97265625, 0.529296875, 0.455078125, 0.021484375, 0.115234375, 0.603515625, 0.021484375, 0.009765625, 0.060546875, 0.029296875, 0.0546875, 0.05078125, 0.05859375, 0.51171875, 0.599609375, 0.62890625, 0.529296875, 0.771484375, 0.96875, 0.412109375, 0.025390625, 0.3671875, 0.724609375, 0.005859375, 0.275390625, 0.455078125, 0.0234375, 0.99609375, 0.107421875, 0.0859375, 0.017578125, 0.435546875, 0.03125, 0.451171875, 0.06640625, 0.923828125, 0.474609375, 0.744140625, 0.005859375, 0.451171875, 0.052734375, 0.576171875, 0.970703125, 0.8359375, 0.009765625, 0.087890625, 0.009765625, 0.013671875, 0.03125, 0.080078125, 0.015625, 0.03515625, 0.041015625, 0.33984375, 0.896484375, 0.806640625, 0.578125, 0.556640625, 0.048828125, 0.505859375, 0.458984375, 0.970703125, 0.017578125, 0.447265625, 0.048828125, 0.01953125, 0.01171875, 0.443359375, 0.07421875, 0.5, 0.078125, 0.63671875, 0.97265625, 0.01171875, 0.1328125, 0.03125, 0.6484375, 0.458984375, 0.015625, 0.759765625, 0.48828125, 0.083984375, 0.587890625, 0.99609375, 0.556640625, 0.046875, 0.01171875, 0.736328125, 0.99609375, 0.001953125, 0.025390625, 0.052734375, 0.970703125, 0.705078125, 0.029296875, 0.138671875, 0.673828125, 0.44921875, 0.044921875, 0.5078125, 0.021484375, 0.0625, 0.634765625, 0.439453125, 0.810546875, 0.828125, 0.0, 0.904296875, 0.146484375, 0.015625, 0.021484375, 0.86328125, 0.0390625, 0.494140625, 0.0234375, 0.435546875, 0.861328125, 0.974609375, 0.0703125, 0.01953125, 0.037109375, 0.05859375, 0.03125, 0.611328125, 0.97265625, 0.451171875, 0.99609375, 0.455078125, 0.544921875, 0.052734375, 0.8125, 0.068359375, 0.111328125, 0.576171875, 0.599609375, 0.083984375, 0.509765625, 0.99609375, 0.0625, 0.359375, 0.943359375, 0.560546875, 0.404296875, 0.91015625, 0.03125, 0.806640625, 0.43359375, 0.0234375, 0.787109375, 0.619140625, 0.064453125, 0.474609375, 0.447265625, 0.5, 0.02734375, 0.625, 0.51171875, 0.744140625, 0.607421875, 0.068359375, 0.7890625, 0.423828125, 0.052734375, 0.955078125, 0.123046875, 0.265625, 0.439453125, 0.02734375, 0.43359375, 0.056640625, 0.072265625, 0.01953125, 0.75390625, 0.662109375, 0.97265625, 0.806640625, 0.037109375, 0.99609375, 0.833984375, 0.08984375, 0.013671875, 0.609375, 0.63671875, 0.041015625, 0.521484375, 0.89453125, 0.67578125, 0.103515625, 0.435546875, 0.974609375, 0.021484375, 0.244140625, 0.970703125, 0.970703125, 0.025390625, 0.427734375, 0.6328125, 0.486328125, 0.5390625, 0.5625, 0.05859375, 0.677734375, 0.53515625, 0.732421875, 0.455078125, 0.203125, 0.0078125, 0.02734375, 0.75390625, 0.017578125, 0.486328125, 0.0078125, 0.466796875, 0.03125, 0.673828125, 0.806640625, 0.158203125, 0.02734375, 0.787109375, 0.080078125, 0.037109375, 0.505859375, 0.916015625, 0.01171875, 0.521484375, 0.57421875, 0.5703125, 0.044921875, 0.03515625, 0.54296875, 0.033203125, 0.4609375, 0.03125, 0.626953125, 0.44140625, 0.015625, 0.08984375, 0.294921875, 0.044921875, 0.90625, 0.056640625, 0.693359375, 0.830078125, 0.04296875, 0.546875, 0.06640625, 0.51171875, 0.66015625, 0.05078125, 0.33203125, 0.01953125, 0.97265625, 0.037109375, 0.93359375, 0.859375, 0.939453125, 0.49609375, 0.0234375, 0.021484375, 0.517578125, 0.041015625, 0.0546875, 0.021484375, 0.142578125, 0.736328125, 0.28515625, 0.02734375, 0.458984375, 0.470703125, 0.025390625, 0.0625, 0.61328125, 0.62109375, 0.068359375, 0.9453125, 0.97265625, 0.3984375, 0.78515625, 0.53515625, 0.041015625, 0.970703125, 0.048828125, 0.80078125, 0.103515625, 0.056640625, 0.55859375, 0.0, 0.884765625, 0.5078125, 0.794921875, 0.0390625, 0.052734375, 0.83984375, 0.169921875, 0.83984375, 0.1875, 0.484375, 0.501953125, 0.47265625, 0.08984375, 0.0, 0.73046875, 0.513671875, 0.40625, 0.560546875, 0.59375, 0.517578125, 0.61328125, 0.783203125, 0.97265625, 0.705078125, 0.025390625, 0.982421875, 0.796875, 0.4453125, 0.04296875, 0.50390625, 0.435546875, 0.65625, 0.0703125, 0.90625, 0.068359375, 0.5078125, 0.51171875, 0.998046875, 0.5078125, 0.1171875, 0.658203125, 0.8828125, 0.482421875, 0.1171875, 0.306640625, 0.1875, 0.62109375, 0.97265625, 0.021484375, 0.029296875, 0.091796875, 0.615234375, 0.111328125, 0.685546875, 0.412109375, 0.970703125, 0.41015625, 0.046875, 0.0859375, 0.998046875, 0.447265625, 0.59765625, 0.02734375, 0.447265625, 0.9453125, 0.0, 0.083984375, 0.12109375, 0.5, 0.595703125, 0.140625, 0.138671875, 0.017578125, 0.6640625, 0.470703125, 0.83203125, 0.232421875, 0.603515625, 0.115234375, 0.44140625, 0.51953125, 0.046875, 0.970703125, 0.15234375, 0.044921875, 0.873046875, 0.919921875, 0.501953125, 0.97265625, 0.587890625, 0.001953125, 0.087890625, 0.580078125, 0.99609375, 0.01953125, 0.091796875, 0.626953125, 0.19140625, 0.763671875, 0.482421875, 0.41796875, 0.0234375, 0.626953125, 0.970703125, 0.99609375, 0.580078125, 0.099609375, 0.6796875, 0.455078125, 0.0, 0.169921875, 0.044921875, 0.3515625, 0.001953125, 0.771484375, 0.99609375, 0.705078125, 0.623046875, 0.51953125, 0.91796875, 0.01171875, 0.427734375, 0.369140625, 0.79296875, 0.73828125, 0.61328125, 0.548828125, 0.54296875, 0.201171875, 0.0234375, 0.439453125, 0.404296875, 0.970703125, 0.31640625, 0.00390625, 0.666015625, 0.029296875, 0.62890625, 0.89453125, 0.736328125, 0.041015625, 0.015625, 0.447265625, 0.01953125, 0.01953125, 0.09765625, 0.046875, 0.05078125, 0.0625, 0.009765625, 0.025390625, 0.46875, 0.662109375, 0.025390625, 0.669921875, 0.03125, 0.01953125, 0.69921875, 0.71875, 0.6015625, 0.99609375, 0.1328125, 0.62890625, 0.001953125, 0.5, 0.01953125, 0.07421875, 0.072265625, 0.029296875, 0.52734375, 0.44140625, 0.021484375, 0.06640625, 0.017578125, 0.01171875, 0.671875, 0.421875, 0.01171875, 0.828125, 0.154296875, 0.255859375, 0.607421875, 0.40625, 0.537109375, 0.609375, 0.064453125, 0.435546875, 0.009765625, 0.994140625, 0.48828125, 0.498046875, 0.650390625, 0.02734375, 0.0234375, 0.802734375, 0.494140625, 0.521484375, 0.150390625, 0.01171875, 0.02734375, 0.59375, 0.970703125, 0.439453125, 0.5078125, 0.86328125, 0.1171875, 0.265625, 0.845703125, 0.0859375, 0.462890625, 0.013671875, 0.970703125, 0.013671875, 0.001953125, 0.474609375, 0.73828125, 0.568359375, 0.47265625, 0.373046875, 0.994140625, 0.248046875, 0.0234375, 0.05859375, 0.013671875, 0.021484375, 0.12109375, 0.0390625, 0.04296875, 0.728515625, 0.625, 0.619140625, 0.498046875, 0.947265625, 0.525390625, 0.744140625, 0.03125, 0.755859375, 0.53125, 0.970703125, 0.0234375, 0.419921875, 0.173828125, 0.55859375, 0.123046875, 0.0703125, 0.064453125, 0.291015625, 0.853515625, 0.568359375, 0.623046875, 0.90625, 0.66015625, 0.021484375, 0.53125, 0.9296875, 0.51953125, 0.017578125, 0.005859375, 0.03125, 0.0234375, 0.0625, 0.201171875, 0.50390625, 0.025390625, 0.46875, 0.005859375, 0.03125, 0.1640625, 0.05859375, 0.580078125, 0.46484375, 0.46484375, 0.01953125, 0.60546875, 0.87109375, 0.97265625, 0.015625, 0.634765625, 0.029296875, 0.98828125, 0.962890625, 0.67578125, 0.03125, 0.095703125, 0.083984375, 0.83203125, 0.58984375, 0.240234375, 0.3671875, 0.498046875, 0.033203125, 0.025390625, 0.005859375, 0.140625, 0.140625, 0.005859375, 0.4609375, 0.9296875, 0.97265625, 0.033203125, 0.525390625, 0.52734375, 0.0, 0.541015625, 0.5234375, 0.49609375, 0.046875, 0.892578125, 0.623046875, 0.09765625, 0.048828125, 0.0703125, 0.455078125, 0.07421875, 0.458984375, 0.48828125, 0.5625, 0.017578125, 0.955078125, 0.97265625, 0.013671875, 0.466796875, 0.61328125, 0.01171875, 0.08203125, 0.884765625, 0.708984375, 0.466796875, 0.025390625, 0.005859375, 0.09765625, 0.455078125, 0.66015625, 0.99609375, 0.103515625, 0.56640625, 0.666015625, 0.6640625, 0.708984375, 0.015625, 0.021484375, 0.6171875, 0.04296875, 0.447265625, 0.970703125, 0.015625, 0.513671875, 0.99609375, 0.064453125, 0.021484375, 0.427734375, 0.013671875, 0.99609375, 0.044921875, 0.037109375, 0.51171875, 0.060546875, 0.123046875, 0.095703125, 0.03125, 0.45703125, 0.484375, 0.103515625, 0.119140625, 0.017578125, 0.56640625, 0.599609375, 0.201171875, 0.4609375, 0.0, 0.44921875, 0.103515625, 0.90625, 0.4609375, 0.03125, 0.0703125, 0.322265625, 0.0078125, 0.0, 0.044921875, 0.05859375, 0.662109375, 0.52734375, 0.05078125, 0.466796875, 0.45703125, 0.505859375, 0.064453125, 0.044921875, 0.205078125, 0.060546875, 0.04296875, 0.9296875, 0.45703125, 0.0234375, 0.021484375, 0.626953125, 0.970703125, 0.037109375, 0.44921875, 0.046875, 0.59375, 0.04296875, 0.060546875, 0.85546875, 0.515625, 0.990234375, 0.283203125, 0.62890625, 0.01953125, 0.0234375, 0.03515625, 0.970703125, 0.916015625, 0.828125, 0.25390625, 0.0234375, 0.166015625, 0.095703125, 0.609375, 0.560546875, 0.30859375, 0.0625, 0.49609375, 0.998046875, 0.021484375, 0.62890625, 0.140625, 0.501953125, 0.53515625, 0.603515625, 0.220703125, 0.578125, 0.46875, 0.005859375, 0.6640625, 0.169921875, 0.509765625, 0.037109375, 0.6328125, 0.0546875, 0.970703125, 0.095703125, 0.47265625, 0.060546875, 0.037109375, 0.03125, 0.029296875, 0.908203125, 0.49609375, 0.068359375, 0.447265625, 0.234375, 0.0, 0.017578125, 0.091796875, 0.005859375, 0.064453125, 0.455078125, 0.0234375, 0.482421875, 0.58203125, 0.048828125, 0.74609375, 0.640625, 0.01171875, 0.3671875, 0.0, 0.47265625, 0.462890625, 0.6328125, 0.0078125, 0.146484375, 0.4375, 0.10546875, 0.140625, 0.970703125, 0.013671875, 0.44921875, 0.970703125, 0.017578125, 0.853515625, 0.1015625, 0.02734375, 0.970703125, 0.033203125, 0.6015625, 0.0625, 0.09375, 0.017578125, 0.033203125, 0.0546875, 0.474609375, 0.48046875, 0.01171875, 0.97265625, 0.509765625, 0.013671875, 0.498046875, 0.17578125, 0.466796875, 0.134765625, 0.021484375, 0.06640625, 0.45703125, 0.013671875, 0.029296875, 0.380859375, 0.994140625, 0.4765625, 0.54296875, 0.01171875, 0.0234375, 0.52734375, 0.02734375, 0.44921875, 0.515625, 0.033203125, 0.021484375, 0.521484375, 0.5703125, 0.970703125, 0.0859375, 0.064453125, 0.0, 0.7734375, 0.14453125, 0.970703125, 0.51171875, 0.71875, 0.0078125, 0.1171875, 0.009765625, 0.15234375, 0.744140625, 0.875, 0.658203125, 0.650390625, 0.509765625, 0.166015625, 0.943359375, 0.45703125, 0.625, 0.697265625, 0.646484375, 0.02734375, 0.623046875, 0.01171875, 0.009765625, 0.041015625, 0.060546875, 0.091796875, 0.443359375, 0.490234375, 0.919921875, 0.041015625, 0.0546875, 0.0078125, 0.041015625, 0.888671875, 0.548828125, 0.1484375, 0.345703125, 0.953125, 0.484375, 0.5546875, 0.0390625, 0.9453125, 0.634765625, 0.017578125, 0.46484375, 0.0078125, 0.083984375, 0.0234375, 0.52734375, 0.080078125, 0.537109375, 0.009765625, 0.13671875, 0.97265625, 0.01953125, 0.0234375, 0.607421875, 0.044921875, 0.04296875, 0.02734375, 0.015625, 0.05859375, 0.421875, 0.99609375, 0.490234375, 0.6171875, 0.072265625, 0.66015625, 0.666015625, 0.927734375, 0.51171875, 0.48046875, 0.0625, 0.998046875, 0.005859375, 0.5390625, 0.0546875, 0.576171875, 0.5234375, 0.5390625, 0.021484375, 0.474609375, 0.041015625, 0.97265625, 0.001953125, 0.515625, 0.720703125, 0.0234375, 0.00390625, 0.01171875, 0.0234375, 0.01171875, 0.119140625, 0.0390625, 0.466796875, 0.00390625, 0.99609375, 0.970703125, 0.025390625, 0.634765625, 0.66015625, 0.013671875, 0.0, 0.009765625, 0.857421875, 0.0234375, 0.037109375, 0.625, 0.1015625, 0.095703125, 0.685546875, 0.0, 0.48828125, 0.2578125, 0.890625, 0.521484375, 0.806640625, 0.4375, 0.5078125, 0.435546875, 0.017578125, 0.6796875, 0.109375, 0.0, 0.67578125, 0.123046875, 0.603515625, 0.736328125, 0.033203125, 0.54296875, 0.009765625, 0.00390625, 0.916015625, 0.896484375, 0.1015625, 0.947265625, 0.998046875, 0.04296875, 0.095703125, 0.08203125, 0.576171875, 0.75, 0.025390625, 0.97265625, 0.88671875, 0.970703125, 0.421875, 0.068359375, 0.48046875, 0.66015625, 0.0078125, 0.287109375, 0.0390625, 0.029296875, 0.76171875, 0.17578125, 0.0234375, 0.00390625, 0.435546875, 0.546875, 0.490234375, 0.04296875, 0.435546875, 0.783203125, 0.009765625, 0.009765625, 0.04296875, 0.99609375, 0.044921875, 0.99609375, 0.033203125, 0.533203125, 0.3359375, 0.970703125, 0.77734375, 0.712890625, 0.97265625, 0.115234375, 0.603515625, 0.83203125, 0.490234375, 0.66015625, 0.033203125, 0.025390625, 0.177734375, 0.119140625, 0.470703125, 0.857421875, 0.970703125, 0.076171875, 0.44921875, 0.033203125, 0.47265625, 0.02734375, 0.037109375, 0.037109375, 0.99609375, 0.75390625, 0.896484375, 0.013671875, 0.716796875, 0.78515625, 0.54296875, 0.55859375, 0.603515625, 0.525390625, 0.8984375, 0.720703125, 0.037109375, 0.15625, 0.08203125, 0.171875, 0.4296875, 0.54296875, 0.4296875, 0.74609375, 0.07421875, 0.0546875, 0.0703125, 0.921875, 0.07421875, 0.6015625, 0.970703125, 0.0234375, 0.015625, 0.01953125, 0.408203125, 0.626953125, 0.07421875, 0.0, 0.01171875, 0.93359375, 0.09375, 0.0625, 0.029296875, 0.056640625, 0.015625, 0.6796875, 0.65234375, 0.994140625, 0.04296875, 0.005859375, 0.619140625, 0.7890625, 0.396484375, 0.90625, 0.830078125, 0.119140625, 0.1171875, 0.607421875, 0.01953125, 0.7578125, 0.109375, 0.181640625, 0.052734375, 0.380859375, 0.740234375, 0.025390625, 0.005859375, 0.529296875, 0.12109375, 0.69140625, 0.671875, 0.4453125, 0.306640625, 0.126953125, 0.05859375, 0.642578125, 0.169921875, 0.99609375, 0.3515625, 0.0234375, 0.0546875, 0.75390625, 0.10546875, 0.79296875, 0.1796875, 0.5390625, 0.083984375, 0.0390625, 0.888671875, 0.095703125, 0.01171875, 0.068359375, 0.794921875, 0.89453125, 0.998046875, 0.0078125, 0.671875, 0.455078125, 0.53515625, 0.4921875, 0.015625, 0.056640625, 0.076171875, 0.458984375, 0.939453125, 0.751953125, 0.025390625, 0.90625, 0.646484375, 0.62890625, 0.49609375, 0.025390625, 0.91015625, 0.0546875, 0.443359375, 0.021484375, 0.548828125, 0.59765625, 0.0859375, 0.76171875, 0.017578125, 0.736328125, 0.0, 0.57421875, 0.66015625, 0.029296875, 0.884765625, 0.28515625, 0.31640625, 0.970703125, 0.43359375, 0.578125, 0.857421875, 0.970703125, 0.365234375, 0.212890625, 0.638671875, 0.490234375, 0.44140625, 0.048828125, 0.97265625, 0.451171875, 0.455078125, 0.71875, 0.958984375, 0.67578125, 0.109375, 0.6015625, 0.29296875, 0.404296875, 0.107421875, 0.09375, 0.0234375, 0.767578125, 0.609375, 0.34375, 0.62109375, 0.48046875, 0.216796875, 0.1171875, 0.087890625, 0.025390625, 0.75, 0.17578125, 0.873046875, 0.0234375, 0.53515625, 0.154296875, 0.595703125, 0.01953125, 0.5859375, 0.15625, 0.7109375, 0.0, 0.09765625, 0.02734375, 0.041015625, 0.037109375, 0.013671875, 0.11328125, 0.017578125, 0.05859375, 0.970703125, 0.85546875, 0.033203125, 0.955078125, 0.01953125, 0.0625, 0.013671875, 0.015625, 0.029296875, 0.97265625, 0.541015625, 0.068359375, 0.0, 0.998046875, 0.53125, 0.53515625, 0.15625, 0.046875, 0.466796875, 0.451171875, 0.998046875, 0.029296875, 0.763671875, 0.818359375, 0.5234375, 0.458984375, 0.041015625, 0.005859375, 0.728515625, 0.552734375, 0.052734375, 0.48828125, 0.017578125, 0.015625, 0.009765625, 0.5390625, 0.00390625, 0.478515625, 0.119140625, 0.509765625, 0.603515625, 0.126953125, 0.744140625, 0.45703125, 0.677734375, 0.15625, 0.54296875, 0.529296875, 0.970703125, 0.033203125, 0.453125, 0.443359375, 0.6796875, 0.060546875, 0.00390625, 0.048828125, 0.025390625, 0.009765625, 0.0703125, 0.640625, 0.7265625, 0.666015625, 0.10546875, 0.599609375, 0.283203125, 0.97265625, 0.021484375, 0.509765625, 0.48828125, 0.931640625, 0.859375, 0.06640625, 0.99609375, 0.01171875, 0.076171875, 0.76171875, 0.048828125, 0.037109375, 0.970703125, 0.125, 0.447265625, 0.552734375, 0.06640625, 0.97265625, 0.865234375, 0.095703125, 0.994140625, 0.453125, 0.095703125, 0.4296875, 0.06640625, 0.62109375, 0.99609375, 0.76953125, 0.158203125, 0.498046875, 0.486328125, 0.724609375, 0.013671875, 0.51953125, 0.361328125, 0.0234375, 0.994140625, 0.794921875, 0.462890625, 0.458984375, 0.0, 0.498046875, 0.298828125, 0.017578125, 0.486328125, 0.541015625, 0.041015625, 0.05859375, 0.05078125, 0.57421875, 0.529296875, 0.994140625, 0.03125, 0.2421875, 0.501953125, 0.0, 0.02734375, 0.4296875, 0.845703125, 0.671875, 0.486328125, 0.875, 0.625, 0.994140625, 0.2265625, 0.056640625, 0.619140625, 0.443359375, 0.0, 0.662109375, 0.021484375, 0.041015625, 0.865234375, 0.630859375, 0.009765625, 0.46875, 0.830078125, 0.470703125, 0.16015625, 0.015625, 0.0703125, 0.99609375, 0.857421875, 0.560546875, 0.109375, 0.033203125, 0.47265625, 0.09375, 0.99609375, 0.4140625, 0.005859375, 0.998046875, 0.505859375, 0.509765625, 0.01171875, 0.72265625, 0.486328125, 0.75390625, 0.017578125, 0.71875, 0.728515625, 0.017578125, 0.06640625, 0.076171875, 0.021484375, 0.35546875, 0.046875, 0.630859375, 0.619140625, 0.427734375, 0.02734375, 0.66796875, 0.90234375, 0.115234375, 0.041015625, 0.5859375, 0.005859375, 0.01171875, 0.49609375, 0.623046875, 0.1796875, 0.53515625, 0.642578125, 0.53515625, 0.478515625, 0.06640625, 0.994140625, 0.671875, 0.462890625, 0.009765625, 0.740234375, 0.43359375, 0.025390625, 0.5, 0.01171875, 0.533203125, 0.025390625, 0.85546875, 0.03515625, 0.38671875, 0.025390625, 0.041015625, 0.0390625, 0.0546875, 0.451171875, 0.623046875, 0.01171875, 0.474609375, 0.03125, 0.603515625, 0.97265625, 0.50390625, 0.419921875, 0.453125, 0.08203125, 0.7890625, 0.021484375, 0.234375, 0.44921875, 0.44140625, 0.513671875, 0.8515625, 0.611328125, 0.46875, 0.115234375, 0.041015625, 0.50390625, 0.01171875, 0.001953125, 0.005859375, 0.28125, 0.5234375, 0.0078125, 0.6171875, 0.134765625, 0.1328125, 0.6875, 0.05078125, 0.9921875, 0.005859375, 0.611328125, 0.658203125, 0.65234375, 0.76171875, 0.078125, 0.064453125, 0.03125, 0.0234375, 0.556640625, 0.056640625, 0.015625, 0.53515625, 0.04296875, 0.970703125, 0.015625, 0.046875, 0.443359375, 0.85546875, 0.66796875, 0.08203125, 0.013671875, 0.744140625, 0.646484375, 0.650390625, 0.037109375, 0.650390625, 0.06640625, 0.041015625, 0.033203125, 0.01953125, 0.669921875, 0.185546875, 0.94140625, 0.759765625, 0.01953125, 0.404296875, 0.052734375, 0.01171875, 0.06640625, 0.7890625, 0.134765625, 0.517578125, 0.01953125, 0.041015625, 0.138671875, 0.02734375, 0.998046875, 0.65234375, 0.298828125, 0.53125, 0.08984375, 0.033203125, 0.162109375, 0.505859375, 0.03125, 0.23828125, 0.271484375, 0.994140625, 0.072265625, 0.029296875, 0.0234375, 0.017578125, 0.443359375, 0.45703125, 0.689453125, 0.052734375, 0.634765625, 0.013671875, 0.998046875, 0.5390625, 0.0078125, 0.615234375, 0.521484375, 0.62109375, 0.033203125, 0.701171875, 0.001953125, 0.837890625, 0.046875, 0.576171875, 0.509765625, 0.689453125, 0.5703125, 0.509765625, 0.048828125, 0.03125, 0.49609375, 0.45703125, 0.44921875, 0.447265625, 0.662109375, 0.431640625, 0.45703125, 0.0859375, 0.44140625, 0.03125, 0.015625, 0.49609375, 0.513671875, 0.806640625, 0.31640625, 0.970703125, 0.84765625, 0.0859375, 0.072265625, 0.623046875, 0.470703125, 0.62109375, 0.630859375, 0.033203125, 0.03515625, 0.017578125, 0.0234375, 0.0625, 0.482421875, 0.1328125, 0.0625, 0.0, 0.021484375, 0.087890625, 0.01171875, 0.568359375, 0.662109375, 0.453125, 0.296875, 0.47265625, 0.044921875, 0.998046875, 0.876953125, 0.1484375, 0.283203125, 0.0625, 0.6640625, 0.048828125, 0.62890625, 0.0703125, 0.6484375, 0.51171875, 0.03515625, 0.02734375, 0.05078125, 0.048828125, 0.970703125, 0.619140625, 0.1875, 0.017578125, 0.83203125, 0.4921875, 0.92578125, 0.998046875, 0.041015625, 0.001953125, 0.693359375, 0.0, 0.099609375, 0.546875, 0.591796875, 0.94140625, 0.58984375, 0.103515625, 0.009765625, 0.884765625, 0.97265625, 0.044921875, 0.443359375, 0.515625, 0.998046875, 0.0, 0.068359375, 0.080078125, 0.08984375, 0.80078125, 0.0234375, 0.01171875, 0.08984375, 0.533203125, 0.017578125, 0.849609375, 0.048828125, 0.474609375, 0.72265625, 0.02734375, 0.751953125, 0.970703125, 0.08984375, 0.513671875, 0.572265625, 0.041015625, 0.76171875, 0.486328125, 0.015625, 0.02734375, 0.32421875, 0.8671875, 0.728515625, 0.693359375, 0.97265625, 0.724609375, 0.970703125, 0.80078125, 0.625, 0.04296875, 0.03515625, 0.029296875, 0.994140625, 0.01953125, 0.779296875, 0.56640625, 0.650390625, 0.859375, 0.8125, 0.4921875, 0.125, 0.015625, 0.998046875, 0.1171875, 0.125, 0.01953125, 0.220703125, 0.5078125, 0.53125, 0.083984375, 0.09765625, 0.4765625, 0.181640625, 0.087890625, 0.689453125, 0.00390625, 0.015625, 0.013671875, 0.009765625, 0.015625, 0.052734375, 0.44140625, 0.56640625, 0.994140625, 0.07421875, 0.005859375, 0.080078125, 0.013671875, 0.705078125, 0.01171875, 0.0, 0.8984375, 0.521484375, 0.09765625, 0.087890625, 0.0, 0.03125, 0.91796875, 0.904296875, 0.025390625, 0.64453125, 0.03515625, 0.505859375, 0.470703125, 0.0625, 0.67578125, 0.529296875, 0.013671875, 0.505859375, 0.591796875, 0.455078125, 0.455078125, 0.033203125, 0.572265625, 0.9453125, 0.576171875, 0.017578125, 0.033203125, 0.484375, 0.0078125, 0.2578125, 0.09765625, 0.88671875, 0.041015625, 0.97265625, 0.751953125, 0.27734375, 0.732421875, 0.033203125, 0.029296875, 0.24609375, 0.2109375, 0.271484375, 0.9140625, 0.912109375, 0.453125, 0.087890625, 0.0390625, 0.5625, 0.486328125, 0.97265625, 0.0546875, 0.009765625, 0.9765625, 0.587890625, 0.70703125, 0.107421875, 0.97265625, 0.08203125, 0.970703125, 0.646484375, 0.705078125, 0.021484375, 0.017578125, 0.03515625, 0.46484375, 0.759765625, 0.578125, 0.033203125, 0.650390625, 0.0, 0.16015625, 0.54296875, 0.04296875, 0.455078125, 0.037109375, 0.662109375, 0.0390625, 0.03515625, 0.521484375, 0.443359375, 0.021484375, 0.03125, 0.97265625, 0.97265625, 0.021484375, 0.07421875, 0.009765625, 0.669921875, 0.916015625, 0.771484375, 0.439453125, 0.970703125, 0.8125, 0.435546875, 0.12109375, 0.521484375, 0.033203125, 0.0234375, 0.052734375, 0.439453125, 0.716796875, 0.0234375, 0.03515625, 0.875, 0.07421875, 0.72265625, 0.037109375, 0.15625, 0.361328125, 0.888671875, 0.60546875, 0.009765625, 0.900390625, 0.109375, 0.484375, 0.447265625, 0.998046875, 0.02734375, 0.05859375, 0.474609375, 0.67578125, 0.970703125, 0.455078125, 0.65234375, 0.021484375, 0.470703125, 0.5234375, 0.005859375, 0.02734375, 0.43359375, 0.03515625, 0.896484375, 0.119140625, 0.46484375, 0.01953125, 0.55078125, 0.01171875, 0.435546875, 0.494140625, 0.05078125, 0.55859375, 0.943359375, 0.458984375, 0.01953125, 0.013671875, 0.017578125, 0.2578125, 0.01171875, 0.5078125, 0.69921875, 0.4140625, 0.6875, 0.005859375, 0.0390625, 0.57421875, 0.970703125, 0.970703125, 0.43359375, 0.296875, 0.53515625, 0.10546875, 0.087890625, 0.720703125, 0.341796875, 0.1015625, 0.84375, 0.666015625, 0.029296875, 0.876953125, 0.12890625, 0.4140625, 0.087890625, 0.080078125, 0.49609375, 0.970703125, 0.021484375, 0.490234375, 0.85546875, 0.015625, 0.529296875, 0.052734375, 0.611328125, 0.611328125, 0.08984375, 0.478515625, 0.04296875, 0.201171875, 0.013671875, 0.603515625, 0.037109375, 0.1484375, 0.041015625, 0.03515625, 0.625, 0.015625, 0.650390625, 0.6015625, 0.55078125, 0.12109375, 0.857421875, 0.15625, 0.177734375, 0.61328125, 0.970703125, 0.470703125, 0.0390625, 0.06640625, 0.255859375, 0.9609375, 0.015625, 0.04296875, 0.091796875, 0.076171875, 0.009765625, 0.203125, 0.115234375, 0.478515625, 0.673828125, 0.0625, 0.6015625, 0.994140625, 0.03125, 0.033203125, 0.443359375, 0.681640625, 0.970703125, 0.15625, 0.021484375, 0.513671875, 0.466796875, 0.056640625, 0.01953125, 0.97265625, 0.013671875, 0.0078125, 0.64453125, 0.51171875, 0.939453125, 0.728515625, 0.509765625, 0.021484375, 0.650390625, 0.62890625, 0.015625, 0.88671875, 0.166015625, 0.62890625, 0.158203125, 0.0390625, 0.046875, 0.65625, 0.03125, 0.666015625, 0.017578125, 0.6796875, 0.673828125, 0.029296875, 0.6953125, 0.0859375, 0.998046875, 0.96875, 0.59765625, 0.05078125, 0.462890625, 0.4609375, 0.05078125, 0.97265625, 0.943359375, 0.068359375, 0.017578125, 0.8125, 0.609375, 0.017578125, 0.056640625, 0.53125, 0.009765625, 0.587890625, 0.021484375, 0.546875, 0.0078125, 0.14453125, 0.47265625, 0.599609375, 0.99609375, 0.9375, 0.97265625, 0.640625, 0.033203125, 0.005859375, 0.810546875, 0.0078125, 0.43359375, 0.76171875, 0.986328125, 0.671875, 0.798828125, 0.443359375, 0.03125, 0.021484375, 0.87890625, 0.896484375, 0.8125, 0.0859375, 0.037109375, 0.03125, 0.3203125, 0.26953125, 0.509765625, 0.44921875, 0.955078125, 0.083984375, 0.001953125, 0.01171875, 0.919921875, 0.109375, 0.70703125, 0.296875, 0.005859375, 0.126953125, 0.017578125, 0.4453125, 0.91796875, 0.0546875, 0.02734375, 0.34375, 0.546875, 0.162109375, 0.041015625, 0.66796875, 0.208984375, 0.708984375, 0.005859375, 0.078125, 0.10546875, 0.728515625, 0.970703125, 0.052734375, 0.123046875, 0.009765625, 0.005859375, 0.01953125, 0.60546875, 0.4765625, 0.03515625, 0.7109375, 0.623046875, 0.005859375, 0.41015625, 0.578125, 0.97265625, 0.90234375, 0.591796875, 0.99609375, 0.037109375, 0.017578125, 0.630859375]

 sparsity of   [0.048828125, 0.0517578125, 0.0087890625, 0.0146484375, 0.3916015625, 0.087890625, 0.0791015625, 0.015625, 0.017578125, 0.9970703125, 0.126953125, 0.1044921875, 0.0029296875, 0.076171875, 0.00390625, 0.0380859375, 0.017578125, 0.1943359375, 0.00390625, 0.009765625, 0.00390625, 0.005859375, 0.0205078125, 0.0625, 0.0009765625, 0.0322265625, 0.0625, 0.0126953125, 0.1328125, 0.0009765625, 0.05078125, 0.0048828125, 0.0048828125, 0.0888671875, 0.0, 0.068359375, 0.1328125, 0.0029296875, 0.04296875, 0.056640625, 0.009765625, 0.0029296875, 0.0615234375, 0.0478515625, 0.044921875, 0.0380859375, 0.046875, 0.0390625, 0.025390625, 0.005859375, 0.03515625, 0.9970703125, 0.0126953125, 0.0068359375, 0.0, 0.0009765625, 0.099609375, 0.0068359375, 0.0791015625, 0.0185546875, 0.0087890625, 0.0048828125, 0.025390625, 0.8681640625, 0.9970703125, 0.0390625, 0.8134765625, 0.103515625, 0.0166015625, 0.0302734375, 0.0419921875, 0.30859375, 0.099609375, 0.0068359375, 0.138671875, 0.0087890625, 0.00390625, 0.005859375, 0.04296875, 0.083984375, 0.0166015625, 0.013671875, 0.0185546875, 0.0068359375, 0.1025390625, 0.00390625, 0.0146484375, 0.0576171875, 0.0, 0.8427734375, 0.0, 0.021484375, 0.8935546875, 0.0380859375, 0.8154296875, 0.09765625, 0.0029296875, 0.0087890625, 0.0107421875, 0.1337890625, 0.01171875, 0.1328125, 0.5703125, 0.1875, 0.12890625, 0.099609375, 0.06640625, 0.0078125, 0.0087890625, 0.0927734375, 0.0244140625, 0.0048828125, 0.0751953125, 0.0, 0.0400390625, 0.0107421875, 0.00390625, 0.095703125, 0.001953125, 0.1025390625, 0.0146484375, 0.236328125, 0.998046875, 0.078125, 0.046875, 0.0244140625, 0.01171875, 0.0693359375, 0.0703125, 0.005859375, 0.9970703125, 0.001953125, 0.021484375, 0.126953125, 0.013671875, 0.0537109375, 0.998046875, 0.0048828125, 0.041015625, 0.0087890625, 0.0, 0.01171875, 0.0458984375, 0.0849609375, 0.0048828125, 0.0185546875, 0.0537109375, 0.0166015625, 0.2021484375, 0.0009765625, 0.103515625, 0.939453125, 0.01171875, 0.0166015625, 0.025390625, 0.095703125, 0.1005859375, 0.1005859375, 0.076171875, 0.0068359375, 0.0244140625, 0.0244140625, 0.0908203125, 0.931640625, 0.080078125, 0.00390625, 0.5283203125, 0.10546875, 0.0087890625, 0.0283203125, 0.0205078125, 0.09375, 0.005859375, 0.0146484375, 0.0029296875, 0.0234375, 0.0341796875, 0.0029296875, 0.033203125, 0.330078125, 0.087890625, 0.0634765625, 0.0068359375, 0.0224609375, 0.0625, 0.0205078125, 0.03125, 0.0302734375, 0.27734375, 0.142578125, 0.0, 0.01171875, 0.017578125, 0.8037109375, 0.0087890625, 0.0234375, 0.1123046875, 0.0146484375, 0.0693359375, 0.01171875, 0.0185546875, 0.083984375, 0.0029296875, 0.0546875, 0.068359375, 0.0244140625, 0.0849609375, 0.0400390625, 0.0029296875, 0.0048828125, 0.0517578125, 0.1181640625, 0.0048828125, 0.005859375, 0.005859375, 0.0478515625, 0.9990234375, 0.009765625, 0.0029296875, 0.107421875, 0.0126953125, 0.2607421875, 0.1064453125, 0.0517578125, 0.0078125, 0.3095703125, 0.0087890625, 0.0751953125, 0.078125, 0.01953125, 0.0849609375, 0.0029296875, 0.01171875, 0.025390625, 0.0888671875, 0.0234375, 0.1171875, 0.0078125, 0.041015625, 0.0859375, 0.0068359375, 0.0029296875, 0.005859375, 0.0888671875, 0.951171875, 0.0234375, 0.0166015625, 0.087890625, 0.1240234375, 0.0107421875, 0.0625, 0.029296875, 0.0048828125, 0.0029296875, 0.0283203125, 0.0888671875, 0.037109375, 0.248046875, 0.880859375, 0.0107421875, 0.0068359375, 0.13671875, 0.005859375, 0.0048828125, 0.9970703125, 0.0, 0.0849609375, 0.0078125, 0.083984375, 0.0185546875, 0.8798828125, 0.0009765625, 0.013671875, 0.1103515625, 0.7666015625, 0.0126953125, 0.0146484375, 0.091796875, 0.09765625, 0.287109375, 0.0078125, 0.685546875, 0.24609375, 0.015625, 0.0078125, 0.0869140625, 0.0615234375, 0.0107421875, 0.087890625, 0.0087890625, 0.072265625, 0.009765625, 0.076171875, 0.103515625, 0.005859375, 0.2900390625, 0.0068359375, 0.0087890625, 0.009765625, 0.0, 0.0439453125, 0.09375, 0.0224609375, 0.0107421875, 0.0, 0.00390625, 0.0166015625, 0.0390625, 0.03515625, 0.0302734375, 0.0302734375, 0.0458984375, 0.0087890625, 0.0068359375, 0.0029296875, 0.048828125, 0.06640625, 0.0, 0.107421875, 0.0654296875, 0.013671875, 0.013671875, 0.00390625, 0.0087890625, 0.029296875, 0.0, 0.00390625, 0.0185546875, 0.794921875, 0.0166015625, 0.01171875, 0.0615234375, 0.0029296875, 0.0029296875, 0.0302734375, 0.0, 0.0107421875, 0.0693359375, 0.0185546875, 0.1142578125, 0.00390625, 0.0546875, 0.0068359375, 0.015625, 0.0654296875, 0.0009765625, 0.1416015625, 0.037109375, 0.0107421875, 0.013671875, 0.0, 0.060546875, 0.248046875, 0.0, 0.0078125, 0.1220703125, 0.9619140625, 0.001953125, 0.001953125, 0.005859375, 0.0, 0.01171875, 0.0478515625, 0.0068359375, 0.013671875, 0.21875, 0.0009765625, 0.013671875, 0.0, 0.70703125, 0.025390625, 0.0419921875, 0.0078125, 0.0234375, 0.1904296875, 0.06640625, 0.0009765625, 0.0048828125, 0.04296875, 0.095703125, 0.0048828125, 0.3173828125, 0.0126953125, 0.0166015625, 0.869140625, 0.0048828125, 0.0244140625, 0.9970703125, 0.96875, 0.00390625, 0.0048828125, 0.09375, 0.0166015625, 0.6533203125, 0.03125, 0.0068359375, 0.015625, 0.0185546875, 0.0234375, 0.04296875, 0.0380859375, 0.015625, 0.00390625, 0.01171875, 0.037109375, 0.0068359375, 0.005859375, 0.2412109375, 0.0107421875, 0.130859375, 0.0615234375, 0.10546875, 0.9970703125, 0.0966796875, 0.9970703125, 0.9990234375, 0.173828125, 0.001953125, 0.0244140625, 0.0927734375, 0.0126953125, 0.1162109375, 0.05859375, 0.01171875, 0.0126953125, 0.0009765625, 0.0966796875, 0.0068359375, 0.001953125, 0.00390625, 0.0087890625, 0.0048828125, 0.0244140625, 0.072265625, 0.0078125, 0.033203125, 0.0048828125, 0.037109375, 0.0205078125, 0.1923828125, 0.0859375, 0.0400390625, 0.0087890625, 0.013671875, 0.0166015625, 0.048828125, 0.23046875, 0.01171875, 0.9970703125, 0.033203125, 0.017578125, 0.046875, 0.0341796875, 0.20703125, 0.01171875, 0.095703125, 0.0224609375, 0.041015625, 0.09375, 0.0322265625, 0.0009765625, 0.0234375, 0.0146484375, 0.083984375, 0.0, 0.0009765625, 0.5927734375, 0.00390625, 0.0087890625, 0.1025390625, 0.04296875, 0.0126953125, 0.015625, 0.107421875, 0.0146484375, 0.02734375, 0.875, 0.0244140625, 0.0078125, 0.1005859375, 0.822265625, 0.09375, 0.005859375, 0.7724609375, 0.005859375, 0.0576171875, 0.2138671875, 0.0029296875, 0.0966796875, 0.0009765625, 0.05078125, 0.0595703125, 0.26171875, 0.0107421875, 0.0576171875, 0.0146484375, 0.0087890625, 0.0322265625, 0.0048828125, 0.0087890625, 0.0, 0.1123046875, 0.4541015625, 0.01171875, 0.0029296875, 0.4775390625, 0.0205078125, 0.064453125, 0.03515625, 0.0107421875, 0.091796875, 0.013671875, 0.0439453125, 0.0390625, 0.009765625, 0.8134765625, 0.033203125, 0.00390625, 0.08984375, 0.00390625, 0.052734375, 0.0185546875, 0.5595703125, 0.03515625, 0.0166015625, 0.9970703125, 0.060546875, 0.0302734375, 0.01171875, 0.02734375, 0.0986328125, 0.0107421875, 0.0849609375, 0.0, 0.005859375, 0.044921875, 0.0087890625, 0.0048828125, 0.0224609375, 0.0, 0.0048828125, 0.0048828125, 0.7080078125, 0.0498046875, 0.0341796875, 0.0078125, 0.0263671875, 0.09375, 0.1630859375, 0.005859375, 0.009765625, 0.009765625, 0.03515625, 0.0810546875, 0.03515625, 0.041015625, 0.0068359375, 0.2939453125, 0.009765625, 0.083984375, 0.388671875, 0.0302734375, 0.8193359375, 0.1044921875, 0.0234375, 0.0107421875, 0.9970703125, 0.091796875, 0.15234375, 0.07421875, 0.0234375, 0.0595703125, 0.08984375, 0.0009765625, 0.0029296875, 0.0693359375, 0.197265625, 0.0361328125, 0.005859375, 0.03515625, 0.0185546875, 0.1845703125, 0.0166015625, 0.03125, 0.9580078125, 0.017578125, 0.0, 0.0068359375, 0.103515625, 0.1787109375, 0.0966796875, 0.1181640625, 0.005859375, 0.9970703125, 0.2451171875, 0.01953125, 0.068359375, 0.005859375, 0.8984375, 0.099609375, 0.0341796875, 0.0, 0.0322265625, 0.005859375, 0.0087890625, 0.0224609375, 0.01171875, 0.0107421875, 0.099609375, 0.0146484375, 0.02734375, 0.095703125, 0.087890625, 0.9970703125, 0.0693359375, 0.005859375, 0.953125, 0.0791015625, 0.0029296875, 0.0400390625, 0.0205078125, 0.1142578125, 0.0, 0.0498046875, 0.0078125, 0.06640625, 0.998046875, 0.1005859375, 0.0107421875, 0.01171875, 0.0029296875, 0.166015625, 0.9306640625, 0.939453125, 0.005859375, 0.0068359375, 0.037109375, 0.0048828125, 0.0029296875, 0.0048828125, 0.1728515625, 0.005859375, 0.091796875, 0.9228515625, 0.001953125, 0.998046875, 0.009765625, 0.005859375, 0.2763671875, 0.0126953125, 0.9970703125, 0.0244140625, 0.029296875, 0.0146484375, 0.0185546875, 0.337890625, 0.0263671875, 0.10546875, 0.0078125, 0.00390625, 0.001953125, 0.0947265625, 0.0166015625, 0.09375, 0.0078125, 0.01171875, 0.0078125, 0.771484375, 0.0087890625, 0.0078125, 0.0009765625, 0.01171875, 0.0302734375, 0.0234375, 0.00390625, 0.0146484375, 0.001953125, 0.205078125, 0.0517578125, 0.015625, 0.9384765625, 0.9228515625, 0.0048828125, 0.142578125, 0.005859375, 0.0595703125, 0.8642578125, 0.0048828125, 0.0029296875, 0.0, 0.0244140625, 0.8837890625, 0.9970703125, 0.052734375, 0.0283203125, 0.9990234375, 0.017578125, 0.015625, 0.068359375, 0.0986328125, 0.0029296875, 0.9970703125, 0.04296875, 0.0205078125, 0.021484375, 0.0185546875, 0.08203125, 0.0078125, 0.0107421875, 0.9140625, 0.0830078125, 0.0908203125, 0.044921875, 0.005859375, 0.015625, 0.009765625, 0.6259765625, 0.04296875, 0.0029296875, 0.322265625, 0.0009765625, 0.0048828125, 0.01171875, 0.08984375, 0.0029296875, 0.1201171875, 0.0751953125, 0.138671875, 0.19140625, 0.00390625, 0.1044921875, 0.0009765625, 0.015625, 0.005859375, 0.00390625, 0.0166015625, 0.0048828125, 0.0263671875, 0.0126953125, 0.0224609375, 0.087890625, 0.015625, 0.0966796875, 0.0205078125, 0.0126953125, 0.078125, 0.1025390625, 0.8876953125, 0.7001953125, 0.029296875, 0.0859375, 0.1064453125, 0.091796875, 0.02734375, 0.01953125, 0.029296875, 0.025390625, 0.79296875, 0.0107421875, 0.017578125, 0.5693359375, 0.0517578125, 0.0703125, 0.0205078125, 0.0029296875, 0.111328125, 0.8076171875, 0.0419921875, 0.9990234375, 0.048828125, 0.07421875, 0.01953125, 0.017578125, 0.2978515625, 0.9970703125, 0.9970703125, 0.1064453125, 0.03125, 0.00390625, 0.0205078125, 0.1943359375, 0.01953125, 0.0986328125, 0.9140625, 0.080078125, 0.0390625, 0.00390625, 0.0419921875, 0.0302734375, 0.1181640625, 0.9990234375, 0.0146484375, 0.0283203125, 0.037109375, 0.2314453125, 0.0107421875, 0.0068359375, 0.87890625, 0.0, 0.0185546875, 0.0205078125, 0.103515625, 0.0302734375, 0.0859375, 0.05859375, 0.0205078125, 0.7587890625, 0.015625, 0.0390625, 0.078125, 0.0068359375, 0.009765625, 0.013671875, 0.0185546875, 0.9970703125, 0.0498046875, 0.08203125, 0.90234375, 0.0029296875, 0.0078125, 0.021484375, 0.9072265625, 0.01171875, 0.005859375, 0.009765625, 0.0625, 0.0087890625, 0.078125, 0.0859375, 0.025390625, 0.021484375, 0.095703125, 0.1044921875, 0.6552734375, 0.056640625, 0.130859375, 0.7451171875, 0.0380859375, 0.658203125, 0.0234375, 0.0986328125, 0.068359375, 0.021484375, 0.0185546875, 0.078125, 0.6796875, 0.025390625, 0.05859375, 0.83203125, 0.0888671875, 0.0322265625, 0.935546875, 0.025390625, 0.095703125, 0.0087890625, 0.0615234375, 0.0068359375, 0.1708984375, 0.0, 0.0322265625, 0.1640625, 0.0126953125, 0.029296875, 0.0, 0.0166015625, 0.1005859375, 0.08984375, 0.068359375, 0.0087890625, 0.3466796875, 0.123046875, 0.0068359375, 0.1943359375, 0.0126953125, 0.875, 0.0029296875, 0.1396484375, 0.0029296875, 0.0, 0.0078125, 0.044921875, 0.0439453125, 0.0673828125, 0.8544921875, 0.017578125, 0.0087890625, 0.037109375, 0.0068359375, 0.1552734375, 0.017578125, 0.0263671875, 0.001953125, 0.03515625, 0.0078125, 0.0107421875, 0.1103515625, 0.005859375, 0.0048828125, 0.0419921875, 0.0068359375, 0.0634765625, 0.0146484375, 0.01953125, 0.1083984375, 0.1181640625, 0.001953125, 0.0234375, 0.01171875, 0.0029296875, 0.9970703125, 0.01171875, 0.001953125, 0.0, 0.021484375, 0.0029296875, 0.0009765625, 0.7666015625, 0.068359375, 0.9970703125, 0.0185546875, 0.0576171875, 0.1162109375, 0.01171875, 0.005859375, 0.0234375, 0.091796875, 0.001953125, 0.07421875, 0.0732421875, 0.009765625, 0.06640625, 0.16015625, 0.0302734375, 0.9599609375, 0.0234375, 0.0908203125, 0.005859375, 0.0, 0.0, 0.1435546875, 0.0, 0.0166015625, 0.0048828125, 0.9990234375, 0.0712890625, 0.0419921875, 0.013671875, 0.00390625, 0.0029296875, 0.9658203125, 0.26171875, 0.015625, 0.005859375, 0.00390625, 0.068359375, 0.0654296875, 0.9013671875, 0.013671875, 0.013671875, 0.021484375, 0.0439453125, 0.005859375, 0.0458984375, 0.005859375, 0.966796875, 0.0126953125, 0.072265625, 0.01171875, 0.998046875, 0.0029296875, 0.005859375, 0.5322265625, 0.0146484375, 0.109375, 0.009765625, 0.0078125, 0.0966796875, 0.01171875, 0.0908203125, 0.03125, 0.001953125, 0.0087890625, 0.0615234375, 0.0517578125, 0.0615234375, 0.0771484375, 0.087890625, 0.001953125, 0.0888671875, 0.00390625, 0.0126953125, 0.0390625, 0.1181640625, 0.0380859375, 0.8759765625, 0.998046875, 0.015625, 0.0322265625, 0.8251953125, 0.064453125, 0.1171875, 0.00390625, 0.005859375, 0.0966796875, 0.009765625, 0.005859375, 0.341796875, 0.0166015625, 0.017578125, 0.0048828125, 0.0048828125, 0.1953125, 0.0380859375, 0.0, 0.041015625, 0.009765625, 0.94140625, 0.005859375, 0.0361328125, 0.0751953125, 0.0078125, 0.0185546875, 0.009765625, 0.0771484375, 0.0029296875, 0.001953125, 0.001953125, 0.0517578125, 0.05859375, 0.10546875, 0.0, 0.21484375, 0.0634765625, 0.0029296875, 0.0068359375, 0.22265625, 0.7705078125, 0.03125, 0.00390625, 0.009765625, 0.0087890625, 0.021484375, 0.015625, 0.0, 0.0146484375, 0.072265625, 0.041015625, 0.0234375, 0.212890625, 0.04296875, 0.0791015625, 0.0078125, 0.9990234375, 0.0419921875, 0.0439453125, 0.1171875, 0.0234375, 0.927734375, 0.015625, 0.01171875, 0.921875, 0.099609375, 0.068359375, 0.0244140625, 0.0029296875, 0.015625, 0.998046875, 0.0302734375, 0.0927734375, 0.00390625, 0.07421875, 0.0126953125, 0.005859375, 0.013671875, 0.0126953125, 0.015625, 0.140625, 0.0224609375, 0.0185546875, 0.19140625, 0.0048828125, 0.0400390625, 0.00390625, 0.0419921875, 0.0, 0.0224609375, 0.8076171875, 0.0771484375, 0.25, 0.083984375, 0.041015625, 0.0048828125, 0.0166015625, 0.0166015625, 0.08984375, 0.0068359375, 0.9169921875, 0.025390625, 0.0283203125, 0.00390625, 0.3359375, 0.0849609375, 0.0166015625, 0.0283203125, 0.0146484375, 0.0283203125, 0.08984375, 0.0048828125, 0.0283203125, 0.0244140625, 0.9970703125, 0.951171875, 0.0322265625, 0.1220703125, 0.1943359375, 0.8310546875, 0.9423828125, 0.0126953125, 0.083984375, 0.025390625, 0.00390625, 0.0341796875, 0.09765625, 0.0244140625, 0.0029296875, 0.021484375, 0.0927734375, 0.013671875, 0.0556640625, 0.0478515625, 0.0029296875, 0.0048828125, 0.9560546875, 0.029296875, 0.1728515625, 0.0048828125, 0.6748046875, 0.005859375, 0.0009765625, 0.001953125, 0.0283203125, 0.58984375, 0.1064453125, 0.015625, 0.095703125, 0.0029296875, 0.96484375, 0.642578125, 0.0, 0.0654296875, 0.009765625, 0.822265625, 0.0869140625, 0.044921875, 0.01171875, 0.998046875, 0.7333984375, 0.083984375, 0.0205078125, 0.0068359375, 0.9140625, 0.0, 0.015625, 0.00390625, 0.09375, 0.0068359375, 0.0, 0.0341796875, 0.310546875, 0.029296875, 0.0107421875, 0.0029296875, 0.0400390625, 0.166015625, 0.0068359375, 0.0126953125, 0.0048828125, 0.01171875, 0.009765625, 0.029296875, 0.1494140625, 0.845703125, 0.017578125, 0.0380859375, 0.0703125, 0.935546875, 0.048828125, 0.2236328125, 0.029296875, 0.037109375, 0.013671875, 0.0078125, 0.005859375, 0.0078125, 0.61328125, 0.015625, 0.021484375, 0.9140625, 0.568359375, 0.01171875, 0.998046875, 0.0361328125, 0.1279296875, 0.0078125, 0.01953125, 0.1669921875, 0.0888671875, 0.017578125, 0.015625, 0.033203125, 0.037109375, 0.0810546875, 0.0, 0.001953125, 0.1171875, 0.1494140625, 0.0791015625, 0.09765625, 0.00390625, 0.0029296875, 0.7841796875, 0.0107421875, 0.0751953125, 0.0302734375, 0.087890625, 0.0205078125, 0.966796875, 0.087890625, 0.0107421875, 0.0234375, 0.021484375, 0.033203125, 0.041015625, 0.0, 0.03125, 0.955078125, 0.0322265625, 0.0341796875, 0.0146484375, 0.021484375, 0.0048828125, 0.6630859375, 0.0341796875, 0.00390625, 0.0234375, 0.0126953125, 0.0068359375, 0.83203125, 0.0, 0.0126953125, 0.0107421875, 0.0048828125, 0.0634765625, 0.0546875, 0.015625, 0.0087890625, 0.2490234375, 0.1279296875, 0.0107421875, 0.0478515625, 0.0, 0.005859375, 0.0615234375, 0.84765625, 0.0, 0.2158203125, 0.083984375, 0.0634765625, 0.0, 0.0126953125, 0.00390625, 0.103515625, 0.1083984375, 0.583984375, 0.005859375, 0.0146484375, 0.7119140625, 0.001953125, 0.0146484375, 0.86328125, 0.0263671875, 0.00390625, 0.0166015625, 0.0078125, 0.9970703125, 0.0322265625, 0.0, 0.0205078125, 0.7255859375, 0.1162109375, 0.1171875, 0.0, 0.009765625, 0.0, 0.193359375, 0.8408203125, 0.091796875, 0.025390625, 0.0068359375, 0.0078125, 0.01953125, 0.9990234375, 0.0048828125, 0.0048828125, 0.0615234375, 0.1708984375, 0.06640625, 0.0107421875, 0.0048828125, 0.0, 0.0126953125, 0.0087890625, 0.0078125, 0.0185546875, 0.005859375, 0.0126953125, 0.0791015625, 0.03515625, 0.0078125, 0.0830078125, 0.8740234375, 0.0771484375, 0.0048828125, 0.005859375, 0.0439453125, 0.0224609375, 0.00390625, 0.08984375, 0.0078125, 0.974609375, 0.3017578125, 0.005859375, 0.087890625, 0.0302734375, 0.0703125, 0.00390625, 0.00390625, 0.05078125, 0.0, 0.05078125, 0.017578125, 0.1064453125, 0.0205078125, 0.0185546875, 0.1025390625, 0.009765625, 0.0849609375, 0.00390625, 0.056640625, 0.1474609375, 0.845703125, 0.021484375, 0.0185546875, 0.9970703125, 0.2841796875, 0.05859375, 0.015625, 0.0048828125, 0.0234375, 0.95703125, 0.0380859375, 0.0185546875, 0.98046875, 0.013671875, 0.0078125, 0.0029296875, 0.998046875, 0.748046875, 0.0625, 0.095703125, 0.052734375, 0.0654296875, 0.0966796875, 0.0029296875, 0.1181640625, 0.0478515625, 0.0, 0.0498046875, 0.00390625, 0.02734375, 0.0986328125, 0.3076171875, 0.0615234375, 0.009765625, 0.0302734375, 0.802734375, 0.3466796875, 0.0927734375, 0.005859375, 0.01953125, 0.091796875, 0.015625, 0.1181640625, 0.0107421875, 0.9208984375, 0.056640625, 0.037109375, 0.0205078125, 0.0546875, 0.0009765625, 0.00390625, 0.0302734375, 0.0048828125, 0.0322265625, 0.0029296875, 0.06640625, 0.029296875, 0.029296875, 0.865234375, 0.04296875, 0.130859375, 0.0205078125, 0.0849609375, 0.1025390625, 0.0029296875, 0.9970703125, 0.0078125, 0.0751953125, 0.08984375, 0.0, 0.01171875, 0.015625, 0.0078125, 0.236328125, 0.0029296875, 0.0234375, 0.0771484375, 0.0009765625, 0.005859375, 0.1181640625, 0.0068359375, 0.09765625, 0.013671875, 0.08203125, 0.09375, 0.0009765625, 0.91796875, 0.19140625, 0.0263671875, 0.017578125, 0.056640625, 0.7119140625, 0.0849609375, 0.2099609375, 0.013671875, 0.0146484375, 0.037109375, 0.8369140625, 0.9970703125, 0.0322265625, 0.015625, 0.0048828125, 0.09765625, 0.919921875, 0.0771484375, 0.0556640625, 0.0732421875, 0.0146484375, 0.1005859375, 0.03515625, 0.0009765625, 0.025390625, 0.0751953125, 0.0712890625, 0.015625, 0.1015625, 0.0302734375, 0.0068359375, 0.0107421875, 0.8076171875, 0.00390625, 0.0068359375, 0.01171875, 0.00390625, 0.998046875, 0.025390625, 0.05078125, 0.9970703125, 0.19921875, 0.02734375, 0.0107421875, 0.0146484375, 0.0, 0.0498046875, 0.1044921875, 0.0, 0.0986328125, 0.0205078125, 0.0048828125, 0.0244140625, 0.0849609375, 0.998046875, 0.0, 0.0, 0.2314453125, 0.0849609375, 0.0205078125, 0.9970703125, 0.0009765625, 0.0830078125, 0.068359375, 0.0078125, 0.0078125, 0.05859375, 0.955078125, 0.0341796875, 0.021484375, 0.0322265625, 0.0478515625, 0.0205078125, 0.0888671875, 0.005859375, 0.1181640625, 0.0, 0.9990234375, 0.0087890625, 0.001953125, 0.0185546875, 0.0615234375, 0.14453125, 0.001953125, 0.001953125, 0.0380859375, 0.220703125, 0.0078125, 0.0048828125, 0.02734375, 0.0625, 0.0068359375, 0.0029296875, 0.0986328125, 0.1181640625, 0.01171875, 0.08984375, 0.017578125, 0.0107421875, 0.1025390625, 0.001953125, 0.0107421875, 0.0185546875, 0.0634765625, 0.0048828125, 0.0048828125, 0.0283203125, 0.0869140625, 0.041015625, 0.0380859375, 0.0390625, 0.0361328125, 0.8994140625, 0.0908203125, 0.1298828125, 0.6103515625, 0.05859375, 0.0869140625, 0.0869140625, 0.00390625, 0.1044921875, 0.025390625, 0.94140625, 0.05078125, 0.072265625, 0.853515625, 0.0, 0.00390625, 0.0517578125, 0.0361328125, 0.908203125, 0.005859375, 0.033203125, 0.091796875, 0.0029296875, 0.103515625, 0.0, 0.1044921875, 0.01953125, 0.6298828125, 0.654296875, 0.2138671875, 0.087890625, 0.9052734375, 0.2177734375, 0.015625, 0.08984375, 0.052734375, 0.017578125, 0.0068359375, 0.0546875, 0.083984375, 0.0185546875, 0.013671875, 0.0927734375, 0.025390625, 0.0234375, 0.0361328125, 0.1396484375, 0.00390625, 0.021484375, 0.013671875, 0.0244140625, 0.0361328125, 0.0419921875, 0.046875, 0.0234375, 0.0595703125, 0.0078125, 0.0322265625, 0.009765625, 0.0234375, 0.0068359375, 0.029296875, 0.0263671875, 0.087890625, 0.0888671875, 0.0068359375, 0.0, 0.0205078125, 0.0, 0.9990234375, 0.080078125, 0.091796875, 0.8701171875, 0.154296875, 0.0126953125, 0.0185546875, 0.9970703125, 0.2119140625, 0.01171875, 0.0234375, 0.0947265625, 0.1845703125, 0.0244140625, 0.001953125, 0.744140625, 0.0087890625, 0.9970703125, 0.1689453125, 0.1083984375, 0.095703125, 0.0390625, 0.0244140625, 0.025390625, 0.0078125, 0.0009765625, 0.0068359375, 0.0400390625, 0.00390625, 0.0087890625, 0.0048828125, 0.0068359375, 0.0009765625, 0.021484375, 0.1103515625, 0.0771484375, 0.9970703125, 0.138671875, 0.015625, 0.01171875, 0.009765625, 0.009765625, 0.0947265625, 0.998046875, 0.9970703125, 0.041015625, 0.9521484375, 0.9580078125, 0.70703125, 0.0205078125, 0.0146484375, 0.009765625, 0.033203125, 0.919921875, 0.0927734375, 0.0, 0.005859375, 0.0185546875, 0.0146484375, 0.021484375, 0.029296875, 0.9970703125, 0.0166015625, 0.1943359375, 0.0654296875, 0.0146484375, 0.00390625, 0.01171875, 0.15234375, 0.0576171875, 0.927734375, 0.001953125, 0.3212890625, 0.0, 0.1396484375, 0.0029296875, 0.0693359375, 0.033203125, 0.0048828125, 0.03515625, 0.060546875, 0.2822265625, 0.0625, 0.0478515625, 0.015625, 0.0009765625, 0.005859375, 0.0146484375, 0.0029296875, 0.0146484375, 0.037109375, 0.0029296875, 0.0087890625, 0.0791015625, 0.072265625, 0.2939453125, 0.0029296875, 0.0361328125, 0.0, 0.02734375, 0.068359375, 0.0771484375, 0.1220703125, 0.009765625, 0.0, 0.2578125, 0.08984375, 0.0, 0.03125, 0.04296875, 0.0966796875, 0.037109375, 0.0205078125, 0.0107421875, 0.03125, 0.0595703125, 0.9990234375, 0.1591796875, 0.0849609375, 0.037109375, 0.0537109375, 0.0146484375, 0.015625, 0.0, 0.0205078125, 0.0888671875, 0.5791015625, 0.037109375, 0.01171875, 0.095703125, 0.0, 0.1181640625, 0.03515625, 0.0703125, 0.0302734375, 0.06640625, 0.078125, 0.083984375, 0.1025390625, 0.033203125, 0.1123046875, 0.025390625, 0.9970703125, 0.013671875, 0.6005859375, 0.0400390625, 0.7734375, 0.1767578125, 0.8251953125, 0.080078125, 0.04296875, 0.0185546875, 0.00390625, 0.005859375, 0.1005859375, 0.0234375, 0.0, 0.0126953125, 0.0126953125, 0.810546875, 0.0458984375, 0.294921875, 0.6787109375, 0.0146484375, 0.00390625, 0.00390625, 0.0927734375, 0.0048828125, 0.0126953125, 0.00390625, 0.0205078125, 0.15625, 0.013671875, 0.0966796875, 0.0068359375, 0.0966796875, 0.037109375, 0.0087890625, 0.0966796875, 0.0126953125, 0.001953125, 0.05078125, 0.01171875, 0.962890625, 0.08984375, 0.0908203125, 0.0966796875, 0.0390625, 0.009765625, 0.0146484375, 0.9404296875, 0.005859375, 0.185546875, 0.00390625, 0.01171875, 0.017578125, 0.01953125, 0.0234375, 0.0751953125, 0.005859375, 0.00390625, 0.02734375, 0.0302734375, 0.0068359375, 0.6943359375, 0.673828125, 0.0166015625, 0.0048828125, 0.0341796875, 0.046875, 0.025390625, 0.0576171875, 0.0068359375, 0.0712890625, 0.0078125, 0.1318359375, 0.10546875, 0.642578125, 0.0693359375, 0.041015625, 0.0302734375, 0.126953125, 0.009765625, 0.09765625, 0.001953125, 0.0, 0.1123046875, 0.0068359375, 0.0107421875, 0.0068359375, 0.0078125, 0.009765625, 0.0673828125, 0.126953125, 0.076171875, 0.0859375, 0.001953125, 0.01171875, 0.0107421875, 0.1005859375, 0.6064453125, 0.0234375, 0.005859375, 0.005859375, 0.0087890625, 0.0458984375, 0.00390625, 0.0029296875, 0.1083984375, 0.0537109375, 0.0068359375, 0.0751953125, 0.1708984375, 0.0087890625, 0.021484375, 0.0048828125, 0.0107421875, 0.033203125, 0.0517578125, 0.095703125, 0.0888671875, 0.0205078125, 0.064453125, 0.0849609375, 0.818359375, 0.865234375, 0.03515625, 0.015625, 0.0078125, 0.0419921875, 0.0107421875, 0.005859375, 0.8974609375, 0.0029296875, 0.0078125, 0.0234375, 0.0400390625, 0.0009765625, 0.0712890625, 0.013671875, 0.1923828125, 0.0068359375, 0.0, 0.9970703125, 0.041015625, 0.0556640625, 0.0068359375, 0.0615234375, 0.9091796875, 0.0107421875, 0.0009765625, 0.02734375, 0.0146484375, 0.0185546875, 0.013671875, 0.01953125, 0.0654296875, 0.0029296875, 0.0029296875, 0.0029296875, 0.021484375, 0.9970703125, 0.02734375, 0.009765625, 0.099609375, 0.0712890625, 0.0, 0.603515625, 0.076171875, 0.09375, 0.0859375, 0.08203125, 0.0048828125, 0.0244140625, 0.021484375, 0.0302734375, 0.037109375, 0.0107421875, 0.01171875, 0.009765625, 0.01171875, 0.0927734375, 0.02734375, 0.9990234375, 0.009765625, 0.0732421875, 0.18359375, 0.8173828125, 0.8671875, 0.091796875, 0.01171875, 0.0068359375, 0.00390625, 0.87890625, 0.0, 0.0927734375, 0.85546875, 0.109375, 0.06640625, 0.02734375, 0.0, 0.029296875, 0.0185546875, 0.0126953125, 0.2587890625, 0.009765625, 0.0029296875, 0.0166015625, 0.0048828125, 0.1337890625, 0.0439453125, 0.8203125, 0.1181640625, 0.3662109375, 0.7939453125, 0.041015625, 0.001953125, 0.94140625, 0.9970703125, 0.0, 0.0927734375, 0.1123046875, 0.041015625, 0.009765625, 0.138671875, 0.0673828125, 0.0966796875, 0.0205078125, 0.0283203125, 0.0048828125, 0.0107421875, 0.03125, 0.0244140625, 0.9970703125, 0.0400390625, 0.041015625, 0.08984375, 0.939453125, 0.005859375, 0.01953125, 0.0859375, 0.0078125, 0.0439453125, 0.0205078125, 0.06640625, 0.033203125, 0.9970703125, 0.876953125, 0.0185546875, 0.0791015625, 0.0244140625, 0.9990234375, 0.013671875, 0.17578125, 0.0029296875, 0.7568359375, 0.1171875, 0.2529296875, 0.005859375, 0.005859375, 0.025390625, 0.896484375, 0.01953125, 0.009765625, 0.0068359375, 0.3798828125, 0.13671875, 0.0078125, 0.0576171875, 0.0791015625, 0.12109375, 0.01953125, 0.0263671875, 0.0322265625, 0.0, 0.0205078125, 0.1005859375, 0.9248046875, 0.099609375, 0.0087890625, 0.04296875, 0.0078125, 0.017578125, 0.0, 0.0283203125, 0.0048828125, 0.966796875, 0.958984375, 0.0703125, 0.0927734375]

 sparsity of   [0.6142578125, 0.54736328125, 0.0615234375, 0.04296875, 0.03369140625, 0.06689453125, 0.03369140625, 0.1552734375, 0.05029296875, 0.2197265625, 0.064453125, 0.1572265625, 0.064453125, 0.03564453125, 0.84521484375, 0.8486328125, 0.04296875, 0.15966796875, 0.0498046875, 0.99853515625, 0.9013671875, 0.39794921875, 0.0400390625, 0.0283203125, 0.0224609375, 0.9677734375, 0.041015625, 0.1650390625, 0.0302734375, 0.1484375, 0.1611328125, 0.05322265625, 0.03759765625, 0.13134765625, 0.0771484375, 0.7353515625, 0.64599609375, 0.0244140625, 0.09423828125, 0.25341796875, 0.08154296875, 0.029296875, 0.76171875, 0.24365234375, 0.01123046875, 0.05078125, 0.01416015625, 0.0703125, 0.02490234375, 0.40478515625, 0.0810546875, 0.0107421875, 0.10009765625, 0.046875, 0.1337890625, 0.037109375, 0.021484375, 0.08251953125, 0.017578125, 0.17578125, 0.17431640625, 0.05810546875, 0.80078125, 0.02294921875, 0.91259765625, 0.02734375, 0.8310546875, 0.0712890625, 0.14990234375, 0.04541015625, 0.20068359375, 0.80908203125, 0.06298828125, 0.02099609375, 0.06640625, 0.35009765625, 0.9609375, 0.67626953125, 0.99853515625, 0.0126953125, 0.998046875, 0.0126953125, 0.03564453125, 0.6064453125, 0.05419921875, 0.02099609375, 0.048828125, 0.7001953125, 0.94873046875, 0.04736328125, 0.212890625, 0.05126953125, 0.03076171875, 0.39892578125, 0.06689453125, 0.00830078125, 0.08447265625, 0.01416015625, 0.99755859375, 0.3779296875, 0.01904296875, 0.015625, 0.037109375, 0.1572265625, 0.2216796875, 0.6982421875, 0.71044921875, 0.091796875, 0.6484375, 0.03076171875, 0.15771484375, 0.0693359375, 0.01416015625, 0.0126953125, 0.0830078125, 0.00439453125, 0.037109375, 0.01904296875, 0.02587890625, 0.171875, 0.99951171875, 0.046875, 0.26513671875, 0.22265625, 0.04345703125, 0.052734375, 0.14208984375, 0.0810546875, 0.35888671875, 0.05908203125, 0.0390625, 0.0498046875, 0.0068359375, 0.01708984375, 0.92041015625, 0.04931640625, 0.17529296875, 0.103515625, 0.9345703125, 0.220703125, 0.0283203125, 0.0166015625, 0.0205078125, 0.06005859375, 0.81787109375, 0.08056640625, 0.06982421875, 0.0830078125, 0.5068359375, 0.896484375, 0.0224609375, 0.04248046875, 0.02880859375, 0.0380859375, 0.10205078125, 0.1142578125, 0.0185546875, 0.0498046875, 0.0302734375, 0.03662109375, 0.25390625, 0.91015625, 0.05712890625, 0.02734375, 0.1435546875, 0.00927734375, 0.86669921875, 0.015625, 0.02001953125, 0.85498046875, 0.43896484375, 0.02978515625, 0.84130859375, 0.00927734375, 0.013671875, 0.0283203125, 0.01171875, 0.9990234375, 0.02294921875, 0.8125, 0.99951171875, 0.78173828125, 0.03173828125, 0.11328125, 0.021484375, 0.01708984375, 0.16064453125, 0.0107421875, 0.56640625, 0.76904296875, 0.111328125, 0.0595703125, 0.94091796875, 0.15625, 0.04541015625, 0.9345703125, 0.76904296875, 0.0087890625, 0.77001953125, 0.03076171875, 0.0224609375, 0.01513671875, 0.08154296875, 0.01318359375, 0.0087890625, 0.11376953125, 0.7060546875, 0.01611328125, 0.77099609375, 0.13330078125, 0.07666015625, 0.017578125, 0.02099609375, 0.8369140625, 0.025390625, 0.724609375, 0.23681640625, 0.9990234375, 0.017578125, 0.04150390625, 0.7646484375, 0.01416015625, 0.95166015625, 0.03564453125, 0.03173828125, 0.17431640625, 0.00341796875, 0.095703125, 0.09814453125, 0.0087890625, 0.033203125, 0.0146484375, 0.04736328125, 0.0205078125, 0.025390625, 0.2880859375, 0.61669921875, 0.24755859375, 0.23046875, 0.09130859375, 0.01171875, 0.1953125, 0.02197265625, 0.88134765625, 0.5009765625, 0.076171875, 0.04833984375, 0.0390625, 0.01416015625, 0.01025390625, 0.04736328125, 0.02783203125, 0.13037109375, 0.02001953125, 0.013671875, 0.044921875, 0.0078125, 0.91455078125, 0.42724609375, 0.01806640625, 0.013671875, 0.06689453125, 0.0126953125, 0.298828125, 0.04638671875, 0.0927734375, 0.26953125, 0.02197265625, 0.04638671875, 0.03173828125, 0.20361328125, 0.03125, 0.1650390625, 0.0234375, 0.05859375, 0.84375, 0.021484375, 0.01123046875, 0.080078125, 0.0205078125, 0.03076171875, 0.7109375, 0.1240234375, 0.09033203125, 0.0400390625, 0.99853515625, 0.025390625, 0.0146484375, 0.10498046875, 0.029296875, 0.15625, 0.0224609375, 0.99853515625, 0.0263671875, 0.58154296875, 0.1142578125, 0.05029296875, 0.7666015625, 0.04736328125, 0.05078125, 0.01708984375, 0.7666015625, 0.03857421875, 0.03955078125, 0.58251953125, 0.9990234375, 0.9990234375, 0.3369140625, 0.00927734375, 0.06591796875, 0.04150390625, 0.1005859375, 0.0400390625, 0.05615234375, 0.04443359375, 0.01318359375, 0.02490234375, 0.1943359375, 0.921875, 0.017578125, 0.93212890625, 0.07763671875, 0.0283203125, 0.05224609375, 0.626953125, 0.17626953125, 0.01025390625, 0.9990234375, 0.9990234375, 0.03173828125, 0.10498046875, 0.04736328125, 0.26318359375, 0.71875, 0.03564453125, 0.0283203125, 0.69384765625, 0.93603515625, 0.04052734375, 0.10791015625, 0.01611328125, 0.134765625, 0.384765625, 0.04833984375, 0.15771484375, 0.84375, 0.08447265625, 0.04296875, 0.02978515625, 0.09814453125, 0.103515625, 0.01806640625, 0.89306640625, 0.02001953125, 0.14794921875, 0.68603515625, 0.9296875, 0.046875, 0.01123046875, 0.02978515625, 0.00830078125, 0.78564453125, 0.037109375, 0.0419921875, 0.1572265625, 0.017578125, 0.0263671875, 0.29296875, 0.189453125, 0.0712890625, 0.00732421875, 0.013671875, 0.3056640625, 0.0693359375, 0.025390625, 0.0478515625, 0.25634765625, 0.080078125, 0.03759765625, 0.10205078125, 0.0419921875, 0.01904296875, 0.0185546875, 0.123046875, 0.81005859375, 0.0625, 0.02783203125, 0.0615234375, 0.01953125, 0.111328125, 0.07958984375, 0.89306640625, 0.51708984375, 0.0458984375, 0.02392578125, 0.04638671875, 0.14599609375, 0.1171875, 0.0400390625, 0.0537109375, 0.03125, 0.09521484375, 0.1962890625, 0.0244140625, 0.1142578125, 0.02685546875, 0.60498046875, 0.01708984375, 0.7001953125, 0.0263671875, 0.6728515625, 0.09130859375, 0.88232421875, 0.345703125, 0.2578125, 0.30029296875, 0.0263671875, 0.017578125, 0.01171875, 0.03173828125, 0.01318359375, 0.12548828125, 0.02099609375, 0.6162109375, 0.0234375, 0.01708984375, 0.0126953125, 0.6923828125, 0.107421875, 0.99951171875, 0.0341796875, 0.02880859375, 0.06201171875, 0.025390625, 0.0322265625, 0.14208984375, 0.2705078125, 0.01611328125, 0.11962890625, 0.552734375, 0.02685546875, 0.0234375, 0.1318359375, 0.123046875, 0.8583984375, 0.19775390625, 0.05908203125, 0.69677734375, 0.0673828125, 0.12451171875, 0.03857421875, 0.05322265625, 0.447265625, 0.21630859375, 0.80859375, 0.19873046875, 0.01611328125, 0.06787109375, 0.06591796875, 0.03564453125, 0.78466796875, 0.53857421875, 0.0166015625, 0.029296875, 0.19677734375, 0.0234375, 0.09326171875, 0.02490234375, 0.10302734375, 0.02294921875, 0.0869140625, 0.0205078125, 0.146484375, 0.029296875, 0.6708984375, 0.017578125, 0.642578125, 0.0234375, 0.18798828125, 0.02099609375, 0.009765625, 0.08544921875, 0.1142578125, 0.02490234375, 0.0947265625, 0.02099609375, 0.0966796875, 0.01806640625, 0.66845703125, 0.7802734375, 0.9990234375, 0.74658203125, 0.87646484375, 0.8916015625, 0.99853515625, 0.0322265625, 0.0224609375, 0.01123046875, 0.1669921875, 0.99853515625, 0.25341796875, 0.02587890625, 0.99853515625, 0.26025390625, 0.943359375, 0.05029296875, 0.03369140625, 0.046875, 0.6884765625, 0.6865234375, 0.0546875, 0.02001953125]

 sparsity of   [0.0, 0.0, 0.009765625, 0.0, 0.01996527798473835, 0.0004340277810115367, 0.0316840298473835, 0.0, 0.0, 0.013888888992369175, 0.0425347238779068, 0.1338975727558136, 0.0, 0.0, 0.03081597201526165, 0.0397135429084301, 0.0, 0.0004340277810115367, 0.0, 0.0, 0.1388888955116272, 0.0, 0.0004340277810115367, 0.0, 0.5690104365348816, 0.0008680555620230734, 0.00021701389050576836, 0.00021701389050576836, 0.0, 0.0, 0.00021701389050576836, 0.0, 0.0, 0.0, 0.08203125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00021701389050576836, 0.0, 0.0028211805038154125, 0.0, 0.0, 0.013020833022892475, 0.0, 0.0377604179084301, 0.0562065988779068, 0.0, 0.0, 0.0, 0.0036892362404614687, 0.0004340277810115367, 0.00021701389050576836, 0.1575520783662796, 0.005425347480922937, 0.0, 0.0, 0.8530815839767456, 0.0, 0.0, 0.0, 0.0, 0.00021701389050576836, 0.00021701389050576836, 0.1232638880610466, 0.0, 0.0067274305038154125, 0.0, 0.009114583022892475, 0.0970052108168602, 0.0, 0.0, 0.0034722222480922937, 0.0, 0.0071614584885537624, 0.0, 0.0, 0.0010850694961845875, 0.0, 0.0, 0.0, 0.0, 0.00021701389050576836, 0.0, 0.0004340277810115367, 0.00021701389050576836, 0.03125, 0.0, 0.1032986119389534, 0.0, 0.0, 0.0, 0.02170138992369175, 0.013671875, 0.2697482705116272, 0.0069444444961845875, 0.0, 0.073133684694767, 0.0928819477558136, 0.9637587070465088, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.004123263992369175, 0.0006510416860692203, 0.00021701389050576836, 0.9986979365348816, 0.00021701389050576836, 0.005859375, 0.0, 0.00021701389050576836, 0.01519097201526165, 0.206814244389534, 0.0319010429084301, 0.02495659701526165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007378472480922937, 0.015407986007630825, 0.02604166604578495, 0.006076388992369175, 0.01953125, 0.00021701389050576836, 0.00021701389050576836, 0.0, 0.0, 0.0015190972480922937, 0.0, 0.0, 0.0, 0.0004340277810115367, 0.0, 0.0, 0.0, 0.0, 0.00021701389050576836, 0.0700954869389534, 0.0, 0.0, 0.0036892362404614687, 0.0, 0.1449652761220932, 0.00021701389050576836, 0.0028211805038154125, 0.0071614584885537624, 0.0, 0.0, 0.0, 0.0355902798473835, 0.0186631940305233, 0.0, 0.0, 0.007595486007630825, 0.0, 0.0, 0.118055559694767, 0.0, 0.0, 0.00021701389050576836, 0.0, 0.048828125, 0.0, 0.00021701389050576836, 0.0, 0.0, 0.0, 0.029296875, 0.025390625, 0.0, 0.0, 0.0, 0.0030381944961845875, 0.0, 0.0, 0.0425347238779068, 0.0, 0.0034722222480922937, 0.2584635317325592, 0.0, 0.008029513992369175, 0.0, 0.0, 0.00021701389050576836, 0.0, 0.0, 0.9880642294883728, 0.0, 0.0, 0.0, 0.0030381944961845875, 0.0, 0.01019965298473835, 0.0403645820915699, 0.0, 0.00021701389050576836, 0.0, 0.9993489384651184, 0.0, 0.0, 0.0, 0.0049913194961845875, 0.01410590298473835, 0.0, 0.0, 0.0008680555620230734, 0.0, 0.01888020895421505, 0.0, 0.0, 0.0, 0.0423177070915699, 0.0006510416860692203, 0.0, 0.017578125, 0.00021701389050576836, 0.0, 0.0, 0.0, 0.0067274305038154125, 0.0, 0.0, 0.0, 0.00021701389050576836, 0.0531684048473835, 0.0729166641831398, 0.0, 0.0, 0.0, 0.0, 0.00021701389050576836, 0.0004340277810115367, 0.0572916679084301, 0.0, 0.0, 0.0, 0.0, 0.8795573115348816, 0.0184461809694767, 0.9997829794883728, 0.014756944961845875, 0.0, 0.0, 0.0, 0.0, 0.01974826492369175, 0.083984375, 0.0, 0.00021701389050576836, 0.0, 0.0321180559694767, 0.0, 0.0, 0.0345052070915699, 0.0, 0.0, 0.01822916604578495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.082899309694767, 0.0, 0.0, 0.0, 0.02886284701526165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0464409738779068, 0.0, 0.041015625, 0.0013020833721384406, 0.0375434048473835, 0.0, 0.0, 0.0013020833721384406, 0.0744357630610466, 0.0, 0.0071614584885537624, 0.0577256940305233, 0.0, 0.0444878488779068, 0.00021701389050576836, 0.0, 0.0505642369389534, 0.0006510416860692203, 0.0, 0.0, 0.0145399309694767, 0.0394965298473835, 0.00021701389050576836, 0.0, 0.0, 0.0004340277810115367, 0.0, 0.00021701389050576836, 0.013020833022892475, 0.0, 0.0, 0.0, 0.0023871527519077063, 0.0008680555620230734, 0.193142369389534, 0.0, 0.00021701389050576836, 0.1764322966337204, 0.0345052070915699, 0.005425347480922937, 0.0, 0.0, 0.0768229141831398, 0.0, 0.0455729179084301, 0.00021701389050576836, 0.00021701389050576836, 0.0, 0.0, 0.0, 0.0036892362404614687, 0.0, 0.0, 0.0, 0.0, 0.00021701389050576836, 0.0, 0.0555555559694767, 0.0004340277810115367, 0.0, 0.00021701389050576836, 0.00021701389050576836, 0.0434027798473835, 0.0, 0.0, 0.0, 0.9993489384651184, 0.0, 0.0, 0.00021701389050576836, 0.0, 0.0, 0.0, 0.0106336809694767, 0.7163628339767456, 0.0, 0.0, 0.0, 0.0, 0.012803819961845875, 0.0, 0.0, 0.0648871511220932, 0.0, 0.0, 0.9993489384651184, 0.0, 0.01519097201526165, 0.094618059694767, 0.0, 0.0, 0.0, 0.01128472201526165, 0.0, 0.1410590261220932, 0.0069444444961845875, 0.0, 0.0, 0.0, 0.0028211805038154125, 0.0362413190305233, 0.08984375, 0.0, 0.0, 0.1547309011220932, 0.0, 0.00021701389050576836, 0.0310329869389534, 0.0, 0.0, 0.0, 0.0, 0.9989149570465088, 0.0010850694961845875, 0.0, 0.0, 0.999131977558136, 0.0, 0.0, 0.0, 0.0, 0.0479600690305233, 0.0427517369389534, 0.0, 0.0, 0.9995659589767456, 0.005425347480922937, 0.0, 0.998046875, 0.0045572915114462376, 0.0, 0.0, 0.029296875, 0.0232204869389534, 0.00021701389050576836, 0.0494791679084301, 0.007595486007630825, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.3205295205116272, 0.0, 0.00021701389050576836, 0.0245225690305233, 0.0, 0.0004340277810115367, 0.0, 0.0, 0.0167100690305233, 0.0, 0.0358072929084301, 0.0, 0.0, 0.0026041667442768812, 0.0, 0.0, 0.1002604141831398, 0.0, 0.0, 0.0501302070915699, 0.0006510416860692203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00021701389050576836, 0.0, 0.0, 0.00021701389050576836, 0.0314670130610466, 0.0, 0.0, 0.0, 0.00021701389050576836, 0.0052083334885537624, 0.0, 0.0086805559694767, 0.0, 0.0, 0.0, 0.0, 0.005425347480922937, 0.0004340277810115367, 0.0, 0.0, 0.0, 0.0015190972480922937, 0.0, 0.00021701389050576836, 0.0, 0.0006510416860692203, 0.0, 0.0, 0.0, 0.0004340277810115367, 0.00390625, 0.6395399570465088, 0.0, 0.0, 0.0, 0.0, 0.0394965298473835, 0.0, 0.0, 0.0, 0.10546875, 0.0030381944961845875, 0.0861545130610466, 0.00021701389050576836, 0.00021701389050576836, 0.01996527798473835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00021701389050576836, 0.029296875, 0.0, 0.0, 0.0, 0.00021701389050576836, 0.00021701389050576836, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 0.017578125, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.001953125, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.029296875, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.001953125, 0.0, 0.01953125, 0.0, 0.001953125, 0.0, 0.08203125, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.03125, 0.00390625, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.025390625, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.134765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02734375, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013671875, 0.0, 0.0390625, 0.0, 0.01171875, 0.0, 0.009765625, 0.009765625, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0078125, 0.001953125, 0.0, 0.0, 0.0, 0.00390625, 0.001953125, 0.0, 0.0, 0.017578125, 0.0, 0.001953125, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.126953125, 0.05078125, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.029296875, 0.0, 0.0, 0.0, 0.0, 0.005859375, 0.17578125, 0.0, 0.037109375, 0.0, 0.0, 0.033203125, 0.0, 0.0, 0.626953125, 0.0234375, 0.001953125, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.029296875, 0.0, 0.0078125, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.001953125, 0.01171875, 0.001953125, 0.9140625, 0.0, 0.998046875, 0.0, 0.021484375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03515625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.921875, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.99609375, 0.01171875, 0.0, 0.0, 0.0, 0.015625, 0.001953125, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048828125, 0.0, 0.525390625, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.021484375, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.025390625, 0.0, 0.0, 0.994140625, 0.0, 0.02734375, 0.0, 0.0546875, 0.005859375, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.03125, 0.0, 0.0, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.03515625, 0.0, 0.033203125, 0.736328125, 0.056640625, 0.0, 0.0, 0.021484375, 0.015625, 0.0, 0.009765625, 0.00390625, 0.0, 0.0, 0.001953125, 0.0, 0.994140625, 0.0, 0.0, 0.0, 0.0, 0.013671875, 0.0, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.029296875, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.017578125, 0.03515625, 0.009765625, 0.0, 0.005859375, 0.0, 0.0, 0.07421875, 0.0, 0.0, 0.0, 0.02734375, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.001953125, 0.013671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017578125, 0.015625, 0.0, 0.0, 0.0, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.001953125, 0.005859375, 0.001953125, 0.001953125, 0.0, 0.009765625, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.001953125, 0.009765625, 0.02734375, 0.0, 0.0, 0.994140625, 0.00390625, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.01171875, 0.0, 0.037109375, 0.0859375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.005859375, 0.00390625, 0.0, 0.0, 0.01171875, 0.0078125, 0.044921875, 0.0546875, 0.0, 0.0, 0.0234375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0546875, 0.0, 0.0, 0.0, 0.0, 0.068359375, 0.0, 0.0390625, 0.021484375, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.013671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.05859375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.01171875, 0.013671875, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.03125, 0.005859375, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.017578125, 0.0, 0.0, 0.076171875, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.064453125, 0.015625, 0.0, 0.03125, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.076171875, 0.005859375, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.02734375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.00390625, 0.43359375, 0.0, 0.0, 0.05859375, 0.0, 0.0, 0.0, 0.041015625, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.025390625, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.01171875, 0.0, 0.05859375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.087890625, 0.0, 0.0, 0.0, 0.001953125, 0.001953125, 0.03515625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.994140625, 0.005859375, 0.0, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025390625, 0.0, 0.005859375, 0.0, 0.03125, 0.025390625, 0.0, 0.08984375, 0.001953125, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.005859375, 0.001953125, 0.0, 0.0, 0.0, 0.025390625, 0.005859375, 0.0, 0.01171875, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.001953125, 0.017578125, 0.0, 0.0, 0.048828125, 0.01953125, 0.0, 0.0, 0.9921875, 0.01953125, 0.046875, 0.00390625, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.001953125, 0.98046875, 0.0234375, 0.0, 0.001953125, 0.0, 0.0, 0.029296875, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025390625, 0.0, 0.0, 0.0234375, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.033203125, 0.1015625, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009765625, 0.0, 0.044921875, 0.005859375, 0.0, 0.0, 0.001953125, 0.0, 0.005859375, 0.0, 0.029296875, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.00390625, 0.0, 0.0, 0.0, 0.0234375, 0.015625, 0.0, 0.17578125, 0.0078125, 0.0, 0.005859375, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.99609375, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.990234375, 0.00390625, 0.0, 0.017578125, 0.0, 0.0, 0.08203125, 0.00390625, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.025390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09375, 0.02734375, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.041015625, 0.0, 0.0, 0.02734375, 0.017578125, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.017578125, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.171875, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0703125, 0.0, 0.033203125, 0.001953125, 0.0, 0.0, 0.2734375, 0.0, 0.0234375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.04296875, 0.0, 0.0, 0.037109375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052734375, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.021484375, 0.0, 0.015625, 0.876953125, 0.0, 0.021484375, 0.0, 0.0, 0.03125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013671875, 0.0, 0.0, 0.001953125, 0.009765625, 0.0, 0.029296875, 0.015625, 0.0, 0.0, 0.0390625, 0.0, 0.0, 0.033203125, 0.00390625, 0.0, 0.00390625, 0.0, 0.994140625, 0.0, 0.0, 0.001953125, 0.0, 0.052734375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.001953125, 0.05078125, 0.0, 0.0, 0.0, 0.001953125, 0.01953125, 0.0, 0.9921875, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.0234375, 0.013671875, 0.025390625, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07421875, 0.0, 0.025390625, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.015625, 0.021484375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.001953125, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0390625, 0.00390625, 0.0, 0.001953125, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.052734375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.029296875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021484375, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.07421875, 0.0, 0.05078125, 0.0, 0.0, 0.0, 0.044921875, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.001953125, 0.0, 0.99609375, 0.0, 0.0078125, 0.0, 0.0, 0.005859375, 0.0, 0.044921875, 0.0, 0.068359375, 0.166015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9921875, 0.0, 0.0, 0.001953125, 0.01171875, 0.0, 0.021484375, 0.0, 0.0, 0.0, 0.00390625, 0.001953125, 0.0, 0.017578125, 0.0, 0.166015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06640625, 0.0, 0.0, 0.04296875, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.01171875, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.068359375, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.009765625, 0.99609375, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.095703125, 0.0, 0.0, 0.0390625, 0.0, 0.0, 0.0, 0.02734375, 0.0, 0.001953125, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.021484375, 0.0, 0.986328125, 0.0, 0.09375, 0.0, 0.0078125, 0.0, 0.0, 0.142578125, 0.0, 0.001953125, 0.00390625, 0.02734375, 0.0, 0.009765625, 0.609375, 0.0, 0.13671875, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.025390625, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.03515625, 0.0, 0.0, 0.0, 0.05859375, 0.0, 0.75390625, 0.0, 0.0078125, 0.0, 0.005859375, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046875, 0.001953125, 0.66015625, 0.0, 0.0, 0.916015625, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009765625, 0.0, 0.01171875, 0.013671875, 0.0, 0.0, 0.044921875, 0.001953125, 0.01171875, 0.0, 0.001953125, 0.0, 0.05859375, 0.0, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.234375, 0.005859375, 0.0078125, 0.0, 0.0, 0.0, 0.03125, 0.0, 0.0, 0.0, 0.001953125, 0.99609375, 0.013671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021484375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08984375, 0.0, 0.0, 0.017578125, 0.998046875, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.0, 0.00390625, 0.0, 0.001953125, 0.044921875, 0.0, 0.33203125, 0.009765625, 0.001953125, 0.0, 0.0, 0.041015625, 0.0, 0.0, 0.017578125, 0.0, 0.005859375, 0.01953125, 0.0, 0.0, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.041015625, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.990234375, 0.0, 0.0, 0.0, 0.060546875, 0.0, 0.0, 0.0, 0.021484375, 0.0, 0.001953125, 0.0, 0.025390625, 0.0, 0.001953125, 0.001953125, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.0, 0.02734375, 0.0, 0.0, 0.0, 0.013671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.12109375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.01171875, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.994140625, 0.01953125, 0.0, 0.0, 0.0, 0.0, 0.056640625, 0.0, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046875, 0.025390625, 0.001953125, 0.0, 0.0, 0.0, 0.009765625, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.04296875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029296875, 0.001953125, 0.001953125, 0.001953125, 0.0, 0.03515625, 0.0, 0.0, 0.009765625, 0.0, 0.005859375, 0.0, 0.0, 0.013671875, 0.0, 0.0, 0.0, 0.0, 0.076171875, 0.0, 0.0, 0.0, 0.001953125, 0.083984375, 0.0, 0.0, 0.013671875, 0.0, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0234375, 0.0234375, 0.0, 0.0546875, 0.0, 0.015625, 0.0, 0.046875, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.00390625, 0.03125, 0.0, 0.0, 0.001953125, 0.01171875, 0.001953125, 0.0, 0.8671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.66015625, 0.0234375, 0.0625, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.74609375, 0.0, 0.005859375, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.994140625, 0.01953125, 0.01171875, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.001953125, 0.0, 0.001953125, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005859375, 0.015625, 0.0, 0.0, 0.001953125, 0.0, 0.025390625, 0.037109375, 0.0, 0.0703125, 0.125, 0.0, 0.0, 0.060546875, 0.0546875, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.044921875, 0.0, 0.0, 0.0, 0.001953125, 0.044921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0703125, 0.0, 0.0, 0.0625, 0.0, 0.03125, 0.0, 0.0, 0.1875, 0.0, 0.0, 0.0, 0.01171875, 0.005859375, 0.0, 0.0, 0.0, 0.0, 0.060546875, 0.0, 0.00390625, 0.01171875, 0.0078125, 0.0703125, 0.033203125, 0.0, 0.0, 0.0, 0.0, 0.994140625, 0.0, 0.0, 0.0, 0.07421875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.986328125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.060546875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.056640625, 0.0, 0.0, 0.001953125, 0.0, 0.001953125, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0234375, 0.0, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.140625, 0.0, 0.0, 0.966796875, 0.0, 0.0, 0.0, 0.017578125, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.08203125, 0.0, 0.01171875, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.005859375, 0.0, 0.076171875, 0.0, 0.029296875, 0.99609375, 0.0, 0.0, 0.015625, 0.0078125, 0.015625, 0.01953125, 0.005859375, 0.0, 0.0, 0.0078125, 0.021484375, 0.0, 0.00390625, 0.017578125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.064453125, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.00390625, 0.994140625, 0.998046875, 0.001953125, 0.06640625, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.013671875, 0.0, 0.0, 0.0, 0.0, 0.080078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005859375, 0.029296875, 0.0703125, 0.0, 0.0, 0.0, 0.9921875, 0.0234375, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.021484375, 0.0078125, 0.0, 0.001953125, 0.0, 0.013671875, 0.0, 0.025390625, 0.0, 0.001953125, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.994140625, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.001953125, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.05078125, 0.033203125, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.03125, 0.0, 0.046875, 0.0078125, 0.0, 0.021484375, 0.0, 0.052734375, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.015625, 0.0, 0.00390625, 0.0, 0.013671875, 0.0, 0.021484375, 0.00390625, 0.083984375, 0.0, 0.017578125, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021484375, 0.0, 0.03125, 0.0, 0.0, 0.0, 0.0, 0.998046875, 0.0, 0.0, 0.021484375, 0.001953125, 0.0, 0.0, 0.052734375, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.048828125, 0.0, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.021484375, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.021484375, 0.03125, 0.001953125, 0.0078125, 0.0, 0.0, 0.0, 0.021484375, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.02734375, 0.0, 0.0078125, 0.0, 0.00390625, 0.0, 0.0, 0.013671875, 0.00390625, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.0, 0.0, 0.02734375, 0.0, 0.0, 0.009765625, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.14453125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.033203125, 0.0078125, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001953125, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0234375, 0.0, 0.005859375, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.025390625, 0.0, 0.736328125, 0.0, 0.001953125]

 sparsity of   [0.109375, 0.03515625, 0.0, 0.0, 0.0234375, 0.166015625, 0.0009765625, 0.013671875, 0.0, 0.0009765625, 0.02001953125, 0.0185546875, 0.017578125, 0.00048828125, 0.171875, 0.0478515625, 0.99853515625, 0.05712890625, 0.01025390625, 0.17236328125, 0.0234375, 0.0556640625, 0.0791015625, 0.01708984375, 0.021484375, 0.01708984375, 0.0830078125, 0.134765625, 0.09765625, 0.03271484375, 0.03076171875, 0.0234375, 0.0283203125, 0.0654296875, 0.01904296875, 0.0, 0.14599609375, 0.025390625, 0.0322265625, 0.0263671875, 0.07763671875, 0.01220703125, 0.01953125, 0.00927734375, 0.0234375, 0.0234375, 0.03369140625, 0.02587890625, 0.4033203125, 0.9052734375, 0.0126953125, 0.05517578125, 0.05859375, 0.02197265625, 0.01513671875, 0.0, 0.02294921875, 0.02734375, 0.50537109375, 0.01220703125, 0.048828125, 0.03515625, 0.01953125, 0.00927734375, 0.04931640625, 0.01806640625, 0.017578125, 0.0185546875, 0.02099609375, 0.02392578125, 0.02587890625, 0.02685546875, 0.00927734375, 0.0224609375, 0.04345703125, 0.00390625, 0.0087890625, 0.02783203125, 0.0419921875, 0.1640625, 0.02490234375, 0.04150390625, 0.01611328125, 0.0185546875, 0.02587890625, 0.03564453125, 0.00927734375, 0.00732421875, 0.00390625, 0.03466796875, 0.04248046875, 0.673828125, 0.15234375, 0.005859375, 0.02099609375, 0.05078125, 0.06201171875, 0.99951171875, 0.0, 0.0068359375, 0.06640625, 0.00048828125, 0.0205078125, 0.17724609375, 0.0234375, 0.00927734375, 0.06689453125, 0.0, 0.02490234375, 0.02880859375, 0.04345703125, 0.046875, 0.0390625, 0.0, 0.0, 0.0146484375, 0.0341796875, 0.00048828125, 0.00634765625, 0.00244140625, 0.0322265625, 0.017578125, 0.11474609375, 0.0859375, 0.0380859375, 0.0458984375, 0.02783203125, 0.0, 0.02587890625, 0.0380859375, 0.06689453125, 0.05322265625, 0.955078125, 0.0458984375, 0.2978515625, 0.01123046875, 0.5009765625, 0.03173828125, 0.0185546875, 0.0146484375, 0.01953125, 0.0, 0.01416015625, 0.01708984375, 0.0, 0.0, 0.0341796875, 0.00048828125, 0.41552734375, 0.61083984375, 0.0, 0.51220703125, 0.01025390625, 0.00537109375, 0.00048828125, 0.0, 0.0234375, 0.04248046875, 0.0, 0.0537109375, 0.01025390625, 0.0986328125, 0.00439453125, 0.06982421875, 0.0546875, 0.02392578125, 0.0, 0.0380859375, 0.03271484375, 0.0234375, 0.03515625, 0.05712890625, 0.00244140625, 0.02783203125, 0.04248046875, 0.0, 0.0234375, 0.00048828125, 0.18408203125, 0.0087890625, 0.00048828125, 0.2314453125, 0.1181640625, 0.09423828125, 0.080078125, 0.06103515625, 0.03125, 0.02392578125, 0.0185546875, 0.02783203125, 0.02490234375, 0.05712890625, 0.00048828125, 0.0, 0.484375, 0.0166015625, 0.00634765625, 0.0517578125, 0.0361328125, 0.0, 0.0107421875, 0.0, 0.5302734375, 0.0927734375, 0.0400390625, 0.0341796875, 0.0283203125, 0.12451171875, 0.01220703125, 0.01171875, 0.01171875, 0.00390625, 0.0498046875, 0.033203125, 0.00048828125, 0.03857421875, 0.00341796875, 0.03173828125, 0.02587890625, 0.04638671875, 0.30859375, 0.123046875, 0.0361328125, 0.02392578125, 0.03759765625, 0.09814453125, 0.07568359375, 0.04638671875, 0.02734375, 0.03125, 0.03515625, 0.01318359375, 0.02490234375, 0.3984375, 0.029296875, 0.02294921875, 0.0, 0.03515625, 0.0830078125, 0.02880859375, 0.0, 0.01318359375, 0.015625, 0.02392578125, 0.04931640625, 0.01416015625, 0.150390625, 0.0, 0.5947265625, 0.00048828125, 0.19677734375, 0.03271484375, 0.03564453125, 0.01611328125, 0.0, 0.0361328125, 0.03076171875, 0.01513671875, 0.033203125, 0.04638671875, 0.01220703125, 0.0078125, 0.0205078125, 0.0126953125, 0.54736328125, 0.03466796875, 0.033203125, 0.06005859375, 0.02783203125, 0.02490234375, 0.0126953125, 0.0166015625, 0.04833984375, 0.0087890625, 0.02197265625, 0.0, 0.205078125, 0.0234375, 0.1552734375, 0.0224609375, 0.03271484375, 0.009765625, 0.02783203125, 0.029296875, 0.0166015625, 0.046875, 0.0068359375, 0.01318359375, 0.01171875, 0.01318359375, 0.04736328125, 0.06396484375, 0.0322265625, 0.12646484375, 0.03125, 0.0, 0.021484375, 0.03662109375, 0.02197265625, 0.0419921875, 0.033203125, 0.03515625, 0.01025390625, 0.01318359375, 0.0205078125, 0.04248046875, 0.05908203125, 0.017578125, 0.99853515625, 0.0, 0.12109375, 0.0009765625, 0.0400390625, 0.06103515625, 0.99951171875, 0.01513671875, 0.009765625, 0.06201171875, 0.04443359375, 0.61865234375, 0.08251953125, 0.0537109375, 0.06689453125, 0.02880859375, 0.91357421875, 0.04052734375, 0.0, 0.0302734375, 0.02880859375, 0.07470703125, 0.02783203125, 0.001953125, 0.00048828125, 0.02685546875, 0.052734375, 0.01416015625, 0.0234375, 0.0751953125, 0.19580078125, 0.001953125, 0.03564453125, 0.00341796875, 0.0, 0.037109375, 0.01708984375, 0.00048828125, 0.0126953125, 0.01904296875, 0.203125, 0.046875, 0.11279296875, 0.0078125, 0.00048828125, 0.0185546875, 0.0146484375, 0.01318359375, 0.04052734375, 0.00537109375, 0.02880859375, 0.00390625, 0.0166015625, 0.02001953125, 0.02783203125, 0.0400390625, 0.07470703125, 0.01708984375, 0.01708984375, 0.056640625, 0.0146484375, 0.02197265625, 0.0126953125, 0.34814453125, 0.08056640625, 0.02099609375, 0.00048828125, 0.0576171875, 0.0234375, 0.02685546875, 0.00927734375, 0.001953125, 0.06005859375, 0.0390625, 0.06591796875, 0.056640625, 0.0947265625, 0.0068359375, 0.859375, 0.06396484375, 0.013671875, 0.0400390625, 0.904296875, 0.775390625, 0.0185546875, 0.02197265625, 0.0478515625, 0.005859375, 0.0458984375, 0.0, 0.07568359375, 0.03564453125, 0.01904296875, 0.021484375, 0.02978515625, 0.01220703125, 0.017578125, 0.0341796875, 0.0, 0.044921875, 0.0, 0.00537109375, 0.0146484375, 0.0234375, 0.0224609375, 0.02099609375, 0.00439453125, 0.0283203125, 0.0302734375, 0.037109375, 0.05712890625, 0.03955078125, 0.400390625, 0.0, 0.0244140625, 0.080078125, 0.021484375, 0.0048828125, 0.01806640625, 0.02734375, 0.0234375, 0.04541015625, 0.02734375, 0.09130859375, 0.15478515625, 0.04296875, 0.033203125, 0.025390625, 0.0380859375, 0.0712890625, 0.09228515625, 0.06591796875, 0.0126953125, 0.00830078125, 0.052734375, 0.017578125, 0.142578125, 0.02294921875, 0.0234375, 0.0244140625, 0.0, 0.06005859375, 0.0947265625, 0.0068359375, 0.02685546875, 0.015625, 0.0322265625, 0.0234375, 0.0078125, 0.53857421875, 0.03271484375, 0.0654296875, 0.0078125, 0.00634765625, 0.0380859375, 0.05078125, 0.0185546875, 0.41455078125, 0.09228515625, 0.01708984375, 0.0263671875, 0.08203125, 0.01123046875, 0.0126953125, 0.125, 0.005859375, 0.134765625, 0.0478515625, 0.02685546875, 0.0087890625, 0.0263671875, 0.02001953125, 0.095703125, 0.02587890625, 0.0185546875, 0.05322265625, 0.0205078125, 0.02783203125, 0.94970703125, 0.02001953125, 0.00244140625, 0.0107421875, 0.0751953125, 0.00732421875, 0.03125, 0.02294921875, 0.0234375, 0.05419921875, 0.111328125, 0.08935546875, 0.02490234375, 0.015625, 0.015625, 0.02587890625, 0.03955078125, 0.09228515625, 0.0224609375, 0.0107421875, 0.05078125, 0.00048828125, 0.0859375, 0.01513671875, 0.02001953125, 0.06689453125]

 sparsity of   [0.0703125, 0.0, 0.0010850694961845875, 0.0, 0.002170138992369175, 0.0015190972480922937, 0.01953125, 0.0, 0.0, 0.068359375, 0.181423619389534, 0.0588107630610466, 0.01171875, 0.02799479104578495, 0.0, 0.046875, 0.0, 0.0, 0.0342881940305233, 0.5329861044883728, 0.9995659589767456, 0.02886284701526165, 0.222439244389534, 0.0635850727558136, 0.02951388992369175, 0.0377604179084301, 0.0933159738779068, 0.0453559048473835, 0.0418836809694767, 0.5184462070465088, 0.1119791641831398, 0.00021701389050576836, 0.0900607630610466, 0.0646701380610466, 0.0223524309694767, 0.01323784701526165, 0.00021701389050576836, 0.009765625, 0.0164930559694767, 0.0245225690305233, 0.0212673619389534, 0.0, 0.9989149570465088, 0.00021701389050576836, 0.0967881977558136, 0.0223524309694767, 0.0323350690305233, 0.00021701389050576836, 0.1050347238779068, 0.0167100690305233, 0.007595486007630825, 0.0, 0.9982638955116272, 0.0492621548473835, 0.0, 0.0, 0.0, 0.0358072929084301, 0.013020833022892475, 0.01801215298473835, 0.0290798619389534, 0.009765625, 0.0399305559694767, 0.005642361007630825, 0.0518663190305233, 0.0, 0.004123263992369175, 0.0364583320915699, 0.0733506977558136, 0.0004340277810115367, 0.9982638955116272, 0.0394965298473835, 0.02973090298473835, 0.7248263955116272, 0.0, 0.00390625, 0.001953125, 0.0466579869389534, 0.0, 0.0, 0.0284288190305233, 0.0544704869389534, 0.00434027798473835, 0.0, 0.0032552082557231188, 0.002170138992369175, 0.02604166604578495, 0.0666232630610466, 0.0, 0.0, 0.00021701389050576836, 0.02756076492369175, 0.0065104165114462376, 0.0, 0.0466579869389534, 0.008897569961845875, 0.0, 0.00021701389050576836, 0.02083333395421505, 0.0648871511220932, 0.0883246511220932, 0.02473958395421505, 0.02560763992369175, 0.01410590298473835, 0.9997829794883728, 0.0618489570915699, 0.010850694961845875, 0.0, 0.08203125, 0.9995659589767456, 0.0282118059694767, 0.0193142369389534, 0.0, 0.119140625, 0.01996527798473835, 0.0, 0.0, 0.02604166604578495, 0.015625, 0.0034722222480922937, 0.0032552082557231188, 0.2684461772441864, 0.0, 0.00021701389050576836, 0.0785590261220932, 0.009765625, 0.0004340277810115367, 0.006076388992369175, 0.0212673619389534, 0.0052083334885537624, 0.015625, 0.00021701389050576836, 0.01996527798473835, 0.0232204869389534, 0.00021701389050576836, 0.1028645858168602, 0.0, 0.0, 0.01801215298473835, 0.0034722222480922937, 0.0067274305038154125, 0.046875, 0.0, 0.0, 0.0375434048473835, 0.015407986007630825, 0.100477434694767, 0.1000434011220932, 0.0555555559694767, 0.08984375, 0.0047743055038154125, 0.0718315988779068, 0.0, 0.0963541641831398, 0.00021701389050576836, 0.0444878488779068, 0.00021701389050576836, 0.1017795130610466, 0.2677951455116272, 0.0, 0.154079869389534, 0.0928819477558136, 0.12109375, 0.0, 0.008897569961845875, 0.00933159701526165, 0.0481770820915699, 0.0164930559694767, 0.02018229104578495, 0.01019965298473835, 0.0622829869389534, 0.0, 0.012803819961845875, 0.0004340277810115367, 0.0394965298473835, 0.0006510416860692203, 0.0, 0.03081597201526165, 0.00021701389050576836, 0.015625, 0.0, 0.0509982630610466, 0.0544704869389534, 0.490234375, 0.3880208432674408, 0.0, 0.0549045130610466, 0.0032552082557231188, 0.00021701389050576836, 0.0, 0.013020833022892475, 0.0284288190305233, 0.007595486007630825, 0.0303819440305233, 0.00021701389050576836, 0.00021701389050576836, 0.025390625, 0.01215277798473835, 0.0145399309694767, 0.0, 0.0004340277810115367, 0.0360243059694767, 0.00021701389050576836, 0.0447048619389534, 0.00021701389050576836, 0.0030381944961845875, 0.0625, 0.0559895820915699, 0.011067708022892475, 0.0, 0.0590277798473835, 0.5770399570465088, 0.0, 0.1032986119389534, 0.0, 0.0, 0.0010850694961845875, 0.01714409701526165, 0.0460069440305233, 0.010850694961845875, 0.0776909738779068, 0.0, 0.0, 0.0627170130610466, 0.0, 0.0657552108168602, 0.02582465298473835, 0.0, 0.0004340277810115367, 0.0531684048473835, 0.0, 0.012369791977107525, 0.0036892362404614687, 0.0, 0.0, 0.03125, 0.0004340277810115367, 0.00021701389050576836, 0.0603298619389534, 0.009548611007630825, 0.0323350690305233, 0.009114583022892475, 0.01888020895421505, 0.0, 0.03081597201526165, 0.015407986007630825, 0.00021701389050576836, 0.014322916977107525, 0.0006510416860692203, 0.004123263992369175, 0.00021701389050576836, 0.015625, 0.0, 0.01822916604578495, 0.01974826492369175, 0.00021701389050576836, 0.076171875, 0.0, 0.0010850694961845875, 0.01410590298473835, 0.02582465298473835, 0.00021701389050576836, 0.0349392369389534, 0.015625, 0.0167100690305233, 0.0518663190305233, 0.0768229141831398, 0.0, 0.01215277798473835, 0.1538628488779068, 0.0557725690305233, 0.0, 0.0262586809694767, 0.0, 0.0679253488779068, 0.0, 0.1762152761220932, 0.0473090298473835, 0.0364583320915699, 0.002170138992369175, 0.0290798619389534, 0.0394965298473835, 0.0086805559694767, 0.00021701389050576836, 0.086805559694767, 0.0334201380610466, 0.0, 0.0006510416860692203, 0.0703125, 0.0004340277810115367, 0.004123263992369175, 0.02278645895421505, 0.0065104165114462376, 0.2532552182674408, 0.011935763992369175, 0.01128472201526165, 0.0086805559694767, 0.1037326380610466, 0.0015190972480922937, 0.0067274305038154125, 0.0, 0.006076388992369175, 0.1245659738779068, 0.00021701389050576836, 0.9431423544883728, 0.3606770932674408, 0.00021701389050576836, 0.0397135429084301, 0.013454861007630825, 0.4806857705116272, 0.0193142369389534, 0.0, 0.014973958022892475, 0.0, 0.03125, 0.0, 0.0635850727558136, 0.008897569961845875, 0.0, 0.075086809694767, 0.03081597201526165, 0.05859375, 0.0512152798473835, 0.0078125, 0.0, 0.0379774309694767, 0.02973090298473835, 0.0, 0.0, 0.01519097201526165, 0.0861545130610466, 0.0, 0.00021701389050576836, 0.0, 0.052734375, 0.0, 0.0384114570915699, 0.046875, 0.0234375, 0.0, 0.00021701389050576836, 0.094618059694767, 0.02560763992369175, 0.0, 0.0, 0.01801215298473835, 0.0184461809694767, 0.0, 0.01692708395421505, 0.1111111119389534, 0.0, 0.0, 0.0, 0.9997829794883728, 0.0006510416860692203, 0.02734375, 0.0004340277810115367, 0.0290798619389534, 0.0503472238779068, 0.0006510416860692203, 0.048828125, 0.4691840410232544, 0.6032986044883728, 0.0403645820915699, 0.0015190972480922937, 0.0193142369389534, 0.263671875, 0.0004340277810115367, 0.0707465261220932, 0.0, 0.02495659701526165, 0.008897569961845875, 0.00021701389050576836, 0.0067274305038154125, 0.0, 0.0, 0.008029513992369175, 0.0724826380610466, 0.015625, 0.0, 0.1228298619389534, 0.0523003488779068, 0.0399305559694767, 0.025390625, 0.0232204869389534, 0.01019965298473835, 0.0, 0.02191840298473835, 0.0234375, 0.9800347089767456, 0.014322916977107525, 0.008029513992369175, 0.0520833320915699, 0.02886284701526165, 0.881944477558136, 0.0, 0.1321614533662796, 0.0342881940305233, 0.02495659701526165, 0.0036892362404614687, 0.0531684048473835, 0.1440972238779068, 0.0, 0.00021701389050576836, 0.021484375, 0.0, 0.0, 0.0, 0.046875, 0.02213541604578495, 0.0729166641831398, 0.00021701389050576836, 0.0, 0.0, 0.013454861007630825, 0.0, 0.3118489682674408, 0.0, 0.0052083334885537624, 0.0, 0.197048619389534, 0.0034722222480922937, 0.00021701389050576836, 0.0638020858168602, 0.0, 0.0544704869389534, 0.0737847238779068, 0.02994791604578495, 0.0336371548473835, 0.0525173619389534, 0.2100694477558136, 0.0913628488779068, 0.02994791604578495, 0.0397135429084301, 0.0, 0.1447482705116272, 0.03515625, 0.0013020833721384406, 0.0, 0.0930989608168602, 0.0490451380610466, 0.0034722222480922937, 0.017578125, 0.02408854104578495, 0.0, 0.00021701389050576836, 0.013671875, 0.01215277798473835, 0.0, 0.01627604104578495, 0.0078125, 0.0, 0.0368923619389534, 0.008463541977107525, 0.00021701389050576836, 0.9175347089767456, 0.012803819961845875, 0.0, 0.0390625, 0.09375, 0.01215277798473835, 0.004123263992369175, 0.0, 0.012803819961845875, 0.0013020833721384406, 0.017578125, 0.0464409738779068, 0.0885416641831398, 0.0167100690305233, 0.999131977558136, 0.372612863779068, 0.0203993059694767, 0.8294270634651184, 0.0772569477558136, 0.0310329869389534, 0.086805559694767, 0.00021701389050576836, 0.01779513992369175, 0.00629340298473835, 0.0, 0.0, 0.00021701389050576836, 0.0193142369389534, 0.0345052070915699, 0.067274309694767, 0.0, 0.0592447929084301, 0.0069444444961845875, 0.0010850694961845875, 0.0271267369389534, 0.3934461772441864, 0.9984809160232544, 0.0065104165114462376, 0.0023871527519077063, 0.2421875, 0.001953125, 0.072265625, 0.0347222238779068, 0.0726996511220932, 0.00021701389050576836, 0.4283854067325592, 0.02083333395421505, 0.0006510416860692203, 0.0325520820915699, 0.0028211805038154125, 0.0028211805038154125, 0.0368923619389534, 0.0427517369389534, 0.0451388880610466, 0.01519097201526165, 0.1881510466337204, 0.0464409738779068]

 sparsity of   [0.0234375, 0.033203125, 0.025390625, 0.02734375, 0.17578125, 0.1171875, 0.01953125, 0.015625, 0.15625, 0.103515625, 0.017578125, 0.072265625, 0.1953125, 0.005859375, 0.078125, 0.0234375, 0.205078125, 0.0234375, 0.09375, 0.0234375, 0.953125, 0.0234375, 0.55859375, 0.021484375, 0.001953125, 0.072265625, 0.052734375, 0.06640625, 0.029296875, 0.787109375, 0.50390625, 0.080078125, 0.01171875, 0.00390625, 0.0078125, 0.048828125, 0.017578125, 0.025390625, 0.013671875, 0.02734375, 0.06640625, 0.052734375, 0.03515625, 0.0078125, 0.525390625, 0.033203125, 0.111328125, 0.181640625, 0.1171875, 0.037109375, 0.033203125, 0.021484375, 0.064453125, 0.515625, 0.0, 0.021484375, 0.025390625, 0.994140625, 0.107421875, 0.587890625, 0.013671875, 0.037109375, 0.00390625, 0.017578125, 0.962890625, 0.041015625, 0.029296875, 0.275390625, 0.01171875, 0.78515625, 0.07421875, 0.20703125, 0.03515625, 0.724609375, 0.005859375, 0.0234375, 0.607421875, 0.876953125, 0.908203125, 0.044921875, 0.013671875, 0.005859375, 0.005859375, 0.10546875, 0.091796875, 0.546875, 0.021484375, 0.015625, 0.078125, 0.376953125, 0.220703125, 0.7421875, 0.001953125, 0.20703125, 0.0859375, 0.267578125, 0.025390625, 0.048828125, 0.03515625, 0.83203125, 0.02734375, 0.0234375, 0.02734375, 0.005859375, 0.046875, 0.1171875, 0.05078125, 0.109375, 0.65625, 0.8515625, 0.279296875, 0.04296875, 0.2265625, 0.99609375, 0.16015625, 0.14453125, 0.048828125, 0.04296875, 0.0703125, 0.08984375, 0.0703125, 0.046875, 0.03515625, 0.060546875, 0.3671875, 0.259765625, 0.01953125, 0.306640625, 0.001953125, 0.025390625, 0.109375, 0.099609375, 0.064453125, 0.00390625, 0.09765625, 0.125, 0.0078125, 0.8828125, 0.064453125, 0.046875, 0.025390625, 0.0703125, 0.833984375, 0.044921875, 0.02734375, 0.015625, 0.998046875, 0.03515625, 0.08203125, 0.08984375, 0.08984375, 0.76171875, 0.029296875, 0.029296875, 0.015625, 0.3828125, 0.029296875, 0.0234375, 0.037109375, 0.041015625, 0.109375, 0.033203125, 0.052734375, 0.037109375, 0.044921875, 0.03125, 0.0390625, 0.177734375, 0.005859375, 0.091796875, 0.01953125, 0.013671875, 0.6015625, 0.02734375, 0.041015625, 0.04296875, 0.03125, 0.001953125, 0.056640625, 0.021484375, 0.095703125, 0.064453125, 0.859375, 0.029296875, 0.056640625, 0.00390625, 0.1328125, 0.16015625, 0.052734375, 0.005859375, 0.078125, 0.0859375, 0.07421875, 0.4375, 0.015625, 0.052734375, 0.046875, 0.001953125, 0.193359375, 0.02734375, 0.0234375, 0.119140625, 0.99609375, 0.078125, 0.046875, 0.01953125, 0.017578125, 0.01171875, 0.037109375, 0.06640625, 0.005859375, 0.021484375, 0.99609375, 0.017578125, 0.111328125, 0.0390625, 0.912109375, 0.0234375, 0.01953125, 0.029296875, 0.1484375, 0.087890625, 0.08984375, 0.044921875, 0.0078125, 0.009765625, 0.01171875, 0.017578125, 0.193359375, 0.00390625, 0.015625, 0.06640625, 0.115234375, 0.005859375, 0.99609375, 0.154296875, 0.0, 0.0, 0.0390625, 0.107421875, 0.998046875, 0.994140625, 0.0625, 0.091796875, 0.021484375, 0.0, 0.08203125, 0.1171875, 0.7109375, 0.064453125, 0.791015625, 0.634765625, 0.01171875, 0.046875, 0.171875, 0.11328125, 0.03125, 0.01953125, 0.01171875, 0.162109375, 0.029296875, 0.029296875, 0.01953125, 0.14453125, 0.73046875, 0.015625, 0.046875, 0.158203125, 0.037109375, 0.04296875, 0.05078125, 0.0625, 0.03515625, 0.01953125, 0.02734375, 0.005859375, 0.0625, 0.603515625, 0.0625, 0.86328125, 0.0703125, 0.89453125, 0.03515625, 0.033203125, 0.158203125, 0.02734375, 0.0546875, 0.05078125, 0.037109375, 0.0546875, 0.27734375, 0.080078125, 0.53125, 0.056640625, 0.078125, 0.01953125, 0.416015625, 0.001953125, 0.99609375, 0.16015625, 0.48828125, 0.478515625, 0.48046875, 0.009765625, 0.005859375, 0.00390625, 0.1640625, 0.705078125, 0.189453125, 0.009765625, 0.03125, 0.005859375, 0.861328125, 0.0390625, 0.015625, 0.046875, 0.017578125, 0.0234375, 0.111328125, 0.296875, 0.033203125, 0.537109375, 0.994140625, 0.03515625, 0.021484375, 0.04296875, 0.04296875, 0.58984375, 0.03125, 0.0234375, 0.04296875, 0.310546875, 0.025390625, 0.0859375, 0.04296875, 0.5859375, 0.00390625, 0.181640625, 0.04296875, 0.548828125, 0.04296875, 0.046875, 0.013671875, 0.701171875, 0.0078125, 0.04296875, 0.076171875, 0.04296875, 0.017578125, 0.09765625, 0.001953125, 0.005859375, 0.01171875, 0.638671875, 0.087890625, 0.005859375, 0.01953125, 0.017578125, 0.998046875, 0.763671875, 0.99609375, 0.001953125, 0.99609375, 0.017578125, 0.013671875, 0.16015625, 0.00390625, 0.064453125, 0.28125, 0.994140625, 0.01953125, 0.078125, 0.646484375, 0.037109375, 0.0078125, 0.107421875, 0.109375, 0.630859375, 0.060546875, 0.048828125, 0.04296875, 0.125, 0.0234375, 0.171875, 0.943359375, 0.666015625, 0.19140625, 0.091796875, 0.009765625, 0.08984375, 0.03515625, 0.083984375, 0.99609375, 0.0234375, 0.201171875, 0.703125, 0.06640625, 0.013671875, 0.02734375, 0.009765625, 0.064453125, 0.150390625, 0.255859375, 0.015625, 0.9453125, 0.009765625, 0.00390625, 0.037109375, 0.056640625, 0.01953125, 0.443359375, 0.1171875, 0.3359375, 0.037109375, 0.068359375, 0.041015625, 0.681640625, 0.099609375, 0.09765625, 0.029296875, 0.015625, 0.013671875, 0.642578125, 0.015625, 0.1953125, 0.07421875, 0.1171875, 0.80859375, 0.224609375, 0.03515625, 0.05078125, 0.03515625, 0.029296875, 0.111328125, 0.03125, 0.033203125, 0.025390625, 0.45703125, 0.650390625, 0.0234375, 0.0234375, 0.044921875, 0.3671875, 0.0078125, 0.083984375, 0.048828125, 0.13671875, 0.001953125, 0.03515625, 0.099609375, 0.994140625, 0.001953125, 0.052734375, 0.0390625, 0.00390625, 0.0, 0.0390625, 0.0234375, 0.078125, 0.103515625, 0.02734375, 0.138671875, 0.02734375, 0.65625, 0.046875, 0.0546875, 0.041015625, 0.041015625, 0.056640625, 0.11328125, 0.0234375, 0.064453125, 0.029296875, 0.009765625, 0.103515625, 0.01953125, 0.001953125, 0.080078125, 0.103515625, 0.9765625, 0.009765625, 0.109375, 0.125, 0.048828125, 0.009765625, 0.021484375, 0.015625, 0.021484375, 0.1171875, 0.15234375, 0.01171875, 0.01953125, 0.029296875, 0.048828125, 0.009765625, 0.005859375, 0.72265625, 0.00390625, 0.03125, 0.115234375, 0.03125, 0.01953125, 0.05078125, 0.033203125, 0.52734375, 0.462890625, 0.017578125, 0.01171875, 0.01171875, 0.041015625, 0.994140625, 0.01171875, 0.01171875, 0.060546875, 0.01171875, 0.689453125, 0.099609375, 0.05859375, 0.02734375, 0.11328125, 0.068359375, 0.06640625, 0.80859375, 0.00390625, 0.94921875, 0.125, 0.021484375, 0.994140625, 0.353515625, 0.03515625, 0.0234375, 0.080078125, 0.03515625, 0.03125, 0.7265625, 0.015625, 0.162109375, 0.0390625, 0.0078125, 0.755859375, 0.03125, 0.03125, 0.02734375, 0.994140625, 0.546875, 0.01171875, 0.064453125, 0.7578125, 0.8046875, 0.310546875, 0.02734375, 0.0078125, 0.18359375, 0.0625, 0.013671875, 0.220703125, 0.08203125, 0.01171875, 0.86328125, 0.37109375, 0.009765625, 0.08203125, 0.0859375, 0.03125, 0.125, 0.083984375, 0.6875, 0.0390625, 0.0546875, 0.99609375, 0.00390625, 0.08984375, 0.2578125, 0.00390625, 0.01171875, 0.89453125, 0.19921875, 0.00390625, 0.07421875, 0.0078125, 0.01953125, 0.048828125, 0.451171875, 0.796875, 0.84375, 0.0546875, 0.0625, 0.009765625, 0.017578125, 0.056640625, 0.0625, 0.125, 0.041015625, 0.3359375, 0.0703125, 0.029296875, 0.052734375, 0.021484375, 0.1953125, 0.998046875, 0.041015625, 0.0703125, 0.052734375, 0.0390625, 0.078125, 0.10546875, 0.29296875, 0.033203125, 0.498046875, 0.044921875, 0.033203125, 0.044921875, 0.224609375, 0.185546875, 0.201171875, 0.080078125, 0.02734375, 0.0234375, 0.626953125, 0.02734375, 0.150390625, 0.013671875, 0.0546875, 0.103515625, 0.056640625, 0.0078125, 0.017578125, 0.767578125, 0.03125, 0.052734375, 0.0546875, 0.96875, 0.015625, 0.05859375, 0.01953125, 0.00390625, 0.00390625, 0.869140625, 0.86328125, 0.0546875, 0.185546875, 0.048828125, 0.142578125, 0.1171875, 0.064453125, 0.013671875, 0.18359375, 0.017578125, 0.0234375, 0.16796875, 0.037109375, 0.05078125, 0.001953125, 0.0078125, 0.046875, 0.064453125, 0.09375, 0.0859375, 0.01953125, 0.015625, 0.021484375, 0.140625, 0.037109375, 0.1171875, 0.05859375, 0.435546875, 0.009765625, 0.0625, 0.044921875, 0.01953125, 0.005859375, 0.015625, 0.005859375, 0.330078125, 0.0390625, 0.029296875, 0.017578125, 0.078125, 0.068359375, 0.037109375, 0.021484375, 0.037109375, 0.27734375, 0.125, 0.5625, 0.0390625, 0.08203125, 0.994140625, 0.015625, 0.009765625, 0.115234375, 0.177734375, 0.095703125, 0.060546875, 0.06640625, 0.7890625, 0.0859375, 0.056640625, 0.0859375, 0.060546875, 0.03125, 0.048828125, 0.03125, 0.044921875, 0.994140625, 0.0, 0.19921875, 0.033203125, 0.01171875, 0.166015625, 0.13671875, 0.01953125, 0.04296875, 0.025390625, 0.0859375, 0.994140625, 0.013671875, 0.029296875, 0.228515625, 0.234375, 0.015625, 0.0078125, 0.037109375, 0.02734375, 0.04296875, 0.021484375, 0.025390625, 0.029296875, 0.935546875, 0.04296875, 0.02734375, 0.015625, 0.05078125, 0.07421875, 0.02734375, 0.76171875, 0.19140625, 0.041015625, 0.013671875, 0.01953125, 0.091796875, 0.046875, 0.04296875, 0.0703125, 0.04296875, 0.017578125, 0.09375, 0.01171875, 0.01171875, 0.00390625, 0.005859375, 0.267578125, 0.064453125, 0.005859375, 0.05078125, 0.1640625, 0.01171875, 0.033203125, 0.017578125, 0.0390625, 0.015625, 0.046875, 0.056640625, 0.763671875, 0.583984375, 0.013671875, 0.021484375, 0.904296875, 0.01953125, 0.056640625, 0.05859375, 0.0625, 0.01171875, 0.0, 0.03515625, 0.689453125, 0.0, 0.078125, 0.01171875, 0.078125, 0.1171875, 0.16015625, 0.18359375, 0.0078125, 0.01171875, 0.021484375, 0.72265625, 0.54296875, 0.142578125, 0.021484375, 0.99609375, 0.65625, 0.86328125, 0.119140625, 0.05859375, 0.037109375, 0.02734375, 0.029296875, 0.029296875, 0.99609375, 0.787109375, 0.0859375, 0.080078125, 0.02734375, 0.0234375, 0.09375, 0.0078125, 0.61328125, 0.099609375, 0.05859375, 0.091796875, 0.5546875, 0.203125, 0.71484375, 0.013671875, 0.015625, 0.02734375, 0.009765625, 0.119140625, 0.02734375, 0.43359375, 0.11328125, 0.671875, 0.134765625, 0.087890625, 0.01171875, 0.048828125, 0.8046875, 0.052734375, 0.04296875, 0.62890625, 0.994140625, 0.109375, 0.04296875, 0.03515625, 0.03515625, 0.0234375, 0.025390625, 0.015625, 0.001953125, 0.0078125, 0.9140625, 0.046875, 0.994140625, 0.060546875, 0.43359375, 0.0, 0.072265625, 0.044921875, 0.033203125, 0.005859375, 0.01953125, 0.064453125, 0.033203125, 0.21875, 0.03125, 0.08203125, 0.921875, 0.021484375, 0.005859375, 0.75390625, 0.12109375, 0.1015625, 0.998046875, 0.41015625, 0.056640625, 0.017578125, 0.0703125, 0.189453125, 0.330078125, 0.0, 0.875, 0.005859375, 0.017578125, 0.056640625, 0.0703125, 0.107421875, 0.04296875, 0.0234375, 0.03515625, 0.341796875, 0.228515625, 0.021484375, 0.03515625, 0.021484375, 0.0546875, 0.001953125, 0.072265625, 0.03125, 0.015625, 0.005859375, 0.037109375, 0.064453125, 0.037109375, 0.173828125, 0.05859375, 0.19140625, 0.931640625, 0.0390625, 0.578125, 0.025390625, 0.056640625, 0.017578125, 0.99609375, 0.998046875, 0.009765625, 0.02734375, 0.025390625, 0.052734375, 0.2265625, 0.044921875, 0.03515625, 0.640625, 0.01953125, 0.583984375, 0.056640625, 0.017578125, 0.3125, 0.02734375, 0.091796875, 0.01171875, 0.029296875, 0.064453125, 0.748046875, 0.02734375, 0.107421875, 0.044921875, 0.349609375, 0.025390625, 0.44140625, 0.28515625, 0.021484375, 0.025390625, 0.3359375, 0.046875, 0.00390625, 0.048828125, 0.013671875, 0.126953125, 0.05078125, 0.994140625, 0.009765625, 0.994140625, 0.025390625, 0.0078125, 0.935546875, 0.087890625, 0.017578125, 0.0546875, 0.0546875, 0.046875, 0.00390625, 0.052734375, 0.072265625, 0.984375, 0.029296875, 0.236328125, 0.04296875, 0.017578125, 0.09765625, 0.896484375, 0.021484375, 0.00390625, 0.86328125, 0.001953125, 0.587890625, 0.03515625, 0.052734375, 0.013671875, 0.005859375, 0.958984375, 0.00390625, 0.15234375, 0.015625, 0.009765625, 0.029296875, 0.048828125, 0.05078125, 0.595703125, 0.955078125, 0.123046875, 0.044921875, 0.23046875, 0.009765625, 0.03515625, 0.158203125, 0.15625, 0.08203125, 0.015625, 0.146484375, 0.021484375, 0.0234375, 0.056640625, 0.01171875, 0.03125, 0.015625, 0.99609375, 0.10546875, 0.0078125, 0.80078125, 0.126953125, 0.01953125, 0.443359375, 0.998046875, 0.005859375, 0.091796875, 0.072265625, 0.103515625, 0.05859375, 0.029296875, 0.0, 0.01171875, 0.748046875, 0.015625, 0.033203125, 0.01171875, 0.03125, 0.01953125, 0.08203125, 0.125, 0.017578125, 0.05078125, 0.12109375, 0.021484375, 0.0859375, 0.205078125, 0.05078125, 0.044921875, 0.1484375, 0.013671875, 0.03515625, 0.06640625, 0.025390625, 0.046875, 0.205078125, 0.203125, 0.048828125, 0.1640625, 0.05078125, 0.072265625, 0.037109375, 0.107421875, 0.1015625, 0.681640625, 0.017578125, 0.150390625, 0.05078125, 0.619140625, 0.037109375, 0.99609375, 0.021484375, 0.099609375, 0.03515625, 0.005859375, 0.1796875, 0.017578125, 0.017578125, 0.033203125, 0.015625, 0.07421875, 0.060546875, 0.064453125, 0.025390625, 0.201171875, 0.17578125, 0.01953125, 0.998046875, 0.015625, 0.00390625, 0.052734375, 0.0078125, 0.1484375, 0.009765625, 0.009765625, 0.138671875, 0.01171875, 0.015625, 0.90234375, 0.03125, 0.734375, 0.232421875, 0.005859375, 0.064453125, 0.015625, 0.224609375, 0.103515625, 0.05859375, 0.017578125, 0.806640625, 0.07421875, 0.7109375, 0.591796875, 0.115234375, 0.060546875, 0.0390625, 0.001953125, 0.021484375, 0.0, 0.017578125, 0.048828125, 0.21875, 0.07421875, 0.037109375, 0.0078125, 0.015625, 0.029296875, 0.02734375, 0.826171875, 0.994140625, 0.052734375, 0.001953125, 0.0234375, 0.005859375, 0.056640625, 0.046875, 0.220703125, 0.013671875, 0.0078125, 0.994140625, 0.767578125, 0.033203125, 0.033203125, 0.05859375, 0.072265625, 0.06640625, 0.44140625, 0.0546875, 0.267578125, 0.90234375, 0.009765625, 0.08984375, 0.025390625, 0.044921875, 0.0, 0.013671875, 0.77734375, 0.033203125, 0.01953125, 0.10546875, 0.626953125, 0.0078125, 0.013671875, 0.015625, 0.005859375, 0.02734375, 0.021484375, 0.033203125, 0.033203125, 0.037109375, 0.01953125, 0.009765625, 0.041015625, 0.029296875, 0.078125, 0.033203125, 0.13671875, 0.216796875, 0.8671875, 0.03125, 0.013671875, 0.08984375, 0.998046875, 0.60546875, 0.01171875, 0.078125, 0.04296875, 0.576171875, 0.111328125, 0.03515625, 0.037109375, 0.005859375, 0.83984375, 0.048828125, 0.994140625, 0.037109375, 0.0, 0.09375, 0.08203125, 0.037109375, 0.001953125, 0.708984375, 0.05859375, 0.041015625, 0.029296875, 0.0, 0.029296875, 0.2734375, 0.00390625, 0.06640625, 0.029296875, 0.029296875, 0.060546875, 0.0546875, 0.251953125, 0.005859375, 0.994140625, 0.04296875, 0.029296875, 0.009765625, 0.06640625, 0.037109375, 0.11328125, 0.0078125, 0.03125, 0.0, 0.044921875, 0.01953125, 0.068359375, 0.08984375, 0.009765625, 0.2421875, 0.0859375, 0.130859375, 0.0546875, 0.0546875, 0.0390625, 0.068359375, 0.0078125, 0.01953125, 0.2265625, 0.103515625, 0.052734375, 0.0390625, 0.09375, 0.013671875, 0.06640625, 0.005859375, 0.0546875, 0.107421875, 0.71484375, 0.046875, 0.15234375, 0.01953125, 0.025390625, 0.185546875, 0.009765625, 0.044921875, 0.0078125, 0.017578125, 0.19921875, 0.07421875, 0.0546875, 0.017578125, 0.041015625, 0.09375, 0.107421875, 0.033203125, 0.001953125, 0.044921875, 0.0078125, 0.1171875, 0.107421875, 0.1484375, 0.05859375, 0.091796875, 0.0859375, 0.060546875, 0.00390625, 0.025390625, 0.08203125, 0.005859375, 0.013671875, 0.0078125, 0.0546875, 0.107421875, 0.087890625, 0.994140625, 0.052734375, 0.951171875, 0.11328125, 0.017578125, 0.064453125, 0.70703125, 0.724609375, 0.03125, 0.00390625, 0.033203125, 0.029296875, 0.177734375, 0.044921875, 0.044921875, 0.025390625, 0.5625, 0.021484375, 0.494140625, 0.00390625, 0.048828125, 0.564453125, 0.00390625, 0.0234375, 0.076171875, 0.01171875, 0.068359375, 0.31640625, 0.0390625, 0.078125, 0.994140625, 0.666015625, 0.01171875, 0.046875, 0.076171875, 0.0078125, 0.04296875, 0.07421875, 0.0, 0.041015625, 0.087890625, 0.8984375, 0.17578125, 0.01171875, 0.00390625, 0.12109375, 0.0, 0.044921875, 0.58984375, 0.05078125, 0.50390625, 0.1328125, 0.052734375, 0.05859375, 0.0078125, 0.037109375, 0.1015625, 0.00390625, 0.1015625, 0.013671875, 0.03125, 0.044921875, 0.00390625, 0.994140625, 0.21875, 0.080078125, 0.041015625, 0.015625, 0.87109375, 0.005859375, 0.087890625, 0.025390625, 0.015625, 0.994140625, 0.10546875, 0.123046875, 0.0078125, 0.818359375, 0.037109375, 0.0390625, 0.11328125, 0.107421875, 0.03125, 0.046875, 0.033203125, 0.02734375, 0.11328125, 0.953125, 0.0234375, 0.908203125, 0.01171875, 0.181640625, 0.03515625, 0.255859375, 0.009765625, 0.044921875, 0.0234375, 0.048828125, 0.037109375, 0.0625, 0.77734375, 0.01953125, 0.111328125, 0.0078125, 0.91015625, 0.072265625, 0.03125, 0.19140625, 0.03125, 0.1015625, 0.07421875, 0.03515625, 0.009765625, 0.35546875, 0.01171875, 0.234375, 0.017578125, 0.021484375, 0.837890625, 0.0, 0.93359375, 0.021484375, 0.076171875, 0.81640625, 0.01953125, 0.021484375, 0.03515625, 0.123046875, 0.005859375, 0.02734375, 0.0625, 0.07421875, 0.041015625, 0.25390625, 0.10546875, 0.283203125, 0.03515625, 0.001953125, 0.216796875, 0.966796875, 0.013671875, 0.078125, 0.05078125, 0.0078125, 0.0625, 0.166015625, 0.033203125, 0.576171875, 0.013671875, 0.0234375, 0.025390625, 0.048828125, 0.052734375, 0.015625, 0.04296875, 0.05078125, 0.01953125, 0.0078125, 0.01953125, 0.05859375, 0.79296875, 0.0390625, 0.009765625, 0.630859375, 0.091796875, 0.05078125, 0.08203125, 0.39453125, 0.052734375, 0.041015625, 0.69921875, 0.88671875, 0.88671875, 0.681640625, 0.076171875, 0.080078125, 0.0703125, 0.009765625, 0.3125, 0.03515625, 0.533203125, 0.044921875, 0.06640625, 0.0859375, 0.087890625, 0.646484375, 0.0703125, 0.525390625, 0.150390625, 0.009765625, 0.994140625, 0.083984375, 0.02734375, 0.181640625, 0.037109375, 0.009765625, 0.08984375, 0.04296875, 0.025390625, 0.095703125, 0.04296875, 0.994140625, 0.021484375, 0.033203125, 0.255859375, 0.177734375, 0.021484375, 0.087890625, 0.0625, 0.0234375, 0.068359375, 0.0390625, 0.015625, 0.775390625, 0.634765625, 0.009765625, 0.009765625, 0.001953125, 0.076171875, 0.044921875, 0.06640625, 0.248046875, 0.11328125, 0.037109375, 0.0078125, 0.12109375, 0.693359375, 0.041015625, 0.99609375, 0.01953125, 0.01171875, 0.013671875, 0.115234375, 0.015625, 0.029296875, 0.009765625, 0.013671875, 0.068359375, 0.060546875, 0.05078125, 0.0078125, 0.125, 0.078125, 0.7109375, 0.962890625, 0.0078125, 0.634765625, 0.0234375, 0.345703125, 0.134765625, 0.92578125, 0.001953125, 0.052734375, 0.853515625, 0.029296875, 0.900390625, 0.052734375, 0.037109375, 0.01953125, 0.05078125, 0.025390625, 0.173828125, 0.505859375, 0.666015625, 0.158203125, 0.013671875, 0.021484375, 0.142578125, 0.064453125, 0.041015625, 0.05859375, 0.02734375, 0.03515625, 0.08203125, 0.02734375, 0.498046875, 0.609375, 0.056640625, 0.052734375, 0.220703125, 0.75, 0.0, 0.6796875, 0.041015625, 0.81640625, 0.046875, 0.57421875, 0.033203125, 0.046875, 0.11328125, 0.06640625, 0.908203125, 0.01953125, 0.166015625, 0.1875, 0.080078125, 0.099609375, 0.044921875, 0.02734375, 0.3671875, 0.07421875, 0.01953125, 0.037109375, 0.99609375, 0.021484375, 0.05859375, 0.056640625, 0.06640625, 0.029296875, 0.001953125, 0.017578125, 0.02734375, 0.1640625, 0.8828125, 0.484375, 0.0390625, 0.015625, 0.0546875, 0.248046875, 0.0234375, 0.068359375, 0.0078125, 0.0078125, 0.0390625, 0.01171875, 0.05078125, 0.00390625, 0.994140625, 0.0234375, 0.021484375, 0.119140625, 0.009765625, 0.0078125, 0.072265625, 0.8125, 0.845703125, 0.115234375, 0.041015625, 0.30078125, 0.8984375, 0.044921875, 0.009765625, 0.08984375, 0.0078125, 0.009765625, 0.8671875, 0.048828125, 0.099609375, 0.5859375, 0.498046875, 0.005859375, 0.123046875, 0.08203125, 0.005859375, 0.029296875, 0.6875, 0.029296875, 0.0390625, 0.0390625, 0.017578125, 0.080078125, 0.0234375, 0.099609375, 0.146484375, 0.009765625, 0.0546875, 0.08984375, 0.017578125, 0.611328125, 0.080078125, 0.12109375, 0.025390625, 0.0234375, 0.12890625, 0.0546875, 0.6484375, 0.017578125, 0.1484375, 0.779296875, 0.05078125, 0.00390625, 0.05859375, 0.998046875, 0.658203125, 0.029296875, 0.14453125, 0.0390625, 0.0546875, 0.033203125, 0.025390625, 0.693359375, 0.017578125, 0.03125, 0.2734375, 0.09765625, 0.505859375, 0.005859375, 0.857421875, 0.033203125, 0.052734375, 0.05859375, 0.037109375, 0.0625, 0.12109375, 0.033203125, 0.013671875, 0.021484375, 0.732421875, 0.048828125, 0.103515625, 0.009765625, 0.013671875, 0.0234375, 0.083984375, 0.994140625, 0.083984375, 0.013671875, 0.01953125, 0.01171875, 0.93359375, 0.037109375, 0.71875, 0.06640625, 0.00390625, 0.0078125, 0.037109375, 0.998046875, 0.052734375, 0.046875, 0.001953125, 0.037109375, 0.03515625, 0.029296875, 0.03515625, 0.0078125, 0.08203125, 0.013671875, 0.048828125, 0.017578125, 0.05078125, 0.994140625, 0.017578125, 0.05078125, 0.998046875, 0.052734375, 0.091796875, 0.017578125, 0.16796875, 0.025390625, 0.169921875, 0.03515625, 0.015625, 0.06640625, 0.724609375, 0.537109375, 0.02734375, 0.009765625, 0.001953125, 0.0390625, 0.0234375, 0.138671875, 0.025390625, 0.08984375, 0.169921875, 0.017578125, 0.005859375, 0.087890625, 0.037109375, 0.0078125, 0.11328125, 0.029296875, 0.96484375, 0.03515625, 0.0078125, 0.81640625, 0.994140625, 0.470703125, 0.23046875, 0.03125, 0.03125, 0.509765625, 0.921875, 0.0, 0.193359375, 0.02734375, 0.052734375, 0.01171875, 0.01171875, 0.994140625, 0.005859375, 0.033203125, 0.142578125, 0.01953125, 0.833984375, 0.123046875, 0.0859375, 0.998046875, 0.01953125, 0.03125, 0.0234375, 0.001953125, 0.025390625, 0.30859375, 0.19921875, 0.923828125, 0.01953125, 0.328125, 0.017578125, 0.998046875, 0.009765625, 0.021484375, 0.0703125, 0.2890625, 0.080078125, 0.94921875, 0.029296875, 0.06640625, 0.099609375, 0.005859375, 0.01171875, 0.505859375, 0.04296875, 0.0546875, 0.45703125, 0.13671875, 0.375, 0.0234375, 0.0234375, 0.02734375, 0.048828125, 0.130859375, 0.994140625, 0.6328125, 0.205078125, 0.0546875, 0.060546875, 0.08203125, 0.009765625, 0.01953125, 0.1328125, 0.044921875, 0.033203125, 0.00390625, 0.01171875, 0.60546875, 0.99609375, 0.013671875, 0.025390625, 0.0078125, 0.037109375, 0.009765625, 0.1015625, 0.06640625, 0.833984375, 0.0, 0.06640625, 0.00390625, 0.021484375, 0.103515625, 0.044921875, 0.013671875, 0.01953125, 0.009765625, 0.076171875, 0.046875, 0.03515625, 0.021484375, 0.0078125, 0.400390625, 0.009765625, 0.04296875, 0.12890625, 0.19140625, 0.07421875, 0.04296875, 0.0390625, 0.619140625, 0.603515625, 0.005859375, 0.111328125, 0.99609375, 0.02734375, 0.662109375, 0.009765625, 0.037109375, 0.05859375, 0.1171875, 0.078125, 0.00390625, 0.6875, 0.013671875, 0.05859375, 0.015625, 0.013671875, 0.005859375, 0.037109375, 0.015625, 0.546875, 0.091796875, 0.025390625, 0.001953125, 0.037109375, 0.99609375, 0.060546875, 0.02734375, 0.013671875, 0.455078125, 0.05078125, 0.017578125, 0.013671875, 0.015625, 0.994140625, 0.0078125, 0.015625, 0.01953125, 0.0390625, 0.201171875, 0.154296875, 0.99609375, 0.025390625, 0.158203125, 0.015625, 0.171875, 0.10546875, 0.044921875, 0.15625, 0.009765625, 0.41796875, 0.048828125, 0.755859375, 0.140625, 0.017578125, 0.001953125, 0.994140625, 0.01171875, 0.021484375, 0.015625, 0.013671875, 0.203125, 0.03125, 0.62109375, 0.0390625, 0.01171875, 0.021484375, 0.0, 0.060546875, 0.75390625, 0.1953125, 0.068359375, 0.0390625, 0.005859375, 0.12109375, 0.140625, 0.06640625, 0.12890625, 0.06640625, 0.05859375, 0.072265625, 0.052734375, 0.0546875, 0.072265625, 0.03515625, 0.0078125, 0.009765625, 0.017578125, 0.12109375, 0.015625, 0.142578125, 0.0234375, 0.74609375, 0.0078125, 0.025390625, 0.029296875, 0.0390625, 0.048828125, 0.107421875, 0.033203125, 0.025390625, 0.197265625, 0.017578125, 0.037109375, 0.033203125, 0.66796875, 0.23046875, 0.9609375, 0.24609375, 0.044921875, 0.046875, 0.833984375, 0.04296875, 0.0234375, 0.701171875, 0.671875, 0.041015625, 0.021484375, 0.00390625, 0.052734375, 0.037109375, 0.00390625, 0.140625, 0.10546875, 0.1484375, 0.005859375, 0.021484375, 0.1015625, 0.08203125, 0.046875, 0.068359375, 0.703125, 0.107421875, 0.0078125, 0.6484375, 0.130859375, 0.017578125, 0.0234375, 0.05859375, 0.828125, 0.09765625, 0.0234375, 0.96484375, 0.78125, 0.064453125, 0.017578125, 0.1328125, 0.197265625, 0.025390625, 0.0546875, 0.037109375, 0.6328125, 0.994140625, 0.064453125, 0.7734375, 0.01953125, 0.8203125, 0.052734375, 0.994140625, 0.99609375, 0.08203125, 0.169921875, 0.05078125, 0.060546875, 0.025390625, 0.1953125, 0.03515625, 0.0, 0.01953125, 0.009765625, 0.173828125, 0.68359375, 0.046875, 0.83984375, 0.07421875, 0.21875, 0.076171875, 0.2421875, 0.044921875, 0.0234375, 0.19140625, 0.025390625, 0.00390625, 0.064453125, 0.09375, 0.736328125, 0.025390625, 0.017578125, 0.041015625, 0.8671875, 0.083984375, 0.021484375, 0.890625, 0.02734375, 0.029296875, 0.66796875, 0.005859375, 0.03125, 0.08984375, 0.00390625, 0.759765625, 0.00390625, 0.02734375, 0.02734375, 0.037109375]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Total parameter pruned: 6480513.027112223 (unstructured) 0 (structured)

max weight is  tensor([1.9776e-01, 8.4597e-01, 1.1346e-01, 2.8265e-01, 3.3880e-09, 2.5526e-02,
        6.7641e-09, 2.3887e-02, 1.2885e-02, 2.3441e-01, 2.4757e-04, 9.4035e-02,
        5.3542e-02, 2.2643e-02, 3.5035e-01, 6.7480e-02, 1.4636e-01, 9.6135e-03,
        4.3435e-02, 1.4880e-01, 1.3980e-02, 2.1041e-01, 1.1191e-01, 4.9239e-01,
        2.8004e-01, 4.5494e-09, 7.4196e-09, 4.1976e-09, 5.3899e-09, 2.2476e-01,
        8.4902e-03, 5.8608e-02, 1.5334e-01, 1.8101e-09, 7.9889e-02, 2.5258e-01,
        3.1621e-09, 3.3778e-01, 1.2474e-02, 2.8872e-01, 4.3291e-02, 2.5789e-02,
        3.0999e-09, 2.4216e-01, 2.2853e-02, 2.8173e-02, 1.5399e-01, 3.5719e-01,
        6.8990e-03, 2.9472e-02, 3.8746e-01, 2.5772e-02, 1.2784e-01, 3.9655e-03,
        3.4962e-02, 3.0388e-02, 4.7754e-01, 1.3046e-03, 5.5526e-02, 2.2507e-09,
        2.6674e-09, 3.3880e-09, 7.3122e-01, 7.4299e-09], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([1.4107e-08, 1.4958e-01, 8.4850e-02, 3.2965e-08, 2.8912e-02, 9.8518e-02,
        1.2874e-01, 1.7831e-01, 2.1848e-02, 1.5637e-01, 8.4186e-02, 3.1966e-08,
        3.3062e-02, 2.6226e-02, 3.8526e-08, 1.5805e-08, 2.6215e-08, 1.7444e-01,
        6.2229e-02, 3.6565e-02, 1.4204e-01, 1.3874e-01, 4.6477e-02, 1.0903e-01,
        2.6215e-08, 2.6588e-01, 1.5343e-08, 5.5776e-08, 3.3615e-01, 8.1472e-02,
        3.1897e-08, 1.0547e-01, 1.7511e-01, 7.7373e-02, 3.8526e-08, 8.9598e-09,
        3.2965e-08, 2.8330e-01, 1.3531e-01, 3.2965e-08, 1.9746e-08, 1.1135e-01,
        4.2504e-02, 6.6590e-02, 2.0813e-02, 2.4603e-01, 3.8526e-08, 9.0769e-02,
        1.4139e-01, 1.5344e-08, 6.3790e-02, 1.2392e-01, 9.4656e-03, 1.4103e-08,
        3.2965e-08, 3.2965e-08, 4.9931e-02, 4.2729e-08, 8.6986e-02, 4.7811e-08,
        2.1015e-01, 5.4818e-03, 6.8848e-02, 1.2729e-02], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([3.2815e-02, 4.2388e-07, 1.8769e-07, 4.2388e-07, 4.9139e-07, 6.8153e-07,
        6.1192e-07, 1.6750e-07, 5.4802e-02, 1.6750e-07, 1.6750e-07, 7.1777e-03,
        3.3741e-07, 1.9441e-01, 3.7055e-02, 3.3533e-02, 8.8877e-02, 1.0910e-01,
        1.1947e-07, 2.2581e-07, 1.1478e-07, 6.1750e-07, 4.9136e-02, 1.4102e-01,
        2.5189e-07, 7.3912e-07, 9.0024e-07, 9.2652e-02, 7.3912e-07, 9.0024e-07,
        7.3749e-02, 5.2575e-02, 1.6750e-07, 5.1805e-07, 3.9002e-07, 9.2080e-07,
        1.6750e-07, 4.2110e-02, 3.4894e-02, 4.0416e-07, 6.4301e-02, 8.1084e-02,
        1.8769e-07, 1.6751e-07, 8.4641e-02, 8.1663e-02, 2.2743e-02, 2.2952e-02,
        1.9975e-01, 4.6135e-02, 5.0507e-02, 6.3356e-02, 2.2581e-07, 8.1387e-02,
        4.0416e-07, 2.2752e-01, 1.6487e-07, 4.0416e-07, 5.5931e-02, 5.1103e-02,
        1.8769e-07, 7.5664e-02, 5.3115e-02, 1.6950e-02], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([5.5387e-02, 9.5047e-03, 2.1687e-02, 2.2172e-07, 2.0357e-02, 2.7034e-02,
        4.1990e-03, 2.0672e-02, 3.2392e-08, 3.0351e-02, 9.5163e-03, 4.7701e-08,
        5.4617e-08, 4.4061e-02, 4.0129e-08, 3.4581e-02, 1.5678e-01, 5.9866e-08,
        3.4047e-02, 4.2104e-03, 8.8670e-02, 1.8302e-02, 3.4135e-08, 3.6919e-08,
        1.0899e-01, 2.1584e-08, 3.7274e-02, 1.4920e-02, 2.0150e-02, 1.9052e-02,
        9.3607e-02, 2.9197e-02, 4.3055e-02, 1.8567e-01, 4.2614e-02, 2.5223e-02,
        2.6951e-08, 1.8234e-08, 1.3455e-01, 3.9445e-02, 7.9485e-02, 5.9743e-02,
        1.3303e-01, 4.0543e-08, 6.0598e-02, 3.1399e-08, 1.0297e-02, 3.0163e-02,
        4.7627e-02, 1.5681e-01, 1.8479e-01, 5.3383e-08, 4.8208e-02, 5.5999e-08,
        4.4296e-03, 1.0125e-01, 7.3353e-03, 3.5146e-02, 5.6785e-02, 3.5565e-02,
        6.7787e-03, 1.1051e-01, 7.8087e-02, 1.7684e-02, 2.0456e-01, 5.9243e-08,
        2.7294e-08, 1.1914e-07, 1.6189e-01, 5.1746e-02, 2.5812e-08, 5.8177e-02,
        1.1255e-02, 2.3901e-02, 1.4918e-01, 6.2147e-08, 1.2541e-02, 1.9508e-02,
        2.5900e-08, 2.0031e-02, 8.1611e-02, 7.3966e-02, 1.8749e-01, 2.9935e-02,
        1.6494e-08, 5.5519e-08, 8.6199e-02, 4.2802e-02, 1.6947e-01, 1.2428e-08,
        2.9041e-08, 6.8179e-08, 4.6552e-08, 2.1188e-02, 7.3894e-02, 2.3524e-08,
        7.4235e-02, 5.7911e-08, 3.7555e-02, 9.2982e-02, 4.0543e-08, 5.9243e-08,
        5.7289e-02, 4.3033e-03, 1.2756e-02, 5.6879e-08, 3.4506e-08, 2.3460e-08,
        1.4650e-01, 1.9671e-01, 3.1946e-08, 1.7001e-01, 2.5924e-08, 5.7044e-02,
        2.1741e-02, 2.1577e-08, 2.9041e-08, 3.6017e-08, 8.4928e-08, 1.9405e-02,
        3.6441e-02, 8.8220e-03, 1.9249e-02, 1.5012e-02, 4.5349e-02, 2.5405e-02,
        3.4513e-08, 1.3602e-02, 1.8848e-01, 9.4988e-02, 8.8085e-03, 5.7165e-08,
        5.5929e-03, 1.6749e-01, 1.4220e-07, 1.4986e-02, 6.2225e-02, 5.3201e-02,
        1.8252e-02, 7.5497e-02, 1.1560e-07, 5.3738e-08, 1.8981e-01, 3.9053e-08,
        5.0390e-08, 7.3662e-02, 2.1525e-01, 2.1808e-08, 4.8903e-02, 6.7945e-03,
        2.0617e-02, 1.0005e-01, 3.7962e-08, 1.7063e-01, 2.4204e-02, 1.4901e-02,
        1.7261e-02, 5.9324e-03, 5.8549e-08, 4.2705e-08, 2.8504e-02, 8.4445e-03,
        2.8091e-02, 2.3470e-08, 1.8108e-02, 5.2056e-02, 6.7948e-08, 1.8460e-02,
        1.7940e-02, 3.5374e-08, 1.7092e-08, 2.5557e-02, 1.6494e-08, 7.9590e-08,
        3.9118e-08, 1.7951e-02, 3.8492e-02, 5.5523e-02, 5.2265e-02, 7.5716e-08,
        6.3895e-04, 1.9606e-02, 2.5244e-02, 5.4645e-02, 8.8462e-03, 1.5935e-07,
        1.1914e-07, 4.5952e-02, 2.4610e-02, 1.4364e-01, 1.1358e-02, 7.1167e-08,
        1.7942e-02, 6.9276e-02, 6.5923e-08, 4.5597e-02, 1.1748e-02, 4.7256e-02,
        1.7017e-08, 3.9097e-08, 1.1558e-07, 2.6966e-02, 6.5283e-08, 6.2291e-02,
        1.1176e-02, 1.0216e-02, 1.4127e-02, 7.7133e-08, 1.7037e-02, 3.5266e-02,
        1.0925e-01, 3.6381e-08, 2.5467e-08, 2.1224e-02, 4.4966e-08, 6.5283e-08,
        2.0772e-02, 7.7795e-02, 5.0479e-08, 6.2816e-08, 2.9187e-02, 2.2138e-02,
        8.2024e-02, 5.7305e-08, 9.6311e-02, 6.3180e-02, 3.6756e-02, 5.2395e-02,
        2.5812e-08, 2.4162e-08, 2.9681e-08, 4.4139e-08, 4.2248e-02, 7.6391e-08,
        1.9108e-02, 3.8562e-02, 1.1914e-07, 9.8494e-03, 1.1796e-02, 6.5989e-02,
        4.4966e-08, 8.1423e-08, 2.3278e-02, 1.1914e-07, 8.4928e-08, 1.1082e-07,
        2.9271e-02, 5.9243e-08, 1.1913e-07, 5.2970e-08, 5.0478e-02, 1.2432e-02,
        4.7364e-02, 6.2445e-03, 3.0157e-02, 4.9003e-02], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([4.0447e-02, 3.4031e-02, 5.8795e-02, 6.2817e-02, 3.3550e-02, 2.2313e-01,
        8.1672e-02, 1.5867e-01, 1.2917e-02, 3.4436e-02, 1.1511e-01, 1.1286e-01,
        1.0778e-02, 2.8439e-02, 2.3767e-08, 5.8290e-02, 1.0564e-01, 6.2709e-02,
        6.0152e-02, 9.0326e-02, 1.1272e-01, 9.0860e-02, 1.1147e-01, 5.0581e-08,
        3.9079e-02, 1.7011e-08, 9.7327e-02, 7.7907e-02, 6.5461e-02, 1.5716e-02,
        2.5679e-02, 1.7825e-01, 1.5040e-01, 1.6444e-01, 6.0424e-09, 8.8735e-02,
        2.5487e-08, 2.3643e-09, 2.8387e-02, 1.8244e-01, 4.6350e-02, 6.3149e-02,
        2.2686e-02, 8.8401e-09, 7.6799e-02, 2.7826e-02, 1.0003e-01, 4.8382e-02,
        2.7432e-02, 6.3828e-02, 7.6300e-02, 6.4932e-02, 7.7302e-03, 7.9209e-02,
        7.8958e-02, 4.7388e-02, 9.1389e-02, 2.6653e-02, 5.6670e-02, 1.0074e-01,
        8.4943e-02, 5.3524e-02, 3.6788e-02, 2.5521e-02, 1.2809e-01, 9.2496e-09,
        6.2227e-02, 2.1738e-08, 1.1928e-01, 3.9952e-02, 1.0283e-08, 1.3238e-02,
        1.7151e-01, 7.7229e-02, 2.0395e-01, 2.4470e-08, 9.7987e-02, 1.5560e-01,
        2.3767e-08, 1.8398e-01, 2.5419e-02, 4.3707e-02, 7.0916e-02, 2.0443e-01,
        2.3767e-08, 1.5009e-08, 8.9007e-02, 9.4410e-02, 5.8382e-02, 9.3927e-09,
        9.2496e-09, 1.0286e-01, 8.8401e-09, 3.2398e-02, 7.1572e-02, 8.7251e-02,
        2.4082e-02, 6.4748e-03, 5.2995e-02, 3.7580e-02, 2.3767e-08, 1.4030e-08,
        7.5007e-02, 5.8142e-02, 9.8232e-02, 2.6495e-08, 5.4976e-02, 4.2489e-02,
        6.6250e-02, 3.0892e-02, 3.8712e-02, 4.5020e-02, 2.3767e-08, 2.6001e-02,
        1.0076e-01, 2.2496e-02, 1.7011e-08, 9.3293e-02, 1.4030e-08, 5.4162e-02,
        8.9612e-09, 1.2793e-01, 1.1588e-01, 1.1777e-01, 6.0427e-02, 3.2472e-02,
        8.2355e-02, 9.8215e-02, 1.7347e-01, 1.3566e-01, 9.7108e-02, 2.1738e-08,
        1.1761e-01, 1.4104e-01, 1.5111e-08, 1.5105e-02, 8.1144e-02, 1.1196e-02,
        6.7697e-02, 3.4469e-02, 6.6599e-09, 7.0903e-02, 3.5156e-02, 7.6641e-02,
        4.7684e-03, 2.6383e-02, 1.5195e-01, 1.8471e-02, 6.0082e-02, 1.0471e-01,
        1.4612e-01, 1.2282e-01, 4.9742e-08, 1.0746e-01, 9.0362e-09, 1.9774e-01,
        1.5240e-02, 3.9778e-03, 2.6495e-08, 9.3927e-09, 5.4393e-02, 9.0157e-02,
        5.8483e-02, 9.2496e-09, 1.6348e-01, 1.9637e-02, 1.4030e-08, 8.6668e-02,
        2.2384e-01, 2.4701e-02, 1.7011e-08, 1.6224e-08, 9.2496e-09, 2.4459e-08,
        9.2496e-09, 3.5492e-02, 6.4900e-02, 5.3807e-02, 4.9411e-02, 2.3767e-08,
        8.4832e-02, 1.0836e-01, 4.4630e-02, 1.1263e-01, 1.2495e-01, 9.8284e-09,
        9.2496e-09, 6.7131e-03, 2.2183e-01, 1.0312e-01, 1.1295e-02, 2.6503e-08,
        6.7461e-02, 7.0028e-02, 7.5196e-02, 1.4225e-02, 1.1234e-01, 5.0422e-02,
        1.3532e-02, 1.4851e-08, 1.4030e-08, 1.9824e-01, 1.4030e-08, 4.3423e-02,
        9.2369e-02, 6.9903e-02, 1.1145e-01, 2.3767e-08, 1.1447e-01, 1.7127e-01,
        4.1759e-02, 4.9756e-09, 2.3767e-08, 1.6124e-08, 1.4310e-08, 6.6599e-09,
        1.2962e-01, 5.8981e-02, 9.2496e-09, 1.4851e-08, 3.0947e-02, 1.7044e-01,
        6.7102e-02, 2.2707e-02, 8.8893e-02, 9.5716e-02, 4.6556e-03, 7.3950e-02,
        2.1738e-08, 8.5345e-03, 2.3767e-08, 2.3767e-08, 1.0708e-01, 1.4310e-08,
        1.4530e-01, 1.3845e-01, 8.5304e-09, 1.3648e-01, 8.0740e-02, 1.0959e-01,
        9.2789e-09, 3.5971e-08, 1.8386e-01, 2.1203e-08, 1.4030e-08, 8.1359e-09,
        1.5705e-01, 1.4030e-08, 6.1031e-09, 5.2429e-02, 1.6838e-02, 6.8832e-09,
        7.7110e-02, 9.7116e-02, 2.9357e-02, 7.0394e-02], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([1.6690e-07, 4.6621e-02, 5.5470e-02, 1.0434e-07, 7.6220e-08, 4.1602e-07,
        4.1195e-02, 1.6690e-07, 4.8632e-08, 3.0139e-02, 1.0134e-07, 1.9476e-07,
        8.1646e-08, 1.3167e-01, 1.5774e-07, 9.1119e-08, 9.1118e-08, 2.3114e-07,
        4.8632e-08, 1.1499e-01, 9.1118e-08, 3.6724e-07, 9.8855e-08, 1.3502e-07,
        4.8718e-08, 5.5778e-02, 1.2299e-07, 1.6240e-07, 3.4908e-03, 1.6690e-07,
        1.6669e-02, 2.9536e-02, 2.3591e-02, 4.0794e-02, 7.5921e-08, 2.8479e-02,
        6.7511e-08, 3.5775e-07, 2.3588e-07, 4.4916e-02, 2.1298e-07, 1.1471e-01,
        6.6692e-02, 8.6642e-02, 8.1646e-08, 3.5637e-02, 3.6570e-02, 6.3944e-03,
        3.8469e-02, 2.9208e-08, 4.0731e-02, 2.4373e-07, 4.0102e-02, 6.9083e-08,
        9.1118e-08, 1.8758e-02, 1.1114e-01, 3.1111e-02, 4.9150e-02, 2.4373e-07,
        4.1602e-07, 1.5774e-07, 4.5823e-08, 6.1681e-02], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([3.8572e-07, 4.9959e-02, 9.9058e-08, 3.7216e-07, 1.3551e-01, 5.0547e-07,
        1.2996e-02, 3.9977e-02, 1.2469e-07, 1.2469e-07, 1.2469e-07, 4.2084e-07,
        3.7216e-07, 1.2469e-07, 2.1167e-07, 3.5875e-02, 3.8572e-07, 2.1167e-07,
        1.2469e-07, 4.2309e-07, 3.3345e-07, 1.2981e-07, 2.4746e-01, 6.5428e-07,
        3.3345e-07, 1.7959e-02, 4.0103e-02, 6.0046e-02, 9.5923e-03, 7.2252e-02,
        2.5884e-07, 9.9058e-08, 1.0249e-02, 3.8572e-07, 9.9058e-08, 6.8561e-07,
        1.4472e-07, 2.3328e-07, 5.4312e-07, 1.3013e-02, 5.4312e-07, 1.0367e-02,
        6.8069e-07, 4.2084e-07, 1.5041e-02, 6.5428e-07, 1.5238e-07, 8.9172e-08,
        5.4312e-07, 4.2084e-07, 6.8065e-07, 1.5101e-07, 1.3466e-07, 3.3345e-07,
        4.3350e-07, 1.3083e-01, 1.5238e-07, 2.3134e-01, 9.2861e-02, 3.8213e-02,
        2.1167e-07, 8.8013e-07, 1.2469e-07, 2.4415e-01], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([1.4574e-02, 6.6834e-08, 2.8669e-02, 4.9195e-08, 5.1893e-02, 1.0062e-01,
        5.0004e-02, 2.6191e-02, 6.8270e-08, 8.2469e-02, 5.2954e-02, 2.7467e-08,
        5.3527e-08, 3.6932e-08, 4.9905e-08, 8.1209e-08, 1.5332e-02, 6.8815e-08,
        1.1992e-07, 4.5515e-02, 1.1530e-02, 9.2702e-03, 7.2773e-08, 7.7108e-08,
        1.5988e-02, 5.1919e-08, 2.5924e-08, 3.3635e-08, 6.9824e-02, 7.0828e-03,
        8.2320e-03, 7.2573e-03, 9.0172e-03, 1.6287e-02, 2.8090e-08, 4.4670e-08,
        1.0198e-01, 8.8293e-02, 1.0678e-02, 3.9363e-08, 7.1502e-02, 3.2238e-08,
        6.2367e-03, 2.3539e-01, 6.9925e-02, 1.4468e-08, 2.3715e-08, 5.2883e-02,
        4.4679e-02, 3.7555e-02, 7.8016e-03, 1.9346e-02, 5.2624e-08, 2.6476e-08,
        1.0183e-02, 9.6255e-03, 4.0956e-08, 1.8185e-01, 7.7346e-03, 1.0888e-02,
        1.9912e-08, 8.0085e-03, 5.7197e-08, 2.1976e-02, 1.6141e-02, 7.1519e-08,
        2.6563e-08, 3.1950e-02, 1.2831e-02, 6.3681e-02, 2.0477e-01, 2.5412e-08,
        5.1985e-02, 8.5485e-02, 1.3122e-02, 7.3079e-02, 2.5008e-03, 2.5050e-02,
        4.9516e-08, 6.2706e-02, 4.2647e-02, 6.4767e-03, 7.2684e-02, 1.5736e-02,
        2.7670e-08, 1.2066e-07, 1.2092e-02, 6.6297e-02, 1.8270e-02, 3.1946e-08,
        4.9905e-08, 3.9007e-02, 1.2066e-07, 9.8941e-08, 3.9586e-03, 5.0286e-08,
        7.3882e-03, 2.0247e-08, 4.6282e-02, 8.1296e-02, 2.1869e-08, 9.5419e-02,
        6.1051e-08, 1.3771e-02, 2.8519e-02, 1.1372e-08, 3.5640e-08, 5.7635e-08,
        3.3634e-08, 1.6023e-02, 4.8400e-03, 6.9723e-03, 4.9905e-08, 5.0958e-08,
        2.0978e-02, 5.7438e-08, 7.7108e-08, 5.8057e-08, 4.7686e-08, 1.2561e-02,
        8.8885e-08, 1.5211e-02, 1.9455e-01, 5.9809e-02, 2.7931e-08, 4.0999e-08,
        3.4073e-08, 1.1899e-02, 2.2007e-02, 1.3301e-02, 5.5672e-02, 4.0991e-08,
        4.8554e-02, 9.8099e-03, 2.7450e-08, 2.4177e-08, 1.9063e-02, 3.0064e-02,
        8.0189e-08, 4.1740e-08, 1.5922e-01, 3.9448e-08, 9.9199e-03, 1.6357e-08,
        2.6152e-08, 6.2441e-08, 1.7919e-02, 1.4235e-08, 4.7172e-03, 6.1847e-02,
        1.0253e-01, 1.0037e-02, 8.0201e-02, 1.5411e-02, 7.0886e-08, 9.7628e-02,
        5.6162e-08, 5.8512e-03, 2.6129e-08, 6.7912e-05, 8.5839e-02, 5.8115e-03,
        5.6356e-08, 4.9905e-08, 1.1311e-02, 4.0234e-08, 5.5715e-02, 8.4330e-03,
        1.3780e-02, 3.9247e-08, 3.2627e-02, 2.3794e-08, 4.9905e-08, 2.3437e-02,
        1.2066e-07, 9.9987e-08, 2.3171e-08, 7.8481e-02, 8.8032e-08, 1.0672e-07,
        2.7786e-02, 3.6447e-04, 2.0815e-02, 1.1324e-01, 3.3012e-03, 2.0588e-08,
        7.4931e-08, 6.4111e-02, 1.3215e-02, 1.2917e-02, 5.0414e-08, 2.2000e-08,
        4.7636e-08, 4.5090e-08, 1.8760e-02, 4.4974e-08, 1.9690e-08, 8.4823e-02,
        1.8055e-02, 8.4806e-08, 1.2066e-07, 1.1259e-01, 1.4857e-01, 3.4439e-08,
        5.1940e-02, 2.4836e-06, 2.8675e-02, 3.1079e-02, 6.1628e-02, 2.1177e-02,
        7.2343e-02, 1.0606e-07, 2.7670e-08, 7.4345e-08, 5.7644e-08, 3.3328e-08,
        1.4553e-02, 2.5532e-08, 2.7670e-08, 2.0871e-01, 1.4710e-02, 1.3605e-02,
        8.9453e-03, 6.3627e-08, 2.2098e-02, 3.1208e-08, 6.3888e-08, 9.6904e-03,
        3.2797e-08, 2.7777e-03, 9.5798e-09, 1.0638e-07, 1.8404e-02, 5.9274e-02,
        1.6219e-02, 6.5177e-03, 2.1833e-08, 6.6383e-02, 1.2084e-02, 7.1628e-03,
        1.9575e-08, 2.6782e-08, 1.7571e-02, 9.5896e-03, 4.9516e-08, 1.5512e-08,
        1.1075e-02, 1.4402e-01, 1.9575e-08, 5.8781e-08, 1.0513e-02, 1.9598e-08,
        6.7338e-02, 2.8514e-02, 6.5878e-02, 7.6388e-02], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([3.0210e-07, 2.5655e-07, 5.0618e-02, 9.3457e-03, 2.3982e-07, 1.6384e-07,
        1.0211e-01, 3.1899e-07, 5.7082e-02, 9.4868e-03, 6.4565e-07, 9.2215e-03,
        1.8083e-02, 3.7518e-08, 3.9817e-07, 1.6406e-01, 1.2983e-01, 2.5846e-07,
        1.0120e-01, 4.1012e-07, 1.1022e-02, 1.5411e-07, 2.0765e-02, 5.6417e-07,
        1.4662e-01, 2.0257e-02, 1.1700e-01, 9.3815e-03, 1.2040e-01, 1.1902e-01,
        6.7047e-07, 1.0981e-01, 9.3156e-08, 5.1840e-02, 9.0776e-03, 1.7060e-07,
        2.9986e-07, 1.0844e-07, 2.1095e-07, 9.3544e-03, 3.8533e-07, 4.6135e-07,
        2.3982e-07, 1.5358e-01, 2.5710e-07, 3.7518e-08, 3.1210e-07, 3.9244e-07,
        8.3501e-08, 8.0560e-03, 2.6103e-07, 1.2727e-01, 1.3883e-01, 3.7411e-07,
        2.0301e-07, 1.3043e-01, 3.1210e-07, 1.1251e-01, 3.9817e-07, 1.5769e-02,
        1.6729e-07, 1.1920e-01, 3.9624e-07, 3.0095e-07], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([8.3565e-03, 9.8187e-02, 1.1425e-01, 1.2560e-01, 9.6720e-02, 1.0936e-01,
        6.3923e-07, 4.9798e-07, 6.7106e-02, 1.9427e-07, 5.7457e-07, 4.8269e-07,
        1.0814e-01, 5.5360e-07, 4.8681e-07, 4.1498e-03, 5.8563e-07, 1.1041e-01,
        7.0186e-02, 9.5306e-07, 9.5894e-02, 8.7831e-02, 1.5406e-06, 1.0116e-01,
        1.0312e-01, 1.1128e-01, 9.6821e-02, 2.8946e-07, 1.3312e-01, 6.1700e-07,
        1.3870e-01, 1.0082e-06, 1.0213e-01, 1.1053e-01, 3.8218e-02, 8.7254e-02,
        3.7569e-03, 9.0443e-02, 5.4345e-02, 1.2182e-04, 6.3923e-07, 1.0919e-07,
        8.2957e-07, 1.0419e-01, 1.9131e-07, 1.2356e-01, 9.0212e-02, 8.8112e-07,
        7.1290e-07, 2.4145e-07, 1.0165e-02, 6.1937e-03, 2.6274e-02, 9.2228e-07,
        4.8681e-07, 3.7640e-02, 9.4381e-02, 9.9566e-02, 9.6298e-02, 6.7624e-03,
        5.2776e-07, 7.6630e-07, 9.3505e-03, 2.3624e-07], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([2.2394e-02, 1.7009e-07, 3.7901e-08, 6.7576e-08, 1.0444e-07, 1.9751e-02,
        2.7904e-02, 9.5232e-03, 1.1899e-07, 3.5787e-03, 5.2539e-03, 5.3532e-03,
        7.6239e-08, 4.2950e-02, 1.0608e-01, 1.5402e-02, 2.7856e-02, 4.3228e-03,
        3.7974e-03, 5.7114e-08, 1.2184e-02, 1.1672e-02, 7.1903e-08, 1.3882e-01,
        5.5525e-02, 1.6296e-01, 8.9869e-02, 7.0643e-08, 1.1996e-02, 4.5329e-08,
        6.7262e-02, 1.1427e-02, 1.5660e-02, 1.0599e-02, 1.3367e-02, 5.8414e-08,
        6.9951e-02, 1.5262e-01, 8.1269e-02, 7.6416e-03, 9.1597e-03, 1.0622e-02,
        2.5972e-02, 1.1847e-02, 1.0150e-02, 5.9851e-08, 1.3651e-02, 5.6452e-03,
        2.1785e-02, 3.7698e-02, 2.4631e-02, 5.4945e-03, 6.2439e-02, 6.5553e-08,
        6.8878e-03, 8.6606e-02, 8.0141e-03, 8.0394e-03, 6.4611e-02, 1.5140e-02,
        3.9311e-03, 2.3140e-02, 5.4611e-02, 3.7730e-08, 2.0784e-02, 2.0690e-01,
        3.3056e-03, 5.5723e-02, 4.1963e-02, 4.2839e-02, 1.3852e-02, 6.2299e-03,
        1.1146e-02, 3.0687e-02, 9.7374e-03, 4.2303e-03, 9.4870e-03, 1.1645e-02,
        1.4332e-01, 2.3646e-02, 5.5605e-02, 5.8903e-02, 2.5290e-02, 2.2025e-02,
        6.7035e-02, 2.8125e-08, 9.2023e-03, 2.1769e-02, 6.4350e-02, 1.2148e-01,
        1.4844e-01, 8.1448e-03, 7.8822e-08, 6.4645e-08, 2.2443e-02, 3.4006e-08,
        1.2953e-01, 5.4418e-08, 3.7601e-02, 3.1991e-02, 1.2092e-01, 2.3704e-02,
        7.2967e-08, 6.5690e-08, 1.1871e-02, 1.7175e-01, 5.5109e-08, 7.6842e-08,
        8.5314e-02, 1.3055e-02, 3.1251e-08, 1.4467e-01, 9.3106e-08, 4.6407e-02,
        1.0561e-02, 3.6227e-08, 1.1434e-01, 1.9455e-03, 1.1778e-01, 3.0508e-08,
        7.2718e-08, 4.0332e-03, 1.1388e-02, 1.8436e-02, 8.4020e-08, 8.8626e-03,
        3.6180e-03, 8.5148e-03, 1.2824e-01, 1.5145e-02, 3.0329e-03, 1.5340e-01,
        1.4873e-02, 4.6667e-03, 1.8669e-01, 2.6687e-08, 5.4789e-02, 2.1853e-02,
        5.3328e-03, 6.1599e-02, 2.2876e-02, 8.4758e-08, 8.6894e-03, 5.6919e-03,
        1.5744e-08, 7.8177e-08, 5.5131e-02, 2.7012e-08, 2.6240e-02, 1.3794e-02,
        1.1676e-02, 1.2549e-02, 5.9430e-03, 6.9610e-02, 7.1258e-08, 1.4448e-02,
        3.9917e-02, 8.8603e-08, 1.6015e-01, 7.1816e-08, 1.0348e-02, 1.2737e-02,
        8.1423e-03, 8.6902e-02, 1.6908e-02, 4.8882e-08, 8.6691e-02, 1.3024e-02,
        2.0615e-02, 1.7761e-08, 6.8944e-02, 2.2855e-08, 1.6407e-01, 7.8688e-08,
        9.5315e-08, 8.6910e-08, 5.2242e-03, 3.2324e-02, 8.9217e-03, 6.7895e-02,
        4.4486e-03, 1.7380e-02, 3.9110e-08, 1.2784e-02, 2.9767e-02, 4.1367e-08,
        1.5134e-01, 3.7640e-08, 2.0176e-02, 1.3909e-02, 3.9036e-03, 7.8825e-08,
        7.4971e-03, 3.6827e-08, 1.6618e-03, 1.8063e-02, 5.1324e-03, 1.0842e-02,
        3.3310e-02, 1.4934e-01, 6.6547e-02, 1.1154e-02, 4.8980e-02, 1.0353e-02,
        1.3459e-02, 1.5389e-02, 1.6045e-02, 2.0699e-08, 1.5598e-02, 8.2315e-03,
        1.5087e-02, 5.7526e-02, 1.4513e-01, 7.0639e-08, 1.9385e-02, 1.7149e-01,
        1.9504e-02, 5.5890e-02, 8.8350e-02, 1.8625e-02, 1.2736e-02, 1.7468e-02,
        7.1204e-02, 5.4274e-08, 3.2058e-02, 6.4977e-08, 6.9291e-02, 1.3454e-02,
        1.2425e-07, 7.0627e-08, 1.7718e-01, 2.2219e-01, 5.7661e-02, 8.3419e-03,
        1.5640e-02, 9.4125e-03, 1.6489e-07, 1.4214e-02, 1.2426e-02, 1.7919e-02,
        1.2189e-01, 1.7942e-01, 1.2703e-02, 6.3569e-03, 1.5469e-02, 2.5222e-08,
        1.8228e-02, 1.0978e-02, 4.9517e-02, 9.1848e-08, 7.4211e-02, 3.0238e-08,
        5.7732e-03, 1.2062e-02, 1.1392e-02, 6.5281e-03], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([1.4530e-01, 1.2886e-07, 1.2144e-07, 7.6758e-02, 2.7807e-01, 3.5052e-07,
        1.0984e-02, 1.4739e-07, 9.8332e-08, 5.4326e-02, 2.1371e-07, 1.2839e-01,
        1.1534e-07, 3.7135e-07, 2.7437e-07, 3.8193e-07, 1.5210e-01, 2.2856e-07,
        3.5052e-07, 1.1118e-07, 2.4834e-07, 1.1586e-01, 1.8485e-07, 2.7028e-07,
        3.7673e-08, 6.6787e-02, 4.4529e-08, 1.2201e-07, 4.0850e-02, 1.4132e-01,
        3.0302e-07, 1.0975e-07, 3.9305e-02, 1.4557e-01, 1.2939e-01, 1.2723e-02,
        7.2780e-02, 3.7135e-07, 1.1785e-07, 2.0198e-01, 1.2496e-01, 1.4338e-07,
        5.4513e-07, 1.0894e-07, 1.2994e-07, 1.5647e-07, 2.3216e-01, 5.5662e-08,
        1.7223e-01, 1.5647e-07, 5.4553e-07, 5.2434e-02, 1.5017e-01, 6.1990e-02,
        5.2803e-07, 1.1344e-07, 2.2856e-07, 8.5685e-08, 1.1876e-07, 7.9102e-08,
        2.6076e-07, 1.3737e-01, 1.6773e-07, 4.2169e-07, 1.8704e-01, 1.2886e-07,
        3.1660e-07, 1.2833e-01, 1.6978e-01, 5.4093e-07, 1.1815e-02, 4.5913e-07,
        5.3171e-02, 5.9426e-08, 4.5914e-07, 2.2962e-02, 2.9087e-02, 1.6558e-01,
        2.2478e-01, 2.5874e-07, 1.2886e-07, 1.8656e-01, 5.5614e-02, 7.6060e-02,
        1.8485e-07, 5.1342e-02, 1.1785e-07, 6.4979e-02, 1.4745e-07, 3.8326e-02,
        2.1813e-01, 1.5155e-01, 1.1350e-07, 1.9163e-07, 2.9495e-02, 7.9580e-02,
        1.8647e-07, 1.5173e-07, 2.2173e-01, 1.2770e-01, 1.0447e-01, 1.2994e-07,
        1.2201e-07, 5.4553e-07, 1.1785e-07, 1.1534e-07, 1.1350e-07, 2.2870e-07,
        3.8193e-07, 1.3901e-01, 2.4988e-07, 3.7135e-07, 1.2380e-01, 4.5914e-07,
        2.1019e-07, 1.4745e-07, 3.1659e-07, 4.0080e-02, 4.0854e-07, 5.4553e-07,
        2.4663e-07, 1.4745e-07, 1.1350e-07, 1.6922e-01, 3.5052e-07, 2.9447e-02,
        2.0947e-07, 1.2994e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([5.8697e-07, 3.1656e-06, 1.2689e-06, 3.8657e-06, 9.2504e-02, 2.6223e-02,
        1.0578e-01, 1.0615e-06, 1.0278e-06, 1.1653e-06, 3.1185e-02, 1.0184e-01,
        1.9066e-06, 3.9109e-02, 2.0104e-06, 1.1070e-01, 3.9878e-07, 3.0028e-02,
        1.7052e-06, 1.4600e-06, 1.5617e-06, 1.9066e-06, 2.9368e-06, 1.0357e-06,
        1.2964e-06, 1.1028e-01, 8.5799e-02, 5.2203e-07, 4.8552e-02, 7.3831e-02,
        4.7518e-07, 2.1867e-06, 4.8967e-07, 7.6705e-07, 8.8236e-02, 1.2388e-06,
        1.2388e-06, 6.1739e-07, 2.3430e-02, 1.9140e-06, 4.6776e-02, 1.7817e-06,
        1.7052e-06, 1.5280e-06, 1.0840e-06, 2.5231e-06, 3.6494e-02, 2.1450e-06,
        1.6362e-06, 2.0462e-06, 2.2255e-06, 3.9936e-02, 1.5617e-06, 2.0930e-02,
        3.1253e-06, 9.1543e-07, 1.0278e-06, 1.2096e-06, 7.9506e-02, 2.1450e-06,
        9.8047e-02, 8.5393e-07, 1.5617e-06, 4.2414e-02, 1.5136e-06, 3.5519e-02,
        3.8141e-02, 1.4985e-01, 1.8969e-06, 1.7052e-06, 3.3559e-07, 1.0278e-06,
        1.2480e-06, 2.0911e-02, 6.3284e-07, 3.1431e-06, 3.3559e-07, 2.1450e-06,
        3.8363e-02, 1.7052e-06, 2.2324e-06, 1.1509e-06, 1.2096e-06, 3.0398e-06,
        7.9914e-07, 1.0371e-01, 1.7052e-06, 2.7523e-02, 3.6795e-07, 1.4600e-06,
        6.9359e-07, 2.5231e-06, 1.3362e-06, 7.9914e-07, 3.0398e-06, 9.3248e-02,
        8.4351e-02, 2.7750e-02, 1.2388e-06, 9.2647e-07, 2.5935e-02, 6.8747e-07,
        1.1509e-06, 1.6813e-06, 4.8967e-07, 1.2964e-06, 3.3559e-07, 1.2549e-06,
        2.7136e-06, 1.8206e-06, 1.2388e-06, 2.5231e-06, 8.0223e-07, 4.3551e-02,
        8.6819e-02, 3.3559e-07, 1.2480e-06, 3.9591e-02, 3.2257e-02, 3.5155e-02,
        2.1450e-06, 1.1027e-06, 6.3880e-07, 1.2689e-06, 3.9994e-02, 1.2096e-06,
        2.1294e-06, 1.8694e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([4.0158e-08, 1.4320e-01, 3.9823e-08, 5.0027e-02, 6.4418e-02, 8.5866e-08,
        1.4718e-01, 1.4456e-07, 3.6622e-02, 7.7005e-08, 1.6049e-02, 4.8136e-08,
        7.6133e-08, 4.6377e-02, 1.5509e-07, 4.5706e-08, 1.9118e-01, 9.8492e-08,
        6.9988e-08, 2.0174e-02, 2.3175e-02, 2.2004e-07, 9.8492e-08, 6.2472e-02,
        5.0687e-02, 2.2682e-02, 1.0063e-02, 2.5281e-07, 1.8304e-02, 3.1031e-02,
        1.8035e-07, 4.5706e-08, 9.8492e-08, 4.5586e-02, 8.0180e-04, 1.4456e-07,
        7.4313e-08, 7.7127e-02, 6.3838e-02, 5.8751e-02, 1.2973e-02, 5.4570e-02,
        1.0370e-07, 1.3784e-02, 7.2196e-08, 7.6403e-08, 6.9988e-08, 3.8452e-02,
        6.8359e-02, 1.4306e-07, 9.1983e-03, 6.5998e-02, 2.5912e-02, 9.8492e-08,
        3.7262e-02, 6.9988e-08, 1.4091e-07, 1.4091e-07, 1.4456e-07, 1.3432e-01,
        6.4444e-02, 3.4689e-02, 1.0370e-07, 4.7095e-08, 1.8035e-07, 4.3992e-02,
        3.6455e-02, 7.6295e-02, 5.6808e-02, 2.5281e-07, 3.8948e-02, 2.7682e-02,
        9.9370e-08, 1.1632e-07, 5.7182e-08, 5.4386e-08, 1.7192e-01, 6.6261e-02,
        2.5281e-07, 4.5706e-08, 6.8008e-02, 4.7295e-08, 8.6278e-02, 4.6604e-02,
        4.5033e-02, 5.8624e-02, 8.5226e-02, 5.2337e-02, 9.9979e-08, 4.1491e-02,
        4.0823e-02, 5.1593e-08, 5.3130e-02, 9.8492e-08, 5.5246e-02, 3.3871e-02,
        8.9551e-03, 4.5177e-02, 7.4313e-08, 1.0528e-01, 9.7000e-03, 4.4277e-02,
        3.2452e-02, 2.5574e-02, 6.6691e-03, 1.0760e-02, 1.4772e-01, 8.9845e-02,
        3.8805e-02, 1.4091e-07, 1.0370e-07, 1.0780e-01, 9.9371e-08, 6.7585e-08,
        2.2496e-07, 1.6989e-02, 1.2491e-02, 1.0794e-07, 4.6479e-02, 3.6087e-02,
        4.2678e-03, 8.4408e-03, 7.0476e-02, 2.9235e-08, 1.0368e-07, 9.1196e-10,
        1.4258e-07, 3.3362e-08, 1.4456e-07, 5.9751e-02, 7.6985e-02, 3.5448e-02,
        9.9370e-08, 8.2177e-08, 6.7891e-08, 4.5706e-08, 1.1362e-07, 6.0631e-02,
        4.0991e-02, 4.1723e-02, 7.3751e-02, 3.7958e-08, 4.1010e-08, 3.5418e-02,
        3.7748e-02, 1.2210e-02, 9.0137e-03, 1.4456e-07, 8.1312e-08, 2.9183e-02,
        2.3661e-02, 6.2686e-02, 2.9166e-02, 6.8777e-02, 2.9235e-08, 2.5190e-07,
        2.4615e-02, 8.7246e-02, 3.0390e-02, 1.1248e-07, 1.0108e-01, 3.9422e-02,
        1.4887e-07, 1.7210e-02, 4.8136e-08, 1.4456e-07, 1.0370e-07, 6.5325e-08,
        1.4596e-01, 5.4599e-08, 3.7385e-02, 3.3760e-02, 3.3361e-08, 7.9223e-03,
        1.2833e-07, 5.1854e-02, 1.4456e-07, 3.3818e-02, 2.9057e-07, 9.8492e-08,
        6.9988e-08, 1.3797e-07, 1.5510e-07, 1.2752e-07, 1.5710e-02, 7.4313e-08,
        2.7318e-02, 1.1248e-07, 4.7683e-02, 5.2264e-02, 2.5835e-02, 2.1995e-07,
        2.2264e-02, 9.6905e-03, 1.1940e-07, 1.2032e-07, 9.5647e-02, 4.5706e-08,
        5.1942e-02, 9.9464e-03, 8.8055e-08, 4.7095e-08, 7.4931e-02, 3.2483e-08,
        4.6669e-02, 1.8434e-07, 1.0370e-07, 3.6457e-02, 4.5706e-08, 1.0305e-07,
        2.1224e-02, 4.2580e-02, 1.8689e-06, 3.6117e-03, 3.3408e-02, 7.1667e-02,
        5.5119e-02, 2.9235e-08, 1.9783e-02, 2.1376e-02, 2.8348e-02, 1.0574e-07,
        5.4599e-08, 2.1676e-02, 5.0414e-02, 2.8118e-02, 4.5913e-02, 1.3838e-07,
        1.7343e-02, 4.1010e-08, 5.9863e-02, 1.1419e-02, 1.0869e-07, 5.3770e-02,
        1.4596e-02, 5.6310e-03, 5.0642e-02, 3.5940e-02, 5.6212e-02, 1.3788e-02,
        3.6069e-02, 3.3441e-02, 6.5553e-02, 9.1826e-03, 5.7054e-02, 2.0103e-01,
        3.5895e-08, 1.4456e-07, 1.4456e-07, 2.8389e-02, 6.2127e-02, 2.3376e-02,
        3.2483e-08, 6.4554e-02, 4.1010e-08, 9.8492e-08, 3.1162e-08, 3.2761e-02,
        3.3172e-02, 2.2994e-02, 1.0522e-07, 1.4456e-07, 7.1020e-02, 1.6841e-02,
        3.0015e-02, 9.6312e-02, 7.1739e-02, 1.4911e-01, 1.9931e-01, 4.5706e-08,
        1.1248e-07, 1.1140e-02, 1.1965e-02, 4.8104e-08, 4.5706e-08, 1.0205e-01,
        8.2359e-02, 1.4091e-07, 3.9291e-02, 9.3768e-02, 9.4438e-03, 4.9879e-02,
        8.3367e-02, 6.0358e-02, 5.1465e-02, 1.5330e-01, 4.9072e-02, 2.7836e-02,
        8.0195e-02, 3.6987e-02, 5.0631e-02, 6.3958e-02, 1.4456e-07, 7.7576e-08,
        4.5138e-02, 4.9477e-02, 5.3813e-02, 3.9564e-02, 4.8329e-02, 2.1736e-02,
        4.9152e-02, 7.6479e-03, 2.2004e-07, 3.5730e-02, 8.2416e-02, 5.8000e-02,
        3.9715e-08, 9.8492e-08, 6.5743e-02, 8.1410e-03, 5.9968e-02, 5.1216e-02,
        2.2131e-02, 1.4887e-07, 3.8800e-02, 3.9896e-07, 4.5553e-08, 6.1643e-02,
        1.3406e-07, 5.8705e-02, 1.2643e-07, 8.5369e-08, 4.7121e-08, 1.4313e-07,
        7.3343e-02, 6.0257e-02, 6.9754e-02, 4.2843e-02, 4.3660e-02, 6.5325e-08,
        7.3831e-02, 2.6960e-02, 1.2078e-07, 4.1494e-02, 2.4843e-02, 5.3941e-02,
        7.6043e-08, 4.8136e-08, 1.3690e-02, 3.8554e-02, 3.3512e-02, 3.2391e-02,
        1.4131e-02, 1.5725e-02, 3.2483e-08, 8.2089e-08, 7.0962e-02, 1.6212e-02,
        9.8492e-08, 1.0451e-07, 4.1010e-08, 5.8933e-02, 6.5325e-08, 2.7834e-02,
        3.4198e-02, 7.1317e-02, 1.0370e-07, 9.8492e-08, 6.7891e-08, 2.6505e-02,
        4.7232e-02, 7.6955e-02, 5.0292e-02, 8.5369e-08, 3.7980e-02, 9.8966e-08,
        7.7576e-08, 1.0370e-07, 4.5767e-08, 2.3974e-02, 7.5109e-02, 4.4884e-02,
        2.7233e-02, 5.1008e-02, 1.5509e-07, 1.2168e-02, 6.0136e-02, 3.7041e-02,
        3.6590e-02, 7.1956e-08, 8.8307e-03, 2.7448e-02, 2.5281e-07, 6.5325e-08,
        2.8493e-02, 1.4887e-07, 4.1010e-08, 8.9682e-02, 1.8162e-02, 5.4740e-08,
        3.7183e-02, 1.1248e-07, 3.1162e-08, 5.1837e-02, 1.0443e-07, 8.1005e-02,
        1.9773e-03, 3.2344e-02, 2.0583e-02, 7.4313e-08, 6.4856e-02, 1.8035e-07,
        6.0359e-03, 1.4091e-07, 2.3309e-02, 1.8035e-07, 4.9994e-02, 7.2358e-03,
        2.3956e-08, 3.3770e-02, 6.7891e-08, 4.5706e-08, 3.5565e-02, 4.4242e-02,
        4.1084e-02, 4.7390e-02, 5.4099e-02, 5.2118e-02, 1.1430e-02, 5.1345e-02,
        3.4118e-03, 6.3591e-02, 4.3233e-03, 6.7585e-08, 9.8492e-08, 9.8492e-08,
        4.5706e-08, 3.5106e-08, 1.2669e-07, 5.1960e-02, 1.8294e-01, 8.7879e-02,
        4.9473e-02, 5.6900e-02, 1.0869e-07, 3.2195e-08, 2.3983e-02, 4.8920e-02,
        5.5456e-02, 9.7181e-03, 3.4151e-02, 9.8492e-08, 1.8883e-02, 5.4740e-08,
        4.7125e-08, 7.7576e-08, 1.9555e-02, 3.5176e-08, 6.7891e-08, 6.9651e-02,
        7.4509e-02, 4.8136e-08, 3.9526e-02, 3.5747e-02, 4.5157e-02, 1.4456e-07,
        4.0884e-08, 1.2204e-01, 4.2558e-02, 7.3468e-02, 1.8782e-02, 6.9156e-08,
        1.5509e-07, 9.8572e-03, 4.5706e-08, 4.5706e-08, 5.1480e-02, 6.5446e-03,
        9.0028e-02, 8.5874e-08, 1.3742e-07, 1.8682e-01, 4.9182e-02, 1.9167e-02,
        4.0543e-02, 8.5369e-08, 4.5878e-02, 1.6378e-01, 3.4209e-02, 1.4887e-07,
        1.3902e-07, 1.4765e-02, 2.9726e-02, 2.7078e-07, 1.2695e-07, 1.0370e-07,
        8.3458e-02, 2.2708e-07, 8.5874e-08, 3.3362e-08, 1.0869e-07, 6.0893e-02,
        4.6718e-02, 1.0779e-01, 5.4394e-08, 5.2346e-02, 4.2147e-02, 4.1170e-02,
        3.0917e-02, 9.8417e-08, 3.6287e-02, 6.9988e-08, 6.2832e-02, 1.0583e-07,
        1.2620e-01, 9.1189e-03, 1.1248e-07, 1.8238e-02, 4.4355e-02, 6.9456e-02,
        8.6884e-03, 2.3540e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([8.0208e-08, 3.5144e-02, 1.0235e-02, 5.1724e-02, 5.1510e-02, 4.4484e-02,
        4.5528e-03, 1.6428e-07, 8.9276e-03, 3.2247e-07, 7.7791e-08, 1.8641e-07,
        6.0206e-08, 5.3243e-02, 3.2876e-07, 6.0206e-08, 3.9204e-02, 6.0206e-08,
        3.2247e-07, 4.2643e-02, 2.6842e-02, 2.4285e-07, 5.4773e-08, 6.3041e-02,
        1.4624e-07, 4.2675e-02, 6.3720e-02, 2.4285e-07, 7.5965e-02, 5.0827e-02,
        1.2609e-07, 6.0206e-08, 8.2330e-08, 2.7422e-02, 3.5247e-02, 6.0206e-08,
        1.9514e-07, 4.0754e-02, 3.8724e-02, 4.9866e-02, 1.2983e-01, 5.1261e-02,
        1.1250e-07, 7.4753e-02, 8.0208e-08, 5.4773e-08, 4.7787e-08, 8.2022e-02,
        2.7807e-02, 1.7654e-02, 5.8045e-02, 3.4414e-02, 7.1156e-02, 1.6388e-07,
        3.5858e-02, 1.0065e-07, 2.4285e-07, 1.0065e-07, 4.7787e-08, 3.0820e-02,
        4.7731e-02, 5.9358e-02, 1.4093e-07, 3.2876e-07, 1.1266e-07, 5.0082e-02,
        7.2089e-02, 5.4418e-02, 6.0131e-03, 2.0084e-07, 7.4430e-02, 5.1302e-02,
        4.7787e-08, 2.8148e-02, 3.3104e-02, 4.3120e-02, 2.4021e-02, 1.2483e-07,
        2.4285e-07, 8.0208e-08, 5.2406e-02, 3.7088e-07, 4.8014e-02, 4.9965e-02,
        6.4152e-02, 3.8116e-02, 9.2706e-02, 7.3487e-02, 6.8867e-08, 5.2813e-02,
        6.1691e-02, 5.3805e-02, 3.2568e-02, 2.6127e-07, 2.1542e-02, 5.2738e-03,
        6.0416e-02, 5.5834e-02, 6.0206e-08, 2.4728e-02, 4.3717e-02, 2.0678e-07,
        8.3686e-02, 4.3059e-02, 5.4549e-02, 7.0397e-02, 5.5431e-02, 5.6066e-02,
        7.3073e-02, 1.4093e-07, 3.5869e-07, 8.1164e-03, 1.0065e-07, 1.4093e-07,
        6.8867e-08, 5.4106e-02, 5.0107e-02, 6.8867e-08, 4.0609e-02, 6.4106e-02,
        4.8006e-03, 6.0482e-02, 4.4195e-02, 2.2713e-07, 2.5651e-02, 1.8087e-07,
        2.4077e-02, 3.5910e-08, 4.2752e-07, 8.8811e-02, 3.8048e-02, 4.4683e-02,
        2.6225e-07, 6.8867e-08, 1.4093e-07, 5.4773e-08, 3.1333e-02, 1.5239e-02,
        1.4401e-02, 4.3531e-02, 3.9117e-02, 4.2752e-07, 1.8978e-07, 4.8944e-02,
        6.0529e-02, 2.6032e-02, 8.0722e-02, 7.6744e-08, 4.3575e-07, 5.2387e-02,
        4.0535e-02, 2.8968e-02, 2.2300e-03, 7.3080e-02, 6.0206e-08, 4.3009e-08,
        7.1638e-02, 5.9826e-02, 2.1412e-02, 6.0206e-08, 1.0271e-02, 4.4313e-02,
        2.4285e-07, 1.1036e-02, 6.0206e-08, 2.2070e-07, 3.2247e-07, 6.0206e-08,
        6.0216e-03, 1.6428e-07, 3.6762e-02, 7.6568e-02, 1.4104e-07, 6.8486e-02,
        4.7787e-08, 4.9541e-02, 2.2405e-07, 4.6810e-02, 2.6225e-07, 6.0206e-08,
        6.0206e-08, 6.0206e-08, 2.6225e-07, 2.0801e-02, 3.9895e-02, 1.8641e-07,
        8.2185e-02, 3.3452e-07, 5.5246e-02, 2.9699e-03, 8.7533e-02, 3.2531e-07,
        2.9256e-02, 7.8452e-08, 7.3195e-08, 5.4773e-08, 5.1181e-02, 6.0206e-08,
        4.8730e-02, 5.4185e-02, 5.0697e-02, 4.4174e-08, 6.2851e-03, 2.3889e-07,
        4.6412e-02, 3.7741e-02, 2.4285e-07, 4.7970e-02, 6.0206e-08, 1.4998e-02,
        5.3318e-02, 3.8377e-02, 7.9595e-08, 6.4877e-02, 8.2347e-02, 5.5958e-02,
        5.6007e-02, 8.2330e-08, 5.3766e-02, 1.9674e-02, 5.3299e-02, 6.0206e-08,
        1.5275e-07, 1.7620e-07, 5.9961e-02, 5.0522e-02, 4.0552e-02, 1.4093e-07,
        6.5349e-02, 2.4285e-07, 3.2556e-02, 1.9423e-07, 3.2876e-07, 3.5642e-02,
        3.1946e-02, 7.1296e-02, 8.7976e-08, 4.8207e-02, 4.4535e-02, 1.2058e-01,
        6.5209e-02, 8.0457e-02, 4.1218e-02, 7.8638e-02, 6.3329e-02, 2.9589e-02,
        1.5275e-07, 3.2531e-07, 2.2713e-07, 7.3913e-02, 7.0499e-02, 4.7432e-02,
        4.7787e-08, 3.3543e-02, 2.4285e-07, 2.4285e-07, 2.4285e-07, 7.5810e-02,
        4.3744e-02, 3.4440e-02, 6.1116e-03, 4.2752e-07, 2.1265e-03, 1.0865e-07,
        3.8572e-02, 1.1275e-02, 5.0741e-02, 3.3439e-02, 4.0387e-02, 1.4093e-07,
        2.6225e-07, 6.7165e-02, 8.3594e-02, 3.5212e-03, 6.0206e-08, 3.2600e-02,
        3.2085e-03, 5.4773e-08, 1.8993e-03, 4.0675e-02, 6.5827e-02, 8.4600e-02,
        2.2963e-02, 7.1451e-02, 5.8863e-02, 5.6675e-02, 4.4408e-02, 5.6090e-02,
        4.4348e-02, 6.2018e-02, 3.3606e-02, 4.0612e-02, 6.0206e-08, 6.0206e-08,
        5.0641e-02, 4.1805e-02, 3.6404e-03, 1.8063e-07, 6.8252e-02, 5.3705e-02,
        6.3261e-03, 6.2856e-02, 1.3795e-07, 3.6456e-02, 5.9908e-02, 3.9057e-02,
        3.7088e-07, 4.7787e-08, 2.8120e-02, 5.9597e-02, 4.3217e-02, 3.3551e-02,
        6.5886e-02, 1.2609e-07, 6.7466e-02, 1.6901e-07, 4.7787e-08, 4.0283e-02,
        1.4104e-07, 6.4404e-02, 3.9878e-02, 4.2396e-07, 6.8871e-08, 3.3452e-07,
        4.7322e-03, 4.3576e-02, 2.4331e-07, 3.2848e-02, 6.5945e-02, 2.0070e-07,
        2.3755e-02, 6.0323e-02, 4.4174e-08, 3.8823e-02, 5.1692e-02, 4.8779e-02,
        2.2713e-07, 1.1250e-07, 8.3002e-02, 5.4961e-02, 6.3419e-02, 1.8840e-02,
        1.8468e-02, 9.4568e-02, 5.4773e-08, 2.6225e-07, 5.5829e-02, 8.6097e-02,
        1.9638e-07, 2.3889e-07, 2.6225e-07, 4.0575e-03, 3.2859e-07, 9.2528e-02,
        4.9770e-02, 3.7902e-02, 6.0206e-08, 6.8867e-08, 6.8867e-08, 1.1294e-07,
        4.0047e-02, 3.9458e-02, 1.5741e-07, 1.4093e-07, 5.4911e-02, 4.8106e-02,
        2.4285e-07, 3.3452e-07, 3.0438e-02, 5.9793e-02, 4.9875e-02, 3.9963e-02,
        6.5181e-02, 1.8395e-03, 3.5869e-07, 1.8214e-02, 3.3678e-02, 7.4636e-02,
        4.1508e-02, 2.7357e-02, 9.3157e-02, 1.6966e-02, 6.0206e-08, 1.8069e-07,
        6.4286e-02, 1.4104e-07, 4.7787e-08, 1.8339e-02, 2.3757e-02, 1.4093e-07,
        6.5928e-02, 4.7787e-08, 1.9514e-07, 1.2234e-07, 1.7785e-02, 4.2486e-03,
        8.8659e-03, 6.1918e-02, 5.4954e-02, 4.7787e-08, 5.3863e-02, 1.4104e-07,
        6.5804e-02, 2.6225e-07, 5.6978e-02, 1.2183e-07, 2.9532e-02, 4.5094e-02,
        3.2764e-07, 5.2861e-02, 6.8867e-08, 4.7787e-08, 8.2937e-02, 1.7120e-02,
        4.3673e-02, 3.0702e-02, 4.4341e-03, 4.7697e-02, 4.6063e-02, 7.7615e-02,
        9.1571e-08, 5.7492e-02, 5.4093e-02, 6.8867e-08, 1.4093e-07, 6.0206e-08,
        7.3195e-08, 2.2774e-02, 1.2608e-07, 5.5029e-03, 9.3107e-03, 4.5048e-02,
        5.8362e-02, 5.3292e-02, 1.4093e-07, 3.5869e-07, 7.9865e-02, 2.8292e-02,
        2.9456e-02, 7.4620e-02, 8.1228e-02, 4.7787e-08, 1.0240e-01, 6.0206e-08,
        3.0896e-02, 5.4773e-08, 8.9244e-03, 4.2738e-07, 1.1949e-07, 3.0222e-02,
        3.7686e-02, 1.8641e-07, 8.0273e-02, 3.7531e-02, 4.2575e-02, 4.7787e-08,
        7.0450e-02, 1.5430e-02, 3.8555e-02, 6.3442e-02, 5.4360e-02, 2.6692e-07,
        6.0206e-08, 5.3910e-02, 6.8867e-08, 1.1250e-07, 7.1593e-02, 5.6419e-02,
        5.5139e-02, 3.5909e-08, 6.8867e-08, 2.6036e-02, 4.4566e-02, 5.0749e-02,
        3.9679e-02, 8.0208e-08, 5.3576e-02, 4.1659e-02, 9.4872e-02, 2.6225e-07,
        2.3148e-02, 5.6095e-02, 1.3551e-01, 1.1746e-07, 2.8649e-02, 2.2713e-07,
        3.5230e-02, 4.0400e-02, 5.5509e-08, 5.4773e-08, 2.6225e-07, 4.2109e-02,
        3.4823e-02, 4.2714e-02, 4.7788e-08, 4.5367e-02, 3.3623e-02, 3.0004e-02,
        6.1560e-02, 2.6529e-02, 5.4680e-02, 6.0206e-08, 3.7575e-02, 5.0775e-02,
        1.1002e-02, 3.8650e-02, 2.4285e-07, 2.9106e-02, 1.7820e-01, 1.1407e-02,
        4.5970e-02, 3.7099e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([3.7695e-02, 5.1230e-07, 2.1709e-02, 1.5100e-07, 5.5394e-02, 5.1252e-02,
        1.6879e-07, 1.7029e-07, 2.4184e-07, 4.3641e-07, 4.6711e-02, 7.8143e-07,
        4.4342e-07, 3.5711e-07, 1.8199e-02, 1.7029e-07, 1.9453e-07, 4.3641e-07,
        7.5936e-07, 1.0063e-07, 2.9534e-07, 4.3641e-07, 4.6301e-07, 1.0184e-02,
        4.2908e-02, 6.1783e-07, 5.1230e-07, 1.7029e-07, 4.9526e-02, 4.8741e-07,
        5.1230e-07, 1.0063e-07, 3.5711e-07, 8.0057e-08, 3.9728e-02, 3.5048e-02,
        3.3417e-07, 1.0133e-06, 5.1387e-02, 1.0586e-02, 1.0181e-01, 2.9114e-02,
        7.5936e-07, 3.1496e-02, 2.1162e-07, 2.3845e-07, 1.7029e-07, 3.6007e-07,
        5.8434e-02, 5.7713e-02, 8.3228e-02, 5.6098e-02, 1.4578e-07, 1.5373e-07,
        4.8741e-07, 3.5711e-07, 5.3149e-02, 7.7399e-02, 2.1237e-07, 8.0058e-08,
        5.2324e-02, 5.1230e-07, 4.5355e-02, 4.8741e-07, 4.7661e-08, 1.5177e-02,
        7.4404e-07, 6.6020e-02, 4.8562e-02, 5.6069e-07, 6.4719e-02, 5.1230e-07,
        4.0511e-02, 7.5936e-07, 2.3845e-07, 2.1237e-07, 2.9534e-07, 2.1237e-07,
        1.4103e-07, 2.1895e-07, 3.0482e-02, 6.2096e-02, 4.3389e-02, 1.8984e-03,
        4.8020e-02, 1.5975e-07, 1.4103e-07, 5.1230e-07, 2.3845e-07, 1.4103e-07,
        7.5294e-07, 7.9751e-07, 7.8953e-02, 7.8143e-07, 2.9534e-07, 7.8143e-07,
        2.1162e-07, 4.1424e-07, 1.0062e-07, 3.4691e-02, 1.0062e-07, 8.0058e-08,
        1.5865e-07, 3.5711e-07, 2.7769e-07, 2.9534e-07, 1.8963e-07, 3.7276e-03,
        4.8741e-07, 2.9534e-07, 4.0565e-02, 3.0005e-07, 1.7029e-07, 1.4103e-07,
        7.3168e-02, 2.3845e-07, 3.4390e-07, 6.6187e-02, 3.4268e-02, 2.1895e-07,
        3.7875e-02, 3.3417e-07, 9.4116e-08, 4.8741e-07, 2.7769e-07, 1.7029e-07,
        2.3845e-07, 4.6301e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([3.2803e-07, 1.8865e-07, 9.9536e-07, 7.9739e-02, 6.1825e-07, 1.8865e-07,
        7.0767e-02, 7.1249e-02, 8.4955e-02, 8.1993e-02, 3.2803e-07, 4.1635e-02,
        3.8817e-07, 5.9980e-07, 6.0354e-07, 9.4712e-02, 8.0241e-07, 1.2914e-06,
        2.3734e-07, 1.0088e-01, 2.0112e-02, 6.3581e-07, 1.1818e-01, 5.2459e-07,
        1.0859e-01, 4.1626e-02, 1.0986e-01, 2.9737e-07, 6.8220e-02, 8.1443e-02,
        2.6732e-07, 1.3144e-07, 5.9103e-07, 6.1010e-02, 1.4171e-06, 4.4301e-07,
        2.0328e-07, 2.8304e-02, 1.0231e-06, 6.7618e-02, 7.1723e-07, 3.8817e-07,
        7.4534e-02, 2.3734e-07, 1.3161e-06, 2.5633e-07, 7.2182e-02, 8.9367e-02,
        3.8817e-07, 4.3757e-07, 9.1732e-08, 2.3734e-07, 4.0975e-07, 7.2215e-08,
        7.8664e-02, 3.5551e-07, 1.3018e-06, 1.0474e-01, 1.0612e-01, 5.9980e-07,
        1.1418e-01, 3.2803e-07, 1.0983e-01, 2.3734e-07, 9.1732e-08, 9.0367e-02,
        3.8817e-07, 8.0241e-07, 5.1078e-07, 7.3682e-02, 9.1732e-08, 4.4437e-07,
        1.7042e-07, 2.5633e-07, 2.3734e-07, 8.3682e-02, 7.5991e-02, 6.4998e-02,
        2.7820e-07, 5.1078e-07, 2.9737e-07, 2.9760e-06, 1.3161e-06, 1.0556e-01,
        1.0171e-01, 4.1640e-02, 3.4073e-07, 5.1078e-07, 8.0241e-07, 5.5824e-07,
        9.8001e-02, 5.2046e-02, 9.9676e-02, 8.3348e-02, 2.7961e-02, 9.9536e-07,
        2.3734e-07, 7.7777e-07, 1.0483e-01, 1.8461e-07, 9.9536e-07, 6.8259e-02,
        7.5819e-02, 9.6987e-02, 5.5922e-07, 1.3161e-06, 8.9181e-02, 7.1723e-07,
        8.0241e-07, 7.1743e-02, 1.8866e-07, 4.4437e-07, 2.3734e-07, 2.3734e-07,
        1.3033e-06, 9.1734e-08, 5.5922e-07, 9.1252e-02, 3.2803e-07, 2.3734e-07,
        4.5823e-07, 2.3734e-07, 1.1426e-07, 2.5633e-07, 1.1160e-01, 6.1557e-02,
        7.1723e-07, 4.7976e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.5866e-07, 3.1995e-02, 1.1422e-07, 2.5442e-02, 4.8834e-02, 9.6254e-08,
        3.7467e-02, 2.3183e-07, 6.7007e-02, 1.4889e-01, 1.1169e-07, 3.4845e-02,
        2.1137e-02, 7.0335e-03, 6.0450e-02, 1.7140e-07, 1.3652e-02, 5.1787e-02,
        5.1465e-02, 5.3640e-03, 8.0710e-08, 7.0695e-08, 6.0226e-08, 3.1053e-02,
        2.9457e-02, 1.3180e-02, 3.3849e-02, 1.1483e-07, 1.7992e-02, 2.2078e-02,
        5.9911e-02, 4.5448e-08, 1.4439e-07, 3.1963e-02, 1.8913e-02, 8.1384e-02,
        4.2203e-08, 5.6617e-02, 2.3162e-02, 3.8472e-02, 4.3762e-02, 2.6619e-02,
        5.1471e-02, 1.0014e-02, 2.2424e-01, 3.3030e-08, 1.8083e-07, 8.6116e-03,
        3.5088e-02, 5.4672e-08, 2.4237e-02, 1.3095e-02, 1.3292e-02, 1.2690e-07,
        4.8419e-08, 1.3494e-01, 1.8083e-07, 4.4085e-02, 5.1798e-08, 2.6556e-02,
        2.1599e-02, 1.5973e-02, 5.9706e-02, 3.6724e-02, 8.5397e-08, 4.5601e-08,
        1.0702e-02, 3.4971e-02, 9.8421e-03, 5.1208e-02, 1.7455e-02, 3.9126e-02,
        1.3380e-07, 3.9730e-02, 1.1581e-07, 1.6361e-01, 3.3304e-02, 9.5404e-08,
        3.3030e-08, 2.6098e-02, 5.4746e-02, 4.1542e-02, 1.3538e-02, 3.5981e-02,
        2.2131e-02, 1.1525e-02, 1.5538e-02, 2.7289e-02, 3.6364e-02, 4.9116e-03,
        3.2307e-02, 5.2443e-08, 8.2176e-02, 3.4910e-08, 3.3823e-02, 6.1269e-08,
        1.2619e-02, 2.2942e-02, 4.2317e-02, 9.6376e-02, 1.8467e-02, 1.8971e-07,
        2.1765e-02, 1.0571e-02, 7.1912e-02, 2.4916e-02, 5.8819e-02, 5.5450e-02,
        8.6544e-03, 7.0654e-02, 1.5866e-07, 5.4273e-02, 5.4546e-02, 5.0252e-02,
        8.0756e-02, 7.1371e-02, 8.5569e-03, 5.5286e-08, 1.1843e-02, 6.1540e-03,
        4.7616e-08, 6.0673e-02, 2.0829e-02, 6.2164e-02, 4.1892e-02, 3.3611e-02,
        4.8535e-08, 3.7019e-08, 4.5448e-08, 2.4372e-02, 2.9431e-02, 6.5946e-02,
        2.5880e-07, 8.8820e-02, 6.2392e-08, 4.1826e-02, 5.4648e-08, 8.8075e-03,
        4.3217e-02, 4.1490e-03, 9.4995e-03, 1.8143e-07, 1.1483e-07, 2.0374e-02,
        4.9549e-02, 1.4988e-01, 1.3876e-02, 3.7607e-02, 5.4536e-08, 4.6059e-02,
        5.1266e-02, 4.2592e-02, 7.0422e-02, 6.1135e-02, 2.0615e-02, 4.9135e-03,
        3.1918e-02, 5.8787e-02, 1.4031e-07, 7.0799e-08, 6.1912e-02, 6.2103e-02,
        1.8445e-02, 6.5003e-08, 4.5448e-08, 8.2053e-08, 6.1107e-08, 5.8295e-02,
        3.3042e-02, 1.4818e-07, 1.3131e-02, 1.6428e-02, 1.5581e-07, 5.3147e-02,
        9.0497e-03, 4.2747e-08, 1.4439e-07, 1.3182e-02, 6.2631e-08, 6.2631e-08,
        6.2099e-08, 3.4910e-08, 1.1578e-07, 9.5504e-02, 1.4998e-02, 7.7440e-02,
        2.3847e-02, 4.0689e-02, 3.1186e-02, 5.1426e-02, 1.4065e-02, 1.6974e-02,
        4.9234e-02, 9.5409e-08, 4.8298e-02, 1.6330e-07, 1.3973e-01, 3.6641e-03,
        3.5646e-02, 3.8158e-02, 4.2386e-03, 3.6619e-02, 2.5406e-02, 6.8200e-08,
        1.0187e-02, 6.5999e-08, 1.1483e-07, 3.2391e-02, 4.2203e-08, 1.1654e-07,
        3.8337e-02, 4.0263e-02, 7.7871e-08, 2.7554e-02, 4.6802e-02, 1.1305e-02,
        3.7496e-02, 3.4335e-02, 2.9407e-02, 7.4240e-02, 1.0472e-02, 1.0420e-07,
        1.2317e-01, 8.9963e-08, 1.5195e-02, 3.2879e-02, 1.7301e-02, 1.8143e-07,
        2.2478e-02, 4.5767e-02, 4.6732e-02, 6.5329e-08, 9.5134e-09, 3.6904e-02,
        1.2475e-02, 3.4207e-02, 5.3937e-08, 6.3718e-02, 4.7934e-02, 2.2727e-02,
        9.4192e-03, 1.7082e-02, 1.2201e-01, 1.9327e-02, 3.3443e-02, 4.9671e-08,
        1.2029e-07, 5.5286e-08, 6.2099e-08, 6.4835e-02, 2.8158e-02, 4.7255e-02,
        6.8200e-08, 1.0221e-02, 7.1880e-08, 1.3218e-07, 4.4166e-02, 3.2648e-02,
        4.2956e-02, 7.2333e-03, 4.0825e-03, 6.2386e-02, 1.7961e-02, 4.3453e-02,
        1.0047e-02, 1.7893e-02, 1.5258e-02, 1.0493e-02, 1.0089e-02, 3.4910e-08,
        3.7019e-08, 9.3093e-03, 2.2077e-02, 1.6345e-07, 1.8143e-07, 9.9061e-02,
        2.0091e-02, 5.4536e-08, 3.8699e-02, 2.4103e-02, 1.7790e-02, 7.1271e-02,
        7.3049e-03, 4.8663e-02, 2.4298e-02, 9.8772e-03, 7.0580e-03, 1.3592e-02,
        2.9070e-02, 8.9977e-08, 3.4013e-02, 5.9397e-02, 3.0806e-08, 7.5390e-02,
        1.1744e-02, 2.3900e-02, 8.1788e-03, 1.7060e-07, 1.5988e-02, 7.1784e-02,
        1.3441e-01, 3.1761e-02, 1.8143e-07, 2.9824e-02, 3.6723e-02, 2.0304e-02,
        7.9744e-08, 3.4299e-02, 6.1267e-03, 3.6911e-02, 5.0161e-02, 2.1021e-02,
        2.3017e-02, 3.8285e-02, 2.5528e-02, 5.5248e-08, 1.7339e-02, 3.0717e-02,
        7.9531e-02, 1.0506e-02, 5.4727e-08, 5.7028e-02, 1.6330e-07, 1.0180e-07,
        4.1690e-02, 8.8892e-03, 2.1257e-02, 3.3715e-02, 4.7330e-03, 3.9784e-08,
        4.3361e-02, 5.1514e-02, 8.5490e-02, 5.0161e-02, 2.9598e-02, 6.1919e-02,
        1.7386e-01, 1.7140e-07, 1.1640e-02, 5.8931e-02, 2.9161e-02, 3.0735e-02,
        1.8254e-08, 1.5771e-02, 9.5069e-08, 5.6296e-02, 2.5519e-02, 1.8689e-02,
        5.8094e-02, 3.6820e-02, 1.0809e-07, 3.1960e-02, 6.6179e-08, 1.7269e-02,
        1.1324e-02, 1.2893e-02, 4.2602e-02, 4.5448e-08, 1.4851e-01, 1.5207e-07,
        5.3759e-02, 6.8213e-02, 9.0557e-08, 6.8200e-08, 1.6484e-02, 6.4577e-08,
        2.7032e-02, 5.0115e-08, 3.2698e-02, 1.2284e-02, 5.2308e-02, 5.6245e-02,
        1.5771e-02, 3.4401e-02, 9.1053e-08, 1.3690e-07, 5.8365e-02, 2.4426e-02,
        3.1524e-02, 5.9053e-03, 3.2664e-02, 2.8092e-02, 2.5745e-02, 3.6294e-08,
        2.0268e-02, 5.6076e-02, 5.1101e-02, 4.9470e-02, 1.1006e-08, 1.5581e-07,
        2.2044e-02, 4.0270e-02, 7.7890e-08, 3.2692e-02, 9.4869e-08, 5.8598e-02,
        2.9892e-02, 1.2777e-02, 4.6969e-02, 4.9166e-08, 5.6708e-02, 1.9852e-07,
        1.2543e-02, 3.0888e-02, 4.8449e-02, 6.8200e-08, 2.8159e-07, 1.6209e-02,
        1.5143e-01, 5.9968e-02, 3.3030e-08, 1.2482e-07, 1.2884e-02, 4.5893e-02,
        3.7760e-02, 8.0569e-02, 1.1415e-02, 3.4523e-02, 4.8792e-02, 1.5884e-02,
        3.9730e-02, 1.8114e-02, 3.9684e-02, 5.4273e-08, 5.4661e-08, 5.8273e-02,
        2.6256e-02, 5.9215e-02, 9.8410e-08, 7.8553e-03, 3.4014e-02, 7.0639e-03,
        3.2690e-02, 4.7960e-02, 1.6330e-07, 8.5686e-02, 5.9343e-02, 1.6467e-07,
        8.0385e-03, 3.0354e-02, 4.4511e-02, 3.5951e-02, 1.8142e-02, 4.2203e-08,
        2.1882e-02, 1.7140e-07, 4.4470e-08, 4.1872e-02, 1.3731e-01, 6.9222e-03,
        3.2771e-02, 7.2997e-02, 4.5132e-02, 4.5283e-02, 4.4031e-02, 1.2482e-07,
        3.1253e-02, 4.1691e-02, 3.2337e-02, 3.2516e-02, 7.8264e-03, 1.0324e-07,
        8.7274e-02, 1.4649e-02, 1.8083e-07, 1.4441e-07, 3.2705e-02, 4.8645e-02,
        7.0613e-02, 1.5866e-07, 1.5581e-07, 7.9030e-03, 2.0681e-02, 3.6313e-02,
        1.1648e-07, 6.6173e-02, 2.0903e-02, 1.4399e-02, 1.1671e-02, 4.5448e-08,
        1.1743e-07, 2.6271e-07, 4.8814e-02, 1.3925e-07, 2.9132e-07, 7.6799e-02,
        4.3005e-02, 6.1007e-02, 4.8733e-02, 8.2053e-08, 3.4632e-02, 2.1082e-02,
        8.3557e-02, 6.5337e-03, 5.9695e-08, 6.3380e-02, 7.6468e-02, 3.4518e-02,
        5.1992e-02, 2.2566e-03, 1.8035e-02, 4.8197e-02, 2.8868e-02, 5.6388e-03,
        4.0785e-02, 1.9616e-02, 4.7669e-02, 3.3036e-03, 6.4757e-02, 4.8020e-02,
        5.8863e-02, 1.2756e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([3.6030e-07, 1.4065e-07, 1.9922e-07, 3.3698e-02, 5.1525e-02, 2.6612e-02,
        5.8755e-07, 6.1294e-07, 3.7615e-02, 3.4460e-02, 9.0215e-04, 3.0323e-02,
        4.4972e-02, 4.5271e-07, 1.1663e-01, 2.4063e-07, 4.4177e-02, 2.1843e-07,
        3.1633e-07, 3.3412e-07, 2.7700e-07, 3.2786e-03, 3.3428e-07, 3.1714e-07,
        2.3431e-07, 2.8340e-02, 2.4733e-02, 1.3216e-01, 2.6389e-08, 5.3893e-02,
        2.8779e-02, 4.3574e-02, 2.2521e-02, 2.7700e-07, 4.3943e-02, 6.9787e-07,
        4.6669e-02, 5.5797e-02, 1.6772e-02, 3.4517e-02, 1.8592e-02, 1.4065e-07,
        2.9828e-07, 3.3718e-02, 3.7377e-02, 6.9837e-08, 2.7278e-02, 6.6689e-07,
        1.7165e-06, 3.5852e-07, 7.2897e-07, 4.5348e-07, 1.1807e-01, 9.1382e-07,
        3.1915e-02, 3.6030e-07, 2.6947e-02, 2.1168e-02, 7.7283e-07, 3.0001e-02,
        2.0906e-02, 4.4710e-07, 4.1669e-02, 4.2052e-02, 3.4579e-02, 5.3835e-02,
        5.0383e-07, 6.0214e-07, 4.0313e-07, 3.4737e-02, 3.0348e-02, 2.9306e-07,
        3.7165e-07, 4.2039e-07, 3.6697e-02, 6.6232e-07, 3.5167e-07, 2.9465e-02,
        2.4063e-07, 6.8376e-08, 3.6267e-02, 1.0640e-06, 2.7830e-02, 1.2178e-06,
        4.0467e-02, 3.2157e-02, 1.8217e-02, 4.4315e-02, 2.0202e-07, 3.6824e-02,
        3.8395e-07, 6.0214e-07, 4.8140e-02, 9.7554e-08, 2.3431e-07, 4.1524e-07,
        1.3752e-06, 4.1333e-02, 4.7301e-02, 8.9411e-07, 1.4251e-01, 3.8330e-02,
        3.7088e-02, 4.0917e-02, 3.9888e-02, 3.2086e-02, 3.8395e-07, 1.2111e-06,
        4.5477e-02, 4.0834e-02, 4.7065e-07, 3.9154e-07, 3.4228e-02, 3.2468e-02,
        3.5880e-02, 4.6437e-07, 1.0217e-06, 4.7178e-02, 3.0659e-02, 4.1524e-07,
        3.2824e-07, 5.0390e-07, 3.0381e-02, 1.1352e-01, 1.2178e-06, 1.6311e-07,
        3.9220e-02, 3.8842e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([2.6564e-02, 4.2009e-02, 9.1585e-03, 3.6310e-02, 2.7017e-06, 1.0025e-06,
        2.2885e-06, 1.0687e-06, 2.2451e-06, 1.3128e-06, 2.3043e-06, 7.6616e-02,
        1.1618e-01, 1.4123e-06, 1.5324e-06, 1.3475e-06, 1.0234e-06, 2.2399e-06,
        2.6210e-06, 1.2129e-01, 1.0112e-01, 1.5327e-06, 1.0407e-06, 3.3589e-02,
        3.8195e-06, 6.8625e-07, 1.9833e-06, 3.4907e-07, 1.7541e-06, 7.7802e-02,
        8.8905e-02, 1.8103e-06, 9.4678e-07, 3.9312e-02, 2.2117e-06, 1.8503e-06,
        7.9999e-07, 1.9443e-06, 7.2641e-07, 3.5622e-08, 2.8356e-02, 7.5454e-07,
        9.4918e-02, 2.2407e-06, 2.9805e-06, 1.1216e-06, 1.6590e-06, 3.3361e-02,
        1.1211e-06, 3.8462e-02, 1.8083e-06, 2.5384e-06, 1.2676e-06, 9.8153e-07,
        1.6744e-07, 8.9719e-02, 2.9583e-06, 9.5610e-02, 2.7575e-06, 3.5946e-06,
        6.2129e-07, 1.8083e-06, 3.2569e-02, 3.1311e-06, 1.1216e-06, 1.7948e-06,
        9.6171e-02, 1.8993e-06, 8.6838e-07, 1.1211e-06, 2.6779e-07, 1.0174e-01,
        3.7974e-06, 1.8083e-06, 3.0398e-07, 1.5636e-06, 1.0641e-06, 2.8668e-06,
        1.6127e-06, 2.3392e-06, 9.2030e-02, 8.3117e-02, 3.1577e-02, 7.8969e-07,
        1.8083e-06, 7.3709e-07, 1.0634e-06, 3.4154e-06, 4.5965e-06, 3.0398e-07,
        3.2516e-02, 1.3999e-06, 3.1763e-02, 1.0806e-06, 1.0298e-01, 9.8666e-02,
        8.7527e-02, 2.8668e-06, 2.6054e-06, 9.7332e-02, 1.9833e-02, 2.1064e-06,
        4.2305e-06, 7.2200e-02, 9.3198e-02, 3.6165e-06, 1.0025e-06, 8.0975e-07,
        8.3772e-07, 5.0442e-03, 2.3406e-06, 1.9113e-06, 1.7674e-06, 2.6054e-06,
        3.4525e-02, 9.2285e-02, 4.8982e-06, 1.3267e-06, 6.9229e-02, 8.9506e-07,
        2.8723e-02, 1.5169e-06, 1.0777e-01, 8.2236e-02, 1.6744e-07, 2.9085e-06,
        1.6084e-06, 1.8119e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([2.1993e-02, 2.8670e-02, 7.1022e-08, 6.4346e-02, 8.3172e-02, 2.4940e-02,
        6.1420e-03, 5.2118e-08, 6.7897e-02, 2.0433e-02, 7.4605e-02, 1.6744e-07,
        3.0968e-02, 3.9300e-02, 1.0605e-01, 1.4197e-07, 1.4731e-02, 5.6574e-08,
        2.9678e-02, 3.8290e-02, 5.6714e-08, 2.6083e-07, 1.2535e-07, 3.4542e-02,
        1.6783e-07, 1.3214e-02, 3.3708e-02, 4.7335e-02, 1.5570e-02, 4.7353e-02,
        1.3367e-02, 4.1929e-08, 8.3153e-08, 2.0932e-02, 9.3328e-03, 5.4918e-08,
        2.4765e-07, 3.8924e-02, 6.3056e-02, 3.8456e-08, 5.9641e-02, 3.0323e-02,
        7.3292e-08, 3.5972e-02, 1.0266e-02, 7.5511e-04, 1.4197e-07, 1.8276e-02,
        7.3245e-08, 3.0111e-02, 3.1442e-02, 2.6046e-02, 6.2853e-02, 1.6369e-07,
        6.3701e-08, 8.1917e-03, 1.6369e-07, 4.8552e-02, 5.8574e-02, 1.0808e-07,
        8.7956e-02, 2.9286e-07, 1.2140e-07, 5.5266e-02, 6.2115e-08, 1.5054e-07,
        6.0562e-02, 2.3824e-02, 2.8802e-02, 1.4031e-07, 2.1322e-02, 5.5179e-02,
        1.2209e-07, 3.9586e-08, 6.4665e-08, 3.3945e-02, 3.1827e-03, 6.0700e-08,
        1.4197e-07, 7.7145e-08, 3.2201e-02, 3.1883e-02, 1.6099e-02, 3.4701e-03,
        4.1939e-03, 7.5477e-02, 2.2760e-02, 1.3458e-01, 1.0014e-07, 8.6469e-03,
        1.8280e-02, 2.6640e-08, 7.4968e-02, 6.8530e-02, 1.7091e-02, 1.1994e-07,
        2.9184e-08, 4.2623e-02, 1.6907e-07, 1.1922e-02, 1.2163e-07, 9.2716e-08,
        2.2813e-02, 1.1830e-02, 1.2569e-01, 3.4290e-02, 3.0069e-02, 1.2936e-01,
        9.6910e-03, 3.2881e-02, 1.6541e-02, 2.4900e-02, 9.4176e-08, 4.0879e-02,
        2.9235e-02, 5.6318e-08, 1.8972e-07, 6.2931e-08, 2.6747e-08, 1.1992e-07,
        1.0396e-07, 1.4066e-02, 1.6806e-02, 6.7533e-02, 3.0880e-08, 7.3861e-08,
        1.0707e-07, 1.6182e-07, 5.7869e-02, 5.4064e-02, 2.8589e-02, 1.0927e-02,
        1.6369e-07, 3.3588e-02, 8.3153e-08, 1.5969e-07, 4.4620e-08, 5.5951e-08,
        1.1772e-07, 2.8574e-02, 7.4470e-03, 2.6188e-07, 3.2439e-02, 3.2434e-08,
        5.3274e-02, 2.5704e-02, 3.6005e-02, 1.1038e-07, 8.3153e-08, 2.9351e-02,
        6.3987e-02, 3.8358e-02, 1.9839e-07, 1.0190e-02, 2.5044e-02, 7.8220e-08,
        5.6152e-02, 2.3023e-02, 1.4114e-07, 2.3279e-07, 1.1083e-02, 1.5163e-01,
        2.4505e-02, 6.2382e-08, 6.2640e-08, 9.2245e-08, 2.0231e-01, 4.3758e-02,
        3.3811e-02, 8.3153e-08, 6.5801e-08, 2.9373e-02, 1.6369e-07, 4.5455e-02,
        8.8415e-08, 2.9854e-02, 8.9953e-08, 3.8027e-02, 4.2538e-02, 6.2106e-08,
        6.0244e-02, 1.4800e-07, 2.6072e-07, 7.6001e-02, 7.1870e-03, 1.8827e-02,
        7.1692e-03, 1.6447e-07, 7.3096e-02, 4.6196e-02, 2.3448e-02, 3.8426e-02,
        9.1703e-02, 7.5717e-08, 3.7546e-02, 2.4765e-07, 2.2842e-02, 1.6969e-07,
        3.6549e-02, 5.1873e-02, 1.0365e-07, 2.3551e-02, 3.7938e-02, 4.5451e-02,
        1.9743e-07, 6.9743e-08, 2.5966e-08, 2.3286e-02, 1.2209e-07, 1.6835e-07,
        6.0142e-02, 1.2703e-01, 8.1258e-08, 2.7685e-02, 3.9177e-02, 2.6589e-02,
        5.5966e-02, 1.2052e-07, 2.6555e-02, 4.6595e-08, 4.2572e-02, 1.6847e-07,
        3.9329e-02, 4.7189e-08, 4.6647e-02, 4.3340e-02, 2.4295e-02, 4.4587e-02,
        1.6130e-02, 1.2162e-07, 3.7176e-02, 1.6959e-07, 7.9956e-09, 1.0531e-01,
        1.1882e-07, 2.5388e-02, 1.3737e-07, 6.2111e-02, 8.2725e-02, 2.7398e-02,
        8.8071e-08, 3.7819e-02, 6.0317e-03, 3.2440e-02, 6.2944e-02, 5.6516e-02,
        8.3153e-08, 5.1916e-08, 5.8751e-08, 2.9646e-02, 5.2858e-02, 5.5372e-02,
        5.1916e-08, 1.3410e-02, 2.6747e-08, 6.3716e-02, 3.7981e-03, 5.0614e-02,
        3.0846e-02, 6.4782e-08, 1.0215e-07, 1.1588e-02, 7.6391e-08, 8.3721e-08,
        1.0329e-02, 1.7787e-02, 3.1966e-02, 7.8424e-03, 1.1947e-02, 2.2102e-01,
        8.3153e-08, 1.1801e-07, 1.7093e-02, 5.4545e-08, 2.5966e-08, 2.0799e-02,
        1.6735e-01, 1.8976e-07, 1.1909e-07, 1.3974e-01, 5.0394e-02, 2.8608e-02,
        2.4071e-07, 5.0295e-02, 4.1517e-02, 4.5923e-02, 4.6458e-02, 3.5710e-02,
        5.1563e-02, 3.3516e-02, 2.4357e-02, 7.6525e-08, 2.7047e-02, 1.1982e-07,
        4.3527e-02, 6.7831e-02, 1.9809e-02, 8.1050e-08, 2.5826e-02, 3.1042e-02,
        2.0102e-02, 2.7086e-02, 5.1110e-08, 2.6180e-02, 4.8530e-02, 1.4291e-02,
        1.6960e-07, 2.4270e-07, 3.9152e-02, 7.3240e-08, 3.9393e-02, 7.6331e-02,
        1.1839e-02, 2.3823e-07, 3.9036e-02, 7.1015e-08, 4.7079e-08, 2.5039e-02,
        9.7887e-03, 4.1814e-02, 3.2348e-03, 2.8942e-02, 1.6960e-07, 2.0875e-01,
        4.0119e-02, 4.6422e-02, 1.8872e-07, 1.1965e-07, 4.4357e-02, 7.3253e-08,
        9.6808e-03, 3.8114e-02, 5.6858e-02, 3.6020e-02, 5.7821e-02, 5.2515e-02,
        2.8428e-02, 2.6317e-08, 4.3145e-02, 4.1145e-02, 7.3447e-02, 1.3882e-07,
        1.2439e-07, 1.4756e-02, 1.8976e-07, 1.1940e-07, 2.8075e-03, 2.0703e-02,
        5.2713e-08, 4.8452e-02, 2.8664e-08, 5.5805e-02, 2.2149e-07, 3.1914e-02,
        6.6313e-02, 2.0255e-02, 2.1676e-02, 7.3607e-08, 1.5803e-02, 4.3259e-08,
        4.6896e-02, 3.7275e-02, 1.2915e-07, 1.6369e-07, 2.7222e-02, 2.0288e-02,
        2.1472e-08, 7.2202e-02, 6.0345e-02, 3.5745e-02, 7.3109e-02, 5.5322e-02,
        3.6608e-02, 4.7612e-08, 6.2640e-08, 1.9156e-07, 5.4639e-02, 2.0708e-02,
        6.7556e-02, 8.2182e-08, 2.2392e-02, 2.4153e-07, 4.7241e-08, 2.0757e-07,
        1.9003e-02, 1.2285e-07, 1.7390e-02, 4.1999e-02, 6.2444e-08, 9.9132e-08,
        4.8008e-02, 2.6708e-07, 3.3518e-07, 1.3458e-07, 4.8420e-02, 3.5444e-02,
        2.1776e-07, 1.0613e-02, 2.2028e-04, 1.2484e-01, 1.9225e-02, 2.2149e-07,
        4.7826e-02, 4.9229e-02, 3.8913e-02, 2.6746e-08, 6.8158e-02, 6.4859e-02,
        2.9684e-02, 2.9701e-02, 9.5445e-08, 7.1015e-08, 2.8215e-02, 1.6638e-02,
        4.5093e-02, 4.4408e-02, 8.7611e-03, 2.0205e-01, 3.3439e-02, 3.0811e-02,
        2.4788e-02, 3.3955e-02, 3.3589e-02, 1.8976e-07, 7.4146e-02, 1.3659e-07,
        1.2668e-07, 1.0361e-07, 8.1280e-08, 6.7677e-03, 7.4020e-02, 3.7184e-02,
        9.1592e-03, 5.2146e-08, 1.6664e-02, 2.4424e-03, 3.1656e-02, 1.0787e-02,
        8.1357e-03, 3.9356e-02, 2.0403e-02, 8.1120e-08, 1.7768e-02, 8.8978e-08,
        1.9739e-07, 1.8976e-07, 3.4248e-02, 5.7056e-02, 3.5635e-02, 8.5318e-03,
        3.5289e-02, 9.8339e-03, 3.9425e-02, 8.2983e-08, 4.9741e-02, 8.1380e-02,
        6.1345e-02, 9.4748e-03, 1.2644e-01, 2.9579e-02, 1.3445e-01, 3.3525e-07,
        4.0317e-02, 5.6871e-02, 2.6747e-08, 2.5694e-07, 4.3245e-02, 2.2673e-02,
        4.9075e-02, 4.2997e-08, 6.2106e-08, 1.0770e-02, 1.9257e-02, 1.3024e-07,
        1.0075e-07, 1.1872e-07, 3.2292e-02, 1.7335e-02, 2.6683e-02, 3.3729e-08,
        4.0093e-02, 2.2140e-02, 7.2767e-02, 2.2349e-07, 4.5604e-08, 5.1365e-02,
        2.9735e-02, 8.0982e-08, 2.4789e-02, 2.6083e-07, 1.6975e-01, 3.9469e-02,
        3.1648e-02, 1.2192e-02, 2.6746e-08, 5.1969e-02, 1.7572e-01, 4.2369e-02,
        8.4865e-02, 1.8896e-07, 2.9478e-02, 6.7063e-08, 4.8939e-02, 1.6406e-02,
        4.6705e-02, 6.5031e-02, 7.5958e-08, 5.4914e-02, 1.7392e-02, 7.3544e-08,
        5.5097e-02, 1.4099e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.0572e-06, 4.4960e-02, 2.6402e-02, 3.4247e-02, 6.9643e-07, 1.1165e-03,
        1.5402e-06, 5.9643e-07, 5.2622e-07, 5.0070e-07, 9.1059e-07, 1.2254e-01,
        9.5666e-07, 4.7674e-07, 3.2397e-03, 4.1365e-07, 4.1365e-07, 8.5717e-04,
        9.5425e-07, 4.2974e-02, 2.8204e-07, 3.6513e-02, 7.9459e-07, 2.4246e-07,
        8.7769e-02, 3.0422e-03, 5.7814e-07, 2.9998e-02, 3.6213e-07, 3.1778e-02,
        2.8507e-07, 4.4227e-02, 1.0350e-04, 9.7512e-07, 8.1189e-07, 5.1968e-07,
        1.7309e-07, 1.1157e-01, 8.7262e-02, 1.6669e-02, 1.7789e-07, 4.7674e-07,
        5.5654e-07, 2.2639e-02, 4.1411e-07, 4.9929e-02, 9.5262e-07, 3.3818e-02,
        4.6512e-07, 3.8321e-07, 1.0132e-03, 1.0106e-06, 8.6668e-02, 2.3677e-02,
        2.5777e-03, 3.6480e-02, 4.6524e-07, 3.6783e-02, 3.9995e-02, 7.0344e-07,
        3.2264e-03, 7.0344e-07, 9.7123e-03, 1.7309e-07, 3.3838e-02, 8.3282e-07,
        4.8340e-07, 3.6097e-02, 7.2804e-04, 3.6950e-07, 1.1251e-06, 2.6791e-02,
        2.8849e-07, 5.1968e-07, 7.1124e-07, 2.7336e-02, 3.4471e-02, 2.7612e-07,
        2.4161e-03, 3.0362e-07, 1.3939e-06, 3.3838e-02, 1.0840e-03, 2.1837e-07,
        4.8898e-02, 2.8204e-07, 3.5428e-02, 1.0520e-06, 3.4726e-03, 4.1317e-07,
        1.9544e-07, 3.7338e-02, 2.8845e-02, 3.4052e-07, 1.3939e-06, 4.8340e-07,
        9.8057e-02, 4.1317e-07, 5.0070e-07, 8.8588e-07, 4.1409e-02, 4.1587e-02,
        2.8204e-07, 2.3552e-03, 4.1411e-07, 1.7309e-07, 4.7674e-07, 6.4513e-07,
        9.6691e-07, 5.8926e-07, 9.5794e-02, 4.6524e-07, 4.7674e-07, 7.6048e-07,
        3.4207e-07, 3.0431e-02, 9.8271e-02, 8.5026e-07, 8.8310e-07, 8.4328e-02,
        4.1317e-07, 3.7438e-02, 3.8321e-07, 9.4967e-07, 3.6213e-07, 1.4959e-07,
        4.3933e-07, 1.0227e-01], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.5348e-06, 1.1761e-06, 3.8768e-07, 3.5775e-02, 6.9856e-07, 3.4579e-06,
        3.4579e-06, 1.5051e-06, 7.1631e-07, 8.7193e-07, 7.1395e-07, 1.2269e-06,
        3.7651e-07, 2.5713e-02, 2.0976e-06, 1.0968e-06, 1.8993e-06, 4.6182e-07,
        8.4475e-07, 4.4678e-06, 1.3835e-06, 1.3415e-06, 1.1201e-01, 1.6552e-06,
        2.7517e-06, 1.8148e-06, 1.1408e-06, 3.5689e-02, 1.1258e-06, 9.7455e-07,
        3.1229e-06, 1.6882e-06, 1.2269e-06, 2.3656e-06, 1.1307e-01, 1.4012e-06,
        2.8973e-06, 7.3349e-07, 2.0951e-06, 8.0734e-07, 2.7660e-06, 1.5348e-06,
        7.4363e-04, 1.2258e-01, 5.1039e-07, 1.8993e-06, 3.3121e-06, 1.0956e-06,
        1.2053e-06, 1.3648e-06, 1.3835e-06, 5.8301e-07, 2.3444e-06, 7.1939e-07,
        1.2510e-06, 1.2722e-06, 4.0985e-02, 1.2121e-06, 1.0992e-06, 7.0364e-07,
        7.7484e-07, 1.5348e-06, 6.6883e-07, 1.0438e-01, 3.8600e-02, 1.4013e-06,
        1.2510e-06, 7.7484e-07, 1.3803e-06, 1.0992e-06, 5.1039e-07, 1.2298e-06,
        1.9693e-06, 6.0503e-07, 1.1276e-06, 1.3648e-06, 3.0724e-06, 3.3609e-02,
        6.7060e-07, 1.9693e-06, 8.0028e-07, 2.3656e-06, 8.4729e-02, 7.0219e-07,
        9.7513e-07, 2.5918e-06, 1.3648e-06, 1.1863e-01, 1.3633e-06, 1.0212e-01,
        3.4344e-02, 4.7710e-07, 3.5842e-06, 6.4670e-07, 1.5348e-06, 5.5394e-07,
        3.4579e-06, 8.7924e-02, 7.8611e-07, 1.0499e-01, 2.5918e-06, 2.4931e-06,
        1.3746e-06, 1.9837e-06, 1.0102e-06, 1.9455e-06, 9.0808e-07, 3.2932e-06,
        1.1798e-06, 4.6020e-06, 1.1460e-06, 2.7081e-02, 1.7513e-06, 6.3922e-07,
        1.2741e-06, 9.5315e-02, 7.7484e-07, 8.8178e-02, 4.6341e-02, 3.4579e-06,
        3.0513e-06, 2.4856e-06, 9.8898e-07, 9.0808e-07, 2.0976e-06, 9.8112e-07,
        1.0866e-01, 9.0757e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([6.9818e-02, 1.3630e-07, 1.0449e-07, 6.0341e-08, 7.5306e-02, 9.6720e-03,
        1.3024e-07, 1.5679e-07, 2.3314e-07, 1.3790e-02, 1.1215e-02, 3.5886e-02,
        1.9482e-07, 9.0149e-03, 1.2579e-07, 6.8704e-08, 5.3228e-03, 9.8036e-08,
        1.4282e-07, 1.5582e-01, 6.0126e-08, 2.6814e-02, 3.3164e-07, 1.7627e-02,
        1.9161e-07, 5.6829e-08, 7.8487e-03, 1.7752e-01, 1.3397e-07, 2.8144e-02,
        5.2910e-08, 1.9491e-01, 5.4935e-08, 1.2975e-07, 1.1932e-01, 1.1001e-02,
        4.2488e-08, 8.0813e-08, 1.4073e-07, 1.8275e-07, 3.1816e-02, 1.7175e-02,
        1.2671e-07, 1.1876e-02, 7.0205e-03, 4.0343e-08, 1.7583e-01, 6.8593e-08,
        4.5430e-08, 9.0307e-08, 1.1651e-02, 2.5113e-02, 4.7992e-02, 2.4648e-07,
        4.1341e-02, 7.2773e-08, 3.6249e-08, 1.2699e-07, 6.3811e-08, 1.6928e-07,
        3.8427e-02, 6.7881e-08, 7.6656e-09, 1.4935e-07, 1.5679e-07, 1.0992e-07,
        4.4896e-08, 2.8288e-02, 8.0794e-08, 6.9295e-08, 9.1301e-02, 1.9646e-02,
        2.5027e-07, 1.0110e-07, 2.0237e-02, 7.1513e-08, 2.8276e-03, 5.3359e-08,
        1.8585e-01, 1.0739e-07, 1.2906e-07, 1.4766e-07, 1.0481e-02, 1.1680e-07,
        1.3188e-07, 7.3721e-08, 1.6716e-03, 2.1382e-02, 7.7695e-08, 1.2828e-07,
        1.4914e-03, 5.0566e-08, 8.2180e-03, 1.6278e-07, 5.0365e-08, 5.1544e-08,
        3.4361e-02, 2.1100e-02, 6.1688e-08, 9.0946e-03, 9.0601e-08, 1.2125e-07,
        1.5200e-07, 7.2124e-02, 9.7674e-08, 6.5133e-02, 1.6310e-07, 3.5226e-03,
        1.3448e-02, 7.4377e-08, 2.4641e-07, 4.0127e-02, 6.8095e-08, 2.3310e-07,
        3.1293e-02, 1.2533e-07, 1.0076e-07, 9.9454e-08, 8.6665e-08, 7.9399e-08,
        4.8135e-02, 1.4971e-07, 1.3260e-02, 8.4992e-03, 7.2135e-08, 1.9702e-07,
        1.1995e-02, 7.9451e-02, 1.1924e-07, 2.2834e-02, 3.8849e-02, 4.5982e-08,
        3.5951e-08, 2.2627e-02, 2.5198e-07, 5.0620e-08, 6.6381e-03, 8.1435e-08,
        5.8745e-08, 4.8298e-08, 1.3363e-03, 2.4500e-07, 1.5650e-07, 1.5791e-01,
        6.2724e-08, 1.3201e-03, 1.0927e-02, 1.4435e-07, 1.7169e-01, 1.3860e-02,
        4.7935e-08, 1.8615e-07, 1.8289e-02, 7.0026e-04, 1.3746e-07, 1.1568e-07,
        6.3831e-02, 1.2576e-07, 5.4028e-02, 5.4935e-08, 1.3328e-07, 1.4591e-01,
        6.8384e-08, 1.2147e-07, 5.4643e-08, 1.6442e-07, 2.5609e-07, 1.2582e-07,
        5.2222e-02, 6.0657e-08, 1.2898e-02, 2.9606e-02, 9.1570e-08, 1.8928e-02,
        6.3066e-08, 9.7200e-08, 1.1492e-01, 1.6377e-07, 1.5675e-01, 3.7703e-08,
        3.6329e-02, 1.4930e-01, 1.2669e-07, 3.0400e-02, 4.9724e-08, 8.3756e-08,
        2.2043e-02, 5.1727e-08, 1.7856e-07, 8.9844e-08, 6.7457e-03, 4.7112e-08,
        7.0843e-03, 8.0743e-08, 7.1371e-08, 4.8825e-08, 1.5465e-03, 1.8284e-07,
        3.4727e-02, 1.5874e-07, 7.1374e-08, 7.4682e-02, 3.0395e-07, 8.7307e-02,
        5.5671e-03, 7.3258e-08, 9.9184e-08, 1.7456e-07, 1.0650e-07, 1.1774e-07,
        2.3906e-02, 7.8072e-08, 6.8670e-08, 1.1466e-02, 4.3980e-02, 2.0226e-07,
        4.2047e-02, 7.9751e-03, 7.3356e-03, 2.9403e-02, 1.5922e-02, 8.6007e-08,
        9.5691e-08, 2.2431e-07, 3.7769e-02, 7.2228e-02, 1.6867e-07, 7.5950e-02,
        2.3047e-02, 9.8055e-08, 1.2265e-07, 1.2294e-07, 3.3076e-07, 1.4129e-07,
        5.5909e-02, 1.1556e-07, 5.3803e-08, 3.5171e-02, 5.2843e-02, 2.5603e-02,
        6.6330e-03, 1.8386e-02, 5.5503e-08, 1.0401e-02, 2.5195e-02, 2.1501e-02,
        9.4090e-08, 1.6638e-01, 2.4637e-07, 1.9854e-02, 1.0279e-02, 3.4826e-03,
        2.5198e-07, 1.0165e-02, 2.5198e-07, 6.7035e-02, 5.1113e-02, 5.7833e-03,
        1.6304e-07, 6.2016e-08, 4.6352e-08, 7.3424e-08, 1.0847e-07, 6.6608e-08,
        1.6328e-01, 1.0826e-02, 2.2745e-02, 1.0473e-02, 9.2199e-03, 1.6056e-02,
        8.6037e-08, 2.3328e-07, 1.0643e-02, 7.1396e-08, 1.6442e-07, 1.9959e-07,
        1.7379e-07, 5.4935e-08, 1.2076e-07, 7.1743e-08, 3.3028e-03, 1.7076e-02,
        6.7783e-08, 2.9827e-02, 1.9845e-02, 1.9828e-07, 1.9061e-07, 1.2047e-07,
        1.2729e-07, 9.3945e-08, 1.1169e-07, 1.5419e-07, 1.2255e-07, 8.4496e-08,
        2.1683e-02, 7.8124e-08, 7.1024e-08, 1.3462e-07, 7.1924e-08, 3.9148e-02,
        1.6936e-07, 3.1128e-02, 9.1569e-08, 6.6806e-02, 1.5677e-02, 1.1915e-07,
        6.0129e-08, 5.9284e-02, 1.0210e-07, 1.3957e-07, 1.1469e-01, 7.2123e-08,
        9.9429e-03, 8.3934e-08, 1.3260e-07, 2.7152e-07, 5.3766e-08, 1.0762e-07,
        1.2997e-02, 4.4562e-02, 6.3427e-08, 7.0104e-08, 5.4935e-08, 3.4844e-02,
        2.6933e-02, 2.3711e-01, 2.5819e-08, 1.1632e-07, 7.8839e-08, 5.8680e-02,
        3.5738e-02, 4.2239e-08, 1.8038e-07, 2.0788e-02, 3.1682e-02, 7.8353e-08,
        1.7555e-02, 1.6265e-07, 8.7678e-03, 1.0019e-07, 1.9168e-07, 1.7535e-07,
        1.6456e-07, 8.4816e-03, 8.2628e-08, 1.9811e-07, 1.6390e-02, 1.4898e-02,
        8.9619e-08, 1.5235e-07, 1.4557e-01, 1.0888e-02, 4.0934e-02, 1.5472e-07,
        5.0565e-08, 5.3394e-02, 5.3121e-08, 5.4935e-08, 1.7337e-07, 9.9915e-08,
        4.1701e-02, 1.1570e-07, 1.6298e-07, 6.1201e-08, 7.8962e-03, 8.3961e-08,
        1.8130e-07, 9.3235e-08, 2.4677e-02, 1.6093e-02, 1.1884e-07, 2.4590e-02,
        2.2733e-02, 1.3970e-02, 6.0657e-08, 8.1561e-08, 4.7500e-02, 6.3201e-08,
        1.0174e-07, 1.6458e-07, 2.5062e-02, 2.2914e-07, 1.1117e-07, 3.0431e-02,
        1.1201e-07, 1.5064e-02, 7.9466e-08, 3.9830e-02, 3.3614e-02, 6.9247e-02,
        1.8277e-07, 8.5813e-08, 1.6265e-07, 6.1531e-08, 1.3942e-07, 2.5133e-02,
        1.3787e-07, 9.7445e-03, 2.8399e-02, 6.5417e-03, 4.5607e-08, 3.7684e-08,
        3.2338e-08, 3.6546e-08, 1.6824e-08, 4.2713e-02, 1.0711e-07, 2.7667e-07,
        3.1944e-02, 8.1526e-08, 4.8012e-08, 1.4720e-02, 3.0532e-02, 1.2454e-07,
        5.3331e-02, 9.4865e-08, 6.1456e-08, 4.2786e-02, 5.1319e-08, 1.4004e-02,
        1.3143e-07, 2.6977e-02, 7.1729e-08, 1.3366e-07, 6.4923e-08, 2.9357e-08,
        3.2876e-02, 8.1226e-02, 1.7270e-07, 6.8584e-08, 5.0428e-08, 2.5408e-02,
        4.8315e-02, 2.0190e-07, 2.9599e-02, 2.0079e-07, 1.5644e-07, 2.5143e-02,
        8.6118e-08, 2.3419e-02, 1.2568e-07, 5.5461e-02, 1.1112e-02, 4.8825e-08,
        2.6314e-02, 1.0196e-01, 7.1339e-08, 1.9843e-07, 5.0995e-08, 2.3759e-08,
        2.8444e-02, 8.8657e-03, 3.3342e-02, 4.6312e-02, 4.6034e-02, 9.2126e-08,
        5.4378e-08, 4.3368e-02, 2.1732e-02, 1.5106e-02, 1.9868e-07, 2.5198e-07,
        4.5235e-08, 1.7643e-02, 1.7269e-07, 1.5679e-07, 3.2323e-08, 2.3444e-02,
        7.8082e-08, 1.2722e-01, 7.8631e-08, 1.4060e-02, 1.0527e-07, 2.3612e-08,
        3.5187e-08, 1.6456e-07, 1.5336e-02, 1.2924e-02, 2.8594e-02, 1.5679e-07,
        1.3415e-07, 2.3342e-07, 6.1299e-02, 3.6249e-08, 8.0067e-08, 6.3389e-08,
        1.6579e-02, 2.2005e-02, 1.3291e-07, 1.1904e-07, 3.7129e-03, 3.0172e-02,
        5.2668e-08, 5.8011e-03, 6.1592e-08, 1.2039e-02, 8.0667e-08, 3.5139e-02,
        3.6568e-02, 4.7763e-08, 1.1384e-07, 1.2559e-07, 1.1519e-07, 5.0294e-02,
        7.2611e-02, 9.3309e-08, 6.2072e-08, 1.3524e-07, 2.8741e-02, 3.3325e-02,
        6.7056e-08, 7.7457e-08], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([9.5221e-02, 4.8583e-07, 3.7956e-07, 1.0474e-01, 6.1688e-02, 3.0558e-07,
        1.0674e-01, 1.2044e-07, 1.2355e-07, 1.5823e-07, 9.5601e-08, 9.8255e-02,
        7.5494e-02, 4.5197e-07, 6.8928e-02, 5.3234e-07, 2.2507e-07, 6.0929e-02,
        9.4828e-02, 6.9558e-02, 1.6047e-07, 8.6588e-02, 1.0957e-07, 1.6470e-07,
        9.7269e-02, 1.2044e-07, 6.3692e-08, 2.6454e-07, 9.7391e-02, 1.6470e-07,
        5.8758e-02, 3.9293e-07, 4.4449e-07, 1.2044e-07, 1.3777e-07, 1.9204e-07,
        1.2184e-07, 9.7717e-02, 4.8583e-07, 1.0076e-01, 7.1759e-07, 7.2736e-02,
        8.4691e-07, 1.1034e-01, 6.3692e-08, 6.4971e-07, 1.6047e-07, 8.7174e-07,
        1.6047e-07, 1.0689e-01, 1.0957e-07, 1.2044e-07, 1.2044e-07, 8.4950e-02,
        8.9048e-02, 5.6800e-07, 6.4659e-07, 2.8216e-07, 8.5015e-02, 1.6468e-02,
        4.7788e-07, 1.2044e-07, 8.7174e-07, 1.2044e-07, 4.8794e-02, 8.5758e-02,
        9.0213e-02, 4.8583e-07, 1.3845e-07, 1.0407e-01, 6.7186e-02, 5.3234e-07,
        1.1373e-01, 4.7788e-07, 9.0373e-08, 1.1268e-01, 2.2507e-07, 1.2184e-07,
        2.8529e-07, 2.3380e-07, 9.5601e-08, 5.3234e-07, 5.8674e-07, 3.7293e-07,
        5.6800e-07, 5.8876e-02, 4.8583e-07, 1.2044e-07, 5.3402e-07, 1.0576e-01,
        1.1261e-01, 9.4540e-02, 3.5251e-07, 5.8553e-08, 1.0305e-01, 4.7788e-07,
        1.6047e-07, 4.8583e-07, 4.8583e-07, 2.7190e-07, 1.9037e-07, 1.4643e-07,
        5.3234e-07, 6.7647e-02, 2.8216e-07, 1.9204e-07, 6.5500e-02, 5.3234e-07,
        7.8910e-02, 6.5236e-07, 9.2711e-02, 8.9116e-02, 9.3910e-02, 1.0147e-01,
        1.3553e-07, 1.3553e-07, 1.0593e-01, 7.3261e-02, 1.8198e-07, 5.6800e-07,
        1.0187e-07, 6.4659e-07, 5.3234e-07, 8.3363e-02, 4.8583e-07, 9.7939e-02,
        4.7583e-08, 3.2786e-07, 1.3777e-07, 1.6612e-07, 7.9150e-02, 9.1331e-02,
        8.5531e-02, 4.8583e-07, 3.9397e-07, 4.8583e-07, 6.3692e-08, 1.0957e-07,
        1.2044e-07, 8.9659e-02, 8.5982e-02, 8.7174e-07, 2.8216e-07, 5.3234e-07,
        4.7788e-07, 7.4197e-07, 6.4659e-07, 5.7509e-07, 6.8535e-02, 4.4449e-07,
        6.3692e-08, 1.2044e-07, 8.6383e-02, 1.2469e-01, 4.8583e-07, 1.3777e-07,
        4.8030e-02, 9.5601e-08, 2.2507e-07, 1.2044e-07, 1.2044e-07, 1.0204e-01,
        1.6047e-07, 1.1400e-01, 1.8001e-07, 7.6898e-02, 8.1467e-02, 4.7788e-07,
        1.2044e-07, 1.0957e-07, 1.3777e-07, 1.0216e-01, 8.1232e-02, 1.2184e-07,
        9.6083e-02, 5.3234e-07, 9.5601e-08, 9.0470e-02, 7.3698e-02, 3.2786e-07,
        8.3057e-02, 1.2044e-07, 2.2507e-07, 9.6157e-02, 4.4449e-07, 2.8216e-07,
        8.7923e-02, 1.2044e-07, 4.8583e-07, 5.3402e-07, 1.0258e-01, 1.0934e-01,
        8.4251e-02, 1.2044e-07, 1.0172e-01, 1.0541e-01, 9.0825e-02, 1.3777e-07,
        9.5575e-02, 7.4197e-07, 4.8583e-07, 4.4449e-07, 2.0242e-07, 9.9501e-02,
        2.8216e-07, 1.2184e-07, 1.0285e-01, 2.2507e-07, 1.0389e-01, 1.2184e-07,
        9.7007e-02, 1.4643e-07, 1.0957e-07, 2.8216e-07, 5.3234e-07, 8.7206e-02,
        4.8583e-07, 1.0369e-01, 9.5929e-02, 7.1759e-07, 1.6047e-07, 1.0435e-01,
        9.1839e-02, 4.7788e-07, 9.4843e-02, 5.6800e-07, 9.0908e-02, 5.3234e-07,
        2.0242e-07, 1.6047e-07, 4.8583e-07, 4.1347e-07, 9.5601e-08, 1.6047e-07,
        1.3777e-07, 1.0609e-01, 1.4372e-07, 4.5476e-02, 2.5140e-07, 2.8216e-07,
        6.3857e-02, 1.2044e-07, 5.3234e-07, 1.3777e-07, 4.8583e-07, 6.5236e-07,
        9.0393e-02, 6.4659e-07, 8.2731e-02, 1.6470e-07, 9.5601e-08, 5.3402e-07,
        1.0982e-01, 1.2044e-07, 8.7369e-02, 9.5601e-08], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([5.6530e-02, 1.2761e-06, 1.7457e-06, 1.7321e-06, 2.0046e-06, 6.3723e-02,
        2.3938e-06, 6.8457e-07, 6.4005e-02, 8.9318e-07, 3.7726e-06, 5.9510e-07,
        6.8457e-07, 1.6536e-06, 1.0786e-06, 4.8203e-06, 5.9510e-07, 8.9317e-07,
        2.7875e-06, 1.0171e-06, 1.0676e-06, 5.9510e-07, 6.8457e-07, 7.3909e-07,
        9.3489e-07, 3.7726e-06, 3.7561e-06, 4.8196e-06, 1.2071e-06, 1.0676e-06,
        4.2195e-06, 2.5133e-06, 2.0046e-06, 1.3667e-06, 1.1636e-06, 4.2195e-06,
        4.9358e-02, 2.5133e-06, 6.8457e-07, 2.0155e-06, 7.1530e-02, 6.8698e-02,
        7.5084e-02, 8.0350e-02, 2.0115e-06, 4.2195e-06, 2.0046e-06, 2.0155e-06,
        1.8479e-02, 6.8457e-07, 4.2195e-06, 1.0631e-06, 9.3489e-07, 7.7499e-07,
        8.9317e-07, 3.7556e-06, 2.3938e-06, 2.0155e-06, 8.2207e-02, 6.8457e-07,
        2.0046e-06, 1.0171e-06, 1.7321e-06, 2.0155e-06, 4.8820e-07, 6.1534e-07,
        2.0046e-06, 4.8181e-06, 1.4335e-06, 1.4230e-06, 2.5133e-06, 1.2071e-06,
        5.9510e-07, 4.2195e-06, 6.6938e-02, 2.0046e-06, 2.0046e-06, 7.9055e-02,
        1.0171e-06, 1.4335e-06, 3.8161e-06, 7.6588e-02, 9.1908e-07, 7.4435e-02,
        1.2761e-06, 4.2195e-06, 9.3489e-07, 2.3938e-06, 5.9510e-07, 1.4335e-06,
        6.8549e-02, 5.2878e-02, 1.7321e-06, 1.7457e-06, 2.0155e-06, 4.2195e-06,
        6.3072e-02, 2.3938e-06, 2.5953e-06, 2.5953e-06, 1.6274e-06, 2.0155e-06,
        1.9751e-06, 2.9954e-06, 1.1416e-06, 1.9751e-06, 7.2810e-02, 3.4083e-06,
        1.0676e-06, 9.3489e-07, 1.7321e-06, 8.0463e-02, 1.4335e-06, 1.9751e-06,
        2.5133e-06, 1.2071e-06, 1.7457e-06, 1.4335e-06, 2.0155e-06, 8.7161e-02,
        7.2482e-02, 2.5133e-06, 1.7321e-06, 2.0046e-06, 1.0676e-06, 6.8457e-07,
        2.9954e-06, 3.8161e-06, 6.3923e-02, 6.2798e-02, 6.7986e-02, 1.7321e-06,
        6.1487e-02, 1.0676e-06, 8.8632e-07, 2.1554e-06, 9.3489e-07, 2.5953e-06,
        6.8457e-07, 6.8457e-07, 9.3489e-07, 2.0155e-06, 2.4201e-06, 1.1636e-06,
        5.3907e-02, 3.2324e-06, 1.7457e-06, 5.9510e-07, 6.5125e-02, 4.2195e-06,
        6.8457e-07, 3.7558e-06, 7.5973e-02, 7.3688e-02, 1.0676e-06, 5.9510e-07,
        6.8457e-07, 7.2453e-02, 4.2195e-06, 2.3938e-06, 1.4335e-06, 6.6542e-02,
        6.8295e-02, 8.6237e-02, 2.5133e-06, 7.7471e-02, 4.2195e-06, 6.4054e-02,
        2.0155e-06, 1.7321e-06, 1.4335e-06, 3.6782e-06, 5.6709e-02, 5.9510e-07,
        8.1165e-02, 8.2467e-07, 4.9828e-02, 5.4244e-07, 1.3667e-06, 5.9510e-07,
        2.2942e-06, 7.4350e-02, 6.4824e-07, 1.6274e-06, 1.7457e-06, 7.6142e-07,
        3.2327e-06, 5.8764e-02, 1.0676e-06, 4.2195e-06, 1.4335e-06, 1.0676e-06,
        1.0676e-06, 5.7135e-02, 5.4244e-07, 1.7321e-06, 2.5133e-06, 2.5133e-06,
        6.9179e-02, 3.7726e-06, 5.9510e-07, 6.7031e-02, 4.2195e-06, 2.5133e-06,
        9.4795e-07, 3.7301e-06, 6.4824e-07, 2.3938e-06, 5.8580e-02, 6.8552e-02,
        4.2195e-06, 4.8201e-06, 1.7321e-06, 7.9648e-07, 1.8165e-06, 9.1541e-07,
        3.7726e-06, 9.3489e-07, 2.0155e-06, 9.3489e-07, 2.0155e-06, 1.7321e-06,
        5.3933e-02, 1.0676e-06, 9.3489e-07, 1.2071e-06, 2.4201e-06, 3.7828e-06,
        2.0155e-06, 2.3938e-06, 1.7321e-06, 1.7321e-06, 5.9510e-07, 6.2447e-02,
        1.1636e-06, 1.7321e-06, 3.7301e-06, 8.9318e-07, 2.0155e-06, 8.9318e-07,
        8.2759e-02, 1.0676e-06, 2.9954e-06, 1.7457e-06, 8.5274e-02, 1.7321e-06,
        4.2195e-06, 1.1636e-06, 6.5336e-02, 1.4926e-06, 9.4795e-07, 1.4230e-06,
        6.0158e-02, 1.7321e-06, 1.0631e-06, 7.3909e-07], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([4.4506e-02, 2.1140e-07, 1.2930e-07,  ..., 4.0867e-02, 2.3885e-07,
        5.1765e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([3.2763e-02, 2.6037e-07, 2.9179e-07,  ..., 4.6968e-02, 1.1988e-06,
        2.8792e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([4.8229e-07, 8.7139e-07, 7.3153e-07, 4.8354e-07, 3.9201e-07, 5.0649e-07,
        6.5453e-07, 4.8680e-07, 5.1444e-07, 2.6461e-02, 3.1101e-07, 1.0100e-06,
        4.8354e-07, 5.7881e-07, 8.4923e-07, 1.3477e-06, 6.5453e-07, 1.1544e-01,
        2.9641e-02, 2.2418e-07, 1.5041e-06, 9.8914e-07, 1.7219e-06, 1.1518e-06,
        4.8986e-07, 3.0996e-02, 1.7943e-02, 1.9807e-01, 1.0553e-06, 1.3469e-06,
        2.2776e-06, 1.7993e-06, 1.0951e-06, 9.3526e-07, 1.4055e-02, 1.2680e-06,
        4.8354e-07, 3.9201e-07, 2.8666e-02, 5.7540e-07, 7.4144e-07, 1.6361e-01,
        3.0734e-02, 7.9739e-07, 3.4693e-02, 3.3071e-02, 9.3121e-07, 5.2287e-07,
        1.0271e-06, 1.6435e-06, 8.5357e-07, 4.9052e-07, 3.3658e-02, 1.3469e-06,
        1.5533e-06, 9.7659e-07, 1.2017e-06, 3.9022e-07, 6.0538e-07, 6.0538e-07,
        2.7525e-02, 1.5971e-06, 2.4061e-02, 1.4646e-06, 3.4610e-02, 3.9938e-02,
        1.2680e-06, 2.8817e-07, 8.8063e-07, 1.6929e-06, 1.5731e-06, 2.6462e-02,
        6.5372e-07, 3.5469e-07, 1.7113e-06, 2.4317e-06, 3.4513e-02, 1.9924e-01,
        2.7565e-02, 1.0951e-06, 2.2418e-07, 5.7881e-07, 6.5372e-07, 1.7993e-06,
        3.1110e-07, 5.6008e-07, 2.2418e-07, 3.5469e-07, 2.5933e-02, 4.3686e-07,
        3.9201e-07, 3.1110e-07, 1.4606e-06, 5.7540e-07, 7.3370e-07, 6.5453e-07,
        1.5755e-01, 1.3469e-06, 1.5971e-06, 1.4028e-06, 2.5178e-02, 7.9707e-07,
        1.6084e-06, 2.0098e-07, 8.2160e-07, 1.0951e-06, 2.2418e-07, 1.5000e-06,
        9.0505e-07, 3.7977e-02, 1.2680e-06, 8.2160e-07, 1.5630e-06, 1.7993e-06,
        1.7113e-06, 1.5630e-06, 1.5731e-06, 8.0880e-07, 1.0123e-06, 2.1137e-01,
        8.0880e-07, 4.8680e-07, 9.1472e-07, 8.8447e-07, 4.3686e-07, 2.6018e-02,
        6.1290e-07, 1.7993e-06, 2.2644e-02, 1.0655e-06, 9.4143e-07, 1.5731e-06,
        5.6060e-07, 2.4533e-06, 1.5630e-06, 1.1148e-06, 1.4180e-06, 3.7199e-02,
        1.2680e-06, 5.6889e-07, 8.6014e-07, 1.5716e-02, 1.6566e-06, 1.3469e-06,
        6.0538e-07, 6.4852e-07, 6.5453e-07, 2.9276e-02, 1.5731e-06, 1.7993e-06,
        6.5372e-07, 3.5469e-07, 1.3469e-06, 4.8680e-07, 9.1559e-07, 7.4144e-07,
        2.1980e-02, 1.5630e-06, 5.2287e-07, 2.9993e-02, 8.2160e-07, 3.0971e-02,
        9.4143e-07, 8.6014e-07, 6.5372e-07, 6.5453e-07, 9.7659e-07, 5.8581e-07,
        6.8145e-07, 3.1390e-02, 3.1110e-07, 2.1672e-02, 4.8354e-07, 8.0880e-07,
        4.3148e-02, 1.0951e-06, 1.5223e-06, 3.9201e-07, 6.8491e-07, 1.2680e-06,
        4.8354e-07, 1.5731e-06, 4.3686e-07, 5.9559e-07, 2.7772e-02, 3.4177e-02,
        6.0042e-05, 1.5533e-06, 2.5791e-02, 8.6014e-07, 3.1025e-02, 3.9201e-07,
        3.2165e-02, 1.0123e-06, 6.5453e-07, 1.5533e-06, 3.7977e-02, 6.0068e-07,
        1.5731e-06, 1.3469e-06, 1.1148e-06, 4.8680e-07, 2.3927e-06, 3.9201e-07,
        2.0098e-07, 4.8986e-07, 3.5721e-02, 7.4144e-07, 1.8562e-02, 1.5533e-06,
        3.9201e-07, 1.6825e-06, 6.0068e-07, 8.5357e-07, 3.2286e-02, 6.8145e-07,
        1.2017e-06, 2.1318e-02, 1.5630e-06, 5.6197e-07, 1.0271e-06, 3.6641e-02,
        3.7015e-02, 9.9784e-07, 4.8680e-07, 2.2418e-07, 8.9460e-07, 8.0880e-07,
        5.6008e-07, 1.4646e-06, 3.4505e-02, 2.2437e-02, 9.3121e-07, 2.9430e-02,
        2.8669e-02, 7.9739e-07, 4.8354e-07, 6.5453e-07, 4.0677e-03, 5.1444e-07,
        7.4144e-07, 4.3686e-07, 5.2287e-07, 2.7047e-02, 8.2581e-07, 1.1518e-06,
        4.6883e-07, 3.5469e-07, 7.9209e-07, 1.5630e-06, 2.2418e-07, 8.5357e-07,
        2.5828e-07, 1.0938e-07, 3.1110e-07, 4.8229e-07], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([2.6641e-02, 1.3684e-06, 2.1355e-06, 5.2413e-02, 9.3082e-07, 1.2057e-06,
        4.4729e-02, 2.9349e-06, 4.5580e-07, 1.2110e-06, 2.4481e-06, 7.4133e-07,
        2.7860e-02, 1.2110e-06, 2.9349e-06, 1.9529e-06, 2.0009e-06, 2.3342e-06,
        1.4101e-06, 9.3446e-07, 2.8691e-06, 4.2803e-06, 2.8691e-06, 9.4306e-07,
        9.3349e-07, 1.0700e-06, 1.2110e-06, 9.2306e-07, 1.5402e-06, 5.9467e-07,
        3.6824e-02, 1.4398e-06, 1.9980e-06, 8.4081e-07, 2.2643e-06, 1.8197e-06,
        6.6621e-07, 1.0700e-06, 3.3354e-02, 2.9349e-06, 2.7539e-06, 3.3989e-07,
        9.4306e-07, 6.4183e-02, 1.2057e-06, 1.4614e-06, 2.0052e-06, 1.6291e-06,
        1.2609e-06, 3.5414e-02, 2.9349e-06, 1.9529e-06, 5.3950e-02, 5.3016e-02,
        2.6403e-06, 5.3481e-02, 1.4736e-06, 5.2565e-02, 9.3446e-07, 2.6403e-06,
        2.0503e-06, 1.2057e-06, 9.3349e-07, 2.3342e-06, 2.8691e-06, 2.0503e-06,
        6.6621e-07, 4.1749e-06, 5.8861e-02, 7.7802e-07, 9.1811e-07, 4.7119e-02,
        1.4101e-06, 1.3309e-06, 9.7150e-07, 1.6209e-06, 6.4327e-02, 1.3309e-06,
        2.1355e-06, 6.1781e-07, 5.3001e-02, 4.2803e-06, 9.1811e-07, 9.4042e-07,
        2.6403e-06, 2.3101e-02, 2.1355e-06, 2.1355e-06, 1.0468e-06, 1.3611e-01,
        1.8109e-06, 1.2110e-06, 6.4341e-07, 2.9349e-06, 9.4306e-07, 2.1104e-06,
        1.0965e-06, 9.8211e-07, 9.4306e-07, 5.8679e-02, 9.7150e-07, 2.3342e-06,
        5.1193e-02, 6.0363e-02, 6.1781e-07, 6.6621e-07, 2.1355e-06, 1.5402e-06,
        4.1287e-02, 1.5437e-06, 8.6350e-07, 2.4481e-06, 2.2963e-06, 4.6964e-02,
        9.8211e-07, 2.5550e-06, 6.0053e-02, 4.4366e-02, 6.1780e-07, 6.6621e-07,
        2.0606e-06, 5.5348e-02, 9.8211e-07, 5.9221e-02, 1.8211e-06, 9.1811e-07,
        6.6621e-07, 2.7539e-06, 1.3684e-06, 9.7150e-07, 2.7539e-06, 1.0700e-06,
        2.1355e-06, 2.3342e-06, 2.9349e-06, 1.2110e-06, 2.9349e-06, 5.5449e-07,
        2.7539e-06, 4.5276e-02, 9.3446e-07, 2.0009e-06, 1.1682e-06, 4.6101e-02,
        2.0606e-06, 3.3989e-07, 3.0623e-06, 2.9349e-06, 4.2752e-06, 2.9349e-06,
        5.9467e-07, 1.4092e-06, 1.1682e-06, 7.7802e-07, 4.1931e-02, 2.7539e-06,
        5.9467e-07, 6.4191e-07, 1.0700e-06, 1.1682e-06, 2.4481e-06, 2.0503e-06,
        3.6879e-06, 9.8211e-07, 3.8677e-02, 1.3201e-06, 2.3528e-06, 6.1777e-07,
        2.1355e-06, 8.4081e-07, 4.2803e-06, 2.7539e-06, 4.3861e-02, 2.2643e-06,
        9.3349e-07, 2.1355e-06, 9.1811e-07, 1.3201e-06, 1.0468e-06, 2.8079e-06,
        2.0606e-06, 1.5402e-06, 6.1610e-07, 2.7031e-06, 6.1780e-07, 2.8011e-06,
        4.3717e-02, 6.3449e-02, 3.2695e-02, 4.0149e-06, 4.7170e-02, 1.7164e-02,
        6.1610e-07, 2.9826e-02, 1.7933e-06, 7.7092e-02, 2.3342e-06, 5.9467e-07,
        5.7751e-02, 5.5961e-02, 6.8179e-02, 1.1973e-06, 2.9349e-06, 2.9349e-06,
        1.6209e-06, 1.0965e-06, 1.8197e-06, 2.9349e-06, 1.0700e-06, 4.2757e-06,
        4.2861e-06, 1.6209e-06, 6.1610e-07, 9.3446e-07, 5.5260e-02, 2.3511e-06,
        6.3095e-02, 1.5437e-06, 4.1957e-06, 4.1749e-06, 1.6209e-06, 1.2110e-06,
        5.5210e-06, 6.1610e-07, 7.7802e-07, 5.7730e-02, 2.3528e-06, 5.1732e-02,
        1.9665e-06, 1.4092e-06, 1.2345e-06, 3.3546e-02, 5.9367e-02, 4.2684e-02,
        1.9823e-06, 2.3342e-06, 4.2761e-06, 4.2803e-06, 4.2752e-06, 9.1811e-07,
        2.1355e-06, 2.6272e-02, 1.8197e-06, 5.9466e-02, 4.1709e-06, 2.0606e-06,
        9.3446e-07, 1.4101e-06, 2.9349e-06, 2.0009e-06, 1.4101e-06, 1.8109e-06,
        3.2556e-02, 7.7802e-07, 5.9228e-02, 4.2761e-06], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([4.2066e-02, 1.6165e-07, 1.0328e-07,  ..., 3.6861e-02, 3.8874e-07,
        1.3906e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([4.7823e-02, 3.8666e-02, 5.3187e-02, 4.0489e-02, 7.7565e-07, 3.9411e-02,
        5.3320e-02, 4.2131e-02, 4.9804e-07, 6.8658e-07, 3.7746e-02, 2.5398e-07,
        5.0088e-02, 1.4807e-06, 3.4149e-07, 4.4105e-07, 7.7793e-07, 4.4148e-02,
        1.1683e-06, 7.0262e-07, 2.2529e-03, 3.4865e-02, 4.0854e-07, 4.4687e-02,
        4.8307e-02, 4.8884e-02, 7.9635e-07, 3.9761e-02, 2.8669e-07, 6.6883e-02,
        4.5524e-07, 1.6557e-06, 5.0047e-02, 5.0683e-07, 4.8664e-02, 6.1242e-07,
        4.3396e-02, 4.1923e-02, 1.4585e-06, 4.1971e-02, 4.3392e-02, 3.3770e-02,
        4.3144e-07, 4.5524e-07, 5.0774e-02, 4.8126e-02, 1.0406e-06, 5.5359e-07,
        3.7144e-02, 6.9045e-07, 4.4995e-02, 5.8343e-07, 4.9306e-02, 4.5176e-07,
        4.8208e-02, 1.4571e-06, 2.1745e-06, 4.8937e-07, 4.8211e-02, 6.3470e-07,
        2.2015e-06, 2.5398e-07, 5.0795e-02, 5.0006e-02, 4.4105e-07, 2.1971e-06,
        5.4960e-02, 4.9567e-02, 5.1425e-02, 7.2148e-07, 1.0791e-06, 5.6696e-07,
        7.6411e-07, 4.3039e-02, 4.5212e-02, 5.0214e-02, 4.1556e-02, 1.0578e-01,
        4.0330e-02, 2.2429e-06, 4.1822e-02, 4.8196e-02, 5.2477e-02, 3.8286e-02,
        4.5924e-02, 4.8207e-02, 1.1683e-06, 5.7794e-02, 7.7793e-07, 4.6386e-07,
        8.8934e-07, 8.0690e-07, 4.9855e-02, 1.0709e-06, 7.0262e-07, 5.3528e-02,
        2.8669e-07, 7.7793e-07, 7.0262e-07, 4.6043e-07, 1.0709e-06, 1.4608e-06,
        4.0854e-07, 4.3569e-02, 5.7010e-02, 4.9962e-02, 2.4320e-07, 5.6517e-07,
        8.7459e-07, 4.8021e-02, 6.1242e-07, 4.8255e-02, 3.8611e-02, 6.3470e-07,
        4.4228e-02, 1.9727e-06, 1.4650e-06, 4.9764e-02, 5.0036e-02, 5.9768e-07,
        5.0339e-02, 1.9836e-06, 7.4803e-07, 5.0650e-02, 4.4879e-02, 6.4364e-07,
        4.3144e-07, 4.6759e-02, 4.4247e-02, 4.6406e-02, 4.8604e-02, 5.1815e-02,
        5.0438e-02, 1.0406e-06, 5.9291e-02, 7.0277e-07, 3.1697e-07, 4.7693e-02,
        4.8999e-02, 9.3556e-07, 4.6787e-07, 4.0141e-02, 4.5511e-02, 5.1712e-02,
        4.2958e-02, 5.5119e-02, 4.8410e-02, 4.8797e-02, 4.3147e-02, 4.9231e-02,
        4.8596e-02, 7.6411e-07, 4.7203e-02, 1.1191e-06, 7.0262e-07, 4.7715e-02,
        5.0323e-02, 5.1578e-02, 4.3180e-02, 4.6386e-07, 4.4593e-02, 4.7659e-02,
        3.0572e-02, 7.7565e-07, 4.8937e-07, 1.1233e-06, 1.0406e-06, 8.1943e-07,
        5.2886e-02, 4.6744e-02, 4.3767e-02, 5.1687e-02, 4.1893e-02, 3.7485e-02,
        4.0859e-02, 1.7270e-06, 6.1242e-07, 2.2382e-06, 5.4146e-02, 3.1756e-07,
        4.2227e-02, 8.0690e-07, 4.4949e-02, 3.8291e-02, 4.3378e-02, 5.1969e-02,
        4.0735e-02, 4.4788e-02, 4.0235e-02, 4.9634e-02, 8.8594e-07, 5.1554e-02,
        2.2015e-06, 4.9000e-02, 4.3281e-02, 4.4290e-02, 4.3144e-07, 4.5806e-02,
        5.4203e-02, 4.3431e-02, 4.8489e-02, 1.0746e-06, 5.3274e-02, 4.4271e-02,
        4.2422e-02, 4.3780e-07, 8.9780e-07, 4.0163e-02, 7.1691e-07, 5.4183e-02,
        1.0564e-06, 1.6904e-06, 5.3018e-02, 4.1881e-02, 1.4650e-06, 3.0738e-07,
        4.5350e-02, 4.5561e-07, 3.7449e-07, 4.6923e-02, 4.7379e-02, 6.4364e-07,
        4.1253e-02, 4.4781e-02, 4.1903e-02, 4.5733e-02, 2.0568e-06, 2.9039e-06,
        8.0690e-07, 4.6386e-07, 1.9043e-06, 1.0549e-06, 4.7030e-02, 4.2741e-02,
        5.2662e-02, 4.9327e-02, 4.3300e-02, 4.7713e-07, 4.0800e-02, 4.9095e-02,
        1.0406e-06, 5.0683e-07, 8.0690e-07, 2.8669e-07, 4.4723e-02, 6.1242e-07,
        5.2708e-02, 4.1965e-02, 4.3979e-02, 8.4891e-07, 4.5362e-02, 4.8129e-02,
        4.6715e-02, 4.6386e-07, 4.6261e-02, 5.6517e-07], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([3.9680e-06, 4.4498e-02, 1.1913e-06, 4.8755e-06, 3.3326e-02, 3.2098e-06,
        3.2211e-02, 3.7002e-02, 3.1766e-06, 2.8359e-02, 3.3812e-02, 3.4818e-06,
        8.4867e-02, 4.1303e-06, 7.2972e-07, 3.1869e-02, 3.1085e-02, 3.1413e-06,
        4.0718e-06, 7.7987e-02, 3.7933e-06, 3.0845e-02, 3.1994e-06, 1.4315e-06,
        2.0497e-06, 2.9359e-02, 6.3514e-06, 6.8587e-02, 7.3432e-06, 8.8700e-02,
        4.1028e-06, 3.2462e-02, 3.2440e-07, 2.6593e-02, 1.0239e-05, 3.1922e-02,
        1.0612e-01, 5.0789e-07, 6.5634e-06, 2.7809e-06, 2.7408e-06, 2.1858e-06,
        2.7283e-06, 2.8239e-02, 1.4444e-06, 6.9846e-02, 2.7949e-06, 5.0564e-06,
        3.2302e-02, 7.5543e-06, 2.9275e-06, 3.3469e-06, 4.8921e-06, 2.7649e-06,
        1.7425e-07, 1.0445e-01, 3.8963e-02, 4.6491e-02, 2.0497e-06, 1.1803e-06,
        8.4332e-02, 3.3218e-02, 1.1913e-06, 2.7649e-06, 1.0526e-06, 3.2810e-06,
        3.3181e-02, 4.2933e-06, 3.0145e-02, 1.1041e-05, 3.0463e-02, 3.1994e-06,
        3.1994e-06, 3.4893e-02, 8.0904e-02, 5.2042e-06, 2.5396e-06, 6.6261e-06,
        4.5357e-06, 2.9253e-02, 3.4955e-02, 3.7524e-06, 4.5357e-06, 1.0311e-01,
        7.7196e-02, 7.0643e-02, 3.3867e-02, 1.7585e-06, 3.5909e-06, 4.8110e-06,
        4.3605e-06, 3.2591e-02, 4.8755e-06, 1.7192e-06, 7.1192e-02, 6.7099e-06,
        3.7188e-02, 6.7099e-06, 3.3524e-02, 3.6744e-02, 3.2732e-02, 4.0372e-02,
        8.5728e-07, 2.0109e-06, 3.3736e-06, 7.4574e-02, 3.2401e-02, 8.3321e-02,
        3.9020e-02, 3.1036e-02, 2.8341e-02, 6.6261e-06, 2.3430e-06, 1.1041e-01,
        5.6302e-06, 1.0201e-06, 7.9372e-06, 2.0497e-06, 3.2946e-06, 5.2581e-06,
        3.0725e-02, 6.3514e-06, 2.8513e-06, 2.8665e-06, 5.9926e-06, 1.7585e-06,
        4.8271e-06, 3.5873e-06, 2.3619e-06, 6.0771e-06, 3.1553e-02, 2.1497e-06,
        1.7142e-06, 3.9680e-06, 6.0364e-06, 4.3605e-06, 2.0497e-06, 4.9279e-06,
        5.0245e-06, 2.6282e-06, 7.7695e-06, 5.7367e-02, 3.7157e-06, 3.1451e-02,
        3.6207e-02, 2.4969e-06, 8.4650e-02, 3.4139e-06, 1.4777e-06, 1.5732e-06,
        7.4887e-02, 2.6857e-02, 8.2066e-02, 6.9777e-06, 7.2453e-02, 3.1078e-06,
        3.0668e-02, 3.1766e-06, 6.3514e-06, 4.5620e-02, 8.8115e-02, 3.9327e-06,
        7.0897e-02, 9.7269e-02, 3.3186e-02, 1.7920e-06, 7.6335e-02, 3.6954e-06,
        3.2132e-06, 4.1872e-06, 1.3161e-06, 3.2810e-06, 3.2810e-06, 3.4934e-06,
        2.9848e-06, 4.8110e-06, 7.3071e-02, 2.4163e-06, 3.5300e-02, 3.8448e-06,
        1.1325e-05, 3.4439e-02, 1.8695e-06, 9.0543e-02, 6.8460e-02, 2.1119e-06,
        8.1969e-06, 2.7057e-06, 3.1427e-02, 2.5035e-06, 6.3100e-07, 3.4818e-06,
        4.9603e-02, 3.1302e-06, 7.1345e-02, 2.1168e-06, 2.8641e-02, 3.2196e-02,
        3.6331e-02, 2.9507e-06, 2.2061e-06, 1.6396e-06, 2.9507e-06, 1.7070e-06,
        1.6396e-06, 3.2792e-06, 3.4755e-06, 6.5038e-06, 9.8579e-07, 2.6346e-02,
        5.0200e-06, 3.2953e-02, 2.7809e-06, 2.7408e-06, 2.0497e-06, 2.8903e-02,
        3.2373e-06, 2.7809e-06, 5.0495e-02, 5.1793e-06, 1.6407e-06, 3.0488e-02,
        8.5968e-02, 7.2255e-02, 6.6277e-02, 4.4360e-06, 3.3818e-02, 1.9875e-06,
        8.5507e-06, 5.0369e-06, 1.7585e-06, 3.3041e-02, 8.6749e-02, 2.0497e-06,
        3.5255e-06, 3.0769e-06, 3.6721e-02, 7.5906e-06, 2.1994e-06, 3.4823e-06,
        2.2710e-06, 3.7933e-06, 3.2090e-02, 7.6253e-02, 4.3189e-06, 4.2397e-02,
        4.0193e-06, 8.9455e-06, 7.9714e-02, 4.2251e-06, 8.9457e-07, 4.0315e-02,
        2.1168e-06, 2.9296e-06, 3.1174e-02, 3.1994e-06], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([6.3104e-02, 1.6235e-07, 6.7502e-08,  ..., 5.5812e-02, 3.8756e-07,
        4.4228e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([5.3278e-07, 7.2539e-07, 5.0754e-02, 8.6152e-02, 4.3861e-07, 2.2097e-06,
        8.7471e-02, 1.0172e-06, 1.4431e-06, 8.0625e-07, 2.1808e-06, 5.3278e-07,
        2.7098e-02, 8.8409e-07, 7.5022e-07, 9.8247e-02, 3.5402e-06, 5.2533e-07,
        1.3804e-06, 2.1926e-06, 2.7402e-06, 1.1015e-01, 1.2657e-06, 9.6155e-07,
        1.4542e-06, 8.1679e-07, 2.7402e-06, 1.2574e-06, 1.0959e-06, 1.9623e-06,
        7.5034e-02, 6.0467e-07, 1.5919e-06, 1.4721e-06, 9.9771e-07, 5.1116e-07,
        1.0796e-01, 2.2433e-06, 2.2765e-02, 1.2555e-06, 1.0657e-01, 4.8110e-06,
        1.3804e-06, 1.4022e-01, 1.3272e-06, 5.7547e-07, 8.0625e-07, 7.0083e-07,
        2.4554e-06, 2.2115e-06, 2.7328e-07, 8.5255e-07, 5.7503e-07, 6.6406e-07,
        1.9491e-06, 2.1808e-06, 4.0352e-03, 1.8804e-06, 8.8409e-07, 9.6258e-07,
        1.4542e-06, 2.4554e-06, 1.1332e-01, 1.0104e-06, 2.0611e-06, 9.7707e-02,
        1.2118e-06, 1.2253e-06, 1.6539e-06, 1.3804e-06, 1.0113e-01, 2.6891e-02,
        1.3216e-06, 1.2881e-01, 2.7402e-06, 4.2815e-07, 1.0228e-01, 2.3477e-06,
        1.0455e-01, 9.1110e-02, 7.1109e-07, 1.1400e-01, 1.1885e-06, 1.5537e-01,
        2.1145e-06, 3.4414e-06, 8.0625e-07, 4.3498e-07, 9.5221e-02, 9.5336e-02,
        1.2252e-06, 1.0709e-06, 3.4110e-06, 2.4423e-06, 1.3000e-01, 7.4502e-02,
        1.0077e-01, 2.4590e-02, 8.3814e-07, 1.6966e-06, 9.6079e-02, 1.9708e-06,
        9.5850e-07, 7.4149e-07, 9.1299e-02, 1.2715e-06, 1.2723e-06, 1.5017e-06,
        1.0314e-01, 3.0758e-06, 1.7425e-06, 1.2574e-06, 9.5767e-02, 4.5430e-07,
        5.7661e-07, 1.9591e-06, 8.1782e-07, 8.6247e-02, 9.0324e-02, 2.5695e-06,
        2.7204e-06, 1.1169e-01, 9.4232e-07, 8.2491e-07, 1.0639e-06, 8.7814e-07,
        1.0096e-01, 8.1518e-02, 1.7864e-06, 7.3672e-02, 6.7781e-07, 1.6496e-06,
        4.0762e-07, 1.4321e-01, 6.8889e-02, 9.9640e-02, 1.0104e-06, 1.1644e-06,
        9.0116e-07, 2.1528e-06, 8.0625e-07, 7.2881e-07, 2.0582e-06, 1.9560e-06,
        1.2248e-01, 1.7425e-06, 1.2723e-06, 7.8460e-02, 9.2809e-02, 2.3776e-07,
        1.0104e-06, 9.0505e-02, 1.8227e-06, 6.0463e-07, 1.1706e-06, 1.2723e-06,
        1.0940e-01, 1.3910e-06, 1.0042e-01, 8.1679e-07, 1.1645e-01, 2.1379e-06,
        9.7783e-07, 2.6649e-06, 2.8195e-02, 1.4148e-06, 7.2881e-07, 1.6354e-06,
        1.3439e-06, 1.8274e-06, 2.8143e-06, 2.0364e-06, 9.4173e-02, 2.7368e-06,
        5.6839e-07, 7.0169e-07, 2.8015e-06, 2.4188e-06, 7.1109e-07, 1.0104e-06,
        9.3509e-02, 4.3861e-07, 6.7573e-07, 9.4232e-07, 1.0639e-06, 1.6729e-06,
        2.4483e-06, 7.2881e-07, 7.7786e-02, 9.7006e-02, 2.5505e-02, 1.2269e-06,
        3.8885e-06, 9.3283e-07, 7.1063e-02, 1.0104e-06, 8.1679e-07, 1.0487e-06,
        9.3283e-07, 9.5482e-02, 8.0371e-07, 8.9946e-07, 8.0244e-07, 4.3051e-07,
        7.1109e-07, 4.4979e-06, 8.7449e-02, 3.1452e-07, 1.8731e-06, 2.1646e-06,
        3.3326e-06, 1.0206e-01, 4.5430e-07, 1.2139e-06, 9.8964e-07, 2.3788e-06,
        1.1165e-06, 2.3555e-06, 8.4781e-07, 3.4580e-06, 6.5469e-07, 6.7781e-07,
        8.0371e-07, 1.0783e-01, 1.1165e-06, 1.0639e-06, 2.7122e-06, 1.5608e-06,
        9.2504e-07, 8.0371e-07, 9.2504e-07, 8.8409e-07, 9.3283e-07, 3.1220e-06,
        8.7638e-02, 8.8409e-07, 2.1921e-06, 1.4509e-06, 1.0487e-06, 1.6700e-06,
        2.1723e-06, 3.1452e-07, 2.5034e-06, 9.3599e-02, 3.8627e-06, 2.7402e-06,
        8.8409e-07, 1.2866e-06, 1.0639e-06, 2.2961e-02, 1.0418e-06, 1.8622e-06,
        1.4689e-06, 7.8378e-02, 8.5660e-02, 1.4977e-01], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([2.9987e-06, 6.7265e-06, 9.8805e-06, 2.2932e-06, 1.0049e-06, 6.4050e-02,
        4.3920e-06, 6.6357e-06, 2.9535e-06, 3.8411e-02, 5.9587e-06, 7.8458e-06,
        3.7493e-06, 7.5332e-06, 8.1303e-06, 4.4001e-06, 3.5617e-06, 6.7097e-02,
        6.7513e-06, 2.3854e-06, 2.8458e-06, 1.4135e-06, 3.4233e-06, 1.4235e-06,
        3.6310e-06, 9.7621e-07, 1.8536e-06, 6.4644e-02, 6.6274e-02, 3.6386e-06,
        5.9677e-06, 1.6439e-06, 5.3518e-06, 8.4479e-06, 5.1144e-06, 5.0383e-06,
        2.9191e-06, 6.5519e-06, 7.3054e-06, 1.8140e-06, 1.5344e-06, 3.4939e-06,
        5.4515e-02, 6.8555e-06, 2.9591e-06, 5.1033e-06, 3.9975e-06, 3.1428e-06,
        3.6934e-06, 9.6046e-06, 6.7748e-02, 1.3790e-05, 9.5335e-06, 3.6577e-06,
        3.3007e-06, 3.2474e-06, 5.6254e-06, 2.2674e-06, 3.5371e-02, 3.0709e-06,
        5.7092e-02, 4.5081e-06, 2.3214e-06, 5.6146e-06, 7.6341e-06, 2.7601e-06,
        4.4698e-06, 6.8232e-02, 6.5519e-06, 2.5312e-06, 4.0225e-06, 4.1565e-06,
        8.1827e-06, 6.6890e-06, 2.9987e-06, 6.7197e-06, 4.5742e-06, 8.6318e-02,
        2.9987e-06, 5.4985e-06, 4.0807e-06, 4.6540e-02, 1.6862e-06, 5.8179e-02,
        1.9100e-06, 3.2370e-06, 6.2821e-02, 2.9666e-06, 6.5588e-02, 2.7579e-06,
        5.2527e-06, 3.4566e-06, 8.1303e-06, 3.6324e-02, 1.4537e-06, 2.1685e-06,
        7.4770e-06, 7.0200e-06, 3.1670e-06, 5.6230e-06, 4.1446e-06, 4.3079e-06,
        4.1478e-06, 5.2993e-06, 6.8614e-02, 2.5192e-06, 6.5614e-02, 2.9317e-06,
        3.1737e-06, 6.2701e-06, 2.1604e-06, 1.8767e-06, 4.3207e-06, 1.9411e-06,
        2.8428e-06, 5.6637e-06, 2.5911e-06, 8.6353e-04, 1.8949e-06, 1.4699e-02,
        6.5121e-02, 3.2289e-06, 2.6735e-06, 8.9035e-06, 4.1727e-06, 6.5757e-06,
        4.8185e-06, 1.7842e-06, 4.4446e-06, 2.7601e-06, 2.3128e-06, 1.1530e-05,
        2.0954e-06, 2.8636e-06, 1.2189e-06, 5.4614e-06, 5.8510e-06, 2.9615e-06,
        6.5519e-06, 5.2993e-06, 5.3518e-06, 2.9865e-02, 7.4576e-02, 3.6934e-06,
        2.7601e-06, 2.8160e-06, 1.8339e-06, 2.9121e-06, 8.4479e-06, 6.5519e-06,
        3.1663e-06, 3.6851e-06, 6.0549e-06, 4.3756e-06, 6.0313e-02, 2.5136e-06,
        8.8462e-02, 5.4070e-06, 3.9813e-06, 2.5312e-06, 9.6057e-06, 3.3931e-06,
        3.0830e-06, 3.7385e-06, 7.1935e-06, 6.3923e-06, 5.2776e-06, 1.9920e-06,
        3.1663e-06, 3.8835e-02, 2.9152e-06, 2.3214e-06, 7.0636e-02, 2.9151e-06,
        1.9565e-06, 7.5104e-02, 5.4454e-06, 1.5597e-06, 1.5435e-06, 4.0482e-06,
        9.2635e-06, 3.6590e-06, 1.0302e-06, 2.0607e-06, 2.5136e-06, 3.0046e-06,
        5.0746e-06, 4.4001e-06, 3.3542e-06, 5.1678e-06, 1.9532e-06, 7.3413e-06,
        4.8185e-06, 6.8363e-06, 2.7601e-06, 8.0987e-02, 9.0314e-02, 3.5659e-06,
        9.7621e-07, 8.5585e-06, 3.0506e-06, 1.8536e-06, 9.7621e-07, 9.7621e-07,
        7.1154e-02, 4.4001e-06, 4.3980e-06, 2.6643e-06, 4.7548e-06, 5.3989e-06,
        5.5009e-06, 5.3518e-06, 9.7621e-07, 5.6146e-06, 3.6386e-06, 7.0200e-06,
        1.3187e-06, 7.7519e-02, 6.7197e-06, 3.2289e-06, 3.2631e-06, 3.2669e-06,
        7.9667e-06, 3.6934e-06, 5.4454e-06, 4.3726e-06, 5.5426e-06, 3.6559e-06,
        1.8114e-06, 1.1370e-05, 1.5597e-06, 6.1833e-02, 3.6310e-06, 6.3176e-02,
        2.1089e-06, 3.5957e-06, 3.4082e-06, 6.6397e-02, 4.4001e-06, 5.0768e-06,
        5.4454e-06, 6.6511e-02, 2.9008e-06, 2.7241e-06, 6.3986e-02, 2.7489e-06,
        5.2993e-06, 2.7601e-06, 5.5050e-06, 6.5519e-06, 6.7795e-06, 3.0709e-06,
        6.0784e-02, 7.0702e-02, 5.8554e-06, 7.1832e-02], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([4.7718e-07, 1.3364e-07, 2.1829e-07,  ..., 1.5898e-07, 2.2760e-07,
        6.4038e-02], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([2.7360e-06, 1.0184e-06, 5.6788e-07, 1.1900e-06, 2.4104e-07, 2.0414e-06,
        1.6109e-06, 2.4080e-06, 1.1105e-06, 2.2230e-06, 1.4402e-06, 4.4949e-07,
        1.0295e-06, 5.3101e-07, 1.3946e-06, 3.1758e-06, 8.0559e-07, 1.0009e-06,
        6.8778e-07, 3.1497e-06, 2.4080e-06, 1.2044e-06, 6.6246e-07, 4.1027e-06,
        7.1036e-07, 1.8867e-06, 3.1748e-06, 8.6867e-07, 5.9368e-07, 1.4765e-06,
        6.1723e-07, 1.7813e-06, 7.1664e-07, 9.5916e-07, 1.1582e-06, 1.8619e-06,
        1.5938e-06, 1.2044e-06, 8.9673e-07, 3.0357e-06, 1.7269e-06, 7.1664e-07,
        2.0414e-06, 8.9673e-07, 3.1747e-06, 4.1598e-07, 4.3855e-08, 9.7570e-07,
        1.9754e-06, 1.8432e-06, 2.9231e-06, 2.1612e-06, 1.3349e-06, 1.4330e-06,
        9.7027e-07, 2.7360e-06, 7.4986e-07, 4.9171e-07, 1.1293e-06, 1.1892e-06,
        1.6592e-06, 8.0558e-07, 2.1862e-06, 2.7360e-06, 1.2281e-06, 1.5753e-06,
        1.3268e-06, 1.8375e-06, 2.3009e-06, 1.1455e-06, 6.3584e-07, 1.1145e-06,
        1.1455e-06, 6.9783e-07, 5.0508e-07, 1.4985e-06, 1.3107e-06, 1.2044e-06,
        1.2044e-06, 4.1024e-06, 7.5830e-07, 2.2714e-06, 1.4557e-06, 4.0992e-07,
        1.1908e-06, 1.2114e-06, 1.8032e-06, 1.3440e-06, 1.0796e-06, 2.4080e-06,
        1.1105e-06, 8.7715e-07, 6.8963e-07, 1.6859e-06, 9.2169e-07, 1.2877e-06,
        1.8869e-06, 6.2329e-07, 3.2065e-07, 1.2044e-06, 2.4080e-06, 2.1612e-06,
        1.7269e-06, 2.4080e-06, 1.4503e-06, 7.5830e-07, 2.8443e-06, 6.1430e-07,
        5.3101e-07, 1.3624e-06, 5.4224e-07, 2.2062e-06, 1.1105e-06, 2.0414e-06,
        5.6481e-07, 1.0129e-06, 1.0183e-06, 2.4080e-06, 2.0810e-06, 1.5753e-06,
        5.4224e-07, 8.4461e-07, 4.2349e-07, 9.9930e-07, 6.2329e-07, 2.8277e-06,
        1.2281e-06, 1.1105e-06, 2.4080e-06, 1.3785e-06, 1.8303e-06, 2.0414e-06,
        1.0796e-06, 1.4402e-06, 1.4591e-06, 1.2114e-06, 1.8303e-06, 7.0561e-07,
        2.4080e-06, 1.0001e-06, 1.4534e-06, 2.7360e-06, 1.4807e-06, 1.4412e-06,
        1.5504e-06, 8.6557e-07, 9.7570e-07, 6.8963e-07, 1.3624e-06, 1.4224e-06,
        1.0001e-06, 1.3440e-06, 1.1859e-06, 5.9565e-07, 1.9754e-06, 1.0701e-06,
        7.7397e-07, 1.1024e-06, 2.0363e-06, 1.7269e-06, 7.8035e-07, 2.9399e-06,
        2.9798e-07, 1.0701e-06, 1.1105e-06, 6.2457e-07, 2.1612e-06, 6.2329e-07,
        4.1598e-07, 1.7269e-06, 7.8254e-07, 1.7269e-06, 1.2044e-06, 2.0280e-06,
        2.9399e-06, 2.7492e-06, 1.4262e-06, 2.4080e-06, 8.9672e-07, 3.8312e-08,
        4.2349e-07, 4.2349e-07, 1.8619e-06, 2.0414e-06, 1.2405e-06, 2.8443e-06,
        1.7611e-06, 1.7760e-06, 2.9399e-06, 7.5528e-07, 1.7205e-06, 4.5306e-07,
        6.8963e-07, 1.4985e-06, 1.1105e-06, 1.1892e-06, 7.5830e-07, 4.5328e-07,
        1.5958e-06, 2.9231e-06, 9.7987e-07, 1.5747e-06, 2.4080e-06, 1.0127e-06,
        3.2065e-07, 1.0903e-06, 5.3101e-07, 9.6340e-07, 6.8778e-07, 1.4741e-06,
        7.8254e-07, 7.1664e-07, 1.1293e-06, 6.8778e-07, 7.1664e-07, 1.0295e-06,
        2.9231e-06, 1.7269e-06, 1.8432e-06, 3.1749e-06, 1.1145e-06, 4.9171e-07,
        1.7269e-06, 6.3584e-07, 5.7737e-07, 4.9171e-07, 1.2044e-06, 4.2349e-07,
        1.3361e-06, 3.6300e-07, 2.9399e-06, 1.4985e-06, 6.8778e-07, 6.2003e-07,
        2.4080e-06, 1.8619e-06, 4.2349e-07, 1.1160e-06, 2.1991e-06, 1.2114e-06,
        1.2044e-06, 2.4080e-06, 1.1105e-06, 1.1509e-06, 1.0184e-06, 1.8432e-06,
        1.1859e-06, 2.3543e-06, 8.6867e-07, 1.4063e-06, 1.4591e-06, 1.0532e-06,
        1.0796e-06, 1.4591e-06, 2.4080e-06, 1.1293e-06], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([3.0929e-06, 3.2618e-06, 2.4660e-06, 2.1163e-06, 1.8531e-06, 2.0378e-06,
        2.1102e-07, 6.3643e-06, 3.3740e-06, 2.7239e-06, 3.2536e-06, 2.3479e-06,
        4.0388e-06, 1.6805e-06, 2.9334e-06, 2.2826e-06, 5.0075e-06, 1.5292e-06,
        5.9653e-06, 9.1498e-07, 3.5336e-06, 2.1083e-06, 6.5872e-06, 6.5239e-06,
        1.6805e-06, 1.4694e-06, 1.2629e-06, 1.3215e-06, 2.9660e-06, 1.8531e-06,
        4.2936e-06, 3.4928e-06, 5.8481e-06, 5.0270e-06, 1.0179e-05, 2.5889e-06,
        1.6805e-06, 5.7113e-06, 2.7248e-06, 1.6971e-06, 3.2063e-06, 4.9663e-06,
        5.4170e-06, 5.5783e-06, 6.3148e-06, 4.2678e-06, 2.1451e-06, 9.9651e-07,
        3.2887e-06, 1.8836e-06, 3.1810e-06, 3.8425e-06, 2.0816e-06, 4.0388e-06,
        1.6805e-06, 3.9274e-06, 3.2517e-06, 1.6383e-06, 3.1673e-06, 3.2618e-06,
        3.0237e-06, 5.4170e-06, 4.4995e-06, 2.1858e-06, 6.3643e-06, 5.1590e-06,
        5.8896e-06, 8.5252e-06, 2.9334e-06, 2.1729e-06, 2.6991e-06, 4.0361e-06,
        5.4170e-06, 4.1061e-06, 1.8582e-06, 2.0378e-06, 6.3148e-06, 1.8711e-06,
        2.9415e-06, 1.5728e-06, 1.9285e-06, 2.3293e-06, 1.9642e-06, 1.8836e-06,
        1.3939e-06, 4.1062e-06, 6.2221e-06, 1.3215e-06, 2.2512e-06, 3.0918e-06,
        2.6012e-06, 3.2944e-07, 2.3146e-07, 2.9729e-06, 2.2282e-06, 5.6154e-06,
        3.9274e-06, 3.2618e-06, 5.0584e-06, 2.4660e-06, 2.1729e-06, 1.3082e-06,
        2.8250e-06, 4.0790e-06, 1.7493e-07, 2.1370e-06, 1.7202e-06, 2.7648e-06,
        5.4170e-06, 4.3350e-06, 1.1218e-06, 8.7821e-06, 3.9112e-06, 5.6154e-06,
        6.1756e-06, 5.1623e-06, 3.6067e-06, 4.2829e-06, 2.6521e-06, 8.5241e-06,
        3.1578e-06, 5.1623e-06, 1.5728e-06, 1.8531e-06, 1.7491e-07, 4.9663e-06,
        2.6521e-06, 6.3148e-06, 3.7657e-06, 1.2350e-06, 4.4575e-06, 3.2962e-06,
        4.9663e-06, 4.4293e-06, 3.3272e-06, 2.0378e-06, 4.9663e-06, 2.7495e-06,
        4.3024e-06, 3.7176e-06, 5.6616e-06, 3.1673e-06, 5.6154e-06, 3.7522e-06,
        3.9112e-06, 2.7836e-06, 6.8933e-06, 5.5783e-06, 3.9504e-06, 2.4660e-06,
        5.7610e-06, 3.4703e-06, 4.1062e-06, 4.7041e-06, 1.7493e-07, 2.1102e-07,
        3.2600e-06, 5.8875e-06, 1.3215e-06, 2.4660e-06, 2.5436e-06, 3.6036e-06,
        3.3811e-06, 2.1540e-06, 2.0378e-06, 6.5872e-06, 5.8413e-06, 6.7090e-06,
        2.9718e-06, 2.0378e-06, 6.0413e-06, 2.3293e-06, 3.7657e-06, 1.8531e-06,
        1.7160e-06, 5.6154e-06, 9.0195e-06, 5.6616e-06, 3.6156e-06, 6.2502e-06,
        2.4660e-06, 4.0361e-06, 4.0669e-06, 6.1756e-06, 1.0184e-05, 5.4170e-06,
        2.4660e-06, 5.6154e-06, 2.4660e-06, 1.7494e-07, 2.0221e-06, 3.2943e-07,
        6.3148e-06, 2.0378e-06, 2.3293e-06, 4.7041e-06, 6.3148e-06, 3.2618e-06,
        2.6012e-06, 1.6805e-06, 2.3293e-06, 6.5239e-06, 2.0378e-06, 1.8836e-06,
        2.1729e-06, 1.8836e-06, 8.4606e-06, 5.6716e-07, 1.9285e-06, 2.1729e-06,
        1.7135e-06, 2.4660e-06, 3.8757e-06, 2.9621e-06, 2.0110e-06, 1.6727e-06,
        5.4170e-06, 4.2936e-06, 1.8836e-06, 1.6935e-06, 3.6100e-06, 7.1256e-06,
        2.3293e-06, 7.2538e-07, 1.9642e-06, 3.1578e-06, 2.9664e-06, 3.0541e-06,
        2.3293e-06, 4.3351e-06, 5.0075e-06, 3.1803e-06, 1.2586e-06, 1.7092e-06,
        3.9491e-06, 3.2767e-06, 3.1810e-06, 7.3485e-06, 3.4466e-06, 3.2618e-06,
        1.0466e-06, 1.8966e-06, 2.9334e-06, 3.4850e-06, 6.5872e-06, 3.6540e-06,
        2.4660e-06, 5.3079e-06, 2.5083e-06, 7.5446e-06, 1.7491e-07, 1.3897e-06,
        4.3024e-06, 3.1578e-06, 3.2962e-06, 3.9112e-06], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([1.4324e-07, 2.0413e-07, 1.3185e-07,  ..., 1.2632e-07, 1.2525e-07,
        2.4345e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([3.2138e-07, 1.0527e-06, 9.1682e-07, 1.0121e-06, 5.4276e-07, 6.7338e-07,
        2.3855e-06, 1.6732e-06, 1.2587e-06, 1.3635e-06, 8.4029e-07, 2.5473e-06,
        8.3213e-07, 6.8987e-07, 9.1169e-07, 1.3247e-06, 1.0202e-06, 2.8186e-06,
        4.2565e-07, 7.5266e-07, 9.4229e-07, 1.0353e-06, 1.2064e-07, 3.5602e-07,
        1.1419e-06, 7.5551e-07, 7.9629e-07, 2.1439e-06, 1.8207e-06, 6.0096e-07,
        9.4604e-07, 4.9844e-07, 1.9115e-06, 9.4077e-07, 8.8071e-07, 1.0121e-06,
        1.2282e-06, 2.0555e-06, 8.0122e-07, 2.0355e-07, 1.2064e-07, 8.3214e-07,
        3.5621e-07, 5.4080e-07, 1.2282e-06, 6.4651e-07, 2.5332e-06, 1.5985e-06,
        4.4945e-07, 6.9866e-07, 1.6989e-06, 1.4577e-06, 9.4604e-07, 1.5207e-06,
        3.5621e-07, 1.0121e-06, 6.6040e-07, 1.0121e-06, 1.1099e-06, 8.4537e-07,
        1.8202e-06, 1.8621e-06, 6.0096e-07, 7.2813e-07, 2.0355e-07, 2.6076e-06,
        1.4393e-06, 2.4615e-06, 3.2138e-07, 5.2665e-07, 3.2138e-07, 2.5332e-06,
        7.8476e-07, 1.0503e-06, 4.9844e-07, 2.0555e-06, 2.6471e-06, 3.2749e-07,
        6.9866e-07, 6.3256e-07, 1.5985e-06, 1.5361e-06, 6.0096e-07, 1.3842e-06,
        1.4019e-06, 1.0202e-06, 1.4577e-06, 9.3550e-07, 1.0984e-06, 8.0122e-07,
        4.4945e-07, 1.0121e-06, 1.0121e-06, 1.3842e-06, 1.3842e-06, 5.6630e-07,
        4.6243e-07, 8.3100e-07, 1.8172e-06, 1.5631e-06, 8.6823e-07, 9.8480e-07,
        1.0121e-06, 2.5332e-06, 1.0920e-06, 1.1310e-06, 9.3550e-07, 2.5332e-06,
        8.3214e-07, 1.0353e-06, 5.0350e-07, 7.3733e-07, 4.3342e-07, 8.0122e-07,
        8.0122e-07, 8.3213e-07, 4.9844e-07, 1.0301e-06, 1.0318e-06, 7.0113e-07,
        1.1210e-06, 9.3550e-07, 8.0122e-07, 8.4148e-07, 4.9844e-07, 7.8909e-07,
        8.3213e-07, 1.1655e-06, 6.0096e-07, 1.3023e-06, 1.3023e-06, 1.0149e-06,
        1.2808e-06, 1.1310e-06, 2.0555e-06, 2.1026e-07, 6.1315e-07, 2.0555e-06,
        1.1210e-06, 7.5266e-07, 9.4604e-07, 7.5266e-07, 4.4945e-07, 1.3842e-06,
        9.8480e-07, 7.8909e-07, 1.0353e-06, 8.4537e-07, 6.6040e-07, 7.3733e-07,
        1.0121e-06, 4.2720e-07, 2.0769e-06, 1.0529e-06, 1.0121e-06, 9.1518e-07,
        6.1315e-07, 6.0443e-07, 1.0725e-06, 1.3118e-07, 1.3023e-06, 8.3099e-07,
        1.2048e-06, 8.3213e-07, 9.9856e-07, 5.4080e-07, 7.8476e-07, 2.8601e-07,
        2.1423e-06, 6.9214e-07, 3.1005e-06, 1.5715e-06, 1.3842e-06, 1.0121e-06,
        1.9115e-06, 5.2665e-07, 1.5292e-06, 3.9531e-07, 2.5485e-06, 1.2688e-06,
        7.8476e-07, 2.5332e-06, 1.5207e-06, 3.2138e-07, 1.2808e-06, 3.6458e-07,
        8.7143e-07, 1.0878e-06, 6.0096e-07, 2.4615e-06, 4.2720e-07, 5.0278e-07,
        6.9866e-07, 1.2048e-06, 1.3023e-06, 3.2921e-07, 9.1169e-07, 1.0527e-06,
        1.3842e-06, 6.9866e-07, 5.6115e-07, 1.1210e-06, 2.0555e-06, 6.9914e-07,
        9.4077e-07, 6.2312e-07, 1.1642e-06, 2.0769e-06, 8.0122e-07, 5.7000e-07,
        7.1900e-07, 1.1210e-06, 1.1210e-06, 1.7385e-06, 1.0680e-06, 7.5207e-07,
        1.3001e-06, 1.0353e-06, 1.1655e-06, 6.7338e-07, 3.2798e-07, 2.7008e-06,
        7.8909e-07, 1.3842e-06, 7.8909e-07, 5.4080e-07, 6.9914e-07, 9.1169e-07,
        5.4080e-07, 1.2048e-06, 9.4077e-07, 1.0151e-06, 7.8476e-07, 1.0920e-06,
        9.5872e-07, 1.0878e-06, 9.4604e-07, 4.4945e-07, 1.0301e-06, 1.8691e-06,
        1.0725e-06, 1.3023e-06, 1.0274e-06, 2.0555e-06, 8.6823e-07, 9.1681e-07,
        1.2282e-06, 1.0151e-06, 5.6630e-07, 2.3559e-06, 1.7794e-06, 1.8202e-06,
        1.2604e-06, 6.9866e-07, 2.0769e-06, 2.4615e-06], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([1.1630e-06, 3.4216e-06, 5.4024e-06, 8.2809e-06, 4.2477e-06, 3.7666e-06,
        5.2516e-06, 6.6830e-06, 1.9506e-06, 4.2399e-06, 3.0592e-06, 3.3764e-06,
        3.2680e-06, 3.9756e-06, 1.6809e-06, 4.6187e-06, 4.1384e-06, 2.0741e-06,
        1.7793e-06, 2.9229e-06, 1.1630e-06, 4.5690e-06, 4.3676e-06, 1.0818e-06,
        7.8319e-06, 9.0422e-06, 1.7238e-06, 2.7990e-06, 1.8224e-06, 2.7278e-06,
        4.3676e-06, 4.1410e-06, 1.0964e-06, 5.4837e-06, 6.7647e-06, 2.4377e-06,
        3.7506e-06, 5.6751e-06, 1.1280e-06, 3.7974e-06, 4.2583e-06, 5.5026e-06,
        3.1305e-06, 5.5494e-06, 5.7299e-06, 1.7034e-06, 2.6969e-06, 2.1215e-06,
        2.1368e-06, 6.0966e-06, 1.0964e-06, 4.1021e-06, 4.1644e-06, 2.1368e-06,
        3.6756e-06, 3.7379e-06, 2.7828e-06, 1.6423e-06, 4.2583e-06, 5.0903e-06,
        5.4583e-06, 4.0009e-06, 2.1536e-06, 7.2243e-06, 2.2017e-06, 4.2376e-06,
        5.5553e-06, 2.1215e-06, 2.6230e-06, 1.1630e-06, 4.1016e-07, 3.7863e-06,
        3.8753e-06, 1.0818e-06, 3.4216e-06, 2.1039e-06, 4.0329e-06, 5.5026e-06,
        3.8951e-06, 5.0314e-06, 2.7793e-06, 2.0480e-06, 4.0214e-06, 3.3487e-06,
        1.9380e-06, 2.8578e-06, 9.8841e-07, 2.0741e-06, 1.6105e-06, 1.0378e-06,
        2.4429e-06, 2.8167e-06, 1.9484e-06, 4.2376e-06, 2.4012e-06, 1.4016e-06,
        3.2237e-06, 4.2376e-06, 1.5126e-06, 3.5105e-06, 7.8319e-06, 2.7644e-06,
        1.6356e-06, 1.4626e-06, 1.9521e-06, 4.9115e-06, 1.7426e-06, 2.8325e-06,
        3.2680e-06, 6.1276e-06, 4.5442e-06, 2.6338e-06, 2.1368e-06, 3.7980e-06,
        3.4255e-06, 4.1429e-06, 2.2802e-06, 4.2583e-06, 1.9506e-06, 3.9882e-06,
        7.0399e-06, 3.8127e-06, 5.4222e-06, 2.7644e-06, 4.2214e-06, 7.8771e-06,
        3.7592e-06, 1.0964e-06, 2.8642e-06, 5.0563e-06, 6.9700e-06, 4.5841e-06,
        1.0818e-06, 6.0201e-06, 5.7078e-06, 3.2276e-06, 4.9179e-06, 3.3620e-06,
        2.4431e-06, 2.1368e-06, 1.8701e-06, 5.3631e-06, 3.8459e-06, 7.8374e-06,
        1.8168e-06, 4.1384e-06, 1.2058e-06, 3.3341e-06, 3.4823e-06, 3.2419e-06,
        5.9253e-06, 3.1465e-06, 5.3088e-06, 2.9827e-07, 5.5553e-06, 2.9971e-06,
        1.4905e-06, 5.5553e-06, 3.4200e-06, 9.8174e-07, 4.2477e-06, 5.9086e-06,
        6.2524e-06, 3.0773e-06, 2.7392e-06, 4.9270e-06, 4.2561e-06, 4.2583e-06,
        1.1280e-06, 4.1410e-06, 2.2137e-06, 3.6357e-06, 1.7860e-06, 2.8294e-06,
        4.6254e-06, 1.3454e-06, 7.4919e-06, 2.5706e-06, 3.6153e-06, 2.7352e-06,
        2.7392e-06, 4.1021e-06, 3.6725e-06, 3.8127e-06, 3.5392e-06, 2.3261e-06,
        1.7192e-06, 1.5066e-06, 3.7863e-06, 2.2605e-06, 2.1215e-06, 5.7061e-06,
        1.8701e-06, 1.9441e-06, 3.8127e-06, 4.1021e-06, 3.7047e-06, 3.8299e-06,
        7.1841e-06, 3.0909e-06, 3.4080e-06, 1.9862e-06, 9.0231e-07, 1.8959e-06,
        3.2087e-06, 6.6181e-06, 2.0839e-06, 2.0341e-06, 4.7359e-06, 5.1908e-06,
        2.7292e-06, 3.3607e-06, 1.7187e-06, 2.7392e-06, 9.0422e-06, 2.5307e-06,
        4.3582e-06, 5.0314e-06, 5.0903e-06, 4.1384e-06, 1.3676e-06, 2.0592e-06,
        2.0741e-06, 6.1752e-06, 6.0966e-06, 8.7787e-06, 2.9890e-06, 5.6817e-06,
        3.8373e-06, 4.8271e-06, 6.9700e-06, 4.4848e-06, 1.9493e-06, 2.1830e-06,
        5.7664e-06, 2.1368e-06, 7.8319e-06, 2.0024e-06, 4.9791e-06, 5.9402e-06,
        5.4072e-06, 5.0658e-06, 1.0229e-06, 3.8459e-06, 3.2276e-06, 2.1536e-06,
        3.0360e-06, 3.8299e-06, 1.4626e-06, 2.5664e-06, 2.0741e-06, 2.2566e-06,
        1.7793e-06, 4.9253e-06, 5.1740e-06, 1.8168e-06], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([3.3819e-07, 5.8142e-07, 2.0792e-07,  ..., 6.9142e-08, 2.4978e-07,
        2.7003e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([5.5469e-07, 4.4350e-07, 1.3140e-06, 5.7868e-07, 2.0339e-06, 4.5016e-07,
        5.7255e-07, 2.0397e-06, 1.3140e-06, 4.8535e-07, 2.0887e-07, 4.2873e-07,
        1.3140e-06, 5.4514e-07, 6.3397e-07, 4.1866e-07, 5.0980e-07, 1.4769e-06,
        1.8029e-07, 4.8535e-07, 4.4087e-07, 1.4769e-06, 5.0980e-07, 1.1158e-06,
        1.4769e-06, 4.4350e-07, 7.7414e-07, 1.1413e-06, 5.7868e-07, 8.5985e-07,
        4.8264e-07, 1.4545e-06, 7.3274e-07, 4.0995e-07, 1.3945e-06, 1.3267e-06,
        1.4769e-06, 6.4956e-07, 1.3267e-06, 3.6971e-07, 6.2669e-07, 1.3267e-06,
        3.3464e-07, 4.4350e-07, 9.8368e-07, 1.3140e-06, 1.3945e-06, 2.0350e-06,
        8.0292e-07, 9.3404e-07, 2.0397e-06, 6.4956e-07, 1.3267e-06, 4.0869e-07,
        4.2873e-07, 5.0152e-07, 9.7869e-07, 2.0397e-06, 4.4087e-07, 3.3249e-07,
        2.0397e-06, 4.4350e-07, 6.3397e-07, 8.5985e-07, 4.8535e-07, 4.8535e-07,
        7.7413e-07, 1.3140e-06, 9.3033e-07, 1.3267e-06, 5.4514e-07, 6.3790e-07,
        5.5469e-07, 5.7868e-07, 6.7507e-07, 7.6981e-07, 6.7507e-07, 6.2669e-07,
        7.7414e-07, 8.0292e-07, 4.4350e-07, 5.7304e-07, 4.0995e-07, 3.3464e-07,
        4.9697e-07, 7.7414e-07, 4.4087e-07, 5.5469e-07, 4.2873e-07, 1.3945e-06,
        7.7414e-07, 6.6681e-07, 1.3267e-06, 5.4076e-07, 1.9780e-07, 9.8368e-07,
        7.7414e-07, 1.7458e-06, 1.3945e-06, 1.4769e-06, 5.2156e-07, 1.4756e-06,
        6.3790e-07, 9.7869e-07, 1.2616e-06, 6.6681e-07, 8.0292e-07, 1.6143e-06,
        8.0292e-07, 1.2616e-06, 8.0292e-07, 4.0995e-07, 2.0121e-06, 1.9289e-06,
        2.0236e-06, 1.0156e-06, 4.4987e-07, 6.3130e-07, 1.4545e-06, 2.0397e-06,
        8.5985e-07, 4.2873e-07, 4.8535e-07, 1.3945e-06, 7.7414e-07, 1.7458e-06,
        7.7414e-07, 4.4350e-07, 4.4350e-07, 1.2135e-06, 5.2491e-07, 5.5469e-07,
        1.3945e-06, 5.7496e-07, 1.0156e-06, 6.9475e-07, 1.9289e-06, 4.4087e-07,
        1.9289e-06, 4.2873e-07, 2.5116e-07, 5.0980e-07, 9.7348e-07, 1.3267e-06,
        4.8535e-07, 1.4842e-06, 4.5016e-07, 7.7414e-07, 4.1004e-07, 5.5469e-07,
        8.0292e-07, 3.8778e-07, 5.0980e-07, 5.4076e-07, 2.0481e-06, 2.0397e-06,
        1.0156e-06, 4.2873e-07, 6.4956e-07, 1.9850e-06, 4.8960e-07, 8.0292e-07,
        4.3530e-02, 4.8535e-07, 1.3173e-06, 1.0156e-06, 1.6143e-06, 4.8535e-07,
        4.5016e-07, 2.0397e-06, 5.5469e-07, 2.6342e-07, 5.7868e-07, 4.4350e-07,
        1.2642e-06, 1.3945e-06, 1.3140e-06, 1.3267e-06, 1.3267e-06, 3.8778e-07,
        4.8535e-07, 1.3945e-06, 3.3249e-07, 5.7868e-07, 1.0321e-06, 4.4350e-07,
        1.8029e-07, 4.4350e-07, 1.1517e-06, 6.9474e-07, 7.3274e-07, 5.4514e-07,
        1.3945e-06, 4.9697e-07, 1.0156e-06, 4.9697e-07, 7.3875e-02, 4.4350e-07,
        1.9289e-06, 9.8368e-07, 4.2873e-07, 1.8029e-07, 4.0995e-07, 1.9289e-06,
        1.3531e-07, 2.0588e-08, 4.4350e-07, 4.4350e-07, 4.0995e-07, 2.6342e-07,
        4.8535e-07, 1.9714e-06, 8.5985e-07, 4.2873e-07, 9.3404e-07, 5.0980e-07,
        5.8262e-07, 4.4350e-07, 5.7868e-07, 8.5985e-07, 9.3033e-07, 4.2873e-07,
        4.4350e-07, 1.3140e-06, 6.6681e-07, 5.5469e-07, 5.5469e-07, 1.0156e-06,
        2.0397e-06, 5.7868e-07, 1.1413e-06, 1.3945e-06, 6.3397e-07, 5.4514e-07,
        5.5469e-07, 4.2873e-07, 1.3945e-06, 1.6143e-06, 5.5469e-07, 4.4350e-07,
        9.7869e-07, 4.2873e-07, 1.1063e-06, 5.5469e-07, 1.6143e-06, 1.3140e-06,
        8.5985e-07, 4.1941e-07, 2.9030e-07, 1.6143e-06, 8.0292e-07, 1.3945e-06,
        2.0397e-06, 1.3945e-06, 2.6517e-06, 4.2873e-07, 1.7520e-06, 5.7496e-07,
        1.9780e-07, 5.0980e-07, 2.0397e-06, 1.9850e-06, 5.0980e-07, 4.6206e-07,
        1.3945e-06, 9.6101e-07, 2.6342e-07, 4.8535e-07, 4.8535e-07, 1.3140e-06,
        7.7414e-07, 2.0244e-06, 7.0172e-07, 1.9780e-07, 4.0995e-07, 9.4818e-07,
        4.2873e-07, 6.9542e-07, 7.7414e-07, 6.3397e-07, 2.0397e-06, 1.4769e-06,
        1.4769e-06, 1.6143e-06, 4.9697e-07, 1.1158e-06, 2.9678e-02, 9.2768e-07,
        7.6981e-07, 8.0292e-07, 1.9780e-07, 1.1063e-06, 4.4346e-07, 1.8029e-07,
        1.0321e-06, 1.4769e-06, 9.8368e-07, 2.0302e-06, 3.6971e-07, 4.4663e-07,
        4.2059e-07, 3.6971e-07, 1.4769e-06, 6.6681e-07, 1.3140e-06, 9.6070e-07,
        5.9232e-07, 1.4769e-06, 5.0980e-07, 1.0435e-06, 1.3140e-06, 4.9697e-07,
        1.3267e-06, 5.5469e-07, 6.6992e-03, 6.9542e-07, 1.4545e-06, 1.7458e-06,
        4.4087e-07, 4.8535e-07, 1.3267e-06, 6.3397e-07, 4.4087e-07, 6.3130e-07,
        5.0980e-07, 2.0262e-06, 1.4769e-06, 5.5469e-07, 2.0244e-06, 1.4769e-06,
        3.3464e-07, 1.8029e-07, 6.7661e-07, 1.2616e-06, 1.6596e-02, 2.6760e-07,
        1.3173e-06, 1.0798e-06, 5.6596e-07, 8.0292e-07, 1.3267e-06, 2.0887e-07,
        2.0397e-06, 2.0397e-06, 7.7414e-07, 4.1866e-07, 4.8535e-07, 8.0292e-07,
        8.4773e-07, 4.4350e-07, 4.2267e-07, 6.6681e-07, 1.3140e-06, 4.4087e-07,
        1.3945e-06, 6.7018e-07, 4.4350e-07, 4.8535e-07, 1.0156e-06, 1.3140e-06,
        6.8826e-07, 2.9268e-07, 1.1158e-06, 5.7868e-07, 4.2059e-07, 9.8739e-07,
        1.3267e-06, 1.3140e-06, 2.6342e-07, 1.2616e-06, 1.1158e-06, 2.0481e-06,
        1.4565e-06, 5.5469e-07, 4.4350e-07, 6.7018e-07, 2.0397e-06, 7.7414e-07,
        1.3140e-06, 1.3140e-06, 2.0481e-06, 8.0292e-07, 6.7018e-07, 4.8535e-07,
        5.7496e-07, 1.8029e-07, 8.0292e-07, 5.5469e-07, 6.6681e-07, 2.0481e-06,
        4.4350e-07, 5.5469e-07, 9.3033e-07, 5.7868e-07, 8.0292e-07, 4.8535e-07,
        2.0397e-06, 6.6681e-07, 1.3945e-06, 1.9289e-06, 1.7458e-06, 1.6143e-06,
        6.6681e-07, 1.6143e-06, 6.9474e-07, 1.4426e-06, 1.6143e-06, 4.4087e-07,
        3.3464e-07, 1.2875e-07, 1.6143e-06, 1.3945e-06, 4.8535e-07, 6.4956e-07,
        1.7309e-06, 1.4769e-06, 4.0227e-07, 2.0397e-06, 2.6342e-07, 5.0980e-07,
        1.9289e-06, 2.0397e-06, 1.1063e-06, 5.0980e-07, 4.4350e-07, 5.7868e-07,
        3.3249e-07, 2.0397e-06, 4.4350e-07, 1.2616e-06, 9.7869e-07, 8.5985e-07,
        1.9850e-06, 6.4956e-07, 1.3945e-06, 1.8029e-07, 5.5469e-07, 2.6342e-07,
        5.5469e-07, 5.4076e-07, 1.9714e-06, 4.4350e-07, 8.0292e-07, 4.1866e-07,
        2.0397e-06, 7.7414e-07, 9.8368e-07, 5.7868e-07, 4.4087e-07, 2.0339e-06,
        1.6143e-06, 4.8535e-07, 1.4769e-06, 5.5469e-07, 1.2616e-06, 8.0292e-07,
        6.6681e-07, 1.0321e-06, 2.0397e-06, 4.1004e-07, 4.8960e-07, 5.0980e-07,
        1.3267e-06, 5.5469e-07, 7.7414e-07, 1.2616e-06, 4.2892e-07, 2.0397e-06,
        4.4350e-07, 4.2059e-07, 4.8535e-07, 5.4514e-07, 7.7414e-07, 5.0980e-07,
        9.7867e-07, 1.4769e-06, 1.1063e-06, 5.4514e-07, 4.4350e-07, 1.1158e-06,
        5.7868e-07, 3.3464e-07, 4.2873e-07, 4.1004e-07, 7.7413e-07, 1.1063e-06,
        2.0481e-06, 1.6143e-06, 1.3140e-06, 4.8535e-07, 1.2616e-06, 1.2592e-06,
        4.2059e-07, 1.3267e-06, 6.4956e-07, 7.7414e-07, 1.3945e-06, 1.3945e-06,
        4.8535e-07, 3.3249e-07, 5.4514e-07, 5.5469e-07, 3.3464e-07, 1.3267e-06,
        1.3140e-06, 4.4087e-07, 4.8535e-07, 5.7496e-07, 1.2616e-06, 2.0244e-06,
        1.9780e-07, 4.4350e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([2.7646e-06, 2.0548e-06, 3.1962e-06, 2.2981e-06, 5.7274e-06, 8.1348e-06,
        5.2221e-06, 6.3102e-06, 2.2391e-06, 5.5049e-06, 5.9787e-06, 2.7481e-06,
        6.3311e-06, 3.6643e-06, 5.7642e-06, 4.3269e-06, 4.7116e-06, 4.3269e-06,
        1.3311e-06, 1.3311e-06, 2.8210e-06, 4.3842e-06, 1.2101e-05, 1.2768e-05,
        5.3843e-06, 3.6642e-06, 3.2874e-06, 4.7116e-06, 3.4413e-06, 6.2114e-06,
        5.0234e-06, 1.0909e-05, 4.3517e-06, 8.8720e-06, 1.1264e-05, 6.6661e-06,
        4.3517e-06, 1.1590e-05, 4.3842e-06, 8.1348e-06, 2.1355e-06, 4.3517e-06,
        6.7675e-06, 1.9993e-06, 2.0557e-06, 4.3517e-06, 5.5049e-06, 5.9269e-06,
        9.3949e-06, 4.3517e-06, 4.3269e-06, 9.3949e-06, 4.9685e-06, 3.6643e-06,
        9.3949e-06, 2.8210e-06, 6.9548e-06, 1.6281e-05, 4.3269e-06, 9.3949e-06,
        6.7675e-06, 9.5087e-06, 9.3949e-06, 2.7315e-06, 3.5508e-06, 4.3517e-06,
        9.9455e-07, 1.0909e-05, 3.1962e-06, 2.8210e-06, 6.0431e-07, 3.0195e-06,
        2.0557e-06, 6.4073e-06, 2.8210e-06, 6.3311e-06, 5.4478e-06, 5.0234e-06,
        6.9513e-06, 3.4413e-06, 6.4480e-06, 3.6711e-06, 7.0833e-06, 4.6403e-06,
        9.3949e-06, 9.3949e-06, 7.1868e-06, 2.8496e-06, 6.4055e-06, 2.0557e-06,
        4.8147e-06, 2.7788e-06, 6.9064e-07, 3.5876e-06, 9.3949e-06, 6.6661e-06,
        4.3517e-06, 9.3949e-06, 3.4413e-06, 4.3269e-06, 4.2604e-06, 3.4544e-06,
        6.7675e-06, 9.3949e-06, 9.9455e-07, 6.7675e-06, 4.3842e-06, 6.7675e-06,
        5.0234e-06, 5.9268e-06, 9.5087e-06, 6.3311e-06, 2.4692e-06, 6.8043e-06,
        4.7321e-06, 1.0909e-05, 4.3269e-06, 7.5879e-06, 2.3270e-06, 3.4413e-06,
        5.9269e-06, 9.3949e-06, 9.3949e-06, 4.0275e-06, 6.0376e-06, 7.0833e-06,
        1.9111e-06, 4.3842e-06, 9.9455e-07, 4.3269e-06, 4.0275e-06, 8.3279e-06,
        6.9064e-07, 8.7456e-06, 7.9541e-06, 4.3842e-06, 4.6403e-06, 5.1381e-06,
        6.3311e-06, 9.3949e-06, 3.1962e-06, 4.6403e-06, 4.6403e-06, 4.0055e-06,
        1.2101e-05, 9.3949e-06, 3.5508e-06, 3.1962e-06, 5.4343e-06, 9.9455e-07,
        5.2169e-06, 4.1696e-06, 4.7321e-06, 4.7307e-06, 9.3949e-06, 3.1247e-06,
        5.9567e-06, 1.0269e-05, 4.7321e-06, 1.2559e-06, 6.9064e-07, 4.5001e-06,
        9.5087e-06, 3.4413e-06, 4.6403e-06, 7.0833e-06, 4.3269e-06, 4.6403e-06,
        3.1962e-06, 6.8233e-06, 3.0792e-06, 9.3949e-06, 1.3311e-06, 9.5087e-06,
        4.6403e-06, 9.3949e-06, 6.7675e-06, 1.0909e-05, 4.6403e-06, 5.7578e-06,
        1.3217e-05, 4.3517e-06, 4.3269e-06, 1.3259e-06, 2.0557e-06, 4.3269e-06,
        3.8079e-06, 6.7675e-06, 6.9064e-07, 4.6403e-06, 4.4864e-06, 1.1590e-05,
        7.0303e-07, 2.5911e-06, 6.4480e-06, 1.6819e-05, 4.6403e-06, 6.3311e-06,
        3.8079e-06, 2.2392e-06, 3.6643e-06, 4.6311e-06, 1.3311e-06, 4.7116e-06,
        4.6311e-06, 1.3311e-06, 1.3311e-06, 1.9099e-06, 3.0195e-06, 3.6642e-06,
        6.0431e-07, 4.6513e-06, 2.8496e-06, 3.4390e-06, 4.9685e-06, 2.3989e-06,
        6.3311e-06, 2.7315e-06, 4.8147e-06, 1.9699e-06, 1.2629e-05, 9.9455e-07,
        4.7116e-06, 3.1962e-06, 5.9504e-06, 1.5646e-06, 4.3269e-06, 6.0345e-06,
        4.7116e-06, 5.7578e-06, 5.7299e-06, 2.0557e-06, 9.7633e-06, 8.3279e-06,
        9.3949e-06, 5.1258e-06, 9.3949e-06, 2.5911e-06, 5.4343e-06, 4.9685e-06,
        8.1348e-06, 1.8188e-06, 3.6643e-06, 3.4413e-06, 4.6311e-06, 1.1590e-05,
        4.0275e-06, 1.1316e-05, 6.0854e-06, 6.9064e-07, 2.7481e-06, 4.6403e-06,
        2.7222e-06, 6.7675e-06, 5.4343e-06, 3.1565e-06, 8.3279e-06, 3.8679e-06,
        5.9269e-06, 2.4739e-06, 1.0909e-05, 6.9548e-06, 4.5078e-06, 9.3949e-06,
        8.1348e-06, 6.7675e-06, 1.9574e-06, 4.3269e-06, 3.0792e-06, 4.3269e-06,
        1.0482e-05, 4.8147e-06, 2.7676e-06, 3.3501e-06, 9.3949e-06, 2.4739e-06,
        6.9064e-07, 8.7456e-06, 1.1590e-05, 1.2648e-05, 4.9452e-06, 4.3517e-06,
        9.7633e-06, 5.9567e-06, 5.9268e-06, 6.1272e-06, 2.2995e-06, 8.5496e-06,
        9.3949e-06, 1.1590e-05, 4.3269e-06, 8.3279e-06, 3.1962e-06, 4.6403e-06,
        5.2767e-06, 6.6712e-06, 4.0275e-06, 1.1264e-05, 5.9269e-06, 3.1962e-06,
        4.3269e-06, 9.7633e-06, 5.9567e-06, 5.5049e-06, 3.1962e-06, 2.9575e-06,
        6.9548e-06, 1.4568e-06, 5.9269e-06, 5.7642e-06, 3.1962e-06, 1.0319e-05,
        7.0833e-06, 2.8210e-06, 4.4756e-06, 5.4478e-06, 4.9685e-06, 2.4739e-06,
        1.9736e-06, 2.8496e-06, 9.9455e-07, 4.5705e-06, 4.9685e-06, 4.5018e-06,
        7.0303e-07, 3.6643e-06, 4.3269e-06, 3.6643e-06, 3.1962e-06, 2.2995e-06,
        9.3949e-06, 3.4413e-06, 8.3279e-06, 2.4739e-06, 5.0234e-06, 6.8044e-06,
        5.9269e-06, 3.2874e-06, 8.3279e-06, 4.3269e-06, 4.3269e-06, 4.7116e-06,
        8.7456e-06, 4.9223e-06, 8.2558e-06, 6.9064e-07, 2.3328e-06, 3.4413e-06,
        5.2221e-06, 6.9548e-06, 6.3311e-06, 4.3842e-06, 2.4739e-06, 2.5421e-06,
        1.1590e-05, 2.9575e-06, 3.4413e-06, 1.2324e-05, 7.6522e-06, 6.7675e-06,
        6.9064e-07, 4.7321e-06, 4.5018e-06, 4.7307e-06, 8.7456e-06, 5.3238e-06,
        6.0345e-06, 4.3090e-06, 5.2221e-06, 6.6661e-06, 9.3949e-06, 1.3311e-06,
        3.4413e-06, 6.1272e-06, 5.2169e-06, 3.1962e-06, 4.6403e-06, 7.6522e-06,
        2.7315e-06, 9.3949e-06, 1.2777e-05, 7.3110e-06, 5.7578e-06, 4.9452e-06,
        5.5049e-06, 9.3949e-06, 5.9269e-06, 1.3311e-06, 5.2169e-06, 2.2392e-06,
        1.6819e-05, 1.3311e-06, 9.7633e-06, 4.8147e-06, 2.8810e-06, 4.3842e-06,
        2.8210e-06, 8.1348e-06, 5.1258e-06, 2.8056e-06, 4.5970e-06, 5.9269e-06,
        3.0195e-06, 4.6311e-06, 3.1962e-06, 4.3517e-06, 3.2108e-06, 2.7481e-06,
        4.7992e-06, 6.9064e-07, 3.4413e-06, 2.5911e-06, 4.2038e-06, 5.0234e-06,
        6.4356e-06, 3.4420e-06, 2.0557e-06, 1.1655e-05, 4.0055e-06, 1.6495e-06,
        5.4343e-06, 4.3517e-06, 3.0195e-06, 5.0234e-06, 4.3090e-06, 1.9383e-06,
        9.3949e-06, 5.9269e-06, 4.6403e-06, 4.3269e-06, 3.6643e-06, 1.9111e-06,
        4.4074e-06, 2.5421e-06, 9.3949e-06, 2.4739e-06, 3.8079e-06, 5.9269e-06,
        6.3311e-06, 2.1355e-06, 6.8043e-06, 9.3949e-06, 5.9567e-06, 4.7116e-06,
        1.1590e-05, 6.6661e-06, 4.0055e-06, 8.3279e-06, 4.5970e-06, 6.8044e-06,
        1.0269e-05, 5.4343e-06, 6.9064e-07, 6.9548e-06, 5.3238e-06, 5.0234e-06,
        8.7456e-06, 8.3279e-06, 9.5087e-06, 3.0195e-06, 1.2768e-05, 3.8079e-06,
        3.7631e-06, 3.2874e-06, 4.0275e-06, 6.1272e-06, 9.6028e-07, 6.8044e-06,
        4.3517e-06, 3.0195e-06, 3.1962e-06, 4.3517e-06, 5.0234e-06, 3.6711e-06,
        6.7675e-06, 9.5087e-06, 9.3949e-06, 9.3949e-06, 3.8079e-06, 1.1096e-05,
        2.0557e-06, 9.3949e-06, 4.4794e-06, 8.1832e-06, 6.1272e-06, 3.0195e-06,
        2.8496e-06, 9.9455e-07, 4.6401e-06, 1.1590e-05, 4.8147e-06, 3.0792e-06,
        3.6643e-06, 6.3311e-06, 1.3311e-06, 3.5508e-06, 5.9269e-06, 9.0849e-03,
        1.3311e-06, 2.8210e-06, 5.3238e-06, 3.0792e-06, 9.3949e-06, 4.3517e-06,
        3.3097e-06, 1.0909e-05, 3.4413e-06, 8.7456e-06, 7.1868e-06, 4.3517e-06,
        3.6110e-06, 7.0833e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([3.6643e-07, 9.6968e-07, 6.4735e-07,  ..., 1.0303e-06, 6.5057e-07,
        8.5610e-07], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.1357e-06, 7.4146e-07, 1.4447e-06,  ..., 5.0361e-07, 7.3228e-07,
        1.5807e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([2.6189e-06, 2.8436e-06, 2.9741e-06, 1.4390e-06, 1.4098e-06, 6.1410e-06,
        6.4184e-06, 4.9194e-06, 2.5469e-06, 8.8997e-07, 1.8721e-06, 8.8997e-07,
        1.8721e-06, 4.2210e-06, 2.7545e-06, 1.6191e-06, 4.6526e-06, 3.0139e-06,
        2.3428e-06, 2.1727e-06, 1.7525e-06, 2.1307e-06, 2.3491e-06, 5.2190e-06,
        5.4239e-07, 2.9452e-06, 6.1410e-06, 1.8676e-06, 1.3706e-06, 2.5866e-06,
        6.7824e-06, 2.0027e-06, 1.5981e-06, 6.1465e-07, 3.2779e-06, 1.9612e-06,
        2.0996e-06, 1.8676e-06, 2.8249e-06, 2.9111e-06, 1.4743e-06, 3.0886e-06,
        4.6529e-06, 5.1191e-06, 4.5804e-06, 8.4631e-06, 2.2526e-06, 4.1866e-06,
        4.9882e-06, 5.1191e-06, 3.5778e-06, 4.8989e-06, 1.6975e-06, 2.0027e-06,
        4.8665e-06, 5.2820e-06, 2.5259e-06, 3.3629e-06, 3.1956e-06, 2.6763e-06,
        1.9722e-06, 1.1506e-06, 1.7525e-06, 9.9322e-07, 3.4717e-06, 1.4650e-06,
        1.5930e-06, 1.0376e-06, 5.6668e-06, 1.7525e-06, 2.5232e-06, 2.9618e-06,
        5.4321e-06, 5.0620e-06, 3.1228e-06, 1.9081e-06, 4.1214e-06, 1.0560e-06,
        2.8920e-06, 5.6668e-06, 9.2906e-07, 2.8920e-06, 4.4813e-06, 5.4321e-06,
        6.7824e-06, 2.3201e-06, 4.2565e-06, 2.4939e-06, 1.8491e-06, 4.1284e-06,
        1.8676e-06, 1.4098e-06, 1.7525e-06, 3.0274e-06, 6.1176e-06, 3.5055e-06,
        8.6942e-07, 2.2937e-06, 5.0332e-06, 5.1191e-06, 1.4445e-06, 3.2350e-06,
        1.8676e-06, 8.8997e-07, 2.9111e-06, 3.3960e-06, 1.7824e-06, 3.1317e-06,
        1.5930e-06, 5.2821e-06, 2.0746e-06, 1.1365e-06, 2.3201e-06, 1.8491e-06,
        7.8952e-07, 3.0382e-06, 4.7678e-06, 2.1660e-06, 3.3093e-06, 1.4098e-06,
        3.4287e-06, 4.6526e-06, 3.5778e-06, 5.1191e-06, 6.7739e-07, 4.5499e-06,
        1.4958e-06, 6.0419e-06, 3.4717e-06, 2.4639e-06, 2.9724e-06, 2.9741e-06,
        3.1003e-06, 4.2209e-06, 3.7611e-06, 4.6529e-06, 9.2309e-07, 4.3845e-06,
        3.3498e-06, 2.9111e-06, 3.8902e-06, 4.8989e-06, 5.2875e-06, 1.8854e-06,
        3.3651e-06, 3.1555e-06, 1.6975e-06, 1.8414e-06, 7.4322e-07, 1.8856e-06,
        2.0314e-06, 9.9322e-07, 2.7421e-06, 3.3093e-06, 1.8863e-06, 3.3093e-06,
        2.7364e-06, 3.1433e-06, 2.4921e-06, 1.2643e-06, 5.1191e-06, 2.3428e-06,
        1.4080e-06, 8.7464e-06, 5.6665e-06, 5.1932e-06, 1.0560e-06, 4.7053e-06,
        8.7464e-06, 1.5030e-06, 2.6841e-06, 1.8491e-06, 1.0180e-06, 1.5109e-06,
        5.8111e-06, 4.7053e-06, 3.3329e-06, 1.2085e-06, 4.8989e-06, 2.0027e-06,
        1.7369e-07, 1.9845e-06, 1.7899e-06, 1.6591e-06, 1.6368e-06, 1.6188e-06,
        4.3058e-06, 1.8676e-06, 8.6941e-07, 4.9233e-06, 1.1985e-06, 2.0027e-06,
        3.1003e-06, 4.6526e-06, 2.3428e-06, 2.7364e-06, 3.1034e-06, 2.3201e-06,
        6.7276e-06, 3.5560e-06, 4.5471e-06, 5.8111e-06, 2.2937e-06, 3.2350e-06,
        3.1317e-06, 5.6665e-06, 5.4239e-07, 6.4184e-06, 4.5588e-06, 5.2821e-06,
        4.8665e-06, 5.1191e-06, 5.3119e-06, 1.7525e-06, 1.2007e-06, 5.4321e-06,
        4.0969e-06, 1.3431e-06, 1.3393e-06, 2.5502e-06, 1.7525e-06, 3.6957e-06,
        1.8413e-06, 2.6810e-06, 8.1113e-06, 2.0027e-06, 4.7449e-06, 4.3845e-06,
        2.7647e-06, 2.3201e-06, 2.3669e-06, 2.8118e-06, 2.8602e-06, 2.7154e-06,
        3.8771e-06, 2.0165e-06, 1.8491e-06, 1.4958e-06, 5.1191e-06, 1.5930e-06,
        1.9067e-06, 2.3428e-06, 4.8989e-06, 4.9015e-06, 7.0095e-06, 1.7093e-06,
        2.7364e-06, 5.1191e-06, 1.8676e-06, 6.7806e-06, 1.1572e-06, 3.1034e-06,
        4.7153e-06, 4.1284e-06, 3.1003e-06, 1.1385e-06, 8.6942e-07, 2.0027e-06,
        3.0787e-06, 1.1385e-06, 3.4540e-06, 4.8665e-06, 3.2530e-06, 3.4179e-06,
        4.8109e-06, 1.5101e-06, 4.6526e-06, 1.8676e-06, 3.1317e-06, 1.8991e-06,
        1.4698e-06, 4.4364e-06, 2.9767e-06, 3.3093e-06, 3.1317e-06, 2.7657e-06,
        2.7657e-06, 2.0314e-06, 4.0363e-06, 2.0027e-06, 4.4364e-06, 1.5158e-06,
        2.0788e-06, 2.8249e-06, 3.5055e-06, 6.7806e-06, 3.1688e-06, 5.0332e-06,
        5.1191e-06, 1.2441e-06, 2.2475e-06, 4.3203e-06, 1.9081e-06, 4.8241e-06,
        2.8436e-06, 4.7554e-06, 1.2643e-06, 6.8202e-06, 5.4321e-06, 2.7364e-06,
        2.2635e-06, 3.0833e-06, 5.6034e-06, 2.7343e-06, 4.0858e-06, 1.9772e-06,
        1.3393e-06, 2.7545e-06, 1.6205e-06, 6.2671e-06, 1.6612e-06, 2.9981e-06,
        4.6526e-06, 6.7806e-06, 2.2379e-06, 4.8268e-06, 8.4631e-06, 3.7272e-06,
        3.2056e-06, 2.0314e-06, 1.8856e-06, 3.3629e-06, 1.5981e-06, 1.7824e-06,
        4.6529e-06, 2.8758e-06, 3.0382e-06, 2.3428e-06, 6.2330e-07, 1.5981e-06,
        4.3058e-06, 5.4321e-06, 5.6741e-06, 9.2977e-07, 1.6481e-06, 1.5930e-06,
        4.3845e-06, 1.8460e-06, 1.6975e-06, 2.2749e-06, 8.2485e-06, 3.0833e-06,
        2.9111e-06, 2.9003e-06, 2.5382e-06, 3.3093e-06, 2.0027e-06, 3.0727e-06,
        2.8920e-06, 1.1985e-06, 6.2330e-07, 4.7277e-07, 2.0654e-06, 5.6857e-06,
        1.4445e-06, 1.3431e-06, 1.8856e-06, 3.2525e-06, 4.8989e-06, 3.1992e-06,
        4.8989e-06, 2.6079e-06, 2.5692e-06, 2.0027e-06, 2.8602e-06, 6.7806e-06,
        2.7364e-06, 2.8042e-06, 3.4281e-06, 5.1191e-06, 1.8293e-06, 2.2526e-06,
        2.0993e-06, 2.2133e-06, 3.0833e-06, 3.1228e-06, 4.3845e-06, 9.0070e-07,
        1.3744e-06, 7.4245e-06, 2.5083e-06, 5.6741e-06, 9.9322e-07, 2.9767e-06,
        2.8042e-06, 2.6149e-06, 2.9728e-06, 1.2085e-06, 4.8989e-06, 1.7093e-06,
        2.0027e-06, 3.3604e-06, 1.7824e-06, 1.0866e-06, 4.0128e-06, 9.0070e-07,
        2.7657e-06, 2.1452e-06, 6.4184e-06, 1.4445e-06, 3.3014e-06, 3.5778e-06,
        2.0165e-06, 2.4885e-06, 1.6368e-06, 1.8491e-06, 7.0095e-06, 4.8989e-06,
        1.7398e-06, 8.8175e-06, 1.7999e-06, 1.5109e-06, 2.9618e-06, 5.1191e-06,
        4.0106e-06, 1.9670e-06, 6.4184e-06, 3.3777e-06, 3.3629e-06, 5.4321e-06,
        1.3400e-06, 2.2188e-06, 2.6915e-06, 2.4731e-06, 2.0314e-06, 1.9081e-06,
        9.0070e-07, 2.4939e-06, 2.5694e-06, 1.9701e-06, 8.1334e-07, 4.3297e-07,
        2.3428e-06, 9.9322e-07, 2.7823e-06, 1.7724e-06, 5.1191e-06, 8.9252e-06,
        6.2330e-07, 3.0274e-06, 4.0858e-06, 3.9545e-06, 5.4321e-06, 5.4321e-06,
        2.4287e-06, 8.8997e-07, 2.9777e-06, 5.1191e-06, 5.0625e-06, 2.5382e-06,
        2.3428e-06, 2.2133e-06, 1.1237e-06, 1.6042e-06, 9.6474e-07, 4.3845e-06,
        4.4964e-06, 2.7249e-06, 3.7272e-06, 5.4321e-06, 3.4717e-06, 1.5930e-06,
        1.8293e-06, 2.0314e-06, 2.9981e-06, 4.1144e-06, 2.7490e-06, 1.9374e-06,
        3.4308e-06, 1.7525e-06, 2.7364e-06, 5.9810e-06, 3.0393e-06, 4.6020e-07,
        1.7824e-06, 3.2350e-06, 4.0220e-06, 4.2394e-06, 3.3291e-06, 2.2368e-06,
        4.8989e-06, 3.4239e-06, 7.5532e-06, 5.4321e-06, 7.5532e-06, 2.7364e-06,
        1.1338e-06, 2.1660e-06, 3.2350e-06, 6.2330e-07, 2.3428e-06, 6.2330e-07,
        6.1751e-06, 2.5050e-06, 2.8042e-06, 2.7154e-06, 5.3119e-06, 1.6368e-06,
        7.6538e-06, 6.7806e-06, 7.5532e-06, 6.1515e-07, 6.7824e-06, 2.9111e-06,
        2.9190e-06, 4.4937e-06, 4.1284e-06, 4.7449e-06, 4.7053e-06, 3.4717e-06,
        1.4958e-06, 3.4681e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([7.9581e-06, 1.9152e-05, 1.0854e-05, 1.6490e-05, 9.9153e-06, 9.4895e-06,
        1.3292e-05, 1.4790e-05, 1.0345e-05, 1.0806e-05, 8.1571e-06, 4.7379e-06,
        1.4298e-05, 2.0638e-05, 1.0196e-05, 8.5710e-06, 5.9195e-06, 9.9712e-06,
        6.6232e-06, 1.2690e-05, 1.0061e-05, 7.9669e-06, 2.2140e-05, 1.6712e-05,
        5.2708e-06, 9.8249e-06, 7.0357e-06, 9.7344e-06, 1.0284e-05, 1.3449e-05,
        1.2793e-05, 1.6303e-05, 9.4826e-06, 1.4529e-05, 2.4408e-05, 4.6234e-06,
        8.1571e-06, 5.6830e-06, 3.9037e-06, 9.1636e-06, 1.7640e-05, 6.5795e-06,
        1.0734e-05, 1.0565e-05, 9.7055e-06, 4.4342e-06, 3.2054e-06, 1.0894e-05,
        1.5348e-05, 1.1650e-05, 1.2583e-05, 1.1369e-05, 6.0069e-06, 1.6287e-05,
        8.3767e-06, 6.0883e-06, 2.4850e-05, 3.6135e-06, 1.8197e-05, 9.8249e-06,
        1.0310e-05, 1.4323e-05, 1.5967e-05, 7.7366e-06, 2.1933e-05, 4.5706e-06,
        9.5646e-06, 7.7135e-07, 1.7380e-05, 7.5849e-06, 8.4273e-06, 1.5609e-05,
        2.1596e-05, 1.7507e-05, 1.0192e-05, 2.3192e-05, 1.7908e-05, 1.8637e-06,
        1.4529e-05, 1.9574e-05, 9.6755e-06, 1.2507e-05, 1.1649e-05, 6.8663e-06,
        1.3695e-05, 1.2077e-05, 1.0284e-05, 8.7022e-06, 9.4826e-06, 1.0414e-05,
        2.0828e-05, 2.5802e-05, 1.2335e-05, 1.1755e-05, 1.7926e-05, 1.0773e-05,
        5.5470e-06, 3.8826e-07, 9.4286e-06, 1.3881e-05, 2.1071e-05, 1.7640e-05,
        1.6108e-05, 1.2597e-05, 1.1277e-05, 9.1318e-06, 7.8557e-06, 1.5327e-05,
        3.8830e-06, 2.0482e-05, 1.3267e-05, 1.7970e-05, 8.0301e-06, 8.5474e-06,
        3.4096e-05, 1.5121e-05, 1.0191e-05, 9.1636e-06, 6.6394e-06, 1.0599e-05,
        9.7989e-06, 1.1762e-05, 9.4443e-06, 1.2273e-05, 1.1318e-05, 1.0696e-05,
        1.6472e-05, 6.7522e-06, 1.8858e-05, 1.2617e-05, 2.0867e-05, 1.7443e-05,
        8.9644e-06, 1.0030e-05, 1.2137e-05, 8.7565e-06, 1.0139e-05, 9.8494e-06,
        6.5183e-06, 2.5283e-05, 1.0069e-05, 1.5604e-05, 8.2880e-06, 1.1228e-05,
        1.7405e-05, 1.1302e-05, 1.0461e-05, 9.3050e-06, 5.2708e-06, 1.3342e-05,
        6.5183e-06, 8.8130e-06, 2.0731e-05, 5.5444e-06, 6.7322e-06, 1.2764e-05,
        1.4754e-05, 1.1283e-05, 9.5552e-06, 8.9029e-06, 4.6234e-06, 3.1525e-05,
        9.4715e-06, 8.5476e-06, 1.4320e-05, 7.5870e-06, 1.3324e-05, 1.2793e-05,
        1.0059e-05, 7.0502e-06, 1.7406e-05, 1.6622e-05, 1.2186e-05, 1.1402e-05,
        1.7510e-05, 7.1220e-06, 5.5384e-06, 4.5623e-06, 4.2919e-06, 7.0439e-06,
        1.7510e-05, 4.6234e-06, 1.5306e-05, 6.8027e-06, 1.1504e-05, 1.3939e-05,
        6.4412e-06, 2.0895e-05, 1.0551e-05, 6.8230e-06, 7.5870e-06, 1.3033e-05,
        3.1350e-06, 4.6234e-06, 4.0559e-06, 7.1829e-06, 1.6490e-05, 1.2781e-05,
        8.8713e-06, 1.8331e-05, 7.4205e-06, 9.4286e-06, 6.4107e-06, 4.2531e-06,
        5.0338e-06, 1.2731e-05, 4.3739e-06, 1.7065e-05, 1.7291e-05, 2.1866e-05,
        9.6755e-06, 1.0344e-05, 1.1402e-05, 9.5524e-06, 8.8713e-06, 8.1038e-06,
        1.4540e-05, 7.2887e-06, 2.2757e-05, 8.7527e-06, 2.4734e-05, 1.5327e-05,
        5.5444e-06, 3.5924e-05, 1.6147e-05, 2.0411e-05, 9.5647e-06, 7.5849e-06,
        1.1369e-05, 1.7705e-05, 1.0139e-05, 1.6194e-05, 1.3649e-05, 1.1007e-05,
        9.2474e-06, 1.2819e-05, 1.5875e-05, 1.0551e-05, 1.3033e-05, 5.0382e-06,
        2.6114e-05, 1.2445e-05, 3.9473e-06, 8.8062e-06, 1.0940e-05, 2.1933e-05,
        1.3680e-05, 1.0284e-06, 6.6563e-06, 1.3068e-05, 4.7379e-06, 2.4850e-05,
        1.0588e-05, 1.3292e-05, 8.7192e-06, 1.1256e-05, 1.6472e-05, 4.6234e-06,
        4.2531e-06, 1.1755e-05, 1.8178e-05, 1.5771e-05, 1.5604e-05, 2.3307e-05,
        2.1071e-05, 8.1038e-06, 8.9777e-06, 6.9418e-06, 1.8449e-05, 1.6591e-05,
        1.0854e-05, 6.5795e-06, 4.2969e-06, 9.5250e-06, 7.0989e-06, 1.0894e-05,
        8.6257e-06, 1.4616e-05, 1.7380e-05, 1.7959e-05, 1.7655e-05, 8.3767e-06,
        1.1488e-05, 1.2849e-05, 9.5587e-06, 9.2876e-06, 2.3930e-05, 2.5283e-05,
        8.8713e-06, 1.5729e-05, 6.2368e-06, 7.5690e-06, 4.7518e-06, 1.4018e-05,
        8.7565e-06, 6.5183e-06, 1.6109e-05, 3.6097e-06, 1.2037e-05, 9.5552e-06,
        9.6573e-06, 1.8531e-05, 5.3898e-06, 7.7757e-06, 4.4347e-06, 1.2401e-05,
        1.4154e-05, 5.5444e-06, 1.7272e-05, 1.3195e-05, 4.0254e-06, 8.4784e-06,
        4.6234e-06, 2.1550e-05, 6.5684e-06, 5.1369e-06, 9.9187e-06, 2.1641e-05,
        1.2793e-05, 1.2137e-05, 8.7658e-06, 1.9152e-05, 1.9485e-05, 6.6767e-06,
        1.6676e-05, 1.4320e-05, 1.8621e-05, 1.2230e-05, 1.3977e-05, 8.8160e-06,
        1.5138e-05, 2.1874e-05, 8.8713e-06, 1.8857e-05, 6.2394e-06, 1.3773e-05,
        7.3682e-06, 9.9303e-06, 1.5008e-05, 4.3296e-06, 8.0262e-06, 9.9303e-06,
        6.5670e-06, 1.2793e-05, 9.4750e-06, 1.3966e-05, 1.2690e-05, 1.4911e-05,
        8.9969e-06, 1.6886e-05, 1.0495e-05, 9.1230e-06, 6.2791e-06, 1.1890e-05,
        1.2849e-05, 7.0989e-06, 2.1110e-06, 1.3695e-05, 6.3969e-06, 1.3924e-05,
        4.0254e-06, 1.7712e-05, 1.3534e-05, 1.0894e-05, 1.0630e-05, 1.2819e-05,
        1.4790e-05, 1.4873e-05, 1.9174e-05, 7.5247e-06, 9.7390e-06, 1.4378e-05,
        2.2491e-05, 9.7736e-06, 1.8148e-05, 2.4112e-05, 5.6437e-06, 5.6437e-06,
        1.0894e-05, 8.6297e-06, 9.7856e-06, 2.1097e-05, 9.8664e-06, 2.1866e-05,
        7.1220e-06, 6.7724e-06, 1.2443e-05, 7.7957e-06, 1.5121e-05, 8.2045e-06,
        1.6396e-05, 1.7390e-05, 1.2819e-05, 1.1318e-05, 1.1975e-05, 7.0989e-06,
        7.0989e-06, 1.4911e-05, 9.5587e-06, 1.1271e-05, 6.9768e-06, 2.4444e-06,
        1.7959e-05, 7.5767e-06, 8.4176e-06, 1.0863e-05, 1.3688e-05, 1.0129e-05,
        1.0007e-05, 5.4811e-06, 1.3102e-05, 1.7694e-05, 8.6108e-06, 1.1697e-05,
        4.7239e-06, 1.4421e-05, 1.0551e-05, 5.4117e-06, 7.4109e-06, 2.3006e-05,
        8.1571e-06, 7.1607e-06, 6.5151e-06, 1.8505e-05, 9.2962e-06, 1.7291e-05,
        9.6099e-06, 8.8713e-06, 1.0792e-05, 1.1271e-05, 1.5579e-05, 6.7416e-06,
        5.0489e-06, 1.7640e-05, 4.3739e-06, 4.8357e-06, 9.4453e-06, 1.9015e-05,
        1.2445e-05, 1.1271e-05, 2.2227e-05, 1.5838e-05, 1.4602e-05, 1.5608e-05,
        1.1283e-05, 1.4774e-05, 9.4443e-06, 5.5762e-07, 8.8553e-06, 7.3682e-06,
        1.5839e-05, 1.6256e-05, 5.1883e-06, 1.8468e-05, 1.2443e-05, 4.4342e-06,
        1.0232e-05, 6.2742e-06, 9.5245e-06, 1.2781e-05, 1.2335e-05, 1.0985e-05,
        1.1271e-05, 9.3846e-06, 5.0827e-06, 8.0581e-06, 1.8826e-05, 9.4286e-06,
        8.3767e-06, 7.4758e-06, 1.5138e-05, 1.5194e-05, 1.9881e-05, 1.8652e-05,
        1.8991e-05, 1.0985e-05, 6.8663e-06, 6.4747e-06, 6.7035e-06, 8.2939e-06,
        1.0894e-05, 5.4840e-06, 1.1667e-05, 6.1952e-06, 1.4359e-05, 3.5539e-06,
        1.2445e-05, 1.2445e-05, 1.5609e-05, 1.0650e-05, 2.5415e-05, 8.9081e-06,
        6.4412e-06, 1.3292e-05, 5.6502e-06, 4.8225e-06, 5.6963e-06, 7.5849e-06,
        1.2335e-05, 1.2335e-05, 1.0850e-05, 1.8767e-05, 1.2242e-05, 2.0334e-05,
        2.0029e-05, 2.1071e-05, 9.7989e-06, 6.4393e-06, 6.8663e-06, 1.5306e-05,
        9.7736e-06, 1.5595e-05], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.7765e-06, 7.5513e-07, 2.7589e-06,  ..., 1.3582e-06, 1.8398e-06,
        1.1872e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([7.6885e-06, 4.1280e-06, 4.9145e-06, 2.9025e-06, 1.7675e-06, 8.7274e-06,
        6.5203e-06, 1.9622e-06, 3.5356e-06, 2.7312e-06, 5.1696e-06, 1.6720e-06,
        1.3863e-05, 7.4621e-06, 5.4826e-06, 6.8729e-06, 2.6826e-06, 1.9245e-06,
        3.3949e-06, 3.6591e-06, 3.7725e-06, 2.9116e-06, 1.3799e-05, 5.9611e-06,
        6.3124e-06, 4.0650e-06, 5.6616e-06, 4.7596e-06, 6.1845e-06, 6.1518e-06,
        2.2398e-06, 2.9854e-06, 4.2205e-06, 3.1638e-06, 2.8409e-06, 5.4021e-06,
        2.4028e-06, 2.5626e-06, 4.0721e-06, 3.1638e-06, 4.0764e-06, 7.0103e-06,
        2.2025e-06, 1.4013e-05, 8.4651e-06, 7.0652e-06, 2.0471e-06, 3.9491e-06,
        2.4028e-06, 4.1496e-06, 3.5356e-06, 8.1859e-06, 7.9699e-06, 4.3623e-06,
        2.7917e-06, 3.3798e-06, 5.5145e-06, 3.9262e-06, 3.5162e-06, 7.0475e-06,
        4.4823e-06, 5.1980e-06, 4.3363e-06, 5.4381e-06, 4.8205e-06, 4.2887e-06,
        1.3190e-06, 6.4211e-06, 3.1638e-06, 6.1518e-06, 8.0336e-06, 5.1175e-06,
        4.7473e-06, 4.1280e-06, 4.8938e-06, 1.8945e-06, 6.1775e-06, 5.3944e-06,
        5.5291e-06, 1.1609e-06, 5.0418e-06, 7.9828e-06, 3.0084e-06, 6.3733e-06,
        6.6366e-06, 4.1280e-06, 5.5340e-06, 1.4250e-06, 4.1280e-06, 8.4512e-06,
        5.1905e-06, 2.6471e-06, 4.4217e-06, 1.9851e-06, 1.0130e-05, 2.4028e-06,
        6.6538e-06, 2.6081e-06, 2.5921e-06, 3.7456e-06, 6.4725e-06, 2.1087e-06,
        7.1206e-06, 1.4921e-06, 8.6288e-06, 3.1638e-06, 3.2479e-06, 1.3432e-06,
        9.1873e-06, 3.9693e-06, 3.0063e-06, 8.0201e-06, 3.2388e-06, 2.6826e-06,
        3.5536e-06, 7.4198e-06, 8.7274e-06, 6.2385e-06, 3.5272e-06, 4.4823e-06,
        6.9834e-06, 1.6601e-06, 3.0475e-06, 3.2468e-06, 3.7571e-06, 4.4719e-06,
        2.9609e-07, 3.2313e-06, 1.9426e-06, 5.9956e-06, 5.7307e-06, 5.0432e-06,
        8.5716e-06, 6.5608e-06, 2.1890e-06, 6.8006e-06, 5.4498e-06, 3.6064e-06,
        1.7605e-06, 4.9213e-06, 8.0953e-06, 1.3432e-06, 4.2526e-06, 6.5109e-06,
        9.5004e-07, 6.4300e-06, 6.7660e-06, 2.1272e-06, 5.2425e-06, 5.2425e-06,
        6.2418e-06, 4.4436e-06, 4.9213e-06, 8.3917e-06, 3.3055e-06, 9.5355e-06,
        3.7945e-06, 2.9428e-06, 4.0672e-06, 5.8660e-06, 7.1796e-06, 4.9401e-06,
        7.2272e-06, 1.7011e-06, 1.9945e-06, 1.5995e-06, 3.6137e-06, 4.7253e-06,
        1.1700e-05, 4.1593e-06, 4.7596e-06, 2.1625e-06, 4.2718e-06, 2.9835e-06,
        8.6718e-07, 3.3797e-06, 5.9561e-06, 4.4823e-06, 3.5356e-06, 5.5608e-06,
        6.0098e-06, 3.0403e-07, 5.4826e-06, 5.9618e-06, 4.9864e-06, 2.4298e-06,
        2.6931e-06, 4.1593e-06, 4.2109e-06, 7.4590e-06, 2.1934e-06, 1.0997e-06,
        5.4021e-06, 7.2719e-06, 5.0418e-06, 6.7527e-06, 7.4507e-06, 5.7378e-06,
        8.4301e-06, 2.9345e-06, 5.4826e-06, 3.5536e-06, 5.4498e-06, 4.8159e-06,
        4.1518e-06, 4.1593e-06, 4.1280e-06, 4.8006e-06, 4.3763e-06, 4.9513e-06,
        5.7167e-06, 4.2882e-06, 3.1466e-06, 6.8232e-06, 3.6385e-06, 1.5995e-06,
        3.2607e-06, 4.1280e-06, 6.1518e-06, 4.0672e-06, 5.8342e-06, 4.1593e-06,
        2.4927e-06, 2.0176e-06, 6.7896e-06, 6.0751e-06, 2.5367e-06, 5.9677e-06,
        2.0970e-06, 9.3584e-06, 2.4927e-06, 4.4776e-06, 1.0355e-06, 6.5829e-06,
        2.6273e-06, 3.8326e-06, 7.5874e-06, 3.6467e-06, 4.3763e-06, 4.8951e-06,
        2.5749e-06, 7.9628e-06, 5.6616e-06, 2.6696e-06, 4.1280e-06, 8.0881e-06,
        1.1700e-05, 4.0205e-06, 4.2788e-06, 1.9622e-06, 8.2424e-07, 2.7092e-06,
        1.4613e-06, 9.2598e-06, 3.0696e-06, 4.1280e-06, 4.1982e-06, 6.6907e-06,
        5.8585e-06, 4.5378e-06, 5.2871e-06, 2.1244e-06, 3.3352e-06, 3.9875e-06,
        2.4329e-06, 4.1280e-06, 1.8945e-06, 5.0433e-06, 8.1932e-06, 1.3770e-05,
        2.4899e-06, 1.0130e-05, 6.1192e-06, 5.8541e-06, 3.8999e-06, 1.3432e-06,
        3.5356e-06, 4.1497e-06, 1.7745e-06, 7.4934e-06, 4.7596e-06, 4.1593e-06,
        5.8559e-06, 5.4306e-06, 4.9078e-06, 4.4436e-06, 5.0717e-06, 3.5356e-06,
        5.6174e-06, 7.4825e-06, 1.2110e-05, 2.5921e-06, 1.5821e-06, 3.6612e-06,
        7.6885e-06, 8.2511e-07, 3.8138e-06, 8.5716e-06, 2.9778e-06, 3.5289e-06,
        2.6778e-06, 6.3521e-06, 3.4710e-06, 5.7853e-06, 3.1388e-06, 3.6781e-06,
        1.5051e-05, 4.8964e-06, 2.3830e-06, 5.6616e-06, 9.4630e-06, 7.4774e-06,
        2.1540e-06, 6.5712e-07, 1.6287e-06, 5.0188e-06, 8.5246e-06, 2.6069e-06,
        4.8825e-06, 2.0223e-06, 2.6977e-06, 1.5821e-06, 2.6549e-06, 8.4651e-06,
        1.8579e-06, 4.6681e-06, 4.4710e-06, 5.1051e-06, 4.2109e-06, 5.6252e-06,
        6.5712e-07, 6.1845e-06, 5.9729e-06, 3.6536e-06, 4.1518e-06, 4.1280e-06,
        3.6619e-06, 5.1986e-06, 3.0401e-07, 2.0622e-06, 3.0063e-06, 4.2205e-06,
        6.2385e-06, 4.9513e-06, 4.1518e-06, 4.3361e-06, 5.1980e-06, 3.1638e-06,
        1.8750e-06, 1.5525e-06, 1.3909e-06, 4.1593e-06, 2.5355e-06, 2.6415e-06,
        4.2887e-06, 3.0063e-06, 7.0675e-06, 1.9851e-06, 3.1638e-06, 5.4306e-06,
        9.3584e-06, 2.1535e-06, 1.6601e-06, 5.7736e-06, 9.5355e-06, 6.7070e-06,
        2.3117e-06, 4.0764e-06, 7.1778e-06, 1.5995e-06, 4.8950e-06, 3.7600e-06,
        2.9025e-06, 2.9025e-06, 4.4624e-06, 3.7221e-06, 1.9702e-06, 8.6718e-07,
        6.3932e-06, 4.8959e-06, 3.6612e-06, 5.9278e-06, 3.2388e-06, 4.7253e-06,
        1.8750e-06, 3.6826e-06, 9.4630e-06, 4.1280e-06, 1.7772e-06, 7.2364e-06,
        4.3763e-06, 2.7122e-06, 5.1501e-06, 7.0109e-06, 7.0109e-06, 6.9636e-06,
        8.4651e-06, 4.4217e-06, 2.6039e-06, 4.1593e-06, 9.5355e-06, 2.8997e-06,
        8.3300e-06, 2.7122e-06, 8.7227e-06, 6.0789e-06, 2.3153e-06, 3.6142e-06,
        9.5355e-06, 4.0672e-06, 5.2425e-06, 2.5107e-06, 5.5118e-06, 3.1638e-06,
        6.3506e-06, 2.5947e-06, 4.1593e-06, 4.0672e-06, 3.5148e-06, 1.2356e-05,
        2.1890e-06, 1.0997e-06, 3.7600e-06, 2.7909e-06, 4.9996e-06, 1.9245e-06,
        3.6545e-06, 2.2450e-06, 4.1280e-06, 1.8361e-06, 4.2887e-06, 2.3875e-06,
        5.8670e-06, 3.2468e-06, 9.8649e-06, 3.3659e-06, 4.4106e-06, 1.7121e-06,
        5.1980e-06, 6.6907e-06, 3.8380e-06, 2.1485e-06, 5.9618e-06, 5.4272e-06,
        2.4298e-06, 1.4005e-06, 3.8363e-06, 3.6064e-06, 3.5536e-06, 1.4864e-06,
        2.7501e-06, 2.7128e-06, 4.1280e-06, 4.9513e-06, 3.6826e-06, 5.2083e-06,
        4.4625e-06, 7.2420e-06, 5.5798e-06, 3.9262e-06, 4.1593e-06, 5.9425e-06,
        2.5367e-06, 1.8750e-06, 2.2256e-06, 4.5380e-06, 5.0433e-06, 8.7274e-06,
        2.8796e-06, 5.5873e-06, 7.7339e-06, 1.6225e-06, 6.6161e-06, 7.5383e-06,
        5.7999e-06, 9.2401e-06, 2.8002e-06, 2.2086e-06, 3.3764e-06, 7.7544e-06,
        4.3763e-06, 5.9948e-06, 6.4830e-06, 6.6779e-06, 4.1661e-06, 6.7660e-06,
        2.5921e-06, 3.6539e-06, 4.8169e-07, 3.6545e-06, 2.0708e-06, 8.1798e-06,
        4.1280e-06, 4.8484e-06, 2.6049e-06, 5.8181e-06, 3.1142e-06, 3.6590e-06,
        3.2388e-06, 2.6083e-06, 1.0130e-05, 4.9513e-06, 5.4502e-06, 1.7280e-06,
        6.0620e-06, 2.5367e-06, 4.3363e-06, 2.6735e-06, 2.8180e-06, 7.0109e-06,
        3.7725e-06, 3.5646e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([8.1439e-06, 6.3884e-06, 6.2305e-06, 9.3220e-06, 1.9061e-05, 3.9331e-06,
        1.2016e-05, 1.6606e-05, 7.9231e-06, 2.1253e-06, 1.0017e-06, 1.2788e-05,
        1.8596e-05, 1.3059e-05, 1.2636e-05, 1.3940e-05, 4.5339e-06, 1.5080e-05,
        1.1837e-05, 1.8302e-05, 1.0694e-05, 1.0559e-05, 1.0607e-05, 9.4927e-06,
        2.1900e-05, 1.1837e-05, 6.4341e-06, 4.7409e-06, 1.5723e-05, 5.9222e-06,
        1.3668e-05, 6.2305e-06, 4.9816e-06, 3.8835e-06, 9.6316e-06, 5.6572e-06,
        2.2277e-05, 1.1514e-05, 1.5629e-05, 9.1031e-06, 1.5911e-05, 1.2923e-05,
        6.3549e-06, 3.3565e-06, 1.4410e-05, 1.2591e-05, 1.0803e-05, 1.8700e-05,
        8.9252e-06, 2.1841e-05, 3.6936e-06, 9.9208e-06, 1.1459e-05, 6.2524e-06,
        3.9043e-06, 4.6528e-06, 1.1920e-05, 5.9168e-06, 8.5403e-06, 4.8454e-06,
        3.2182e-05, 1.7665e-05, 1.3917e-05, 1.2859e-05, 1.5542e-05, 5.5015e-06,
        8.6360e-06, 9.9503e-06, 2.1786e-05, 1.9086e-05, 7.5658e-06, 5.6078e-06,
        6.3967e-06, 1.0113e-06, 6.2214e-06, 1.0668e-05, 4.5816e-06, 1.7317e-05,
        1.6017e-05, 9.4124e-06, 9.1031e-06, 8.5403e-06, 5.3290e-06, 6.2498e-06,
        6.0129e-06, 1.7779e-05, 1.5824e-05, 4.8454e-06, 2.6185e-05, 8.3071e-06,
        1.7701e-05, 9.6316e-06, 5.2279e-06, 1.3119e-05, 5.1018e-06, 5.7759e-06,
        1.2503e-05, 9.4529e-06, 9.4927e-06, 3.4264e-06, 6.5178e-06, 9.7717e-06,
        5.6450e-06, 5.8139e-06, 3.1688e-06, 1.3536e-05, 1.4418e-05, 1.4395e-05,
        4.8942e-06, 1.5360e-05, 1.1134e-05, 4.7564e-06, 1.1454e-05, 6.4981e-06,
        4.1321e-06, 8.9020e-06, 7.1661e-06, 1.3536e-05, 2.1642e-05, 3.3952e-06,
        1.2016e-05, 5.5713e-06, 1.3559e-05, 1.4251e-05, 5.6078e-06, 7.8704e-06,
        1.9114e-05, 1.0425e-05, 1.5007e-05, 1.2307e-05, 1.2193e-05, 1.5441e-05,
        4.8454e-06, 4.5339e-06, 4.0066e-06, 1.9473e-05, 5.4035e-06, 1.5077e-05,
        8.5031e-06, 5.6071e-06, 9.9208e-06, 5.9168e-06, 8.9593e-06, 4.9757e-06,
        3.9221e-06, 3.7604e-06, 8.1439e-06, 3.7758e-06, 4.5339e-06, 3.5872e-06,
        6.7740e-06, 8.5031e-06, 3.5288e-06, 1.5080e-05, 1.3214e-06, 7.3025e-06,
        1.1425e-05, 5.1018e-06, 1.1487e-05, 5.1859e-06, 1.5176e-05, 4.8454e-06,
        9.5627e-06, 1.0956e-05, 5.9168e-06, 4.5338e-06, 1.1250e-05, 1.9673e-05,
        5.7144e-06, 1.3115e-05, 5.8396e-06, 2.6185e-05, 1.2016e-05, 5.9521e-06,
        1.0407e-05, 3.7307e-06, 1.0151e-05, 3.1512e-06, 1.1556e-05, 1.8712e-05,
        9.7481e-06, 6.6300e-06, 8.6664e-06, 1.2016e-05, 1.1487e-05, 1.5481e-05,
        7.9365e-06, 3.3952e-06, 1.8610e-05, 1.1139e-05, 7.3656e-06, 4.5338e-06,
        1.8739e-05, 1.3865e-05, 5.5158e-06, 1.6904e-05, 1.1771e-05, 3.7604e-06,
        6.5844e-06, 2.4549e-05, 2.7281e-07, 1.2100e-05, 6.3884e-06, 5.4035e-06,
        8.5031e-06, 1.5135e-05, 5.6631e-06, 1.3311e-05, 7.5919e-06, 7.9253e-06,
        8.5604e-06, 2.9500e-06, 7.0957e-06, 6.0006e-06, 1.1771e-05, 3.2367e-06,
        2.7745e-05, 1.1837e-05, 1.0271e-05, 6.0129e-06, 6.2898e-06, 1.0068e-05,
        6.7763e-06, 6.2898e-06, 6.5714e-06, 5.1018e-06, 2.4826e-06, 7.5157e-06,
        1.1426e-05, 4.5643e-06, 1.4390e-05, 1.1425e-05, 8.4176e-06, 3.6638e-06,
        9.6316e-06, 4.8142e-06, 1.9958e-05, 9.7445e-06, 1.1425e-05, 1.0834e-05,
        1.8302e-05, 1.9417e-05, 1.1737e-05, 3.8743e-06, 1.9061e-05, 5.8178e-06,
        7.6103e-06, 7.8395e-06, 5.0472e-06, 1.7983e-05, 6.7225e-06, 1.8302e-05,
        1.2358e-05, 1.0322e-05, 5.6078e-06, 6.7851e-06, 1.0800e-05, 7.9968e-06,
        8.7484e-06, 9.1031e-06, 5.6078e-06, 1.1766e-05, 8.5962e-06, 1.7108e-05,
        1.0084e-05, 1.1459e-05, 2.1786e-05, 6.0039e-06, 5.5158e-06, 1.0274e-05,
        8.8443e-06, 9.1031e-06, 1.0645e-05, 7.7371e-06, 5.9274e-06, 2.8949e-06,
        1.3668e-05, 1.6006e-05, 2.3466e-05, 5.0472e-06, 7.9418e-06, 7.9231e-06,
        1.9958e-05, 1.0408e-05, 1.5034e-05, 9.8915e-06, 5.8216e-06, 2.3029e-05,
        7.5893e-06, 8.5031e-06, 1.0425e-05, 9.6316e-06, 5.6085e-06, 1.4181e-05,
        1.4622e-05, 1.2345e-05, 9.4927e-06, 8.4301e-06, 6.2305e-06, 1.1469e-05,
        6.5844e-06, 5.9168e-06, 7.1852e-06, 1.3214e-05, 3.2132e-05, 5.5713e-06,
        5.5851e-06, 1.3677e-05, 9.6316e-06, 1.2324e-05, 7.0104e-06, 6.5714e-06,
        8.4868e-06, 9.4124e-06, 7.9418e-06, 5.3216e-06, 1.0417e-05, 1.1124e-05,
        1.8596e-05, 5.7231e-06, 8.5294e-06, 1.9441e-05, 7.1617e-06, 2.2227e-05,
        1.3518e-05, 1.7407e-05, 8.9443e-06, 6.7034e-06, 1.2527e-05, 1.2016e-05,
        1.2092e-05, 1.1630e-05, 1.5480e-05, 1.1487e-05, 9.6315e-06, 1.1425e-05,
        1.3289e-05, 2.6900e-06, 1.1862e-05, 9.4745e-06, 1.5758e-05, 3.6194e-06,
        5.7144e-06, 7.5724e-06, 5.3369e-06, 7.2746e-06, 1.5093e-05, 1.2413e-05,
        6.1303e-06, 5.6078e-06, 6.0236e-06, 8.9983e-07, 7.0957e-06, 1.9103e-05,
        1.2772e-05, 4.1069e-06, 1.1030e-05, 8.6017e-06, 3.3475e-06, 1.5227e-05,
        3.1512e-06, 9.6906e-06, 3.2354e-06, 1.2012e-05, 9.1221e-06, 1.6830e-05,
        1.0006e-05, 8.5294e-06, 2.1253e-06, 7.9968e-06, 4.9787e-06, 1.1608e-05,
        1.5093e-05, 1.4402e-05, 6.7740e-06, 1.0416e-05, 9.4926e-06, 7.9600e-06,
        5.0426e-06, 9.3183e-06, 1.6265e-05, 1.9478e-05, 4.5643e-06, 7.5658e-06,
        1.0068e-05, 1.3546e-05, 1.0006e-05, 6.2305e-06, 9.6315e-06, 1.4050e-05,
        1.5135e-05, 6.4981e-06, 9.1031e-06, 1.6617e-05, 1.4181e-05, 8.9593e-06,
        1.5305e-05, 9.6492e-06, 8.3209e-06, 9.1221e-06, 1.8302e-05, 5.6078e-06,
        1.8557e-05, 1.1331e-05, 2.9921e-06, 3.6194e-06, 1.0913e-05, 1.3668e-05,
        1.4181e-05, 5.6078e-06, 9.1221e-06, 4.1069e-06, 7.5489e-06, 6.2214e-06,
        9.4927e-06, 1.2686e-05, 1.1864e-05, 4.0196e-06, 2.2999e-05, 8.8010e-06,
        1.4141e-05, 1.2530e-05, 6.5844e-06, 8.6454e-06, 1.3896e-05, 5.9168e-06,
        6.4341e-06, 2.5896e-05, 1.2672e-05, 6.7968e-06, 1.1487e-05, 9.4927e-06,
        8.6355e-06, 1.0559e-05, 7.2774e-06, 7.5107e-06, 2.1841e-05, 3.9388e-06,
        1.4552e-05, 5.6078e-06, 8.3522e-06, 1.3126e-05, 1.1514e-05, 8.7718e-06,
        9.6906e-06, 1.0499e-05, 1.1940e-05, 1.6490e-05, 8.5604e-06, 5.8139e-06,
        8.2055e-06, 6.5844e-06, 1.7053e-05, 1.1070e-05, 9.8154e-06, 1.4915e-05,
        1.9473e-05, 4.0066e-06, 8.3209e-06, 7.6814e-06, 9.7445e-06, 8.5403e-06,
        1.0879e-05, 2.1841e-05, 1.1431e-05, 1.0800e-05, 1.0417e-05, 4.9817e-06,
        6.3581e-06, 9.7989e-06, 1.1487e-05, 1.8302e-05, 1.1705e-05, 4.5339e-06,
        1.1725e-05, 6.6512e-06, 1.5983e-05, 1.6363e-05, 1.0520e-05, 5.8535e-06,
        5.3116e-06, 1.1425e-05, 3.6936e-06, 1.3783e-05, 2.1563e-05, 1.6061e-06,
        1.1023e-05, 3.3952e-06, 9.5203e-06, 1.2518e-05, 5.5666e-06, 9.7989e-06,
        1.3726e-05, 5.7144e-06, 1.0739e-05, 6.2305e-06, 1.2530e-05, 4.6035e-06,
        1.0775e-05, 1.0949e-05, 5.0998e-06, 1.0498e-05, 1.9061e-05, 1.7885e-05,
        8.3838e-06, 9.5627e-06, 1.2230e-05, 1.2176e-05, 1.2608e-05, 3.7604e-06,
        6.7740e-06, 1.0938e-05], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([5.1800e-07, 7.2876e-07, 4.0070e-07,  ..., 4.4273e-07, 1.2780e-06,
        1.6299e-06], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.2429, 1.4354, 1.2137, 1.1692, 1.3233, 1.2021, 1.4722, 1.1835, 1.3659,
        1.1918, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211,
        0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211,
        0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211,
        0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211,
        0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211,
        0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211,
        0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211,
        0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211,
        0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211,
        0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211, 0.0211,
        0.0211], device='cuda:0', grad_fn=<NormBackward1>)

 sparsity of   [0.0, 0.0, 0.0, 0.0, 1.0, 0.03703703731298447, 1.0, 0.0, 0.03703703731298447, 0.03703703731298447, 0.6666666865348816, 0.0, 0.0, 0.03703703731298447, 0.03703703731298447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.03703703731298447, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03703703731298447, 0.03703703731298447, 0.0, 0.03703703731298447, 0.0, 0.1111111119389534, 0.0, 0.0, 0.0, 0.07407407462596893, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]

 sparsity of   [1.0, 0.203125, 0.203125, 1.0, 0.25, 0.203125, 0.203125, 0.203125, 0.21875, 0.21875, 0.21875, 1.0, 0.203125, 0.234375, 1.0, 1.0, 1.0, 0.203125, 0.203125, 0.28125, 0.203125, 0.203125, 0.21875, 0.203125, 1.0, 0.21875, 1.0, 1.0, 0.21875, 0.234375, 1.0, 0.203125, 0.203125, 0.21875, 1.0, 1.0, 1.0, 0.21875, 0.21875, 1.0, 1.0, 0.21875, 0.234375, 0.21875, 0.296875, 0.21875, 1.0, 0.203125, 0.203125, 1.0, 0.21875, 0.203125, 0.21875, 1.0, 1.0, 1.0, 0.234375, 1.0, 0.203125, 1.0, 0.21875, 0.296875, 0.234375, 0.25]

 sparsity of   [0.3611111044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.347222238779068, 1.0, 1.0, 0.3923611044883728, 1.0, 0.3420138955116272, 0.347222238779068, 0.3489583432674408, 0.3506944477558136, 0.3489583432674408, 1.0, 1.0, 1.0, 1.0, 0.3489583432674408, 0.34375, 1.0, 1.0, 1.0, 0.3489583432674408, 1.0, 1.0, 0.3454861044883728, 0.3524305522441864, 1.0, 1.0, 1.0, 1.0, 1.0, 0.347222238779068, 0.3454861044883728, 1.0, 0.3506944477558136, 0.3524305522441864, 1.0, 1.0, 0.3420138955116272, 0.3506944477558136, 0.3489583432674408, 0.3645833432674408, 0.3454861044883728, 0.3541666567325592, 0.347222238779068, 0.3506944477558136, 1.0, 0.3454861044883728, 1.0, 0.3489583432674408, 1.0, 1.0, 0.3489583432674408, 0.3489583432674408, 1.0, 0.3506944477558136, 0.34375, 0.3576388955116272]

 sparsity of   [0.484375, 0.5, 0.5, 1.0, 0.5, 0.484375, 0.515625, 0.5, 1.0, 0.484375, 0.515625, 1.0, 1.0, 0.5, 1.0, 0.5, 0.484375, 1.0, 0.5, 0.5, 0.484375, 0.515625, 1.0, 1.0, 0.484375, 1.0, 0.515625, 0.5, 0.5, 0.5, 0.484375, 0.5, 0.484375, 0.484375, 0.484375, 0.5, 1.0, 1.0, 0.46875, 0.5, 0.5, 0.484375, 0.484375, 1.0, 0.5, 1.0, 0.5, 0.515625, 0.5, 0.5, 0.484375, 1.0, 0.5, 1.0, 0.5, 0.46875, 0.53125, 0.5, 0.484375, 0.484375, 0.515625, 0.484375, 0.46875, 0.5, 0.484375, 1.0, 1.0, 1.0, 0.484375, 0.5, 1.0, 0.484375, 0.5, 0.5, 0.46875, 1.0, 0.5, 0.53125, 1.0, 0.484375, 0.484375, 0.484375, 0.484375, 0.484375, 1.0, 1.0, 0.484375, 0.484375, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.46875, 1.0, 0.484375, 0.484375, 1.0, 1.0, 0.484375, 0.515625, 0.5, 1.0, 1.0, 1.0, 0.46875, 0.46875, 1.0, 0.484375, 1.0, 0.46875, 0.484375, 1.0, 1.0, 1.0, 1.0, 0.484375, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.484375, 0.46875, 0.515625, 1.0, 0.515625, 0.46875, 1.0, 0.5, 0.484375, 0.484375, 0.5, 0.46875, 1.0, 1.0, 0.5, 1.0, 1.0, 0.484375, 0.484375, 1.0, 0.515625, 0.5, 0.5, 0.484375, 1.0, 0.484375, 0.5, 0.484375, 0.5, 0.5, 1.0, 1.0, 0.484375, 0.515625, 0.484375, 1.0, 0.515625, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 0.484375, 0.484375, 0.484375, 1.0, 0.5625, 0.5, 0.515625, 0.515625, 0.484375, 1.0, 1.0, 0.5, 0.5, 0.5, 0.515625, 1.0, 0.5, 0.484375, 1.0, 0.5, 0.515625, 0.5, 1.0, 1.0, 1.0, 0.484375, 1.0, 0.484375, 0.515625, 0.515625, 0.5, 1.0, 0.484375, 0.5, 0.484375, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.46875, 1.0, 1.0, 0.5, 0.484375, 0.484375, 1.0, 0.484375, 0.484375, 0.484375, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.484375, 1.0, 0.484375, 0.5, 0.46875, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.53125, 0.515625, 0.484375, 0.5, 0.484375, 0.5]

 sparsity of   [0.265625, 0.203125, 0.21875, 0.203125, 0.234375, 0.234375, 0.21875, 0.21875, 0.265625, 0.265625, 0.203125, 0.234375, 0.296875, 0.296875, 1.0, 0.21875, 0.234375, 0.21875, 0.28125, 0.234375, 0.203125, 0.234375, 0.203125, 1.0, 0.234375, 1.0, 0.203125, 0.203125, 0.203125, 0.265625, 0.25, 0.21875, 0.21875, 0.234375, 1.0, 0.203125, 1.0, 1.0, 0.234375, 0.21875, 0.203125, 0.3125, 0.234375, 1.0, 0.234375, 0.25, 0.203125, 0.21875, 0.265625, 0.203125, 0.234375, 0.25, 0.359375, 0.21875, 0.21875, 0.234375, 0.234375, 0.265625, 0.21875, 0.203125, 0.234375, 0.234375, 0.25, 0.21875, 0.234375, 1.0, 0.21875, 1.0, 0.203125, 0.234375, 1.0, 0.28125, 0.203125, 0.234375, 0.25, 1.0, 0.203125, 0.25, 1.0, 0.234375, 0.3125, 0.21875, 0.21875, 0.203125, 1.0, 1.0, 0.21875, 0.203125, 0.21875, 1.0, 1.0, 0.234375, 1.0, 0.25, 0.203125, 0.265625, 0.25, 0.25, 0.21875, 0.21875, 1.0, 1.0, 0.21875, 0.21875, 0.21875, 1.0, 0.21875, 0.203125, 0.25, 0.25, 0.21875, 0.25, 1.0, 0.234375, 0.234375, 0.265625, 1.0, 0.21875, 1.0, 0.203125, 1.0, 0.203125, 0.203125, 0.203125, 0.25, 0.21875, 0.203125, 0.21875, 0.21875, 0.21875, 0.203125, 1.0, 0.25, 0.21875, 1.0, 0.28125, 0.21875, 0.328125, 0.21875, 0.21875, 1.0, 0.21875, 0.28125, 0.21875, 0.40625, 0.28125, 0.203125, 0.234375, 0.203125, 0.234375, 0.203125, 0.21875, 1.0, 0.203125, 1.0, 0.21875, 0.265625, 0.40625, 1.0, 1.0, 0.25, 0.203125, 0.25, 1.0, 0.21875, 0.265625, 1.0, 0.203125, 0.203125, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.21875, 0.234375, 0.25, 1.0, 0.21875, 0.234375, 0.25, 0.203125, 0.21875, 1.0, 1.0, 0.265625, 0.234375, 0.21875, 0.21875, 1.0, 0.21875, 0.21875, 0.21875, 0.25, 0.203125, 0.203125, 0.234375, 1.0, 1.0, 0.203125, 1.0, 0.203125, 0.25, 0.234375, 0.21875, 1.0, 0.203125, 0.203125, 0.21875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.203125, 0.203125, 1.0, 1.0, 0.265625, 0.203125, 0.234375, 0.203125, 0.234375, 0.25, 0.421875, 0.203125, 1.0, 0.28125, 1.0, 1.0, 0.203125, 1.0, 0.21875, 0.234375, 1.0, 0.203125, 0.203125, 0.25, 1.0, 1.0, 0.21875, 1.0, 1.0, 1.0, 0.203125, 1.0, 1.0, 0.21875, 0.21875, 1.0, 0.21875, 0.21875, 0.21875, 0.21875]

 sparsity of   [1.0, 0.2421875, 0.22265625, 1.0, 1.0, 1.0, 0.24609375, 1.0, 1.0, 0.2421875, 1.0, 1.0, 1.0, 0.21875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.23828125, 1.0, 1.0, 0.30078125, 1.0, 0.25390625, 0.24609375, 0.23046875, 0.23046875, 1.0, 0.23046875, 1.0, 1.0, 1.0, 0.22265625, 1.0, 0.21875, 0.22265625, 0.2265625, 1.0, 0.21875, 0.234375, 0.2734375, 0.24609375, 1.0, 0.22265625, 1.0, 0.23046875, 1.0, 1.0, 0.24609375, 0.22265625, 0.234375, 0.22265625, 1.0, 1.0, 1.0, 1.0, 0.234375]

 sparsity of   [1.0, 0.5642361044883728, 1.0, 1.0, 0.5607638955116272, 1.0, 0.585069477558136, 0.5677083134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5729166865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5555555820465088, 1.0, 1.0, 0.5815972089767456, 0.5677083134651184, 0.553819477558136, 0.5868055820465088, 0.5572916865348816, 1.0, 1.0, 0.5815972089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5729166865348816, 1.0, 0.59375, 1.0, 1.0, 0.5677083134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5572916865348816, 1.0, 0.5486111044883728, 0.5590277910232544, 0.569444477558136, 1.0, 1.0, 1.0, 0.5503472089767456]

 sparsity of   [0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.671875, 0.671875, 0.671875, 1.0, 0.671875, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 1.0, 1.0, 0.6875, 0.703125, 0.6875, 1.0, 1.0, 0.6875, 1.0, 1.0, 1.0, 0.671875, 0.6875, 0.671875, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.671875, 0.65625, 0.703125, 1.0, 0.671875, 1.0, 0.6875, 0.65625, 0.671875, 1.0, 1.0, 0.671875, 0.6875, 0.65625, 0.6875, 0.671875, 1.0, 1.0, 0.671875, 0.6875, 1.0, 0.65625, 0.6875, 0.671875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.671875, 0.6875, 0.671875, 0.671875, 1.0, 0.671875, 0.65625, 0.6875, 0.65625, 0.703125, 0.6875, 1.0, 0.65625, 0.65625, 0.6875, 0.65625, 0.6875, 1.0, 1.0, 0.703125, 0.65625, 0.6875, 1.0, 1.0, 0.671875, 1.0, 1.0, 0.734375, 1.0, 0.6875, 1.0, 0.6875, 0.65625, 1.0, 0.6875, 1.0, 0.6875, 0.671875, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.671875, 1.0, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 0.671875, 1.0, 1.0, 1.0, 0.6875, 0.6875, 0.703125, 0.671875, 1.0, 0.65625, 0.6875, 1.0, 1.0, 0.6875, 0.671875, 1.0, 1.0, 0.671875, 1.0, 0.6875, 1.0, 1.0, 1.0, 0.671875, 1.0, 0.6875, 0.6875, 0.671875, 0.703125, 0.671875, 0.6875, 1.0, 0.671875, 1.0, 0.6875, 1.0, 1.0, 0.671875, 0.6875, 1.0, 1.0, 0.703125, 1.0, 0.671875, 0.6875, 0.6875, 1.0, 0.65625, 1.0, 1.0, 0.671875, 1.0, 1.0, 1.0, 0.671875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 0.65625, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.671875, 1.0, 1.0, 0.671875, 0.671875, 1.0, 1.0, 0.671875, 0.671875, 1.0, 0.671875, 1.0, 0.671875, 0.6875, 0.6875, 0.6875, 0.65625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 1.0, 1.0, 0.65625, 0.6875, 0.6875, 0.703125, 1.0, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6875, 0.671875, 0.671875, 0.703125, 1.0, 0.671875, 0.703125, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.671875, 1.0, 1.0, 0.6875, 1.0, 0.671875, 0.65625, 0.671875, 0.671875]

 sparsity of   [1.0, 1.0, 0.15625, 0.171875, 1.0, 1.0, 0.140625, 1.0, 0.15625, 0.17578125, 1.0, 0.1875, 0.16796875, 1.0, 1.0, 0.15234375, 0.15234375, 1.0, 0.16015625, 1.0, 0.19140625, 1.0, 0.16796875, 1.0, 0.1484375, 0.1640625, 0.1484375, 0.17578125, 0.15234375, 0.15234375, 1.0, 0.15625, 1.0, 0.1484375, 0.171875, 1.0, 1.0, 1.0, 1.0, 0.17578125, 1.0, 1.0, 1.0, 0.15625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16796875, 1.0, 0.14453125, 0.14453125, 1.0, 1.0, 0.1484375, 1.0, 0.1640625, 1.0, 0.1796875, 1.0, 0.15625, 1.0, 1.0]

 sparsity of   [0.5416666865348816, 0.5190972089767456, 0.5277777910232544, 0.5295138955116272, 0.5243055820465088, 0.5277777910232544, 1.0, 1.0, 0.5347222089767456, 1.0, 1.0, 1.0, 0.5190972089767456, 1.0, 1.0, 0.5434027910232544, 1.0, 0.5208333134651184, 0.5295138955116272, 1.0, 0.5277777910232544, 0.5295138955116272, 1.0, 0.5260416865348816, 0.5243055820465088, 0.5260416865348816, 0.5295138955116272, 1.0, 0.5277777910232544, 1.0, 0.5208333134651184, 1.0, 0.522569477558136, 0.5295138955116272, 0.5364583134651184, 0.53125, 0.553819477558136, 0.5399305820465088, 0.5399305820465088, 0.8246527910232544, 1.0, 1.0, 1.0, 0.5347222089767456, 1.0, 0.5260416865348816, 0.515625, 1.0, 1.0, 1.0, 0.538194477558136, 0.5434027910232544, 0.5364583134651184, 1.0, 1.0, 0.5347222089767456, 0.5243055820465088, 0.53125, 0.5434027910232544, 0.5555555820465088, 1.0, 1.0, 0.5434027910232544, 1.0]

 sparsity of   [0.375, 1.0, 1.0, 1.0, 1.0, 0.375, 0.390625, 0.40625, 1.0, 0.40625, 0.390625, 0.390625, 1.0, 0.375, 0.375, 0.390625, 0.40625, 0.390625, 0.421875, 1.0, 0.390625, 0.40625, 1.0, 0.359375, 0.359375, 0.375, 0.359375, 1.0, 0.40625, 1.0, 0.390625, 0.40625, 0.40625, 0.375, 0.40625, 1.0, 0.359375, 0.359375, 0.359375, 0.390625, 0.390625, 0.390625, 0.375, 0.375, 0.390625, 1.0, 0.390625, 0.390625, 0.359375, 0.375, 0.375, 0.40625, 0.359375, 1.0, 0.4375, 0.375, 0.375, 0.421875, 0.375, 0.375, 0.390625, 0.375, 0.375, 1.0, 0.390625, 0.375, 0.40625, 0.375, 0.359375, 0.390625, 0.40625, 0.390625, 0.375, 0.390625, 0.390625, 0.40625, 0.375, 0.359375, 0.359375, 0.375, 0.359375, 0.375, 0.40625, 0.375, 0.375, 1.0, 0.40625, 0.390625, 0.375, 0.359375, 0.375, 0.421875, 1.0, 1.0, 0.375, 1.0, 0.375, 1.0, 0.359375, 0.359375, 0.359375, 0.375, 1.0, 1.0, 0.40625, 0.390625, 1.0, 1.0, 0.40625, 0.390625, 1.0, 0.390625, 1.0, 0.375, 0.390625, 1.0, 0.359375, 0.40625, 0.359375, 1.0, 1.0, 0.390625, 0.375, 0.375, 1.0, 0.421875, 0.40625, 0.375, 0.375, 0.40625, 0.4375, 0.375, 0.40625, 0.40625, 0.375, 1.0, 0.375, 0.359375, 0.390625, 0.359375, 0.375, 1.0, 0.390625, 0.40625, 1.0, 1.0, 0.359375, 1.0, 0.375, 0.390625, 0.375, 0.390625, 0.421875, 0.359375, 1.0, 0.390625, 0.359375, 1.0, 0.359375, 1.0, 0.390625, 0.375, 0.390625, 0.359375, 0.375, 1.0, 0.359375, 0.40625, 0.390625, 1.0, 0.359375, 1.0, 0.375, 1.0, 1.0, 1.0, 0.390625, 0.359375, 0.421875, 0.359375, 0.390625, 0.390625, 1.0, 0.40625, 0.375, 1.0, 0.390625, 1.0, 0.375, 0.390625, 0.40625, 1.0, 0.40625, 1.0, 0.421875, 0.375, 0.390625, 0.359375, 0.375, 0.359375, 0.359375, 0.375, 0.390625, 0.390625, 0.40625, 0.390625, 0.40625, 1.0, 0.390625, 0.390625, 0.375, 0.359375, 0.375, 1.0, 0.390625, 0.359375, 0.390625, 0.375, 0.390625, 0.390625, 0.390625, 0.375, 0.390625, 1.0, 0.375, 1.0, 0.359375, 0.40625, 1.0, 1.0, 0.359375, 0.359375, 0.375, 0.40625, 0.390625, 0.40625, 1.0, 0.375, 0.375, 0.375, 0.359375, 0.375, 0.390625, 0.40625, 0.375, 1.0, 0.359375, 0.375, 0.375, 1.0, 0.375, 1.0, 0.375, 0.40625, 0.375, 0.40625]

 sparsity of   [0.02734375, 1.0, 1.0, 0.03515625, 0.03125, 1.0, 0.0625, 1.0, 1.0, 0.03125, 1.0, 0.01953125, 1.0, 1.0, 1.0, 1.0, 0.01953125, 1.0, 1.0, 1.0, 1.0, 0.02734375, 1.0, 1.0, 1.0, 0.02734375, 1.0, 1.0, 0.03125, 0.03515625, 1.0, 1.0, 0.0390625, 0.01953125, 0.02734375, 0.0546875, 0.03515625, 1.0, 1.0, 0.03125, 0.015625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0234375, 1.0, 0.03515625, 1.0, 1.0, 0.02734375, 0.015625, 0.03515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0234375, 1.0, 1.0, 0.0234375, 1.0, 1.0, 0.03515625, 0.0234375, 1.0, 0.08984375, 1.0, 0.03515625, 1.0, 1.0, 0.05078125, 0.03515625, 0.02734375, 0.01953125, 1.0, 1.0, 0.03515625, 0.03125, 0.0234375, 1.0, 0.02734375, 1.0, 0.03125, 1.0, 0.0390625, 0.01953125, 0.01953125, 1.0, 1.0, 0.02734375, 0.01953125, 1.0, 1.0, 0.01953125, 0.0234375, 0.03515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.02734375, 1.0, 1.0, 0.0234375, 1.0, 1.0, 1.0, 1.0, 0.0234375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.03515625, 1.0, 0.0546875, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 0.600694477558136, 0.6050347089767456, 0.6041666865348816, 1.0, 1.0, 1.0, 0.6032986044883728, 0.6015625, 1.0, 0.6015625, 1.0, 0.5963541865348816, 1.0, 0.6032986044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6015625, 0.6015625, 1.0, 0.6032986044883728, 0.5998263955116272, 1.0, 1.0, 1.0, 1.0, 0.6050347089767456, 1.0, 1.0, 1.0, 0.6041666865348816, 1.0, 0.6024305820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6032986044883728, 1.0, 1.0, 1.0, 1.0, 0.5989583134651184, 1.0, 0.6032986044883728, 1.0, 1.0, 1.0, 1.0, 0.5998263955116272, 1.0, 0.600694477558136, 1.0, 1.0, 0.6041666865348816, 1.0, 0.6050347089767456, 0.6041666865348816, 0.5989583134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6015625, 1.0, 1.0, 1.0, 1.0, 0.6032986044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5998263955116272, 1.0, 0.6059027910232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5972222089767456, 0.6032986044883728, 0.6041666865348816, 1.0, 1.0, 0.6076388955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6024305820465088, 0.600694477558136, 1.0, 1.0, 0.5989583134651184, 0.6041666865348816, 0.6041666865348816, 1.0, 1.0, 1.0, 1.0, 0.6041666865348816, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 0.6796875, 1.0, 0.6953125, 0.703125, 1.0, 0.6953125, 1.0, 0.6875, 1.0, 0.703125, 1.0, 1.0, 0.6875, 1.0, 1.0, 0.6875, 1.0, 1.0, 0.6875, 0.6953125, 1.0, 1.0, 0.6875, 0.6953125, 0.6953125, 0.703125, 1.0, 0.703125, 0.6953125, 1.0, 1.0, 1.0, 0.6875, 0.734375, 1.0, 1.0, 0.6875, 0.6796875, 0.6875, 0.6953125, 0.6953125, 1.0, 0.6953125, 1.0, 1.0, 1.0, 0.6953125, 0.6875, 1.0, 0.703125, 0.6875, 0.6953125, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6796875, 0.6875, 0.6875, 1.0, 1.0, 1.0, 0.6875, 0.6875, 0.6796875, 0.6875, 1.0, 0.6953125, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6953125, 1.0, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 0.7109375, 0.6875, 1.0, 0.6796875, 0.703125, 0.6875, 0.703125, 0.703125, 0.6953125, 0.703125, 0.6875, 0.6796875, 0.703125, 1.0, 1.0, 0.6953125, 1.0, 1.0, 1.0, 0.703125, 0.703125, 1.0, 0.6875, 0.6953125, 0.703125, 0.7109375, 0.6796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6796875, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6953125, 0.6953125, 0.6796875, 1.0, 1.0, 0.6953125, 0.6953125, 0.703125, 0.703125, 1.0, 1.0, 0.6953125, 0.6953125, 0.6875, 0.6796875, 0.6953125, 1.0, 1.0, 0.6875, 0.6875, 0.703125, 1.0, 0.6796875, 0.6875, 1.0, 0.703125, 1.0, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.6953125, 0.6875, 1.0, 0.6953125, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6953125, 1.0, 0.703125, 1.0, 0.6875, 0.6875, 0.6953125, 1.0, 0.6875, 0.703125, 1.0, 1.0, 0.6875, 1.0, 0.6875, 0.703125, 1.0, 1.0, 0.6796875, 1.0, 0.6875, 1.0, 1.0, 0.6953125, 1.0, 1.0, 0.6953125, 0.6875, 1.0, 0.703125, 0.6875, 0.6796875, 0.6875, 1.0, 0.6875, 0.6953125, 0.6953125, 1.0, 1.0, 0.6953125, 0.6875, 0.7109375, 0.703125, 1.0, 0.703125, 1.0, 0.6875, 0.7109375, 1.0, 0.6875, 0.703125, 0.703125, 0.6953125, 0.6953125, 0.6875, 0.703125, 0.6875, 0.703125, 0.6875, 0.7109375, 0.6875, 0.671875, 1.0, 1.0, 1.0, 0.6953125, 0.6875, 0.6953125, 1.0, 0.6875, 1.0, 1.0, 1.0, 0.703125, 0.6953125, 0.6953125, 1.0, 1.0, 0.6875, 0.703125, 0.6875, 0.6796875, 0.6875, 0.6875, 0.6953125, 1.0, 1.0, 0.703125, 0.6953125, 1.0, 1.0, 0.6875, 0.6875, 1.0, 0.6953125, 0.6796875, 0.703125, 0.6953125, 0.6875, 0.6953125, 0.6875, 0.703125, 0.6875, 0.6953125, 0.6953125, 0.6875, 0.6953125, 0.6875, 1.0, 1.0, 0.6953125, 0.6796875, 0.6875, 0.6953125, 0.6875, 0.6953125, 0.6875, 0.703125, 1.0, 0.6953125, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.7109375, 0.6875, 0.6796875, 0.6953125, 1.0, 0.6875, 1.0, 1.0, 0.6953125, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6796875, 0.6953125, 0.6875, 0.6875, 0.6953125, 1.0, 0.6875, 0.6875, 1.0, 0.6953125, 0.7109375, 0.6953125, 1.0, 1.0, 0.6953125, 0.6875, 0.6953125, 0.6875, 0.703125, 0.6953125, 1.0, 1.0, 0.6875, 0.703125, 1.0, 1.0, 1.0, 0.6953125, 1.0, 0.6953125, 0.6953125, 0.6796875, 1.0, 1.0, 1.0, 0.6875, 0.6796875, 0.6875, 0.6953125, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6953125, 0.6875, 0.6875, 0.6875, 0.7109375, 1.0, 0.6953125, 0.6875, 0.6953125, 0.703125, 1.0, 0.703125, 0.6875, 1.0, 1.0, 0.703125, 1.0, 1.0, 0.6875, 0.703125, 1.0, 0.6875, 1.0, 1.0, 0.6953125, 1.0, 0.6875, 0.71875, 0.6953125, 0.7109375, 1.0, 0.6875, 1.0, 0.703125, 1.0, 0.6953125, 1.0, 0.6953125, 0.703125, 1.0, 0.6875, 1.0, 1.0, 0.6953125, 0.6875, 0.6875, 0.6953125, 0.703125, 0.6875, 0.6875, 0.6875, 0.703125, 0.6875, 0.703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6796875, 0.6875, 0.6953125, 0.6953125, 1.0, 1.0, 0.6875, 0.6875, 0.6953125, 0.703125, 0.6875, 1.0, 0.6953125, 1.0, 1.0, 1.0, 0.6953125, 1.0, 1.0, 0.6875, 0.6953125, 1.0, 0.6875, 0.703125, 0.6953125, 1.0, 1.0, 0.6796875, 0.6953125, 0.6875, 0.6953125, 1.0, 1.0, 0.6953125, 1.0, 1.0, 0.6953125, 0.7109375, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 0.6953125, 1.0, 0.6875, 0.6953125, 0.703125, 1.0, 1.0, 0.6953125, 0.6953125, 1.0, 1.0, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6796875, 0.6875, 0.6875, 1.0, 0.6953125, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.6953125, 0.6953125, 1.0, 0.6953125, 0.703125, 0.6875, 0.6953125, 1.0]

 sparsity of   [1.0, 0.0390625, 0.078125, 0.04296875, 0.03515625, 0.04296875, 0.12109375, 1.0, 0.0625, 1.0, 1.0, 1.0, 1.0, 0.0390625, 1.0, 1.0, 0.046875, 1.0, 1.0, 0.0390625, 0.05078125, 1.0, 1.0, 0.02734375, 1.0, 0.0390625, 0.0390625, 1.0, 0.01953125, 0.03125, 1.0, 1.0, 1.0, 0.046875, 0.03515625, 1.0, 1.0, 0.05078125, 0.0390625, 0.04296875, 0.046875, 0.03125, 1.0, 0.03515625, 1.0, 1.0, 1.0, 0.0390625, 0.03515625, 0.05859375, 0.02734375, 0.03515625, 0.01953125, 1.0, 0.04296875, 1.0, 1.0, 1.0, 1.0, 0.0390625, 0.03125, 0.03515625, 1.0, 1.0, 1.0, 0.04296875, 0.03515625, 0.0234375, 0.09375, 1.0, 0.03515625, 0.01953125, 1.0, 0.04296875, 0.0390625, 0.03125, 0.05078125, 1.0, 1.0, 1.0, 0.03125, 1.0, 0.046875, 0.0390625, 0.03125, 0.0390625, 0.02734375, 0.02734375, 1.0, 0.05078125, 0.03125, 0.04296875, 0.03515625, 1.0, 0.04296875, 0.109375, 0.04296875, 0.0234375, 1.0, 0.05078125, 0.03125, 1.0, 0.03125, 0.02734375, 0.03125, 0.03515625, 0.04296875, 0.0390625, 0.02734375, 1.0, 1.0, 0.09375, 1.0, 1.0, 1.0, 0.03515625, 0.0390625, 1.0, 0.03515625, 0.03515625, 0.09765625, 0.01953125, 0.02734375, 1.0, 0.05078125, 1.0, 0.0390625, 1.0, 1.0, 0.02734375, 0.046875, 0.03125, 1.0, 1.0, 1.0, 1.0, 0.0390625, 0.0625, 0.07421875, 0.0390625, 0.0390625, 1.0, 1.0, 0.046875, 0.02734375, 0.0390625, 0.02734375, 1.0, 1.0, 0.04296875, 0.05859375, 0.03515625, 0.19140625, 0.02734375, 1.0, 1.0, 0.02734375, 0.03125, 0.0546875, 1.0, 0.07421875, 0.03125, 1.0, 0.06640625, 1.0, 1.0, 1.0, 1.0, 0.11328125, 1.0, 0.04296875, 0.04296875, 1.0, 0.03125, 1.0, 0.0390625, 1.0, 0.03125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0546875, 0.03125, 1.0, 0.03125, 1.0, 0.03125, 0.16015625, 0.0234375, 1.0, 0.03515625, 1.0, 1.0, 1.0, 0.0390625, 1.0, 0.02734375, 0.03515625, 0.03515625, 1.0, 0.10546875, 1.0, 0.02734375, 0.03515625, 1.0, 0.03515625, 1.0, 0.05078125, 0.03125, 0.0390625, 1.0, 0.03125, 0.0234375, 0.03515625, 0.04296875, 1.0, 0.046875, 0.05859375, 0.03125, 1.0, 1.0, 1.0, 0.0234375, 0.02734375, 0.05078125, 1.0, 0.02734375, 1.0, 0.0390625, 1.0, 1.0, 0.03125, 0.04296875, 0.03515625, 1.0, 0.03125, 0.03515625, 0.04296875, 0.0234375, 0.02734375, 0.03515625, 0.046875, 0.0390625, 0.04296875, 1.0, 1.0, 1.0, 0.03515625, 0.02734375, 0.04296875, 1.0, 0.04296875, 1.0, 1.0, 1.0, 0.02734375, 0.03125, 0.04296875, 0.1015625, 1.0, 0.1875, 1.0, 0.0390625, 0.0625, 0.0390625, 0.05859375, 0.04296875, 1.0, 1.0, 0.02734375, 0.02734375, 0.1015625, 1.0, 0.05078125, 0.13671875, 1.0, 0.1953125, 0.03125, 0.02734375, 0.02734375, 0.05078125, 0.0390625, 0.01953125, 0.03515625, 0.0234375, 0.03125, 0.04296875, 0.02734375, 0.03125, 0.04296875, 1.0, 1.0, 0.02734375, 0.04296875, 0.140625, 1.0, 0.02734375, 0.01953125, 0.11328125, 0.02734375, 1.0, 0.0390625, 0.02734375, 0.0390625, 1.0, 1.0, 0.046875, 0.046875, 0.02734375, 0.03515625, 0.0390625, 1.0, 0.03515625, 1.0, 1.0, 0.05078125, 1.0, 0.03125, 0.0390625, 1.0, 1.0, 1.0, 0.10546875, 0.03125, 1.0, 0.046875, 0.02734375, 1.0, 0.0546875, 0.03125, 1.0, 0.0390625, 0.03125, 0.0390625, 1.0, 1.0, 0.0390625, 0.04296875, 0.02734375, 0.05078125, 0.05859375, 0.03125, 1.0, 1.0, 0.02734375, 0.05078125, 1.0, 1.0, 1.0, 0.1328125, 1.0, 0.02734375, 0.03125, 0.04296875, 1.0, 1.0, 1.0, 1.0, 0.03125, 0.03125, 1.0, 1.0, 0.03125, 0.03125, 1.0, 1.0, 0.03125, 0.046875, 0.03125, 0.03515625, 0.03515625, 0.17578125, 1.0, 0.06640625, 0.03125, 0.046875, 0.02734375, 0.046875, 0.03125, 0.0703125, 1.0, 1.0, 0.0234375, 1.0, 1.0, 0.046875, 0.0390625, 1.0, 0.0234375, 1.0, 1.0, 1.0, 0.0625, 0.1328125, 0.06640625, 0.03125, 0.02734375, 1.0, 0.04296875, 1.0, 0.02734375, 1.0, 0.046875, 1.0, 0.04296875, 0.03515625, 1.0, 0.0390625, 1.0, 1.0, 0.0234375, 0.0546875, 0.046875, 0.05078125, 0.1484375, 0.03125, 0.0390625, 0.02734375, 1.0, 0.02734375, 0.046875, 1.0, 1.0, 1.0, 1.0, 0.0390625, 1.0, 0.109375, 0.046875, 0.046875, 0.02734375, 0.03125, 1.0, 1.0, 0.0390625, 0.0546875, 0.04296875, 0.02734375, 0.02734375, 1.0, 0.02734375, 1.0, 0.03515625, 1.0, 0.078125, 1.0, 1.0, 0.0234375, 0.03125, 1.0, 0.0234375, 0.03125, 0.02734375, 1.0, 0.046875, 0.05078125, 0.03515625, 0.02734375, 0.03125, 1.0, 1.0, 0.03515625, 1.0, 1.0, 0.03515625, 0.0234375, 0.02734375, 1.0, 1.0, 0.0390625, 0.03125, 0.03515625, 0.0390625, 1.0, 0.0234375, 0.046875, 0.03125, 1.0, 0.04296875, 0.03125, 0.02734375, 1.0, 0.04296875, 1.0, 0.04296875, 0.05078125, 1.0, 1.0, 1.0, 0.046875, 0.0390625, 0.046875, 1.0, 0.03125, 0.0390625, 0.05078125, 0.02734375, 0.03515625, 0.0234375, 1.0, 0.0390625, 0.04296875, 0.07421875, 0.03515625, 1.0, 0.04296875, 0.03515625, 0.0546875, 0.04296875, 0.03515625]

 sparsity of   [0.341796875, 1.0, 0.349609375, 1.0, 0.330078125, 0.333984375, 1.0, 1.0, 1.0, 1.0, 0.33203125, 1.0, 1.0, 1.0, 0.353515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.34765625, 0.3359375, 1.0, 1.0, 1.0, 0.328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.330078125, 0.349609375, 1.0, 1.0, 0.333984375, 0.361328125, 0.326171875, 0.3359375, 1.0, 0.341796875, 1.0, 1.0, 1.0, 1.0, 0.328125, 0.32421875, 0.32421875, 0.33203125, 1.0, 1.0, 1.0, 1.0, 0.333984375, 0.328125, 1.0, 1.0, 0.3359375, 1.0, 0.341796875, 1.0, 1.0, 0.357421875, 1.0, 0.328125, 0.3359375, 1.0, 0.328125, 1.0, 0.33984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.34375, 0.33203125, 0.33203125, 0.45703125, 0.333984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.322265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.412109375, 1.0, 1.0, 0.33203125, 1.0, 1.0, 1.0, 0.333984375, 1.0, 1.0, 0.328125, 0.333984375, 1.0, 0.337890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 0.6579861044883728, 1.0, 1.0, 0.6597222089767456, 0.655381977558136, 0.6571180820465088, 0.65625, 1.0, 0.6701388955116272, 1.0, 1.0, 1.0, 0.6597222089767456, 1.0, 1.0, 1.0, 0.6571180820465088, 0.6805555820465088, 1.0, 0.65625, 1.0, 0.6579861044883728, 0.6779513955116272, 0.6579861044883728, 1.0, 0.6605902910232544, 0.6605902910232544, 1.0, 1.0, 1.0, 0.663194477558136, 1.0, 1.0, 1.0, 0.6770833134651184, 1.0, 0.6640625, 1.0, 1.0, 0.6588541865348816, 1.0, 1.0, 1.0, 0.6623263955116272, 0.65625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.65625, 1.0, 1.0, 0.655381977558136, 0.6579861044883728, 1.0, 0.6579861044883728, 1.0, 0.6571180820465088, 1.0, 1.0, 0.663194477558136, 1.0, 1.0, 1.0, 0.6640625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6597222089767456, 0.6623263955116272, 0.663194477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6579861044883728, 0.65625, 0.6649305820465088, 1.0, 1.0, 1.0, 1.0, 0.6536458134651184, 0.6588541865348816, 0.655381977558136, 0.6640625, 0.6840277910232544, 1.0, 1.0, 1.0, 0.6579861044883728, 1.0, 1.0, 0.6545138955116272, 0.6614583134651184, 0.6571180820465088, 1.0, 1.0, 0.6536458134651184, 1.0, 1.0, 0.6597222089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6623263955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6623263955116272, 0.6571180820465088, 1.0, 1.0]

 sparsity of   [1.0, 0.625, 1.0, 0.6328125, 0.6171875, 1.0, 0.6328125, 1.0, 0.6171875, 0.6171875, 1.0, 0.625, 0.625, 0.6328125, 0.625, 1.0, 0.6171875, 0.6328125, 0.6171875, 0.6328125, 1.0, 1.0, 1.0, 0.6328125, 0.625, 0.6171875, 0.6171875, 1.0, 0.625, 0.625, 0.6171875, 1.0, 1.0, 0.6171875, 0.6328125, 0.6171875, 1.0, 0.6171875, 0.625, 0.625, 0.6171875, 0.625, 0.6328125, 0.6171875, 0.625, 1.0, 1.0, 0.625, 0.625, 1.0, 0.6171875, 0.6328125, 0.6328125, 1.0, 1.0, 0.6171875, 1.0, 0.625, 1.0, 0.625, 0.6328125, 0.625, 0.6171875, 0.625, 1.0, 1.0, 0.625, 0.6171875, 0.6171875, 0.6171875, 0.625, 0.6171875, 1.0, 0.6171875, 1.0, 0.625, 0.6171875, 1.0, 1.0, 0.625, 0.625, 0.625, 0.6171875, 0.625, 0.6171875, 0.6328125, 0.6171875, 0.6171875, 0.6171875, 0.625, 0.625, 1.0, 0.6171875, 1.0, 0.6171875, 1.0, 0.625, 0.625, 0.6171875, 0.6171875, 0.625, 1.0, 0.625, 0.6171875, 0.6171875, 0.6171875, 0.625, 0.6171875, 0.625, 0.625, 1.0, 0.625, 0.6171875, 0.6171875, 0.6171875, 0.625, 0.625, 1.0, 0.625, 0.6328125, 1.0, 0.6171875, 0.6171875, 0.6171875, 0.625, 0.6171875, 1.0, 1.0, 1.0, 0.625, 0.625, 0.625, 1.0, 0.625, 1.0, 0.625, 1.0, 0.625, 0.6171875, 0.625, 0.625, 1.0, 1.0, 0.625, 0.6328125, 0.609375, 0.6171875, 0.6328125, 1.0, 0.6171875, 0.6171875, 0.6171875, 0.6171875, 0.6171875, 0.625, 0.625, 0.6171875, 0.625, 1.0, 1.0, 0.625, 0.6171875, 0.625, 1.0, 1.0, 1.0, 1.0, 0.6328125, 0.6171875, 1.0, 0.6328125, 0.625, 1.0, 0.6171875, 0.625, 1.0, 1.0, 0.640625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.6171875, 0.6171875, 0.625, 0.625, 1.0, 0.625, 1.0, 0.6171875, 0.6328125, 0.625, 0.625, 0.6484375, 0.625, 0.6171875, 1.0, 0.6328125, 1.0, 1.0, 0.625, 1.0, 1.0, 0.625, 0.625, 1.0, 0.625, 0.609375, 0.625, 0.6171875, 0.625, 0.6171875, 0.6328125, 0.625, 1.0, 0.625, 1.0, 0.6328125, 0.625, 0.625, 1.0, 0.6328125, 0.6171875, 0.6328125, 1.0, 1.0, 0.6171875, 0.6328125, 0.625, 1.0, 0.625, 0.625, 0.625, 0.6328125, 0.625, 0.6171875, 0.6171875, 0.625, 1.0, 1.0, 1.0, 1.0, 0.6171875, 0.6171875, 0.625, 1.0, 0.6171875, 1.0, 1.0, 0.625, 0.625, 0.625, 0.6328125, 0.625, 0.6171875, 0.625, 0.625, 0.625, 0.625, 0.6328125, 0.6171875, 0.625, 1.0, 1.0, 0.640625, 0.625, 1.0, 1.0, 0.625, 0.625, 1.0, 0.625, 0.6328125, 0.6328125, 0.625, 0.625, 0.6171875, 0.6171875, 0.6171875, 0.6328125, 0.625, 0.6328125, 1.0, 0.6171875, 0.6171875, 1.0, 0.6171875, 0.6328125, 0.625, 0.6328125, 1.0, 0.625, 0.6171875, 0.625, 0.6171875, 1.0, 0.6171875, 0.6171875, 0.6171875, 1.0, 0.6328125, 0.625, 0.625, 0.625, 0.6171875, 0.625, 0.625, 0.6171875, 1.0, 0.625, 0.6171875, 0.6171875, 0.6328125, 1.0, 0.6171875, 1.0, 1.0, 0.625, 0.640625, 0.6171875, 0.6171875, 0.640625, 1.0, 0.625, 0.609375, 0.625, 0.625, 0.6171875, 0.6171875, 0.6171875, 1.0, 0.625, 0.6171875, 0.6328125, 0.625, 1.0, 0.6171875, 1.0, 0.625, 0.625, 0.6171875, 0.6171875, 0.625, 1.0, 0.6171875, 1.0, 0.6171875, 0.625, 0.625, 0.6171875, 1.0, 0.6171875, 1.0, 0.6171875, 0.625, 1.0, 1.0, 0.625, 1.0, 0.625, 1.0, 0.625, 0.625, 0.625, 0.6171875, 0.640625, 0.625, 1.0, 1.0, 0.6171875, 0.625, 0.6171875, 0.625, 0.6328125, 0.625, 0.625, 1.0, 0.625, 0.6171875, 0.6171875, 0.6171875, 1.0, 1.0, 0.625, 0.625, 1.0, 0.6328125, 1.0, 0.625, 0.625, 0.6171875, 0.6171875, 1.0, 0.6171875, 1.0, 0.625, 0.625, 0.625, 1.0, 1.0, 0.625, 0.6171875, 0.625, 1.0, 1.0, 0.625, 0.6171875, 0.6171875, 0.625, 0.625, 0.625, 0.625, 0.6171875, 0.625, 0.625, 0.625, 1.0, 1.0, 0.6171875, 0.625, 0.6171875, 1.0, 0.625, 0.6171875, 0.625, 0.6328125, 0.625, 1.0, 0.6171875, 0.6171875, 1.0, 0.625, 0.6171875, 0.6171875, 0.6171875, 0.625, 1.0, 0.6171875, 1.0, 1.0, 0.6328125, 0.6171875, 0.6328125, 0.6171875, 0.625, 0.6171875, 0.625, 0.625, 1.0, 0.625, 0.625, 0.6171875, 0.625, 0.625, 1.0, 0.6171875, 0.625, 1.0, 1.0, 0.6171875, 0.6171875, 0.625, 1.0, 1.0, 0.6171875, 0.6328125, 0.6171875, 1.0, 0.6171875, 0.6328125, 0.6171875, 0.6171875, 1.0, 1.0, 1.0, 0.6171875, 1.0, 1.0, 0.6171875, 0.625, 0.609375, 0.625, 1.0, 0.625, 0.6171875, 0.6171875, 0.625, 1.0, 0.6171875, 0.625, 0.6171875, 0.6171875, 0.6484375, 0.6171875, 0.6171875, 0.625, 0.6328125, 0.625, 0.625, 0.625, 0.6328125, 0.625, 0.6171875, 0.625, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 0.1875, 0.177734375, 0.1875, 1.0, 1.0, 0.18359375, 0.19140625, 0.318359375, 0.1875, 0.18359375, 1.0, 0.171875, 1.0, 0.18359375, 1.0, 1.0, 1.0, 1.0, 0.220703125, 1.0, 1.0, 1.0, 0.1875, 0.1953125, 0.189453125, 1.0, 0.17578125, 0.1875, 0.18359375, 0.1953125, 1.0, 0.17578125, 1.0, 0.1875, 0.181640625, 0.189453125, 0.1796875, 0.1875, 1.0, 1.0, 0.1875, 0.181640625, 1.0, 0.181640625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1796875, 1.0, 0.189453125, 1.0, 0.1953125, 0.1875, 1.0, 0.18359375, 0.1953125, 1.0, 0.181640625, 0.18359375, 0.193359375, 0.173828125, 1.0, 1.0, 1.0, 0.1796875, 0.177734375, 1.0, 1.0, 1.0, 0.18359375, 1.0, 1.0, 0.185546875, 1.0, 1.0, 0.181640625, 1.0, 0.185546875, 1.0, 0.1875, 0.189453125, 0.193359375, 0.1796875, 1.0, 0.185546875, 1.0, 1.0, 0.185546875, 1.0, 1.0, 1.0, 1.0, 0.181640625, 0.177734375, 1.0, 0.17578125, 0.177734375, 0.185546875, 0.177734375, 0.1875, 0.1875, 1.0, 1.0, 0.18359375, 0.17578125, 1.0, 1.0, 0.185546875, 0.185546875, 0.181640625, 1.0, 1.0, 0.17578125, 0.1875, 1.0, 1.0, 1.0, 0.18359375, 0.1796875, 1.0, 1.0, 0.173828125, 0.18359375]

 sparsity of   [0.4522569477558136, 0.4513888955116272, 0.46875, 0.4505208432674408, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4479166567325592, 0.448784738779068, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4470486044883728, 0.440972238779068, 1.0, 1.0, 0.4583333432674408, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4548611044883728, 0.4479166567325592, 1.0, 1.0, 0.4479166567325592, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4539930522441864, 1.0, 0.4470486044883728, 1.0, 1.0, 1.0, 1.0, 0.4626736044883728, 1.0, 0.453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4435763955116272, 1.0, 0.4505208432674408, 1.0, 1.0, 1.0, 1.0, 0.4600694477558136, 1.0, 1.0, 1.0, 0.4539930522441864, 1.0, 1.0, 1.0, 1.0, 0.4479166567325592, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4609375, 0.4470486044883728, 0.456597238779068, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4513888955116272, 1.0, 0.4592013955116272, 1.0, 0.440972238779068, 0.4479166567325592, 0.4461805522441864, 1.0, 1.0, 0.456597238779068, 0.4539930522441864, 1.0, 1.0, 0.4470486044883728, 0.448784738779068, 1.0, 1.0, 1.0, 1.0, 0.4861111044883728, 1.0, 1.0, 1.0, 1.0, 0.4505208432674408, 0.4470486044883728, 1.0, 1.0, 0.4557291567325592, 1.0, 0.4557291567325592, 1.0, 0.4539930522441864, 0.4539930522441864, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6953125, 0.6875, 1.0, 0.6875, 0.6875, 0.6953125, 1.0, 0.6875, 1.0, 0.6953125, 0.6875, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.6953125, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6953125, 0.6875, 1.0, 1.0, 0.6875, 0.6953125, 1.0, 0.6875, 0.6875, 1.0, 0.6953125, 0.6875, 0.6875, 1.0, 0.6953125, 1.0, 0.6875, 0.6875, 0.6953125, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 1.0, 1.0, 0.6875, 0.6953125, 1.0, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 0.703125, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6953125, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6953125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6953125, 0.6875, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6953125, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6953125, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6953125, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 1.0, 0.6953125, 1.0, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.703125, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.6953125, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6953125, 0.6875, 1.0, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6953125, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6953125, 1.0, 1.0, 0.6953125, 0.6875, 0.6875, 0.6875, 0.6875, 0.703125, 1.0, 1.0, 0.6953125, 1.0, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 0.6953125, 0.6875, 0.6953125, 0.6875, 1.0, 0.6953125, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6953125, 0.6953125, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6953125, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 0.703125, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6953125, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 1.0, 1.0, 0.6953125, 0.6875, 1.0, 0.6875, 1.0, 0.6953125, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6953125, 1.0, 1.0, 1.0, 0.6875, 0.703125, 0.6875, 1.0, 0.6875, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 1.0, 1.0, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 0.734375, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6953125, 0.6875, 0.6875, 0.6953125, 1.0, 0.6953125, 0.6953125, 0.6953125, 0.6875, 0.6953125, 0.6875, 0.6953125, 1.0, 0.6875, 1.0, 1.0, 1.0, 0.6875, 0.6953125, 0.6875, 0.6875, 0.6875, 0.6953125, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6953125, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 1.0, 1.0, 1.0, 0.6875, 0.6953125, 0.6875, 1.0, 0.6953125, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6953125, 0.6875, 1.0, 0.6875, 1.0, 0.6953125, 0.6875, 0.6875, 0.6953125, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 1.0]

 sparsity of   [1.0, 0.14453125, 0.150390625, 0.142578125, 1.0, 0.275390625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.140625, 1.0, 1.0, 0.169921875, 1.0, 1.0, 0.259765625, 1.0, 0.1484375, 1.0, 0.140625, 1.0, 1.0, 0.142578125, 0.1796875, 1.0, 0.14453125, 1.0, 0.142578125, 1.0, 0.138671875, 0.90234375, 1.0, 1.0, 1.0, 1.0, 0.1484375, 0.140625, 0.15234375, 1.0, 1.0, 1.0, 0.150390625, 1.0, 0.140625, 1.0, 0.140625, 1.0, 1.0, 0.25, 1.0, 0.140625, 0.14453125, 0.19140625, 0.14453125, 1.0, 0.146484375, 0.1484375, 1.0, 0.19921875, 1.0, 0.1484375, 1.0, 0.14453125, 1.0, 1.0, 0.142578125, 0.302734375, 1.0, 1.0, 0.154296875, 1.0, 1.0, 1.0, 0.1484375, 0.150390625, 1.0, 0.189453125, 1.0, 1.0, 0.13671875, 0.2421875, 1.0, 0.13671875, 1.0, 0.140625, 1.0, 0.1875, 1.0, 1.0, 0.142578125, 0.146484375, 1.0, 1.0, 1.0, 0.138671875, 1.0, 1.0, 1.0, 0.138671875, 0.150390625, 1.0, 0.203125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.134765625, 1.0, 1.0, 1.0, 1.0, 0.138671875, 0.140625, 1.0, 1.0, 0.13671875, 1.0, 0.140625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.140625]

 sparsity of   [1.0, 1.0, 1.0, 0.5807291865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5729166865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5737847089767456, 1.0, 1.0, 1.0, 1.0, 0.5763888955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5720486044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.663194477558136, 0.5746527910232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5755208134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5737847089767456, 0.5798611044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5789930820465088, 1.0, 1.0, 1.0, 1.0, 0.5711805820465088, 1.0, 1.0, 1.0, 1.0, 0.5798611044883728, 1.0, 0.5720486044883728, 0.5746527910232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5746527910232544, 1.0, 0.5703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5763888955116272, 1.0, 1.0, 1.0, 0.5746527910232544, 1.0, 0.5729166865348816, 0.5763888955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5720486044883728, 1.0]

 sparsity of   [0.7265625, 1.0, 1.0, 1.0, 0.703125, 0.71875, 1.0, 1.0, 1.0, 0.7109375, 0.7578125, 0.7109375, 1.0, 0.7109375, 1.0, 1.0, 0.7109375, 1.0, 1.0, 0.71875, 1.0, 0.7109375, 1.0, 0.7109375, 1.0, 1.0, 0.7109375, 0.703125, 1.0, 0.71875, 1.0, 0.7265625, 1.0, 1.0, 0.703125, 0.7109375, 1.0, 1.0, 1.0, 1.0, 0.7265625, 0.7109375, 1.0, 0.7109375, 0.71875, 1.0, 0.7109375, 1.0, 1.0, 1.0, 0.75, 0.71875, 0.703125, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.703125, 0.71875, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 0.7109375, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.7109375, 0.7109375, 1.0, 1.0, 0.765625, 1.0, 0.7109375, 1.0, 1.0, 1.0, 0.7109375, 0.7109375, 1.0, 0.7109375, 1.0, 1.0, 1.0, 0.7109375, 1.0, 0.7265625, 1.0, 0.7109375, 0.7109375, 1.0, 1.0, 0.7109375, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7265625, 1.0, 0.7109375, 0.71875, 1.0, 1.0, 0.7109375, 0.7109375, 1.0, 0.703125, 0.71875, 1.0, 1.0, 0.7265625, 1.0, 1.0, 0.7109375, 1.0, 1.0, 1.0, 0.7265625, 1.0, 1.0, 0.7109375, 1.0, 0.7109375, 0.703125, 1.0, 0.71875, 0.703125, 1.0, 1.0, 0.71875, 0.765625, 1.0, 1.0, 0.71875, 1.0, 0.7109375, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.703125, 1.0, 0.703125, 0.734375, 1.0, 0.7109375, 1.0, 1.0, 0.7109375, 1.0, 0.703125, 1.0, 0.7109375, 0.703125, 1.0, 0.7109375, 1.0, 1.0, 0.703125, 1.0, 1.0, 1.0, 0.7109375, 1.0, 0.734375, 1.0, 1.0, 1.0, 0.7109375, 1.0, 0.7109375, 1.0, 1.0, 0.7109375, 1.0, 0.71875, 0.7109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7265625, 1.0, 1.0, 0.7265625, 0.7109375, 1.0, 0.7109375, 0.7109375, 0.7265625, 0.71875, 0.71875, 1.0, 1.0, 1.0, 0.7109375, 0.71875, 1.0, 0.734375, 0.703125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 0.7109375, 0.703125, 0.7109375, 0.71875, 0.7109375, 1.0, 0.7109375, 0.7421875, 0.7109375, 1.0, 0.703125, 1.0, 0.7109375, 0.7109375, 0.71875, 1.0, 0.7109375, 1.0, 0.7109375, 0.7109375, 0.7109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7265625, 0.7109375, 0.7109375, 0.7109375, 0.71875, 0.7109375, 1.0, 1.0, 0.7109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.7109375, 0.703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.703125, 1.0, 1.0, 1.0, 1.0, 0.703125, 1.0, 0.7109375, 1.0, 0.71875, 0.703125, 1.0, 1.0, 0.7109375, 1.0, 1.0, 0.71875, 1.0, 0.7109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7265625, 0.703125, 1.0, 1.0, 1.0, 0.7109375, 0.703125, 0.7265625, 1.0, 1.0, 1.0, 0.7109375, 0.7109375, 1.0, 1.0, 0.7109375, 0.71875, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 0.7109375, 0.71875, 1.0, 1.0, 0.71875, 0.7421875, 0.7265625, 1.0, 1.0, 0.7109375, 1.0, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 0.734375, 1.0, 0.7109375, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 0.7265625, 1.0, 0.7109375, 1.0, 0.71875, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7109375, 1.0, 0.7109375, 0.703125, 0.7109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.734375, 0.7109375, 1.0, 0.71875, 1.0, 1.0, 0.7109375, 1.0, 0.703125, 1.0, 0.7265625, 1.0, 1.0, 1.0, 1.0, 0.7265625, 0.7109375, 1.0, 1.0, 1.0, 0.703125, 0.703125, 1.0, 0.7265625, 1.0, 1.0, 0.7109375, 1.0, 0.703125, 1.0, 0.71875, 0.703125, 1.0, 0.7109375, 0.703125, 1.0, 1.0, 1.0, 1.0, 0.7109375, 0.7109375, 0.703125, 0.71875, 0.703125, 1.0, 1.0, 0.703125, 0.7265625, 0.75, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.7109375, 1.0, 0.7265625, 1.0, 1.0, 1.0, 1.0, 0.703125, 0.71875, 0.703125, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 1.0, 0.71875, 0.7109375, 1.0, 1.0, 0.7109375, 0.7109375, 1.0, 0.71875, 1.0, 0.7109375, 1.0, 0.7109375, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.7421875, 0.7109375, 1.0, 1.0, 1.0, 0.71875, 0.7265625, 1.0, 1.0]

 sparsity of   [0.109375, 1.0, 1.0, 0.107421875, 0.119140625, 1.0, 0.10546875, 1.0, 1.0, 1.0, 1.0, 0.103515625, 0.107421875, 1.0, 0.111328125, 1.0, 1.0, 0.11328125, 0.111328125, 0.107421875, 1.0, 0.11328125, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 0.09765625, 1.0, 0.11328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.103515625, 1.0, 0.109375, 1.0, 0.107421875, 1.0, 0.109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.107421875, 1.0, 1.0, 1.0, 0.109375, 0.103515625, 1.0, 1.0, 1.0, 0.109375, 0.126953125, 1.0, 1.0, 1.0, 1.0, 0.111328125, 0.11328125, 0.103515625, 1.0, 1.0, 0.107421875, 0.109375, 1.0, 0.107421875, 1.0, 1.0, 0.10546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12109375, 1.0, 1.0, 1.0, 0.103515625, 0.10546875, 0.107421875, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 1.0, 0.1171875, 1.0, 0.115234375, 1.0, 0.107421875, 0.10546875, 0.107421875, 0.10546875, 1.0, 1.0, 0.10546875, 0.111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1015625, 1.0, 0.107421875, 1.0, 1.0, 1.0, 1.0, 0.111328125, 0.107421875, 0.103515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11328125, 0.109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 0.111328125, 0.109375, 1.0, 1.0, 0.115234375, 1.0, 1.0, 1.0, 1.0, 0.10546875, 1.0, 0.10546875, 1.0, 0.109375, 0.10546875, 1.0, 1.0, 1.0, 1.0, 0.109375, 0.111328125, 1.0, 0.10546875, 1.0, 1.0, 0.103515625, 0.11328125, 1.0, 0.125, 1.0, 1.0, 0.10546875, 1.0, 1.0, 0.107421875, 1.0, 1.0, 1.0, 0.109375, 0.10546875, 0.109375, 1.0, 0.115234375, 0.103515625, 0.111328125, 1.0, 0.109375, 1.0, 1.0, 1.0, 1.0, 0.10546875, 1.0, 1.0, 0.11328125, 1.0, 0.103515625, 1.0, 0.109375, 1.0, 1.0, 1.0, 1.0, 0.109375, 1.0, 0.1015625, 0.107421875, 1.0, 1.0, 0.10546875, 0.111328125, 1.0, 0.119140625, 1.0, 0.10546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.10546875, 1.0, 0.1171875, 1.0, 1.0, 0.115234375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.109375, 1.0, 0.11328125, 1.0, 1.0, 1.0, 0.103515625, 1.0, 0.107421875, 1.0]

 sparsity of   [0.6419270634651184, 1.0, 1.0, 1.0, 1.0, 0.6414930820465088, 1.0, 1.0, 0.6432291865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.643663227558136, 1.0, 1.0, 1.0, 0.6423611044883728, 0.6440972089767456, 0.6423611044883728, 0.6423611044883728, 1.0, 1.0, 1.0, 1.0, 0.6467013955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6427951455116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6432291865348816, 1.0, 1.0, 0.6419270634651184, 1.0, 1.0, 1.0, 0.6427951455116272, 1.0, 0.6414930820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.643663227558136, 0.6423611044883728, 1.0, 1.0, 1.0, 1.0, 0.6432291865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.643663227558136, 1.0, 1.0, 1.0, 1.0, 0.6419270634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6432291865348816, 0.6432291865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6423611044883728, 0.643663227558136, 0.6423611044883728, 1.0, 0.6432291865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6419270634651184, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.6432291865348816, 0.6419270634651184, 1.0, 1.0, 1.0, 0.6440972089767456, 1.0, 1.0, 1.0, 0.6432291865348816, 0.6427951455116272, 0.6414930820465088, 1.0, 0.6419270634651184, 1.0, 0.6414930820465088, 1.0, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.6427951455116272, 1.0, 0.6423611044883728, 1.0, 1.0, 1.0, 1.0, 0.6414930820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6419270634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 0.643663227558136, 1.0, 1.0, 1.0, 1.0, 0.6440972089767456, 1.0, 1.0, 0.6427951455116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6423611044883728, 0.6423611044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.643663227558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6427951455116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.640625, 1.0, 1.0, 1.0, 0.6414930820465088, 1.0, 1.0, 1.0, 0.6432291865348816, 1.0, 1.0, 1.0, 0.6440972089767456, 1.0, 1.0, 1.0]

 sparsity of   [0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.8046875, 0.8046875, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 0.8046875, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.8203125, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.8046875, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.8046875, 0.796875, 0.80859375, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.8046875, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 0.8046875, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 0.8046875, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8046875, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.8046875, 0.80078125, 1.0, 1.0, 0.80859375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.8046875, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 0.796875, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.8046875, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.8046875, 1.0, 0.8046875, 0.80078125, 1.0, 0.796875, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.84375, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 0.8046875, 1.0, 0.8046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8046875, 1.0, 1.0, 0.80078125, 0.80859375, 1.0, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 0.80859375, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.8046875, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.8046875, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 0.796875, 1.0, 1.0, 1.0, 0.8046875, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.81640625, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 0.80859375, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.8046875, 1.0, 1.0, 1.0, 0.80078125, 0.8046875, 0.80078125, 1.0, 1.0, 0.80078125, 0.8046875, 1.0, 1.0, 0.80078125, 0.80078125, 0.8046875, 0.796875, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.8046875, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.8046875, 0.80078125, 0.8046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 0.8046875, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 0.8046875, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.8046875, 1.0, 0.80859375, 0.80078125, 0.80078125, 0.8046875, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.8046875, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8046875, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.8046875, 1.0, 0.80078125, 0.80078125, 1.0, 0.8046875, 0.80078125, 1.0, 0.8046875, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 0.8046875, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.8046875, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 0.8046875, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.8046875, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80859375, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.8046875, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.8046875, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.8046875, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.8046875, 0.80078125, 0.8046875, 1.0, 1.0, 0.80078125, 0.80078125, 0.8046875, 1.0, 0.80078125, 1.0, 0.80078125, 0.8046875, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.8046875, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.8046875, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8046875, 0.796875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.8046875, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.8046875, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.8046875, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.8046875, 1.0, 0.80078125, 0.8046875, 0.80078125, 0.80078125, 1.0, 0.8046875, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.8046875, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80859375, 1.0, 1.0, 1.0, 0.8046875, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.8046875, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.8046875, 1.0, 0.80078125]

 sparsity of   [0.109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.115234375, 1.0, 1.0, 0.115234375, 1.0, 1.0, 0.16015625, 0.119140625, 0.111328125, 1.0, 0.11328125, 1.0, 1.0, 1.0, 1.0, 0.107421875, 1.0, 1.0, 0.119140625, 0.10546875, 0.107421875, 0.1171875, 0.1171875, 1.0, 1.0, 0.265625, 0.1015625, 0.107421875, 0.115234375, 1.0, 0.10546875, 0.111328125, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 0.119140625, 0.111328125, 0.111328125, 0.10546875, 1.0, 0.109375, 1.0, 1.0, 1.0, 0.10546875, 1.0, 1.0, 1.0, 1.0, 0.13671875, 1.0, 1.0, 0.11328125, 0.162109375, 0.10546875, 1.0, 1.0, 1.0, 0.115234375, 1.0, 1.0, 0.115234375, 0.119140625, 1.0, 1.0, 1.0, 1.0, 0.107421875, 0.11328125, 0.115234375, 0.154296875, 1.0, 1.0, 1.0, 1.0, 0.107421875, 0.107421875, 1.0, 1.0, 0.2109375, 0.11328125, 0.109375, 1.0, 0.119140625, 0.107421875, 0.111328125, 1.0, 0.109375, 1.0, 1.0, 0.208984375, 0.10546875, 1.0, 1.0, 0.11328125, 0.107421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 0.10546875, 1.0, 0.15625, 0.111328125, 0.103515625, 0.11328125, 0.111328125, 1.0, 1.0, 1.0, 0.107421875, 1.0, 1.0, 1.0, 1.0, 0.119140625, 1.0, 1.0, 0.109375, 0.103515625, 1.0, 1.0, 1.0, 0.125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11328125, 1.0, 0.11328125, 0.111328125, 0.107421875, 0.109375, 0.10546875, 1.0, 0.119140625, 1.0, 1.0, 0.103515625, 0.10546875, 0.119140625, 0.10546875, 1.0, 1.0, 1.0, 1.0, 0.111328125, 0.115234375, 1.0, 0.109375, 0.359375, 1.0, 1.0, 0.119140625, 0.115234375, 0.10546875, 0.10546875, 1.0, 1.0, 0.10546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.107421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.10546875, 1.0, 1.0, 0.107421875, 0.111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.109375, 0.12109375, 0.111328125, 1.0, 1.0, 0.11328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 0.11328125, 1.0, 0.115234375, 0.1171875, 1.0, 0.11328125, 1.0, 1.0, 1.0, 1.0, 0.107421875, 1.0, 0.123046875, 0.109375, 1.0, 0.111328125, 0.109375, 0.115234375, 0.1171875, 0.119140625, 0.111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.115234375, 0.109375, 0.1171875, 0.111328125, 1.0, 1.0, 0.109375, 0.11328125, 1.0, 1.0, 1.0, 0.109375, 1.0, 0.109375, 1.0, 0.115234375, 1.0, 0.109375, 1.0, 0.109375, 1.0, 1.0, 0.11328125, 1.0, 0.10546875, 1.0, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.166015625, 1.0, 1.0, 0.111328125, 1.0, 0.1171875, 0.150390625, 0.109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11328125, 1.0, 1.0, 0.119140625, 1.0, 1.0, 1.0, 1.0, 0.10546875, 1.0, 1.0, 1.0, 0.11328125, 0.111328125, 0.126953125, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 0.125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.107421875, 1.0, 1.0, 0.1171875, 0.126953125, 1.0, 0.107421875, 1.0, 1.0, 1.0, 0.1328125, 1.0, 0.109375, 0.103515625, 1.0, 1.0, 0.107421875, 1.0, 0.109375, 1.0, 1.0, 0.11328125, 1.0, 1.0, 0.119140625, 1.0, 0.109375, 1.0, 0.115234375, 1.0, 1.0, 1.0, 0.11328125, 1.0, 1.0, 1.0, 1.0, 0.11328125, 1.0, 1.0, 0.208984375, 0.11328125, 1.0, 1.0, 1.0, 0.11328125, 1.0, 1.0, 1.0, 0.107421875, 1.0, 0.111328125, 1.0, 1.0, 0.126953125, 1.0, 1.0, 1.0, 0.11328125, 0.111328125, 1.0, 0.150390625, 1.0, 0.1171875, 1.0, 1.0, 0.11328125, 1.0, 0.126953125, 0.123046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.115234375, 0.111328125, 1.0, 1.0, 0.123046875, 1.0, 0.119140625, 0.11328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 0.1171875, 1.0, 1.0, 0.107421875, 0.10546875, 0.16015625, 0.119140625, 1.0, 1.0, 0.109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.126953125, 1.0, 1.0, 1.0, 0.109375, 0.111328125, 1.0, 0.130859375, 1.0, 1.0, 0.107421875, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 1.0, 0.109375, 1.0, 0.107421875, 0.109375, 1.0, 0.115234375, 1.0, 1.0, 1.0, 1.0, 0.107421875, 1.0, 0.115234375, 0.115234375, 1.0, 1.0, 0.111328125, 0.119140625, 1.0, 0.111328125, 0.111328125, 0.111328125, 1.0, 0.17578125, 1.0, 0.12890625, 0.115234375, 1.0, 1.0, 1.0, 0.109375, 0.109375, 0.107421875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.123046875, 1.0, 0.1171875, 0.103515625, 1.0, 1.0, 1.0, 0.11328125, 1.0, 0.123046875, 1.0, 1.0, 0.11328125, 0.10546875, 1.0, 1.0, 0.10546875, 0.111328125, 0.12109375, 0.115234375, 0.1171875, 1.0, 0.10546875, 0.10546875, 1.0, 1.0, 0.103515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.125, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.12890625, 0.111328125, 0.115234375, 1.0, 0.11328125, 1.0, 1.0, 1.0, 1.0, 0.1171875, 0.115234375, 0.115234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.109375, 1.0, 0.23828125, 0.109375, 1.0, 1.0, 0.107421875, 0.11328125, 0.111328125, 0.478515625, 1.0, 1.0, 1.0, 0.109375, 0.126953125, 1.0, 1.0, 0.107421875, 1.0, 1.0, 1.0, 1.0, 0.10546875, 1.0, 0.103515625, 0.111328125, 0.11328125, 0.109375, 0.111328125, 1.0, 0.111328125, 0.126953125, 1.0, 0.1171875, 0.1171875, 1.0, 0.11328125, 1.0, 1.0, 0.111328125, 1.0, 1.0, 0.115234375, 0.115234375, 0.115234375, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 1.0, 0.1171875, 0.107421875, 0.109375, 0.119140625, 1.0, 1.0, 0.11328125, 1.0, 1.0, 1.0, 1.0, 0.111328125, 0.10546875, 1.0, 1.0, 0.119140625, 0.103515625, 0.119140625, 1.0, 1.0, 0.119140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11328125, 0.115234375, 1.0, 0.11328125, 1.0, 1.0, 0.115234375, 1.0, 0.130859375, 1.0, 0.123046875, 0.11328125, 1.0, 1.0, 0.123046875, 1.0, 0.109375, 1.0, 0.111328125, 0.109375, 1.0, 0.111328125, 0.115234375, 1.0, 1.0, 0.11328125, 1.0, 0.119140625, 0.11328125, 0.111328125, 1.0, 1.0, 0.109375, 0.11328125, 0.123046875, 1.0, 1.0, 1.0, 1.0, 0.115234375, 1.0, 0.109375, 1.0, 0.115234375, 0.111328125, 0.20703125, 0.1171875, 1.0, 1.0, 1.0, 0.115234375, 0.1953125, 1.0, 1.0, 1.0, 0.353515625, 0.109375, 1.0, 0.119140625, 0.111328125, 0.15234375, 0.103515625, 1.0, 1.0, 1.0, 0.115234375, 1.0, 1.0, 1.0, 0.1171875, 1.0, 0.162109375, 1.0, 0.107421875, 0.11328125, 1.0, 1.0, 0.1171875, 0.119140625, 1.0, 0.11328125, 0.1015625, 0.111328125, 1.0, 1.0, 1.0, 1.0, 0.1015625, 0.275390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 0.107421875, 0.14453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11328125, 0.111328125, 1.0, 1.0, 0.11328125, 1.0, 0.111328125, 0.119140625, 0.1171875, 1.0, 1.0, 0.111328125, 0.115234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 0.111328125, 1.0, 0.107421875, 1.0, 0.123046875, 1.0, 1.0, 1.0, 0.10546875, 0.115234375, 0.109375, 1.0, 1.0, 0.1171875, 0.111328125, 0.10546875, 1.0, 1.0, 0.123046875, 0.11328125, 0.109375, 1.0, 0.166015625, 1.0, 0.103515625, 0.11328125, 1.0, 1.0, 1.0, 1.0, 0.115234375, 1.0, 0.109375, 0.11328125, 1.0, 1.0, 1.0, 1.0, 0.11328125, 0.115234375, 0.1171875, 1.0, 0.107421875, 1.0, 1.0, 1.0, 1.0, 0.107421875, 0.115234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.365234375, 0.109375, 0.10546875, 0.111328125, 1.0, 0.109375, 0.11328125, 0.109375, 0.11328125, 1.0, 0.111328125, 0.119140625, 1.0, 0.12109375, 1.0, 1.0, 0.123046875, 0.109375, 1.0, 1.0, 0.111328125, 0.111328125, 1.0, 1.0, 1.0, 0.11328125, 0.12109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.115234375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 0.12109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.115234375, 0.107421875, 0.11328125, 1.0, 1.0, 0.11328125, 0.11328125, 0.119140625, 0.10546875, 0.111328125, 1.0, 0.115234375, 1.0, 1.0, 1.0, 0.115234375, 1.0, 0.11328125, 1.0, 1.0, 0.12109375, 0.111328125, 1.0, 1.0, 1.0, 1.0, 0.103515625, 0.109375, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 0.1171875, 0.107421875, 1.0, 1.0, 0.11328125, 1.0, 0.107421875, 1.0, 1.0, 0.12109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.109375, 1.0, 0.125, 1.0, 0.10546875, 1.0, 1.0, 0.107421875, 0.10546875, 1.0, 1.0, 1.0, 1.0, 0.115234375, 1.0, 0.11328125, 0.111328125, 0.109375, 0.10546875, 1.0, 0.107421875, 1.0, 0.11328125, 1.0, 0.109375, 1.0, 0.111328125, 1.0, 1.0, 0.1171875, 0.255859375, 1.0, 1.0, 1.0, 0.1171875, 1.0, 1.0, 0.1796875, 0.1171875, 1.0, 1.0, 0.107421875, 0.11328125, 1.0, 0.107421875, 1.0, 1.0, 1.0, 0.111328125, 1.0, 1.0, 0.111328125, 1.0, 0.12109375, 0.111328125, 1.0, 0.111328125, 1.0, 0.123046875, 0.12109375, 1.0, 0.109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.109375, 1.0, 1.0, 1.0, 0.109375, 0.119140625, 0.12109375, 1.0, 1.0, 1.0, 0.107421875, 1.0, 1.0, 0.13671875, 1.0, 1.0, 0.123046875, 0.119140625, 1.0, 1.0, 1.0, 0.12109375, 1.0, 0.16015625, 0.1171875, 0.109375, 1.0, 0.109375]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5439453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5263671875, 0.537109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.537109375, 0.546875, 0.533203125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5419921875, 1.0, 1.0, 1.0, 0.5341796875, 1.0, 1.0, 0.5263671875, 0.5380859375, 1.0, 0.537109375, 0.5361328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5361328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.537109375, 1.0, 0.54296875, 1.0, 0.53515625, 0.5341796875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.541015625, 1.0, 1.0, 1.0, 1.0, 0.5390625, 0.529296875, 0.537109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.54296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.529296875, 1.0, 1.0, 1.0, 0.5380859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5341796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.525390625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5400390625, 1.0, 1.0, 0.541015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5361328125, 1.0, 1.0, 1.0, 0.5478515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.537109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.54296875, 1.0, 1.0, 0.5400390625, 1.0, 0.5380859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5390625, 1.0, 0.5400390625, 1.0, 1.0, 0.533203125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.537109375, 0.5341796875, 1.0, 1.0, 0.5380859375, 1.0, 0.537109375, 1.0, 0.53515625, 1.0, 1.0, 1.0, 0.537109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5380859375, 1.0, 0.546875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5361328125, 1.0, 1.0, 0.5380859375, 1.0, 1.0, 1.0, 0.5322265625, 0.5361328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.533203125, 0.5419921875, 1.0, 0.537109375, 0.53515625, 1.0, 1.0, 1.0, 0.5634765625, 1.0, 1.0, 1.0, 1.0, 0.5361328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.7838541865348816, 1.0, 1.0, 0.7790798544883728, 1.0, 1.0, 0.7821180820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7838541865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7847222089767456, 1.0, 1.0, 1.0, 1.0, 0.78125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7834201455116272, 1.0, 1.0, 0.7829861044883728, 0.7838541865348816, 1.0, 0.7825520634651184, 1.0, 0.7808159589767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7799479365348816, 1.0, 1.0, 0.7829861044883728, 1.0, 1.0, 1.0, 1.0, 0.78125, 1.0, 1.0, 1.0, 0.780381977558136, 1.0, 1.0, 1.0, 1.0, 0.7860243320465088, 1.0, 1.0, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7808159589767456, 1.0, 1.0, 0.7816840410232544, 0.78125, 1.0, 1.0, 1.0, 1.0, 0.7829861044883728, 1.0, 1.0, 1.0, 1.0, 0.78125, 1.0, 1.0, 0.7795138955116272, 0.7825520634651184, 1.0, 1.0, 1.0, 0.7808159589767456, 1.0, 0.7795138955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7821180820465088, 1.0, 1.0, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7795138955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7821180820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7847222089767456, 0.7790798544883728, 0.784288227558136, 1.0, 0.7808159589767456, 0.7868923544883728, 1.0, 0.7855902910232544, 1.0, 0.7782118320465088, 1.0, 1.0, 0.7808159589767456, 0.7808159589767456, 0.7786458134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7799479365348816, 1.0, 0.780381977558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7799479365348816, 1.0, 0.7825520634651184, 1.0, 1.0, 1.0, 0.7825520634651184, 0.7808159589767456, 0.7829861044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.784288227558136, 1.0, 0.7786458134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7838541865348816, 1.0, 0.7786458134651184, 1.0]

 sparsity of   [0.78125, 1.0, 1.0, 0.79296875, 0.78515625, 1.0, 0.7890625, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.796875, 1.0, 1.0, 0.78515625, 0.79296875, 1.0, 1.0, 0.78125, 1.0, 1.0, 0.79296875, 1.0, 0.78125, 1.0, 1.0, 0.79296875, 0.79296875, 0.78125, 0.77734375, 0.78515625, 1.0, 1.0, 1.0, 0.7890625, 0.79296875, 0.78515625, 1.0, 0.77734375, 0.796875, 0.79296875, 1.0, 1.0, 1.0, 0.78515625, 0.79296875, 0.78125, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.796875, 0.79296875, 0.796875, 1.0, 0.7890625, 1.0, 0.78125, 1.0, 0.77734375, 1.0, 1.0, 0.78515625, 1.0, 0.79296875, 1.0, 0.78515625, 0.80078125, 0.7890625, 0.796875, 1.0, 1.0, 1.0, 0.7890625, 0.77734375, 1.0, 0.796875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.77734375, 0.7890625, 0.79296875, 0.78515625, 1.0, 0.79296875, 1.0, 1.0, 0.77734375, 0.78125, 1.0, 1.0, 1.0, 0.80078125, 0.78125, 1.0, 0.79296875, 0.78125, 0.79296875, 1.0, 0.796875, 1.0, 1.0, 0.7890625, 0.79296875, 1.0, 1.0, 0.79296875, 0.78515625, 1.0, 0.78125, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.7890625, 1.0, 0.78515625, 1.0, 0.78515625, 0.78515625, 0.7890625, 0.78515625, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 0.78125, 0.79296875, 0.78125, 1.0, 1.0, 1.0, 0.8203125, 1.0, 0.77734375, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.796875, 1.0, 0.796875, 0.79296875, 0.78515625, 0.78125, 0.7890625, 0.8046875, 0.7890625, 1.0, 1.0, 0.7890625, 0.77734375, 0.796875, 0.79296875, 1.0, 0.79296875, 1.0, 0.796875, 0.79296875, 0.796875, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.78125, 0.78515625, 0.78125, 0.796875, 1.0, 1.0, 0.78125, 1.0, 0.7890625, 0.78125, 1.0, 1.0, 1.0, 0.78125, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78125, 0.77734375, 0.78515625, 0.78515625, 0.78125, 0.79296875, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.796875, 0.78515625, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78125, 1.0, 0.79296875, 1.0, 0.78125, 0.79296875, 1.0, 0.796875, 1.0, 0.78125, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.7890625, 1.0, 0.77734375, 0.79296875, 0.78515625, 0.796875, 0.796875, 0.78125, 0.79296875, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.78515625, 0.79296875, 0.78515625, 1.0, 1.0, 0.79296875, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.78125, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 0.77734375, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.79296875, 1.0, 0.80078125, 0.78125, 0.78515625, 1.0, 0.7890625, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.7890625, 0.83203125, 1.0, 1.0, 1.0, 0.78125, 1.0, 1.0, 1.0, 0.78515625, 0.7890625, 0.78125, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 0.78515625, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.796875, 0.796875, 1.0, 1.0, 0.80078125, 0.7890625, 1.0, 0.78515625, 1.0, 1.0, 0.78125, 0.7890625, 1.0, 0.78125, 0.77734375, 1.0, 1.0, 0.78125, 1.0, 0.78515625, 1.0, 1.0, 0.796875, 0.79296875, 0.78515625, 0.79296875, 1.0, 0.79296875, 1.0, 0.796875, 1.0, 1.0, 1.0, 0.78515625, 0.77734375, 1.0, 1.0, 0.78125, 0.7890625, 1.0, 1.0, 0.79296875, 0.78125, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 0.78125, 1.0, 0.78515625, 1.0, 0.79296875, 1.0, 1.0, 0.796875, 1.0, 1.0, 0.79296875, 0.796875, 1.0, 0.78125, 0.79296875, 1.0, 0.78125, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.78125, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.78125, 1.0, 1.0, 1.0, 1.0, 0.77734375, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.79296875, 0.78515625, 1.0, 1.0, 0.78125, 0.78515625, 0.77734375, 0.796875, 0.78125, 0.78515625, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.78125, 0.80078125, 1.0, 0.7890625, 1.0, 0.78125, 1.0, 1.0, 1.0, 0.77734375, 0.78125, 1.0, 1.0, 1.0, 0.7890625, 1.0, 0.78125, 0.78125, 1.0, 0.796875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.78515625, 0.79296875, 0.8046875, 1.0, 1.0, 0.79296875, 0.7890625, 1.0, 0.78515625, 0.796875, 0.79296875, 1.0, 0.78515625, 1.0, 1.0, 0.7890625, 0.7890625, 1.0, 1.0, 0.80078125, 0.796875, 0.78125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 0.79296875, 0.79296875, 1.0, 0.78125, 1.0, 0.78515625, 0.796875, 0.78515625, 1.0, 1.0, 0.78125, 0.78515625, 1.0, 1.0, 0.7890625, 0.7890625, 0.79296875, 0.78515625, 0.78515625, 1.0, 0.78125, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.78125, 1.0, 0.80078125, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.79296875, 0.80078125, 0.78515625, 1.0, 0.7890625, 1.0, 1.0, 0.78515625, 1.0, 0.79296875, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.78125, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 0.79296875, 0.78515625, 0.796875, 0.7890625, 0.78125, 1.0, 1.0, 0.79296875, 0.796875, 1.0, 0.79296875, 0.796875, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 0.77734375, 0.77734375, 0.79296875, 0.79296875, 0.78125, 1.0, 0.77734375, 0.79296875, 1.0, 0.79296875, 0.78125, 1.0, 0.78125, 1.0, 0.7890625, 0.7890625, 1.0, 1.0, 0.78515625, 0.7890625, 0.78125, 1.0, 1.0, 0.7890625, 1.0, 0.78515625, 1.0, 1.0, 0.78125, 0.79296875, 0.78515625, 0.78125, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.78125, 1.0, 1.0, 0.796875, 0.78515625, 0.78515625, 1.0, 0.80078125, 0.78515625, 0.796875, 0.78125, 0.7890625, 0.78125, 1.0, 1.0, 0.796875, 0.79296875, 1.0, 0.7890625, 0.78515625, 1.0, 0.77734375, 1.0, 1.0, 1.0, 0.796875, 0.78515625, 0.78515625, 1.0, 0.79296875, 1.0, 0.78515625, 1.0, 0.79296875, 0.796875, 0.78515625, 0.80078125, 0.79296875, 1.0, 1.0, 0.79296875, 0.77734375, 0.796875, 0.78515625, 0.79296875, 0.796875, 0.77734375, 0.78515625, 0.77734375, 0.79296875, 1.0, 0.7890625, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 0.79296875, 0.80078125, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.78515625, 0.79296875, 1.0, 0.79296875, 0.78125, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.7890625, 0.78125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.78515625, 0.78515625, 0.7890625, 0.8046875, 0.78125, 0.78515625, 1.0, 0.78125, 0.80078125, 0.79296875, 1.0, 1.0, 1.0, 0.7890625, 0.78125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.7890625, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 0.78515625, 0.79296875, 0.78125, 1.0, 0.80078125, 0.79296875, 0.78125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.78125, 0.78515625, 1.0, 0.796875, 1.0, 0.77734375, 1.0, 1.0, 1.0, 0.79296875, 0.796875, 0.79296875, 1.0, 1.0, 0.79296875, 0.78125, 0.78515625, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.78125, 1.0, 0.78125, 0.80078125, 1.0, 1.0, 0.78515625, 1.0, 0.796875, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.796875, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.78125, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.7890625, 0.79296875, 0.7890625, 1.0, 0.79296875, 0.7890625, 0.78125, 0.78515625, 1.0, 0.79296875, 0.79296875, 1.0, 0.796875, 1.0, 1.0, 0.78125, 0.7890625, 1.0, 1.0, 0.7890625, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78125, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.78515625, 0.7890625, 0.796875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.7890625, 0.78515625, 1.0, 1.0, 0.796875, 0.78125, 0.79296875, 0.7890625, 0.78125, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.77734375, 1.0, 0.796875, 0.79296875, 0.79296875, 0.796875, 1.0, 1.0, 0.7890625, 0.78125, 0.79296875, 0.78125, 1.0, 0.8046875, 1.0, 0.796875, 1.0, 0.78515625, 0.7890625, 0.79296875, 1.0, 0.78515625, 0.77734375, 0.80078125, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.77734375, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.796875, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.796875, 0.79296875, 0.79296875, 0.78515625, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 0.796875, 1.0, 0.78125, 1.0, 0.796875, 1.0, 0.79296875, 0.78125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.7890625, 0.796875, 0.7890625, 0.78515625, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 0.77734375, 0.79296875, 1.0, 0.796875, 1.0, 1.0, 0.78125, 1.0, 0.7890625, 0.78515625, 1.0, 0.78515625, 1.0, 0.80859375, 0.796875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.78515625, 1.0, 0.79296875, 0.78515625, 0.7890625, 1.0, 0.78515625, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 0.77734375, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.796875, 0.78515625, 0.79296875, 1.0, 0.79296875]

 sparsity of   [0.4462890625, 0.435546875, 0.43359375, 0.4345703125, 1.0, 0.435546875, 0.4267578125, 0.4365234375, 1.0, 1.0, 0.4375, 1.0, 0.43359375, 1.0, 1.0, 1.0, 1.0, 0.431640625, 1.0, 1.0, 0.5166015625, 0.4423828125, 1.0, 0.4365234375, 0.4326171875, 0.435546875, 1.0, 0.4345703125, 1.0, 0.4267578125, 1.0, 1.0, 0.4375, 1.0, 0.431640625, 1.0, 0.43359375, 0.439453125, 1.0, 0.4365234375, 0.435546875, 0.4404296875, 1.0, 1.0, 0.435546875, 0.4365234375, 1.0, 1.0, 0.4404296875, 1.0, 0.443359375, 1.0, 0.43359375, 1.0, 0.43359375, 1.0, 1.0, 1.0, 0.43359375, 1.0, 1.0, 1.0, 0.431640625, 0.43359375, 1.0, 1.0, 0.4345703125, 0.4345703125, 0.431640625, 1.0, 1.0, 1.0, 1.0, 0.435546875, 0.4306640625, 0.435546875, 0.435546875, 0.4228515625, 0.4384765625, 1.0, 0.4384765625, 0.4365234375, 0.4296875, 0.4375, 0.4345703125, 0.4296875, 1.0, 0.4326171875, 1.0, 1.0, 1.0, 1.0, 0.43359375, 1.0, 1.0, 0.4306640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.435546875, 0.4306640625, 0.4345703125, 1.0, 1.0, 1.0, 0.431640625, 1.0, 0.4306640625, 0.439453125, 1.0, 0.4365234375, 1.0, 1.0, 0.4326171875, 0.427734375, 1.0, 0.43359375, 1.0, 1.0, 0.435546875, 0.4326171875, 1.0, 1.0, 0.4326171875, 0.4326171875, 0.435546875, 0.43359375, 0.4326171875, 0.4326171875, 1.0, 0.431640625, 1.0, 1.0, 0.435546875, 0.4365234375, 1.0, 1.0, 0.4365234375, 0.4287109375, 0.431640625, 0.4345703125, 0.431640625, 0.435546875, 0.4365234375, 0.4365234375, 0.4365234375, 0.4287109375, 1.0, 0.4384765625, 1.0, 1.0, 0.4345703125, 0.4345703125, 0.43359375, 0.4306640625, 1.0, 0.4306640625, 0.4345703125, 0.439453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4365234375, 0.4326171875, 0.4345703125, 0.4306640625, 0.43359375, 0.4375, 0.4365234375, 1.0, 1.0, 1.0, 0.4287109375, 1.0, 0.435546875, 1.0, 0.435546875, 0.443359375, 0.4345703125, 0.43359375, 0.439453125, 0.4326171875, 0.43359375, 0.4296875, 1.0, 0.4375, 1.0, 0.4296875, 0.4345703125, 0.4384765625, 1.0, 0.431640625, 0.427734375, 0.4345703125, 0.431640625, 1.0, 0.4306640625, 0.4345703125, 0.4375, 1.0, 1.0, 0.439453125, 1.0, 0.43359375, 1.0, 1.0, 0.4326171875, 0.4365234375, 1.0, 1.0, 0.435546875, 1.0, 1.0, 0.4365234375, 0.435546875, 1.0, 0.439453125, 0.4326171875, 0.4384765625, 0.4345703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4375, 0.4287109375, 0.42578125, 0.43359375, 0.4326171875, 1.0, 0.4365234375, 0.4306640625, 1.0, 1.0, 1.0, 1.0, 0.4306640625, 1.0, 0.4345703125, 0.4345703125, 0.4326171875, 1.0, 0.43359375, 0.435546875, 0.4345703125, 1.0, 0.431640625, 1.0]

 sparsity of   [1.0, 0.4388020932674408, 1.0, 1.0, 0.4422743022441864, 1.0, 0.4401041567325592, 0.440972238779068, 1.0, 0.440972238779068, 0.4405381977558136, 1.0, 0.440972238779068, 1.0, 1.0, 0.4396701455116272, 0.4444444477558136, 1.0, 1.0, 0.44140625, 1.0, 0.4396701455116272, 1.0, 1.0, 1.0, 0.4396701455116272, 1.0, 0.4418402910232544, 1.0, 0.4401041567325592, 1.0, 0.4427083432674408, 1.0, 0.44140625, 1.0, 0.440972238779068, 0.4396701455116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4431423544883728, 1.0, 0.4396701455116272, 1.0, 1.0, 0.44140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4392361044883728, 0.4396701455116272, 0.4392361044883728, 1.0, 1.0, 0.4405381977558136, 0.4396701455116272, 1.0, 1.0, 1.0, 1.0, 0.4427083432674408, 1.0, 0.4405381977558136, 1.0, 0.4435763955116272, 1.0, 1.0, 0.4396701455116272, 0.440972238779068, 1.0, 1.0, 1.0, 1.0, 0.4401041567325592, 0.4401041567325592, 1.0, 1.0, 0.4379340410232544, 0.4422743022441864, 0.4401041567325592, 0.4422743022441864, 1.0, 1.0, 1.0, 1.0, 0.4396701455116272, 1.0, 1.0, 0.4392361044883728, 1.0, 0.4401041567325592, 1.0, 0.4392361044883728, 0.4401041567325592, 0.4396701455116272, 0.4396701455116272, 1.0, 1.0, 1.0, 0.440972238779068, 0.440972238779068, 0.44140625, 0.4405381977558136, 0.4440104067325592, 0.440972238779068, 1.0, 1.0, 0.4418402910232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.44140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4388020932674408, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4431423544883728, 1.0, 0.4422743022441864, 0.440972238779068, 1.0, 0.4401041567325592, 1.0, 1.0, 1.0, 0.4383680522441864, 0.4422743022441864, 0.4405381977558136, 1.0, 0.44140625, 1.0, 0.4405381977558136, 1.0, 1.0, 0.440972238779068, 0.4405381977558136, 1.0, 0.4405381977558136, 0.4392361044883728, 0.4392361044883728, 1.0, 0.4401041567325592, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4388020932674408, 1.0, 0.4396701455116272, 1.0, 1.0, 0.4431423544883728, 1.0, 0.4401041567325592, 0.4405381977558136, 1.0, 1.0, 1.0, 0.4392361044883728, 1.0, 1.0, 1.0, 0.44140625, 1.0, 0.4388020932674408, 1.0, 0.4422743022441864, 0.4401041567325592, 0.4396701455116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4405381977558136, 1.0, 0.4401041567325592, 1.0, 1.0, 1.0, 0.4401041567325592, 1.0, 1.0, 0.4388020932674408, 1.0, 1.0, 0.440972238779068, 0.4388020932674408, 0.4396701455116272, 0.4396701455116272, 1.0, 0.4422743022441864, 1.0, 1.0, 1.0, 1.0, 0.4405381977558136, 0.4388020932674408, 1.0, 1.0, 1.0, 0.44140625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.440972238779068, 0.4396701455116272, 1.0, 0.4383680522441864, 1.0, 1.0, 0.4418402910232544, 1.0, 1.0, 0.4401041567325592, 1.0, 1.0, 0.4396701455116272, 1.0]

 sparsity of   [0.6171875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62890625, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6171875, 0.6171875, 1.0, 0.62109375, 1.0, 1.0, 0.62109375, 1.0, 0.6171875, 1.0, 1.0, 0.62109375, 0.625, 1.0, 0.625, 0.62109375, 1.0, 1.0, 0.625, 0.625, 1.0, 0.62109375, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 0.625, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.625, 1.0, 0.62109375, 0.625, 1.0, 1.0, 0.62109375, 1.0, 0.6171875, 1.0, 0.6171875, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.6171875, 0.62109375, 0.62109375, 0.62109375, 1.0, 1.0, 1.0, 0.625, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 0.625, 0.62109375, 1.0, 1.0, 1.0, 1.0, 0.6171875, 0.625, 1.0, 1.0, 1.0, 1.0, 0.6171875, 1.0, 0.62109375, 0.62109375, 0.62109375, 0.625, 0.6171875, 1.0, 1.0, 0.6171875, 0.6171875, 1.0, 1.0, 0.62109375, 0.6171875, 1.0, 0.62109375, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.6171875, 1.0, 0.62109375, 0.6171875, 0.6171875, 0.6171875, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.62109375, 0.6171875, 1.0, 1.0, 1.0, 0.63671875, 0.6171875, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6171875, 1.0, 1.0, 1.0, 1.0, 0.625, 0.62109375, 1.0, 0.62109375, 0.62109375, 0.625, 0.625, 0.62109375, 0.625, 0.62109375, 1.0, 1.0, 0.6171875, 0.6171875, 0.62109375, 0.62109375, 1.0, 1.0, 0.6171875, 0.6484375, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 0.62109375, 1.0, 0.62109375, 0.62109375, 1.0, 1.0, 0.62890625, 1.0, 1.0, 0.6171875, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 0.62109375, 0.62109375, 0.625, 0.62109375, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 0.62109375, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.62109375, 0.62109375, 1.0, 1.0, 1.0, 0.6171875, 1.0, 1.0, 0.6171875, 1.0, 1.0, 0.62109375, 1.0, 0.625, 0.6171875, 0.61328125, 0.62890625, 0.6171875, 0.62890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 1.0, 0.6171875, 0.6171875, 1.0, 1.0, 1.0, 0.6171875, 1.0, 0.625, 1.0, 1.0, 1.0, 0.625, 0.6171875, 1.0, 1.0, 1.0, 0.62890625, 1.0, 0.6171875, 1.0, 1.0, 1.0, 0.6171875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 0.625, 0.62109375, 0.6171875, 0.625, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.62109375, 0.62109375, 1.0, 1.0, 1.0, 0.62890625, 1.0, 0.62890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6171875, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 0.62109375, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.62109375, 0.62109375, 1.0, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 1.0, 0.6171875, 0.625, 0.62109375, 0.625, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 0.62109375, 1.0, 0.625, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 0.6171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6171875, 0.62890625, 0.6171875, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.6171875, 1.0, 1.0, 1.0, 1.0, 0.6171875, 0.625, 0.62109375, 0.6171875, 1.0, 1.0, 1.0, 0.62109375, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 0.6171875, 0.62109375, 0.62109375, 1.0, 0.6171875, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.62109375, 0.6171875, 1.0, 0.625, 1.0, 0.625, 0.62109375, 1.0, 1.0, 0.62109375, 0.62109375, 1.0, 1.0, 1.0, 0.625, 1.0, 0.62890625, 0.6171875, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.62109375, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 0.62109375, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 0.62109375, 0.62109375, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 0.6171875, 1.0, 0.62109375, 1.0, 0.625, 1.0, 0.625, 1.0, 1.0, 0.6171875, 0.62109375, 1.0, 0.62109375, 0.625, 0.62109375, 0.6171875, 0.62109375, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 0.62109375, 0.62109375, 0.625, 1.0, 0.6171875, 1.0, 1.0, 0.62109375, 1.0, 0.6171875, 0.62890625, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.640625, 1.0, 1.0, 0.62109375, 1.0, 1.0, 0.625, 1.0, 0.62109375, 0.62109375, 1.0, 0.625, 1.0, 0.62109375, 1.0, 1.0, 0.625, 0.62109375, 1.0, 1.0, 0.62109375, 0.6171875, 1.0, 1.0, 1.0, 0.6171875, 1.0, 0.61328125, 0.6171875, 0.6171875, 0.625, 0.6171875, 1.0, 0.625, 0.6171875, 1.0, 0.625, 0.625, 1.0, 0.62109375, 1.0, 1.0, 0.62109375, 1.0, 1.0, 0.62109375, 0.625, 0.62109375, 1.0, 0.625, 0.62109375, 0.62890625, 0.62890625, 0.625, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 0.62109375, 0.6171875, 1.0, 1.0, 0.62109375, 0.62109375, 0.62109375, 1.0, 1.0, 0.62109375, 0.62109375, 0.625, 0.62109375, 0.6171875, 1.0, 1.0, 0.62109375, 0.62109375, 1.0, 0.61328125, 0.62109375, 1.0, 0.62109375, 1.0, 0.625, 1.0, 0.625, 0.625, 0.62109375, 1.0, 0.62109375, 1.0, 0.625, 1.0, 0.62109375, 0.6171875, 0.62109375, 0.62109375, 0.6171875, 1.0, 0.62109375, 0.625, 0.62109375, 0.625, 0.62109375, 0.62109375, 1.0, 0.62109375, 0.6171875, 0.62109375, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 0.62109375, 0.62109375, 0.625, 1.0, 1.0, 1.0, 0.625, 0.62109375, 1.0, 1.0, 1.0, 0.63671875, 0.6171875, 1.0, 1.0, 0.6171875, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 0.625, 1.0, 0.625, 0.6171875, 1.0, 0.62109375, 0.62109375, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.6171875, 0.625, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.6171875, 1.0, 1.0, 1.0, 0.6171875, 1.0, 0.62109375, 1.0, 0.625, 1.0, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 0.625, 0.62109375, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.625, 1.0, 0.6171875, 1.0, 1.0, 1.0, 0.62109375, 0.62109375, 1.0, 1.0, 1.0, 1.0, 0.625, 1.0, 0.62109375, 1.0, 0.6171875, 0.62109375, 1.0, 1.0, 0.62109375, 1.0, 0.6171875, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.62890625, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 0.62109375, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.62109375, 0.6171875, 0.6171875, 1.0, 0.62109375, 0.6171875, 0.62109375, 0.62109375, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6171875, 0.62109375, 1.0, 1.0, 0.6171875, 0.62109375, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6171875, 1.0, 1.0, 1.0, 0.62890625, 1.0, 1.0, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.63671875, 0.625, 0.6171875, 1.0, 1.0, 0.625, 0.62109375, 0.62109375, 0.625, 0.625, 1.0, 0.6171875, 1.0, 1.0, 1.0, 1.0, 0.6171875, 0.62109375, 1.0, 0.62109375, 0.62890625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 0.625, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 0.62109375, 0.62109375, 1.0, 1.0, 0.62109375, 0.62109375, 0.62109375, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 0.6171875, 0.62109375, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 0.62109375, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62890625, 0.62109375, 0.625, 0.62109375, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 0.62109375, 1.0, 1.0, 0.6171875, 0.6171875, 0.62109375, 0.62109375, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.625, 0.62109375, 1.0, 0.62109375, 0.625, 1.0, 1.0, 1.0, 0.62109375, 0.625, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 0.6171875, 0.62109375, 0.6171875, 1.0, 1.0, 0.625, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 0.625, 0.6171875, 1.0, 0.62109375]

 sparsity of   [1.0, 1.0, 0.4091796875, 0.4091796875, 1.0, 1.0, 0.41796875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.421875, 1.0, 1.0, 0.4150390625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.41015625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.41796875, 1.0, 0.421875, 1.0, 0.4052734375, 1.0, 1.0, 0.4091796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4541015625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4072265625, 1.0, 1.0, 0.4150390625, 1.0, 1.0, 1.0, 1.0, 0.408203125, 0.4296875, 1.0, 0.4013671875, 1.0, 1.0, 0.4111328125, 1.0, 0.4150390625, 0.41015625, 1.0, 0.4130859375, 1.0, 0.408203125, 1.0, 1.0, 1.0, 1.0, 0.4111328125, 0.4140625, 1.0, 1.0, 1.0, 1.0, 0.408203125, 0.41015625, 0.408203125, 0.4228515625, 1.0, 1.0, 0.41015625, 1.0, 1.0, 1.0, 0.41015625, 1.0, 1.0, 1.0, 0.4091796875, 1.0, 1.0, 1.0, 0.4130859375, 1.0, 1.0, 1.0, 1.0, 0.404296875, 0.41796875, 1.0, 1.0, 0.416015625, 1.0, 1.0, 1.0, 1.0, 0.4111328125, 0.4111328125, 1.0, 0.4130859375, 1.0, 1.0, 1.0, 0.40625, 0.41796875, 0.40625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.412109375, 1.0, 1.0, 0.4091796875, 0.4052734375, 1.0, 1.0, 0.4072265625, 1.0, 1.0, 1.0, 1.0, 0.4052734375, 1.0, 0.4140625, 1.0, 0.4150390625, 1.0, 1.0, 1.0, 0.4208984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.40625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4072265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4140625, 0.41015625, 0.4228515625, 1.0, 1.0, 1.0, 0.40625, 1.0, 1.0, 1.0, 1.0, 0.4111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.408203125, 1.0, 1.0, 1.0, 1.0, 0.4111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.408203125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.408203125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4150390625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.423828125, 1.0, 1.0, 1.0, 0.4091796875, 0.41015625, 0.4033203125]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 0.7326388955116272, 1.0, 1.0, 1.0, 0.73046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7282986044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7300347089767456, 0.7352430820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7282986044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7300347089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7365451455116272, 1.0, 0.7348090410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7291666865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7209201455116272, 1.0, 1.0, 1.0, 0.7282986044883728, 1.0, 0.7287326455116272, 1.0, 1.0, 0.729600727558136, 1.0, 0.7291666865348816, 1.0, 1.0, 1.0, 1.0, 0.73046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7287326455116272, 1.0, 0.7322048544883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7769097089767456, 1.0, 0.7313368320465088, 0.7282986044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7282986044883728, 0.7313368320465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7282986044883728, 1.0, 0.7252604365348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7330729365348816, 1.0, 1.0, 0.7287326455116272, 1.0, 1.0, 0.7326388955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.734375, 0.7322048544883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7261284589767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7261284589767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7330729365348816, 1.0, 0.7309027910232544, 1.0, 1.0, 1.0, 0.7243923544883728, 1.0, 1.0, 1.0, 0.7322048544883728, 1.0, 1.0, 0.7339409589767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7252604365348816, 0.7326388955116272, 1.0, 0.7269965410232544]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 0.859375, 1.0, 1.0, 1.0, 1.0, 0.8359375, 0.8359375, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 0.8359375, 0.83984375, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.83984375, 0.8359375, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 0.8515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 0.83984375, 1.0, 1.0, 1.0, 0.83203125, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83203125, 1.0, 1.0, 0.85546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 0.8359375, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 0.83984375, 0.8359375, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 0.84375, 1.0, 1.0, 0.83984375, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.84765625, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.84375, 1.0, 0.83203125, 0.83984375, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.8359375, 1.0, 1.0, 0.8359375, 1.0, 0.83984375, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.83984375, 1.0, 0.8359375, 0.83984375, 1.0, 1.0, 0.84765625, 0.83984375, 1.0, 0.83203125, 1.0, 1.0, 1.0, 0.8359375, 1.0, 0.8359375, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 0.83203125, 1.0, 0.83984375, 1.0, 1.0, 1.0, 0.8359375, 0.8359375, 1.0, 0.83984375, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 0.83984375, 1.0, 0.83984375, 0.83984375, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 0.83984375, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.828125, 1.0, 1.0, 0.8359375, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 0.8359375, 1.0, 1.0, 0.83984375, 0.8359375, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83203125, 1.0, 1.0, 1.0, 0.83984375, 0.8359375, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 0.8359375, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.8359375, 1.0, 0.83984375, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.8359375]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4306640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4228515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.427734375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4853515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4521484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.990234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4208984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4228515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4248046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.46875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4130859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6337890625, 1.0, 1.0, 1.0, 1.0, 0.416015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4169921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4208984375, 1.0, 1.0, 0.4189453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4443359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4189453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4189453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.416015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.416015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6533203125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4248046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4150390625, 1.0, 1.0, 0.4150390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.525390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.46875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4150390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.583984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4150390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.455078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.41796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4111328125, 1.0, 1.0, 1.0, 0.4189453125, 1.0, 1.0, 1.0, 0.4140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4169921875, 1.0, 0.576171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5087890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4267578125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.666015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4091796875, 0.5322265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.419921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5400390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4150390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4208984375, 1.0, 1.0, 0.416015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4072265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.416015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.40625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.412109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.40625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.416015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.52685546875, 0.525390625, 0.52685546875, 0.52880859375, 0.52734375, 0.52880859375, 0.5283203125, 0.5283203125, 0.5263671875, 0.52587890625, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125]

Total parameter pruned: 22546319.00338237 (unstructured) 21278559 (structured)

Test: [0/79]	Time 0.155 (0.155)	Loss 0.3271 (0.3271) ([0.199]+[0.128])	Prec@1 94.531 (94.531)
 * Prec@1 94.410

 Total elapsed time  3:53:00.467472 
 FINETUNING


 sparsity of   [0.0, 0.0, 0.0, 0.0, 1.0, 0.03703703731298447, 1.0, 0.0, 0.03703703731298447, 0.03703703731298447, 0.6666666865348816, 0.0, 0.0, 0.03703703731298447, 0.03703703731298447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.03703703731298447, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03703703731298447, 0.03703703731298447, 0.0, 0.03703703731298447, 0.0, 0.1111111119389534, 0.0, 0.0, 0.0, 0.07407407462596893, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]

 sparsity of   [1.0, 0.203125, 0.203125, 1.0, 0.25, 0.203125, 0.203125, 0.203125, 0.21875, 0.21875, 0.21875, 1.0, 0.203125, 0.234375, 1.0, 1.0, 1.0, 0.203125, 0.203125, 0.28125, 0.203125, 0.203125, 0.21875, 0.203125, 1.0, 0.21875, 1.0, 1.0, 0.21875, 0.234375, 1.0, 0.203125, 0.203125, 0.21875, 1.0, 1.0, 1.0, 0.21875, 0.21875, 1.0, 1.0, 0.21875, 0.234375, 0.21875, 0.296875, 0.21875, 1.0, 0.203125, 0.203125, 1.0, 0.21875, 0.203125, 0.21875, 1.0, 1.0, 1.0, 0.234375, 1.0, 0.203125, 1.0, 0.21875, 0.296875, 0.234375, 0.25]

 sparsity of   [0.3611111044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.347222238779068, 1.0, 1.0, 0.3923611044883728, 1.0, 0.3420138955116272, 0.347222238779068, 0.3489583432674408, 0.3506944477558136, 0.3489583432674408, 1.0, 1.0, 1.0, 1.0, 0.3489583432674408, 0.34375, 1.0, 1.0, 1.0, 0.3489583432674408, 1.0, 1.0, 0.3454861044883728, 0.3524305522441864, 1.0, 1.0, 1.0, 1.0, 1.0, 0.347222238779068, 0.3454861044883728, 1.0, 0.3506944477558136, 0.3524305522441864, 1.0, 1.0, 0.3420138955116272, 0.3506944477558136, 0.3489583432674408, 0.3645833432674408, 0.3454861044883728, 0.3541666567325592, 0.347222238779068, 0.3506944477558136, 1.0, 0.3454861044883728, 1.0, 0.3489583432674408, 1.0, 1.0, 0.3489583432674408, 0.3489583432674408, 1.0, 0.3506944477558136, 0.34375, 0.3576388955116272]

 sparsity of   [0.484375, 0.5, 0.5, 1.0, 0.5, 0.484375, 0.515625, 0.5, 1.0, 0.484375, 0.515625, 1.0, 1.0, 0.5, 1.0, 0.5, 0.484375, 1.0, 0.5, 0.5, 0.484375, 0.515625, 1.0, 1.0, 0.484375, 1.0, 0.515625, 0.5, 0.5, 0.5, 0.484375, 0.5, 0.484375, 0.484375, 0.484375, 0.5, 1.0, 1.0, 0.46875, 0.5, 0.5, 0.484375, 0.484375, 1.0, 0.5, 1.0, 0.5, 0.515625, 0.5, 0.5, 0.484375, 1.0, 0.5, 1.0, 0.5, 0.46875, 0.53125, 0.5, 0.484375, 0.484375, 0.515625, 0.484375, 0.46875, 0.5, 0.484375, 1.0, 1.0, 1.0, 0.484375, 0.5, 1.0, 0.484375, 0.5, 0.5, 0.46875, 1.0, 0.5, 0.53125, 1.0, 0.484375, 0.484375, 0.484375, 0.484375, 0.484375, 1.0, 1.0, 0.484375, 0.484375, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.46875, 1.0, 0.484375, 0.484375, 1.0, 1.0, 0.484375, 0.515625, 0.5, 1.0, 1.0, 1.0, 0.46875, 0.46875, 1.0, 0.484375, 1.0, 0.46875, 0.484375, 1.0, 1.0, 1.0, 1.0, 0.484375, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.484375, 0.46875, 0.515625, 1.0, 0.515625, 0.46875, 1.0, 0.5, 0.484375, 0.484375, 0.5, 0.46875, 1.0, 1.0, 0.5, 1.0, 1.0, 0.484375, 0.484375, 1.0, 0.515625, 0.5, 0.5, 0.484375, 1.0, 0.484375, 0.5, 0.484375, 0.5, 0.5, 1.0, 1.0, 0.484375, 0.515625, 0.484375, 1.0, 0.515625, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 0.484375, 0.484375, 0.484375, 1.0, 0.5625, 0.5, 0.515625, 0.515625, 0.484375, 1.0, 1.0, 0.5, 0.5, 0.5, 0.515625, 1.0, 0.5, 0.484375, 1.0, 0.5, 0.515625, 0.5, 1.0, 1.0, 1.0, 0.484375, 1.0, 0.484375, 0.515625, 0.515625, 0.5, 1.0, 0.484375, 0.5, 0.484375, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.46875, 1.0, 1.0, 0.5, 0.484375, 0.484375, 1.0, 0.484375, 0.484375, 0.484375, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.484375, 1.0, 0.484375, 0.5, 0.46875, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.53125, 0.515625, 0.484375, 0.5, 0.484375, 0.5]

 sparsity of   [0.265625, 0.203125, 0.21875, 0.203125, 0.234375, 0.234375, 0.21875, 0.21875, 0.265625, 0.265625, 0.203125, 0.234375, 0.296875, 0.296875, 1.0, 0.21875, 0.234375, 0.21875, 0.28125, 0.234375, 0.203125, 0.234375, 0.203125, 1.0, 0.234375, 1.0, 0.203125, 0.203125, 0.203125, 0.265625, 0.25, 0.21875, 0.21875, 0.234375, 1.0, 0.203125, 1.0, 1.0, 0.234375, 0.21875, 0.203125, 0.3125, 0.234375, 1.0, 0.234375, 0.25, 0.203125, 0.21875, 0.265625, 0.203125, 0.234375, 0.25, 0.359375, 0.21875, 0.21875, 0.234375, 0.234375, 0.265625, 0.21875, 0.203125, 0.234375, 0.234375, 0.25, 0.21875, 0.234375, 1.0, 0.21875, 1.0, 0.203125, 0.234375, 1.0, 0.28125, 0.203125, 0.234375, 0.25, 1.0, 0.203125, 0.25, 1.0, 0.234375, 0.3125, 0.21875, 0.21875, 0.203125, 1.0, 1.0, 0.21875, 0.203125, 0.21875, 1.0, 1.0, 0.234375, 1.0, 0.25, 0.203125, 0.265625, 0.25, 0.25, 0.21875, 0.21875, 1.0, 1.0, 0.21875, 0.21875, 0.21875, 1.0, 0.21875, 0.203125, 0.25, 0.25, 0.21875, 0.25, 1.0, 0.234375, 0.234375, 0.265625, 1.0, 0.21875, 1.0, 0.203125, 1.0, 0.203125, 0.203125, 0.203125, 0.25, 0.21875, 0.203125, 0.21875, 0.21875, 0.21875, 0.203125, 1.0, 0.25, 0.21875, 1.0, 0.28125, 0.21875, 0.328125, 0.21875, 0.21875, 1.0, 0.21875, 0.28125, 0.21875, 0.40625, 0.28125, 0.203125, 0.234375, 0.203125, 0.234375, 0.203125, 0.21875, 1.0, 0.203125, 1.0, 0.21875, 0.265625, 0.40625, 1.0, 1.0, 0.25, 0.203125, 0.25, 1.0, 0.21875, 0.265625, 1.0, 0.203125, 0.203125, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.21875, 0.234375, 0.25, 1.0, 0.21875, 0.234375, 0.25, 0.203125, 0.21875, 1.0, 1.0, 0.265625, 0.234375, 0.21875, 0.21875, 1.0, 0.21875, 0.21875, 0.21875, 0.25, 0.203125, 0.203125, 0.234375, 1.0, 1.0, 0.203125, 1.0, 0.203125, 0.25, 0.234375, 0.21875, 1.0, 0.203125, 0.203125, 0.21875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.203125, 0.203125, 1.0, 1.0, 0.265625, 0.203125, 0.234375, 0.203125, 0.234375, 0.25, 0.421875, 0.203125, 1.0, 0.28125, 1.0, 1.0, 0.203125, 1.0, 0.21875, 0.234375, 1.0, 0.203125, 0.203125, 0.25, 1.0, 1.0, 0.21875, 1.0, 1.0, 1.0, 0.203125, 1.0, 1.0, 0.21875, 0.21875, 1.0, 0.21875, 0.21875, 0.21875, 0.21875]

 sparsity of   [1.0, 0.2421875, 0.22265625, 1.0, 1.0, 1.0, 0.24609375, 1.0, 1.0, 0.2421875, 1.0, 1.0, 1.0, 0.21875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2265625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.23828125, 1.0, 1.0, 0.30078125, 1.0, 0.25390625, 0.24609375, 0.23046875, 0.23046875, 1.0, 0.23046875, 1.0, 1.0, 1.0, 0.22265625, 1.0, 0.21875, 0.22265625, 0.2265625, 1.0, 0.21875, 0.234375, 0.2734375, 0.24609375, 1.0, 0.22265625, 1.0, 0.23046875, 1.0, 1.0, 0.24609375, 0.22265625, 0.234375, 0.22265625, 1.0, 1.0, 1.0, 1.0, 0.234375]

 sparsity of   [1.0, 0.5642361044883728, 1.0, 1.0, 0.5607638955116272, 1.0, 0.585069477558136, 0.5677083134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5729166865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5555555820465088, 1.0, 1.0, 0.5815972089767456, 0.5677083134651184, 0.553819477558136, 0.5868055820465088, 0.5572916865348816, 1.0, 1.0, 0.5815972089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5729166865348816, 1.0, 0.59375, 1.0, 1.0, 0.5677083134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5572916865348816, 1.0, 0.5486111044883728, 0.5590277910232544, 0.569444477558136, 1.0, 1.0, 1.0, 0.5503472089767456]

 sparsity of   [0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.671875, 0.671875, 0.671875, 1.0, 0.671875, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 1.0, 1.0, 0.6875, 0.703125, 0.6875, 1.0, 1.0, 0.6875, 1.0, 1.0, 1.0, 0.671875, 0.6875, 0.671875, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.671875, 0.65625, 0.703125, 1.0, 0.671875, 1.0, 0.6875, 0.65625, 0.671875, 1.0, 1.0, 0.671875, 0.6875, 0.65625, 0.6875, 0.671875, 1.0, 1.0, 0.671875, 0.6875, 1.0, 0.65625, 0.6875, 0.671875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.671875, 0.6875, 0.671875, 0.671875, 1.0, 0.671875, 0.65625, 0.6875, 0.65625, 0.703125, 0.6875, 1.0, 0.65625, 0.65625, 0.6875, 0.65625, 0.6875, 1.0, 1.0, 0.703125, 0.65625, 0.6875, 1.0, 1.0, 0.671875, 1.0, 1.0, 0.734375, 1.0, 0.6875, 1.0, 0.6875, 0.65625, 1.0, 0.6875, 1.0, 0.6875, 0.671875, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.671875, 1.0, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 0.671875, 1.0, 1.0, 1.0, 0.6875, 0.6875, 0.703125, 0.671875, 1.0, 0.65625, 0.6875, 1.0, 1.0, 0.6875, 0.671875, 1.0, 1.0, 0.671875, 1.0, 0.6875, 1.0, 1.0, 1.0, 0.671875, 1.0, 0.6875, 0.6875, 0.671875, 0.703125, 0.671875, 0.6875, 1.0, 0.671875, 1.0, 0.6875, 1.0, 1.0, 0.671875, 0.6875, 1.0, 1.0, 0.703125, 1.0, 0.671875, 0.6875, 0.6875, 1.0, 0.65625, 1.0, 1.0, 0.671875, 1.0, 1.0, 1.0, 0.671875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 0.65625, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.671875, 1.0, 1.0, 0.671875, 0.671875, 1.0, 1.0, 0.671875, 0.671875, 1.0, 0.671875, 1.0, 0.671875, 0.6875, 0.6875, 0.6875, 0.65625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 1.0, 1.0, 0.65625, 0.6875, 0.6875, 0.703125, 1.0, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6875, 0.671875, 0.671875, 0.703125, 1.0, 0.671875, 0.703125, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.671875, 1.0, 1.0, 0.6875, 1.0, 0.671875, 0.65625, 0.671875, 0.671875]

 sparsity of   [1.0, 1.0, 0.15625, 0.171875, 1.0, 1.0, 0.140625, 1.0, 0.15625, 0.17578125, 1.0, 0.1875, 0.16796875, 1.0, 1.0, 0.15234375, 0.15234375, 1.0, 0.16015625, 1.0, 0.19140625, 1.0, 0.16796875, 1.0, 0.1484375, 0.1640625, 0.1484375, 0.17578125, 0.15234375, 0.15234375, 1.0, 0.15625, 1.0, 0.1484375, 0.171875, 1.0, 1.0, 1.0, 1.0, 0.17578125, 1.0, 1.0, 1.0, 0.15625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16796875, 1.0, 0.14453125, 0.14453125, 1.0, 1.0, 0.1484375, 1.0, 0.1640625, 1.0, 0.1796875, 1.0, 0.15625, 1.0, 1.0]

 sparsity of   [0.5416666865348816, 0.5190972089767456, 0.5277777910232544, 0.5295138955116272, 0.5243055820465088, 0.5277777910232544, 1.0, 1.0, 0.5347222089767456, 1.0, 1.0, 1.0, 0.5190972089767456, 1.0, 1.0, 0.5434027910232544, 1.0, 0.5208333134651184, 0.5295138955116272, 1.0, 0.5277777910232544, 0.5295138955116272, 1.0, 0.5260416865348816, 0.5243055820465088, 0.5260416865348816, 0.5295138955116272, 1.0, 0.5277777910232544, 1.0, 0.5208333134651184, 1.0, 0.522569477558136, 0.5295138955116272, 0.5364583134651184, 0.53125, 0.553819477558136, 0.5399305820465088, 0.5399305820465088, 0.8246527910232544, 1.0, 1.0, 1.0, 0.5347222089767456, 1.0, 0.5260416865348816, 0.515625, 1.0, 1.0, 1.0, 0.538194477558136, 0.5434027910232544, 0.5364583134651184, 1.0, 1.0, 0.5347222089767456, 0.5243055820465088, 0.53125, 0.5434027910232544, 0.5555555820465088, 1.0, 1.0, 0.5434027910232544, 1.0]

 sparsity of   [0.375, 1.0, 1.0, 1.0, 1.0, 0.375, 0.390625, 0.40625, 1.0, 0.40625, 0.390625, 0.390625, 1.0, 0.375, 0.375, 0.390625, 0.40625, 0.390625, 0.421875, 1.0, 0.390625, 0.40625, 1.0, 0.359375, 0.359375, 0.375, 0.359375, 1.0, 0.40625, 1.0, 0.390625, 0.40625, 0.40625, 0.375, 0.40625, 1.0, 0.359375, 0.359375, 0.359375, 0.390625, 0.390625, 0.390625, 0.375, 0.375, 0.390625, 1.0, 0.390625, 0.390625, 0.359375, 0.375, 0.375, 0.40625, 0.359375, 1.0, 0.4375, 0.375, 0.375, 0.421875, 0.375, 0.375, 0.390625, 0.375, 0.375, 1.0, 0.390625, 0.375, 0.40625, 0.375, 0.359375, 0.390625, 0.40625, 0.390625, 0.375, 0.390625, 0.390625, 0.40625, 0.375, 0.359375, 0.359375, 0.375, 0.359375, 0.375, 0.40625, 0.375, 0.375, 1.0, 0.40625, 0.390625, 0.375, 0.359375, 0.375, 0.421875, 1.0, 1.0, 0.375, 1.0, 0.375, 1.0, 0.359375, 0.359375, 0.359375, 0.375, 1.0, 1.0, 0.40625, 0.390625, 1.0, 1.0, 0.40625, 0.390625, 1.0, 0.390625, 1.0, 0.375, 0.390625, 1.0, 0.359375, 0.40625, 0.359375, 1.0, 1.0, 0.390625, 0.375, 0.375, 1.0, 0.421875, 0.40625, 0.375, 0.375, 0.40625, 0.4375, 0.375, 0.40625, 0.40625, 0.375, 1.0, 0.375, 0.359375, 0.390625, 0.359375, 0.375, 1.0, 0.390625, 0.40625, 1.0, 1.0, 0.359375, 1.0, 0.375, 0.390625, 0.375, 0.390625, 0.421875, 0.359375, 1.0, 0.390625, 0.359375, 1.0, 0.359375, 1.0, 0.390625, 0.375, 0.390625, 0.359375, 0.375, 1.0, 0.359375, 0.40625, 0.390625, 1.0, 0.359375, 1.0, 0.375, 1.0, 1.0, 1.0, 0.390625, 0.359375, 0.421875, 0.359375, 0.390625, 0.390625, 1.0, 0.40625, 0.375, 1.0, 0.390625, 1.0, 0.375, 0.390625, 0.40625, 1.0, 0.40625, 1.0, 0.421875, 0.375, 0.390625, 0.359375, 0.375, 0.359375, 0.359375, 0.375, 0.390625, 0.390625, 0.40625, 0.390625, 0.40625, 1.0, 0.390625, 0.390625, 0.375, 0.359375, 0.375, 1.0, 0.390625, 0.359375, 0.390625, 0.375, 0.390625, 0.390625, 0.390625, 0.375, 0.390625, 1.0, 0.375, 1.0, 0.359375, 0.40625, 1.0, 1.0, 0.359375, 0.359375, 0.375, 0.40625, 0.390625, 0.40625, 1.0, 0.375, 0.375, 0.375, 0.359375, 0.375, 0.390625, 0.40625, 0.375, 1.0, 0.359375, 0.375, 0.375, 1.0, 0.375, 1.0, 0.375, 0.40625, 0.375, 0.40625]

 sparsity of   [0.02734375, 1.0, 1.0, 0.03515625, 0.03125, 1.0, 0.0625, 1.0, 1.0, 0.03125, 1.0, 0.01953125, 1.0, 1.0, 1.0, 1.0, 0.01953125, 1.0, 1.0, 1.0, 1.0, 0.02734375, 1.0, 1.0, 1.0, 0.02734375, 1.0, 1.0, 0.03125, 0.03515625, 1.0, 1.0, 0.0390625, 0.01953125, 0.02734375, 0.0546875, 0.03515625, 1.0, 1.0, 0.03125, 0.015625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0234375, 1.0, 0.03515625, 1.0, 1.0, 0.02734375, 0.015625, 0.03515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0234375, 1.0, 1.0, 0.0234375, 1.0, 1.0, 0.03515625, 0.0234375, 1.0, 0.08984375, 1.0, 0.03515625, 1.0, 1.0, 0.05078125, 0.03515625, 0.02734375, 0.01953125, 1.0, 1.0, 0.03515625, 0.03125, 0.0234375, 1.0, 0.02734375, 1.0, 0.03125, 1.0, 0.0390625, 0.01953125, 0.01953125, 1.0, 1.0, 0.02734375, 0.01953125, 1.0, 1.0, 0.01953125, 0.0234375, 0.03515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.02734375, 1.0, 1.0, 0.0234375, 1.0, 1.0, 1.0, 1.0, 0.0234375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.03515625, 1.0, 0.0546875, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 0.600694477558136, 0.6050347089767456, 0.6041666865348816, 1.0, 1.0, 1.0, 0.6032986044883728, 0.6015625, 1.0, 0.6015625, 1.0, 0.5963541865348816, 1.0, 0.6032986044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6015625, 0.6015625, 1.0, 0.6032986044883728, 0.5998263955116272, 1.0, 1.0, 1.0, 1.0, 0.6050347089767456, 1.0, 1.0, 1.0, 0.6041666865348816, 1.0, 0.6024305820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6032986044883728, 1.0, 1.0, 1.0, 1.0, 0.5989583134651184, 1.0, 0.6032986044883728, 1.0, 1.0, 1.0, 1.0, 0.5998263955116272, 1.0, 0.600694477558136, 1.0, 1.0, 0.6041666865348816, 1.0, 0.6050347089767456, 0.6041666865348816, 0.5989583134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6015625, 1.0, 1.0, 1.0, 1.0, 0.6032986044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5998263955116272, 1.0, 0.6059027910232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5972222089767456, 0.6032986044883728, 0.6041666865348816, 1.0, 1.0, 0.6076388955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6024305820465088, 0.600694477558136, 1.0, 1.0, 0.5989583134651184, 0.6041666865348816, 0.6041666865348816, 1.0, 1.0, 1.0, 1.0, 0.6041666865348816, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 0.6796875, 1.0, 0.6953125, 0.703125, 1.0, 0.6953125, 1.0, 0.6875, 1.0, 0.703125, 1.0, 1.0, 0.6875, 1.0, 1.0, 0.6875, 1.0, 1.0, 0.6875, 0.6953125, 1.0, 1.0, 0.6875, 0.6953125, 0.6953125, 0.703125, 1.0, 0.703125, 0.6953125, 1.0, 1.0, 1.0, 0.6875, 0.734375, 1.0, 1.0, 0.6875, 0.6796875, 0.6875, 0.6953125, 0.6953125, 1.0, 0.6953125, 1.0, 1.0, 1.0, 0.6953125, 0.6875, 1.0, 0.703125, 0.6875, 0.6953125, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6796875, 0.6875, 0.6875, 1.0, 1.0, 1.0, 0.6875, 0.6875, 0.6796875, 0.6875, 1.0, 0.6953125, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6953125, 1.0, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 0.7109375, 0.6875, 1.0, 0.6796875, 0.703125, 0.6875, 0.703125, 0.703125, 0.6953125, 0.703125, 0.6875, 0.6796875, 0.703125, 1.0, 1.0, 0.6953125, 1.0, 1.0, 1.0, 0.703125, 0.703125, 1.0, 0.6875, 0.6953125, 0.703125, 0.7109375, 0.6796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6796875, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6953125, 0.6953125, 0.6796875, 1.0, 1.0, 0.6953125, 0.6953125, 0.703125, 0.703125, 1.0, 1.0, 0.6953125, 0.6953125, 0.6875, 0.6796875, 0.6953125, 1.0, 1.0, 0.6875, 0.6875, 0.703125, 1.0, 0.6796875, 0.6875, 1.0, 0.703125, 1.0, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.6953125, 0.6875, 1.0, 0.6953125, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6953125, 1.0, 0.703125, 1.0, 0.6875, 0.6875, 0.6953125, 1.0, 0.6875, 0.703125, 1.0, 1.0, 0.6875, 1.0, 0.6875, 0.703125, 1.0, 1.0, 0.6796875, 1.0, 0.6875, 1.0, 1.0, 0.6953125, 1.0, 1.0, 0.6953125, 0.6875, 1.0, 0.703125, 0.6875, 0.6796875, 0.6875, 1.0, 0.6875, 0.6953125, 0.6953125, 1.0, 1.0, 0.6953125, 0.6875, 0.7109375, 0.703125, 1.0, 0.703125, 1.0, 0.6875, 0.7109375, 1.0, 0.6875, 0.703125, 0.703125, 0.6953125, 0.6953125, 0.6875, 0.703125, 0.6875, 0.703125, 0.6875, 0.7109375, 0.6875, 0.671875, 1.0, 1.0, 1.0, 0.6953125, 0.6875, 0.6953125, 1.0, 0.6875, 1.0, 1.0, 1.0, 0.703125, 0.6953125, 0.6953125, 1.0, 1.0, 0.6875, 0.703125, 0.6875, 0.6796875, 0.6875, 0.6875, 0.6953125, 1.0, 1.0, 0.703125, 0.6953125, 1.0, 1.0, 0.6875, 0.6875, 1.0, 0.6953125, 0.6796875, 0.703125, 0.6953125, 0.6875, 0.6953125, 0.6875, 0.703125, 0.6875, 0.6953125, 0.6953125, 0.6875, 0.6953125, 0.6875, 1.0, 1.0, 0.6953125, 0.6796875, 0.6875, 0.6953125, 0.6875, 0.6953125, 0.6875, 0.703125, 1.0, 0.6953125, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.7109375, 0.6875, 0.6796875, 0.6953125, 1.0, 0.6875, 1.0, 1.0, 0.6953125, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6796875, 0.6953125, 0.6875, 0.6875, 0.6953125, 1.0, 0.6875, 0.6875, 1.0, 0.6953125, 0.7109375, 0.6953125, 1.0, 1.0, 0.6953125, 0.6875, 0.6953125, 0.6875, 0.703125, 0.6953125, 1.0, 1.0, 0.6875, 0.703125, 1.0, 1.0, 1.0, 0.6953125, 1.0, 0.6953125, 0.6953125, 0.6796875, 1.0, 1.0, 1.0, 0.6875, 0.6796875, 0.6875, 0.6953125, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6953125, 0.6875, 0.6875, 0.6875, 0.7109375, 1.0, 0.6953125, 0.6875, 0.6953125, 0.703125, 1.0, 0.703125, 0.6875, 1.0, 1.0, 0.703125, 1.0, 1.0, 0.6875, 0.703125, 1.0, 0.6875, 1.0, 1.0, 0.6953125, 1.0, 0.6875, 0.71875, 0.6953125, 0.7109375, 1.0, 0.6875, 1.0, 0.703125, 1.0, 0.6953125, 1.0, 0.6953125, 0.703125, 1.0, 0.6875, 1.0, 1.0, 0.6953125, 0.6875, 0.6875, 0.6953125, 0.703125, 0.6875, 0.6875, 0.6875, 0.703125, 0.6875, 0.703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6796875, 0.6875, 0.6953125, 0.6953125, 1.0, 1.0, 0.6875, 0.6875, 0.6953125, 0.703125, 0.6875, 1.0, 0.6953125, 1.0, 1.0, 1.0, 0.6953125, 1.0, 1.0, 0.6875, 0.6953125, 1.0, 0.6875, 0.703125, 0.6953125, 1.0, 1.0, 0.6796875, 0.6953125, 0.6875, 0.6953125, 1.0, 1.0, 0.6953125, 1.0, 1.0, 0.6953125, 0.7109375, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 0.6953125, 1.0, 0.6875, 0.6953125, 0.703125, 1.0, 1.0, 0.6953125, 0.6953125, 1.0, 1.0, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6796875, 0.6875, 0.6875, 1.0, 0.6953125, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.6953125, 0.6953125, 1.0, 0.6953125, 0.703125, 0.6875, 0.6953125, 1.0]

 sparsity of   [1.0, 0.0390625, 0.078125, 0.04296875, 0.03515625, 0.04296875, 0.12109375, 1.0, 0.0625, 1.0, 1.0, 1.0, 1.0, 0.0390625, 1.0, 1.0, 0.046875, 1.0, 1.0, 0.0390625, 0.05078125, 1.0, 1.0, 0.02734375, 1.0, 0.0390625, 0.0390625, 1.0, 0.01953125, 0.03125, 1.0, 1.0, 1.0, 0.046875, 0.03515625, 1.0, 1.0, 0.05078125, 0.0390625, 0.04296875, 0.046875, 0.03125, 1.0, 0.03515625, 1.0, 1.0, 1.0, 0.0390625, 0.03515625, 0.05859375, 0.02734375, 0.03515625, 0.01953125, 1.0, 0.04296875, 1.0, 1.0, 1.0, 1.0, 0.0390625, 0.03125, 0.03515625, 1.0, 1.0, 1.0, 0.04296875, 0.03515625, 0.0234375, 0.09375, 1.0, 0.03515625, 0.01953125, 1.0, 0.04296875, 0.0390625, 0.03125, 0.05078125, 1.0, 1.0, 1.0, 0.03125, 1.0, 0.046875, 0.0390625, 0.03125, 0.0390625, 0.02734375, 0.02734375, 1.0, 0.05078125, 0.03125, 0.04296875, 0.03515625, 1.0, 0.04296875, 0.109375, 0.04296875, 0.0234375, 1.0, 0.05078125, 0.03125, 1.0, 0.03125, 0.02734375, 0.03125, 0.03515625, 0.04296875, 0.0390625, 0.02734375, 1.0, 1.0, 0.09375, 1.0, 1.0, 1.0, 0.03515625, 0.0390625, 1.0, 0.03515625, 0.03515625, 0.09765625, 0.01953125, 0.02734375, 1.0, 0.05078125, 1.0, 0.0390625, 1.0, 1.0, 0.02734375, 0.046875, 0.03125, 1.0, 1.0, 1.0, 1.0, 0.0390625, 0.0625, 0.07421875, 0.0390625, 0.0390625, 1.0, 1.0, 0.046875, 0.02734375, 0.0390625, 0.02734375, 1.0, 1.0, 0.04296875, 0.05859375, 0.03515625, 0.19140625, 0.02734375, 1.0, 1.0, 0.02734375, 0.03125, 0.0546875, 1.0, 0.07421875, 0.03125, 1.0, 0.06640625, 1.0, 1.0, 1.0, 1.0, 0.11328125, 1.0, 0.04296875, 0.04296875, 1.0, 0.03125, 1.0, 0.0390625, 1.0, 0.03125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0546875, 0.03125, 1.0, 0.03125, 1.0, 0.03125, 0.16015625, 0.0234375, 1.0, 0.03515625, 1.0, 1.0, 1.0, 0.0390625, 1.0, 0.02734375, 0.03515625, 0.03515625, 1.0, 0.10546875, 1.0, 0.02734375, 0.03515625, 1.0, 0.03515625, 1.0, 0.05078125, 0.03125, 0.0390625, 1.0, 0.03125, 0.0234375, 0.03515625, 0.04296875, 1.0, 0.046875, 0.05859375, 0.03125, 1.0, 1.0, 1.0, 0.0234375, 0.02734375, 0.05078125, 1.0, 0.02734375, 1.0, 0.0390625, 1.0, 1.0, 0.03125, 0.04296875, 0.03515625, 1.0, 0.03125, 0.03515625, 0.04296875, 0.0234375, 0.02734375, 0.03515625, 0.046875, 0.0390625, 0.04296875, 1.0, 1.0, 1.0, 0.03515625, 0.02734375, 0.04296875, 1.0, 0.04296875, 1.0, 1.0, 1.0, 0.02734375, 0.03125, 0.04296875, 0.1015625, 1.0, 0.1875, 1.0, 0.0390625, 0.0625, 0.0390625, 0.05859375, 0.04296875, 1.0, 1.0, 0.02734375, 0.02734375, 0.1015625, 1.0, 0.05078125, 0.13671875, 1.0, 0.1953125, 0.03125, 0.02734375, 0.02734375, 0.05078125, 0.0390625, 0.01953125, 0.03515625, 0.0234375, 0.03125, 0.04296875, 0.02734375, 0.03125, 0.04296875, 1.0, 1.0, 0.02734375, 0.04296875, 0.140625, 1.0, 0.02734375, 0.01953125, 0.11328125, 0.02734375, 1.0, 0.0390625, 0.02734375, 0.0390625, 1.0, 1.0, 0.046875, 0.046875, 0.02734375, 0.03515625, 0.0390625, 1.0, 0.03515625, 1.0, 1.0, 0.05078125, 1.0, 0.03125, 0.0390625, 1.0, 1.0, 1.0, 0.10546875, 0.03125, 1.0, 0.046875, 0.02734375, 1.0, 0.0546875, 0.03125, 1.0, 0.0390625, 0.03125, 0.0390625, 1.0, 1.0, 0.0390625, 0.04296875, 0.02734375, 0.05078125, 0.05859375, 0.03125, 1.0, 1.0, 0.02734375, 0.05078125, 1.0, 1.0, 1.0, 0.1328125, 1.0, 0.02734375, 0.03125, 0.04296875, 1.0, 1.0, 1.0, 1.0, 0.03125, 0.03125, 1.0, 1.0, 0.03125, 0.03125, 1.0, 1.0, 0.03125, 0.046875, 0.03125, 0.03515625, 0.03515625, 0.17578125, 1.0, 0.06640625, 0.03125, 0.046875, 0.02734375, 0.046875, 0.03125, 0.0703125, 1.0, 1.0, 0.0234375, 1.0, 1.0, 0.046875, 0.0390625, 1.0, 0.0234375, 1.0, 1.0, 1.0, 0.0625, 0.1328125, 0.06640625, 0.03125, 0.02734375, 1.0, 0.04296875, 1.0, 0.02734375, 1.0, 0.046875, 1.0, 0.04296875, 0.03515625, 1.0, 0.0390625, 1.0, 1.0, 0.0234375, 0.0546875, 0.046875, 0.05078125, 0.1484375, 0.03125, 0.0390625, 0.02734375, 1.0, 0.02734375, 0.046875, 1.0, 1.0, 1.0, 1.0, 0.0390625, 1.0, 0.109375, 0.046875, 0.046875, 0.02734375, 0.03125, 1.0, 1.0, 0.0390625, 0.0546875, 0.04296875, 0.02734375, 0.02734375, 1.0, 0.02734375, 1.0, 0.03515625, 1.0, 0.078125, 1.0, 1.0, 0.0234375, 0.03125, 1.0, 0.0234375, 0.03125, 0.02734375, 1.0, 0.046875, 0.05078125, 0.03515625, 0.02734375, 0.03125, 1.0, 1.0, 0.03515625, 1.0, 1.0, 0.03515625, 0.0234375, 0.02734375, 1.0, 1.0, 0.0390625, 0.03125, 0.03515625, 0.0390625, 1.0, 0.0234375, 0.046875, 0.03125, 1.0, 0.04296875, 0.03125, 0.02734375, 1.0, 0.04296875, 1.0, 0.04296875, 0.05078125, 1.0, 1.0, 1.0, 0.046875, 0.0390625, 0.046875, 1.0, 0.03125, 0.0390625, 0.05078125, 0.02734375, 0.03515625, 0.0234375, 1.0, 0.0390625, 0.04296875, 0.07421875, 0.03515625, 1.0, 0.04296875, 0.03515625, 0.0546875, 0.04296875, 0.03515625]

 sparsity of   [0.341796875, 1.0, 0.349609375, 1.0, 0.330078125, 0.333984375, 1.0, 1.0, 1.0, 1.0, 0.33203125, 1.0, 1.0, 1.0, 0.353515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.34765625, 0.3359375, 1.0, 1.0, 1.0, 0.328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.330078125, 0.349609375, 1.0, 1.0, 0.333984375, 0.361328125, 0.326171875, 0.3359375, 1.0, 0.341796875, 1.0, 1.0, 1.0, 1.0, 0.328125, 0.32421875, 0.32421875, 0.33203125, 1.0, 1.0, 1.0, 1.0, 0.333984375, 0.328125, 1.0, 1.0, 0.3359375, 1.0, 0.341796875, 1.0, 1.0, 0.357421875, 1.0, 0.328125, 0.3359375, 1.0, 0.328125, 1.0, 0.33984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.34375, 0.33203125, 0.33203125, 0.45703125, 0.333984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.322265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.412109375, 1.0, 1.0, 0.33203125, 1.0, 1.0, 1.0, 0.333984375, 1.0, 1.0, 0.328125, 0.333984375, 1.0, 0.337890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 0.6579861044883728, 1.0, 1.0, 0.6597222089767456, 0.655381977558136, 0.6571180820465088, 0.65625, 1.0, 0.6701388955116272, 1.0, 1.0, 1.0, 0.6597222089767456, 1.0, 1.0, 1.0, 0.6571180820465088, 0.6805555820465088, 1.0, 0.65625, 1.0, 0.6579861044883728, 0.6779513955116272, 0.6579861044883728, 1.0, 0.6605902910232544, 0.6605902910232544, 1.0, 1.0, 1.0, 0.663194477558136, 1.0, 1.0, 1.0, 0.6770833134651184, 1.0, 0.6640625, 1.0, 1.0, 0.6588541865348816, 1.0, 1.0, 1.0, 0.6623263955116272, 0.65625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.65625, 1.0, 1.0, 0.655381977558136, 0.6579861044883728, 1.0, 0.6579861044883728, 1.0, 0.6571180820465088, 1.0, 1.0, 0.663194477558136, 1.0, 1.0, 1.0, 0.6640625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6597222089767456, 0.6623263955116272, 0.663194477558136, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6579861044883728, 0.65625, 0.6649305820465088, 1.0, 1.0, 1.0, 1.0, 0.6536458134651184, 0.6588541865348816, 0.655381977558136, 0.6640625, 0.6840277910232544, 1.0, 1.0, 1.0, 0.6579861044883728, 1.0, 1.0, 0.6545138955116272, 0.6614583134651184, 0.6571180820465088, 1.0, 1.0, 0.6536458134651184, 1.0, 1.0, 0.6597222089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6623263955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6623263955116272, 0.6571180820465088, 1.0, 1.0]

 sparsity of   [1.0, 0.625, 1.0, 0.6328125, 0.6171875, 1.0, 0.6328125, 1.0, 0.6171875, 0.6171875, 1.0, 0.625, 0.625, 0.6328125, 0.625, 1.0, 0.6171875, 0.6328125, 0.6171875, 0.6328125, 1.0, 1.0, 1.0, 0.6328125, 0.625, 0.6171875, 0.6171875, 1.0, 0.625, 0.625, 0.6171875, 1.0, 1.0, 0.6171875, 0.6328125, 0.6171875, 1.0, 0.6171875, 0.625, 0.625, 0.6171875, 0.625, 0.6328125, 0.6171875, 0.625, 1.0, 1.0, 0.625, 0.625, 1.0, 0.6171875, 0.6328125, 0.6328125, 1.0, 1.0, 0.6171875, 1.0, 0.625, 1.0, 0.625, 0.6328125, 0.625, 0.6171875, 0.625, 1.0, 1.0, 0.625, 0.6171875, 0.6171875, 0.6171875, 0.625, 0.6171875, 1.0, 0.6171875, 1.0, 0.625, 0.6171875, 1.0, 1.0, 0.625, 0.625, 0.625, 0.6171875, 0.625, 0.6171875, 0.6328125, 0.6171875, 0.6171875, 0.6171875, 0.625, 0.625, 1.0, 0.6171875, 1.0, 0.6171875, 1.0, 0.625, 0.625, 0.6171875, 0.6171875, 0.625, 1.0, 0.625, 0.6171875, 0.6171875, 0.6171875, 0.625, 0.6171875, 0.625, 0.625, 1.0, 0.625, 0.6171875, 0.6171875, 0.6171875, 0.625, 0.625, 1.0, 0.625, 0.6328125, 1.0, 0.6171875, 0.6171875, 0.6171875, 0.625, 0.6171875, 1.0, 1.0, 1.0, 0.625, 0.625, 0.625, 1.0, 0.625, 1.0, 0.625, 1.0, 0.625, 0.6171875, 0.625, 0.625, 1.0, 1.0, 0.625, 0.6328125, 0.609375, 0.6171875, 0.6328125, 1.0, 0.6171875, 0.6171875, 0.6171875, 0.6171875, 0.6171875, 0.625, 0.625, 0.6171875, 0.625, 1.0, 1.0, 0.625, 0.6171875, 0.625, 1.0, 1.0, 1.0, 1.0, 0.6328125, 0.6171875, 1.0, 0.6328125, 0.625, 1.0, 0.6171875, 0.625, 1.0, 1.0, 0.640625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.6171875, 0.6171875, 0.625, 0.625, 1.0, 0.625, 1.0, 0.6171875, 0.6328125, 0.625, 0.625, 0.6484375, 0.625, 0.6171875, 1.0, 0.6328125, 1.0, 1.0, 0.625, 1.0, 1.0, 0.625, 0.625, 1.0, 0.625, 0.609375, 0.625, 0.6171875, 0.625, 0.6171875, 0.6328125, 0.625, 1.0, 0.625, 1.0, 0.6328125, 0.625, 0.625, 1.0, 0.6328125, 0.6171875, 0.6328125, 1.0, 1.0, 0.6171875, 0.6328125, 0.625, 1.0, 0.625, 0.625, 0.625, 0.6328125, 0.625, 0.6171875, 0.6171875, 0.625, 1.0, 1.0, 1.0, 1.0, 0.6171875, 0.6171875, 0.625, 1.0, 0.6171875, 1.0, 1.0, 0.625, 0.625, 0.625, 0.6328125, 0.625, 0.6171875, 0.625, 0.625, 0.625, 0.625, 0.6328125, 0.6171875, 0.625, 1.0, 1.0, 0.640625, 0.625, 1.0, 1.0, 0.625, 0.625, 1.0, 0.625, 0.6328125, 0.6328125, 0.625, 0.625, 0.6171875, 0.6171875, 0.6171875, 0.6328125, 0.625, 0.6328125, 1.0, 0.6171875, 0.6171875, 1.0, 0.6171875, 0.6328125, 0.625, 0.6328125, 1.0, 0.625, 0.6171875, 0.625, 0.6171875, 1.0, 0.6171875, 0.6171875, 0.6171875, 1.0, 0.6328125, 0.625, 0.625, 0.625, 0.6171875, 0.625, 0.625, 0.6171875, 1.0, 0.625, 0.6171875, 0.6171875, 0.6328125, 1.0, 0.6171875, 1.0, 1.0, 0.625, 0.640625, 0.6171875, 0.6171875, 0.640625, 1.0, 0.625, 0.609375, 0.625, 0.625, 0.6171875, 0.6171875, 0.6171875, 1.0, 0.625, 0.6171875, 0.6328125, 0.625, 1.0, 0.6171875, 1.0, 0.625, 0.625, 0.6171875, 0.6171875, 0.625, 1.0, 0.6171875, 1.0, 0.6171875, 0.625, 0.625, 0.6171875, 1.0, 0.6171875, 1.0, 0.6171875, 0.625, 1.0, 1.0, 0.625, 1.0, 0.625, 1.0, 0.625, 0.625, 0.625, 0.6171875, 0.640625, 0.625, 1.0, 1.0, 0.6171875, 0.625, 0.6171875, 0.625, 0.6328125, 0.625, 0.625, 1.0, 0.625, 0.6171875, 0.6171875, 0.6171875, 1.0, 1.0, 0.625, 0.625, 1.0, 0.6328125, 1.0, 0.625, 0.625, 0.6171875, 0.6171875, 1.0, 0.6171875, 1.0, 0.625, 0.625, 0.625, 1.0, 1.0, 0.625, 0.6171875, 0.625, 1.0, 1.0, 0.625, 0.6171875, 0.6171875, 0.625, 0.625, 0.625, 0.625, 0.6171875, 0.625, 0.625, 0.625, 1.0, 1.0, 0.6171875, 0.625, 0.6171875, 1.0, 0.625, 0.6171875, 0.625, 0.6328125, 0.625, 1.0, 0.6171875, 0.6171875, 1.0, 0.625, 0.6171875, 0.6171875, 0.6171875, 0.625, 1.0, 0.6171875, 1.0, 1.0, 0.6328125, 0.6171875, 0.6328125, 0.6171875, 0.625, 0.6171875, 0.625, 0.625, 1.0, 0.625, 0.625, 0.6171875, 0.625, 0.625, 1.0, 0.6171875, 0.625, 1.0, 1.0, 0.6171875, 0.6171875, 0.625, 1.0, 1.0, 0.6171875, 0.6328125, 0.6171875, 1.0, 0.6171875, 0.6328125, 0.6171875, 0.6171875, 1.0, 1.0, 1.0, 0.6171875, 1.0, 1.0, 0.6171875, 0.625, 0.609375, 0.625, 1.0, 0.625, 0.6171875, 0.6171875, 0.625, 1.0, 0.6171875, 0.625, 0.6171875, 0.6171875, 0.6484375, 0.6171875, 0.6171875, 0.625, 0.6328125, 0.625, 0.625, 0.625, 0.6328125, 0.625, 0.6171875, 0.625, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 0.1875, 0.177734375, 0.1875, 1.0, 1.0, 0.18359375, 0.19140625, 0.318359375, 0.1875, 0.18359375, 1.0, 0.171875, 1.0, 0.18359375, 1.0, 1.0, 1.0, 1.0, 0.220703125, 1.0, 1.0, 1.0, 0.1875, 0.1953125, 0.189453125, 1.0, 0.17578125, 0.1875, 0.18359375, 0.1953125, 1.0, 0.17578125, 1.0, 0.1875, 0.181640625, 0.189453125, 0.1796875, 0.1875, 1.0, 1.0, 0.1875, 0.181640625, 1.0, 0.181640625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1796875, 1.0, 0.189453125, 1.0, 0.1953125, 0.1875, 1.0, 0.18359375, 0.1953125, 1.0, 0.181640625, 0.18359375, 0.193359375, 0.173828125, 1.0, 1.0, 1.0, 0.1796875, 0.177734375, 1.0, 1.0, 1.0, 0.18359375, 1.0, 1.0, 0.185546875, 1.0, 1.0, 0.181640625, 1.0, 0.185546875, 1.0, 0.1875, 0.189453125, 0.193359375, 0.1796875, 1.0, 0.185546875, 1.0, 1.0, 0.185546875, 1.0, 1.0, 1.0, 1.0, 0.181640625, 0.177734375, 1.0, 0.17578125, 0.177734375, 0.185546875, 0.177734375, 0.1875, 0.1875, 1.0, 1.0, 0.18359375, 0.17578125, 1.0, 1.0, 0.185546875, 0.185546875, 0.181640625, 1.0, 1.0, 0.17578125, 0.1875, 1.0, 1.0, 1.0, 0.18359375, 0.1796875, 1.0, 1.0, 0.173828125, 0.18359375]

 sparsity of   [0.4522569477558136, 0.4513888955116272, 0.46875, 0.4505208432674408, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4479166567325592, 0.448784738779068, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4470486044883728, 0.440972238779068, 1.0, 1.0, 0.4583333432674408, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4548611044883728, 0.4479166567325592, 1.0, 1.0, 0.4479166567325592, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4539930522441864, 1.0, 0.4470486044883728, 1.0, 1.0, 1.0, 1.0, 0.4626736044883728, 1.0, 0.453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4435763955116272, 1.0, 0.4505208432674408, 1.0, 1.0, 1.0, 1.0, 0.4600694477558136, 1.0, 1.0, 1.0, 0.4539930522441864, 1.0, 1.0, 1.0, 1.0, 0.4479166567325592, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4609375, 0.4470486044883728, 0.456597238779068, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4513888955116272, 1.0, 0.4592013955116272, 1.0, 0.440972238779068, 0.4479166567325592, 0.4461805522441864, 1.0, 1.0, 0.456597238779068, 0.4539930522441864, 1.0, 1.0, 0.4470486044883728, 0.448784738779068, 1.0, 1.0, 1.0, 1.0, 0.4861111044883728, 1.0, 1.0, 1.0, 1.0, 0.4505208432674408, 0.4470486044883728, 1.0, 1.0, 0.4557291567325592, 1.0, 0.4557291567325592, 1.0, 0.4539930522441864, 0.4539930522441864, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6953125, 0.6875, 1.0, 0.6875, 0.6875, 0.6953125, 1.0, 0.6875, 1.0, 0.6953125, 0.6875, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.6953125, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6953125, 0.6875, 1.0, 1.0, 0.6875, 0.6953125, 1.0, 0.6875, 0.6875, 1.0, 0.6953125, 0.6875, 0.6875, 1.0, 0.6953125, 1.0, 0.6875, 0.6875, 0.6953125, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 1.0, 1.0, 0.6875, 0.6953125, 1.0, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 0.703125, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6953125, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6953125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6953125, 0.6875, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6953125, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6953125, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6953125, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 1.0, 0.6953125, 1.0, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.703125, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.6953125, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6953125, 0.6875, 1.0, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6953125, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6953125, 1.0, 1.0, 0.6953125, 0.6875, 0.6875, 0.6875, 0.6875, 0.703125, 1.0, 1.0, 0.6953125, 1.0, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 0.6953125, 0.6875, 0.6953125, 0.6875, 1.0, 0.6953125, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6953125, 0.6953125, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6953125, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 0.703125, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 1.0, 0.6953125, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 1.0, 1.0, 0.6953125, 0.6875, 1.0, 0.6875, 1.0, 0.6953125, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6953125, 1.0, 1.0, 1.0, 0.6875, 0.703125, 0.6875, 1.0, 0.6875, 1.0, 1.0, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 1.0, 1.0, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 0.734375, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 1.0, 1.0, 1.0, 0.6953125, 0.6875, 0.6875, 0.6953125, 1.0, 0.6953125, 0.6953125, 0.6953125, 0.6875, 0.6953125, 0.6875, 0.6953125, 1.0, 0.6875, 1.0, 1.0, 1.0, 0.6875, 0.6953125, 0.6875, 0.6875, 0.6875, 0.6953125, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6953125, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 1.0, 1.0, 1.0, 0.6875, 0.6953125, 0.6875, 1.0, 0.6953125, 0.6875, 0.6875, 1.0, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 1.0, 0.6875, 0.6875, 0.6875, 0.6875, 1.0, 0.6875, 0.6875, 0.6953125, 0.6875, 1.0, 0.6875, 1.0, 0.6953125, 0.6875, 0.6875, 0.6953125, 1.0, 0.6875, 0.6875, 1.0, 0.6875, 1.0]

 sparsity of   [1.0, 0.14453125, 0.150390625, 0.142578125, 1.0, 0.275390625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.140625, 1.0, 1.0, 0.169921875, 1.0, 1.0, 0.259765625, 1.0, 0.1484375, 1.0, 0.140625, 1.0, 1.0, 0.142578125, 0.1796875, 1.0, 0.14453125, 1.0, 0.142578125, 1.0, 0.138671875, 0.90234375, 1.0, 1.0, 1.0, 1.0, 0.1484375, 0.140625, 0.15234375, 1.0, 1.0, 1.0, 0.150390625, 1.0, 0.140625, 1.0, 0.140625, 1.0, 1.0, 0.25, 1.0, 0.140625, 0.14453125, 0.19140625, 0.14453125, 1.0, 0.146484375, 0.1484375, 1.0, 0.19921875, 1.0, 0.1484375, 1.0, 0.14453125, 1.0, 1.0, 0.142578125, 0.302734375, 1.0, 1.0, 0.154296875, 1.0, 1.0, 1.0, 0.1484375, 0.150390625, 1.0, 0.189453125, 1.0, 1.0, 0.13671875, 0.2421875, 1.0, 0.13671875, 1.0, 0.140625, 1.0, 0.1875, 1.0, 1.0, 0.142578125, 0.146484375, 1.0, 1.0, 1.0, 0.138671875, 1.0, 1.0, 1.0, 0.138671875, 0.150390625, 1.0, 0.203125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.134765625, 1.0, 1.0, 1.0, 1.0, 0.138671875, 0.140625, 1.0, 1.0, 0.13671875, 1.0, 0.140625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.140625]

 sparsity of   [1.0, 1.0, 1.0, 0.5807291865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5729166865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5737847089767456, 1.0, 1.0, 1.0, 1.0, 0.5763888955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5720486044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.663194477558136, 0.5746527910232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5755208134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5737847089767456, 0.5798611044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5789930820465088, 1.0, 1.0, 1.0, 1.0, 0.5711805820465088, 1.0, 1.0, 1.0, 1.0, 0.5798611044883728, 1.0, 0.5720486044883728, 0.5746527910232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5746527910232544, 1.0, 0.5703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5763888955116272, 1.0, 1.0, 1.0, 0.5746527910232544, 1.0, 0.5729166865348816, 0.5763888955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5720486044883728, 1.0]

 sparsity of   [0.7265625, 1.0, 1.0, 1.0, 0.703125, 0.71875, 1.0, 1.0, 1.0, 0.7109375, 0.7578125, 0.7109375, 1.0, 0.7109375, 1.0, 1.0, 0.7109375, 1.0, 1.0, 0.71875, 1.0, 0.7109375, 1.0, 0.7109375, 1.0, 1.0, 0.7109375, 0.703125, 1.0, 0.71875, 1.0, 0.7265625, 1.0, 1.0, 0.703125, 0.7109375, 1.0, 1.0, 1.0, 1.0, 0.7265625, 0.7109375, 1.0, 0.7109375, 0.71875, 1.0, 0.7109375, 1.0, 1.0, 1.0, 0.75, 0.71875, 0.703125, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.703125, 0.71875, 1.0, 1.0, 0.71875, 1.0, 0.71875, 1.0, 0.7109375, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.7109375, 0.7109375, 1.0, 1.0, 0.765625, 1.0, 0.7109375, 1.0, 1.0, 1.0, 0.7109375, 0.7109375, 1.0, 0.7109375, 1.0, 1.0, 1.0, 0.7109375, 1.0, 0.7265625, 1.0, 0.7109375, 0.7109375, 1.0, 1.0, 0.7109375, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7265625, 1.0, 0.7109375, 0.71875, 1.0, 1.0, 0.7109375, 0.7109375, 1.0, 0.703125, 0.71875, 1.0, 1.0, 0.7265625, 1.0, 1.0, 0.7109375, 1.0, 1.0, 1.0, 0.7265625, 1.0, 1.0, 0.7109375, 1.0, 0.7109375, 0.703125, 1.0, 0.71875, 0.703125, 1.0, 1.0, 0.71875, 0.765625, 1.0, 1.0, 0.71875, 1.0, 0.7109375, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.703125, 1.0, 0.703125, 0.734375, 1.0, 0.7109375, 1.0, 1.0, 0.7109375, 1.0, 0.703125, 1.0, 0.7109375, 0.703125, 1.0, 0.7109375, 1.0, 1.0, 0.703125, 1.0, 1.0, 1.0, 0.7109375, 1.0, 0.734375, 1.0, 1.0, 1.0, 0.7109375, 1.0, 0.7109375, 1.0, 1.0, 0.7109375, 1.0, 0.71875, 0.7109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7265625, 1.0, 1.0, 0.7265625, 0.7109375, 1.0, 0.7109375, 0.7109375, 0.7265625, 0.71875, 0.71875, 1.0, 1.0, 1.0, 0.7109375, 0.71875, 1.0, 0.734375, 0.703125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 0.7109375, 0.703125, 0.7109375, 0.71875, 0.7109375, 1.0, 0.7109375, 0.7421875, 0.7109375, 1.0, 0.703125, 1.0, 0.7109375, 0.7109375, 0.71875, 1.0, 0.7109375, 1.0, 0.7109375, 0.7109375, 0.7109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7265625, 0.7109375, 0.7109375, 0.7109375, 0.71875, 0.7109375, 1.0, 1.0, 0.7109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.71875, 0.71875, 1.0, 0.7109375, 0.703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.703125, 1.0, 1.0, 1.0, 1.0, 0.703125, 1.0, 0.7109375, 1.0, 0.71875, 0.703125, 1.0, 1.0, 0.7109375, 1.0, 1.0, 0.71875, 1.0, 0.7109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7265625, 0.703125, 1.0, 1.0, 1.0, 0.7109375, 0.703125, 0.7265625, 1.0, 1.0, 1.0, 0.7109375, 0.7109375, 1.0, 1.0, 0.7109375, 0.71875, 1.0, 0.71875, 1.0, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 0.7109375, 0.71875, 1.0, 1.0, 0.71875, 0.7421875, 0.7265625, 1.0, 1.0, 0.7109375, 1.0, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 0.734375, 1.0, 0.7109375, 0.71875, 0.71875, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 0.7265625, 1.0, 0.7109375, 1.0, 0.71875, 0.71875, 0.71875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7109375, 1.0, 0.7109375, 0.703125, 0.7109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 0.71875, 1.0, 1.0, 0.734375, 0.7109375, 1.0, 0.71875, 1.0, 1.0, 0.7109375, 1.0, 0.703125, 1.0, 0.7265625, 1.0, 1.0, 1.0, 1.0, 0.7265625, 0.7109375, 1.0, 1.0, 1.0, 0.703125, 0.703125, 1.0, 0.7265625, 1.0, 1.0, 0.7109375, 1.0, 0.703125, 1.0, 0.71875, 0.703125, 1.0, 0.7109375, 0.703125, 1.0, 1.0, 1.0, 1.0, 0.7109375, 0.7109375, 0.703125, 0.71875, 0.703125, 1.0, 1.0, 0.703125, 0.7265625, 0.75, 1.0, 1.0, 1.0, 0.71875, 1.0, 1.0, 1.0, 0.71875, 1.0, 0.7109375, 1.0, 0.7265625, 1.0, 1.0, 1.0, 1.0, 0.703125, 0.71875, 0.703125, 1.0, 1.0, 1.0, 0.7109375, 1.0, 1.0, 1.0, 0.71875, 0.7109375, 1.0, 1.0, 0.7109375, 0.7109375, 1.0, 0.71875, 1.0, 0.7109375, 1.0, 0.7109375, 0.71875, 1.0, 1.0, 1.0, 1.0, 0.7421875, 0.7109375, 1.0, 1.0, 1.0, 0.71875, 0.7265625, 1.0, 1.0]

 sparsity of   [0.109375, 1.0, 1.0, 0.107421875, 0.119140625, 1.0, 0.10546875, 1.0, 1.0, 1.0, 1.0, 0.103515625, 0.107421875, 1.0, 0.111328125, 1.0, 1.0, 0.11328125, 0.111328125, 0.107421875, 1.0, 0.11328125, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 0.09765625, 1.0, 0.11328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.103515625, 1.0, 0.109375, 1.0, 0.107421875, 1.0, 0.109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.107421875, 1.0, 1.0, 1.0, 0.109375, 0.103515625, 1.0, 1.0, 1.0, 0.109375, 0.126953125, 1.0, 1.0, 1.0, 1.0, 0.111328125, 0.11328125, 0.103515625, 1.0, 1.0, 0.107421875, 0.109375, 1.0, 0.107421875, 1.0, 1.0, 0.10546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12109375, 1.0, 1.0, 1.0, 0.103515625, 0.10546875, 0.107421875, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 1.0, 0.1171875, 1.0, 0.115234375, 1.0, 0.107421875, 0.10546875, 0.107421875, 0.10546875, 1.0, 1.0, 0.10546875, 0.111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1015625, 1.0, 0.107421875, 1.0, 1.0, 1.0, 1.0, 0.111328125, 0.107421875, 0.103515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11328125, 0.109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 0.111328125, 0.109375, 1.0, 1.0, 0.115234375, 1.0, 1.0, 1.0, 1.0, 0.10546875, 1.0, 0.10546875, 1.0, 0.109375, 0.10546875, 1.0, 1.0, 1.0, 1.0, 0.109375, 0.111328125, 1.0, 0.10546875, 1.0, 1.0, 0.103515625, 0.11328125, 1.0, 0.125, 1.0, 1.0, 0.10546875, 1.0, 1.0, 0.107421875, 1.0, 1.0, 1.0, 0.109375, 0.10546875, 0.109375, 1.0, 0.115234375, 0.103515625, 0.111328125, 1.0, 0.109375, 1.0, 1.0, 1.0, 1.0, 0.10546875, 1.0, 1.0, 0.11328125, 1.0, 0.103515625, 1.0, 0.109375, 1.0, 1.0, 1.0, 1.0, 0.109375, 1.0, 0.1015625, 0.107421875, 1.0, 1.0, 0.10546875, 0.111328125, 1.0, 0.119140625, 1.0, 0.10546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.10546875, 1.0, 0.1171875, 1.0, 1.0, 0.115234375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.109375, 1.0, 0.11328125, 1.0, 1.0, 1.0, 0.103515625, 1.0, 0.107421875, 1.0]

 sparsity of   [0.6419270634651184, 1.0, 1.0, 1.0, 1.0, 0.6414930820465088, 1.0, 1.0, 0.6432291865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.643663227558136, 1.0, 1.0, 1.0, 0.6423611044883728, 0.6440972089767456, 0.6423611044883728, 0.6423611044883728, 1.0, 1.0, 1.0, 1.0, 0.6467013955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6427951455116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6432291865348816, 1.0, 1.0, 0.6419270634651184, 1.0, 1.0, 1.0, 0.6427951455116272, 1.0, 0.6414930820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.643663227558136, 0.6423611044883728, 1.0, 1.0, 1.0, 1.0, 0.6432291865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.643663227558136, 1.0, 1.0, 1.0, 1.0, 0.6419270634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6432291865348816, 0.6432291865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6423611044883728, 0.643663227558136, 0.6423611044883728, 1.0, 0.6432291865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6419270634651184, 1.0, 1.0, 1.0, 0.64453125, 1.0, 1.0, 1.0, 0.6432291865348816, 0.6419270634651184, 1.0, 1.0, 1.0, 0.6440972089767456, 1.0, 1.0, 1.0, 0.6432291865348816, 0.6427951455116272, 0.6414930820465088, 1.0, 0.6419270634651184, 1.0, 0.6414930820465088, 1.0, 1.0, 1.0, 1.0, 0.64453125, 1.0, 0.6427951455116272, 1.0, 0.6423611044883728, 1.0, 1.0, 1.0, 1.0, 0.6414930820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6419270634651184, 1.0, 1.0, 1.0, 1.0, 1.0, 0.643663227558136, 1.0, 1.0, 1.0, 1.0, 0.6440972089767456, 1.0, 1.0, 0.6427951455116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6423611044883728, 0.6423611044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.643663227558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6427951455116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.640625, 1.0, 1.0, 1.0, 0.6414930820465088, 1.0, 1.0, 1.0, 0.6432291865348816, 1.0, 1.0, 1.0, 0.6440972089767456, 1.0, 1.0, 1.0]

 sparsity of   [0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.8046875, 0.8046875, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 0.8046875, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.8203125, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.8046875, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.8046875, 0.796875, 0.80859375, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.8046875, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 0.8046875, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 0.8046875, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8046875, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.8046875, 0.80078125, 1.0, 1.0, 0.80859375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.8046875, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 0.796875, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.8046875, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.8046875, 1.0, 0.8046875, 0.80078125, 1.0, 0.796875, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.84375, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 0.8046875, 1.0, 0.8046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8046875, 1.0, 1.0, 0.80078125, 0.80859375, 1.0, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 0.80859375, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.8046875, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.8046875, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 0.796875, 1.0, 1.0, 1.0, 0.8046875, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.81640625, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 0.80859375, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.8046875, 1.0, 1.0, 1.0, 0.80078125, 0.8046875, 0.80078125, 1.0, 1.0, 0.80078125, 0.8046875, 1.0, 1.0, 0.80078125, 0.80078125, 0.8046875, 0.796875, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.8046875, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.8046875, 0.80078125, 0.8046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 0.8046875, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 0.8046875, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.8046875, 1.0, 0.80859375, 0.80078125, 0.80078125, 0.8046875, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.8046875, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8046875, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.8046875, 1.0, 0.80078125, 0.80078125, 1.0, 0.8046875, 0.80078125, 1.0, 0.8046875, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 0.8046875, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.8046875, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 0.8046875, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.8046875, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80859375, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 0.8046875, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.8046875, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.8046875, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.8046875, 0.80078125, 0.8046875, 1.0, 1.0, 0.80078125, 0.80078125, 0.8046875, 1.0, 0.80078125, 1.0, 0.80078125, 0.8046875, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.8046875, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.8046875, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8046875, 0.796875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 0.8046875, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 0.8046875, 0.80078125, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.8046875, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 0.8046875, 1.0, 0.80078125, 0.8046875, 0.80078125, 0.80078125, 1.0, 0.8046875, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.8046875, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 0.80859375, 1.0, 1.0, 1.0, 0.8046875, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 0.80078125, 1.0, 0.80078125, 0.80078125, 1.0, 0.80078125, 1.0, 1.0, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 0.80078125, 1.0, 1.0, 0.8046875, 1.0, 1.0, 0.80078125, 0.80078125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80078125, 0.80078125, 0.8046875, 1.0, 0.80078125]

 sparsity of   [0.109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.115234375, 1.0, 1.0, 0.115234375, 1.0, 1.0, 0.16015625, 0.119140625, 0.111328125, 1.0, 0.11328125, 1.0, 1.0, 1.0, 1.0, 0.107421875, 1.0, 1.0, 0.119140625, 0.10546875, 0.107421875, 0.1171875, 0.1171875, 1.0, 1.0, 0.265625, 0.1015625, 0.107421875, 0.115234375, 1.0, 0.10546875, 0.111328125, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 0.119140625, 0.111328125, 0.111328125, 0.10546875, 1.0, 0.109375, 1.0, 1.0, 1.0, 0.10546875, 1.0, 1.0, 1.0, 1.0, 0.13671875, 1.0, 1.0, 0.11328125, 0.162109375, 0.10546875, 1.0, 1.0, 1.0, 0.115234375, 1.0, 1.0, 0.115234375, 0.119140625, 1.0, 1.0, 1.0, 1.0, 0.107421875, 0.11328125, 0.115234375, 0.154296875, 1.0, 1.0, 1.0, 1.0, 0.107421875, 0.107421875, 1.0, 1.0, 0.2109375, 0.11328125, 0.109375, 1.0, 0.119140625, 0.107421875, 0.111328125, 1.0, 0.109375, 1.0, 1.0, 0.208984375, 0.10546875, 1.0, 1.0, 0.11328125, 0.107421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 0.10546875, 1.0, 0.15625, 0.111328125, 0.103515625, 0.11328125, 0.111328125, 1.0, 1.0, 1.0, 0.107421875, 1.0, 1.0, 1.0, 1.0, 0.119140625, 1.0, 1.0, 0.109375, 0.103515625, 1.0, 1.0, 1.0, 0.125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11328125, 1.0, 0.11328125, 0.111328125, 0.107421875, 0.109375, 0.10546875, 1.0, 0.119140625, 1.0, 1.0, 0.103515625, 0.10546875, 0.119140625, 0.10546875, 1.0, 1.0, 1.0, 1.0, 0.111328125, 0.115234375, 1.0, 0.109375, 0.359375, 1.0, 1.0, 0.119140625, 0.115234375, 0.10546875, 0.10546875, 1.0, 1.0, 0.10546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.107421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.10546875, 1.0, 1.0, 0.107421875, 0.111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.109375, 0.12109375, 0.111328125, 1.0, 1.0, 0.11328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 0.11328125, 1.0, 0.115234375, 0.1171875, 1.0, 0.11328125, 1.0, 1.0, 1.0, 1.0, 0.107421875, 1.0, 0.123046875, 0.109375, 1.0, 0.111328125, 0.109375, 0.115234375, 0.1171875, 0.119140625, 0.111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.115234375, 0.109375, 0.1171875, 0.111328125, 1.0, 1.0, 0.109375, 0.11328125, 1.0, 1.0, 1.0, 0.109375, 1.0, 0.109375, 1.0, 0.115234375, 1.0, 0.109375, 1.0, 0.109375, 1.0, 1.0, 0.11328125, 1.0, 0.10546875, 1.0, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.166015625, 1.0, 1.0, 0.111328125, 1.0, 0.1171875, 0.150390625, 0.109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11328125, 1.0, 1.0, 0.119140625, 1.0, 1.0, 1.0, 1.0, 0.10546875, 1.0, 1.0, 1.0, 0.11328125, 0.111328125, 0.126953125, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 0.125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.107421875, 1.0, 1.0, 0.1171875, 0.126953125, 1.0, 0.107421875, 1.0, 1.0, 1.0, 0.1328125, 1.0, 0.109375, 0.103515625, 1.0, 1.0, 0.107421875, 1.0, 0.109375, 1.0, 1.0, 0.11328125, 1.0, 1.0, 0.119140625, 1.0, 0.109375, 1.0, 0.115234375, 1.0, 1.0, 1.0, 0.11328125, 1.0, 1.0, 1.0, 1.0, 0.11328125, 1.0, 1.0, 0.208984375, 0.11328125, 1.0, 1.0, 1.0, 0.11328125, 1.0, 1.0, 1.0, 0.107421875, 1.0, 0.111328125, 1.0, 1.0, 0.126953125, 1.0, 1.0, 1.0, 0.11328125, 0.111328125, 1.0, 0.150390625, 1.0, 0.1171875, 1.0, 1.0, 0.11328125, 1.0, 0.126953125, 0.123046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.115234375, 0.111328125, 1.0, 1.0, 0.123046875, 1.0, 0.119140625, 0.11328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 0.1171875, 1.0, 1.0, 0.107421875, 0.10546875, 0.16015625, 0.119140625, 1.0, 1.0, 0.109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.126953125, 1.0, 1.0, 1.0, 0.109375, 0.111328125, 1.0, 0.130859375, 1.0, 1.0, 0.107421875, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 1.0, 0.109375, 1.0, 0.107421875, 0.109375, 1.0, 0.115234375, 1.0, 1.0, 1.0, 1.0, 0.107421875, 1.0, 0.115234375, 0.115234375, 1.0, 1.0, 0.111328125, 0.119140625, 1.0, 0.111328125, 0.111328125, 0.111328125, 1.0, 0.17578125, 1.0, 0.12890625, 0.115234375, 1.0, 1.0, 1.0, 0.109375, 0.109375, 0.107421875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.123046875, 1.0, 0.1171875, 0.103515625, 1.0, 1.0, 1.0, 0.11328125, 1.0, 0.123046875, 1.0, 1.0, 0.11328125, 0.10546875, 1.0, 1.0, 0.10546875, 0.111328125, 0.12109375, 0.115234375, 0.1171875, 1.0, 0.10546875, 0.10546875, 1.0, 1.0, 0.103515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.125, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.12890625, 0.111328125, 0.115234375, 1.0, 0.11328125, 1.0, 1.0, 1.0, 1.0, 0.1171875, 0.115234375, 0.115234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.109375, 1.0, 0.23828125, 0.109375, 1.0, 1.0, 0.107421875, 0.11328125, 0.111328125, 0.478515625, 1.0, 1.0, 1.0, 0.109375, 0.126953125, 1.0, 1.0, 0.107421875, 1.0, 1.0, 1.0, 1.0, 0.10546875, 1.0, 0.103515625, 0.111328125, 0.11328125, 0.109375, 0.111328125, 1.0, 0.111328125, 0.126953125, 1.0, 0.1171875, 0.1171875, 1.0, 0.11328125, 1.0, 1.0, 0.111328125, 1.0, 1.0, 0.115234375, 0.115234375, 0.115234375, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 1.0, 0.1171875, 0.107421875, 0.109375, 0.119140625, 1.0, 1.0, 0.11328125, 1.0, 1.0, 1.0, 1.0, 0.111328125, 0.10546875, 1.0, 1.0, 0.119140625, 0.103515625, 0.119140625, 1.0, 1.0, 0.119140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11328125, 0.115234375, 1.0, 0.11328125, 1.0, 1.0, 0.115234375, 1.0, 0.130859375, 1.0, 0.123046875, 0.11328125, 1.0, 1.0, 0.123046875, 1.0, 0.109375, 1.0, 0.111328125, 0.109375, 1.0, 0.111328125, 0.115234375, 1.0, 1.0, 0.11328125, 1.0, 0.119140625, 0.11328125, 0.111328125, 1.0, 1.0, 0.109375, 0.11328125, 0.123046875, 1.0, 1.0, 1.0, 1.0, 0.115234375, 1.0, 0.109375, 1.0, 0.115234375, 0.111328125, 0.20703125, 0.1171875, 1.0, 1.0, 1.0, 0.115234375, 0.1953125, 1.0, 1.0, 1.0, 0.353515625, 0.109375, 1.0, 0.119140625, 0.111328125, 0.15234375, 0.103515625, 1.0, 1.0, 1.0, 0.115234375, 1.0, 1.0, 1.0, 0.1171875, 1.0, 0.162109375, 1.0, 0.107421875, 0.11328125, 1.0, 1.0, 0.1171875, 0.119140625, 1.0, 0.11328125, 0.1015625, 0.111328125, 1.0, 1.0, 1.0, 1.0, 0.1015625, 0.275390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 1.0, 0.107421875, 0.14453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11328125, 0.111328125, 1.0, 1.0, 0.11328125, 1.0, 0.111328125, 0.119140625, 0.1171875, 1.0, 1.0, 0.111328125, 0.115234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 0.111328125, 1.0, 0.107421875, 1.0, 0.123046875, 1.0, 1.0, 1.0, 0.10546875, 0.115234375, 0.109375, 1.0, 1.0, 0.1171875, 0.111328125, 0.10546875, 1.0, 1.0, 0.123046875, 0.11328125, 0.109375, 1.0, 0.166015625, 1.0, 0.103515625, 0.11328125, 1.0, 1.0, 1.0, 1.0, 0.115234375, 1.0, 0.109375, 0.11328125, 1.0, 1.0, 1.0, 1.0, 0.11328125, 0.115234375, 0.1171875, 1.0, 0.107421875, 1.0, 1.0, 1.0, 1.0, 0.107421875, 0.115234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.365234375, 0.109375, 0.10546875, 0.111328125, 1.0, 0.109375, 0.11328125, 0.109375, 0.11328125, 1.0, 0.111328125, 0.119140625, 1.0, 0.12109375, 1.0, 1.0, 0.123046875, 0.109375, 1.0, 1.0, 0.111328125, 0.111328125, 1.0, 1.0, 1.0, 0.11328125, 0.12109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.115234375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.111328125, 0.12109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.115234375, 0.107421875, 0.11328125, 1.0, 1.0, 0.11328125, 0.11328125, 0.119140625, 0.10546875, 0.111328125, 1.0, 0.115234375, 1.0, 1.0, 1.0, 0.115234375, 1.0, 0.11328125, 1.0, 1.0, 0.12109375, 0.111328125, 1.0, 1.0, 1.0, 1.0, 0.103515625, 0.109375, 1.0, 1.0, 0.111328125, 1.0, 1.0, 1.0, 0.1171875, 0.107421875, 1.0, 1.0, 0.11328125, 1.0, 0.107421875, 1.0, 1.0, 0.12109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.109375, 1.0, 0.125, 1.0, 0.10546875, 1.0, 1.0, 0.107421875, 0.10546875, 1.0, 1.0, 1.0, 1.0, 0.115234375, 1.0, 0.11328125, 0.111328125, 0.109375, 0.10546875, 1.0, 0.107421875, 1.0, 0.11328125, 1.0, 0.109375, 1.0, 0.111328125, 1.0, 1.0, 0.1171875, 0.255859375, 1.0, 1.0, 1.0, 0.1171875, 1.0, 1.0, 0.1796875, 0.1171875, 1.0, 1.0, 0.107421875, 0.11328125, 1.0, 0.107421875, 1.0, 1.0, 1.0, 0.111328125, 1.0, 1.0, 0.111328125, 1.0, 0.12109375, 0.111328125, 1.0, 0.111328125, 1.0, 0.123046875, 0.12109375, 1.0, 0.109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.109375, 1.0, 1.0, 1.0, 0.109375, 0.119140625, 0.12109375, 1.0, 1.0, 1.0, 0.107421875, 1.0, 1.0, 0.13671875, 1.0, 1.0, 0.123046875, 0.119140625, 1.0, 1.0, 1.0, 0.12109375, 1.0, 0.16015625, 0.1171875, 0.109375, 1.0, 0.109375]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5439453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5263671875, 0.537109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.537109375, 0.546875, 0.533203125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5419921875, 1.0, 1.0, 1.0, 0.5341796875, 1.0, 1.0, 0.5263671875, 0.5380859375, 1.0, 0.537109375, 0.5361328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5361328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.537109375, 1.0, 0.54296875, 1.0, 0.53515625, 0.5341796875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.541015625, 1.0, 1.0, 1.0, 1.0, 0.5390625, 0.529296875, 0.537109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.54296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.529296875, 1.0, 1.0, 1.0, 0.5380859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5341796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.525390625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5400390625, 1.0, 1.0, 0.541015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5361328125, 1.0, 1.0, 1.0, 0.5478515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.537109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.54296875, 1.0, 1.0, 0.5400390625, 1.0, 0.5380859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5390625, 1.0, 0.5400390625, 1.0, 1.0, 0.533203125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.537109375, 0.5341796875, 1.0, 1.0, 0.5380859375, 1.0, 0.537109375, 1.0, 0.53515625, 1.0, 1.0, 1.0, 0.537109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5380859375, 1.0, 0.546875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5361328125, 1.0, 1.0, 0.5380859375, 1.0, 1.0, 1.0, 0.5322265625, 0.5361328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.533203125, 0.5419921875, 1.0, 0.537109375, 0.53515625, 1.0, 1.0, 1.0, 0.5634765625, 1.0, 1.0, 1.0, 1.0, 0.5361328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.7838541865348816, 1.0, 1.0, 0.7790798544883728, 1.0, 1.0, 0.7821180820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7838541865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7847222089767456, 1.0, 1.0, 1.0, 1.0, 0.78125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7834201455116272, 1.0, 1.0, 0.7829861044883728, 0.7838541865348816, 1.0, 0.7825520634651184, 1.0, 0.7808159589767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7799479365348816, 1.0, 1.0, 0.7829861044883728, 1.0, 1.0, 1.0, 1.0, 0.78125, 1.0, 1.0, 1.0, 0.780381977558136, 1.0, 1.0, 1.0, 1.0, 0.7860243320465088, 1.0, 1.0, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7808159589767456, 1.0, 1.0, 0.7816840410232544, 0.78125, 1.0, 1.0, 1.0, 1.0, 0.7829861044883728, 1.0, 1.0, 1.0, 1.0, 0.78125, 1.0, 1.0, 0.7795138955116272, 0.7825520634651184, 1.0, 1.0, 1.0, 0.7808159589767456, 1.0, 0.7795138955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7821180820465088, 1.0, 1.0, 1.0, 0.7816840410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7795138955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7821180820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7847222089767456, 0.7790798544883728, 0.784288227558136, 1.0, 0.7808159589767456, 0.7868923544883728, 1.0, 0.7855902910232544, 1.0, 0.7782118320465088, 1.0, 1.0, 0.7808159589767456, 0.7808159589767456, 0.7786458134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7799479365348816, 1.0, 0.780381977558136, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7799479365348816, 1.0, 0.7825520634651184, 1.0, 1.0, 1.0, 0.7825520634651184, 0.7808159589767456, 0.7829861044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.784288227558136, 1.0, 0.7786458134651184, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7838541865348816, 1.0, 0.7786458134651184, 1.0]

 sparsity of   [0.78125, 1.0, 1.0, 0.79296875, 0.78515625, 1.0, 0.7890625, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.796875, 1.0, 1.0, 0.78515625, 0.79296875, 1.0, 1.0, 0.78125, 1.0, 1.0, 0.79296875, 1.0, 0.78125, 1.0, 1.0, 0.79296875, 0.79296875, 0.78125, 0.77734375, 0.78515625, 1.0, 1.0, 1.0, 0.7890625, 0.79296875, 0.78515625, 1.0, 0.77734375, 0.796875, 0.79296875, 1.0, 1.0, 1.0, 0.78515625, 0.79296875, 0.78125, 1.0, 1.0, 1.0, 0.79296875, 0.79296875, 0.796875, 0.79296875, 0.796875, 1.0, 0.7890625, 1.0, 0.78125, 1.0, 0.77734375, 1.0, 1.0, 0.78515625, 1.0, 0.79296875, 1.0, 0.78515625, 0.80078125, 0.7890625, 0.796875, 1.0, 1.0, 1.0, 0.7890625, 0.77734375, 1.0, 0.796875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.77734375, 0.7890625, 0.79296875, 0.78515625, 1.0, 0.79296875, 1.0, 1.0, 0.77734375, 0.78125, 1.0, 1.0, 1.0, 0.80078125, 0.78125, 1.0, 0.79296875, 0.78125, 0.79296875, 1.0, 0.796875, 1.0, 1.0, 0.7890625, 0.79296875, 1.0, 1.0, 0.79296875, 0.78515625, 1.0, 0.78125, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.7890625, 1.0, 0.78515625, 1.0, 0.78515625, 0.78515625, 0.7890625, 0.78515625, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 0.78125, 0.79296875, 0.78125, 1.0, 1.0, 1.0, 0.8203125, 1.0, 0.77734375, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.796875, 1.0, 0.796875, 0.79296875, 0.78515625, 0.78125, 0.7890625, 0.8046875, 0.7890625, 1.0, 1.0, 0.7890625, 0.77734375, 0.796875, 0.79296875, 1.0, 0.79296875, 1.0, 0.796875, 0.79296875, 0.796875, 1.0, 0.79296875, 0.79296875, 1.0, 0.79296875, 0.78125, 0.78515625, 0.78125, 0.796875, 1.0, 1.0, 0.78125, 1.0, 0.7890625, 0.78125, 1.0, 1.0, 1.0, 0.78125, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.78125, 0.77734375, 0.78515625, 0.78515625, 0.78125, 0.79296875, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.796875, 0.78515625, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78125, 1.0, 0.79296875, 1.0, 0.78125, 0.79296875, 1.0, 0.796875, 1.0, 0.78125, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.7890625, 1.0, 0.77734375, 0.79296875, 0.78515625, 0.796875, 0.796875, 0.78125, 0.79296875, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.78515625, 0.79296875, 0.78515625, 1.0, 1.0, 0.79296875, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 0.78125, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 0.77734375, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.79296875, 1.0, 0.80078125, 0.78125, 0.78515625, 1.0, 0.7890625, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.7890625, 0.83203125, 1.0, 1.0, 1.0, 0.78125, 1.0, 1.0, 1.0, 0.78515625, 0.7890625, 0.78125, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 1.0, 0.78515625, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.796875, 0.796875, 1.0, 1.0, 0.80078125, 0.7890625, 1.0, 0.78515625, 1.0, 1.0, 0.78125, 0.7890625, 1.0, 0.78125, 0.77734375, 1.0, 1.0, 0.78125, 1.0, 0.78515625, 1.0, 1.0, 0.796875, 0.79296875, 0.78515625, 0.79296875, 1.0, 0.79296875, 1.0, 0.796875, 1.0, 1.0, 1.0, 0.78515625, 0.77734375, 1.0, 1.0, 0.78125, 0.7890625, 1.0, 1.0, 0.79296875, 0.78125, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 0.78125, 1.0, 0.78515625, 1.0, 0.79296875, 1.0, 1.0, 0.796875, 1.0, 1.0, 0.79296875, 0.796875, 1.0, 0.78125, 0.79296875, 1.0, 0.78125, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.78125, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.78125, 1.0, 1.0, 1.0, 1.0, 0.77734375, 0.7890625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.79296875, 0.78515625, 1.0, 1.0, 0.78125, 0.78515625, 0.77734375, 0.796875, 0.78125, 0.78515625, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 0.78125, 0.80078125, 1.0, 0.7890625, 1.0, 0.78125, 1.0, 1.0, 1.0, 0.77734375, 0.78125, 1.0, 1.0, 1.0, 0.7890625, 1.0, 0.78125, 0.78125, 1.0, 0.796875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.78515625, 0.79296875, 0.8046875, 1.0, 1.0, 0.79296875, 0.7890625, 1.0, 0.78515625, 0.796875, 0.79296875, 1.0, 0.78515625, 1.0, 1.0, 0.7890625, 0.7890625, 1.0, 1.0, 0.80078125, 0.796875, 0.78125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 0.79296875, 0.79296875, 1.0, 0.78125, 1.0, 0.78515625, 0.796875, 0.78515625, 1.0, 1.0, 0.78125, 0.78515625, 1.0, 1.0, 0.7890625, 0.7890625, 0.79296875, 0.78515625, 0.78515625, 1.0, 0.78125, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 0.78125, 1.0, 0.80078125, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.79296875, 0.80078125, 0.78515625, 1.0, 0.7890625, 1.0, 1.0, 0.78515625, 1.0, 0.79296875, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.78125, 1.0, 1.0, 0.78515625, 1.0, 0.78515625, 0.79296875, 0.78515625, 0.796875, 0.7890625, 0.78125, 1.0, 1.0, 0.79296875, 0.796875, 1.0, 0.79296875, 0.796875, 1.0, 1.0, 1.0, 1.0, 0.7890625, 1.0, 0.77734375, 0.77734375, 0.79296875, 0.79296875, 0.78125, 1.0, 0.77734375, 0.79296875, 1.0, 0.79296875, 0.78125, 1.0, 0.78125, 1.0, 0.7890625, 0.7890625, 1.0, 1.0, 0.78515625, 0.7890625, 0.78125, 1.0, 1.0, 0.7890625, 1.0, 0.78515625, 1.0, 1.0, 0.78125, 0.79296875, 0.78515625, 0.78125, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.7890625, 0.78125, 1.0, 1.0, 0.796875, 0.78515625, 0.78515625, 1.0, 0.80078125, 0.78515625, 0.796875, 0.78125, 0.7890625, 0.78125, 1.0, 1.0, 0.796875, 0.79296875, 1.0, 0.7890625, 0.78515625, 1.0, 0.77734375, 1.0, 1.0, 1.0, 0.796875, 0.78515625, 0.78515625, 1.0, 0.79296875, 1.0, 0.78515625, 1.0, 0.79296875, 0.796875, 0.78515625, 0.80078125, 0.79296875, 1.0, 1.0, 0.79296875, 0.77734375, 0.796875, 0.78515625, 0.79296875, 0.796875, 0.77734375, 0.78515625, 0.77734375, 0.79296875, 1.0, 0.7890625, 1.0, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 0.79296875, 0.80078125, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.78515625, 0.79296875, 1.0, 0.79296875, 0.78125, 0.79296875, 1.0, 0.79296875, 0.79296875, 0.7890625, 0.78125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.78515625, 0.78515625, 0.7890625, 0.8046875, 0.78125, 0.78515625, 1.0, 0.78125, 0.80078125, 0.79296875, 1.0, 1.0, 1.0, 0.7890625, 0.78125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.7890625, 1.0, 1.0, 0.7890625, 1.0, 1.0, 1.0, 0.78515625, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 0.78515625, 0.79296875, 0.78125, 1.0, 0.80078125, 0.79296875, 0.78125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.78125, 0.78515625, 1.0, 0.796875, 1.0, 0.77734375, 1.0, 1.0, 1.0, 0.79296875, 0.796875, 0.79296875, 1.0, 1.0, 0.79296875, 0.78125, 0.78515625, 1.0, 1.0, 0.79296875, 0.79296875, 0.79296875, 1.0, 0.78125, 1.0, 0.78125, 0.80078125, 1.0, 1.0, 0.78515625, 1.0, 0.796875, 1.0, 0.79296875, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 0.796875, 1.0, 0.7890625, 1.0, 1.0, 1.0, 1.0, 0.78125, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.7890625, 0.79296875, 0.7890625, 1.0, 0.79296875, 0.7890625, 0.78125, 0.78515625, 1.0, 0.79296875, 0.79296875, 1.0, 0.796875, 1.0, 1.0, 0.78125, 0.7890625, 1.0, 1.0, 0.7890625, 0.79296875, 1.0, 1.0, 1.0, 0.79296875, 0.78515625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78125, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 1.0, 0.78515625, 0.7890625, 0.796875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78515625, 0.7890625, 0.78515625, 1.0, 1.0, 0.796875, 0.78125, 0.79296875, 0.7890625, 0.78125, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.77734375, 1.0, 0.796875, 0.79296875, 0.79296875, 0.796875, 1.0, 1.0, 0.7890625, 0.78125, 0.79296875, 0.78125, 1.0, 0.8046875, 1.0, 0.796875, 1.0, 0.78515625, 0.7890625, 0.79296875, 1.0, 0.78515625, 0.77734375, 0.80078125, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 1.0, 0.77734375, 0.78515625, 1.0, 1.0, 1.0, 0.78515625, 1.0, 1.0, 1.0, 0.796875, 1.0, 1.0, 1.0, 1.0, 0.78515625, 1.0, 0.796875, 0.79296875, 0.79296875, 0.78515625, 1.0, 0.79296875, 1.0, 0.79296875, 1.0, 0.796875, 1.0, 0.78125, 1.0, 0.796875, 1.0, 0.79296875, 0.78125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.79296875, 1.0, 1.0, 0.7890625, 0.796875, 0.7890625, 0.78515625, 1.0, 0.78515625, 1.0, 0.78515625, 1.0, 0.77734375, 0.79296875, 1.0, 0.796875, 1.0, 1.0, 0.78125, 1.0, 0.7890625, 0.78515625, 1.0, 0.78515625, 1.0, 0.80859375, 0.796875, 1.0, 1.0, 1.0, 0.79296875, 1.0, 0.78515625, 1.0, 0.79296875, 0.78515625, 0.7890625, 1.0, 0.78515625, 1.0, 0.79296875, 1.0, 1.0, 0.79296875, 1.0, 0.77734375, 1.0, 0.79296875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.796875, 0.78515625, 0.79296875, 1.0, 0.79296875]

 sparsity of   [0.4462890625, 0.435546875, 0.43359375, 0.4345703125, 1.0, 0.435546875, 0.4267578125, 0.4365234375, 1.0, 1.0, 0.4375, 1.0, 0.43359375, 1.0, 1.0, 1.0, 1.0, 0.431640625, 1.0, 1.0, 0.5166015625, 0.4423828125, 1.0, 0.4365234375, 0.4326171875, 0.435546875, 1.0, 0.4345703125, 1.0, 0.4267578125, 1.0, 1.0, 0.4375, 1.0, 0.431640625, 1.0, 0.43359375, 0.439453125, 1.0, 0.4365234375, 0.435546875, 0.4404296875, 1.0, 1.0, 0.435546875, 0.4365234375, 1.0, 1.0, 0.4404296875, 1.0, 0.443359375, 1.0, 0.43359375, 1.0, 0.43359375, 1.0, 1.0, 1.0, 0.43359375, 1.0, 1.0, 1.0, 0.431640625, 0.43359375, 1.0, 1.0, 0.4345703125, 0.4345703125, 0.431640625, 1.0, 1.0, 1.0, 1.0, 0.435546875, 0.4306640625, 0.435546875, 0.435546875, 0.4228515625, 0.4384765625, 1.0, 0.4384765625, 0.4365234375, 0.4296875, 0.4375, 0.4345703125, 0.4296875, 1.0, 0.4326171875, 1.0, 1.0, 1.0, 1.0, 0.43359375, 1.0, 1.0, 0.4306640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.435546875, 0.4306640625, 0.4345703125, 1.0, 1.0, 1.0, 0.431640625, 1.0, 0.4306640625, 0.439453125, 1.0, 0.4365234375, 1.0, 1.0, 0.4326171875, 0.427734375, 1.0, 0.43359375, 1.0, 1.0, 0.435546875, 0.4326171875, 1.0, 1.0, 0.4326171875, 0.4326171875, 0.435546875, 0.43359375, 0.4326171875, 0.4326171875, 1.0, 0.431640625, 1.0, 1.0, 0.435546875, 0.4365234375, 1.0, 1.0, 0.4365234375, 0.4287109375, 0.431640625, 0.4345703125, 0.431640625, 0.435546875, 0.4365234375, 0.4365234375, 0.4365234375, 0.4287109375, 1.0, 0.4384765625, 1.0, 1.0, 0.4345703125, 0.4345703125, 0.43359375, 0.4306640625, 1.0, 0.4306640625, 0.4345703125, 0.439453125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4365234375, 0.4326171875, 0.4345703125, 0.4306640625, 0.43359375, 0.4375, 0.4365234375, 1.0, 1.0, 1.0, 0.4287109375, 1.0, 0.435546875, 1.0, 0.435546875, 0.443359375, 0.4345703125, 0.43359375, 0.439453125, 0.4326171875, 0.43359375, 0.4296875, 1.0, 0.4375, 1.0, 0.4296875, 0.4345703125, 0.4384765625, 1.0, 0.431640625, 0.427734375, 0.4345703125, 0.431640625, 1.0, 0.4306640625, 0.4345703125, 0.4375, 1.0, 1.0, 0.439453125, 1.0, 0.43359375, 1.0, 1.0, 0.4326171875, 0.4365234375, 1.0, 1.0, 0.435546875, 1.0, 1.0, 0.4365234375, 0.435546875, 1.0, 0.439453125, 0.4326171875, 0.4384765625, 0.4345703125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4375, 0.4287109375, 0.42578125, 0.43359375, 0.4326171875, 1.0, 0.4365234375, 0.4306640625, 1.0, 1.0, 1.0, 1.0, 0.4306640625, 1.0, 0.4345703125, 0.4345703125, 0.4326171875, 1.0, 0.43359375, 0.435546875, 0.4345703125, 1.0, 0.431640625, 1.0]

 sparsity of   [1.0, 0.4388020932674408, 1.0, 1.0, 0.4422743022441864, 1.0, 0.4401041567325592, 0.440972238779068, 1.0, 0.440972238779068, 0.4405381977558136, 1.0, 0.440972238779068, 1.0, 1.0, 0.4396701455116272, 0.4444444477558136, 1.0, 1.0, 0.44140625, 1.0, 0.4396701455116272, 1.0, 1.0, 1.0, 0.4396701455116272, 1.0, 0.4418402910232544, 1.0, 0.4401041567325592, 1.0, 0.4427083432674408, 1.0, 0.44140625, 1.0, 0.440972238779068, 0.4396701455116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4431423544883728, 1.0, 0.4396701455116272, 1.0, 1.0, 0.44140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4392361044883728, 0.4396701455116272, 0.4392361044883728, 1.0, 1.0, 0.4405381977558136, 0.4396701455116272, 1.0, 1.0, 1.0, 1.0, 0.4427083432674408, 1.0, 0.4405381977558136, 1.0, 0.4435763955116272, 1.0, 1.0, 0.4396701455116272, 0.440972238779068, 1.0, 1.0, 1.0, 1.0, 0.4401041567325592, 0.4401041567325592, 1.0, 1.0, 0.4379340410232544, 0.4422743022441864, 0.4401041567325592, 0.4422743022441864, 1.0, 1.0, 1.0, 1.0, 0.4396701455116272, 1.0, 1.0, 0.4392361044883728, 1.0, 0.4401041567325592, 1.0, 0.4392361044883728, 0.4401041567325592, 0.4396701455116272, 0.4396701455116272, 1.0, 1.0, 1.0, 0.440972238779068, 0.440972238779068, 0.44140625, 0.4405381977558136, 0.4440104067325592, 0.440972238779068, 1.0, 1.0, 0.4418402910232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.44140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4388020932674408, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4431423544883728, 1.0, 0.4422743022441864, 0.440972238779068, 1.0, 0.4401041567325592, 1.0, 1.0, 1.0, 0.4383680522441864, 0.4422743022441864, 0.4405381977558136, 1.0, 0.44140625, 1.0, 0.4405381977558136, 1.0, 1.0, 0.440972238779068, 0.4405381977558136, 1.0, 0.4405381977558136, 0.4392361044883728, 0.4392361044883728, 1.0, 0.4401041567325592, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4388020932674408, 1.0, 0.4396701455116272, 1.0, 1.0, 0.4431423544883728, 1.0, 0.4401041567325592, 0.4405381977558136, 1.0, 1.0, 1.0, 0.4392361044883728, 1.0, 1.0, 1.0, 0.44140625, 1.0, 0.4388020932674408, 1.0, 0.4422743022441864, 0.4401041567325592, 0.4396701455116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4405381977558136, 1.0, 0.4401041567325592, 1.0, 1.0, 1.0, 0.4401041567325592, 1.0, 1.0, 0.4388020932674408, 1.0, 1.0, 0.440972238779068, 0.4388020932674408, 0.4396701455116272, 0.4396701455116272, 1.0, 0.4422743022441864, 1.0, 1.0, 1.0, 1.0, 0.4405381977558136, 0.4388020932674408, 1.0, 1.0, 1.0, 0.44140625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.440972238779068, 0.4396701455116272, 1.0, 0.4383680522441864, 1.0, 1.0, 0.4418402910232544, 1.0, 1.0, 0.4401041567325592, 1.0, 1.0, 0.4396701455116272, 1.0]

 sparsity of   [0.6171875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62890625, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6171875, 0.6171875, 1.0, 0.62109375, 1.0, 1.0, 0.62109375, 1.0, 0.6171875, 1.0, 1.0, 0.62109375, 0.625, 1.0, 0.625, 0.62109375, 1.0, 1.0, 0.625, 0.625, 1.0, 0.62109375, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 0.625, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.625, 1.0, 0.62109375, 0.625, 1.0, 1.0, 0.62109375, 1.0, 0.6171875, 1.0, 0.6171875, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.6171875, 0.62109375, 0.62109375, 0.62109375, 1.0, 1.0, 1.0, 0.625, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 0.625, 0.62109375, 1.0, 1.0, 1.0, 1.0, 0.6171875, 0.625, 1.0, 1.0, 1.0, 1.0, 0.6171875, 1.0, 0.62109375, 0.62109375, 0.62109375, 0.625, 0.6171875, 1.0, 1.0, 0.6171875, 0.6171875, 1.0, 1.0, 0.62109375, 0.6171875, 1.0, 0.62109375, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.6171875, 1.0, 0.62109375, 0.6171875, 0.6171875, 0.6171875, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.62109375, 0.6171875, 1.0, 1.0, 1.0, 0.63671875, 0.6171875, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6171875, 1.0, 1.0, 1.0, 1.0, 0.625, 0.62109375, 1.0, 0.62109375, 0.62109375, 0.625, 0.625, 0.62109375, 0.625, 0.62109375, 1.0, 1.0, 0.6171875, 0.6171875, 0.62109375, 0.62109375, 1.0, 1.0, 0.6171875, 0.6484375, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 0.62109375, 1.0, 0.62109375, 0.62109375, 1.0, 1.0, 0.62890625, 1.0, 1.0, 0.6171875, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 0.62109375, 0.62109375, 0.625, 0.62109375, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 0.62109375, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.62109375, 0.62109375, 1.0, 1.0, 1.0, 0.6171875, 1.0, 1.0, 0.6171875, 1.0, 1.0, 0.62109375, 1.0, 0.625, 0.6171875, 0.61328125, 0.62890625, 0.6171875, 0.62890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 1.0, 0.6171875, 0.6171875, 1.0, 1.0, 1.0, 0.6171875, 1.0, 0.625, 1.0, 1.0, 1.0, 0.625, 0.6171875, 1.0, 1.0, 1.0, 0.62890625, 1.0, 0.6171875, 1.0, 1.0, 1.0, 0.6171875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 0.625, 0.62109375, 0.6171875, 0.625, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.62109375, 0.62109375, 1.0, 1.0, 1.0, 0.62890625, 1.0, 0.62890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6171875, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 0.62109375, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.62109375, 0.62109375, 1.0, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 1.0, 0.6171875, 0.625, 0.62109375, 0.625, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 0.62109375, 1.0, 0.625, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 0.6171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6171875, 0.62890625, 0.6171875, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.6171875, 1.0, 1.0, 1.0, 1.0, 0.6171875, 0.625, 0.62109375, 0.6171875, 1.0, 1.0, 1.0, 0.62109375, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 0.6171875, 0.62109375, 0.62109375, 1.0, 0.6171875, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.62109375, 0.6171875, 1.0, 0.625, 1.0, 0.625, 0.62109375, 1.0, 1.0, 0.62109375, 0.62109375, 1.0, 1.0, 1.0, 0.625, 1.0, 0.62890625, 0.6171875, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.62109375, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 0.62109375, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 0.62109375, 0.62109375, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 0.6171875, 1.0, 0.62109375, 1.0, 0.625, 1.0, 0.625, 1.0, 1.0, 0.6171875, 0.62109375, 1.0, 0.62109375, 0.625, 0.62109375, 0.6171875, 0.62109375, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 0.62109375, 0.62109375, 0.625, 1.0, 0.6171875, 1.0, 1.0, 0.62109375, 1.0, 0.6171875, 0.62890625, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.640625, 1.0, 1.0, 0.62109375, 1.0, 1.0, 0.625, 1.0, 0.62109375, 0.62109375, 1.0, 0.625, 1.0, 0.62109375, 1.0, 1.0, 0.625, 0.62109375, 1.0, 1.0, 0.62109375, 0.6171875, 1.0, 1.0, 1.0, 0.6171875, 1.0, 0.61328125, 0.6171875, 0.6171875, 0.625, 0.6171875, 1.0, 0.625, 0.6171875, 1.0, 0.625, 0.625, 1.0, 0.62109375, 1.0, 1.0, 0.62109375, 1.0, 1.0, 0.62109375, 0.625, 0.62109375, 1.0, 0.625, 0.62109375, 0.62890625, 0.62890625, 0.625, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 0.62109375, 0.6171875, 1.0, 1.0, 0.62109375, 0.62109375, 0.62109375, 1.0, 1.0, 0.62109375, 0.62109375, 0.625, 0.62109375, 0.6171875, 1.0, 1.0, 0.62109375, 0.62109375, 1.0, 0.61328125, 0.62109375, 1.0, 0.62109375, 1.0, 0.625, 1.0, 0.625, 0.625, 0.62109375, 1.0, 0.62109375, 1.0, 0.625, 1.0, 0.62109375, 0.6171875, 0.62109375, 0.62109375, 0.6171875, 1.0, 0.62109375, 0.625, 0.62109375, 0.625, 0.62109375, 0.62109375, 1.0, 0.62109375, 0.6171875, 0.62109375, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 0.62109375, 0.62109375, 0.625, 1.0, 1.0, 1.0, 0.625, 0.62109375, 1.0, 1.0, 1.0, 0.63671875, 0.6171875, 1.0, 1.0, 0.6171875, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 0.625, 1.0, 0.625, 0.6171875, 1.0, 0.62109375, 0.62109375, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.6171875, 0.625, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.6171875, 1.0, 1.0, 1.0, 0.6171875, 1.0, 0.62109375, 1.0, 0.625, 1.0, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 0.625, 0.62109375, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.625, 1.0, 0.6171875, 1.0, 1.0, 1.0, 0.62109375, 0.62109375, 1.0, 1.0, 1.0, 1.0, 0.625, 1.0, 0.62109375, 1.0, 0.6171875, 0.62109375, 1.0, 1.0, 0.62109375, 1.0, 0.6171875, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.62890625, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 0.62109375, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.62109375, 0.6171875, 0.6171875, 1.0, 0.62109375, 0.6171875, 0.62109375, 0.62109375, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6171875, 0.62109375, 1.0, 1.0, 0.6171875, 0.62109375, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6171875, 1.0, 1.0, 1.0, 0.62890625, 1.0, 1.0, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.63671875, 0.625, 0.6171875, 1.0, 1.0, 0.625, 0.62109375, 0.62109375, 0.625, 0.625, 1.0, 0.6171875, 1.0, 1.0, 1.0, 1.0, 0.6171875, 0.62109375, 1.0, 0.62109375, 0.62890625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 0.625, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 0.62109375, 0.62109375, 1.0, 1.0, 0.62109375, 0.62109375, 0.62109375, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 0.6171875, 0.62109375, 1.0, 1.0, 1.0, 0.62109375, 1.0, 1.0, 0.62109375, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62890625, 0.62109375, 0.625, 0.62109375, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 0.62109375, 1.0, 1.0, 0.6171875, 0.6171875, 0.62109375, 0.62109375, 1.0, 0.62109375, 1.0, 1.0, 1.0, 0.625, 0.62109375, 1.0, 0.62109375, 0.625, 1.0, 1.0, 1.0, 0.62109375, 0.625, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 1.0, 0.62109375, 1.0, 0.6171875, 0.62109375, 0.6171875, 1.0, 1.0, 0.625, 1.0, 0.62109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.62109375, 0.625, 0.6171875, 1.0, 0.62109375]

 sparsity of   [1.0, 1.0, 0.4091796875, 0.4091796875, 1.0, 1.0, 0.41796875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.421875, 1.0, 1.0, 0.4150390625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.41015625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.41796875, 1.0, 0.421875, 1.0, 0.4052734375, 1.0, 1.0, 0.4091796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4541015625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4072265625, 1.0, 1.0, 0.4150390625, 1.0, 1.0, 1.0, 1.0, 0.408203125, 0.4296875, 1.0, 0.4013671875, 1.0, 1.0, 0.4111328125, 1.0, 0.4150390625, 0.41015625, 1.0, 0.4130859375, 1.0, 0.408203125, 1.0, 1.0, 1.0, 1.0, 0.4111328125, 0.4140625, 1.0, 1.0, 1.0, 1.0, 0.408203125, 0.41015625, 0.408203125, 0.4228515625, 1.0, 1.0, 0.41015625, 1.0, 1.0, 1.0, 0.41015625, 1.0, 1.0, 1.0, 0.4091796875, 1.0, 1.0, 1.0, 0.4130859375, 1.0, 1.0, 1.0, 1.0, 0.404296875, 0.41796875, 1.0, 1.0, 0.416015625, 1.0, 1.0, 1.0, 1.0, 0.4111328125, 0.4111328125, 1.0, 0.4130859375, 1.0, 1.0, 1.0, 0.40625, 0.41796875, 0.40625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.412109375, 1.0, 1.0, 0.4091796875, 0.4052734375, 1.0, 1.0, 0.4072265625, 1.0, 1.0, 1.0, 1.0, 0.4052734375, 1.0, 0.4140625, 1.0, 0.4150390625, 1.0, 1.0, 1.0, 0.4208984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.40625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4072265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4140625, 0.41015625, 0.4228515625, 1.0, 1.0, 1.0, 0.40625, 1.0, 1.0, 1.0, 1.0, 0.4111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.408203125, 1.0, 1.0, 1.0, 1.0, 0.4111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.408203125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.408203125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4150390625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.423828125, 1.0, 1.0, 1.0, 0.4091796875, 0.41015625, 0.4033203125]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 0.7326388955116272, 1.0, 1.0, 1.0, 0.73046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7282986044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7300347089767456, 0.7352430820465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7282986044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7300347089767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7365451455116272, 1.0, 0.7348090410232544, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7291666865348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7209201455116272, 1.0, 1.0, 1.0, 0.7282986044883728, 1.0, 0.7287326455116272, 1.0, 1.0, 0.729600727558136, 1.0, 0.7291666865348816, 1.0, 1.0, 1.0, 1.0, 0.73046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7287326455116272, 1.0, 0.7322048544883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7769097089767456, 1.0, 0.7313368320465088, 0.7282986044883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7282986044883728, 0.7313368320465088, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7282986044883728, 1.0, 0.7252604365348816, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7330729365348816, 1.0, 1.0, 0.7287326455116272, 1.0, 1.0, 0.7326388955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.734375, 0.7322048544883728, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7261284589767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7261284589767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7330729365348816, 1.0, 0.7309027910232544, 1.0, 1.0, 1.0, 0.7243923544883728, 1.0, 1.0, 1.0, 0.7322048544883728, 1.0, 1.0, 0.7339409589767456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7252604365348816, 0.7326388955116272, 1.0, 0.7269965410232544]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 0.859375, 1.0, 1.0, 1.0, 1.0, 0.8359375, 0.8359375, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 0.8359375, 0.83984375, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.83984375, 0.8359375, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 0.8515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 0.83984375, 1.0, 1.0, 1.0, 0.83203125, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83203125, 1.0, 1.0, 0.85546875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 0.8359375, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 0.83984375, 0.8359375, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 0.84375, 1.0, 1.0, 0.83984375, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.84765625, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.84375, 1.0, 0.83203125, 0.83984375, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.8359375, 1.0, 1.0, 0.8359375, 1.0, 0.83984375, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.83984375, 1.0, 0.8359375, 0.83984375, 1.0, 1.0, 0.84765625, 0.83984375, 1.0, 0.83203125, 1.0, 1.0, 1.0, 0.8359375, 1.0, 0.8359375, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 0.83203125, 1.0, 0.83984375, 1.0, 1.0, 1.0, 0.8359375, 0.8359375, 1.0, 0.83984375, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 0.83984375, 1.0, 0.83984375, 0.83984375, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 0.83984375, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.828125, 1.0, 1.0, 0.8359375, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.84375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 0.8359375, 1.0, 1.0, 0.83984375, 0.8359375, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83203125, 1.0, 1.0, 1.0, 0.83984375, 0.8359375, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 0.8359375, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.8359375, 1.0, 0.83984375, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 1.0, 1.0, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8359375, 0.83984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.83984375, 1.0, 1.0, 0.8359375]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4306640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4228515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.427734375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4853515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4521484375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.990234375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4208984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4228515625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4248046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.46875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4130859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6337890625, 1.0, 1.0, 1.0, 1.0, 0.416015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4169921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4208984375, 1.0, 1.0, 0.4189453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4443359375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4189453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4189453125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.416015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.416015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6533203125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4248046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4150390625, 1.0, 1.0, 0.4150390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.525390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.46875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4150390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.583984375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4150390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.455078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.41796875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4111328125, 1.0, 1.0, 1.0, 0.4189453125, 1.0, 1.0, 1.0, 0.4140625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4169921875, 1.0, 0.576171875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.421875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4111328125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5087890625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4267578125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.666015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4091796875, 0.5322265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.419921875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5400390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4150390625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4208984375, 1.0, 1.0, 0.416015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4072265625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.416015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.40625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.412109375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.40625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.416015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.52685546875, 0.525390625, 0.52685546875, 0.52880859375, 0.52734375, 0.52880859375, 0.5283203125, 0.5283203125, 0.5263671875, 0.52587890625, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125]

Total parameter pruned: 22546319.00338237 (unstructured) 21278559 (structured)

Test: [0/79]	Time 0.154 (0.154)	Loss 0.3271 (0.3271) ([0.199]+[0.128])	Prec@1 94.531 (94.531)
 * Prec@1 94.420

 Elapsed time for training  3:53:07.575197

 sparsity of   [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]

 sparsity of   [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]

 sparsity of   [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]

 sparsity of   [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]

 sparsity of   [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]

 sparsity of   [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]

 sparsity of   [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]

 sparsity of   [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5390625, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6796875, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.671875, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.640625, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.671875, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.671875, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]

 sparsity of   [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]

 sparsity of   [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]

 sparsity of   [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.625, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.578125, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5703125, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6484375, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.609375, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6171875, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.640625, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5546875, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.625, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.640625, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6484375, 1.0, 0.0, 0.640625, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.578125, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]

 sparsity of   [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]

 sparsity of   [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]

 sparsity of   [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]

 sparsity of   [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]

 sparsity of   [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]

 sparsity of   [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]

 sparsity of   [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]

 sparsity of   [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.58203125, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6015625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5859375, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5625, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]

 sparsity of   [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1181640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2482638955116272, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.005859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5078125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.380859375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.009765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

 sparsity of   [0.52685546875, 0.525390625, 0.52685546875, 0.52880859375, 0.52734375, 0.52880859375, 0.5283203125, 0.5283203125, 0.5263671875, 0.52587890625, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125, 0.8955078125]
Total parameter pruned: 21458324.000030518 (unstructured) 21278559 (structured)
Test: [0/79]	Time 0.131 (0.131)	Loss 0.1991 (0.1991) ([0.199]+[0.000])	Prec@1 94.531 (94.531)
 * Prec@1 94.420
Best accuracy:  0
