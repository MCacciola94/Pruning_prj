V1.0.1-_resnet20_Cifar10_lr0.1_l1.63_a0.001_e1+1_bs128_t0.0001_m0.9_wd0.0005_mlstemp3_Mscl1.0
Files already downloaded and verified
M values:
 {Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 1.6352988481521606, Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 1.169867753982544, Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.9106662273406982, Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.7931119203567505, Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.654869556427002, Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.9789378643035889, Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.7008146047592163, Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False): 0.6066990494728088, Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.6057915091514587, Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.6954296231269836, Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.40856727957725525, Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.7257518768310547, Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.5365347862243652, Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False): 0.48648884892463684, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.5309917330741882, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.39136967062950134, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.41638830304145813, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.43563324213027954, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.300857812166214, Linear(in_features=64, out_features=10, bias=True): 1.863915205001831}
current lr 1.00000e-01
Grad=  tensor(32.2122, device='cuda:0')
Epoch: [0][0/391]	Time 1.770 (1.770)	Data 0.150 (0.150)	Loss 4.7653 (4.7653) ([3.809]+[0.956])	Prec@1 7.031 (7.031)
Epoch: [0][100/391]	Time 0.031 (0.047)	Data 0.000 (0.002)	Loss 2.2798 (2.7240) ([1.681]+[0.599])	Prec@1 35.156 (27.135)
Epoch: [0][200/391]	Time 0.032 (0.039)	Data 0.000 (0.001)	Loss 2.1571 (2.4672) ([1.638]+[0.519])	Prec@1 37.500 (32.354)
Epoch: [0][300/391]	Time 0.033 (0.037)	Data 0.000 (0.001)	Loss 2.0760 (2.3132) ([1.609]+[0.467])	Prec@1 42.188 (36.231)
Test: [0/79]	Time 0.128 (0.128)	Loss 1.6916 (1.6916) ([1.260]+[0.432])	Prec@1 50.781 (50.781)
 * Prec@1 51.560

 Elapsed time for training  0:00:15.062200
Total parameter pruned: 0.0 (unstructured) 0 (structured)

max weight is  tensor([0.7292, 0.9687, 0.7630, 0.9908, 0.9239, 1.1488, 0.5990, 0.5859, 1.2601,
        0.7894, 0.5375, 0.7972, 0.4881, 0.6596, 0.4548, 0.3755],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.5299, 0.6033, 0.5758, 0.5079, 0.6665, 0.2678, 0.2843, 0.4127, 0.6027,
        0.5505, 0.4546, 0.5431, 0.5609, 0.2664, 0.3379, 0.5822],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.4832, 0.4527, 0.5685, 0.5668, 0.4969, 0.4400, 0.2528, 0.2491, 0.3691,
        0.5073, 0.5563, 0.5089, 0.4782, 0.2330, 0.5183, 0.3292],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.5411, 0.2558, 0.3208, 0.2481, 0.4828, 0.4546, 0.2361, 0.5226, 0.5200,
        0.4296, 0.4845, 0.2900, 0.5445, 0.3068, 0.4450, 0.5367],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.2694, 0.4751, 0.4434, 0.4381, 0.5224, 0.5266, 0.4697, 0.4264, 0.2630,
        0.3747, 0.2925, 0.4223, 0.2453, 0.2727, 0.2399, 0.2437],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.5396, 0.5291, 0.4867, 0.4852, 0.4552, 0.2426, 0.5353, 0.5105, 0.2373,
        0.2311, 0.4618, 0.4777, 0.5361, 0.4872, 0.5249, 0.2356],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.4426, 0.4349, 0.3025, 0.4819, 0.4995, 0.2510, 0.4611, 0.4951, 0.2747,
        0.5305, 0.4890, 0.4466, 0.4799, 0.4548, 0.2287, 0.2958],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.4902, 0.4638, 0.4536, 0.2102, 0.1813, 0.2210, 0.2618, 0.2590, 0.4307,
        0.4880, 0.5053, 0.2038, 0.4246, 0.1983, 0.4330, 0.4489, 0.2049, 0.2210,
        0.3897, 0.2384, 0.3970, 0.4492, 0.4510, 0.5570, 0.4775, 0.4427, 0.4178,
        0.4282, 0.4510, 0.2788, 0.4485, 0.4795], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([0.4561, 0.4611, 0.4680, 0.4339, 0.4426, 0.4481, 0.4523, 0.1531, 0.4566,
        0.2023, 0.4669, 0.4487, 0.4343, 0.4307, 0.4816, 0.1962, 0.4699, 0.1947,
        0.4572, 0.1665, 0.4839, 0.4226, 0.1785, 0.2521, 0.2153, 0.2011, 0.1919,
        0.1651, 0.4672, 0.4706, 0.4768, 0.4143], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([0.1950, 0.1984, 0.5538, 0.4865, 0.4692, 0.5403, 0.1959, 0.1804, 0.4726,
        0.1635, 0.5427, 0.5035, 0.4888, 0.1966, 0.2569, 0.1890, 0.4766, 0.4823,
        0.5653, 0.4996, 0.2026, 0.5042, 0.2389, 0.4414, 0.1865, 0.1705, 0.4747,
        0.4717, 0.1870, 0.4568, 0.4539, 0.2220], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([0.1731, 0.1930, 0.3654, 0.3612, 0.3709, 0.3897, 0.1883, 0.4067, 0.3784,
        0.3679, 0.4032, 0.3688, 0.4176, 0.2078, 0.1737, 0.3768, 0.3655, 0.4032,
        0.3604, 0.1956, 0.3657, 0.1958, 0.3923, 0.4002, 0.3688, 0.4375, 0.3692,
        0.3456, 0.2283, 0.2468, 0.3693, 0.3900], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([0.4975, 0.4912, 0.4571, 0.5207, 0.2395, 0.4650, 0.5097, 0.1608, 0.4447,
        0.2530, 0.4385, 0.1662, 0.2127, 0.1629, 0.5235, 0.5312, 0.5235, 0.5253,
        0.4811, 0.1649, 0.1655, 0.1975, 0.4868, 0.1724, 0.5016, 0.4825, 0.5307,
        0.5368, 0.5217, 0.1989, 0.4497, 0.4634], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([0.3971, 0.4684, 0.4363, 0.2078, 0.4431, 0.1726, 0.4612, 0.1742, 0.1914,
        0.4353, 0.4516, 0.4582, 0.4250, 0.4480, 0.4464, 0.1801, 0.1846, 0.4235,
        0.3833, 0.2312, 0.1585, 0.3948, 0.4636, 0.4445, 0.1929, 0.4094, 0.4592,
        0.4036, 0.4016, 0.3991, 0.4499, 0.4106], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([0.3675, 0.1565, 0.4198, 0.1647, 0.1487, 0.3964, 0.1785, 0.1462, 0.1744,
        0.3862, 0.4164, 0.1610, 0.4673, 0.1469, 0.4311, 0.4233, 0.4187, 0.4263,
        0.4223, 0.1647, 0.4577, 0.4071, 0.3839, 0.3780, 0.4086, 0.3984, 0.4258,
        0.1627, 0.1812, 0.1812, 0.4339, 0.4673, 0.4475, 0.4069, 0.3978, 0.1813,
        0.4263, 0.4350, 0.3838, 0.1782, 0.4218, 0.4242, 0.3946, 0.4036, 0.4077,
        0.1634, 0.3662, 0.1369, 0.1681, 0.3994, 0.3929, 0.1673, 0.4183, 0.4233,
        0.1524, 0.3978, 0.3704, 0.3847, 0.1729, 0.4020, 0.4072, 0.2089, 0.4157,
        0.1253], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.4384, 0.1182, 0.1176, 0.4330, 0.1275, 0.1097, 0.4470, 0.1145, 0.4241,
        0.1180, 0.4609, 0.4171, 0.1016, 0.1161, 0.4691, 0.1081, 0.4503, 0.4609,
        0.4374, 0.4413, 0.4502, 0.4419, 0.1141, 0.4366, 0.1258, 0.4043, 0.1237,
        0.1265, 0.4202, 0.4236, 0.1127, 0.4317, 0.1104, 0.4634, 0.1194, 0.4277,
        0.4236, 0.4386, 0.1223, 0.4502, 0.4106, 0.1151, 0.4458, 0.4566, 0.4798,
        0.4344, 0.4331, 0.4533, 0.1320, 0.4353, 0.4267, 0.1016, 0.1226, 0.4353,
        0.4528, 0.4161, 0.4229, 0.4710, 0.1068, 0.4160, 0.1176, 0.0952, 0.1125,
        0.4649], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.1233, 0.3498, 0.1126, 0.1199, 0.1323, 0.2156, 0.3472, 0.1437, 0.1183,
        0.1385, 0.1084, 0.1032, 0.3805, 0.3230, 0.3637, 0.1198, 0.1566, 0.3576,
        0.3446, 0.1239, 0.3644, 0.1440, 0.1370, 0.1185, 0.3374, 0.3368, 0.3743,
        0.1219, 0.3621, 0.1318, 0.3551, 0.3333, 0.1198, 0.3130, 0.3683, 0.3708,
        0.3545, 0.3775, 0.3391, 0.3934, 0.1299, 0.1048, 0.1546, 0.1348, 0.3440,
        0.3560, 0.3730, 0.3710, 0.3438, 0.1269, 0.3571, 0.1204, 0.3489, 0.3507,
        0.3496, 0.3336, 0.1247, 0.3791, 0.3201, 0.1153, 0.3838, 0.3705, 0.3331,
        0.3831], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.3660, 0.3649, 0.3788, 0.3700, 0.1082, 0.3655, 0.3875, 0.3764, 0.3631,
        0.4083, 0.3985, 0.3939, 0.3718, 0.3558, 0.3829, 0.1189, 0.1430, 0.3502,
        0.3907, 0.3556, 0.1421, 0.3838, 0.3591, 0.3800, 0.1077, 0.1311, 0.3681,
        0.1375, 0.3802, 0.1308, 0.3946, 0.1219, 0.3530, 0.1223, 0.1259, 0.3735,
        0.1234, 0.1334, 0.3797, 0.1124, 0.1254, 0.3755, 0.3602, 0.3643, 0.1272,
        0.3931, 0.3451, 0.3950, 0.1305, 0.1509, 0.3915, 0.1308, 0.3845, 0.3792,
        0.1150, 0.1082, 0.3690, 0.3588, 0.3805, 0.3884, 0.1101, 0.3747, 0.3830,
        0.3737], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.3587, 0.4288, 0.1311, 0.1024, 0.1153, 0.3966, 0.1327, 0.3793, 0.1376,
        0.3951, 0.3790, 0.3909, 0.1308, 0.3805, 0.1035, 0.3848, 0.1119, 0.3481,
        0.3820, 0.4308, 0.1190, 0.1365, 0.1417, 0.3910, 0.1397, 0.4346, 0.3904,
        0.3823, 0.3828, 0.1543, 0.3987, 0.1402, 0.4084, 0.3759, 0.3755, 0.3433,
        0.4184, 0.4023, 0.1138, 0.3930, 0.3925, 0.3792, 0.1295, 0.1285, 0.3874,
        0.3687, 0.1153, 0.1052, 0.3662, 0.3603, 0.3523, 0.1334, 0.1138, 0.3524,
        0.3794, 0.3927, 0.3637, 0.3704, 0.1155, 0.1117, 0.1261, 0.1074, 0.3716,
        0.3875], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.2565, 0.1252, 0.2795, 0.3001, 0.1169, 0.2622, 0.1073, 0.2636, 0.1138,
        0.2666, 0.2851, 0.1566, 0.2949, 0.2833, 0.2885, 0.2799, 0.1305, 0.2853,
        0.2955, 0.2688, 0.2774, 0.2743, 0.2819, 0.1415, 0.2788, 0.1323, 0.1391,
        0.2660, 0.1329, 0.1279, 0.2718, 0.1462, 0.1184, 0.1041, 0.2818, 0.1148,
        0.2832, 0.1163, 0.2726, 0.2946, 0.2707, 0.1074, 0.2851, 0.2836, 0.2851,
        0.1391, 0.2916, 0.1271, 0.1098, 0.2832, 0.2931, 0.2799, 0.2918, 0.2799,
        0.1282, 0.2757, 0.1598, 0.2555, 0.1283, 0.2762, 0.2850, 0.2923, 0.2825,
        0.2972], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.5189, 0.6934, 0.4740, 0.5014, 0.4035, 0.4859, 0.6397, 0.6146, 0.6914,
        0.6042], device='cuda:0', grad_fn=<NormBackward1>)

Total parameter pruned: 450.0000052303076 (unstructured) 0 (structured)

Test: [0/79]	Time 0.126 (0.126)	Loss 1.6916 (1.6916) ([1.260]+[0.432])	Prec@1 50.781 (50.781)
 * Prec@1 51.560

 Total elapsed time  0:00:16.328617 
 FINETUNING


Total parameter pruned: 450.0000052303076 (unstructured) 0 (structured)

Test: [0/79]	Time 0.126 (0.126)	Loss 1.6916 (1.6916) ([1.260]+[0.432])	Prec@1 50.781 (50.781)
 * Prec@1 51.560
current lr 1.00000e-01
Grad=  tensor(0.8594, device='cuda:0')
Epoch: [1][0/391]	Time 0.147 (0.147)	Data 0.124 (0.124)	Loss 1.2784 (1.2784) ([1.278]+[0.000])	Prec@1 51.562 (51.562)
Epoch: [1][100/391]	Time 0.013 (0.015)	Data 0.000 (0.001)	Loss 1.2003 (1.2453) ([1.200]+[0.000])	Prec@1 60.156 (55.159)
Epoch: [1][200/391]	Time 0.013 (0.014)	Data 0.000 (0.001)	Loss 1.1409 (1.2044) ([1.141]+[0.000])	Prec@1 54.688 (56.720)
Epoch: [1][300/391]	Time 0.013 (0.014)	Data 0.000 (0.001)	Loss 1.1263 (1.1640) ([1.126]+[0.000])	Prec@1 62.500 (58.204)
Test: [0/79]	Time 0.154 (0.154)	Loss 1.0974 (1.0974) ([1.097]+[0.000])	Prec@1 60.938 (60.938)
 * Prec@1 63.570

 Elapsed time for training  0:00:23.555424
Total parameter pruned: 0.0 (unstructured) 0 (structured)
Test: [0/79]	Time 0.154 (0.154)	Loss 1.0974 (1.0974) ([1.097]+[0.000])	Prec@1 60.938 (60.938)
 * Prec@1 63.570
Best accuracy:  63.57
Test: [0/79]	Time 0.158 (0.158)	Loss 1.1351 (1.1351) ([1.135]+[0.000])	Prec@1 64.844 (64.844)
 * Prec@1 63.300
 Real pruned parameter  0
