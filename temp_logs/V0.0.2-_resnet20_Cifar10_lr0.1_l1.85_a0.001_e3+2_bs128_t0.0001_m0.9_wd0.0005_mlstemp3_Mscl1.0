V0.0.2-_resnet20_Cifar10_lr0.1_l1.85_a0.001_e3+2_bs128_t0.0001_m0.9_wd0.0005_mlstemp3_Mscl1.0
Files already downloaded and verified
M values:
 {Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 1.6352988481521606, Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 1.169867753982544, Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.9106662273406982, Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.7931119203567505, Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.654869556427002, Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.9789378643035889, Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.7008146047592163, Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False): 0.6066990494728088, Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.6057915091514587, Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.6954296231269836, Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.40856727957725525, Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.7257518768310547, Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.5365347862243652, Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False): 0.48648884892463684, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.5309917330741882, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.39136967062950134, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.41638830304145813, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.43563324213027954, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.300857812166214, Linear(in_features=64, out_features=10, bias=True): 1.863915205001831}
current lr 1.00000e-01
Grad=  tensor(34.2408, device='cuda:0')
Epoch: [0][0/391]	Time 1.832 (1.832)	Data 0.162 (0.162)	Loss 12.1904 (12.1904) ([3.237]+[8.954])	Prec@1 7.812 (7.812)
Epoch: [0][100/391]	Time 0.028 (0.047)	Data 0.000 (0.002)	Loss 4.5808 (6.5471) ([1.643]+[2.938])	Prec@1 32.031 (27.684)
Epoch: [0][200/391]	Time 0.028 (0.038)	Data 0.000 (0.001)	Loss 2.7444 (5.0209) ([1.525]+[1.220])	Prec@1 43.750 (33.609)
Epoch: [0][300/391]	Time 0.028 (0.035)	Data 0.000 (0.001)	Loss 2.4548 (4.1920) ([1.561]+[0.894])	Prec@1 42.188 (37.178)
Test: [0/79]	Time 0.238 (0.238)	Loss 5.2502 (5.2502) ([4.538]+[0.713])	Prec@1 21.875 (21.875)
 * Prec@1 23.210
current lr 1.00000e-01
Grad=  tensor(1.9794, device='cuda:0')
Epoch: [1][0/391]	Time 0.295 (0.295)	Data 0.247 (0.247)	Loss 2.0708 (2.0708) ([1.358]+[0.713])	Prec@1 44.531 (44.531)
Epoch: [1][100/391]	Time 0.030 (0.033)	Data 0.000 (0.003)	Loss 2.1347 (2.0872) ([1.485]+[0.650])	Prec@1 49.219 (48.461)
Epoch: [1][200/391]	Time 0.029 (0.031)	Data 0.000 (0.001)	Loss 1.8108 (2.0243) ([1.226]+[0.584])	Prec@1 60.938 (50.109)
Epoch: [1][300/391]	Time 0.029 (0.031)	Data 0.000 (0.001)	Loss 1.9046 (1.9889) ([1.319]+[0.586])	Prec@1 49.219 (50.833)
Test: [0/79]	Time 0.244 (0.244)	Loss 2.4859 (2.4859) ([1.958]+[0.528])	Prec@1 31.250 (31.250)
 * Prec@1 36.500
current lr 1.00000e-01
Grad=  tensor(3.4469, device='cuda:0')
Epoch: [2][0/391]	Time 0.270 (0.270)	Data 0.232 (0.232)	Loss 1.7867 (1.7867) ([1.259]+[0.528])	Prec@1 53.125 (53.125)
Epoch: [2][100/391]	Time 0.028 (0.032)	Data 0.000 (0.002)	Loss 1.7816 (1.7734) ([1.274]+[0.507])	Prec@1 50.781 (54.386)
Epoch: [2][200/391]	Time 0.029 (0.030)	Data 0.000 (0.001)	Loss 1.8218 (1.7453) ([1.337]+[0.485])	Prec@1 53.125 (55.313)
Epoch: [2][300/391]	Time 0.029 (0.030)	Data 0.000 (0.001)	Loss 1.7544 (1.7356) ([1.274]+[0.481])	Prec@1 55.469 (55.365)
Test: [0/79]	Time 0.244 (0.244)	Loss 2.0036 (2.0036) ([1.524]+[0.480])	Prec@1 50.781 (50.781)
 * Prec@1 42.490

 Elapsed time for training  0:00:40.430519
Total parameter pruned: 0.0 (unstructured) 0 (structured)

max weight is  tensor([0.7888, 0.6754, 1.5713, 0.3610, 0.7360, 0.4061, 1.5850, 0.6133, 0.4355,
        0.6143, 0.3464, 0.6975, 0.7011, 1.3113, 0.4598, 1.1194],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.5224, 0.7390, 0.3075, 0.4253, 0.4949, 0.4327, 0.5867, 0.2565, 0.5251,
        0.6018, 0.6948, 0.4484, 0.3660, 0.2316, 0.2498, 0.4203],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.8597, 0.3646, 0.8094, 0.4313, 0.4801, 0.2104, 0.4693, 0.3227, 0.5386,
        0.4572, 0.5422, 0.4505, 0.3616, 0.5589, 0.1067, 0.3224],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.7938, 0.4275, 0.4020, 0.5364, 0.5722, 0.4310, 0.2319, 0.6573, 0.3241,
        0.6587, 0.3251, 0.2772, 0.2131, 0.6978, 0.3866, 0.0899],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.3370, 0.2883, 0.5702, 0.3823, 0.3667, 0.3590, 0.4050, 0.2299, 0.3271,
        0.4989, 0.4297, 0.2817, 0.4569, 0.2666, 0.4576, 0.3354],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.1435, 0.5369, 0.2166, 0.3567, 0.3741, 0.5690, 0.3084, 0.3802, 0.2867,
        0.6725, 0.2764, 0.5318, 0.4178, 0.4713, 0.4363, 0.6283],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.3893, 0.1884, 0.4645, 0.2996, 0.1232, 0.2912, 0.0691, 0.4380, 0.2611,
        0.3380, 0.4051, 0.2902, 0.3349, 0.4038, 0.3179, 0.2546],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.3407, 0.2162, 0.2576, 0.3993, 0.2082, 0.1744, 0.1496, 0.2605, 0.2367,
        0.2365, 0.1835, 0.1715, 0.3045, 0.2679, 0.1722, 0.1906, 0.3417, 0.1378,
        0.3240, 0.1143, 0.2779, 0.0935, 0.2086, 0.4236, 0.1753, 0.2938, 0.3340,
        0.4494, 0.0303, 0.2317, 0.3046, 0.3528], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([0.4266, 0.0291, 0.0716, 0.0230, 0.2809, 0.0177, 0.2569, 0.3231, 0.2903,
        0.0415, 0.0525, 0.0648, 0.1314, 0.1136, 0.0363, 0.0250, 0.1964, 0.3428,
        0.2293, 0.0311, 0.4162, 0.2579, 0.3305, 0.1360, 0.0244, 0.0455, 0.3496,
        0.2816, 0.0213, 0.2214, 0.0383, 0.4144], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([0.2498, 0.0296, 0.0861, 0.0184, 0.2493, 0.0147, 0.3823, 0.0394, 0.0550,
        0.0542, 0.0382, 0.3389, 0.3116, 0.0186, 0.2219, 0.1011, 0.2872, 0.1980,
        0.1673, 0.0764, 0.3431, 0.1741, 0.0133, 0.0329, 0.0079, 0.3784, 0.0424,
        0.4731, 0.3626, 0.0417, 0.2248, 0.0079], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([0.1423, 0.0111, 0.0838, 0.0161, 0.0179, 0.0087, 0.2082, 0.2484, 0.2413,
        0.0165, 0.0340, 0.0299, 0.1366, 0.1144, 0.0506, 0.0159, 0.0503, 0.1697,
        0.0417, 0.0185, 0.2047, 0.1235, 0.1704, 0.0506, 0.0152, 0.0343, 0.2075,
        0.2265, 0.0047, 0.0911, 0.0066, 0.1624], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([0.0164, 0.0440, 0.2292, 0.0238, 0.1955, 0.0365, 0.0461, 0.0222, 0.2266,
        0.0420, 0.2351, 0.0440, 0.0409, 0.0591, 0.0581, 0.0319, 0.2527, 0.0390,
        0.2132, 0.0629, 0.1304, 0.1333, 0.0606, 0.0793, 0.2107, 0.1540, 0.0219,
        0.0306, 0.1607, 0.0909, 0.1760, 0.0903], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([0.1293, 0.0044, 0.0501, 0.0057, 0.0214, 0.0209, 0.1918, 0.1512, 0.2273,
        0.0068, 0.0269, 0.0475, 0.0705, 0.0638, 0.0297, 0.0065, 0.0975, 0.0879,
        0.0103, 0.0031, 0.1742, 0.0755, 0.0704, 0.0384, 0.0423, 0.0292, 0.2134,
        0.1474, 0.0083, 0.0860, 0.0033, 0.1222], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([0.0073, 0.0105, 0.0122, 0.0118, 0.0104, 0.0053, 0.0111, 0.0075, 0.0110,
        0.0125, 0.0120, 0.0117, 0.0068, 0.0105, 0.0127, 0.0102, 0.0097, 0.0134,
        0.0084, 0.0075, 0.0135, 0.0075, 0.0110, 0.0088, 0.0085, 0.0042, 0.0147,
        0.0112, 0.0071, 0.0132, 0.0118, 0.0151, 0.0093, 0.0108, 0.0097, 0.0112,
        0.0088, 0.0104, 0.0096, 0.0058, 0.0109, 0.0074, 0.0102, 0.0104, 0.0081,
        0.0138, 0.0174, 0.0111, 0.0105, 0.0051, 0.0087, 0.0078, 0.0047, 0.0104,
        0.0096, 0.0119, 0.0118, 0.0143, 0.0123, 0.0087, 0.0062, 0.0074, 0.0075,
        0.0084], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.0168, 0.0140, 0.0069, 0.0100, 0.0105, 0.0137, 0.0109, 0.0047, 0.0222,
        0.0090, 0.0147, 0.0213, 0.0197, 0.0131, 0.0066, 0.0095, 0.0286, 0.0289,
        0.0106, 0.0026, 0.0174, 0.0033, 0.0719, 0.0510, 0.0102, 0.0174, 0.0235,
        0.0330, 0.0280, 0.0038, 0.0193, 0.0118, 0.0113, 0.0238, 0.0050, 0.0121,
        0.0245, 0.0138, 0.0110, 0.0367, 0.0059, 0.0171, 0.0290, 0.0129, 0.0136,
        0.0086, 0.0078, 0.0195, 0.0264, 0.0168, 0.0116, 0.0071, 0.0156, 0.0093,
        0.0116, 0.0256, 0.0129, 0.0083, 0.0041, 0.0130, 0.0472, 0.0053, 0.0079,
        0.0163], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.0086, 0.0109, 0.0060, 0.0026, 0.0063, 0.0075, 0.0079, 0.0053, 0.0076,
        0.0114, 0.0051, 0.0036, 0.0057, 0.0109, 0.0031, 0.0127, 0.0084, 0.0062,
        0.0044, 0.0090, 0.0056, 0.0027, 0.0028, 0.0052, 0.0126, 0.0048, 0.0057,
        0.0118, 0.0092, 0.0039, 0.0067, 0.0070, 0.0057, 0.0057, 0.0132, 0.0145,
        0.0081, 0.0083, 0.0058, 0.0074, 0.0100, 0.0068, 0.0099, 0.0075, 0.0040,
        0.0126, 0.0084, 0.0118, 0.0037, 0.0049, 0.0078, 0.0118, 0.0068, 0.0051,
        0.0074, 0.0143, 0.0029, 0.0102, 0.0067, 0.0161, 0.0055, 0.0053, 0.0159,
        0.0077], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.0120, 0.0071, 0.0135, 0.0103, 0.0084, 0.0105, 0.0045, 0.0045, 0.0084,
        0.0094, 0.0080, 0.0113, 0.0047, 0.0231, 0.0068, 0.0120, 0.0088, 0.0063,
        0.0065, 0.0049, 0.0204, 0.0061, 0.0334, 0.0037, 0.0420, 0.0077, 0.0122,
        0.0146, 0.0143, 0.0067, 0.0112, 0.0063, 0.0067, 0.0086, 0.0071, 0.0132,
        0.0123, 0.0158, 0.0205, 0.0198, 0.0127, 0.0200, 0.0308, 0.0329, 0.0044,
        0.0173, 0.0060, 0.0209, 0.0078, 0.0112, 0.0097, 0.0062, 0.0073, 0.0079,
        0.0133, 0.0041, 0.0213, 0.0062, 0.0116, 0.0073, 0.0135, 0.0094, 0.0088,
        0.0098], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.0265, 0.0108, 0.0069, 0.0041, 0.0053, 0.0089, 0.0204, 0.0054, 0.0140,
        0.0108, 0.0041, 0.0165, 0.0047, 0.0093, 0.0070, 0.0217, 0.0117, 0.0078,
        0.0061, 0.0074, 0.0068, 0.0068, 0.0235, 0.0088, 0.0102, 0.0223, 0.0093,
        0.0062, 0.0084, 0.0116, 0.0155, 0.0131, 0.0123, 0.0088, 0.0061, 0.0094,
        0.0095, 0.0040, 0.0156, 0.0066, 0.0151, 0.0040, 0.0056, 0.0112, 0.0078,
        0.0271, 0.0053, 0.0079, 0.0214, 0.0158, 0.0077, 0.0137, 0.0110, 0.0040,
        0.0185, 0.0112, 0.0123, 0.0105, 0.0093, 0.0102, 0.0068, 0.0086, 0.0121,
        0.0037], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.0087, 0.0072, 0.0029, 0.0098, 0.0091, 0.0060, 0.0064, 0.0148, 0.0106,
        0.0047, 0.0123, 0.0097, 0.0119, 0.0167, 0.0079, 0.0062, 0.0557, 0.0077,
        0.0087, 0.0081, 0.0094, 0.0015, 0.0179, 0.0104, 0.0312, 0.0056, 0.0046,
        0.0079, 0.0037, 0.0036, 0.0073, 0.0041, 0.0131, 0.0178, 0.0055, 0.0049,
        0.0090, 0.0132, 0.0262, 0.0048, 0.0105, 0.0224, 0.0149, 0.0149, 0.0074,
        0.0066, 0.0150, 0.0084, 0.0090, 0.0048, 0.0075, 0.0061, 0.0064, 0.0084,
        0.0144, 0.0090, 0.0107, 0.0041, 0.0061, 0.0072, 0.0063, 0.0091, 0.0123,
        0.0048], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([1.0285, 1.5077, 1.0352, 1.0146, 1.0734, 1.4209, 1.5153, 1.2655, 1.7820,
        1.4220], device='cuda:0', grad_fn=<NormBackward1>)

Total parameter pruned: 35589.00026435405 (unstructured) 0 (structured)

Test: [0/79]	Time 0.245 (0.245)	Loss 2.0035 (2.0035) ([1.523]+[0.480])	Prec@1 50.781 (50.781)
 * Prec@1 42.490

 Total elapsed time  0:00:41.811567 
 FINETUNING


Total parameter pruned: 35589.00026435405 (unstructured) 0 (structured)

Test: [0/79]	Time 0.234 (0.234)	Loss 2.0036 (2.0036) ([1.524]+[0.480])	Prec@1 50.781 (50.781)
 * Prec@1 42.490
current lr 1.00000e-01
Grad=  tensor(1.1285, device='cuda:0')
Epoch: [3][0/391]	Time 0.266 (0.266)	Data 0.243 (0.243)	Loss 1.1427 (1.1427) ([1.143]+[0.000])	Prec@1 60.938 (60.938)
Epoch: [3][100/391]	Time 0.013 (0.016)	Data 0.000 (0.002)	Loss 1.0303 (1.1864) ([1.030]+[0.000])	Prec@1 62.500 (57.000)
Epoch: [3][200/391]	Time 0.013 (0.014)	Data 0.000 (0.001)	Loss 1.1661 (1.1497) ([1.166]+[0.000])	Prec@1 57.031 (58.582)
Epoch: [3][300/391]	Time 0.013 (0.014)	Data 0.000 (0.001)	Loss 1.0224 (1.1206) ([1.022]+[0.000])	Prec@1 60.938 (59.684)
Test: [0/79]	Time 0.234 (0.234)	Loss 1.0384 (1.0384) ([1.038]+[0.000])	Prec@1 64.062 (64.062)
 * Prec@1 61.940
current lr 1.00000e-01
Grad=  tensor(0.8930, device='cuda:0')
Epoch: [4][0/391]	Time 0.274 (0.274)	Data 0.253 (0.253)	Loss 1.0035 (1.0035) ([1.003]+[0.000])	Prec@1 66.406 (66.406)
Epoch: [4][100/391]	Time 0.014 (0.017)	Data 0.000 (0.003)	Loss 1.0155 (0.9960) ([1.016]+[0.000])	Prec@1 64.062 (64.813)
Epoch: [4][200/391]	Time 0.013 (0.015)	Data 0.000 (0.001)	Loss 1.0151 (0.9931) ([1.015]+[0.000])	Prec@1 65.625 (64.595)
Epoch: [4][300/391]	Time 0.013 (0.015)	Data 0.000 (0.001)	Loss 1.0625 (0.9825) ([1.062]+[0.000])	Prec@1 61.719 (65.033)
Test: [0/79]	Time 0.238 (0.238)	Loss 1.0616 (1.0616) ([1.062]+[0.000])	Prec@1 59.375 (59.375)
 * Prec@1 63.820

 Elapsed time for training  0:00:55.572385
Total parameter pruned: 0.0 (unstructured) 0 (structured)
Test: [0/79]	Time 0.236 (0.236)	Loss 1.0616 (1.0616) ([1.062]+[0.000])	Prec@1 59.375 (59.375)
 * Prec@1 63.820
Best accuracy:  63.82
Test: [0/79]	Time 0.235 (0.235)	Loss 1.0509 (1.0509) ([1.051]+[0.000])	Prec@1 62.500 (62.500)
 * Prec@1 63.760
 Real pruned parameter  0
