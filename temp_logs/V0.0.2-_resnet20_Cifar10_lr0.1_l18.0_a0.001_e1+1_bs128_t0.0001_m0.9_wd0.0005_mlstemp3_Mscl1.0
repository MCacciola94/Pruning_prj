V0.0.2-_resnet20_Cifar10_lr0.1_l18.0_a0.001_e1+1_bs128_t0.0001_m0.9_wd0.0005_mlstemp3_Mscl1.0
Files already downloaded and verified
M values:
 {Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 1.6352988481521606, Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 1.169867753982544, Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.9106662273406982, Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.7931119203567505, Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.654869556427002, Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.9789378643035889, Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.7008146047592163, Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False): 0.6066990494728088, Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.6057915091514587, Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.6954296231269836, Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.40856727957725525, Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.7257518768310547, Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.5365347862243652, Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False): 0.48648884892463684, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.5309917330741882, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.39136967062950134, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.41638830304145813, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.43563324213027954, Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False): 0.300857812166214, Linear(in_features=64, out_features=10, bias=True): 1.863915205001831}
current lr 1.00000e-01
Grad=  tensor(297.9196, device='cuda:0')
Epoch: [0][0/391]	Time 1.785 (1.785)	Data 0.167 (0.167)	Loss 91.1146 (91.1146) ([3.685]+[87.430])	Prec@1 10.938 (10.938)
Epoch: [0][100/391]	Time 0.029 (0.047)	Data 0.000 (0.002)	Loss 8.2535 (20.5511) ([2.134]+[6.120])	Prec@1 21.094 (21.759)
Epoch: [0][200/391]	Time 0.030 (0.039)	Data 0.000 (0.001)	Loss 5.9270 (13.7089) ([1.917]+[4.010])	Prec@1 19.531 (22.361)
Epoch: [0][300/391]	Time 0.029 (0.036)	Data 0.000 (0.001)	Loss 5.9389 (11.2177) ([2.054]+[3.885])	Prec@1 18.750 (22.848)
Test: [0/79]	Time 0.150 (0.150)	Loss 5.4323 (5.4323) ([1.913]+[3.519])	Prec@1 29.688 (29.688)
 * Prec@1 22.590

 Elapsed time for training  0:00:14.607568
Total parameter pruned: 0.0 (unstructured) 0 (structured)

max weight is  tensor([0.2365, 0.5546, 0.2999, 0.5439, 1.0806, 0.3477, 0.3641, 0.3799, 0.4083,
        0.2896, 0.3412, 0.1692, 0.0908, 0.1379, 0.3072, 0.9955],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.1363, 0.2233, 0.3387, 0.2095, 0.7554, 0.0833, 0.0566, 0.1734, 0.0907,
        0.3132, 0.0734, 0.1506, 0.2330, 0.0715, 0.0763, 0.2289],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.3781, 0.3604, 0.0564, 0.2048, 0.3426, 0.2027, 0.0254, 0.0704, 0.0368,
        0.0601, 0.0260, 0.0694, 0.3000, 0.0373, 0.0411, 0.0507],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.0728, 0.0390, 0.2762, 0.0926, 0.0960, 0.1397, 0.1064, 0.1034, 0.0711,
        0.1703, 0.1418, 0.0535, 0.0529, 0.0536, 0.0641, 0.1012],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.2395, 0.1503, 0.0352, 0.1172, 0.0852, 0.0194, 0.0132, 0.0139, 0.0181,
        0.0955, 0.0452, 0.0225, 0.0454, 0.0282, 0.0132, 0.0157],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.0368, 0.2408, 0.1026, 0.0614, 0.0846, 0.1253, 0.0927, 0.0423, 0.1160,
        0.0822, 0.1997, 0.0345, 0.0270, 0.1998, 0.0438, 0.2244],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.3614, 0.0787, 0.0400, 0.0964, 0.1978, 0.0054, 0.0222, 0.0498, 0.0345,
        0.0185, 0.0741, 0.0249, 0.0354, 0.0311, 0.0312, 0.0560],
       device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.0431, 0.0992, 0.0504, 0.0100, 0.0366, 0.0247, 0.1498, 0.0811, 0.1293,
        0.0084, 0.0327, 0.0560, 0.1185, 0.0168, 0.0204, 0.0177, 0.0530, 0.0371,
        0.0367, 0.0317, 0.0407, 0.0265, 0.0216, 0.1328, 0.0101, 0.0815, 0.0611,
        0.0664, 0.0219, 0.0504, 0.0622, 0.0242], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([0.0065, 0.0227, 0.0145, 0.1214, 0.0772, 0.0470, 0.0411, 0.0310, 0.0849,
        0.0565, 0.0577, 0.0560, 0.0572, 0.0080, 0.0151, 0.0129, 0.0052, 0.0177,
        0.1023, 0.0114, 0.0111, 0.0942, 0.0428, 0.0337, 0.2380, 0.0551, 0.0159,
        0.0378, 0.1273, 0.0165, 0.0242, 0.0791], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([0.0312, 0.0647, 0.0134, 0.0199, 0.0549, 0.0430, 0.0320, 0.0365, 0.0259,
        0.0283, 0.0263, 0.0115, 0.0423, 0.0212, 0.0495, 0.0082, 0.0368, 0.0082,
        0.0433, 0.0393, 0.0165, 0.0404, 0.0302, 0.0304, 0.0278, 0.0195, 0.0216,
        0.0120, 0.0149, 0.2404, 0.0292, 0.0150], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([0.0176, 0.0118, 0.0393, 0.0538, 0.0105, 0.0190, 0.0137, 0.0120, 0.0482,
        0.0141, 0.0251, 0.0253, 0.0307, 0.0247, 0.0278, 0.0322, 0.0170, 0.0163,
        0.0477, 0.0399, 0.0234, 0.0181, 0.0807, 0.0268, 0.0332, 0.0249, 0.0585,
        0.0159, 0.0416, 0.0198, 0.0126, 0.0260], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([0.0203, 0.0713, 0.0394, 0.0380, 0.0225, 0.0221, 0.0321, 0.0176, 0.0232,
        0.0256, 0.0817, 0.0475, 0.0555, 0.0108, 0.0207, 0.0529, 0.0242, 0.0223,
        0.0175, 0.0105, 0.0152, 0.0130, 0.0908, 0.0128, 0.0710, 0.0398, 0.0312,
        0.0167, 0.0249, 0.0169, 0.0517, 0.0435], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([0.0101, 0.0207, 0.0701, 0.1714, 0.0175, 0.0265, 0.0344, 0.0209, 0.0675,
        0.0418, 0.0564, 0.0057, 0.0361, 0.0596, 0.0116, 0.0175, 0.0159, 0.0511,
        0.0277, 0.0235, 0.2417, 0.0742, 0.0276, 0.1230, 0.0184, 0.0506, 0.0380,
        0.0182, 0.0329, 0.0401, 0.0440, 0.0127], device='cuda:0',
       grad_fn=<NormBackward1>)

max weight is  tensor([0.0217, 0.0136, 0.0196, 0.0369, 0.0315, 0.0281, 0.0146, 0.0047, 0.0241,
        0.0334, 0.0228, 0.0180, 0.0161, 0.0102, 0.0093, 0.0515, 0.0092, 0.0859,
        0.0060, 0.0114, 0.0109, 0.0325, 0.0382, 0.0091, 0.0344, 0.0161, 0.0165,
        0.0249, 0.0184, 0.0217, 0.0280, 0.0128, 0.0148, 0.0065, 0.0100, 0.0183,
        0.0326, 0.0099, 0.0120, 0.0088, 0.0120, 0.0323, 0.0208, 0.0126, 0.0201,
        0.0275, 0.0090, 0.0117, 0.0131, 0.0166, 0.0077, 0.0481, 0.0307, 0.0057,
        0.0125, 0.0167, 0.0327, 0.0443, 0.0235, 0.0060, 0.0310, 0.0101, 0.0107,
        0.0253], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.0170, 0.2945, 0.0305, 0.0233, 0.1771, 0.0961, 0.0245, 0.0612, 0.0467,
        0.0194, 0.0052, 0.0051, 0.0852, 0.5050, 0.0236, 0.0359, 0.0590, 0.5146,
        0.0101, 0.3358, 0.2919, 0.1452, 0.0034, 0.0293, 0.0422, 0.4482, 0.0095,
        0.0097, 0.0292, 0.0383, 0.0783, 0.0196, 0.0272, 0.0193, 0.1331, 0.0334,
        0.0404, 0.0173, 0.0544, 0.1474, 0.0220, 0.0418, 0.0304, 0.0134, 0.0278,
        0.0198, 0.1033, 0.0193, 0.0143, 0.3786, 0.0116, 0.0309, 0.0645, 0.0622,
        0.0424, 0.3718, 0.5229, 0.0140, 0.0930, 0.0396, 0.0399, 0.0497, 0.0607,
        0.0134], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.0247, 0.0337, 0.0074, 0.0307, 0.0270, 0.0557, 0.0273, 0.0206, 0.0181,
        0.0199, 0.0068, 0.0102, 0.0042, 0.0122, 0.0157, 0.0061, 0.0180, 0.0247,
        0.0686, 0.0254, 0.0107, 0.0109, 0.0066, 0.0084, 0.0141, 0.0453, 0.0380,
        0.0076, 0.0058, 0.0111, 0.0088, 0.0278, 0.0078, 0.0135, 0.0071, 0.0214,
        0.0297, 0.0130, 0.0074, 0.0137, 0.0144, 0.0232, 0.0173, 0.0156, 0.0085,
        0.0083, 0.0282, 0.0040, 0.0203, 0.0291, 0.0195, 0.0150, 0.0174, 0.0307,
        0.0254, 0.0065, 0.0153, 0.0232, 0.0206, 0.0061, 0.0224, 0.0235, 0.0143,
        0.0096], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.0173, 0.0270, 0.1242, 0.0190, 0.0354, 0.0212, 0.0632, 0.0504, 0.0270,
        0.0177, 0.1849, 0.0047, 0.1177, 0.0096, 0.1191, 0.0185, 0.0773, 0.0281,
        0.0175, 0.2748, 0.0590, 0.0136, 0.0372, 0.0097, 0.0152, 0.1275, 0.2209,
        0.0587, 0.1441, 0.1467, 0.0459, 0.3441, 0.1503, 0.0264, 0.0416, 0.0490,
        0.0409, 0.0234, 0.0595, 0.0196, 0.0214, 0.0212, 0.1474, 0.0043, 0.0638,
        0.0366, 0.0327, 0.0382, 0.0493, 0.2559, 0.0381, 0.0377, 0.0255, 0.0158,
        0.0233, 0.0230, 0.0115, 0.2886, 0.0430, 0.2391, 0.6636, 0.1209, 0.0240,
        0.0195], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.0149, 0.0800, 0.0148, 0.0051, 0.0208, 0.0163, 0.0222, 0.0202, 0.0270,
        0.0187, 0.0326, 0.0297, 0.0156, 0.0669, 0.0227, 0.0558, 0.0338, 0.0532,
        0.0156, 0.0406, 0.0233, 0.0175, 0.0104, 0.0399, 0.0338, 0.0157, 0.0100,
        0.0323, 0.0203, 0.0509, 0.0071, 0.0162, 0.0181, 0.0217, 0.0178, 0.0182,
        0.0503, 0.0251, 0.0178, 0.0142, 0.0077, 0.0301, 0.0237, 0.0398, 0.0239,
        0.0189, 0.0129, 0.0194, 0.0267, 0.0221, 0.0212, 0.0366, 0.0209, 0.0103,
        0.0690, 0.0163, 0.0668, 0.0195, 0.0253, 0.0093, 0.0145, 0.0176, 0.0422,
        0.0163], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.0821, 0.0047, 0.0366, 0.0271, 0.0147, 0.0587, 0.0227, 0.0187, 0.0898,
        0.0568, 0.0132, 0.0229, 0.0134, 0.0405, 0.0362, 0.0090, 0.0462, 0.2613,
        0.0303, 0.0419, 0.0624, 0.0944, 0.0316, 0.0242, 0.0035, 0.2453, 0.0203,
        0.0763, 0.0200, 0.0197, 0.1041, 0.0125, 0.0426, 0.0553, 0.0082, 0.0621,
        0.0263, 0.0340, 0.0047, 0.0465, 0.0716, 0.0407, 0.3615, 0.0264, 0.0121,
        0.0133, 0.3868, 0.0273, 0.0861, 0.0655, 0.0426, 0.0141, 0.0311, 0.0614,
        0.0541, 0.0431, 0.0258, 0.0141, 0.0157, 0.0650, 0.0366, 0.0554, 0.0055,
        0.0336], device='cuda:0', grad_fn=<NormBackward1>)

max weight is  tensor([0.8784, 0.6709, 0.5578, 0.5007, 0.6064, 0.5665, 0.5450, 0.4256, 1.1363,
        0.7429], device='cuda:0', grad_fn=<NormBackward1>)

Total parameter pruned: 15018.000144407153 (unstructured) 0 (structured)

Test: [0/79]	Time 0.154 (0.154)	Loss 5.4323 (5.4323) ([1.913]+[3.519])	Prec@1 29.688 (29.688)
 * Prec@1 22.580

 Total elapsed time  0:00:15.848026 
 FINETUNING


Total parameter pruned: 15018.000144407153 (unstructured) 0 (structured)

Test: [0/79]	Time 0.151 (0.151)	Loss 5.4323 (5.4323) ([1.913]+[3.519])	Prec@1 29.688 (29.688)
 * Prec@1 22.590
current lr 1.00000e-01
Grad=  tensor(4.0510, device='cuda:0')
Epoch: [1][0/391]	Time 0.204 (0.204)	Data 0.181 (0.181)	Loss 1.9311 (1.9311) ([1.931]+[0.000])	Prec@1 25.781 (25.781)
Epoch: [1][100/391]	Time 0.013 (0.015)	Data 0.000 (0.002)	Loss 1.6665 (1.8497) ([1.667]+[0.000])	Prec@1 32.812 (29.409)
Epoch: [1][200/391]	Time 0.013 (0.014)	Data 0.000 (0.001)	Loss 1.7901 (1.7832) ([1.790]+[0.000])	Prec@1 32.031 (32.502)
Epoch: [1][300/391]	Time 0.013 (0.014)	Data 0.000 (0.001)	Loss 1.5479 (1.7168) ([1.548]+[0.000])	Prec@1 37.500 (35.444)
Test: [0/79]	Time 0.187 (0.187)	Loss 1.6768 (1.6768) ([1.677]+[0.000])	Prec@1 37.500 (37.500)
 * Prec@1 36.630

 Elapsed time for training  0:00:23.124864
Total parameter pruned: 1.0 (unstructured) 0 (structured)
Test: [0/79]	Time 0.190 (0.190)	Loss 1.6768 (1.6768) ([1.677]+[0.000])	Prec@1 37.500 (37.500)
 * Prec@1 36.630
Best accuracy:  36.63
Test: [0/79]	Time 0.188 (0.188)	Loss 1.6633 (1.6633) ([1.663]+[0.000])	Prec@1 39.062 (39.062)
 * Prec@1 37.380
 Real pruned parameter  0
